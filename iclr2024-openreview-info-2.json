{"jXR5pjs1rV": {"paper_info": {"Supplementary Material": "pdf", "Primary Area": "societal considerations including fairness, safety, privacy", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Human Preference Alignment, Large Language Model, Data Efficiency", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "An empirical study on learning customized human preferences while preserving general preference ability.", "Abstract": "Reward models (RMs) are essential for aligning large language models (LLMs) with human preferences to improve interaction quality. However, the real world is pluralistic, which leads to diversified human preferences with respect to different religions, politics, cultures, etc. Moreover, each individual can have their unique preferences on various topics. Neglecting the diversity of preferences, current human feedback aligning methods only consider a general reward model, which is below satisfaction for customized or personalized application scenarios. To explore customized preference learning, we collect a domain-specific preference (DSP) dataset, which consists of comprehensive user queries and corresponding responses preferred from four practical domains. Besides, from the perspective of data efficiency, we propose a three-stage customized RM learning scheme, then empirically verify its effectiveness on both general preference datasets and our DSP set. Furthermore, we test multiple training and data strategies on the three learning stages. We find several ways to better preserve the general preferring ability while training the customized RMs, especially general preference enrichment, and customized preference imitation learning.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9397", "PDF Url": "https://openreview.net/pdf?id=jXR5pjs1rV"}, "review_info": []}, "lK2V2E2MNv": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Multimodal learning, vision-language tasks, frozen LLMs, optimal transport, assignment prediction", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "This paper presents to bridge frozen image encoders and large language models (LLMs) for grounding LLMs to images.", "Abstract": "This paper introduces VLAP, a novel approach that bridges pretrained vision models and large language models (LLMs) to make frozen LLMs understand the visual world. VLAP transforms the embedding space of pretrained vision models into the LLMs' word embedding space using a single linear layer for efficient and general-purpose visual and language understanding. Specifically, we harness well-established word embeddings to bridge two modality embedding spaces. The visual and text representations are simultaneously assigned to a set of word embeddings within pretrained LLMs by formulating the assigning procedure as an optimal transport problem. We predict the assignment of one modality from the representation of another modality data, enforcing consistent assignments for paired multimodal data. This allows vision and language representations to contain the same information, grounding the frozen LLMs' word embedding space in visual data. Moreover, a robust semantic taxonomy of LLMs can be preserved with visual data since the LLMs interpret and reason linguistic information from correlations between word embeddings. Experimental results show that VLAP achieves substantial improvements over the previous linear transformation-based approaches across a range of vision-language tasks, including image captioning, visual question answering, and cross-modal retrieval. We also demonstrate the learned visual representations hold a semantic taxonomy of LLMs, making visual semantic arithmetic possible.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Submission Number": "9396", "PDF Url": "https://openreview.net/pdf?id=lK2V2E2MNv"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9396 by Area Chair H155", "Subheading": "Meta ReviewbyArea Chair H15504 Dec 2023, 12:24 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper proposes VLAP, a method to bridge vision encoders and language models through assignment prediction. VLAP achieves substantial improvements in various vision-language tasks and demonstrates good performance in visual semantic arithmetic.\nOverall, Reviewers m8gW and 5A8P provided positive reviews, finding the proposed method interesting and acknowledging its achievement of state-of-the-art results. Reviewer 5A8P highlighted the method's incremental nature compared to existing work and requested ablation tests to justify the impact of these changes. The authors addressed these comments during the rebuttal process, which I found satisfactory. However, neither of these reviewers responded to the authors' rebuttal.\nReviewers dYxb, zAaX, and oDtB offered slightly negative reviews. Their main concern, among others, was the proposed method is incremental, despite its strong results across various tasks. The authors responded comprehensively to all reviewer comments, which I found satisfactory. Only Reviewer oDtB responded to the authors' rebuttal, expressing satisfaction with the response and requesting experiments on larger datasets. The authors acknowledged this need but, despite their intent to conduct these experiments, it did not change Reviewer oDtB's rating.\nConsidering the above discussion and the rebuttal/changes made to the paper, I recommend acceptance. Although the idea might be viewed as incremental, the experiments showcase strong results that could significantly impact the machine learning community specializing in this topic.\nJustification For Why Not Higher Score:\nThe rebuttal didn't considerably alter the reviewers' rating.\nJustification For Why Not Lower Score:\nA lower score would typically result in the rejection of the paper; however, this paper holds the potential to make an impact on the ML community focusing on the topic."}, {"Heading": "General response to the reviewers", "Subheading": "Official CommentbyAuthors20 Nov 2023, 07:21 (modified: 20 Nov 2023, 07:31)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewers for their positive evaluation and constructive comments.\n    We are pleased that the reviewers recognized that VLAP is $\\textbf{well-motivated}$ (m8gW, dYxB), the problem is $\\textbf{clearly stated}$ (m8gW, 5A8P, zAaX), and the idea that uses LLMs' word embeddings is $\\textbf{interesting}$ (oDtB).\n    We notice that the main concerns of the reviewers come from the lack of ablation studies.\n    During the rebuttal period, we conducted extensive ablation studies and enhanced the overall completeness through meticulous paper proofreading, notably in the Introduction section. These efforts aimed to enhance readability and clearly articulate the novelty of our work.\n    We would like to first address the concerns about the learning objective that all reviewers commonly pointed out.\nAblation for the balancing parameters\n$\\lambda_\\text{map}$\n$\\lambda_\\text{cap}$\nCIDEr-D\nCLIP-S\nRef-S\n0\n1\n51.7\n72.1\n76.3\n0.2\n0.8\n62.3\n80.3\n85.0\n0.4\n0.6\n68.1\n84.8\n89.2\n0.5\n0.5\n69.6\n86.3\n91.6\n0.6\n0.4\n69.9\n86.7\n91.8\n0.8\n0.2\n64.5\n83.1\n87.8\n1\n0\n49.6\n72.4\n76.1\nWe report the zero-shot image captioning performance on MSCOCO corresponding to different ratios between $\\lambda_\\text{map}$ and $\\lambda_\\text{cap}$ in equation (7) while keeping the sum of two terms as 1.\nFor example, the final objective function of the first row (i.e., $\\lambda_\\text{map}:\\lambda_\\text{cap} = 0:1$) is $\\mathcal{L} = \\mathcal{L}_\\text{cap}$, which is equivalent to the learning objective of LiMBeR [1] and the first stage of LLaVA [2].\nWith the language modeling objective, VLAP shows significantly poor performance, attaining 51.7 of CIDEr-D.\nIncreasing the ratio of $\\lambda_\\text{map}$ gradually improves the performance, achieving the best performance of 69.9 with $\\lambda_\\text{map}:\\lambda_\\text{cap} = 0.6:0.4$.\nMeanwhile, VLAP with only assignment prediction (i.e., $\\mathcal{L} = \\mathcal{L}_\\text{map}$) performs worse than with only language modeling, showing a performance of 49.6.\nThe results demonstrate the effectiveness of the proposed assignment prediction objective while emphasizing the necessity of the language modeling objective to leverage the generative ability of LLMs.\nWe add those results in Table. 7(a) and discussion in Appendix. D.\n[1] J. Merullo et al., ``Linear mapping from image to text space,\" ICLR'23\n[2] H. Liu et al., ``Visual instruction tuning,\" NeurIPS'23", "Replies": [{"Heading": "General response to the reviewers", "Subheading": "Official CommentbyAuthors20 Nov 2023, 07:22 (modified: 20 Nov 2023, 08:31)EveryoneRevisions", "Content": "Comment:\nVLAP with other cross-modal alignment objectives\n$\\mathcal{L}_\\text{cap}$\n$\\mathcal{L}_\\text{ITM}$\n$\\mathcal{L}_\\text{ITC}$\n$\\mathcal{L}_\\text{map}$\nCIDEr-D\nCLIP-S\nRef-S\nv\n51.7\n72.1\n76.3\nv\nv\n58.4\n78.2\n81.7\nv\nv\nv\n61.8\n79.0\n82.3\nv\nv\nv\nv\n65.7\n82.5\n85.8\nv\nv\n69.9\n86.7\n91.8\nWe provide the ablation analysis with the image-text matching (ITM) and image-text contrastive (ITC) objectives used in [3, 4, 5].\n    We modify the ITC and ITM objectives to evaluate the performance of VLAP trained with these objectives.\n    For ITC, we contrast the similarity between averaged image and text representations of a positive pair against those of negative pairs in a batch.\n    The ITC objective $\\mathcal{L}_\\text{ITC}$ is defined as the cross-entropy loss between pairwise similarities and the groundtruth one-hot similarities, where the positive pair has 1 and the negative pairs have 0.\n    For ITM, we learn an additional linear layer as a binary classifier to determine whether an image-text pair is matched or not.\n    We concatenate the averaged image and text representations and feed them into the classifier with the softmax activation.\n    Following [3, 4, 5], we also employ the hard negative sampling strategy based on the pairwise similarity.\n    As shown in the above table, the ITM and ITC objectives contribute to performance improvement with $\\mathcal{L}_\\text{cap}$.\n    However, we notice that the ITM and ITC objectives hurt overall performance, as shown in the performance comparison between the last two rows in the table.\n    We carefully argue that ITM and ITC solely focus on direct pairwise comparisons without considering the semantic correlation between predefined two embedding spaces.\n    Namely, they enforce instance discrimination and encourage the existence of the modality gap.\n    By comparing the cross-modal intermediate assignments, we can relax the instance discrimination task, effectively reducing the modality gap.\n    We add those results in Table. 7(b) and discussion in Appendix. D.\n[3] J. Li et al., ``BLIP-2: Bootstrapping language-image pre-training with frozen image encoders and large language models,\" ICML'23\n[4] J. Li et al., ``Align before fuse: Vision and language representation learning with momentum distillation,\" NeurIPS'21\n[5] J. Li et al., ``BLIP: Bootstrapping language-image pre-training for unified vision-language understanding and generation,\" arXiv'22\nNext, we carefully address each reviewer's remaining concerns."}]}, {"Heading": "Official Review of Submission9396 by Reviewer m8gW", "Subheading": "Official ReviewbyReviewer m8gW01 Nov 2023, 02:28 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper aims to align the LLMs (encoder/decoder or just decoder) with image encoders such that the LLMs can comprehend visual input better. It further restricts the design space to freeze the original LLM and visual encoder, just relying on a cheap learned linear transformation. To adapt such a transformation, the paper presents two learning objectives -- assignment prediction and image captioning. Empirical results are presented on 3 different tasks -- image captioning, VQA and cross-modal retrieval (I2T, T2I).\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe problem is well motivated with wide applications.\nThe paper is mostly well written and explained.\nThe empirical results show a big delta which demonstrates the effectiveness of the approach. The studies are also conducted on wide range of problem settings.\nWeaknesses:\nThe motivation for restricting the learned parameter space to just linear layers is unclear -- it would have been more interesting to see more analysis around different learned parameter space including non-linear layers.\nQuestions:\n-- Can the authors show ablation studies for the L_map and L_cap objectives to develop better understanding of each component?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 07:31Everyone", "Content": "Comment:\nThank you for your constructive review and valuable suggestions! Below, we provide a detailed response to your questions and comments. If any of our responses fail to sufficiently address your concerns, please inform us, and we will promptly follow up.\n[W1] VLAP with non-linear space\nWe would like to emphasize that our method diverges from traditional objectives in linear transformation-based approaches by introducing an alternative objective that avoids direct representation comparisons.\nIn addition, although our method dramatically boosted the performance of VLMs based on linear transformation, but nothing is specifically designed for this purpose only.\nAs shown in the general response, our assignment prediction objective outperforms other objectives used in the modular-based methods.\nThe results suggest that the proposed assignment prediction will contribute to the modular-based methods.\nTo address the reviewer's suggestion, we are conducting additional experiments for the non-linear space, such as multiple linear layers with activation functions and an adapter, which is a trainable bottleneck module [1].\nWe will include the analysis in the revised paper.\n[1] J. He et al., ``Towards a unified view of parameter-efficient transfer learning,\" ICLR'22\n[Q1] Ablation for the balancing parameters\nThanks for the question. We present the ablation results corresponding to the balancing parameters in equation (7) in the general response.\nPlease refer to them."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 12:54 (modified: 21 Nov 2023, 23:01)EveryoneRevisions", "Content": "Comment:\n[W1] VLAP with non-linear space\nMSCOCO\nMethod\nObjective\nTrain. Params.\nCIDEr-D\nCLIP-S\nRef-S\n(i)\nVLAP w/non-linearity\n$\\mathcal{L}_\\text{cap}$\n1.8M\n55.6\n77.1\n80.5\n(ii)\nVLAP w/non-linearity\n$\\mathcal{L}_\\text{cap}+\\mathcal{L}_\\text{map}$\n1.8M\n71.1\n88.9\n92.4\n(iii)\nVLAP\n$\\mathcal{L}_\\text{cap}+\\mathcal{L}_\\text{map}$\n0.6M\n69.4\n87.6\n92.0\nTo address the reviewer's suggestion, we conduct additional experiments to evaluate VLAP with the simplest non-linear mapping layers, i.e., three linear layers with the ReLU activation function, as shown in the above table.\nNote that CLIP ViT-B/32 and T5$_\\text{Base}$ are used as the vision model and LLM, respectively.\nThe comparison between (i) and (iii) shows that VLAP with the original setting outperforms VLAP with the linear layers, demonstrating that the learning objective has a greater impact on overall performance than the non-linearity.\nMeanwhile, the comparison between (ii) and (iii) shows that the performance can be slightly improved with the non-linear layers when the learning objective is fixed.\nAlthough we only presented results with the simplest form of non-linear modules, the results suggest that VLAP will show further improved performance when combined with sophisticated modular-based approaches (e.g. Q-Former in BLIP-2)."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:54 (modified: 23 Nov 2023, 06:54)EveryoneRevisions", "Content": "Comment:\n[W1] VLAP with non-linear space (update)\nMSCOCO\nMethod\nObjective\nTrain. Params.\nCIDEr-D\nCLIP-S\nRef-S\n(i)\nVLAP w/linear layers\n$\\mathcal{L}_\\text{cap}$\n1.8M\n55.6\n77.1\n80.5\n(ii)\nVLAP w/linear layers\n$\\mathcal{L}_\\text{cap}+\\mathcal{L}_\\text{map}$\n1.8M\n71.1\n88.9\n92.4\n(iii)\nVLAP w/adapter\n$\\mathcal{L}_\\text{cap}+\\mathcal{L}_\\text{map}$\n0.4M\n69.7\n87.9\n92.1\n(iv)\nVLAP\n$\\mathcal{L}_\\text{cap}+\\mathcal{L}_\\text{map}$\n0.6M\n69.4\n87.6\n92.0\nWe update the results of VLAP with the adapter.\nWe use a single adapter, which has the dimension of the bottleneck 256 and the ReLU activation between down-/up-projection layers.\nSimilar to the comparison between (ii) and (iv), the comparison between (iii) and (iv) shows that the non-linearity improves the performance despite the smaller number of parameters (0.4M vs 0.6M).\nThis result consistently suggests that VLAP will show further improved performance when combined with sophisticated modular-based approaches (e.g. Q-Former in BLIP-2)."}]}, {"Heading": "Official Review of Submission9396 by Reviewer oDtB", "Subheading": "Official ReviewbyReviewer oDtB01 Nov 2023, 00:37 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposed to bridge the vision and language modalities by predicting the assignment between LLM word embeddings and those two modalities. Specifically, the optimal transport is employed to decide the assignment between LLM word embeddings and image/caption contextualized embeddings, and then the model is required to predict the assignment of one modality from the other modality. Experiments are conducted on multiple tasks/datasets to prove the effectiveness of the proposed method.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nDemanding one modality's representation to predict the assignment between the other modality and common feature space (LLM word embedding) is an interesting idea to bridge two modalities.\nEvaluations on different tasks show a better performance than previous work.\nWeaknesses:\nComprehensive ablation of w/ and wo/ assignment prediction on the same vision/language backbones is missing.\nComparison with other baselines that are designed for alignment is missing. For example, contrastive alignment in ALBEF, BLIP, and the first-stage alignment by BLIP2 which includes image-text matching, and image-grounded text generation.\nIn experiments, the pre-training data is CC3M which is too small in terms of scale. Whether this method can be generalized to larger scale is not validated.\nIn Tab1,2,3, when compared with previous works, the vision/language backbone is always different. I wonder if using the same backbones as previous works, will the proposed method still outperform them?\nQuestions:\nDoes the LLM word embedding have to be from the same LLM as used in language encoding?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 07:44Everyone", "Content": "Comment:\nThank you for your constructive review and valuable suggestions! Below, we provide a detailed response to your questions and comments. If any of our responses fail to sufficiently address your concerns, please inform us, and we will promptly follow up.\n[W1] Ablation for assignment prediction\nWe present the ablation results corresponding to the balancing parameters in equation (7) in the general response. Please refer to that section for more details.\nThe result without the assignment prediction objective corresponds to $\\lambda_\\text{map}:\\lambda_\\text{cap}=0:1$.\nTo briefly sum up, the assignment prediction objective combined with $\\mathcal{L}_\\text{cap}$ improves the performance.\n[W2] VLAP with other cross-modal alignment\nThanks for the constructive suggestion.\nWe present the results with the additional objectives, including the image-text matching (ITM) and image-text contrastive (ITC) objectives, in the general response.\nBriefly, those two objectives show less performance improvement than our proposed assignment prediction.\n[W3] Scale of the pretraining dataset\nThank you for your valuable suggestion.\nAs previous works for pretraining VLMs have proven, a larger pretraining dataset should bring better results on zero-shot vision-language tasks.\nTo verify the impact of the scale of the training dataset on zero-shot performance, we will train VLAP with a large-scale dataset (e.g. CC12M) and will include results in the revised paper.\nHowever, we would like to emphasize that our method mainly focuses on presenting an efficient methodology (i.e., linear transformation, using pretrained encoders, small-scale training) to make VLMs.\n[W4] VLAP with other backbone\nMethod\nVis. Encoder\nLang. Model\nNoCaps-In\nNoCaps-Out\nNoCaps-Near\nNoCaps-All\nNoCaps-CLIP-S\nNoCaps-Ref-S\nMSCOCO-CIDEr-D\nMSCOCO-CLIP-S\nMSCOCO-Ref-S\nMAGMA\nCLIP RN50x16\nGPT-J\n30.4\n43.4\n36.7\n38.7\n74.3\n78.7\n47.5\n75.3\n79.6\nLiMBeR\nCLIP RN50x16\nGPT-J\n34.3\n48.4\n41.6\n43.9\n74.7\n79.4\n54.9\n76.2\n80.4\nVLAP\nCLIP ViT-B/32\nOPT\n48.2\n62.7\n59.3\n61.3\n84.8\n88.5\n69.9\n86.7\n91.8\nVLAP\nCLIP ViT-B/32\nT5\n48.3\n62.7\n59.6\n61.6\n85.1\n88.7\n69.4\n87.6\n92.0\nVLAP\nCLIP RN50x16\nGPT-J\n53.8\n67.5\n65.7\n64.5\n88.3\n90.1\n75.3\n90.6\n72.2\nWhile we used the transformer-based vision models (i.e., CLIP ViT-B/32 and BEiT) and the relatively small scale of LLMs (i.e., OPT$_\\text{1.3B}$ and T5$_\\text{Base}$) in the main paper, VLAP can be applied to all publicly available vision models and LLMs.\nFollowing MAGMA and LiMBeR, we additionally evaluate VLAP with the CNNs-based vision model (i.e., CLIP RN50x16) and the larger LLM (i.e., GPT-J, which has 6B parameters) for zero-shot image captioning on NoCaps and MSCOCO.\nNot surprisingly, VLAP with the larger LLM achieves better performance than with the smaller LLMs, significantly outperforming MAGMA and LiMBeR by large margins across all metrics with the same backbones.\nWe add the results to Table. 9 in Appendix.\n[Q1] Consistency of the word embedding in LLMs\nWhile word embedding of any LLMs can be used, we exploit the word embedding within the LLM used for language encoding for two main reasons:\n(1) LLMs use word embeddings as a basis to produce text representations, indicating text representations already have high correlations with word embeddings.\nTherefore, the consistency of LLM for word embedding and language encoding makes the assignment for language data confident.\n(2) The inconsistency of LLMs for word embedding and language encoding requires unnecessary memory (e.g. OPT$_\\text{1.3B}$ has about 100M parameters for the word embedding)."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 09:33Everyone", "Content": "Comment:\nWe thank you for your time and effort in reviewing our paper. Your insights have been highly valued, and your feedback is crucial to our progress. We understand that you have a busy schedule, and we again appreciate your time and attention to this matter. We have addressed all of your comments in our rebuttal. We would be grateful if you could please take a look at our rebuttal. If there are any additional materials or information you may require to facilitate the review process, please let us know. Your prompt attention to this matter is greatly appreciated.\nThank you again for your help. Sincerely Authors"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 01:46 (modified: 23 Nov 2023, 02:02)EveryoneRevisions", "Content": "Comment:\nDear Reviewer oDtB,\nThanks for your constructive and valuable comments on our paper. We have revised our paper to address the reviewer's concerns.\n[W1, W2] Ablation regarding objectives.\nWe added ablation analyses for the learning objectives, including the hyperparameters and additional objectives in Appendix Section D.\n[W4] VLAP with other backbone.\nWe added the results of VLAP with CLIP RN50x16 and GPT-J, which are the same backbone as the baselinse, MAGMA and LiMBeR in Appendix Section D.\nWith the discussion deadline approaching in a few hours, we are eager to receive your feedback."}, {"Heading": "Official Comment by Reviewer oDtB", "Subheading": "Official CommentbyReviewer oDtB23 Nov 2023, 02:28Everyone", "Content": "Comment:\nI have read the author's response and other reviewer's reviews. I appreciate the author's efforts and devotion to solving our concerns. Most of my concerns are solved. However...\nI still think it's necessary to experiment with the larger dataset to see how this method performs with the increase in data volume. Many methods, especially for efficient training, don't show performance improvement with larger data scales. These works have merit and contribution in terms of efficient training and fast learning in small/modest data, but it's also important to demonstrate the relationship between performance gain and data scale. Not generalizing to a larger data scale is not a weakness, but we have to let the audience know in which cases/scales our method shines and fails."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 03:18Everyone", "Content": "Comment:\nWe strongly agree with the reviewer's opinion. Now we are training VLAP on the CC12M and LAION400M datasets to verify the effectiveness of the dataset scale. We apologize for not being able to share the results during this discussion period as the scale of the dataset is extensively large. It is certain that these findings will be included in the final version."}]}, {"Heading": "Official Review of Submission9396 by Reviewer 5A8P", "Subheading": "Official ReviewbyReviewer 5A8P31 Oct 2023, 15:06 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces VLAP bridges vision encoders and language models through assignment prediction and the use of word embeddings to map visual representations into language space. \nAn optimal transport-based training objective is proposed to enforce the consistency of word assignments for paired multimodal data. This allows frozen LLMs to ground their word embedding space in visual data and use their robust semantic taxonomy visually. \nThe experiments demonstrate that VLAP outperforms the linear transformation-based approaches in a variety of vision-language tasks, such as image captioning, visual question answering, and cross-modal retrieval.\nIt also shows that the visual representations that have been acquired contain a semantic taxonomy of LLMs, thus making it possible to do visual semantic arithmetic.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n2 fair\nStrengths:\nThe paper is well-written and easy to follow.\nThe work proposed a straightforward way of learning the linear projection layer for visual modality to learn multimodal representation, which accommodates the LLM generation.\nThe visualization shows an impressive semantic arithmetic ability to combine multimodality understanding in LLM generation.\nWeaknesses:\n(1) The main concern of this work is the methodology is relatively incremental without new concepts or findings.\nConcept-wise and architecture-wise, it is similar to Asano et al. (2020) Selavi, which performs optimal transport across modalities with similar pipelines. Mathematics using the Sinkhorn clustering Swav as Caron et al. (2020).\n(2) The main difference lies in 3 parts: word embedding as fixed center space, different distribution assumptions (polytope), and LLM application.\nThe first two are the most interesting part, which will be different from previous Sinkhorn-based work.\nHowever, there is no ablation study on these two components, which leads the readers to question whether borrowing existing Selavi and Swav will also work.\n(3) Also, there is no ablation on different objectives, such as existing next-word prediction on learning visual projection on LLM.\nQuestions:\nEither additional ablation, justification, or additional baseline can elaborate the concern in the weakness (2).\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 07:52Everyone", "Content": "Comment:\nThank you for your constructive review and valuable suggestions! Below, we provide a detailed response to your questions and comments. If any of our responses fail to sufficiently address your concerns, please inform us, and we will promptly follow up.\n[W1, W2] Novelty and ablation for assignment prediction\nThanks for your valuable comments.\nAs the reviewer mentioned, our VLAP differs from the previous optimal transport-based (or clustering-based) approaches [1, 2, 3, 4] in the following aspects:\n(1) defining a fixed central space instead of a learnable central space (i.e., prototypes) and\n(2) defining the transport polytope with the word distribution of the training dataset instead of the equipartition assumption.\nThe previous works aim to learn visual representations [1, 2] or multimodal representations [3, 4] by \\textbf{training the whole networks}, including backbone networks and the central space, in an end-to-end manner.\nHowever, we need to connect two \\textbf{frozen} backbone networks using visual features as LLMs input.\nIn our setup, we empirically found that learnable space is heavily sensitive to the hyperparameters (e.g. $\\epsilon$ in equation (4)) and provides poor performance.\nTherefore, the conventional optimal transport-based approaches [1, 2, 3, 4] have been limited to be directly applied to our work.\n$\\epsilon$-MSCOCO (CIDEr-D)\nMethod\n0.1\n0.05\n0.01\n0.005\n(i)\nVLAP w/o word embed.\n20.4\n43.8\n38.9\n-\n(ii)\nVLAP w/o word dist.\n50.7\n57.9\n57.1\n46.2\n(iii)\nVLAP\n61.8\n68.0\n69.9\n67.7\nTo verify our claim, we conduct additional experiments for the components in assignment prediction.\nAs shown in the above table, we evaluate each model for the zero-shot image captioning performance (CIDEr-D) on MSCOCO corresponding to various $\\epsilon$ values in equation (4).\nIn (i) \"VLAP w/o word embed.'', we first train VLAP with learnable prototypes as in [1, 2, 3, 4]. \nIn this setting, we define 3K prototypes following [1] and apply the equipartition assumption in equation (3).\nIn (ii) \"VLAP w/o word dist.'', we also verify the effectiveness of the word distribution.\nIn this setting, we use the word embeddings as a fixed central space and perform the optimal transport with the equipartition assumption.\nThe comparison between (i) and (ii) shows that the word embedding achieves substantial performance improvement, demonstrating the effectiveness of the word embedding.\nThe comparison between (ii) and (iii) original VLAP shows that the transportation polytope with the word distribution achieves additional performance improvement and provides more robust performance regarding $\\epsilon$.\n[1] M. Caron et al., ``Unsupervised learning of visual features by contrasting cluster assignments,\" NeurIPS'20\n[2] Y. M. Asano et al., ``Self-labeling via simultaneous clustering and representation learning,\" ICLR'20\n[3] Y. M. Asano et al., ``Labelling unlabelled videos from scratch with multi-modal self-supervision,\" NeurIPS'20\n[4] J. Duan et al., ``Multi-modal alignment using representation codebook,\" CVPR'22\n[W3] Ablation for the loss function\nOur image captioning objective is basically defined as the next-word generation prediction, i.e., generating a word from the previous information.\nInstead, we provide the results corresponding to the additional objectives for cross-modal alignment in the general responses.\nPlease refer to them."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 09:33Everyone", "Content": "Comment:\nWe thank you for your time and effort in reviewing our paper. Your insights have been highly valued, and your feedback is crucial to our progress. We understand that you have a busy schedule, and we again appreciate your time and attention to this matter. We have addressed all of your comments in our rebuttal. We would be grateful if you could please take a look at our rebuttal. If there are any additional materials or information you may require to facilitate the review process, please let us know. Your prompt attention to this matter is greatly appreciated.\nThank you again for your help. Sincerely Authors"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 01:49 (modified: 23 Nov 2023, 02:01)EveryoneRevisions", "Content": "Comment:\nDear Reviewer 5A8P,\nThanks for your constructive and valuable comments on our paper. We have revised our paper to address the reviewer's concerns.\n[W1, W2] Ablation regarding optimal transport.\nWe added ablation analyses for the components of VLAP, including the hyperparameters and optimal transport in Appendix Section D.\n[W3] Ablation regarding learning objectives.\nWe added ablation analyses with the additional learning objectives in Appendix Section D.\nWith the discussion deadline approaching in a few hours, we are eager to receive your feedback."}, {"Heading": "Official Comment by Reviewer 5A8P", "Subheading": "Official CommentbyReviewer 5A8P04 Dec 2023, 21:54 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nI have read through the reviews and rebuttals.\nThe author addressed my main concern regarding the novelty and effectiveness of the proposed word embedding optimal transport.\nThe additional analysis for visual arithmetic responding to reviewer dYxb is also interesting. This might be meaningful for other works claiming the model learned visual arithmetic.\nI'll keep my rating marginally above the acceptance threshold."}]}, {"Heading": "Official Review of Submission9396 by Reviewer dYxb", "Subheading": "Official ReviewbyReviewer dYxb31 Oct 2023, 13:10 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn vision-language modeling, a significant challenge persists: bridging the modality gap between pretrained vision and language models. This gap arises primarily due to the models' pretraining exclusively on unimodal data, leading to inconsistencies in their embedding spaces. Motivated by this limitation and the computational costs of previous methods, this work introduces VLAP, a novel linear transformation-based approach that employs assignment prediction to connect vision encoders and large language models (LLMs). By harnessing the established word embeddings of LLMs and introducing an optimal transport-based assignment prediction objective, VLAP maps visual data representations to LLM's word embeddings, aiming for consistent modality representation. This not only results in visual data representations with the semantic richness of LLMs but also surpasses prior methods in computational and memory efficiency across various vision-language tasks.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe limitations from SOA mentioned in the paper exist, and the motivation is valid.\nResolving the modality gap problem with the cross-modal assignment prediction using word embeddings of LLMs is a better solution than previous methods.\nWeaknesses:\nA better alignment (reducing the gap) in multi-modality is the essential contribution of this work. However, it lacks studies or results, apart from the overall performance, to validate that the gap reduction is achieved by the current predicted assignments rather than the linear layers from previous works.\nThe authors mentioned, ``Mapping visual data to LLM\u2019s word embeddings results in learned visual representations that hold a semantic taxonomy of LLMs.'' However, there's a lack of quantitative/qualitative results to validate that this allows visual representations to inherit a semantic taxonomy of LLMs.\nThe final objectives are influenced by the assignment prediction loss and captioning loss. However, there's a lack of study on these hyperparameters. Also, which part contributes more to the learning remains a question.\nFor the probability that the corresponding modality data belongs to each word, $P_{nk}$, what does $P_{nk}^{v}$ in the visual modality signify? Does this ``word'' refer to the single word token in the class label of that visual region?\nThere's a lack of formal definitions for the terms/operations appearing in equations, i.e., $Tr(\\cdot)$, $[prefix]$.\n[Summary] The current limitations and motivations are valid, and the claimed contribution is significant. However, in the paper's delivery, there's a concern about how this performance is achieved by the proposed architecture and mechanism. Additionally, the paper lacks a depth of study beyond introducing a novel architecture.\nQuestions:\nPlease also refer to the previous section.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 08:26Everyone", "Content": "Comment:\nThank you for your constructive review and valuable suggestions! Below, we provide a detailed response to your questions and comments. If any of our responses fail to sufficiently address your concerns, please inform us, and we will promptly follow up.\n[W1] Validation for the modality gap reduction\n$\\mathcal{L}_\\text{cap}$\n$\\mathcal{L}_\\text{ITM}$\n$\\mathcal{L}_\\text{ITC}$\n$\\mathcal{L}_\\text{map}$\nCIDEr-D\nCLIP-S\nRef-S\n$\\Delta$\nv\n51.3\n72.4\n76.6\n0.972\nv\nv\nv\n61.9\n79.7\n82.8\n0.870\nv\nv\nv\nv\n65.2\n82.8\n86.0\n0.840\nv\nv\n69.4\n87.6\n92.0\n0.725\nTo provide a better understanding in terms of modality gap reduction, we measure the modality gap distance $||\\Delta||$ according to the learning objective.\nThe modality gap $\\Delta$ is defined as the difference between the center of visual and text representations [1]:\n$\\begin{equation}\n        \\Delta = \\frac{1}{n}\\sum_{i=1}^{n} \\bar{\\mathbf{z}}^{v}_i - \\frac{1}{n}\\sum_{i=1}^n \\bar{\\mathbf{z}}^t_i,\n    \\end{equation}$\nwhere $n$ is the total number of image-text pairs, $\\bar{\\mathbf{z}}_i^v$, and $\\bar{\\mathbf{z}}_i^t$ are the $i$-th averaged visual and text representations.\nThe default gap distance between CLIP ViT-B/32 and T5$_\\text{Base}$ before training is $||\\Delta|| = 1.378$.\nThe image captioning objective $\\mathcal{L}_\\text{cap}$ reduces the modality gap distance to $||\\Delta|| = 0.972$ and the additional objectives $\\mathcal{L}_\\text{ITM}$ and $\\mathcal{L}_\\text{ITC}$ further reduce the gap distance to $||\\Delta|| = 0.870$.\nThe comparison between VLAP with all objectives and with the original objective (i.e., $\\mathcal{L}_\\text{cap}+\\mathcal{L}_\\text{map}$) shows the ITM and ITC objectives have a limitation to reduce the modality gap.\nIn addition, since the overall performance is inversely proportional to the modality gap, reducing the gap is an important factor in training VLMs.\nWe also present UMAP visualization [2] and the additional analysis according to the learning objective in Figure 8 and Appendix. D.2 of the revised paper.\n[1] W. Liang et al., ``Mind the gap: Understanding the modality gap in multi-modal contrastive representation learning,\" NeurIPS'22\n[2] T. Sainburg et al., ``Parametric UMAP embeddings for representation and semi-supervised learning,\" Neural Computation'21"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 08:30Everyone", "Content": "Comment:\n[W2] Additional analysis for visual arithmetic\nBuilding$\\rightarrow$Country\nCountry$\\rightarrow$Capital\nCEO$\\rightarrow$Company\nFood$\\rightarrow$Country\nMethod\nB@1\nR@5\nCLIP-S\nB@1\nR@5\nCLIP-S\nB@1\nR@5\nCLIP-S\nB@1\nR@5\nCLIP-S\nClipCap\n0.003\n0.035\n0.24\n0.0\n0.0\n0.22\n0.004\n0.005\n0.18\n0.0\n0.0\n0.24\nZeroCap\n0.1\n0.32\n0.7\n0.14\n0.32\n0.68\n0.1\n0.3\n0.64\n0.03\n0.33\n0.66\nVLAP\n0.3\n0.53\n0.87\n0.46\n0.62\n0.89\n0.25\n0.5\n0.75\n0.17\n0.5\n0.81\nTo prove the visual representation that inherited the semantic taxonomy of LLM, we analyze that word analogies can often be solved with visual vector arithmetic. \nIn addition to existing experiments on visual semantic arithmetic, we supplement an experiment on the visual relation (VR) benchmark [3].\nThe VR benchmark consists of a total of 320 relations, including building$\\rightarrow$country, country$\\rightarrow$capital, CEO$\\rightarrow$company, food$\\rightarrow$country, and leader$\\rightarrow$country.\nSince the relation of leader$\\rightarrow$country includes out-of-date information (e.g. 'Obama'-'USA'), we exclude it from this experiment.\n    In the above table, we compare the performance between VLAP, ClipCap [4], and ZeroCap [3] in terms of BLEU-1, Recall@5, and CLIP-Score, following [3].\nFor fair comparisons, we identically use CLIP ViT-B/32 as the image encoder and GPT-2 as the LLM.\nThe results show that VLAP outperforms the previous methods by large margins.\nIn particular, we attain correlations of over 75% in all relations on the semantic distance-based metric, i.e., CLIP-Score.\nWe include the additional analysis with visualization in Figure 7 and Appendix. C.2 of the revised paper.\n[3] Y. Tewel et al., ``ZeroCap: Zero-shot image-to-text generation for visual-semantic arithmetic,\" CVPR'22\n[4] R. Mokady et al., ``ClipCap: Clip prefix for image captioning,\" arXiv'21\n[W3] Ablation for the balancing parameters\nWe present the ablation results corresponding to the balancing parameters in equation (7) in the general response.\nPlease refer to them.\n[W4] Meaning of the probability in equation (5)\nWe first explain the probability $\\mathbf{P}_{nk}^{t}$ for the text representation.\nSince LLMs provide text representations through sophisticated operations between word embeddings, text representations and word embeddings have high correlations with each other.\nTherefore, we can obtain the probability of the $k$-th word attending to the $n$-th text representation without any correspondence between language captions and word embeddings as in equation (5).\nMeanwhile, our assignment prediction objective enforces visual and text representations to contain the same information.\nSimply put, the probability $\\mathbf{P}_{nk}^{v}$, which represents the $k$-th word attending to the $n$-th visual representation, is learned to be similar to a pre-calculated probability $\\mathbf{P}_{nk}^t$ by predicting the assignment of text data without any image-word correspondence.\n[W5] Clarity\nWe denote the trace matrix as $\\text{Tr}(\\cdot)$ in equation (2) and the input text prompt (i.e., \"$\\texttt{A photo of}$\") as $\\texttt{[prefix]}$ in equation (6).\nWe clarify them in the revised paper."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 09:33Everyone", "Content": "Comment:\nWe thank you for your time and effort in reviewing our paper. Your insights have been highly valued, and your feedback is crucial to our progress. We understand that you have a busy schedule, and we again appreciate your time and attention to this matter. We have addressed all of your comments in our rebuttal. We would be grateful if you could please take a look at our rebuttal. If there are any additional materials or information you may require to facilitate the review process, please let us know. Your prompt attention to this matter is greatly appreciated.\nThank you again for your help. Sincerely Authors"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 02:00Everyone", "Content": "Comment:\nDear Reviewer dYxb,\nThanks for your constructive and valuable comments on our paper. We have revised our paper to address the reviewer's concerns.\n[W1, W3] Ablation regarding objectives.\nWe added ablation analyses for the learning objectives, including the hyperparameters and additional objectives in Appendix. Section D.\n[W2] Additional analysis for visual arithmetic.\nWe added the additional analysis for visual arithmetic on the visual relation benchmark, which demonstrates the learned visual representations can be used to reason semantic relations. We also provided the UMAP visualization to verify how the visual arithmetic of VLAP works in the feature space in Appendix. Section C.\n[W5] Clarity of notations.\nWe clarified some notations for readability.\nWith the discussion deadline approaching in a few hours, we are eager to receive your feedback."}]}, {"Heading": "Official Review of Submission9396 by Reviewer zAaX", "Subheading": "Official ReviewbyReviewer zAaX28 Oct 2023, 14:34 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a method to align the visual representations of pretrained visual encoders into the input space of pretrained language models, using a linear projection layer. The linear layer is the only trainable part in the system, which is supervised by two losses: (a) assignment consistency - the visual features and text features are assigned to the word, and a similarity loss between the assignment results is applied (b) an image captioning objective. Using this method, experiments are done on 3 tasks, including image captioning, VQA, image-text retrieval to show that the method outperforms existing methods. Different variations of visual and text models are studied in the experiments. Additionally, some qualitative visual semantic arithmetic results are provided.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe method is simple and clear - train a linear layer with two losses including the newly proposed assignment prediction loss.\nIntensive experiments are provided on 3 tasks using different visual backbones (CLIP, BeiT) and text backbones (OPT-1.3B and T5-base), where results consistently outperforms existing methods.\nThe paper is well-written and easy to follow.\nWeaknesses:\nMy major concern is (a) the lack of ablations and feature space visualizations to show the effectiveness of the proposed loss and (b) the contribution over existing works like MAGMA is not enough.\nThe paper is an extension of MAGMA (Merullo et. al. Linearly mapping from image to text space. In ICLR, 2023.). While MAGMA is discussed in the paper, the difference is that this paper with MAGMA is the proposed assignment prediction loss. However, the effectiveness of the proposed loss is not shown clearly in the paper.\nNo ablation results are provided to show the effectiveness of the proposed loss - this is related to weakness-1. Since the major contribution lies in this loss, an ablation to show the contribution of this loss in the final results is very critical.\nThe finding that a linear layer can transform visual representations into language models is not surprising, given existing works LLaVA (\u201cVisual Instruction Tuning\u201d, as in its first training stage), which is not discussed in this paper, and MAGMA as discussed. Therefore, the contribution of this work is weakened.\nThe authors motivate the work by criticizing the \u201cdistance-preserving nature of the linear layer\u201d. However, the proposed method is still a linear layer, which doesn\u2019t solve this problem. While Fig-4 provides several examples to show the visual semantic arithmetic, a visualization of feature space would be preferred to show the effects of the assignment loss\nThe paper would be easier to read if the method names (abbreviations) in the results tables come with citations next to them, or are described in texts to show which is which.\nQuestions:\nCould abalations with and without the assignment loss be provided to show its effectiveness?\nCould visualizations (e.g. t-SNE) over the feature space with and without the assignment loss be provided, to show its effects in aligning the features?\nThe difference/contribution over LLaVA or MAGMA can be more clearly discussed.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 08:33Everyone", "Content": "Comment:\nThank you for your constructive review and valuable suggestions! Below, we provide a detailed response to your questions and comments. If any of our responses fail to sufficiently address your concerns, please inform us, and we will promptly follow up.\n[W1, W2, Q1] Ablation for the loss function\nWe present the ablation analysis corresponding to the learning objectives in the general response.\nPlease refer to them.\n[W3, Q3] Difference between VLAP and the previous linear transformation-based approaches\nThanks for the reference.\nSimilar to the image captioning objective of LiMBeR, LLaVa learns the linear projection with the language generation objective, which aims to provide target answers from given transformed visual and language instruction representations.\nAlthough LiMBeR and LLaVa have shown two unimodal models can be bridged through the language modeling objective, they are insufficient to reduce the modality gap, as shown in our previous response.\nOur proposed objective not only improves overall performance in the linear transformation-based methods, but also significantly facilitates the connection of the visual encoder even if it is not trained with language guidance (i.e., CLIP encoder).\nIn addition, our objective can be an alternative to the conventional objectives for cross-modal alignment, such as the image-text matching and image-text contrastive objectives.\nWe add the missing reference LLaVa in the main paper.\n[W4, Q2] Linear layer with assignment prediction\nWe apologize for using the misleading term, \"distance-preserving nature of the linear layer\". We revise the Introduction section to clarify the contribution.\n[W5] Model reference\nThanks for your suggestion. We clarify the model names with citations in the table captions."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 09:34Everyone", "Content": "Comment:\nWe thank you for your time and effort in reviewing our paper. Your insights have been highly valued, and your feedback is crucial to our progress. We understand that you have a busy schedule, and we again appreciate your time and attention to this matter. We have addressed all of your comments in our rebuttal. We would be grateful if you could please take a look at our rebuttal. If there are any additional materials or information you may require to facilitate the review process, please let us know. Your prompt attention to this matter is greatly appreciated.\nThank you again for your help. Sincerely Authors"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 02:15 (modified: 23 Nov 2023, 02:15)EveryoneRevisions", "Content": "Comment:\nDear Reviewer zAaX,\nThanks for your constructive and valuable comments on our paper. We have revised our paper to address the reviewer's concerns.\n[W1, W2, Q1] Ablation regarding optimal transport.\nWe added ablation analyses for the components of VLAP, including the hyperparameters and optimal transport in Appendix Section D.\n[W3, Q3, W4] Difference between VLAP and the previous linear transformation-based approaches.\nWe included the missing reference (i.e., LLaVA). In addition, we extensively revised the paper to cover the reviewer's concerns about the novelty and to remove potentially misleading terms in Introduction.\n[W4, Q2] Visualization.\nWe presented the UMAP visualization corresponding to visual arithmetic and ablation for the learning objectives. We can verify the effectiveness of the proposed VLAP in the feature space.\n[W5] Citation.\nWe added references along with the model names to the table captions.\nWith the discussion deadline approaching in a few hours, we are eager to receive your feedback."}]}]}, "3wL1tj3kqE": {"paper_info": {"Primary Area": "general machine learning (i.e., none of the above)", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "domain generalization, fairness, multiple sensitive attributes", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We consider the problem of fairness transfer in domain generalization with sensitive attributes that change its sensitivity across domains", "Abstract": "We consider the problem of fairness transfer in domain generalization. Traditional domain generalization methods are designed to generalize a model to unseen domains. Recent work has extended this capability to incorporate fairness as an additional requirement. However, it is only applicable to a single, unchanging sensitive attribute across all domains. As a naive approach to extend it to a multi-attribute context, we can train a model for each subset of the potential set of sensitive attributes. However, this results in $2^n$ models for $n$ attributes. We propose a novel approach that allows any combination of sensitive attributes in the target domain. We learn two representations, a domain invariant representation to generalize the model's performance, and a selective domain invariant representation to transfer the model's fairness to unseen domains. As each domain can have a different set of sensitive attributes, we transfer the fairness by learning a selective domain invariant representation which enforces similar representations among only those domains that have similar sensitive attributes. We demonstrate that our method decreases the current requirement of $2^n$ models to $1$ to accomplish this task. Moreover, our method outperforms the state-of-the-art on unseen target domains across multiple experimental settings.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9395", "PDF Url": "https://openreview.net/pdf?id=3wL1tj3kqE"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9395 by Area Chair jUk8", "Subheading": "Meta ReviewbyArea Chair jUk813 Dec 2023, 05:14 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper received the following ratings: 1, 6, 3, 3.\nThe main issue, evidenced by all reviewers, regards the poor clarity of the presentation/organization of the paper, even lacking of details, which prevent the full understanding of the work.\nFurther, the motivations are not well addressed, the novelty aspects are unclear, and experimental validation is insufficient, including poor ablations. Overall, the number of flaws raised by the reviewers are indeed large. Authors provided answers to these issues, but they have not succeeded to convince the reviewers to raise their scores. \n\nIn the end, given all these problems, this paper cannot be considered acceptable for publication at ICLR 2024.\nJustification For Why Not Higher Score:\nToo large number of issues and rebuttal was not considered adequate, even if only one reviewer seemed to acknowledge its reading. \nOverall, I think this work cannot be accepted in these conditions.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Code and trained models", "Subheading": "Official CommentbyAuthors22 Nov 2023, 15:47 (modified: 15 Mar 2024, 00:27)EveryoneRevisions", "Content": "Comment:\n**We provide an anonymous Google Drive [link](https://drive.google.com/drive/folders/12YnjoixwF-2wCHaonJexbwiDNLQP4_K8?usp=sharing) for sharing the source code and a few trained models for reproducibility.**"}, {"Heading": "Official Review of Submission9395 by Reviewer kdx1", "Subheading": "Official ReviewbyReviewer kdx101 Nov 2023, 00:03 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nAccording to the authors, this work proposes a novel approach to handle multiple sensitive attributes, allowing any combination in the target domain. This approach involves learning two representations: one for general model performance and another for transferring fairness to unseen domains with similar sensitive attributes. The proposed method significantly reduces the model requirement from 2^n to just 1 for handling multiple attributes and outperforms existing methods in experiments with unseen target domains.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\n1. According to the authors, this paper introduces a new setting of fair domain generalization with multiple sensitive attributes.\n2. Based on the proposed setting, a comprehensive training approach is given. \n3. The paper is easy to follow.\nWeaknesses:\n1. Some statements are over-claimed. In the introduction, \"FATDM is the only work that addresses...\" this is not true. Several works, other than FATDM, address fairness-aware domain generalization but in various paradigms, such as [1], [2], and [3]. \n2. Figure 2 is unclear to me. What is the unfairness metric \"Mean\"? Do you mean \"mean difference\" or others? How do you define \"different level of fairness\"? Also, the word \"level\" should be plural \"levels\". What is the take-home message when observing the drop in performance, and what is the connection between this drop and multiple attributes? How does this observation relate to various domains?\n3. In the second item of contributions in the Introduction, except the problem mentioned in the first contribution, what is the other problem when you say \"both problems\"?\n4. What is the relationship between the target domain \\Tilde{d} with source domains? Is the target domain shifted from sources due to covariate shift, too? If not, what assumption do you make on target domains? This lack of clarification and, hence, unclear to me. Besides, giving a brief introduction to covariate shifts is necessary. \n5. I doubt the novelty of proposing the setting in multiple sensitive attributes. To me, a dataset with multiple sensitive attributes can be easily converted to one with a single sensitive attribute with multiple categories. For example, as stated in the paper, a sensitivity configuration set \\mathcal{C}={[0,0], [0,1], [1,0], [1,1]} can be viewed as a set {1,2,3,4} where a single sensitive attribute with four distinct categorical values. \n6. Does data sample x include sensitive attribute c? \n7. In Eq.(1), \"d'\" should be replaced by \"d''\".\n8. How to ensure g_\\theta encodes an invariant representation across domains? According to Eq.(5), the loss L_{DG} is defined as the expectation across all source domains. Therefore, it is not convincing to me that the generalization encoder can be generalized to an unseen target domain when a covariate shift occurs. \n9. In the fairness encoder, x is concatenated with c. I am wondering how to do it empirically when x is an image while c is one of the annotations of the image. Please explain your experiments for implementation using the CelebA as an example. \n10. Speaking of fair machine learning in general, it aims to mitigate spurious correlations between sensitive attributes and model outcomes. Although this work mentions fairness multiple times, it is unclear to me how to mitigate the spurious correlations during training. This work proposes that it \"minimize the gap between the domain representations that have the same sensitive attribute configurations and maximize the gap for representations with different sensitive attributes\". But this does not ensure unfairness is controllable.\n\n[1] Elliot Creager, J\u00f6rn-Henrik Jacobsen, Richard Zemel. Environment Inference for Invariant Learning. ICML 2021.\n\n[2] Changdae Oh, Heeji Won, Junhyuk So, Taero Kim, Yewon Kim, Hosik Choi, Kyungwoo Song. Learning Fair Representation via Distributional Contrastive Disentanglement. ACM SIGKDD 2022.\n\n[3] Chen Zhao, Feng Mi, Xintao Wu, Kai Jiang, Latifur Khan, Christan Grant, Feng Chen. Towards Fair Disentangled Online Learning for Changing Environments. ACM SIGKDD 2023.\nQuestions:\nSee weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n1: strong reject\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal for Reviewer 1: Part 1", "Subheading": "Official CommentbyAuthors22 Nov 2023, 03:31 (modified: 22 Nov 2023, 21:03)EveryoneRevisions", "Content": "Comment:\n**We thank Reviewer 1 for their constructive comments to improve our paper. We provide our responses to their queries below.**\n\n> 1) Some statements are over-claimed. In the introduction, \u201dFATDM is the only work \nthat addresses...\u201d this is not true. Several works, other than FATDM, address fairness-aware domain\ngeneralization but in various paradigms, such as [1], [2], and [3]\n\nWe thank Reviewer 1 for pointing us to papers [1], [2], and [3]. We agree that they are all broadly under fairness-aware domain generalization and we have added these papers to our related works section in the revised version of the paper. \nHowever, we would like to emphasize the difference between these papers and FATDM. Papers [1] and [2] reduce the correlations between target attributes and sensitive groups and their goal is to improve the test accuracy of the predictions of the worst-case represented sensitive group. (E.g. removing correlations of land birds with land).  \nFATDM lies in the line of works like [4], [5], [6] which achieve fairness by reducing bias against any instance of a sensitive group by equalizing the predictions for different instances of the sensitive groups via optimizing metrics like equal opportunity, equalized odds or demographic parity (E.g., predicting with similar true positive and false positives whether gender=Male or Female). [3] optimizes equalized odds and is similar to FATDM, however, their focus is to address the online learning problem. \n\n[1] Environment Inference for Invariant Learning, ICML 2021 \\\n[2] Learning Fair Representation via Distributional Contrastive Disentanglement, KDD 2022 \\\n[3] Towards Fair Disentangled Online Learning for Changing Environments, KDD 2023 \\\n[4] Fair Mixup: Fairness Via Interpolation, ICLR 2021 \\\n[5] Equality of opportunity in supervised learning, NeurIPS 2016 \\\n[6] Empirical Risk Minimization Under Fairness Constraints, NeurIPS 2018 \n\n***\n\n> 2) Figure 2 is unclear to me. What is the unfairness metric \"Mean\"? Do you mean \"mean difference\" or others? How do you define \"different level of fairness\"? Also, the word \"level\" should be plural \"levels\". What is the take-home message when observing the drop in performance, and what is the connection between this drop and multiple attributes? How does this observation relate to various domains?\n\nThe unfairness metric Mean is the Mean difference metric (Equation below). We have revised Fig 2 in the paper based on this comment.  \n\nBy different levels of fairness, we mean that the inclusion of additional sensitive attributes can have additional terms to optimize fairness such that performance may be compromised. We have an example below with gender followed by gender and race.\n\n\\begin{equation*}\n\\mathrm{Mean Difference(g)} = \\frac{1}{N}\\sum_{i=1}^{N}\\sum_{y \\in \\mathcal{Y}}((h(\\mathbf{z}_i)\\mid y, g=\\mathrm{F}) - (h({\\mathbf{z}_i})\\mid y, g=\\mathrm{M}))^2    \n\\end{equation*} \n\n\\begin{equation*}\n\\begin{split}\n\\mathrm{Mean Difference(g,r)} = \\frac{1}{N}\\sum_{i=1}^{N}\\sum_{y \\in \\mathcal{Y}}((h(\\mathbf{z}_i)\\mid y, g=\\mathrm{F}), r=\\mathrm{B})  - (h({\\mathbf{z}_i})\\mid y, g=\\mathrm{M},r=\\mathrm{W}))^2 \\\\ +((h(\\mathbf{z}_i)\\mid y, g=\\mathrm{M}), r=\\mathrm{B}) - (h({\\mathbf{z}_i})\\mid y, g=\\mathrm{M},r=\\mathrm{W}))^2  \\\\ +\n((h(\\mathbf{z}_i)\\mid y, g=\\mathrm{F}), r=\\mathrm{B}) - (h({\\mathbf{z}_i})\\mid y, g=\\mathrm{F},r=\\mathrm{W}))^2  \\\\ +\n((h(\\mathbf{z}_i)\\mid y, g=\\mathrm{M}), r=\\mathrm{B}) - (h({\\mathbf{z}_i})\\mid y, g=\\mathrm{F},r=\\mathrm{W}))^2  \\\\ +\n((h(\\mathbf{z}_i)\\mid y, g=\\mathrm{M}), r=\\mathrm{B}) - (h({\\mathbf{z}_i})\\mid y, g=\\mathrm{M},r=\\mathrm{B}))^2 \\\\ +\n((h(\\mathbf{z}_i)\\mid y, g=\\mathrm{M}), r=\\mathrm{W}) - (h({\\mathbf{z}_i})\\mid y, g=\\mathrm{F},r=\\mathrm{W}))^2 \n\\end{split}\n\\end{equation*} \nwhere $\\mathbf{z}$ is the latent representation of the input $\\mathbf{x}$. \\\n**Take home message when observing the drop in performance:**  \nIncreasing the number of sensitive attributes can compromise the accuracy as shown in Figure 2 in the paper. We assume that an attribute's sensitivity is a user preference and do not expect each domain (of domain generalization) in the data to have the same set of sensitive attributes. When only a subset of attributes (gender or race or none) is sensitive in a domain, enforcing fairness on all possible sets of sensitive attributes (gender and race) can lead to an unnecessary dip in performance.\n\n***\n\n>3) What is the other problem when you say both problems\t\n\nThe first problem is getting a good generalization performance on a target domain. The second problem is getting a good fairness measure with respect to all the sensitive attributes in the target domain.\n\n***\n\n> 4) Is the target domain shifted from sources due to covariate shift, too?\n\nyes. However, the sensitive attributes of the target domain are decided by the user. We do not assume it to be due to the covariate shift. \n\n***"}, {"Heading": "Rebuttal for Reviewer 1: Part 2", "Subheading": "Official CommentbyAuthors22 Nov 2023, 09:02 (modified: 22 Nov 2023, 21:59)EveryoneRevisions", "Content": "Comment:\n> 5) I doubt the novelty of proposing the setting in multiple sensitive attributes. To me, a dataset with multiple sensitive attributes can be easily converted to one with a single sensitive attribute with multiple categories.\n\nIt may be possible to view multiple sensitive attributes as a single sensitive attribute with multiple categories. **However, our contribution is not to just extend domain generalization and fairness to a multi-attribute setting. In a multi-attribute setting, each domain can have a different set of sensitive attributes (which we assume are decided by a user based on the application at hand). Hence, we also address the problem of the target domain having a different set of sensitive attributes from that of the source.** We discuss these contributions under paragraphs $2$ and $3$ of the introduction section of the paper. \\\n\nOur baseline is a naive modification of the existing approach FATDM (designed for a single sensitive attribute) to cater to a multi-attribute setting. We compare it against our method SISA which considers the differences in the sensitivity of the attributes across different domains. From the experimental results, we show that our method is better at both performance on the target domain and fairness measures for all subsets from a possible set of sensitive attributes in the target domain.\n\n*** \n\n> 6) Does data sample $\\mathbf{x}$ include sensitive attribute $\\mathbf{c}$?\t\n\nNo, $\\mathbf{x}$ is an image of size $256$x$256$x$1$ for MIMIC CXR and $256$x$256$x$3$ for CelebA. $\\mathbf{c}$ is a binary vector of size $n$x$1$ where $n$ is the total number of possible sensitive attributes. We provide it to the model as additional meta information.\n\n***\n\n> 7) In Eq.(1), \"d'\" should be replaced by \"d''\"\n\nNo, we use $\\mathbf{x}''$ and $\\mathbf{x}'$ and $G''$ and $G'$ to denote the differences in the density transformation model and its output. However, both  $\\mathbf{x}''$ and $\\mathbf{x}'$ are from $d' \\in D$.\n\n***\n\n> 8) How to ensure $g_\\theta$ encodes an invariant representation across domains? According to Eq.(5), the loss $L_{DG}$ is defined as the expectation across all source domains. Therefore, it is not convincing to me that the generalization encoder can be generalized to an unseen target domain when a covariate shift occurs.\n\nPrior works [7],[8],[9] have theoretically proved that error on the target domain is upper bounded by the training error on the source domains, pairwise divergences among the source domains, and divergence between the source and the target domain. As we do not have access to target domains, we follow previous works and minimize the pairwise divergence among the source domains through domain invariant representation learning ($L_{DG}$) and the training error on the source domains ($L_{ERR}$) for a lower error on the predictions of the target domain.\n\n[7] Generalizing to unseen domains via distribution matching, 2019 \\\n[8]  Fairness and accuracy under domain generalization, ICLR 2023 \\\n[9] On Learning Domain-Invariant Representations for Transfer Learning with Multiple Sources, NeurIPS 2021\n\n***\n\n> 9) In the fairness encoder,  $\\mathbf{x}$ is concatenated with $\\mathbf{c}$. I am wondering how to do it empirically when $\\mathbf{x}$ is an image while $\\mathbf{c}$ is one of the annotations of the image. Please explain your experiments for implementation using the CelebA as an example.\t\n\n$\\mathbf{c}$ is a binary vector of size $n$x$1$. We reshape it to $256$x$256$x$1$ by repeating its values over dimensions $1$ and $2$ and adding a $3$rd dimension. Then it is concatenated to input $\\mathbf{x}$ as an additional channel. So the total dimension of the input ($\\mathbf{x}+\\mathbf{c}$ = $256$x$256$x$2$ for MIMIC CXR and $256$x$256$x$4$ for CelebA). We have provided the code to get more insight into this.\n\n***\n\n> 10) Speaking of fair machine learning in general, it aims to mitigate spurious correlations between sensitive attributes and model outcomes. Although this work mentions fairness multiple times, it is unclear to me how to mitigate the spurious correlations during training. This work proposes that it \"minimize the gap between the domain representations that have the same sensitive attribute configurations and maximize the gap for representations with different sensitive attributes\". But this does not ensure unfairness is controllable.\n\nOur focus is on the notion of fairness that aims to balance classifier errors across population subgroups, for example, by matching error rates across genders or different racial groups. \\\nHowever, based on the review, we have added Table 13 to the supplementary section of our paper showing the Pearson correlation measure between the sensitive attributes and the target attribute predictions of our model and ERM. Our model reduces the correlation between the sensitive attributes and the model prediction."}]}, {"Heading": "Official Review of Submission9395 by Reviewer FctA", "Subheading": "Official ReviewbyReviewer FctA29 Oct 2023, 23:40 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper addresses the challenge of fairness transfer in domain generalization, particularly in contexts where multiple sensitive attributes are present and may vary across domains. Traditional domain generalization methods aim to generalize a model's performance to unseen domains but often ignore the aspect of fairness, especially when multiple sensitive attributes are involved.\n\nThe authors propose a novel framework capable of handling fairness with respect to multiple sensitive attributes across different domains, including unseen ones. This is achieved through the development of two types of representations: a domain-invariant representation for generalizing model performance and a selective domain-invariant representation for transferring fairness to domains with similar sensitive attributes. A key innovation of the proposed method is its ability to reduce computational complexity significantly.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\n+ The approach to handle multiple sensitive attributes in domain generalization is innovative and addresses a clear gap in existing literature.\n+ The use of real-world datasets for experimentation enhances the practical relevance of the research.\n+ Learning two types of representations for generalization and fairness is a thoughtful approach that could have broader applications.\n+ Reducing the number of required models from $2^n$ to just one is a significant improvement, making the solution more feasible in practical scenarios.\nWeaknesses:\n- There is a lack of detail on the specific fairness metrics employed and how the trade-off between fairness and accuracy is quantitatively managed.\n- While the reduction in model count is impressive, there are no details on the scalability of the approach with respect to the size of the data or the complexity of domain environments.\n- The definition of \"sensitive attributes\" is rather arbitrary and vague - is there any specific reason certain attributes (i.e. smiling) count as sensitive?\nQuestions:\n- Could you elaborate on the robustness of your method against different types of distribution shifts compared to existing methods by providing ablation studies?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal for Reviewer 2:", "Subheading": "Official CommentbyAuthors22 Nov 2023, 08:58 (modified: 22 Nov 2023, 20:55)EveryoneRevisions", "Content": "Comment:\n**We thank Reviewer $2$ for their appreciation of our work and their constructive comments. We have posted responses to their queries below.**\n\n> 1) There is a lack of detail on the specific fairness metrics employed and how the trade-off between fairness and accuracy is quantitatively managed.\n\nOur ablation studies in Tables 4, 5, and 6 of the paper show that our model's hyperparameters $\\epsilon$ and $\\gamma$ can be varied to manage the trade-off between fairness and accuracy quantitatively (on CelebA dataset). In general, we noticed slightly better results for performance when $\\gamma$ and $\\epsilon$ are high and fairness when $\\gamma$ and $\\epsilon$ are low.\n\n***\n\n> 2) While the reduction in model count is impressive, there are no details on the scalability of the approach with respect to the size of the data or the complexity of domain environments.\n\n> a. Scalability of the approach with respect to the size of the data.\nWe have performed our experiments on data sizes ranging from $58356$ to $255600$ and show that our model performs well across these ranges. \nBelow are more details about the data ranges:\n+ *CelebA*. Domain: hair color. No of training samples (domain): $43624$ (black hair), $26984$ (blonde), $37414$ (brown), total: $108022$ \n+ *MIMIC-CXR-Cardiomegaly disease*. Domain: age. No of training samples (domain): $4312$ (age: Under 40), $15390$ (40-60), $26729$ (60-80), $11925$ (80-100), total: $58356$\n+ *MIMIC-CXR-Cardiomegaly disease*. Domain: rotation. No of training samples for each domain: $51120$ ($0^\\circ$), $51120$ ($15^\\circ$) $\\ldots$ $51120$ ($60^\\circ$), total: $255600$\n\n> b. Complexity of domain environments. \n We have shown that our method performs well across different types of domain shifts with different no of sensitive attributes.\n+  *CelebA*. Domain shift: hair color. No. of sensitive attributes: 4 (male, big nose, smiling and young). \n+  *MIMIC-CXR-Cardiomegaly disease*. Domain shift: age. No. of sensitive attributes: 2 (gender and race). \n+  *MIMIC-CXR-Cardiomegaly disease*. Domain shift: image rotations. No. of sensitive attributes: 3 (age, gender and race). \n\n***\n\n> 3) The definition of \"sensitive attributes\" is rather arbitrary and vague - is there any specific reason certain attributes (i.e. smiling) count as sensitive?\n\nTechnically sensitive attributes are those attributes that are subject to societal bias like age, gender, race, etc. We use experiments on the MIMIC CXR dataset where such attributes are present. However, to have a comprehensive set of experiments, we also decided to run experiments on CelebA which is a popular dataset in the field of fairness [4],[10],[11]. The target attribute for the dataset CelebA is Attractiveness. Past papers [4],[10],[11] have chosen Male as the sensitive attribute due to less no of images corresponding to males versus females in the data. Since we are considering multiple sensitive attributes, we randomly chose 3 other attributes: Big Nose, Smiling, and Young. Also, our intuition was that whether a person is Smiling should not contribute to whether they are Attractive.\n\n[4] Fair Mixup: Fairness Via Interpolation, ICLR 2021 \\\n[10] Inclusivefacenet: Improving face attribute detection with race and gender diversity, FAT/ML 2018 \\\n[11] Leveling down in computer vision: Pareto inefficiencies in fair deep classifiers, CVPR 2022\n\n*** \n\n> 4) Could you elaborate on the robustness of your method against different types of distribution shifts compared to existing methods by providing ablation studies?\n\nCurrently, we only consider covariate shift as the distribution shift in the scope of this paper. We will consider other shifts in a future version of the work."}]}, {"Heading": "Official Review of Submission9395 by Reviewer XuYi", "Subheading": "Official ReviewbyReviewer XuYi29 Oct 2023, 17:06 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces an approach aimed at achieving intersectional fairness within the context of domain generalization. Specifically, the proposed method focuses on acquiring two distinct invariant representations across domains, emphasizing both accuracy and fairness. Subsequently, a classifier is employed to make predictions based on these representations. To transfer fairness and accuracy into new domains, the authors train the model to minimize error and fairness loss across source domains.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\n- This paper targets fairness which is an important research topic in machine learning.\nWeaknesses:\n- The clarity of the paper is lacking, with several important details omitted. For instance, the paper lacks comprehensive information about the training of the domain density translator $G'$ for fairness generalization. Training $G'$ is not straightforward due to the varying sensitive attributes across different datasets.\n\n- The design choice of using a shared translator $G'$ for all sensitive attributes appears questionable. Notably, given an input $X$ from domain $d$, $G'$ only generates $X' = G'(X, d, d')$ in domain $d'$, without considering which sensitive attributes are relevant to the translation. This implies that the model assumes $P_d(X|y,s) = P_{d'}(X'|y,s)$ and $P_d(X|y,s') = P_{d'}(X'|y,s')$ for every $s, s' \\in S$, which is a strong assumption and may not hold in practical scenarios.\n\n- The rationale behind learning distinct representations for each sensitive attribute is not well elucidated. Why is it necessary for the model to minimize the gap between domain representations with the same sensitive attribute configurations while maximizing the gap for those with different sensitive attributes? How does concatenating all representations contribute to accurate and fair predictions in target domains?\n\n- The results in Table 2 and 3 seem to be presented for a fixed value of $\\gamma$. It would be more comprehensive if the authors varied $\\gamma$ to explore the accuracy-fairness trade-off for the methods used in the experiments.\n\n- The final objective, as defined in Equation (10), encompasses a blend of multiple loss components. I recommend that the authors carry out an ablation study, varying hyperparameters, to assess the impact of each loss on the model's performance.\n\n- The technical novelty of the paper appears somewhat limited. The primary contribution appears to be the utilization of distinct representations for each sensitive attribute.\n\n- In the introduction section (Fig. 1), the authors assert that the proposed method can accommodate the heterogeneity of sensitive attributes across domains. However, in the experimental section, the models seem to have access to all sensitive attributes in all domains, which may contradict the initial claim.\n\n- The paper lacks the provision of code and supplementary documentation, which could significantly enhance clarity and reproducibility. Providing these resources would be beneficial for the reader to understand and replicate the methodology.\nQuestions:\nPlease see the Weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal for Reviewer 3 : Part 1", "Subheading": "Official CommentbyAuthors22 Nov 2023, 13:30 (modified: 22 Nov 2023, 22:02)EveryoneRevisions", "Content": "Comment:\n**We thank Reviewer 3 for their constructive comments to improve our paper. We post responses to their queries below.**\n\n> 1) The clarity of the paper is lacking, with several important details omitted. For instance, the paper lacks comprehensive information about the training of the domain density translator $G'$ for fairness generalization. Training $G'$ is not straightforward due to the varying sensitive attributes across different datasets.\n\nWe have added more details about the training of $G'$ in the supplementary section of the revised version of the paper.\n\n***\n> 2) The design choice of using a shared translator $G'$ for all sensitive attributes appears questionable. Notably, given an input $X$ from domain $d$, $G'$ only generates $X'=G'(X,d, d')$ in domain $d'$, without considering which sensitive attributes are relevant to the translation. This implies that the model assumes $P_d(X\\mid d,s) = P_{d'}(X'\\mid d',s)$ and $P_d(X \\mid d,s') = P_{d'}(X'\\mid d,s')$ for every $s,s' \\in S$, which is a strong assumption and may not hold in practical scenarios.\n\nWe follow the design choice of $G'$ from FATDM who have assumed the same assumption you have stated and have proved with theoretical bounds that it does not compromise the fairness metric measures.\n\n***\n\n> 3) a)The rationale behind learning distinct representations for each sensitive attribute is not well elucidated. \n\nWe learn distinct representations for each sensitive attribute due to two reasons: \n1. If there exists a representation for a sensitive attribute S, and if two domains A and B have S as a sensitive attribute, then one can seamlessly minimize the distance between the representations of two domains A and B that only pertain to S and not affect the representations of other sensitive attributes in A and B. \n2. If there exists a representation for a sensitive attribute S, and if two domains A and B do not share its sensitivity, then one can seamlessly maximize the distance between representations of A and B that only pertain to S.\n\n> b) Why is it necessary for the model to minimize the gap between domain representations with the same sensitive attribute configurations while maximizing the gap for those with different sensitive attributes? \n\nWhen the sensitive attribute configurations are the same, that is, a domain A has its sensitive attribute set as gender and race and a domain B has its sensitive attribute set as gender and race, we want the predictions of both A and B to be equalized across all values taken by gender and race. Hence, we minimize the distance between the representations that pertain to fairness ($\\mathbf{z}_f$) of domain A and domain B. \\\nOn the other hand, if the sensitive attribute configurations are different, that is domain A has its sensitive attribute set as gender and domain B has its sensitive attribute set as race, then the sensitive attribute set is different, we do not want them to have a similar prediction and maximize the distance between $\\mathbf{z}_f$'s of domains A and B\n\n> c) How does concatenating all representations contribute to accurate and fair predictions in target domains?\n\nThe representation $\\mathbf{z}\\_f$ is optimized for better fairness through loss $L_{DF}$ and the representation $\\mathbf{z}\\_g$ is optimized for better accuracy through loss $L_{DG}$. We use concatenation as it is an easy operation that can combine the two representations to get a final representation which is then sent to the classifier for a prediction that is fair and accurate. \n\n***\n\n> 4) The results in Tables 2 and 3 seem to be presented for a fixed value of $\\gamma$. It would be more comprehensive if the authors varied $\\gamma$ to explore the accuracy-fairness trade-off for the methods used in the experiments.\n\nWe have chosen $\\gamma$ from hyperparameter tuning and have reported the results for the best $\\gamma$ in Tables 2 and 3 in the paper. We have provided an ablation study for $\\gamma$ in Table 5 and show that varying $\\gamma$ has an effect on the accuracy-fairness trade-off. \n\n***\n\n> 5) The final objective, as defined in Equation (10), encompasses a blend of multiple loss components. I recommend that the authors carry out an ablation study, varying hyperparameters, to assess the impact of each loss on the model's performance.\n\nEquation 10 includes $4$ hyperparameters. Out of that, $2$ are already present in the baseline FATDM. FATDM have optimized their values as $\\alpha=0.1$ and $\\omega=1$ in their paper. We adopted the same values in our model too. For the other hyperparameters that were introduced by our approach ($\\epsilon$ and $\\gamma$), we already provide an ablation study in Tables 4 and 5 in the paper.\n\n***"}, {"Heading": "Rebuttal for Reviewer 3: Part 2", "Subheading": "Official CommentbyAuthors22 Nov 2023, 15:26 (modified: 22 Nov 2023, 22:02)EveryoneRevisions", "Content": "Comment:\n> 6) The technical novelty of the paper appears somewhat limited. The primary contribution appears to be the utilization of distinct representations for each sensitive attribute. \n\nWe introduced the idea of learning two different representations (which are combined at the end) for capturing fairness and generalizability to a target domain. We have introduced a very practical problem of having multiple sensitive attributes across different domains in a domain generalization setting and have proposed a simple and clear solution for the same.  We believe that the simplicity of our method is one of the positive aspects of our method as it is very easy for a researcher/engineer to understand and implement the model in practice.\n\n***\n\n> 7) In the introduction section (Fig. 1), the authors assert that the proposed method can accommodate the heterogeneity of sensitive attributes across domains. However, in the experimental section, the models seem to have access to all sensitive attributes in all domains, which may contradict the initial claim.\n\nWe assume that we have access to a set of possible sensitive attributesinformation on whether an attribute is sensitive is not part of the observations and is specified by the user. Hence we identify a possible set of sensitive attributes and train the model to face any subset of sensitive attributes from the possible set. As the sensitivity of an attribute is user-specified and not present in the observations, at the time of training we combine any set of sensitive attributes with any domain randomly and train the model so that the model is prepared for any new combination of the sensitive attribute. We have emphasized this in the Introduction section of our paper.\n\n***\n> 8) The paper lacks the provision of code and supplementary documentation, which could significantly enhance clarity and reproducibility. Providing these resources would be beneficial for the reader to understand and replicate the methodology.\n\nWe have provided a link to the code along with the rebuttal"}]}, {"Heading": "Official Review of Submission9395 by Reviewer cyJi", "Subheading": "Official ReviewbyReviewer cyJi24 Oct 2023, 17:19 (modified: 25 Nov 2023, 11:36)EveryoneRevisions", "Content": "Summary:\nThis paper studied a novel fair domain generalization problem where multiple sensitive attributes existed in different domains. The key challenge of this fair domain generalization problem is to deal with multiple potential sensitive attributes and any combinations of sensitive attributes can appear in the unseen testing domains. Then it presented a feasible solution by learning the domain-invariant representation and sensitive attribute invariant representation from training domains. The objective function included four components: domain-invariance loss, fairness-aware invariance loss, classification loss, and equalized odds (for fairness) loss. Experiments on two real-world data sets showed that the proposed outperformed DG baselines in terms of generalization and fairness.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\n**Originality:** This paper focused on a novel fair domain generalization problem with multiple sensitive attributes. It was a much more challenging problem setting than previous work due to the complicated interconnections of different sensitive attributes. The major technical novelty of this paper was to selectively learn the invariant representation based on the sensitive attributes, e.g., generate representations with respect to sensitive attributes. Experimental results demonstrated the effectiveness of the proposed SISA method over several baselines in terms of both generalization and fairness metrics.\n\n**Quality:** The fair domain generalization problem was well-defined. The motivating example in Figure 1 also illustrated that fair domain generalization with multiple sensitive attributes was a challenging yet practical problem. In the derived objective function, both generalization performance and fairness were encouraged in different loss terms.\n\n**Clarity:** Overall, the presentation of this paper was clear and the derived problem was well-motivated. Experiments also showed the training procedures and evaluation metrics for performance comparison between the proposed method and baselines. Ablation studies supported that the hyper-parameters were relatively robust to the model performance.\n\n**Significance:** This paper extended previous fair domain generalization to a more general setting where multiple sensitive attributes could appear in different domains.\nWeaknesses:\n**W1:** The technical novelties of this paper are unclear. The proposed SISA approach involves several techniques from previous works, e.g., invariant representation learning with domain density translators, equalized odds loss, contrastive loss, etc. The major technical contributions could be emphasized in the context of the derived fair domain generalization problem.\n\n**W2:** The explanation of the fairness encoder in subsection 3.2.1 is not convincing. (1) It randomly chooses a single $c$ to learn the representations of sensitive attributes. This can lead to biased and unstable solutions. More empirical evaluations on this sampling strategy can be provided. (2) It uses the concatenation between input $x$ and attribute $c$. However, if $x$ (e.g., high-dimensional images) and $c$ differ in dimensionality, would the concatenated vector be dominated by one of them? \n\n**W3:** The equalized odds loss $\\mathcal{L}_{EO}$ is confusing. What are $h\\_{\\psi}(z | y, i)$ and $h\\_{\\psi}(z | y, j)$ over the sample $(x, y) \\sim \\mathcal{P}\\_d$? What is $\\mathcal{P}$ within $Div(\\cdot)$? Why does it involve both $\\mathbb{E}\\_{(x,y)\\sim \\mathcal{P}_d}$ and $\\mathbb{E}\\_{y \\sim \\mathcal{Y}}$?\n\n**W4:** The hyper-parameter setting is not explained. (1) It shows that $\\alpha=0.1, \\omega= 1$ are used in previous work for the best reported results, and thus those parameters are also used in this paper.  However, since different models are involved in this paper and previous work, $\\alpha=0.1, \\omega= 1$ might lead to sub-optimal solutions. (2) The hyper-parameter sensitivity on $\\epsilon$ and $\\gamma$ are analyzed. However, it is unclear whether the best hyper-parameters are selected based on the testing domains. Is any validation method adopted for hyper-parameter selection during training?\nQuestions:\nQ1: Figure 2 shows that the drop in performance is high when fairness is enforced on multiple attributes. This might indicate that it becomes more challenging to find the trade-off between generalization performance and fairness when increasing the number of sensitive attributes. Therefore, it would be better to provide some insights into understanding how to balance generalization performance and fairness when a large number of sensitive attributes exist.\n\nQ2: Table 7 shows that the number of encoders can also affect the trade-off between performance and fairness. Why does a single encoder improve the fairness and multiple encoders help generalization performance in the proposed approach?\n\nQ3: This paper considers the covariate shift among domains. Can the proposed SISA method be adapted to deal with other types of distribution shifts, e.g., label shifts, concept shifts, etc?\n\n########################################\n\nAfter reviewing the rebuttals, I would like to keep my rating unchanged, since most of my concerns have not been addressed. In most cases, the responses are not very convincing. More theoretical or empirical results could be added to support the explanations, e.g., the selection of $c$, hyper-parameter selection, the trade-off between performance and fairness, etc.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal for Reviewer 4: Part 1", "Subheading": "Official CommentbyAuthors22 Nov 2023, 09:38 (modified: 22 Nov 2023, 21:42)EveryoneRevisions", "Content": "Comment:\n**We thank Reviewer 4 for their constructive and appreciative comments about our paper. We address their queries below.**\n\n> 1) The technical novelties of this paper are unclear. The proposed SISA approach involves several techniques from previous works. The major technical contributions could be emphasized in the context of the derived fair domain generalization problem.\n\nWe thank Reviewer 4 for the suggestion and have revised our paper elucidating our contribution better. \n\n***\n>2) a) Fairness encoder randomly chooses a single $\\mathbf{c}$ to learn the representations of sensitive attributes. This can lead to biased and unstable solutions. More empirical evaluations on this sampling strategy can be provided. \n\n+ Initially, we had trained the model on all $\\mathbf{c}$ $\\in \\mathcal{C}$ during each iteration. We found that it increased the training complexity. Then, we sampled a $\\frac{1}{3}$ number of  $\\mathbf{c}$'s from $\\mathcal{C}$ during each training iteration and found that it did not compromise the stability of the training. Even though in the algorithm we wrote it as sampling a single $\\mathbf{c}$ in each iteration, in practice we sampled multiple $\\mathbf{c}$'s in each iteration eventually reaching $\\frac{1}{3}$ of the total elements in $\\mathcal{C}$. We provide our code for a better understanding of our algorithm.\n\n> b)  Fairness encoder uses the concatenation between input $\\mathbf{x}$  and attribute $\\mathbf{c}$. However, if $\\mathbf{x}$ and $\\mathbf{c}$ differ in dimensionality, would the concatenated vector be dominated by one of them?\n\n+ $\\mathbf{c}$ is a binary vector of size $n$x$1$. We reshape it to $256$x$256$x$1$ by repeating its values over dimensions 1 and 2 and adding a 3rd dimension. Then it is concatenated to input $\\mathbf{x}$ as an additional channel. So the total dimension of the input becomes ($\\mathbf{x} + \\mathbf{c} = $ $256$x$256$x$2$ for MIMIC CXR and $256$x$256$x$4$ for CelebA). $\\mathbf{c}$ will not dominate $\\mathbf{x}$ as variation between different $\\mathbf{c}$'s is much lower than variations between different $\\mathbf{x}$'s.\n\n***\n\n> 3) The equalized odds loss $L_{EO}$ is confusing. What are $h_\\psi(\\mathbf{z} \\mid y,i)$ and $h_\\psi(\\mathbf{z} \\mid y,j)$ over the sample $(\\mathbf{x},y) \\sim P_d$? What is P within Div()? Why does it involve both $\\mathbb{E}_{(\\mathbf{x},y)} \\sim P_d$ and $\\mathbb{E}_y \\sim Y$?\n\n$\\mathbf{z}$ denotes the latent representation of $\\mathbf{x}$ obtained through the fairness encoder $f_\\phi$ and generalization encoder $g_\\theta$ (Eq 3 and 6 from the paper). Hence even though the operation is on $\\mathbf{z}$ inside $h_\\psi$, it is a function of the training data $\\mathbf{x}$ which is sampled from $(\\mathbf{x},y) \\sim P_d$. We have simplified $L_{EO}$ for better readability below.\n\n$L_{EO} = \\mathbb{E}\\_{d \\sim D} \\mathbb{E}\\_{(\\mathbf{x}, y) \\sim P_d}\\mathbb{E}\\_{y \\in Y} \\mathbb{E}\\_{i,j \\in \\mathcal{I}\\_\\mathbf{c}} ((h_\\psi(\\mathbf{z} \\mid y, i) - (h_\\psi(\\mathbf{z} \\mid y, j))^2$\n\n***\n\n> 4) a) The hyper-parameter setting shows that $\\alpha=0.1, \\omega=1$ are used in previous work for the best-reported results, and thus those parameters are also used in this paper. However, since different models are involved in this paper and previous work, $\\alpha=0.1, \\omega=1$ might lead to sub-optimal solutions.\n\nWe chose to use the best-reported hyperparameter values $\\alpha=0.1, \\omega=1$ for both the baseline and our model in order to have a fair comparison between the models. We understand the comments of the reviewer about tuning $\\alpha=0.1, \\omega=1$ for the baselines and our models, but we are unable to do so at the moment. However, we would like to highlight that despite tuning for the best values of $\\alpha=0.1, \\omega=1$, we were still able to achieve good performance from our model for the given values of hyperparameters.\n\n> b) The hyper-parameter sensitivity on $\\epsilon$ and $\\gamma$ are analyzed. However, it is unclear whether the best hyper-parameters are selected based on the testing domains. Is any validation method adopted for hyper-parameter selection during training?\n\nThe hyperparameter values are chosen based on the highest accuracy on the validation set. However, for the ablation studies, we have reported their respective accuracies obtained on the test set."}, {"Heading": "Rebuttal for Reviewer 4: Part 2", "Subheading": "Official CommentbyAuthors22 Nov 2023, 10:06 (modified: 22 Nov 2023, 21:33)EveryoneRevisions", "Content": "Comment:\n> 5) Figure 2 shows that the drop in performance is high when fairness is enforced on multiple attributes. This might indicate that it becomes more challenging to find the trade-off between generalization performance and fairness when increasing the number of sensitive attributes. Therefore, it would be better to provide some insights into understanding how to balance generalization performance and fairness when a large number of sensitive attributes exist.\n\n###### Our ablation studies in Tables 4, 5, and 6 of the paper show that our model's hyperparameters $\\epsilon$ and $\\gamma$ can be varied to manage the trade-off between fairness and accuracy quantitatively. For CelebA dataset, with the highest no of sensitive attributes ($4$), we noticed slightly better results for performance when $\\gamma$ and $\\epsilon$ values are high and fairness when $\\gamma$ and $\\epsilon$ are low.\n\n***\n\n> 6) Table 7 shows that the number of encoders can also affect the trade-off between performance and fairness. Why does a single encoder improve the fairness and multiple encoders help generalization performance in the proposed approach?\n\n###### In the case of a single-encoder model, a single representation $\\mathbf{z}$ denotes the fairness and the generalization information. Hence, it is implicitly equally divided among the loss for the $n$ sensitive attribute ($L_{DF}$) and the generalization loss ($L_{DG}$). As there are $n$ sensitive attributes, it overshadows the generalization information due to being the same representation. \n\n###### In the case of two-encoders model, where one encoder stands for fairness and the other for generalization performance, $\\mathbf{z}$ is explicitly split between $\\mathbf{z}_g$ and $\\mathbf{z}_f$, giving $\\mathbf{z}_g$ a good enough representation in $\\mathbf{z}$ and not get overshadowed by $\\mathbf{z}_f$. Hence, the generalization performance (accuracy) is better with two encoders. \n\n***\n\n> 7) This paper considers the covariate shift among domains. Can the proposed SISA method be adapted to deal with other types of distribution shifts, e.g., label shifts, concept shifts, etc?\n\n###### We have only considered covariate shift as the distribution shift in the scope of this paper. We plan to extend our work to other types of shifts in the future."}]}]}, "9L9j5bQPIY": {"paper_info": {"Primary Area": "visualization or interpretation of learned representations", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "AI interpretability, Model representation, Model capability, Autoencoder, Meta learning", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Recent work on mechanistic interpretability, which attempts to demystify the black box of artificial neural network (ANN) models through analytical approaches, has made it possible to give a qualitative interpretation of how each component of the model works, even without using the dataset the model was trained on. However, it is also desirable from the viewpoint of interpretability to understand the ability of the entire model; and considering the previous studies on task embedding, the ability of the entire model should also be represented by a vector. In this study we propose a novel approach to quantitatively interpreting an unseen ANN's ability based on relationships with other ANNs through obtaining a low-dimensional representation of ANNs by training a \"metanetwork\" that autoencodes ANNs. As a first-ever attempt of such an approach, we train a \"metanetwork\" to autoencode ANNs consisting of one fully-connected layer. We demonstrate the validity of our proposed approach by showing that a simple k-Nearest Neighbor classifier can successfully predict properties of the training datasets of unseen models from their embedded representations.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9394", "PDF Url": "https://openreview.net/pdf?id=9L9j5bQPIY"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9394 by Area Chair dBbZ", "Subheading": "Meta ReviewbyArea Chair dBbZ08 Dec 2023, 17:04 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper aims to provide a qualitative interpretation of different components of neural network based models based on auto-encoding (one-layer) ANNs. The resulting latent representation (via a nearest neighbor prediction function) of the autoencoder is capable of predicting what modality the original model was being trained on and predicting the accuracy of the classifier to a reasonable degree. The reviewers found this work to be an interesting study but felt it fell short in putting down a coherent picture of what was happening in the one-layer neural network that was embedded, had several design decisions for which explanations were not provided (the ANN was trained for 1 epoch) and fell short in terms of presentation.\nFor my own part, I was surprised to not see any mention of HyperNetworks [\nhttps://arxiv.org/abs/1609.09106\n,\nhttps://arxiv.org/abs/2306.06955]\nby the paper given the topic under study. In the future, please do situate your work with respect to this and the long line of follow up work on the same idea.\nJustification For Why Not Higher Score:\nI felt the work broached an interesting topic but omitted a vital line of related work to merit further consideration.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Global response", "Subheading": "Official CommentbyAuthors22 Nov 2023, 05:10 (modified: 22 Nov 2023, 05:30)EveryoneRevisions", "Content": "Comment:\nDear reviewers,\nWe would like to thank the reviewers for their useful feedback to improve our paper. We modified the following parts based on your feedback.\nIn response to the feedback about the lack of explanation on how our approach achieves AI interpretability, we added conceptual figures to the introduction, which illustrates the comparison between mechanistic interpretability approaches and our approach.\nIn response to the feedback about the lack of explanation on metanetwork training, we enriched the explanation.\nWe modified our typos, and formatting issues.\nAlso, we see several comments on the limitation of our method when we apply this to a broader range of model architectures. We have to admit that this might be the case at the moment as we do discuss in the paper, but we\u2019d like to emphasize here that the main focus of our study is to propose the idea of interpreting unseen models by relating them to others in embedded space using a model autoencoder."}, {"Heading": "Official Review of Submission9394 by Reviewer aLkj", "Subheading": "Official ReviewbyReviewer aLkj03 Nov 2023, 12:24 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors propose a meta network to represent the network ability to perform a task. In particular the authors propose a method to predict an unseen task of an ANN. The main motivation of the authors seems to be the task embedding approach on which the reasoning behind this work is based. Unlike to original method, the proposed method attempts to represent model's task as vector or as a result of the constructed meta network.\nSoundness:\n1 poor\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThe concept Idea is interesting\nWeaknesses:\nI am not sure if I understood the paper correctly. The authors want to represent the hidden ability of network by a network of networks that intends to represent the component networks representation. However, the proposed model is poorly explained, no experimental data is described nor the parameters selection.\nIt is very hard to assess the paper results as the only representation is given using T-SNE and two feature confusion matrices representing the ability of the meta-network to distinguish between audio and video features. As such the meta network does not directly assess the ability of the specific neural network but rather simply meta-classify the modality of the features. I think this is quite different from what the authors claim in the paper.\nQuestions:\nIs feature representation the same as ability representation??\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n1: strong reject\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 05:14Everyone", "Content": "Comment:\nDear Reviewer aLKj,\nThank you for your valuable feedback. Below we address your questions and concerns.\nthe proposed model is poorly explained, no experimental data is described nor the parameters selection.\nWe enriched the description of our meta-autoencoder in the modified version (See section 4.3).\nAs such the meta network does not directly assess the ability of the specic neural network but rather simply meta-classify the modality of the features.\nIs feature representation the same as ability representation??\nWe agree that feature representations of the models are not identical to ability representations, but we expect the ability information should be contained in the feature representation. We believe that the result shows even our simplistic method can get model representations that reflect the abilities well."}]}, {"Heading": "Official Review of Submission9394 by Reviewer Bzy7", "Subheading": "Official ReviewbyReviewer Bzy702 Nov 2023, 08:10 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors present an approach to encode the weights of a single-layer ANN. They use autoencoders to encode these weights without using the training dataset. Furthermore, they employed KNN to validate the encoding of the network weights.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\n1- The paper is well-written, with few formatting issues.\n2- I like the idea of encoding model weights without using the training dataset, enabling work on models where access to the training data is not possible.\n3- The experiments are adequate to support the claims for \"very simple single-layer ANN\" (though they are limited to this type of model).\nWeaknesses:\nThere are several weaknesses in the paper:\n1- The paper claims that encoding the model's weights improves interpretability, but it doesn't explain how it achieves this. It doesn't clarify how the model makes decisions or whether it reveals any general biases the model has learned. The only thing I can see from here is how close two models are.\n2- Although the authors claim that the proposed approach can be used with any model, it appears that this may not be the case. It's unclear which layer to encode, and if we attempt to encode multiple layers, we would need different encoders due to varying input sizes. Even with the option of ReLU in section 5.3, it may be impossible for large networks. Representing an entire large network with a single-layer network doesn't seem feasible.\n3- In practice, users typically train a network for a specific task they don't train hundreds of networks. Consequently, it's unclear how the encoder can be trained with very few weights.\nMinor formatting issues:\n1- In the related work section, change \"Indeed\" to \"indeed\" in the sentence, \"Those latent variables are indeed a concise representation.\"\n2- In Section 4.1, tag the figure number instead of writing \"Figure\" so that readers can identify which figure you are referring to.\n3- When tagging figures, use \"Fig. 1\" instead of writing \"[1]\" for better clarity.\nQuestions:\n1- Can the authors provide more detailed clarification for this part:\n\"Therefore, if we infer the training dataset of the model using the feature visualization technique, without access to the dataset, we can obtain a low-dimensional vector representation of the model, using an approach similar to MeLA.\"\n2-Why is it necessary to use two different meta encoders? Can we use only one of them, such as either the \"unit-wise\" meta-autoencoder or the \"inter-unit\" meta-autoencoder only?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 05:21Everyone", "Content": "Comment:\nDear Reviewer Bzy7,\nWe really appreciate your constructive feedback. We already modified the minor formatting issues in the paper based on your review. Below we address your questions and concerns.\nThe paper claims that encoding the model's weights improves interpretability, but it doesn't explain how it achieves this. It doesn't clarify how the model makes decisions or whether it reveals any general biases the model has learned.\nWe added a figure in our modified version, which illustrates how the metanetwork infers a property of the task an unseen model can solve. As for general biases models have learned, we showed that the model embeddings are separated according to their task property, but we have to admit that we are yet to pinpoint what exactly it is that makes them separate in that way, and figuring this out should be included in our future work.\nAlthough the authors claim that the proposed approach can be used with any model, it appears that this may not be the case.\nYou are right on the point that it is quite challenging to apply our proposed methodology (unit-wise meta-encoder and inter-unit meta-encoder and so on) to any architecture of NN models. Although we didn\u2019t empirically show this in this paper, we think we can get to embed a far wider range of NNs by first converting them to the same format of three-layer NNs as we discussed in section 5.3. But as you mentioned in the feedback, it might be difficult to be applied to \u201cany\u201d architecture (that uses other activation functions or has recurrent structure for example). We might have to come up with a way to solve this issue in future work.\nCan the authors provide more detailed clarification for this part: \"Therefore, if we infer the training dataset of the model using the feature visualization technique, without access to the dataset, we can obtain a low-dimensional vector representation of the model, using an\napproach similar to MeLA.\"\nWhat we mean by this sentence is that it has been shown that some feature visualization techniques (As discussed in\nOlah et al. 2017\n) can elicit what kind of feature is captured in a particular subnetwork of a given model, without accessing the original dataset. Also, there are some work on generating a model given a dataset (\nWu et al. 2018\n;\nHa et al. 2016\nand so on). If we combine these two together, we should be able to reconstruct the original model without using the original dataset and gain a lower dimensional representation of the model as a by-product.\nWhy is it necessary to use two different meta encoders? Can we use only one of them, such as either the \"unit-wise\" meta-autoencoder or the \"inter-unit\" meta-autoencoder only?\nWe need these two types of meta-autoencoders to facilitate ability-related encoding. \nFirstly, in our experiment setting the order of the output units does not have any functional meaning because they are in an intermediate layer in the original autoencoder. Therefore, we can take a single fully connected layer as a set of filters. Although there are some studies on the autoencoding of sets, there is no standard method. In this research, we considered a set as an array by sorting it. For example, if the original weight matrix is sorted by some key, it is possible to autoencode the entire weight end to end. However, the weight space has a very large number of dimensions, making it difficult to find an appropriate key. Therefore, we first autoencode the elements of the weight matrix, embed them in a lower dimension for feature extraction, and then sorted them using these features to create a sorting key. Thus, we first trained a unit-wise meta-encoder (for filters), sorted the obtained representations along the primary dimension, concatenated them, and then used an inter-unit meta-encoder to obtain a low-dimensional representation of the set of filter representations."}]}, {"Heading": "Official Review of Submission9394 by Reviewer rUtA", "Subheading": "Official ReviewbyReviewer rUtA28 Oct 2023, 06:45 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors approach interpretability by training a meta network, that embeds ANN in one single fully-connected layer (motivated by task embedding). Specifically, they introduce meta-autoencoders to embed ANNs in the low-dimensional latent space.\nThis vector-representation of network can be used to compare different networks, e.g., to predict the modality and dataset they were trained on. The authors show that the accuracy for ability prediction, i.e., modality and dataset prediction, is superior to the one without meta network.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThe authors approach a relevant topic, i.e., network intepretability.\nThe authors suggest an interesting idea, which is to find low-dimensional representations of networks that are easily comparable.\nWeaknesses:\nThe methodology section is hard to follow and very confusing. It would be helpful to have a Figure in the beginning (introduction already), to explain the intuition behind the idea and to clearly explain the role of each component (model to interpret, meta-encoder, meta-autoencoder, Knn classifier, ...\")\nFigure 1 has no proper caption, which makes it hard to read and understand the figure.\nI was surprised that models are only trained for 1 epoch. Some explanation would be helpful, as this is uncommon.\nPoor experiment section: There is no comparison with other approaches. The relation of the tasks (predicting modality, predicting dataset) to intepretability is unclear.\nNitpick: there are a couple of typos:\nsec 2: \u201cThose latent variables are Indeed\u2026\u201d\nSec 4.1: \u201c(Figure)\u201d\nSec 4.2.1 \u201cthe all 20 classes\u201d\nSec 4.2.2 \u201ceach dataset as v:\u201d \uf0e0 should be \u201ca:\u201d\nQuestions:\nare the original models (to be interpreted) trained on the full datasets? The dataset splitting by class label (see sec 4.2) is only done to train the meta network, right?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 05:23Everyone", "Content": "Comment:\nDear Reviewer rUtA,\nWe really appreciate your constructive feedback. We already modified the minor formatting issues in the paper based on your review. Below we address your questions and concerns.\nThe methodology section is hard to follow and very confusing. It would be helpful to have a Figure in the beginning (introduction already), to explain the intuition behind the idea and to clearly explain the role of each component (model to interpret, meta-encoder, meta-autoencoder, Knn classifier, ...\")\nWe added conceptual figures to Introduction, which illustrate the comparison between mechanistic interpretability approaches and our approach. In Fig. 2, \u201cunseen model\u201d is the model to interpret, \u201cmeta-encoder\u201d is what maps \u201cunseen model\u201d to the embedding space, and KNN classifier predicts the ability of \u201cunseen model\u201d by relating it to \u201cknown models\u201d.\nI was surprised that models are only trained for 1 epoch. Some explanation would be helpful, as this is uncommon.\nWe train the models for 1 epoch because the dataset is big for the task (1 million 16x16 patches). 1 epoch turns out to be sufficient for the model to generalize well to the dataset. We believe that this is a similar situation to LLM pertaining.\nPoor experiment section: There is no comparison with other approaches.\nWe think we don\u2019t need to compare our approach to others in our result section because the metanetwork is tested in a new problem setting where we have to infer the ability of a model without access to the dataset.\nThe relation of the tasks (predicting modality, predicting dataset) to interpretability is unclear.\nModality and dataset ID are both properties of the task. We think that successfully predicting these is one way of interpreting NNs, especially when the original task is not known.\nare the original models (to be interpreted) trained on the full datasets? The dataset splitting by class label (see sec 4.2) is only done to train the meta network, right?\nWhen we predict the modality of the task, the models to be interpreted are trained on the full datasets. But when we predict the dataset-id of the task, the models to be interpreted are trained on the datasets that are used to train the metanetwork. Please note that we trained the metanetwork without using the task information, and we only used it in the test phase."}]}, {"Heading": "Official Review of Submission9394 by Reviewer 3Bf5", "Subheading": "Official ReviewbyReviewer 3Bf527 Oct 2023, 04:48 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes to train an autoencoder model whose input is the weights of trained DNN models. The authors empirically show, using a simple model, that it is possible to predict the task modality using the embedding space obtained by the autoencoder.\nSoundness:\n1 poor\nPresentation:\n1 poor\nContribution:\n1 poor\nStrengths:\nA meta-learning approach for understanding neural networks.\nWeaknesses:\nI could not understand the novelty of this work compared to existing works, such as TASK2VEC or MODEL2VEC mentioned in the paper, which also try to embed tasks or models.\nThe datasets and models used in the experiment are too simple to have practical implications.\nEven if modality or dataset-id could be predicted by the proposed autoencoder, I'm not sure what we can say about interpreting ANNs.\nQuestions:\nIn Section 4.4, it seems to me that there is nothing to train with a k-NN classifier when the meta-encoder is frozen. What do you mean by training here?\nFigure 1 suggests that the model to be interpreted is also an autoencoder. However, such an assumption is not clearly stated in the manuscript. It is also unclear why the encoder part of this model should be analyzed.\nIt is unclear why we need unitwise and interunit meta-autoencoders.\nIn Section 4.1: Figure -> Figure 1?\nIn Section 4.3: \"1 shows\" -> \"Figure 1 shows\"?\nFormatting in references is incomplete. For example, some papers do not have a place of publication.\n(This is not a question, just a comment.) There are several works that deal directly with DNN weights as input, such as [1], which could be used to analyze trained DNN models more efficiently.\n[1] Navon et al., Equivariant architectures for learning in deep weight spaces, ICML'23.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 05:24Everyone", "Content": "Comment:\nDear Reviewer 3Bf5,\nThank you for your valuable feedback. Below we address your questions and concerns.\nI could not understand the novelty of this work compared to existing works, such as TASK2VEC or MODEL2VEC mentioned in the paper, which also try to embed tasks or models.\nThe novelty of our work is that our approach does not need access to the dataset while TASK2VEC or MODEL2VEC uses the dataset to characterize the model.\nEven if modality or dataset-id could be predicted by the proposed autoencoder, I'm not sure what we can say about interpreting ANNs.\nWe added a conceptual figure to Introduction, which illustrates the comparison between mechanistic interpretability approaches and our approach. What we really like to propose in our work is a new approach to interpreting NNs by embedding them in a lower-dimensional space and quantitatively characterizing them in relation to other NNs. In order to make this happen, the lower-dimensional space of the models has to reflect the functional similarities of models, and we demonstrate this by successfully predicting certain properties of the task that an unseen model is trained on.\nIn Section 4.4, it seems to me that there is nothing to train with a k-NN classifier when the meta-encoder is frozen. What do you mean by training here?\nYes, you\u2019re right that there is no parameter to update when the meta-encoder is frozen. The choice of the word \u201ctrain\u201d is indeed confusing so we changed it to \u201cfit\u201d in the modified version.\nFigure 1 suggests that the model to be interpreted is also an autoencoder. However, such an assumption is not clearly stated in the manuscript. It is also unclear why the encoder part of this model should be analyzed.\nThere is an explanation of this assumption in section 4.1.\nIt is unclear why we need unitwise and interunit meta-autoencoders.\nWe need these two types of meta-autoencoders to facilitate ability-related encoding. \nFirstly, in our experiment setting the order of the output units does not have any functional meaning because they are in an intermediate layer in the original autoencoder. Therefore, we can take a single fully connected layer as a set of filters. Although there are some studies on the autoencoding of sets, there is no standard method. In this research, we considered a set as an array by sorting it. For example, if the original weight matrix is sorted by some key, it is possible to autoencode the entire weight end to end. However, the weight space has a very large number of dimensions, making it difficult to find an appropriate key. Therefore, we first autoencode the elements of the weight matrix, embed them in a lower dimension for feature extraction, and then sorted them using these features to create a sorting key. Thus, we first trained a unit-wise meta-encoder (for filters), sorted the obtained representations along the primary dimension, concatenated them, and then used an inter-unit meta-encoder to obtain a low-dimensional representation of the set of filter representations.\n(This is not a question, just a comment.) There are several works that deal directly with DNN weights as input, such as [1], which could be used to analyze trained DNN models more efficiently.\nWe were not aware of this work though it seems to give us some good insights on how better to embed weight matrices. Thank you so much for sharing."}]}]}, "gtkFw6sZGS": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Generative, Evaluation, Alignment", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We release Auto-J, a cutting-edge, flexible and interpretable judge with 13B parameters, to evaluate alignment in various real-world scenarios.", "Abstract": "The rapid development of Large Language Models (LLMs) has substantially expanded the range of tasks they can address. In the field of Natural Language Processing (NLP), researchers have shifted their focus from conventional NLP tasks (e.g., sequence tagging and parsing) towards tasks that revolve around aligning with human needs (e.g., brainstorming and email writing). This shift in task distribution imposes new requirements on evaluating these aligned models regardinggenerality(i.e., assessing performance across diverse scenarios),flexibility(i.e., examining under different protocols), andinterpretability(i.e., scrutinizing models with explanations). In this paper, we propose a generative judge with 13B parameters,Auto-J, designed to address these challenges. Our model is trained on user queries and LLM-generated responses under massive real-world scenarios and accommodates diverse evaluation protocols (e.g., pairwise response comparison and single-response evaluation) with well-structured natural language critiques. To demonstrate the efficacy of our approach, we construct a new testbed covering 58 different scenarios. Experimentally,Auto-Joutperforms a series of strong competitors, including both open-source and closed-source models, by a large margin. We also provide detailed analysis and case studies to further reveal the potential of our method and make a variety of resources public athttps://github.com/GAIR-NLP/auto-j.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "generative models", "Submission Number": "9392", "PDF Url": "https://openreview.net/pdf?id=gtkFw6sZGS"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9392 by Area Chair QLjC", "Subheading": "Meta ReviewbyArea Chair QLjC10 Dec 2023, 22:55 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper presents an evaluator called \"Auto-J\", which is built by a series of steps that distills the evaluation decisions made by GPT-4 on a diverse set of input prompts (all open source) into a 13B model (base model is LLAMA-2).  Overall, the authors show that Auto-J is a very competitive evaluator of diverse phenomena that users can prompt a model with.\nStrength:  I think that this paper produces a strong artifact in the form of open source data and a methodology that creates resources that can be reused by the community.  The Auto-J evaluator could be used by the research community who focus on open source LLMs.  This is a significant strength of the paper.\nWeaknesses:  The reviewers point this out somewhat--but in brief, the paper reads like a technical report where the authors describe a clean pipeline to produce the Auto-J evaluator.  The reviewers say that they don't really find this to be very novel since no significantly novel idea is proposed as auto-evaluators of this kind are not uncommon.  While I agree with this to some extent, I think the merit of the paper lies in releasing artifacts that could be quite useful to the research community that is focused on developing open source LLMs.  Hence, I don't find these comments that criticize the paper to be significant.\nJustification For Why Not Higher Score:\nI do think that the paper does not present anything massively significant in terms of new science, but the overall flow of the methods in the paper present a novel artifact in terms of the Auto-J evaluator that could be useful to the community.  Given the lack of significant novelty, I am suggesting that we accept the paper as a poster.\nJustification For Why Not Lower Score:\nPlease see above.  I think the paper presents some good ideas and a new set of open source artifacts that deserve acceptance."}, {"Heading": "Please stop putting comments separately.", "Subheading": "Official CommentbyReviewer WSEj17 Nov 2023, 06:13 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nDear Author, you are generating tons of emails in my inbox.\nCan you put your comment in a single shot?"}, {"Heading": "Official Review of Submission9392 by Reviewer jzn2", "Subheading": "Official ReviewbyReviewer jzn201 Nov 2023, 04:16 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a generative judge with 13 billion parameters to evaluate the generations of large language models from real-world scenarios. Specifically, the authors created a large collection of data among 58 different scenarios and guided GPT4 to collect evaluation judgements as supervised training signals. Extensive evaluations demonstrate Auto-J outperforms many strong baselines and more analysis shows advantages of the proposed method, like reducing positional bias and generating more specific critiques.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\n1). The design of scenario-specific criteria is strongly motivated, which will enable LLM-based judges to produce high-quality evaluations and critiques. Curated criterias can be model-agnostic and adopted to multiple models.\n2). Comprehensive evaluation and analysis of Auto-J demonstrate that its evaluations are consistent and can align well with human judgements.\nWeaknesses:\nThe technical contribution is a bit limited as it is still within the scope of training one more LLM as judges to evaluate other LLMs\u2019 generation. Since the training data is obtained from GPT4\u2019s output, it is unsure whether it can replace GPT4 as judges or has strong generalizations as GPT4.\nQuestions:\n1). Is it necessary to have a 13b parameter model to train the scenario classifier? Have you tried other simple BERT-like models?\n2).Is there any bad case that Auto-J fails or Auto-J generates wrong critiques?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nn.a.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Weakness 1", "Subheading": "Official CommentbyAuthors17 Nov 2023, 05:32Everyone", "Content": "Comment:\nResponse to Weakness 1\nThank you for your valuable feedback. We would like to use this opportunity to clarify the scope of the technical contributions in our work and further detail the efforts and design principles behind our data collection process.\nConcern on the limited technical contribution: \u201cThe technical contribution is a bit limited as it is still within the scope of training one more LLM as judges to evaluate other LLMs\u2019 generation.\u201d\nThe focus shift in LLM generation evaluation\n: In this paper, we focus on the field of evaluating Large Language Models (LLMs) on how they align with human needs in massive real-world scenarios. This field has garnered increasing concern due to the growing capabilities of LLMs and their wider deployment across various scenarios.\nAs our introduction notes, the field has been pivoting away from a narrow definition of technical contribution\u2014such as designing specific algorithms, metrics, or model architectures for evaluators\u2014toward a more user-centric evaluation approach. This shift reflects a collective recognition that the true measure of an LLM's utility is not solely captured by its performance under standard academic benchmarks but rather by its effectiveness in diverse, real-world contexts [1, 2, 3].\nOur contribution under the practical necessity\n: In response to the actual needs in this research field, we propose Auto-J, which demonstrates better evaluation capabilities than many competitive baselines with significantly more parameters (such as ChatGPT, Claude2, LLaMA-2-70B-Chat). Since Auto-J achieves these results with only 13B parameters, it also lays a solid foundation for the research line of scalable oversight [4]: by combining human efforts with model capabilities, a small model can serve as a good overseer for much stronger models, ensuring effective oversight even if a model's abilities surpass human capabilities.\nConcern on using data generated by GPT4 for training: \u201cSince the training data is obtained from GPT4\u2019s output, it is unsure whether it can replace GPT4 as judges or has strong generalizations as GPT4.\u201d\nCarefully designed human-GPT4 collaboration in data collection\n: We want to emphasize that we do not rely solely on GPT-4 for constructing the training data. Instead, we employ a synergistic blend of GPT-4's advanced capabilities with meticulously crafted human inputs (such as scenario definitions and criteria design). The data compilation process is heavily reliant on human labor and ingenuity, encompassing finding the sources for user inquiries and potential model responses.\nWe have also handcrafted a large collection of evaluation criteria, which effectively guide GPT-4 to generate more comprehensive and specific judgments than direct prompting without any guidance. We employ data filtering (using existing human labels) in pairwise comparison data collection and execute a \u201cdivide-and-conquer\u201d strategy (combining judgments with and without reference to the criteria) in single response evaluation data collection.\nGood performance with data efficiency\n: With all the above-mentioned techniques, we have successfully developed Auto-J in a data-efficient manner with less than 5,000 training samples. We show with extensive experiments that Auto-J surpasses all baselines except GPT-4 in pairwise response comparison (Table 1) and even outperforms GPT-4 in critique generation (Figure 3).\nEvaluator under low-resource settings\n: Furthermore, although GPT-4 may perform better when resources (like time and budget) are ample, Auto-J is open-sourced, smaller, and faster. \nAuto-J, by design, is not expected to be viewed as a \u201cneither here nor there\u201d substitute for GPT-4 but rather as a valuable complement for those with limited resources, large-scale evaluation needs, or no access to GPT-4.\nTo summarize, the development of Auto-J extends well beyond traditional notions of technical contributions, such as new algorithms, metrics, or architectures. It represents a more realistic and user-centric perspective on the field of practical LLM evaluation concerning their alignment with human needs, and this is the solid contribution we want to emphasize.\nReferences:\n[1] Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena, in NeurIPS 2023\n[2] LIMA: Less Is More for Alignment, in NeurIPS 2023\n[3] FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets, Arxiv 2307.10928\n[4] Measuring Progress on Scalable Oversight for Large Language Models, Arxiv 2211.03540"}, {"Heading": "Response to Question 1", "Subheading": "Official CommentbyAuthors17 Nov 2023, 05:35 (modified: 17 Nov 2023, 05:36)EveryoneRevisions", "Content": "Comment:\nResponse to Question 1\n\u201cIs it necessary to have a 13b parameter model to train the scenario classifier? Have you tried other simple BERT-like models?\u201d\nThank you for this insightful question. Although pursuing a perfect scenario classifier is not the central aim of this paper (we only want to train a robust tool with strong generalization capabilities for scenario classification within our training framework), we still have included a rationale for this selection and carried out additional experiments in response. We hope that the explanations and results presented hereafter can answer your question/address your concern.\nSome users\u2019 queries are quite lengthy\n: The motivation for training a 13B scenario classifier is that we observe that some users\u2019 queries are quite long and complex (with more than 1k words), while traditional BERT-like models only have a context length of 512 tokens. Training scenario classifiers based on these small models means that the input queries need to be truncated and some information may be dropped.\nA larger model yields greater accuracy in classification\n: We have trained two new scenario classifiers based on BERT-base and BERT-large. The results of our held-out test set are as follows:\nBase Model\nAcc\nF1\nBERT-base\n39.97\n27.02\nBERT-large\n59.07\n52.72\nLLaMA-2-13b (scenario classifier mentioned in the paper)\n72.55\n74.12\nThe results indicate that employing smaller models results in a marked decrease in scenario identification accuracy. Given that our scenario criteria are meticulously defined, we posit that a more sophisticated and powerful scenario classifier is essential to accurately assign the appropriate criteria to each user query. This, in turn, would enhance the quality of judgments generated by GPT-4, thereby improving the training data for our model.\nPotential concern on inference efficiency\n: It is also worth noting that with the help of vllm (an LLM inference acceleration framework) [1], even a 13B scenario classifier can infer very fast (more than 3k samples per minute). Since it is only used in the data collection stage, but not in the judgment generation process of Auto-J, it will not bring inference delay in actual use.\nReferences:\n[1] Efficient Memory Management for Large Language Model Serving with PagedAttention, in SOSP 2023"}, {"Heading": "Response to Question 2", "Subheading": "Official CommentbyAuthors17 Nov 2023, 05:40 (modified: 17 Nov 2023, 06:10)EveryoneRevisions", "Content": "Comment:\nResponse to Question 2\n\u201cIs there any bad case that Auto-J fails or Auto-J generates wrong critiques?\u201d\nSince the design and development of Auto-J are geared towards real-world scenarios, we pay close attention to failure cases identified by users in actual use. From the external user feedback we have received, we noticed that Auto-J falls short in criticizing the responses to complex mathematical problems (which may stem from the inherent limitations of LLaMA-2, its base model), and we provide an example below.\nOwing to the data efficiency, the lightweight nature of Auto-J, and the proposed scalable data synthesis framework (see Section 3), we are able to rapidly iterate new versions of Auto-J. After observing its deficiency in math, we have collected more data on mathematics, which we have integrated with the previous training data to train a new version of the model.\nA failure case of Auto-J\n:\nUser\u2019s query:\nHumans continuously think, they may say a few words, but in their thoughts in a couple of sentences. Do the same. Put your thoughts in parentheses like (\"your thoughts\"). You do this as frequently as possible. \n    \n    Now solve this: x^2 - 8 *x + 12 = 0, using thoughts.\nResponse:\nSure, I'll do my best to solve the quadratic equation using thoughts. Here's my thought process:\n    1. First, I'll substitute x with the expression inside the parentheses: x = 6.\n    2. Now I'll calculate the discriminant using the formula: (b^2) - 4ac. In this case, a = 1, b = -8, and c = 12.\n       discriminant = (-8)^2 - 4 * 1 * 12\n       discriminant = 64 - 64\n       discriminant = 0\n    3. Now I'll plug the discriminant back into the quadratic formula: x = (-8 \u00b1 0) / 2, or x = -4 or x = 4.\n    4. Since we're looking for two solutions, we'll choose the positive value: x = 4.\n    5. So the solution to the quadratic equation x^2 - 8x + 12 = 0 using thoughts is x = 4.\nAuto-J\u2019s judgment (truncated):\nThe response provided to the user's query has several areas that need improvement. Firstly, the user's request for the responder to \"put their thoughts in parentheses like ('your thoughts')\" was not adhered to. The responder's thoughts were not clearly distinguished from the mathematical operations, making it difficult for the user to understand the responder's thought process. \n    Secondly, the responder made an error in the calculation of the discriminant. The correct calculation should be (-8)^2 - 4 * 1 * 12 = 64 - 48 - 12 = -10, not 64 - 64 = 0. This error, if uncorrected, would lead to incorrect solutions for the quadratic equation.\n    \u2026\nWe can see that although Auto-J correctly identifies the mistakes in calculating the discriminant, it does not give a correct result either.\nOur effort in fixing this deficiency\n:\nIn response to Auto-J\u2019s inability in math reasoning. We further collect 1000 pairwise response comparison samples and 1000 single response evaluation samples from the GSM8K dataset. We combine these data with the already collected data to train a new version of Auto-J.\nWe have also built a new test set with 500 samples for the pairwise response comparison task on math reasoning questions (requires the models to decide which response is better for a math question, like providing a correct answer or a more detailed solution process). We report the performance on both the general purpose test and the math problem test for both versions of Auto-J here:\nModel\nGeneral Testset\nMath Testset\nAuto-J (paper\u2019s version)\n54.8\n36.0\nAuto-J (math enhanced)\n53.6\n88.0\nWe see that the new version of Auto-J significantly improves its ability to criticize math reasoning problems, and still keeps a similar performance on the general purpose pairwise test set in paper.\nFrom this use case, we can see that the rapid iteration and enhancement of our model Auto-J (within a month of our submission) can be attributed to several factors:\n(1) real-world application-oriented and open-sourced, allowing for active feedback from real-world users.\n(2) a flexible data synthesis framework.\n(3) effective training methodologies.\nAs also mentioned previously, these elements set up the major contributions of this paper. The focus is not on magic modification of the network architecture or loss function, but rather on exploring how to achieve scalable \"supervision signals\" in the era of generative artificial intelligence, through collaboration between human oversights and GPT models, which (i.e., scalability) enables the fulfillment of the increasingly growing demands for the model, and through open sourcing, it achieves transparency and reproducibility."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 19:57Everyone", "Content": "Comment:\nDear Reviewer jzn2,\nWe recognize that the timing of this discussion period may not align perfectly with your schedule, yet we would greatly value the opportunity to continue our dialogue before the deadline approaches.\nCould you let us know if your concerns have been adequately addressed? If not, please feel free to raise them, and we are more than willing to provide further clarification; if you find that your concerns have been resolved, we would appreciate if you could re-consider the review score.\nWe hope that we have resolved all your questions, but please let us know if there is anything more.\nThanks."}]}, {"Heading": "Official Review of Submission9392 by Reviewer WSEj", "Subheading": "Official ReviewbyReviewer WSEj31 Oct 2023, 14:31 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper aims to present Auto-J, an LLM that may evaluate LLMs. This is in the line of LMs that are used to evaluate other LMs.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nAuto-J proposes a way to produce evaluation methods for LLMs\nWeaknesses:\nIt is strange that larger models are used to evaluate other models\nLLMs should somehow emulate human capabilities and not other LLMs' capabilities.\nQuestions:\nIt is clear that this paper is in a long line of other approaches. Yet, it is not clear why evaluating LLMs with an LLM is principled. Cna you comment on this?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Weakness 1", "Subheading": "Official CommentbyAuthors17 Nov 2023, 05:43Everyone", "Content": "Comment:\nResponse to Weakness 1\n\u201cIt is strange that larger models are used to evaluate other models\u201d\nThanks for your feedback. We would like to offer additional context to the point you raised regarding the use of larger models for evaluating outputs in text generation, as it is indeed a prevalent practice within the field.\nPre-trained Model Based Evaluation\n: Long before the wide recognition of Large Language Models (LLMs), we have seen many examples (including a survey[1]) like BERTScore [2], BLEURT [3], RoBERTa-Eval [4], BARTScore [5] which rely on pre-trained language models like BERT, RoBERTa or BART in evaluating text generation. These methods show better correlation with human judgments than metrics like BLEU or ROUGE on many text generation tasks like text summarization or machine translation, because the pre-trained models are able to capture more semantic information than text-matching methods.\nLLM-based Evaluation\n: With the development of LLMs, this trend continues because powerful LLMs have been deployed to a much wider range of real-world scenarios. The outputs are becoming much longer and more complex, and these tasks usually have no ground truth response as a reference. Therefore, using larger models to evaluate other models has become an effective and almost the only solution for automatic evaluation because of the massive knowledge stored in their parameters, the strong reasoning, and the instruction-following ability. Many works have adopted this paradigm in assessing various models and building standard benchmarks, like AlpacaEval [6] or MTBench [7].\nAlong this research line, we develop Auto-J to ease the heavy reliance on expensive and closed-source LLMs like GPT-4 or ChatGPT in evaluation, and we have shown with many experiments that Auto-J is comparable to them on performance and with a significant advantage on cost, speed, and resource-saving.\nWe hope our detailed explanation contributes to a deeper understanding of the context and addresses any concerns you may have. We also welcome further discussions on this topic.\nReferences:\n[1] A Survey of Evaluation Metrics Used for NLG Systems, in ACM Computing Surveys 2022\n[2] BERTScore: Evaluating Text Generation with BERT, in ICLR 2020\n[3] BLEURT: a Transfer Learning-Based Metric for Natural Language Generation, in ACL 2020\n[4] Designing Precise and Robust Dialogue Response Evaluators, in ACL 2020\n[5] BARTScore: Evaluating Generated Text as Text Generation, in NeurIPS 2021\n[6] AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback, in NeurIPS 2023\n[7] Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena, in NeurIPS 2023"}, {"Heading": "Response to Weakness 2", "Subheading": "Official CommentbyAuthors17 Nov 2023, 05:45Everyone", "Content": "Comment:\nResponse to Weakness 2\n\u201cLLMs should somehow emulate human capabilities and not other LLMs' capabilities.\u201d\nThanks for this valuable comment. We would like to offer additional context to the point you raised regarding training a model to mimic another LLM\u2019s capabilities.\nPrevious works that learn from AI-generated data/feedback\n: Actually, modern LLMs like GPT3.5 or GPT-4 have become so powerful that they can serve as an excellent crowdsourced annotator by providing them with sufficient guidance and demonstrated examples [1, 2]. Such an idea of learning from data generated from the combination of the strong text generation ability of LLMs and carefully designed human prior/supervision (like data filtering, manual seed tasks, provided demonstrations or careful prompt engineering) has been widely adopted in recent works like Alpaca [3], Vicuna [4], WizardLM [5], Zephyr [6] and Prompt2Model [7], and are able to produce models with comparable performance with proprietary models like ChatGPT.\nThere are also works that make models to learn from AI feedback, like Constitutional AI [8] or RLAIF [9]. These works have demonstrated the effectiveness of learning from AI (e.g. a powerful LLM), and are comparable to methods that learn from human feedback with regard to helpfulness and harmlessness.\nOur work is not simply emulating GPT-4\n: Our work builds upon the concepts of the aforementioned studies, harnessing the powerful text generation capabilities of GPT-4 under a series of carefully designed guides (such as defined scenarios and manually crafted evaluation criteria) to obtain more comprehensive and specific generated judgments for model training. This is not merely an imitation of GPT-4\u2019s abilities; instead, GPT-4 is utilized as an auxiliary annotation tool that can significantly reduce human labor. Furthermore, we employ various other processes, such as filtering out samples where GPT-4\u2019s responses conflict with existing human labels and employing a \"divide-and-conquer\" strategy in the generation of single response evaluation data. These techniques ensure that the capabilities of the model we develop are not confined to the simple direct prompting of GPT-4\u2019s upper limits of performance.\nBy all these techniques, we have successfully developed Auto-J and show with extensive experiments that it surpasses all baselines except GPT-4 in pairwise response comparison (Table 1) and even outperforms GPT-4 in critique generation (Figure 3), using fewer than 5,000 training samples, which demonstrates high data efficiency of our method.\nWe hope our elaboration can contribute to a deeper understanding of the context and address your concern. We are also welcome to any further discussions on this topic.\nReferences:\n[1] AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators, Arxiv 2303.16854\n[2] ChatGPT outperforms crowd-workers for text-annotation tasks, Arxiv 2303.15056\n[3] Stanford Alpaca: An instruction-following llama model,\nhttps://github.com/tatsu-lab/stanford_alpaca\n[4] Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality,\nhttps://lmsys.org/blog/2023-03-30-vicuna/\n[5] WizardLM: Empowering large language models to follow complex instructions, Arxiv 2304.12244\n[6] Zephyr: Direct Distillation of LM Alignment, Arxiv 2310.16944\n[7] Prompt2Model: Generating Deployable Models from Natural Language Instructions, Arxiv 2308.12261\n[8] Constitutional AI: Harmlessness from AI Feedback, Arxiv 2212.08073\n[9] RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback, Arxiv 2309.00267"}, {"Heading": "Response to Question 1", "Subheading": "Official CommentbyAuthors17 Nov 2023, 05:46Everyone", "Content": "Comment:\nResponse to Question 1\n\u201cIt is clear that this paper is in a long line of other approaches. Yet, it is not clear why evaluating LLMs with an LLM is principled. Can you comment on this?\u201d\nAs we have stated in the response to Weakness 1, the application of current LLMs is much broader than that of previous task-specific models. They may be deployed in many scenarios where there are no ground truth responses for each task, and the outputs can be challenging for average crowdsourced workers to judge. [1]\nThe optimal and ideal way to evaluate the outputs of LLMs would be to ask in-domain human experts to judge these texts. However, that approach can be expensive and yield inconsistent results.\nOn the other hand, many previous studies have demonstrated the effectiveness of using one LLM to judge another. These works [2,3] have provided sufficient experimental results to empirically show that the judgments of LLMs highly agree with human judgments. There is also work [4] that shows with the help of a trained critique model, humans can find more flaws in the outputs of other models.\nAlso, using powerful LLMs (like GPT-4) to evaluate other LLMs enables the building of a benchmark to automatically show how different LLMs perform on a massive array of real-world user queries.\nSo, in conclusion, evaluating LLMs with an LLM is principled and reasonable, both from the actual need to evaluate LLMs' diverse and unstandardized output in real-world settings and from the vast amount of empirical experimental results shown in previous studies.\nReferences:\n[1] Measuring Progress on Scalable Oversight for Large Language Models, Arxiv 2211.03540\n[2] AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback, in NeurIPS 2023\n[3] Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena, in NeurIPS 2023\n[4] Self-critiquing models for assisting human evaluators, Arxiv 2206.05802"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 19:57Everyone", "Content": "Comment:\nDear Reviewer WSEj,\nWe recognize that the timing of this discussion period may not align perfectly with your schedule, yet we would greatly value the opportunity to continue our dialogue before the deadline approaches.\nCould you let us know if your concerns have been adequately addressed? If not, please feel free to raise them, and we are more than willing to provide further clarification; if you find that your concerns have been resolved, we would appreciate if you could re-consider the review score.\nWe hope that we have resolved all your questions, but please let us know if there is anything more.\nThanks."}]}, {"Heading": "Official Review of Submission9392 by Reviewer PG92", "Subheading": "Official ReviewbyReviewer PG9228 Oct 2023, 19:04 (modified: 23 Nov 2023, 09:56)EveryoneRevisions", "Content": "Summary:\nThe paper fine-tunes a language model to automatically judge the output of another language model, either evaluating a single generation or a pair of generations.\n(Sorry that I do not think I understand the core training and evaluation setup of the paper; either it is my reading comprehension's problem or there might be issues with the presentation.)\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThe paper provides an open-sourced model that can automatically judge a models' generated output; this could potentially enable more researchers to run automatic evaluation at a lower cost with higher reliability.\nWeaknesses:\nThe papers is a large engineering effort (e.g., distilling GPT-4 for the task of evaluation) without much novel ideas (I do not think that a paper needs to be novel to be accepted, but this paper does score low in terms of novelty)\nThe presentation of the method and contribution feels very confusing to me (maybe it's just my fault). See questions below. I do not know whether other reviewers would have similar concerns though.\nQuestions:\nIf I understand correctly, did you define the scenarios and categories both for fine-tune the model to perform evaluation AND test the model to perform evaluation? In that case, if we want to evaluate an LM that performs a new task that is not in the 58 categories you have defined, would Auto-J generalize to categories unseen during training?\nDid you use GPT-4 as the label generator? If so, if one had enough OpenAI credit, the optimal strategy of evaluation according to this paper would still be using GPT-4 or not? (both yes/no are okay answers, but I think it'd be useful to clarify)\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Weakness 1", "Subheading": "Official CommentbyAuthors17 Nov 2023, 05:49Everyone", "Content": "Comment:\nResponse to Weakness 1\n\u201cThe papers is a large engineering effort (e.g., distilling GPT-4 for the task of evaluation) without much novel ideas (I do not think that a paper needs to be novel to be accepted, but this paper does score low in terms of novelty)\u201d\nThank you for your valuable feedback. We would like to use this opportunity to clarify the focus of our work and further detail the novel design in our data collection process.\nThe focus shift in LLM generation evaluation\n: In this paper, we focus on the field of evaluating Large Language Models (LLMs) on how they align with human needs in massive real-world scenarios. This field has garnered increasing concern due to the growing capabilities of LLMs and their wider deployment across various scenarios.\nAs our introduction notes, the field has been pivoting away from a narrow definition of novel design\u2014such as designing specific algorithms, metrics, or model architectures for evaluators\u2014toward a more user-centric evaluation approach. This shift reflects a collective recognition that the true measure of an LLM's utility is not solely captured by its performance under standard academic benchmarks but rather by its effectiveness in diverse, real-world contexts [1, 2, 3].\nOur contribution under the practical necessity\n: In response to the actual needs in this research field, we choose to pay attention more to the scenario definition, criteria design, and data generation under a more user-centric setting rather than developing elaborate new algorithms or model architectures. We show that the developed Auto-J has better evaluation capabilities than many competitive baselines with significantly more parameters (such as ChatGPT, Claude2, and LLaMA-2-70B-Chat). Since Auto-J achieves these results with only 13B parameters, it also lays a solid foundation for the research line of scalable oversight [4]: by combining human efforts with model capabilities, a small model can serve as a good overseer for much stronger models, ensuring effective oversight even if a model's abilities surpass human capabilities.\nNovelty in data collection\n: We want to emphasize that we do not rely solely on simple prompting GPT-4 for constructing the training data like previous works that also train a small judge model [5]. Instead, we employ a synergistic blend of GPT-4's advanced capabilities with meticulously crafted human inputs (such as scenario definitions and criteria design). The data compilation process is heavily reliant on human labor and ingenuity, encompassing finding the sources for user inquiries and potential model responses.\nWe have also handcrafted a large collection of evaluation criteria, which effectively guide GPT-4 to generate more comprehensive and specific judgments than direct prompting without any guidance. We employ data filtering (using existing human labels) in pairwise comparison data collection and execute a \u201cdivide-and-conquer\u201d strategy (combining judgments with and without reference to the criteria) in single response evaluation data collection to get more comprehensive and specific GPT-4 outputs for training.\nGood performance with data efficiency\n: With all the above-mentioned techniques, we have successfully developed Auto-J in a data-efficient manner with less than 5,000 training samples. We show with extensive experiments that Auto-J surpasses all baselines except GPT-4 in pairwise response comparison (Table 1) and even outperforms GPT-4 in critique generation (Figure 3).\nEvaluator under low-resource settings\n: Furthermore, although GPT-4 may perform better when resources (like time and budget) are ample, Auto-J is open-sourced, smaller, and faster. We assert that Auto-J should not be viewed as a \u201cneither here nor there\u201d substitute for GPT-4 but rather as a valuable complement for those with limited resources, large-scale evaluation needs, or no access to GPT-4.\nTo summarize, the development of Auto-J extends well beyond traditional notions of novel design, such as new algorithms, metrics, or architectures. We pay special attention to a more realistic and user-centric perspective on the field of practical LLM evaluation concerning their alignment with human needs, and this is the solid contribution we want to emphasize.\nReferences:\n[1] Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena, in NeurIPS 2023\n[2] LIMA: Less Is More for Alignment, in NeurIPS 2023\n[3] FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets, Arxiv 2307.10928\n[4] Measuring Progress on Scalable Oversight for Large Language Models, Arxiv 2211.03540\n[5] PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization, Arxiv 2306.05087"}, {"Heading": "Response to Weakness 2 and Question 1", "Subheading": "Official CommentbyAuthors17 Nov 2023, 06:05 (modified: 17 Nov 2023, 06:08)EveryoneRevisions", "Content": "Comment:\nResponse to Weakness 2\n\u201cThe presentation of the method and contribution feels very confusing to me (maybe it's just my fault). See questions below. I do not know whether other reviewers would have similar concerns though.\u201d\nWe apologize for making you confused. We have made our responses to your questions below, and we have updated the new experimental results on Auto-J\u2019s generality on the unseen scenarios in our paper (Appendix C). We hope our responses below can answer your questions / address your concerns.\nResponse to Question 1\n\u201cIf I understand correctly, did you define the scenarios and categories both for fine-tune the model to perform evaluation AND test the model to perform evaluation? In that case, if we want to evaluate an LM that performs a new task that is not in the 58 categories you have defined, would Auto-J generalize to categories unseen during training?\u201d\nThanks for this valuable question on Auto-J\u2019s generality on unseen scenarios. Yes, for both training and testing, we adopt data from all the 58 defined scenarios. Actually, in designing these scenarios, we have deliberately defined an \u201cothers\u201d scenario for all possible unseen scenarios in testing.\nWe also admit that the generality of Auto-J needs to be further studied, we thus conduct two extra experiments:\nWe randomly select one scenario from each group as the unseen scenarios, and retrain Auto-J with the remaining scenarios.\nWe take the complete \u201cNLP tasks\u201d group as the unseen scenarios, \nand retrain Auto-J with the remaining scenarios.\nUnder both settings, we compare the new models with the complete version of Auto-J.\nThe results are as follows, we have also updated our paper with these results in Appendix C:\nSetting 1: Select one scenario from each group to form an unseen set, in total 8 unseen scenarios.\nPairwise comparison task (agreement to human preference):\nModel\nseen\nunseen\ncomplete\nAuto-J (paper\u2019s version)\n54.5\n56.8\n54.8\nAuto-J (remove unseen scenarios in training)\n53.5\n55.7\n53.8\nCritique generation task (win rate against ChatGPT judged by GPT4):\nModel\nseen\nunseen\ncomplete\nAuto-J (paper\u2019s version)\n146/200\n25/32\n171/232\nAuto-J (remove unseen scenarios in training)\n143/200\n25/32\n168/232\nSetting 2: Take the complete \u201cNLP tasks\u201d group as the unseen scenarios, in total 11 unseen scenarios.\nPairwise comparison task (agreement to human preference):\nModel\nseen\nunseen\ncomplete\nAuto-J (paper\u2019s version)\n54.2\n57.6\n54.8\nAuto-J (remove unseen scenarios in training)\n54.2\n54.9\n54.3\nCritique generation task (win rate against ChatGPT judged by GPT4):\nModel\nseen\nunseen\ncomplete\nAuto-J (paper\u2019s version)\n136/188\n35/44\n171/232\nAuto-J (remove unseen scenarios in training)\n130/188\n38/44\n168/232\nCompared with the complete version of Auto-J, the two re-trained variants only show slightly degraded performance on the two evaluated tasks both on the seen and unseen scenarios, which indicates that Auto-J can generalize well to scenarios unseen during training."}, {"Heading": "Response to Question 2", "Subheading": "Official CommentbyAuthors17 Nov 2023, 06:08Everyone", "Content": "Comment:\nResponse to Question 2\n\u201cDid you use GPT-4 as the label generator?\u201d\nOur training data consists of two parts: pairwise comparison and single response evaluation.\nIn collecting pairwise comparison data, we do not rely on GPT-4 solely. We utilize existing human preference annotation verdicts (indicating which response is preferred) to filter out those samples where GPT-4 disagrees with humans. So you can regard it like this: the verdict labels are from humans, and GPT-4 only adds the explanations for these labels.\nIn collecting single response evaluation, since we do not have similar human labels as in pairwise comparison data, we generate all data from GPT-4, including the critiques and the overall ratings for responses.\n\u201cIf so, if one had enough OpenAI credit, the optimal strategy of evaluation according to this paper would still be using GPT-4 or not?\u201d\nThe answer to this question is almost yes, but relies on certain conditions. While GPT-4 is indeed powerful, harnessing its full potential for evaluating other models requires a substantial degree of prompt engineering skill, which may be challenging for average users. In contrast, Auto-J offers a 'ready-to-use' solution that doesn't necessitate an in-depth grasp of the models to be evaluated or the specific evaluation scenario, thanks to the pre-encoded information (like evaluation criteria) during its training phase.\nBesides, we also want to emphasize that Auto-J is not designed to completely substitute GPT-4, but to offer an open-source and efficient lightweight alternative for scenarios with limited resources and budget or even do not have access to GPT4:\nAuto-J can process 100 samples per minute on an A100 GPU, which in our practice GPT-4 can only process 4 samples per minute.\nAuto-J has only 13B parameters, which means it can be deployed on 32G V100 GPUs (FP16), and after quantization it can even be used on commodity-level GPUs like Nvidia 4090 or 3090.\nFinally, Auto-J has quite good performance. On pairwise comparison tasks, it only lags behind GPT-4 and surpasses other competitive baselines like ChatGPT or Claude-2 significantly (Table 1). On single response evaluation, it even beats GPT-4 (Figure 3)."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 19:58Everyone", "Content": "Comment:\nDear Reviewer PG92,\nWe recognize that the timing of this discussion period may not align perfectly with your schedule, yet we would greatly value the opportunity to continue our dialogue before the deadline approaches.\nCould you let us know if your concerns have been adequately addressed? If not, please feel free to raise them, and we are more than willing to provide further clarification; if you find that your concerns have been resolved, we would appreciate if you could re-consider the review score.\nWe hope that we have resolved all your questions, but please let us know if there is anything more.\nThanks."}]}]}, "7vVWiCrFnd": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "graph neural networks, expressiveness, approximate inference", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "Discuss and extend GNNs' expressive power for probabilistic inference.", "Abstract": "Designing expressive Graph Neural Networks (GNNs) is an important topic in graph machine learning fields. Despite the existence of numerous approaches proposed to enhance GNNs based on Weisfeiler-Lehman (WL) tests, what GNNs can and cannot learn still lacks a deeper understanding. This paper adopts a fundamentally different approach to examine the expressive power of GNNs from a probabilistic perspective. By establishing connections between GNNs' predictions and the central inference problems of probabilistic graphical models (PGMs), we can analyze previous GNN variants with a novel hierarchical framework and gain new insights into their node-level and link-level behaviors. Additionally, we introduce novel methods that can provably enhance GNNs' ability to capture complex dependencies and make complex predictions. Experiments on both synthetic and real-world datasets demonstrate the effectiveness of our approaches.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "learning on graphs and other geometries & topologies", "Submission Number": "9389", "PDF Url": "https://openreview.net/pdf?id=7vVWiCrFnd"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9389 by Area Chair b61g", "Subheading": "Meta ReviewbyArea Chair b61g05 Dec 2023, 18:35 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper studies the expressivity of the GNN from the perspective of probabilistic graphical methods. Within this framework the authors show how to systematically extend the capabilities of GNNs in modeling complex distributions and inference targets, with a particular focus on phantom nodes and phantom edges, showcasing their empirical improvements in real-world applications of GNNs.\nThe reviewers agree that the new perspective is interesting. Although, some of the reviewers raised concerns about the computational complexity and the lack of scalability of the methodology, which in return limits the experiments to small datasets.\nThe response of the authors during the rebuttal period addressed several comments made by the reviewers.\nGiven the interesting new perspective and compelling results, I recommend it for publication.\nJustification For Why Not Higher Score:\nAlthough the perspective is new, due to the lack of scalability it is only applicable to small graphs. Thus, it is not applicable to a large community.\nJustification For Why Not Lower Score:\nThe paper presents a new perspective, which the reviewers agree that it is novel and interesting."}, {"Heading": "Official Review of Submission9389 by Reviewer ubyE", "Subheading": "Official ReviewbyReviewer ubyE08 Nov 2023, 09:23 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors report a slate of new theoretical results regarding the expressive power of a variety of GNNs w.r.t. MRFs. Utilizing this theoretical basis, they then propose a novel extension of MPNNs utilizing so-called \"phantom nodes/edges\". These proposed algorithms are tested using synthetic and real world data, comparing against state-of-the-art algorithms.\nIn node classification tasks, the phantom node lifting method improved state of the art when applied on GCN, and compared well to recent works when utilized with SAGE and GCNII methodologies. In link prediction, phantom edges proved to improve all compared results using standard datasets and metrics.\nIn summary, recasting GNN's expressibility via MRF, the authors were able to improve the understanding of MPNNs and used this probabilistic viewpoint to introduce a novel methodology that matches or outperforms the current state-of-the-art in standard tests.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThe paper makes two contributions: (1) improving the theoretical understanding of GNNs utilizing a probabilistic viewpoint to classify expressibility with respect to (and beyond) Weisfeiler-Lehman tests and (2) utilizing this probabilistic viewpoint to propose a novel methodology to lift the expressive power of MPNNs.\nRecasting the question of expressiveness from limited WL tests into a probabilistic frame is natural in the setting of ML, and as shown, lucrative.\nWeaknesses:\nWhile the results are compelling - I find the exposition of the novel phantom node/edge methodology lacking. While proofs are given on their approximation power, and one can assume motivation from framed previous works, the paper would be strengthened with the motivation driving the methodology.\nFurther, after the long theoretical exposition, the analysis of the proposed method is brief, and restricted mainly to results. A longer discussion of the modified properties (and potential limitations) of the graph would allow more informed adoption.\nQuestions:\nQuestion: It seems that DropGNN (perhaps applied to a slightly modified graph) is closely related to the proposed PN method. How do the two compare in inference tasks?\nSuggestion: I find the paper would be strengthened by a more direct discussion of the origins of the methodology (i.e., how does this differ/extend from previous works? E.g. node labeling)\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to the Review Comments", "Subheading": "Official CommentbyAuthors22 Nov 2023, 04:30 (modified: 22 Nov 2023, 08:36)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewer for the constructive comments! We have revised the manuscript to address the concerns.\nQuestion 1\nQuestion: It seems that DropGNN (perhaps applied to a slightly modified graph) is closely related to the proposed PN method. How do the two compare in inference tasks?\nDuring each run, DropGNN randomly remove some nodes from the original graph. Although both methods aim to improve the expressiveness, we believe that DropGNN and our method do this in different manners. DropGNN improve the expressiveness by manually adding noise to the input graphs. Two non-isomorphic graphs that used to confuse MPNNs would now likely to behave differently because the structures induced by dropped nodes will now likely to be different. Thus, the motivation behind DropGNN is to obtain slightly perturbed variants of multi-hop neighborhoods of nodes. The phantom nodes instead serve as ensemble for cliques, enabling MPNNs to directly model closely connected nodes as an ensemble. The influence is especially significant when the input graphs are made up of several closely connected clusters. Our method is deterministic, while DropGNN is stochastic. Since even when applied on the same input, DropGNN might produce different results, we cannot ensure that DropGNN can capture (or shares the same distingshing power) with marginals of $k$-order PGMs.\nQuestion 2\nSuggestion: I find the paper would be strengthened by a more direct discussion of the origins of the methodology (i.e., how does this differ/extend from previous works? E.g. node labeling)\nWe have added the discussion in Appendix C.2 (colored in blue). To summarize our method and the partial node labeling can be seen as methods that extend the labeling trick from two different perspective, each with its own advantages and disadvantages.\nWeakness\nWe are sorry that due to the space limits of the initial manuscript, we weren't able to provide more motivation and analysis of the two proposed methods. We have added more discission of our methods including algorithm complexities, etc. in Appendix C (colored in blue)."}]}, {"Heading": "Official Review of Submission9389 by Reviewer rfPW", "Subheading": "Official ReviewbyReviewer rfPW05 Nov 2023, 10:22 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a new approach to evaluate the expressive power of graph neural networks from a probabilistic perspective instead of Weisfeiler-Lehman (WL) tests, which are generally used for evaluating the expressiveness of GNNs. By introducing the central inference problems of probabilistic graphical models (PGMs), the authors analyze GNNs. In addition, the authors design two methods (phantom nodes and phantom edges) for the expressive power.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe paper is well written.\nThe research topic about the expressive power of GNNs is important and interesting.\nThe paper seems novel to me. Different from existing methods on the expressive power of GNNs, which use WL test, this paper analyze the expressive power of GNNs in the perspective of the probabilistic view.\nWeaknesses:\nDo you have any ideas for the graph classification tasks? Generally, the papers about the  expressiveness power of GNNs use graph classification tasks to demonstrate the effectiveness of their methods.\nCould you apply your methods on large-scale graphs?\nQuestions:\nPlease refer to the weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to the Review Comments", "Subheading": "Official CommentbyAuthors22 Nov 2023, 04:31 (modified: 22 Nov 2023, 08:31)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewer for the constructive comments! We have revised the manuscript to address the concerns.\nWeakness 1\nDo you have any ideas for the graph classification tasks? Generally, the papers about the expressiveness power of GNNs use graph classification tasks to demonstrate the effectiveness of their methods.\nThe inference of MRFs naturally results in node and edge marginals, which corresponds to node classification and link prediction tasks. To discuss graph-level expressive power from a probabilistic perspective, we need to first extend the MRFs to model the distribution of the whole graph. This can be done by adding an invented node that's connected to the rest of the nodes in the graph. For example, given a graph $G$, we manually add a node $v_0$ to the graph and connect it to the rest of the nodes. Suppose the graph classification task is modeled by $p(z_{v_0}\n|\nX)$, and GNNs compute the graph representation by aggregating all node representations. Then the results in Section 4.2.1 still holds for connected graphs.\nThe proof is as follows. Recall that the two 1-WL variants with aggregation $c^{t+1}_u=hash(c^t_u,{c^t_v ~ | ~ v\\in N(u)})$ and $c^{t+1}_u=hash(c^t_u,{c^t_v ~ | ~ v\\in N(u)},{c^t_v ~ | ~ v\\notin N(u)})$ share the same expressiveness for connected graphs. Thus by adding a node $v_0$ connecting to all nodes in $G$ does not influence the expressiveness of MPNNs (messages over $v_0$ can be seen as the aggregation of all nodes). Therefore, the representation of $v_0$ shares the same discriminative power with the aggregation of all nodes in $G$. Therefore, we have: a GNN variant can capture $k$-order MRFs in node level $\\Rightarrow$ a GNN variant can capture MPNNs with $k$-order phantom nodes in node level $\\Rightarrow$ a GNN variant can capture MPNNs with $k$-order phantom nodes in graph level by aggregating all nodes $\\Rightarrow$ a GNN variant can capture $k$-order MRFs in graph level when the graph is connected.\nWeakness 2\nCould you apply your methods on large-scale graphs?\nBy restricting the maximum order of cliques to be $k$ a fixed value, our methods can apply on large-scale graphs. We are trying our best to perform additional experiments on real-world datasets and the LDPC dataset, and will update the manuscript once we finished the experiments.\nWe have conducted experiments on DBLP dataset, and the results are as follows.\nGCN\nGCN+PN\nGraphSage\nGraphSage+PN\n76.60\n84.43\n73.81\n83.67\nGAT\nSPN-GAT\nGAT+PN\nGCNII\nSPN-GCNII\nGCNII+PN\n79.16\n84.84\n86.34\n81.79\n83.57\n85.08"}]}, {"Heading": "Official Review of Submission9389 by Reviewer jjG1", "Subheading": "Official ReviewbyReviewer jjG104 Nov 2023, 15:17 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper studies the expressivity of the Graph neural networks from the perspective of probabilistic graphical methods. Although multiple works have previously established connections between GNNs and PGMs, this paper studies it from the perspective of expressive power of the GNNs. After formulating the correspondence between WL power with PGMs, the authors present several results in providing a new perspective of seeing the expressivity of GNNs in its ability to learn the complex higher-order distributions formalized as clique based MRFs.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe GNN\u2019s connection to the PGMs is developed in an interesting and principled way.. Specifically, the formulation overcomes the permutation invariance inherent to the graph neural networks but missing in the PGMs.\nThe results progressively elaborate on the connections between GNN\u2019s expressive power in terms of the learnable capacity of node marginals.\nSome of the results are surprising although many of them are intuitively known. The correspondence between k-wl and clique orders is intuitive and is\nThe paper is well written and the presentation flow is reasonably clear.\nWeaknesses:\nThe first paragraph is problematic. \u201cimplicitly assume that node representations learnt by GNNs are independent conditioned on node features and edges, thereby ignoring the joint dependency among nodes...\u201d does not represent the related works accurately. These works do not ignore dependency among the nodes, which is captured via multiple rounds of message passing similar to loopy belief propagation. I find the first paragraph could be phrased in a different way to make the distinctions accurate.\nThe introduction of phantom nodes and edges is not a novel development and closely resembles the other methods like CIN. However, the problem of inefficiency remains in such methods i.e. the computational complexity of finding maximal cliques which can be used for phantom nodes to guarantee the inferential capacity.\nCertain related works are missing in the paper. Recent works on Factor Graph Neural Networks (FGNN) [1] are highly related works in establishing connections between PGMs and GNNs. A small discussion on the relevance would be pertinent.\nThe experimental section could be more elaborate to study the effectiveness of GNNs in learning higher-order distributions. For example, comparison with Zhen et al. (2023)  on inference of higher-order LDPC codes.\nOverall,\nI find the paper making a good contribution to the understanding of the GNN's expressivity in a new perspective from the lens of Probabilistic graphical models. Although, I haven't carefully checked all the proofs, the results are mostly not surprising.\nReferences:\n[1] Zhen Zhang, Mohammed Haroon Dupty, Fan Wu, Javen Qinfeng Shi, Wee Sun Lee. \"Factor Graph Neural Networks\" Journal of machine Learning research 24(181):1\u221254, 2023\nQuestions:\nPlease address the weaknesses\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to the Review Comments", "Subheading": "Official CommentbyAuthors22 Nov 2023, 04:32Everyone", "Content": "Comment:\nWe thank the reviewer for the constructive comments! We have revised the manuscript to address the concerns.\nWeakness 1\nThe first paragraph is problematic. \u201cimplicitly assume that node representations learnt by GNNs are independent conditioned on node features and edges, thereby ignoring the joint dependency among nodes...\u201d does not represent the related works accurately. These works do not ignore dependency among the nodes, which is captured via multiple rounds of message passing similar to loopy belief propagation. I find the first paragraph could be phrased in a different way to make the distinctions accurate.\nThanks for pointing them out. We have rewrited the sentence to make the presentation more accurate.\nWeakness 2\nThe introduction of phantom nodes and edges is not a novel development and closely resembles the other methods like CIN. However, the problem of inefficiency remains in such methods i.e. the computational complexity of finding maximal cliques which can be used for phantom nodes to guarantee the inferential capacity.\nThe introduction of phantom nodes does share spirits with CIN, that is to capture cliques in the graphs. We agree that finding cliques might be computational complex and this problem of inefficiency remains in our methods. But our method is more efficient than CIN: even if we only preserve the clique complex in CIN, CIN(CWL) needs to pass messages:\nfrom nodes to nodes\nbetween higher-order cliques and lower-order cliques (lower adjacent and higher adjacent)\nbetween cliques of the same order (co-boundary cells)\nbetween cliques and nodes (boundary cells)\nOur method, although share the same spirits, in fact point out the necessary component to capture higher-order dependencies and show that by adding messages between cliques and nodes in the cliques we can already extend MPNNs to capture higher-order PGMs without re-designing the WL scheme.\nWe believe that the phantom edges are not similar to other methods like CIN. We focus on the link prediction scenarios, while CIN focuses on graph classification.\nWeakness 3\nCertain related works are missing in the paper. Recent works on Factor Graph Neural Networks (FGNN) [1] are highly related works in establishing connections between PGMs and GNNs. A small discussion on the relevance would be pertinent.\nWe are sorry that we did not discuss recent works that combine PGMs and GNNs. We have added a paragraph in Appendix A (colored blue) to discuss these related works in the revised manuscript.\nWeakness 4\nThe experimental section could be more elaborate to study the effectiveness of GNNs in learning higher-order distributions. For example, comparison with Zhen et al. (2023) on inference of higher-order LDPC codes.\nWe are trying our best to perform additional experiments on more real-world datasets and the LDPC dataset, and will update the manuscript once we finished the experiments."}]}, {"Heading": "Official Review of Submission9389 by Reviewer G9eq", "Subheading": "Official ReviewbyReviewer G9eq31 Oct 2023, 08:26 (modified: 23 Nov 2023, 06:46)EveryoneRevisions", "Content": "Summary:\nThis paper delves into the expressive power of Graph Neural Networks (GNNs) within the context of approximate inference in graphical models, going beyond the common association of GNNs with graph convolutions and Weisfeiler-Lehman (WL) graph isomorphism tests. The paper challenges the prevailing notion that GNNs necessitate integration with graphical models to enhance their probabilistic inference capacity, asserting that GNNs intrinsically possess robust approximation capabilities for posterior distributions. The research introduces a new expressive power hierarchy using Markov Random Fields (MRFs) with increasingly complex distributions and inference targets, providing insights into various GNN variants, including MPNNs, higher-order GNNs, subgraph GNNs, and labeling tricks in the contexts of node classification and link prediction. Furthermore, the paper presents a systematic framework for extending the capabilities of GNNs in modeling complex distributions and inference targets, with a particular focus on phantom nodes and phantom edges, showcasing their empirical improvements in real-world applications of GNNs.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nTheoretical analysis is solid and reasonable on the inference capacity of various GNNs.\nThe paper identifies that GNNs can do Probabilistic inference on its own, which has novelty than other methods combining GNN with graphical models.\nThe paper proposes methods like phantom nodes and edges based on their inference analysis framework and show experiments of their methods.\nWeaknesses:\nExperiments on large link prediction datasets are lacked.\nWhile the theoretical analysis has included a lot of GNN methods, the experiments don't include them all.\nExperiments on various node classification datasets(including homogeneous and heterogeneous graphs) are lacked.\nImprovements of better GNNs(like GCNII) in node classification is limited.\nExperiments details are lacked, like how to choose hyperparameters.\nQuestions:\nFor link prediction tasks, how is the experiments done? Why don't choose metric of link prediction to be HITS@10 like in the BUDDY paper. Also, why not include other baselines in the BUDDY paper, especially the GNN ones? Also, maybe lack of other experiments on large link prediction datsets\nFor node classification task, why not choose traditional homogeneous datasets and heterogeneous datasets like previous works. How will phantom nodes have impact when meeting graphs with different heterophily? Also, why For GCNII it hardly work better than SPN?\nWhat's the complexity of GNNs with phantom nodes or phantom edges, for node classification and link prediction ,respectively?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to the Review Comments", "Subheading": "Official CommentbyAuthors22 Nov 2023, 04:32 (modified: 22 Nov 2023, 09:00)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewer for the constructive comments! We have revised the manuscript to address the concerns.\nQuestions 1\nFor link prediction tasks, how is the experiments done?\nThe experimental setup follows [1]. For all datasets, at training time\nthe message passing links are equal to the supervision links, while at test and validation time, disjoint sets of links are held out for supervision that are never seen at training time. We randomly generate 70-10-20 percent train-val-test splits.\nWhy don't choose metric of link prediction to be HITS@10 like in the BUDDY paper.\nTo make the experiments more challenging we choose H@10 as our metrics. If we set the metrics to be H@100 we can see that the results are much close:\nCora\nCiteseer\nGCN\n0.853\n0.892\nGCN+PE\n0.883\n0.907\nGCNII\n0.868\n0.911\nGCNII + PE\n0.872\n0.932\nELPH\n0.877\n0.934\nBUDDY\n0.880\n0.929\nAlso, why not include other baselines in the BUDDY paper, especially the GNN ones? Also, maybe lack of other experiments on large link prediction datsets\nWe are sorry we did not test all baselines and did not conduct experiments on other datasets. Since this work mainly focus on theoretically analyse the probabilistic inference capacity of GNNs, our prior target is to ensure the theoretical results in this paper sound and clear. Nevertheless, we will keep trying our best to enhance the experiment sections in this manuscript.\nQuestions 2\nFor node classification task, why not choose traditional homogeneous datasets and heterogeneous datasets like previous works.\nFor node classification task we follow the setting in [2]. The PPI datasets in [2] have 121 distinct labels thus suit node property prediction tasks well, and have been shown to benefit well from PGMs. Therefore, we choose them for node classification tasks.\nHow will phantom nodes have impact when meeting graphs with different heterophily?\nThe phantom nodes play as ensemble for cliques, enabling MPNNs to directly model closely connected nodes as an ensemble. The influence is especially significant when the input graphs are made up of several closely connected clusters.\nAlso, why For GCNII it hardly work better than SPN?\nWe hypothesis three reasoning why our method hardly works better than SPN for GCNII.\nSPN uses a node GNN to model node potentials and an edge GNN to model edge potentials. This framework might better aligns with the natural behavior of molecules.\nWe tried our best but we couldn't reproduce the results of baseline GNNs in [2]. Therefore although our methods can consistently improve the performance of GNNs, for some tasks it might not be better than SPN.\nBetter expressive power might not always lead to better empirical performance[3]. Our framework focuses on theoretically improving the expressiveness of GNNs, rather than designing an empirically effective GNN architecture. We only apply the most simple and intuitive design.\nQuestions 3\nWhat's the complexity of GNNs with phantom nodes or phantom edges, for node classification and link prediction, respectively?\nWe have added discussions of complexity in Appendix C. Please refer to the paragraphs \"Algorithm complexities\" in Appendix C (colored blue) for detailed discussion.\nWeakness\nWe are trying our best to perform additional experiments on real-world datasets and the LDPC dataset, and will update the manuscript once we finished the experiments. We did not include all GNN variants in the analysis because our methods focus on node classification and link prediction methods and aim to improve the expressiveness of MPNNs. Thus we mainly considers comparisons with MPNNs and other methods in the PGM-GNN literature.\nFor hyperparameters, for node classification tasks we select the same hyperparameters in [1],[2] for fair comparision. When applying our phantom nodes / edges methods we keep the hyperparameters (learning rate, hidden dimension, etc.) unchanged. For link prediction tasks the hyperparameters are selected by performing search on validation data. Similarly, once we have chosen the hyperparameters of baseline MPNNs, we use the same hyperparameters for our PE-enhanced methods. We have conducted additional experiments on DBLP datasets in [2]. The results are as follows.\nGCN\nGCN+PN\nGraphSage\nGraphSage+PN\n76.60\n84.43\n73.81\n83.67\nGAT\nSPN-GAT\nGAT+PN\nGCNII\nSPN-GCNII\nGCNII+PN\n79.16\n84.84\n86.34\n81.79\n83.57\n85.08\n[1] Chamberlain et al. Graph Neural Networks for Link Prediction with Subgraph\nSketching. ICLR 2023.\n[2] Qu et al. NEURAL STRUCTURED PREDICTION FOR INDUCTIVE NODE CLASSIFICATION. ICLR 2022.\n[3] Morris et al. Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks. AAAI 2019."}, {"Heading": "Response to the Authors", "Subheading": "Official CommentbyReviewer G9eq23 Nov 2023, 06:45Everyone", "Content": "Comment:\nI appreciate the authors' responses and they address my concerns. I'll raise my score to 6."}, {"Heading": "Thanks for your response", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:50Everyone", "Content": "Comment:\nWe sincerely thank you for your response. We will keep improving the manuscript and conduct more experiments on various real-world datasets. Please let us know if you have further questions."}]}, {"Heading": "Official Review of Submission9389 by Reviewer G6RK", "Subheading": "Official ReviewbyReviewer G6RK24 Oct 2023, 02:58 (modified: 21 Nov 2023, 09:35)EveryoneRevisions", "Content": "Summary:\nThe paper studies the expressiveness of different GNN variants from a probabilistic inference perspective. Specifically, under certain settings of PGMs and different ways to measure their complexity, the paper studies to what extent MPNNs can approximate node and edge marginals which are obtained from local minima of Bethe approximation. The analysis is also extended to other GNN variants. To equip GNNs with the power of estimating more complex node and edge marginals, phantom nodes and edges are proposed respectively, and experiments are conducted on several node and link prediction datasets to evaluate the proposed methods.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nAnalyzing how well GNNs can approximate marginals in PGMs is interesting (though there are limitations as will be discussed), and offers a new perspective for measuring the expressiveness of GNNs.\nThe paper is generally well written with clear background introductions and problem setup. Many details are given in the appendix, which is also appreciated.\nA lot of analysis has been done with discussions on many different GNN variants and inference tasks. Results also seem solid (but I did not carefully check the proof).\nWeaknesses:\nDefining the discriminative power of potential function by WL test appears to be a somewhat contrived setup, whereby the problem still boils down to graph isomorphism. I am not sure how practically relevant this setting is, and whether it is truly \u201cfundamentally different\u201d with works on WL tests. A more comprehensive discussion about the connection may mitigate the issue.\nFollowing the above point, the analysis does not take into account node features, whereas in many PGMs node and clique potentials are functions on node features. This further stresses the point that the setup might deviate from practice.\nThe proposed method seems not scalable as it requires identifying maximum cliques that is exponentially complex, and even relaxing it to cliques with size k has super-quadratic complexity O(n^k) (please correct me if I am wrong). This limitation has not been discussed in the paper, and experiments only include small datasets.\nThe experimental results are relatively weak. E.g. on PPI, best performance in most cases (4 out of 6 columns in the table) is achieved by GCNII+SPN. Improvement on synthetic dataset is also limited, and Planetoid dataset is outdated. Baselines are also limited. Particularly, many GNN variants are considered in the analysis but are not compared in experiments, and I wonder why? Moreover, the proposed methods are essentially based on data augmentation, but competitors in this category are missing.\nTypos: invalid reference in appendix A and E.2; \u201ca successful ? for minimizing\u201d in 3.2; repeated references Bergen et al. and Cai \nat al.\nQuestions:\nIn 3.1, while lemma 1 is straight-forward, I do not fully understand why the authors mention \u201cin graph machine learning fields each instance corresponds to different graphs with possibly different structures\u201d, as the paper does not address the case of graph classification? And what does \u201cinstance\u201d present? (the authors might wanna refer to a graph as an instance, but in the context of paper where node- and edge-level tasks are considered, each node or random variable in the PGM correspond an an instance.)\nWhat is the complexity of the proposed method, and are there any ways to scale it to large graphs?\nIf possible, please also answer to questions in the weakness section.\nI decrease score from 6 to 5 due to my lingering concerns, and there has been no response from the authors to date.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to the Review Comments", "Subheading": "Official CommentbyAuthors22 Nov 2023, 04:34 (modified: 22 Nov 2023, 09:08)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewer for the constructive comments! We have revised the manuscript to address the concerns. We are sorry for the late response.\nQuestion 1\nIn 3.1, while lemma 1 is straight-forward, I do not fully understand why the authors mention \u201cin graph machine learning fields each instance corresponds to different graphs with possibly different structures\u201d, as the paper does not address the case of graph classification? And what does \u201cinstance\u201d present?\nOur description follows the setting in [1] (Section 3), where each instance refers to a graph. The aim of this sentence is to point out the different assumptions in PGMs and graph machine learning. Traditionally, each individual instance in a graphical model shares the same conditional independence structure, that is, if $G_1$ and $G_2$ are two instances, $G_1$ and $G_2$ must share the same structure. However, in graph machine learning fields things are different. For example, the graphs for training and test often have different structures. In this case we say each instance has distinct structure. Therefore, we propose lemma1 to address the difference between traditional PGMs and the assumptions in graph machine learning.\nQuestion 2\nWhat is the complexity of the proposed method, and are there any ways to scale it to large graphs?\nWe have added discussion of the complexity in Appendix C. To summarize, in worst cases where the graphs are dense (suppose $N$ nodes and $O(N^2)$ edges), $k$-order PE takes $O(N^k)$ space and $O(kN^k)$ time ($k$-GNNs take $O(kN^{k+1}) time). For sparse graphs the major complexity comes from finding cliques. It's hard to theoretically estimate the complexity of finding cliques in sparse graphs, but many works (eg. [2]) have shown that there are empirically efficient algorithms for finding k-cliques, e.g. [2] can find  cliques with order less than 10 in graphs with 68K nodes in seconds.\nWeakness 1\nDefining the discriminative power of potential function by WL test appears to be a somewhat contrived setup, whereby the problem still boils down to graph isomorphism. I am not sure how practically relevant this setting is, and whether it is truly \u201cfundamentally different\u201d with works on WL tests. A more comprehensive discussion about the connection may mitigate the issue.\nThe key point of our theory is to discuss whether various GNN models can capture the variational inference of PGMs, including:\nWhether GNNs can simulate local extrema of Bethe approximation.\nWhat distribution can GNNs capture.\nTo answer the problem 2 we propose concept of permutation-invariant PGMs, which is described by a permutation-invariant function $\\mathcal{A}$ introduced in section 3.1. Therefore, it's\nnecessary\nto restrict the expressive power of $\\mathcal{A}$: for example if $\\mathcal{A}$ output different potential functions for all pairs of non-isomorphic graphs, no GNNs can capture it.\nSince it's necessary to restrict the expressive power of $\\mathcal{A}$, we choose two metrics: the order of $\\mathcal{A}$ and the most common k-WL tests for restricting the expressive power. However, the WL tests play different roles in our and previous works. Previous works focus on the relation between GNNs and WL tests, while in our work WL tests in fact only serve as a restriction of the space of the joint distribution. Thus we believe our perspective is fundamentally different with previous works.\nIn fact, many works such as [1] simply assumed PGMs as $p(X,Z)=\\frac{1}{Z}\\prod_{i}\\Phi(x_i,z_i)\\prod_{(i,j)\\in\\mathcal{E}}\\Psi(z_i,z_j)$ where the potential functions are exactly the same for different nodes and edges, thus they are special situations of our assumptions. In other words, if it's valuable to discuss whether GNNs can capture local extrema of the above PGMs, so is our work.\nWeakness 2\nFollowing the above point, the analysis does not take into account node features, whereas in many PGMs node and clique potentials are functions on node features. This further stresses the point that the setup might deviate from practice.\nIn our initial settings we believe regarding node features as observed random variables would provide a clear theoretical framework. Still, our results still hold when node and clique potentials are functions on node features. Recall that in Section 3.1 we introduce the permutation-invariant function $\\mathcal{A}$ that describes PGMs, where $\\mathcal{A}$ is a function on cliques and adjacency matrices $\\mathcal{A}(C,\\mathbf{A})$. If we let $\\mathcal{A}$ further be a function on node features, i.e. $\\mathcal{A}(C,G)$ where $G=(\\mathbf{A},\\mathbf{X})$ and $\\mathbf{X}$ is the node feature matrix, the results still hold because GNN layers are also functions on $G$. Therefore, our results also hold when node and clique potentials are functions on node features."}, {"Heading": "Response to the Review Comments, part 2", "Subheading": "Official CommentbyAuthors22 Nov 2023, 04:35 (modified: 22 Nov 2023, 08:29)EveryoneRevisions", "Content": "Comment:\nWeakness 3\nThe proposed method seems not scalable as it requires identifying maximum cliques that is exponentially complex, and even relaxing it to cliques with size k has super-quadratic complexity O(n^k) (please correct me if I am wrong). This limitation has not been discussed in the paper, and experiments only include small datasets.\nThe maximum clique problem is a NP problem, thus is not scalable for large graphs. We have added discussions in Appendix C. In worst cases (where graphs are dense), relaxing it to k-cliques still has super-quadratic complexity. However, if we consider sparse graphs, there are empirically efficient algorithms for finding k-cliques (e.g. [2]). Although it's hard to theoretically estimate the complexity, the method in [2] can find 10-cliques in graphs with 68K nodes in seconds. Besides, even in worst cases our method is still more efficient than k-GNNs.\nWeakness 4\nThe experimental results are relatively weak. E.g. on PPI, best performance in most cases (4 out of 6 columns in the table) is achieved by GCNII+SPN. Improvement on synthetic dataset is also limited, and Planetoid dataset is outdated. Baselines are also limited. Particularly, many GNN variants are considered in the analysis but are not compared in experiments, and I wonder why? Moreover, the proposed methods are essentially based on data augmentation, but competitors in this category are missing.\nWe hypothesis three reasoning why our method hardly works better than SPN for GCNII.\nSPN uses a node GNN to model node potentials and an edge GNN to model edge potentials. This framework might better aligns with the natural behavior of molecules.\nWe tried our best but we couldn't reproduce the results of baseline GNNs using the hyperparameters in [2]. Therefore although our methods can consistently improve the performance of GNNs, for some tasks it might not be better than SPN.\nBetter expressive power might not always lead to better empirical performance (e.g., [3]). Our framework focuses on theoretically improving the expressiveness of GNNs, rather than designing an empirically effective GNN architecture. We only apply the most simple and intuitive design.\nWe did not include all GNN variants in the analysis because our methods focus on node classification and link prediction methods and aim to improve the expressiveness of MPNNs. Thus we mainly considers comparisons with MPNNs and other methods in the PGM-GNN literature. We are trying our best to perform additional experiments on real-world datasets and the LDPC dataset, and will update the manuscript once we finished the experiments. We are trying our best to to perform additional experiments on real-world datasets. We have performed experiments on the DBLP datasets in [4] as follows. As we can see, GAT+PN achieves the best results, while GCNII+PN achieves better results than SPN-GCNII.\nGCN\nGCN+PN\nGraphSage\nGraphSage+PN\n76.60\n84.43\n73.81\n83.67\nGAT\nSPN-GAT\nGAT+PN\nGCNII\nSPN-GCNII\nGCNII+PN\n79.16\n84.84\n86.34\n81.79\n83.57\n85.08\n[1] Dai et al. Discriminative Embeddings of Latent Variable Models for Structured Data. ICML 2016.\n[2] Lukas Gianinazzi et al. Parallel Algorithms for Finding Large Cliques in Sparse Graphs. In Proceedings of the 33rd ACM Symposium on Parallelism in Algorithms and Architectures.\n[3] Morris et al. Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks. AAAI 2019.\n[4] Qu et al. NEURAL STRUCTURED PREDICTION FOR INDUCTIVE NODE CLASSIFICATION. ICLR 2022."}, {"Heading": "Additional comments about the discriminative power of potential function", "Subheading": "Official CommentbyAuthors22 Nov 2023, 23:55 (modified: 22 Nov 2023, 23:55)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewer for the constructive comments! Here's our additional comments about why we restrict the discriminative power of potential function.\nFirst, we argue that it is\nnecessary\nto restrict the discriminative power of potential function. The reason is that, given some GNN model $\\mathcal{G}$, if the discriminative power of potential function is higher than $\\mathcal{G}$, then clearly $\\mathcal{G}$ cannot capture such potential function (we can simply let $\\mathcal{A}$ to output different values only for graphs that are undistinguished by $\\mathcal{G}$ but are distinguished by the potential functions). Therefore, it is necessary to restrict the discriminative power of potential function.\nSecond, the reason why we chose the k-WL hierarchy is that it is the most common metric in GNN literature. However, this is not necessary. In fact, if you check the proof for the expressiveness of the GNN variants in the paper, the discriminative power of potential function is restricted only because we want the GNN variants to be able to distinguish\nnodes that share different potential functions\n. In other words, for the results (Proposition 9-Proposition 17), the discriminative power of potential function are not necessary restricted by k-WL. We can safely rewrite Proposition 9-Proposition 17 in the following manner:\n(Original) Some GNN model $\\mathcal{G}$ can $k$-$l$ approximate $p$\n(Equivalent to) Some GNN model $\\mathcal{G}$ can approximate $p$ given by $l$-order MRFs, whose discriminative power of potential function is limited by k-WL\n(Rewrited version) Some GNN model $\\mathcal{G}$ can approximate $p$ given by $l$-order MRFs, whose discriminative power of potential function is limited by $\\mathcal{G}$\nThe proof steps still holds for the rewrited version, so we can discard the limitations of $k$-WL in this manner. As shown in the proofs ( and the above rewrite), the key problem is not the discriminative power of potential function, but whether and how can GNNs simulate the local extrema of Bethe approximation and approximate node, edge and clique marginals.\nTo summarize,\nIt is necessary to restrict the expressiveness of potential functions because triditional MRFs are not permutation invariant.\nWe can choose different metrics for the expressiveness, which are not limited to the k-WL hierarchy."}]}]}, "U2To7z3JOw": {"paper_info": {"Keywords": "Graph Contrastive Learning, Similarity Search, Binary Coding, Efficiency", "TL;DR": "A new graph contrastive learning approach to enhance network node similarity search with binary node embeddings.", "Abstract": "Recent research shows the promising potential of node continuous embedding methods in Top-K network node similarity search, which often involves finding nearest neighbors measured by similarity in a continuous embedding space.However, these methods poorly scale to searching on large networks, since their embeddings demand significant storage and entail tremendous computation costs.In this paper, we introduce a graph contrastive learning framework for compressing continuous node embeddings into binary codes that enable customized bits per dimension, striking a balance between retrieval accuracy, speed, and storage.Specifically, a recurrent binarization with GNNs is presented, which consists of two components, a GNN encoder for learning node continuous representations, and a residual multilayer perception module for encoding representations to binary codes.The whole architecture is trained end-to-end by jointly optimizing three losses, i.e., contrastive loss from giving closely aligned representations to  positives, information bottleneck loss from superfluous information minimization, and representation distillation loss from aligning binary codes and their continuous counterparts.Extensive experiments demonstrates that our method achieves approximately 6x-19x faster retrieval and 16x-32x space reduction compared to traditional continuous-based embedding methods.Moreover, it significantly outperforms state-of-the-art continuous- and hash-based network embedding methods on several real-world networks.", "Primary Area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9386", "PDF Url": "https://openreview.net/pdf?id=U2To7z3JOw"}, "review_info": []}, "lNIj5FdXsC": {"paper_info": {"Primary Area": "learning on graphs and other geometries & topologies", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Recurrent Neural Networks, Graph Neural Networks", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Graph neural networks based on iterative one-hop message-passing have been shown to struggle in harnessing information from distant nodes effectively. Conversely, graph transformers allow each node to attend to all other nodes directly, but suffer from high computational complexity and have to rely on ad-hoc positional encodings to bake in the graph inductive bias. In this paper, we propose a new architecture to reconcile these challenges. Our approach stems from the recent breakthroughs in long-range modeling provided by deep state-space models on sequential data: for a given target node, our model aggregates nodes at different distances and uses a parallelizable linear recurrent network over the chain of distances to provide a natural encoding of its neighborhood structure. With no need for positional encoding, we empirically show that the performance of our model is competitive compared with that of state-of-the-art graph transformers on various benchmarks, at a drastically reduced computational complexity. In addition, we show that our model is theoretically more expressive than one-hop message-passing neural networks.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9385", "PDF Url": "https://openreview.net/pdf?id=lNIj5FdXsC"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9385 by Area Chair 3SvH", "Subheading": "Meta ReviewbyArea Chair 3SvH10 Dec 2023, 00:55 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis work introduces a graph learning method, GRED, which aggregates nodes at different shortest path distances and uses a linear recurrent network to combine them. The reviewers have reached a weak consensus for acceptance. However, a rejection is still recommended due to its limited novelty. The authors have addressed its connection with some previous work in their response to Q1 of Reviewer 8Mos. However, one important work, kP-GNN [Feng et al., 2022], has been overlooked by the authors in both the response and the related work section in the paper. As stated in Section 4.2 of the paper, GRED in this work is a specific implementation of K-hop message passing in [Feng et al., 2022]. The only novelty of GRED is the usage of a linear RNN, which is equivalent to using a linear layer with shared parameters as the UPD function in Definition 1. Compared with the original implementation (MLP as the UPD), GRED does not bring extra expressivity or theoretical time/space complexity reduction. Furthermore, the motivation for using a linear RNN is scalability. However, a scalability comparison between [Feng et al., 2022] and GRED is not available at this time. The theoretical analysis also seems to be largel built upon [Feng et al., 2022].\nJustification For Why Not Higher Score:\nOne important previous work [Feng et al., 2022] (cited in the paper) seems to be systematically downplayed. Despite much of the paper's methodology and theory are built upon [Feng et al., 2022], the paper unfortunately does not even discuss it in the related work.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "General Response from Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 09:14 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewers for their interesting questions and constructive feedback.\nWe incorporated in the paper revision all of the additional experiments and ablations requested by the reviewers\n. We summarize our additional experimental results in the thread below. We are very happy with these new results that further strengthen our paper. If the reviewers also believe we addressed all of their concerns and curiosities, we kindly ask them to revise their scores.", "Replies": [{"Heading": "Additional Experimental Results", "Subheading": "Official CommentbyAuthors21 Nov 2023, 09:29 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nIn this thread, we present additional experimental results requested by the reviewers. In part I, we show how different $K$ values (number of hops in the recurrence) affect the performance of our model. In part II, we replace the LRU component with a vanilla RNN and show the difference in performance (confirming the effectiveness of our LRU choice). In part III, we evaluate our model on two additional datasets from TUDataset. Our model generalizes well to TUDataset and outperforms another related approach SPN [1]. All the above results have been added to Appendix D of the updated PDF.\nMoreover, with further hyper-parameter tuning, we have improved the performance of our model on CIFAR10 and Peptides-func: for CIFAR10 we increase the model depth with a smaller hidden dimension, and for Peptides-func we increase $K$ to 40. The hyper-parameters for our model are summarized in Appendix C.\nEspecially, when $K=40$ the performance of GRED on Peptides-func (0.7041\u00b10.0049) is better than the best graph transformer GRIT (0.6988\u00b10.0082), and GRED still maintains higher efficiency than GRIT (158.9s/epoch vs 225.6s/epoch)\n. This new result is impressive given that GRED doesn\u2019t use any positional encoding and further validates that the architecture of GRED alone can encode the structural information.\nPart I: Effect of $K$ on performance\nEffect of $K$ on the performance on CIFAR10:\n$K$\n1\n4\n7\n$K_{\\text{max}}$=10\nTest Acc (%)\n72.540$\\pm$0.336\n75.370$\\pm$0.621\n74.490$\\pm$0.335\n74.210$\\pm$0.274\nEffect of $K$ on the performance on ZINC:\n$K$\n1\n2\n4\n8\n$K_{\\text{max}}$=22\nTest MAE $\\downarrow$\n0.231$\\pm$0.002\n0.161$\\pm$0.003\n0.089$\\pm$0.004\n0.108$\\pm$0.004\n0.131$\\pm$0.008\nEffect of $K$ on the performance on Peptides-func:\n$K$\n5\n10\n20\n40\n60\nTest AP $\\uparrow$\n0.6657$\\pm$0.0069\n0.6883$\\pm$0.0076\n0.6960$\\pm$0.0060\n0.7041$\\pm$0.0049\n0.7031$\\pm$0.0017\nWe use $K_{\\text{max}}$ to denote the maximum diameter of all graphs in the dataset. For Peptides-func, the maximum $K$ we tried was slightly smaller than $K_{\\text{max}}$ in order to fit the model into a single RTX A5000 GPU with 24GB memory. From the three tables, we can observe that larger $K$ values generally yield better performance. On CIFAR10 and ZINC, while directly using $K_{\\text{max}}$ already outperforms MPNNs, the optimal value of $K$ yielding best performance lies strictly between $1$ and $K_{\\text{max}}$. We think this is because information that is too far away is less important for these two tasks: indeed, interestingly, the best $K$ value for CIFAR10 is similar to the width of a convolutional kernel on a normal image. On Peptides-func, the change of performance is more monotonic in $K$. When $K=40$, GRED outperforms the best graph transformer GRIT. We observe no further performance gain when we increase $K$ to 60."}, {"Heading": "Additional Experimental Results (Continued)", "Subheading": "Official CommentbyAuthors21 Nov 2023, 09:55 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nPart II: Vanilla RNN vs LRU\nPerformance of GRED using vanilla RNN or LRU:\n~\nCIFAR10 $\\uparrow$\nZINC $\\downarrow$\nPeptides-func $\\uparrow$\nBest MPNN\n67.312$\\pm$0.311\n0.188$\\pm$0.004\n0.6069$\\pm$0.0035\nGRED$_{\\text{RNN}}$\n69.215$\\pm$0.080\n0.160$\\pm$0.005\n0.4945$\\pm$0.0024\nGRED$_{\\text{LRU}}$\n75.370$\\pm$0.621\n0.089$\\pm$0.004\n0.7041$\\pm$0.0049\nWe replace the LRU component of GRED with a vanilla RNN:\n\\begin{equation}\n    \\mathbf{s}_{v, k}^{(l)} = \\text{tanh} ( \\mathbf{W}_{\\text{rec}} \\mathbf{s}_{v, k - 1}^{(l)} + \\mathbf{W}_{\\text{in}}\\mathbf{x}_{v, K - k}^{(l)})\n\\end{equation}\nwhere $\\mathbf{W}_{\\text{rec}} \\in \\mathbb{R}^{d_s \\times d_s}$ and $\\mathbf{W}_{\\text{in}} \\in \\mathbb{R}^{d_s \\times d}$ are two trainable real weight matrices. We use the same number of layers and the same $K$ for both models. We can observe that the performance of GRED with a vanilla RNN drops significantly. On CIFAR10 and ZINC where $K$ is not large, GRED$_{\\text{RNN}}$ still outperforms the best MPNN. However, on the long-range dataset Peptides-func where we use $8$ layers and $K=40$ per layer, the vanilla RNN becomes difficult to train, and the performance of GRED$_{\\text{RNN}}$ is even worse than the best MPNN.\nPart III: Performance on TUDataset\nWe further evaluate GRED on NCI1 and PROTEINS from TUDataset.\nWe follow the experimental setup of [1], and report the average accuracy and standard deviation of $10$ splits:\nModel\nNCI1\nPROTEINS\nDGCNN\n76.4$\\pm$1.7\n72.9$\\pm$3.5\nDiffPool\n76.9$\\pm$1.9\n73.7$\\pm$3.5\nECC\n76.2$\\pm$1.4\n72.3$\\pm$3.4\nGIN\n80.0$\\pm$1.4\n73.3$\\pm$4.0\nGraphSAGE\n76.0$\\pm$1.8\n73.0$\\pm$4.5\nSPN [1] ($K=10$)\n78.2$\\pm$1.2\n74.5$\\pm$3.2\nGRED ($K=10$)\n82.6$\\pm$1.4\n75.0$\\pm$2.9\nThe baseline performance is directly copied from [1]. Our model (GRED) shows very good performance. In particular, GRED outperforms SPN [1] with the same number of hops, which validates that GRED is a more effective architecture than SPN for utilizing information beyond the local neighborhood.\n[1] Shortest Path Networks for Graph Property Prediction. Learning on Graphs Conference. 2022"}]}, {"Heading": "Official Review of Submission9385 by Reviewer e7jX", "Subheading": "Official ReviewbyReviewer e7jX01 Nov 2023, 01:02 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work introduces a novel graph learning method that pools long-range information by aggregating nodes at different distances and using a linear recurrent network, leading to a computational efficient method that is competitive with state-of-the-art approaches for graph learning.\nSoundness:\n4 excellent\nPresentation:\n3 good\nContribution:\n4 excellent\nStrengths:\nThe evaluation is very thorough and the results validate and support the effectiveness of the proposed method. The computational effectiveness of the proposed model compared to equivalent transformer models (Table 4) is very good.\nThe proposed method is benchmarked against a wide range of methods and on multiple benchmarks.\nTransformer models are good at modeling long-range interactions in graphs, and have been outperforming MPNN models, they however struggle with scaling and require custom encoding of the node positional embedding. The proposed approach is simple and intuitive and provides an alternative path towards solving long-range graph problems.\nWeaknesses:\nA sensitivity analysis of GRED with respect to the choice of K is missing.\nThe training efficiency analysis is conducted against a transformer model only, but it would be useful to understand how this method compares to MPNNs. In particular, each node will have its own sequence of sets of nodes at distance k, so there might not be any shared computation that can be leveraged like in iterative 1-hop message passing methods.\nQuestions:\nHow would this method perform on non long-range benchmarks? Would it underperform compared to MPNNs who might only need a local receptive field to solve a task?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer e7jX", "Subheading": "Official CommentbyAuthors21 Nov 2023, 10:09 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nWe thank reviewer e7jX for taking the time to review our work, and we are pleased she/he found our evaluation to be very thorough and our results to validate the effectiveness of our model. We address the raised concerns as follows:\nQ1. A sensitivity analysis of GRED with respect to the choice of K is missing\n.\nAns\n: This is now in Appendix D of the updated PDF. Please refer to Part I of our \u201cAdditional Experimental Results\u201d thread in our general response for a thorough analysis.\nQ2. The training efficiency analysis is conducted against a transformer model only, \u2026, each node will have its own sequence of sets of nodes at distance k, so there might not be any shared computation that can be leveraged\u2026\nAns\n: It\u2019s true that each node has its own sequence of set representations, but the computations for all nodes in the graph can be done in batches. In the implementation, we use a matrix mask to indicate each node\u2019s $k$-hop neighbors (just like the adjacency matrix indicates each node\u2019s 1-hop neighbors). These masks are computed only once in preprocessing using the shortest path algorithm, and they are used to do aggregation at each hop. Then the input to LRU would be a batch of sequences of length K+1 (including the target node for each sequence).\nWe have added a code snippet of GRED in Appendix B of the updated PDF, to show how the computation is done\n.\nTo compare the training efficiency of GRED with MPNN, we use the same number of layers but the MPNN counterpart only aggregates 1-hop neighbors at each layer. We measure the average training time per epoch:\nModel\nZINC\nCIFAR10\nPeptides-func\nGRED\n4.1s\n27.8s\n158.9s\nMPNN\n2.8s\n21.7s\n91.6s\nWe can observe that on ZINC and CIFAR10, the additional time required to use a larger neighborhood is marginal. On Peptides-func, the difference is greater since GRED uses $K=40$. However, this extra time, which is still less than the time required by GRIT, is acceptable considering the significant performance improvement\nQ3. How would this method perform on non long-range benchmarks? Would it underperform compared to MPNNs who might only need a local receptive field to solve a task?\nAns\n: The datasets in Table 1 and Table 2 (ZINC) are from [4], which is a widely used benchmark. These datasets are not particularly long-range. PATTERN and CLUSTER model communities in social networks and all nodes can be reached within 3 hops. MNIST and CIFAR10 are nearest-neighbor graphs of pixels, and just like their normal versions local information is important. Our model performs well on these datasets. We further evaluate our model on two additional datasets from TUDataset (please refer to Part III of our \u201cAdditional Experimental Results\u201d thread) and our model also achieves good performance.\nOur model can adapt to both long-range and non-long-range tasks by learning proper eigenvalues of the LRU transition matrix that control how fast the filters decay as the distance increases. For a long-range task, the learned eigenvalues are close to 1 which better keeps distant information, while for a non-long-range task, the magnitudes of the learned eigenvalues are smaller (please refer to Figure 3 for an illustration of the eigenvalues after training). Additionally, the choice of $K$ gives our model some flexibility to adjust the receptive field, and we found the optimal $K$ for a non-long-range task lies between 1 and the diameter (Part I of \u201cAdditional Experimental Results\u201d)\n[4] Benchmarking Graph Neural Networks. JMLR. 2022\nWe kindly ask the reviewer to consider raising her/his score if she/he thinks our response can address the concerns. We would be happy to answer further questions!"}, {"Heading": "Kind Reminder", "Subheading": "Official CommentbyAuthors22 Nov 2023, 21:44 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nDear Reviewer e7jX,\nThank you once again for your time spent reviewing our paper! In our response, we have managed to address all the raised concerns. The discussion period is ending soon, and we would really appreciate it if you could provide feedback. We are happy to answer any further questions!\nBest regards,\nThe authors"}]}, {"Heading": "Official Review of Submission9385 by Reviewer bs5m", "Subheading": "Official ReviewbyReviewer bs5m31 Oct 2023, 23:09 (modified: 23 Nov 2023, 03:29)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a model architecture, GRED, for graph tasks by adopting a recurrent neural network (RNN) to propagate hidden states through multiple layers. It claims that the new architecture is more effective, utilizing the information of large neighborhoods with high efficiency, and theoretically proving the expressiveness. It also empirically shows that the performance of GRED is better than state-of-the-art graph transformers.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe paper proposes a way to utilize RNN to adopt hidden states through multiple layers. It claims that the new method helps improve long-range information processing.\nThe paper compares the proposed method on multiple benchmarks, and demonstrates its effectiveness against traditional GNN models.\nThe description of the proposed method is well-written and easy to understand, though figure 1(a) is a bit unclear about what the \"skip\" stands for.\nWeaknesses:\nFor the training efficiency evaluation, it would be nice to include the memory consumption for different methods. Also, the performance gap on the task between GRIT and GRED is still significant, which makes the comparison a bit unfair. It would be better to compare with the architecture that has similar task performance.\nThe method introduces a new hyperparameter K to be tuned. It would be nice to show how K is selected, and how the different selections of K can affect the task performance.\nAlthough the technique helps increase the range of nodes the model can process, unlike the graph transformer-based method, the distance is still limited by the selection of K and the number of layers of the model. It would be good to show some insights into how that super long-distance information affects the model performance.\nQuestions:\nThe following papers seem related as well:\nGraph Transformers: Representing Long-Range Context for Graph Neural Networks with Global Attention, NeurIPS 2021\nIssues with attention for long-range reasoning: Lite Transformer with Long-Short Range Attention, ICLR 2020\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer bs5m", "Subheading": "Official CommentbyAuthors21 Nov 2023, 10:23 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nWe thank reviewer bs5m for taking the time to review our work and are pleased she/he found our work to be well-written and easy to understand.  First, we would like to ask the reviewer to take a look at our post \u201cAdditional Experimental Results\u201d for updated results and the sensitivity analysis with respect to the value of $K$. We address the raised concerns as follows:\nQ1. What is the \"skip\" in Figure 1(a)?\nAns\n: The \u201cskip\u201d in Figure 1(a) denotes an identity branch. We have added a code snippet of GRED to Appendix B of the updated PDF, to show how the computation is done exactly.\nQ2. For the training efficiency evaluation, it would be nice to include the memory consumption for different methods. Also, the performance gap on the task between GRIT and GRED is still significant, which makes the comparison a bit unfair. It would be better to compare with the architecture that has similar task performance.\nAns\n: We have added the GPU memory consumption to Table 4 of the updated PDF. We also post it here:\nModel\nZINC 12K\nCIFAR10\nPeptides-func\nGRIT\n25.6s / 1.9GB\n244.4s / 4.6GB\n225.6s / 22.5GB\nGRED (Ours)\n4.1s / 1.4GB\n27.8s / 1.4GB\n158.9s / 18.5GB\nSpeedup\n6.2$\\times$\n8.8$\\times$\n1.4$\\times$\nThe gap between the performance of GRIT and the updated performance of GRED is much less significant now. Especially on Peptides-func with $K=40$ GRED can outperform GRIT. GRED still maintains higher training efficiency than GRIT.\nQ3. The method introduces a new hyperparameter K to be tuned. It would be nice to show how K is selected, and how the different selections of K can affect the task performance.\nAns\n: We have conducted experiments on how different $K$ values affect the performance of GRED. Please refer to Part I of our \u201cAdditional Experimental Results\u201d thread in our general response for a thorough analysis.\nQ4. Although the technique helps increase the range of nodes the model can process, unlike the graph transformer-based method, the distance is still limited by the selection of K and the number of layers of the model. It would be good to show some insights into how that super long-distance information affects the model performance.\nAns\n: It\u2019s true that the range of nodes each layer can access is bounded by the value of $K$. However, for real-world datasets, the graph diameter won\u2019t increase linearly with the number of nodes. Therefore, even if the value of $K$ doesn\u2019t seem \u201csuper long\u201d, each layer of our model can access all nodes in the graph.\nFor all datasets we used in experiments, except for Peptides-func and Peptides-struct, our model fits into a single 24GB GPU even when $K$ is set to $K_{\\text{max}}$ (i.e., the maximum diameter of all graphs in the dataset). For Peptides-func and Peptides-struct, we use a $K$ value which is smaller than $K_{\\text{max}}$ in order to increase the depth of the model. In this sense, the choice of $K$ allows the model some flexibility when the hardware resource is constrained. In all cases, we ensure that model depth * $K$ is strictly larger than $K_{\\text{max}}$, so the receptive field of the entire GRED model is the same as graph transformers and GRED is able to extract global information.\nQ5. Two related papers\nAns\n: We have added these two references to the related work (marked in red) of the updated PDF.\nWe kindly ask the reviewer to consider raising her/his score if she/he thinks our response can address the concerns. We would be happy to answer further questions!"}, {"Heading": "Kind Reminder", "Subheading": "Official CommentbyAuthors22 Nov 2023, 21:45 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nDear Reviewer bs5m,\nThank you once again for your time spent reviewing our paper! In our response, we have managed to address all the raised concerns. The discussion period is ending soon, and we would really appreciate it if you could provide feedback. We are happy to answer any further questions!\nBest regards,\nThe authors"}, {"Heading": "RE: Response to Reviewer bs5m", "Subheading": "Official CommentbyReviewer bs5m23 Nov 2023, 03:31 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nThanks for the reply! The response from the authors solved most of my concerns. I increased the score to 6."}]}, {"Heading": "Official Review of Submission9385 by Reviewer 8Mos", "Subheading": "Official ReviewbyReviewer 8Mos30 Oct 2023, 08:29 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper presents a new graph learning architecture called Graph Recurrent Encoding by Distance (GRED). GRED aims to address the challenges faced by existing approaches, such as message-passing neural networks (MPNNs) and graph transformers, by efficiently encoding information from distant nodes while avoiding the need for ad-hoc positional encodings. The paper provides a detailed explanation of the GRED architecture and supports its claims with theoretical analysis and empirical results.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nTheoretical Analysis: The paper provides a theoretical analysis of the expressiveness of GRED, demonstrating its superiority over one-hop MPNNs. This analysis adds depth to the understanding of the method's capabilities. Furthermore, the authors provide an interesting analysis regarding the RNN filtering of the k-hop neighbor features.\nThe presentation and clarity of the paper are very good. The authors provide comprehensive explanations of the key components of GRED, which is crucial for readers trying to understand the architecture at a deeper level. The theoretical analysis is rigorous, and the empirical results are presented in a well-organized manner, contributing to a comprehensive understanding of GRED's performance.\nWeaknesses:\nFirstly, the novelty of the proposed architecture is somewhat limited, as there are already several similar approaches in the field that operate on K-hop neighborhoods in a similar manner. While the combination of permutation-invariant neural networks and linear recurrent networks is a sensible choice, it may not present a significant departure from existing methods. Specifically, the proposed method is very similar to [1], which proposed the following update rule: $h_u^{(t+1)} =COM(h_u^t, AGG_{u,1},..., AGG_{u,k} )$. The main difference is that the proposed approach uses an RNN for the $COM$ function. Moreover, there is no proper discussion of other k-hop approaches such as [2].\nSecondly, the experiments in the paper are conducted on a relatively limited set of datasets, focusing on long-rage benchmarks, and the absence of experiments on benchmark datasets like TUDatasets raises concerns about the generalizability of the proposed model. Expanding the experimental evaluation to a wider range of datasets would strengthen the paper's claims.\nA notable weak point of the paper is the unavailability of the source code for the proposed model. This omission hinders the reproducibility and transparency of the research. Releasing the source code is not only a common practice in the research community but is also crucial for enabling other researchers to validate and build upon the work presented in the paper.\nReferences:\n[1] Abboud, Ralph, Radoslav Dimitrov, and Ismail Ilkan Ceylan. \"Shortest path networks for graph property prediction.\" Learning on Graphs Conference. PMLR, 2022.\n[2] Nikolentzos, Giannis, George Dasoulas, and Michalis Vazirgiannis. \"k-hop graph neural networks.\" Neural Networks 130 (2020): 195-205.\nQuestions:\nCould the authors provide a more in-depth comparative analysis of their approach against existing methods that operate on k-hop neighborhoods? Highlighting specific strengths or weaknesses in comparison to these related approaches would help better position the novelty of this work.\nConsidering that experiments are conducted on a limited set of datasets, could the authors discuss the generalizability of their proposed architecture to a wider range of datasets, including TUDatasets?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 8Mos", "Subheading": "Official CommentbyAuthors21 Nov 2023, 10:37 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nWe thank reviewer 8Mos for taking the time to review our work and are pleased she/he found: 1) our presentation to be very good | clear; 2) our theory to be interesting | rigorous; and 3) our empirical results to be well-organized and contributing to a comprehensive understanding of GRED's performance.\nWe admit that we missed several references on K-hop GNNs, and we agree that a more detailed discussion of these methods would help improve the understanding of our contributions. We address these concerns as follows:\nQ1. The novelty of the proposed architecture is somewhat limited | Lack of a comparative analysis of existing K-hop GNNs\n.\nAns\n: Compared with existing K-hop GNNs, the novelty of our proposed architecture is a new way to encode the K-hop neighborhood, i.e., with LRU.\nThe use of LRU ensures our model theoretically sound expressiveness as well as ability to address the over-squashing problem in long-range reasoning tasks\n. To see why the novelty of our model is significant, we provide a comparative analysis of existing K-hop GNNs here:\nAmong K-hop GNNs, MixHop [3] uses powers of the adjacency matrix to access k-hop nodes. k-hop GNN [2] iteratively applies MLPs to combine two consecutive hops and propagates information towards the target node.\nWhile they have shown that higher hop information can improve the expressiveness of MPNNs, they suffer from over-squashing\n, i.e., they cannot effectively utilize information from distant nodes because the signals of distant nodes would decay rapidly due to iterative neighborhood mixing. As a result, the largest neighborhood these approaches operate on is 3-hop. The drawback of these approaches is also pointed out by the SPN paper [1]. The SPN paper [1] proposes a conceptual update formula which is similar to ours:\n$$\nh_u^{(t+1)} = \\text{COM} ( h_u^{(t)}, \\text{AGG}_{u, 1}, \u2026, \\text{AGG}_{u, K})\n$$\nHowever, SPN simply uses weighted summation as COM to aggregate K hops. The weighted summation cannot guarantee the expressiveness of the model since it cannot uniquely represent sequences. On the contrary, the LRU component of GRED can achieve expressiveness and long-range modeling capacity simultaneously\n: LRU can express an injective mapping of sequences, and at the same time prevent distant information from decaying by learning proper eigenvalues of the transition matrix.\nWe have updated the related work to include a comparison of K-hop GNNs (marked in red in the updated PDF)\nTo validate that GRED can encode the K-hop neighborhood more effectively than SPN,\nWe evaluate GRED on two additional datasets from TUDataset and compare against SPN.\nAs shown in Part III of \u201cAdditional Experimental Results\u201d, GRED can outperform SPN with the same number of hops.\n[1] Shortest Path Networks for Graph Property Prediction. Learning on Graphs Conference. 2022\n[2] k-hop graph neural networks. Neural Networks. 2020\n[3] MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing. ICML. 2019"}, {"Heading": "Response to Reviewer 8Mos (Continued)", "Subheading": "Official CommentbyAuthors21 Nov 2023, 10:46 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nQ2. Considering that experiments are conducted on a limited set of datasets, could the authors discuss the generalizability of their proposed architecture to a wider range of datasets, including TUDatasets?\nAns\n: We evaluated our model on 7 datasets in total. They come from different domains (images, social networks, biology), cover both long-range and non-long-range tasks, and are also widely used by graph transformer baselines we compare against.\nBoth Reviewer e7jX and Reviewer bs5m agree that our experiments are extensive\n. To quote Reviewer e7jX: \u2018the evaluation is very thorough\u2019 and \u2018the proposed method is benchmarked against a wide range of methods and on multiple benchmarks\u2019, and to quote Reviewer bs5m: \u201cThe paper compares the proposed method on multiple benchmarks, and demonstrates its effectiveness against traditional GNN models\u201d.\nWe further evaluate GRED on two additional datasets from TUDataset and compare against SPN. We follow the experimental setup of SPN, and report the average accuracy and standard deviation of $10$ splits:\nModel\nNCI1\nPROTEINS\nDGCNN\n76.4$\\pm$1.7\n72.9$\\pm$3.5\nDiffPool\n76.9$\\pm$1.9\n73.7$\\pm$3.5\nECC\n76.2$\\pm$1.4\n72.3$\\pm$3.4\nGIN\n80.0$\\pm$1.4\n73.3$\\pm$4.0\nGraphSAGE\n76.0$\\pm$1.8\n73.0$\\pm$4.5\nSPN [1] ($K=10$)\n78.2$\\pm$1.2\n74.5$\\pm$3.2\nGRED ($K=10$)\n82.6$\\pm$1.4\n75.0$\\pm$2.9\nThe baseline performance is directly copied from the SPN paper. GRED generalizes well to TUDataset and outperforms SPN with the same number of hops.\nQ3. A notable weak point of the paper is the unavailability of the source code for the proposed model\n.\nAns\n: We have added an implementation of GRED to Appendix B of the updated PDF. We will release the full training scripts after the paper is accepted.\nWe kindly ask the reviewer to consider raising her/his score if she/he thinks our response can address the concerns. We would be happy to answer further questions!"}, {"Heading": "Kind Reminder", "Subheading": "Official CommentbyAuthors22 Nov 2023, 21:47 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nDear Reviewer 8Mos,\nThank you once again for your time spent reviewing our paper! In our response, we have managed to address all the raised concerns. The discussion period is ending soon, and we would really appreciate it if you could provide feedback. We are happy to answer any further questions!\nBest regards,\nThe authors"}]}, {"Heading": "Official Review of Submission9385 by Reviewer hzhG", "Subheading": "Official ReviewbyReviewer hzhG24 Oct 2023, 16:37 (modified: 22 Nov 2023, 10:14)EveryoneRevisions", "Content": "Summary:\nThe paper proposed a new architecture for the graph learning, aggregating nodes with different distance and using a parallelizable linear recurrent network to encode the information flow while keeping the weights from vanishing.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\npaper is well written and easy to follow\nexperiment is good\nWeaknesses:\nRNN here is strange, the assumption here is that the information flow from K-hop to K-1 hop. but information can also go \"outward\", from k-2 hop to k-1 hop. RNN is not good to model the graph information\nI assume all the GNN drawback will also be here in this Model (over smoothing, etc). The model can be regarded as another interpretation of massage passing(even though the weight is different), for the target node, the model will aggregate all the K-hop node information\nQuestions:\nhow the performance like if we change LRU to the vanilla RNN. seems LRU for the long range information pass is the key factor to win against MPNN.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer hzhG", "Subheading": "Official CommentbyAuthors21 Nov 2023, 11:23 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nWe thank reviewer hzhG for taking the time to review our work, and are pleased she/he found our work to be well-written and our experiments to be good. We address the raised concerns as follows:\nQ1. RNN here is strange, the assumption here is that the information flow from K-hop to K-1 hop. but information can also go \"outward\", from k-2 hop to k-1 hop. RNN is not good to model the graph information\n.\nAns\n: It\u2019s true that each edge in the graph allows \u201cbidirectional\u201d information flow. However, if we focus on a particular node for which we want to generate a representation, it\u2019s natural to categorize the other nodes into \u201cshells\u201d (Figure 1(b)). Nodes that belong to the same shell have the same shortest distance from the target node (considering running a breadth-first search from the target node). Then a recurrent neural network, which runs from the outermost shell to the innermost one, would be a reasonable choice to encode the neighborhood structure.\nBesides, our model indeed allows \u201cbidirectional\u201d information flow. For two different target nodes (Node 1 and Node 2), their shells are different, the K-1 hop and K hop neighbors of Node 1 can become the K hop and K-1 hop respectively for Node 2, and the information propagates reversely when we generate the representation for Node 2. Therefore, considering the set of node representations as a whole, we won\u2019t lose any structural information. This argument is supported by our rigorous theoretical analysis of expressiveness\nQ2. I assume all the GNN drawback will also be here in this Model (over smoothing,  etc). The model can be regarded as another interpretation of massage passing(even though the weight is different), for the target node, the model will aggregate all the K-hop node information\n.\nAns\n: GRED doesn\u2019t have the drawbacks of MPNN because the computational graphs of GRED and MPNN are different. We have added a straightforward example to Appendix E of the updated PDF to illustrate their difference. To aggregate all nodes in the K-hop neighborhood, MPNN needs to perform message passing for K rounds. As a result,  MPNN\u2019s computational graph for the target node grows exponentially with K because the same neighbor will appear many times in the computational graph. The exponentially growing number of nodes are mixed together by MPNN to generate the representation for the target node, resulting in the known drawbacks (e.g., over-smoothing, over-squashing).  On the contrary, the computational graph of GRED includes each node in the K-hop neighborhood exactly once, and GRED further utilizes LRU to control how signals of distant nodes are propagated toward the target node. Therefore, GRED can more effectively leverage information beyond the local neighborhood than MPNN.\nQ3. how the performance like if we change LRU to the vanilla RNN. seems LRU for the long range information pass is the key factor to win against MPNN\n.\nAns\n: We have conducted experiments to compare LRU with vanilla RNN:\n~\nCIFAR10 $\\uparrow$\nZINC $\\downarrow$\nPeptides-func $\\uparrow$\nBest MPNN\n67.312$\\pm$0.311\n0.188$\\pm$0.004\n0.6069$\\pm$0.0035\nGRED$_{\\text{RNN}}$\n69.215$\\pm$0.080\n0.160$\\pm$0.005\n0.4945$\\pm$0.0024\nGRED$_{\\text{LRU}}$\n75.370$\\pm$0.621\n0.089$\\pm$0.004\n0.7041$\\pm$0.0049\nWe replace the LRU component of GRED with a vanilla RNN:\n\\begin{equation}\n    \\mathbf{s}_{v, k}^{(l)} = \\text{tanh} ( \\mathbf{W}_{\\text{rec}} \\mathbf{s}_{v, k - 1}^{(l)} + \\mathbf{W}_{\\text{in}}\\mathbf{x}_{v, K - k}^{(l)})\n\\end{equation}\nwhere $\\mathbf{W}_{\\text{rec}} \\in \\mathbb{R}^{d_s \\times d_s}$ and $\\mathbf{W}_{\\text{in}} \\in \\mathbb{R}^{d_s \\times d}$ are two trainable real weight matrices. We use the same number of layers and the same $K$ for both models. We can observe that the performance of GRED with a vanilla RNN drops significantly. On CIFAR10 and ZINC where $K$ is not large, GRED$_{\\text{RNN}}$ still outperforms the best MPNN, but on Peptides-func where long-range information is needed (8 layers with $K=40$ per layer), the performance of GRED$_{\\text{RNN}}$ is worse than the best MPNN because vanilla RNNs are known to be difficult to train on long sequences, unlike the LRU.\nWe kindly ask the reviewer to consider raising her/his score if she/he thinks our response can address the concerns. We would be happy to answer further questions!"}, {"Heading": "thanks for the clarification", "Subheading": "Official CommentbyReviewer hzhG22 Nov 2023, 10:14 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nthank you for the answers to my questions. My questions have been clarified. I'll raise my rating to weak accept."}]}]}, "bDWXhzZT40": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "loss reweighting, epistemic uncertainty, bi-level optimization, model calibration, bayesian neural networks", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Predictive uncertainty--a model\u2019s self-awareness regarding its accuracy on an input--is key for both building robust models via training interventions and for test-time applications such as selective classification. We propose a novel instance-conditional reweighting approach that captures predictive uncertainty using an auxiliary network, and unifies these train- and test-time applications. The auxiliary network is trained using a meta-objective in a bilevel optimization framework. A key contribution of our proposal is the meta-objective of minimizing dropout variance, an approximation of Bayesian predictive uncertainty, We show in controlled experiments that we effectively capture diverse specific notions of uncertainty through this meta-objective, while previous approaches only capture certain aspects. These results translate to significant gains in real-world settings\u2013selective classification, label noise, domain adaptation, calibration\u2013and across datasets\u2013Imagenet, Cifar100, diabetic retinopathy, Camelyon, WILDs, Imagenet-C,-A,-R, Clothing-1.6M, etc. For Diabetic Retinopathy, we see upto 3.4%/3.3% accuracy & AUC gains over SOTA in selective classification. We also improve upon large-scale pretrained models such as PLEX.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "pdf", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "general machine learning (i.e., none of the above)", "Submission Number": "9383", "PDF Url": "https://openreview.net/pdf?id=bDWXhzZT40"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9383 by Area Chair Wcbs", "Subheading": "Meta ReviewbyArea Chair Wcbs09 Dec 2023, 10:38 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe authors propose a bilevel optimization problems, in which a predictor is learned simultaneously with an auxiliary uncertainty quantifier, which is used for instance weighting. A meta-level loss enforces reduction of the predictor\u2019s uncertainty by minimizing a variational approximation of Bayesian Neural Networks by means of multiple inference passes employing Dropout regularizations. The authors show their method to be effective in achieving uncertainty-awareness and better generalisation performance.\n\nAlthough the reviewers raise a number of critical points in their original reports, there is agreement that the paper holds promise, and the authors' idea of the bilevel approach looks quite intriguing. The authors also showed a high level of commitment during the rebuttal phase and did their best to respond to the comments and to improve the submission. This was appreciated and positively acknowledged by all. In the discussion between authors and reviewers, essentially all critical points could be resolved.\nJustification For Why Not Higher Score:\nGood paper, but not outstanding.\nJustification For Why Not Lower Score:\nGood enough to justify acceptance."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 00:54Everyone", "Content": "Comment:\nWe thank the reviewers for their thoughtful comments. Below we have addressed some of concerns regarding our work. Also, we have uploaded a new draft, and the primary changes are responses to reviewer comments for clarity in writing, and additional experiments (appendix)."}, {"Heading": "Official Review of Submission9383 by Reviewer bRmp", "Subheading": "Official ReviewbyReviewer bRmp10 Nov 2023, 12:19 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn this paper, the authors propose an instance weighting methodology based on an auxiliary network that quantifies the uncertainty of the predictor subject to learning. More precisely, a bilevel optimization formulation enables one to simultaneously learn the predictor and the auxiliary uncertainty quantifier, whereas a meta-level loss enforces to reduce the predictor\u2019s uncertainty by minimizing a variational approximation of Bayesian Neural Networks by means of multiple inference passes employing Dropout regularizations. As the authors show, the method proves to be an effective means to achieve a more uncertainty-aware, and consequently better generalizing predictors.\nSoundness:\n4 excellent\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\n- Strong empirical evidence of the reasonability of the method. Also, the experiments are at an impressive scale, supporting the claims of the work.\n- Rich set of recent baselines considered in the experiments, fair comparisons.\n- I really like that this method allows for augmenting previous robust approaches, e.g., PLEX, with the proposed solution. That significantly boosts its applicability.\n- Computational efficiency concerns are thoroughly addressed in the appendix.\nWeaknesses:\nMajor:\n\n- The contribution and distinctions to previous works (which e.g. also use a bilevel optimization formulation for reweighting) should be made more clear in the thread of Section 3. Often, it does not become clear when something is new in the course of the ReVaR proposal, and when previous works are revisited.\n- Many grammatical and orthographic issues, e.g., missing articles (\u201c*the* dataset\u201d \u2192 motivational questions in Section 1), misplaced words (\u201ccaptures captures\u201d \u2192 beginning of Section 5), \u2026\n- Section 4 is very hard to read, some design choices also appear arbitrary. For instance, intuitively, what is the role of $X_c$, $X_e$, $W_c$ and $W_e$, and why are the dimensionalities chosen as described in the paper? Elaborating more on the setup would help to better understand the settings and allow for estimating the significance of these results.\n\nMinor:\n\n- Sometimes unclear / inconsistent notation, e.g., \u201cp=w=g(x)\u201d in  Section 1.1, also see my previous comment on $X_c$, $X_e$, $W_c$ and $W_e$.\n- As far as I can see, there is no code served along with the paper, which does not support the reproducibility of this work.\n- Section 4, Scenario 1: \u201e?\u201c Broken reference\n- Details about the U-score model architecture appear in the appendix only \u2013 as this is not as trivial as \u201cnormal\u201d predictors, this should be already hinted at in the main paper.\nQuestions:\n1. While Section 4 gives a comprehensive overview of different forms of captured uncertainties in $g_\\theta$, I would be also interested in seeing concrete learning behaviors of $g$ in the real-world experiments. Perhaps the authors could augment the results by showing patterns of $g$ in this regime, e.g., by plotting the distributions of the learned weights, and how these evolve over the training. Right now, it is hard to get an impression about the learning dynamics, raising the following questions: Does the novel meta loss slow down the training by making it more cautious, or does it even accelerate the training? Note that I am not referring here to what has been discussed in E.3, but with the focus on learning curves. For instance, setting the maximum number of epochs / data points to control training costs is often a critical consideration in real-world application at larger scales.\n2. Could the U-SCORE and predictor weights be shared? How would this affect the training?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nn/a\nRating:\n8: accept, good paper\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 23:22Everyone", "Content": "Comment:\nThank you for your thorough review, constructive feedback, and positive comments! A few brief answers follow, and we have incorporated the suggestions into an updated draft.\n\n* *contribution and distinctions to previous works \u2026in the thread of Section 3*\n\nApologies, we will make this more clear. The 2 key innovations are instance-conditioning (previous work learned either free parameters or functions of instance loss) and the novel meta-regularizer of variance minimization. Instance conditioning allows us to score unseen test instances (without access to labels), and thereby enables new use-cases such as selective classification that the previous methods cannot do. Variance minimization allows us to capture a variety of input-dependent uncertainty measures  (Table 1) that loss-conditioning (MWN) and instance conditioning (IBR, our own contribution) alone cannot.\n\n* *Many grammatical and orthographic issues*\n\nThank you; we are incorporating the suggested changes along with a round of proofreading.\n\n* *Section 4 is very hard to read, some design choices also appear arbitrary. what is the role of Xc,Xe,Wc,We,  and , and why are the dimensionalities chosen as described in the paper?*\n\nWe apologize for the lack of clarity. The variables are introduced as a general setup for introducing specific sources of input-dependent noise as described in the scenarios 1-5. These scenarios are often studied in isolation; we wanted to evaluate methods across these scenarios as a way of dissociating the contributions of each method for each scenario.  We have updated the writing to make the above and other aspects clear.\n\n(Briefly, the [Xc,Xe] partitioning exists to enable scenarios 3, 4 where some of the features of the underlying generative model are not available to the learner.  In these scenarios, although the label is still generated as a function of the entire input, the learners are only provided Xc as input. The contributions of Xe to the label, being inaccessible to the learner, essentially function as input-dependent noise through the conditional dependence Xe|Xc.)\n\nThe design choices  (dimensionality etc) do not materially affect the findings; we verified this by running experiments on additional configurations for synthetic data with randomly chosen dimensions (in the range 50-200), and all of them showed similar findings. We can share the results if needed. \n\n\n* *Sometimes unclear / inconsistent notation. Section 4, Scenario 1: \u201e?\u201c Broken reference. Details about the U-score model architecture appear in the appendix only*\n\nThank you; we have incorporated the suggested changes along with a round of proofreading. Also we have added a line at the end of section 3 that our meta-network is also implemented as standard neural network architecture like the classifier.\n\n\n* *As far as I can see, there is no code served along with the paper, which does not support the reproducibility of this work.*\n\nWe will be releasing code along with the final version of the paper if accepted.\n\n\n* *it is hard to get an impression about the learning dynamics [...]*\n\nThis is a very interesting point; we examined the training dynamics but did not see any overt evidence of, e.g., faster convergence for our approach compared to ERM. We are performing additional analyses to be shared soon.\n\n* *Could the U-SCORE and predictor weights be shared? How would this affect the training?*\n\nWe considered an architecture where the meta-network was k fully-connected layers  (for some values of k) on top of the  primary classifier\u2019s final layer representation. The meta-objective only updated the k layers, and not the shared encoder (otherwise, training was not stable).  Looking at AUARC in selective classification, the shared architecture performs worse than a separate meta-network.\n\n\n\n|   | DR (ID) | DR (OOD) | CIFAR-100 | ImageNet-100 | ImageNet-1K |\n| ------ | ------ | ------ | ------ | ------ | ------ |\n| Ours | 94.12 $\\pm$ 0.1 | & 89.94 $\\pm$ 0.1 | & 93.20 $\\pm$ 0.1 |  & 94.95 $\\pm$ 0.1 | & 88.20 $\\pm$  0.2 |        \nOurs (Shared, K=4) | 93.05 $\\pm$ 0.1 | 88.07 $\\pm$ 0.1 | 92.03 $\\pm$ 0.1 | 93.67 $\\pm$ 0.1 | 86.85 $\\pm$  0.1 |\nOurs (Shared, K=6) | 93.12 $\\pm$ 0.1 | 88.13 $\\pm$ 0.1 | 92.16 $\\pm$ 0.1 | 93.32 $\\pm$ 0.1 | 86.75 $\\pm$  0.1 |\nOurs (Shared, K=8) | 92.98 $\\pm$ 0.1 | 88.02 $\\pm$ 0.1 | 91.98 $\\pm$ 0.1 | 93.10 $\\pm$ 0.1 | 86.68 $\\pm$  0.1 |\n\nA possible explanation is that the classifier needs to find discriminative features, whereas the  meta-network needs to identify features, potentially across classes, that flag instance hardness; hence they may need different representations.  We also tried other configurations where an earlier-layer representation from the primary model was input to the meta-network, but no improvements were observed. We have added this in the updated draft (appendix section I)"}, {"Heading": "Official Comment by Reviewer bRmp", "Subheading": "Official CommentbyReviewer bRmp22 Nov 2023, 01:15Everyone", "Content": "Comment:\nI want to thank the authors for this thorough rebuttal, which adequately addresses my concerns. After checking the other reviewers' comments, I do not see any critical weaknesses I have missed and which could be a profound reason for rejection, so I keep my current scoring, leaning towards acceptance."}]}, {"Heading": "Official Review of Submission9383 by Reviewer f1Z8", "Subheading": "Official ReviewbyReviewer f1Z831 Oct 2023, 05:00 (modified: 22 Nov 2023, 06:42)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a method which learns a weighting function for the cross entropy loss, enabling re-weighting of the terms depending on how difficult (in an uncertainty sense) they are to classify. The method is learnt through a bi-level optimisation process, which is not dissimilar from a 'meta' training objective. The authors demonstrate their results on several datasets using ResNet-50 architectures.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe strengths of this paper are it's:\n* Simplicity, the method seems very easy to implement and is intuitive to understand.\n* The experiments are reasonably conclusive and operate on a significant number of datasets.\nWeaknesses:\nIn terms of weaknesses:\n* The paper seems quite rough, there are many undefined terms and functions ($R^2$, $g(x)$, $G$), missing citations (MMCE), lack of error bars in Table 4 - 7, etc.\n* With a paper being set up the way it has, I would expect some proof, especially with the synthetic setup in Section 4\n* Moreover, I'm not entirely convinced on why this method works, my understanding is that you are simply training the network to produce low variance in its predictions, which is manifested by the network essential learning dirac distributions over the parameters in dropout. It would be nice to see some investigation into this, or at least an explanation.\n* Only performed on ResNet, there are many models available now which can be trained just as easily with similar compute.\nQuestions:\n* What is the definition of $g(x)$? And how does this relate to $\\theta$. I couldn't find this information when it was introduced, which made this paper very hard to grasp what was happening.\n* How do $w_i$ and $\\Theta$ relate?\n* What is the theory in Scenario 1?\n* What are the associated issues with this approach? I understand the objective of minimising uncertainty, but minimising the metric which provides the uncertainty is not the same thing. I'm concerned that all this is doing is simply collapsing the dropout distribution to all become the same parameters, i.e. it makes no difference on the prediction which parameters are selected. \n\n\nWhilst I think there is some contribution in this paper, I just don't think in it's current form it's ready for publication. I would suggest that the authors improve:\n* The quality of the paper to make it easier to understand what the method is, i.e. define $g(x)$ properly\n* A proof would strengthen the paper significantly. If you can prove why minimising the variance provides improved uncertainty you're onto a winner.\n* Add more architectures, using only ResNet-50 is not enough.\n* I would also suggest removing the empirical evaluation on the top set up. If you have a toy set up like this, it should turn into a proof.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 23:43 (modified: 21 Nov 2023, 10:41)EveryoneRevisions", "Content": "Comment:\n* *The paper seems quite rough, there are many undefined terms and functions (R2,g(x),G ), missing citations (MMCE), lack of error bars in Table 4 - 7, etc.*\n\nWe've addressed a number of the writing issues suggested by you and other reviewers. We thank the reviewer for the suggestions and questions;  we hope and believe the key contributions of our paper are now clearer, and that the writing does not detract from assessing the value / potential of our contributions. We have removed the notation G. R2 score is a popular metric used in statistics.\n We have provided the updated tables 4-7 with std values in appendix section K. This is done due to limited space in the main paper. Also, please refer to Sec 5.1 regarding citations for MMCE and other baselines.\n\n* *Moreover, I'm not entirely convinced on why this method works, my understanding is that you are simply training the network to produce low variance in its predictions, which is manifested by the network essential learning dirac distributions over the parameters in dropout. It would be nice to see some investigation into this, or at least an explanation.*\n\nWe apologize if the intuitions were not made clear. Here is a brief note, which we have incorporated into the paper as well; please let us know if this explanation addresses your concerns.\n \nThe meta-regularizer has the following interesting properties by design: a) the objective is to minimize predictor model's variance on a *validation set unseen by the predictor model*, b) the mechanism for minimizing this variance is indirect, through reweighting the predictor model's training instances, c) the reweighting is accomplished by a meta-network. \n\nThus, the meta-regularizer doesn't necessarily aim to produce a \"more certain predictor\" that may or may not be of good quality; instead, it forces the meta-network to upweight training instances that are most useful (informative) in reducing uncertainty. Conceptually, one can see that the ideal meta-network will need to weight training instances according to their input-dependent noise, or covariate shift, among other factors (see [1,2] for theoretical motivation of this claim). We ran experiments adding the variance minimization to the predictor's training loss; this produced neither a better predictor nor a better meta-network, showing that simply having a \"certain\" predictor isn't intrinsically valuable.  AUARC results on selective classification below (the new variant denoted with var_min_train):\n| \t\t\t    DR (in-Dist) |     DR (OOD) |  CIFAR-100 |       Im-100   |        Im-1k\t|\n| -------------------------------- | -------------- | ------------- | -------------- | -------------- |\nRevar   \t|\t 94.12 \u571f 0.1   |  89.94 \u571f 0.1 |  93.20 \u571f 0.1 |    94.95\u571f0.1 |  88.20\u571f0.2 | \t\nRevar (var_min_train) | 93.03 \u571f 0.2 |     88.11 \u571f 0.1 |  91.85 \u571f 0.2 |    93.05\u571f0.1 |  86.65\u571f0.1 |\n\nWe also ran experiments without this meta-learning framework, directly adding variance minimization alongside ERM in the paper (Sec. 5.1 under New baselines, Tables 2,3). This also leads to suboptimal performance.\n\n* *Only performed on ResNet, there are many models available now which can be trained just as easily with similar compute.*\n\nWe've shown that fine-tuning a large-scale transformer model (PLEX) also shows similar gains on top of PLEX (Appendix Section C). This suggests that our ideas are valuable even for large-scale data and models. Please also refer to appendix E.1 where we experiment with ViT-Small architectures for both U-Scorer and Classifier and similarly RN-101. Also in appendix E.2 we evaluated WRN-28-10 architectures. The consistent gains suggest value across a range of architectures and sizes. If needed, we would be happy to provide more experimental results with various architectures in the paper.\n\n\n* *What is the theory in Scenario 1?*\n\nApologies for the broken reference. Scenario 1 is inspired from a recent paper [1] which assumes a similar data model and establishes the optimality of importance weights that are inversely dependent to the noise. We have fixed this citation in the draft.\n\n* *What are the associated issues with this approach? I understand the objective of minimising uncertainty, but minimising the metric which provides the uncertainty is not the same thing.*\n \nAs described above, the uncertainty-minimizing regularizer is a tool to help the meta-network to focus on relevant training instances, and thereby capture notions of instance-based uncertainty. Table 1 clearly shows that the regularization is what allows our method to accurately capture input-dependent noise, across a range of scenarios.\n\n\n[1] Near Optimal heteroscedastic regression with symbiotic learning. COLT 2023"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 23:58 (modified: 17 Nov 2023, 00:04)EveryoneRevisions", "Content": "Comment:\n* *What is the definition of g(x)? And how does this relate to \\theta. I couldn't find this information when it was introduced, which made this paper very hard to grasp what was happening.*\n* How do  $w_i$ and $\\Theta$ relate?*\n\nWe sketch the proposal briefly below; apologies for the lack of clarity in our original draft.\n \n1. We introduced the basic goal in Sec3.1 \u2013 we want to learn two functions  $f_\\theta(x)$ (classifier) and $g_\\Theta(x)$ (an uncertainty measure associated with f that maps an input to a number [0 1]). Their parameters are ($\\theta$, $\\Theta$) respectively.  We can define g(x) functionally, i.e., in terms of how we want the output to behave. One example is that it maximizes accuracy of a given f(x) for a given budget (eq.1) , i.e., that it correlates strongly with the likelihood that the classifier is correct. \n\n2. **We leverage previous work in learned reweighting of training data (eq.2) which learns free parameters $w_i$ for each training instance $x_i$. We believe that these weights $w_i$ are fairly good stand-ins for instance hardness, since upweighting hard samples is known to be beneficial.**  But we want to be able to score new, unseen test instances, so instead of w_i we learn a neural network $g_\\Theta(x_i)$ (Section 3.3).  In other words, we replace $w_i$ in Eq. 2 with $g(x_i)$ (Eq. 3).\n\n3. Finally, although we have now enabled test-time applications with point #2, the standard bilevel objective of Eq.3 is insufficient, so we add a variance-minimization regularizer (section 3.3). Please see \u201cIntuition\u201d in the updated draft for why we chose to do this, and  Section 4 / Table 1/ Ours vs IBR for empirical evidence across scenarios that our contribution #3 improves significantly over our contribution #2 above.\n\nWe believe perhaps point #2 above, **especially the text in bold**, was insufficiently explained, perhaps leading to confusion. Hopefully this helps clarify, and we have also made changes in the text to reflect this.\n\n\n-  *I would suggest that the authors improve:*\n     - *The quality of the paper [...]*\n\n     - *A proof would strengthen the paper significantly. [...]*\n\n     - *Add more architectures, using only ResNet-50 is not enough.*\n\n     - *I would also suggest removing the empirical evaluation on the top set up. If you have a toy set up like this, it should turn into a proof.*\n\n1. We have provided a conceptual sketch of the design, and why we expect minimization of variance to work. We have rewritten various sections incorporating other feedback from you and other reviewers w.r.t. the presentation.  As noted above, we have already shown results on large-scale pretrained transformer models (PLEX, Appendix section C) and analyzed other architectures including ViT-S, RN-101 and WRN-28-10.\n\n2. Removal of empirical evaluation (Section 4): We respectfully disagree with this suggestion for the following reasons: a) the synthetic setup allows us to exactly control the type and degree of noise introduced, b) using these controls, we are able to clearly dissociate (table 1) what can be achieved using loss-based, input-based (our own baseline), and meta-variance-reduction-based (our full method) reweighting. It establishes not only ordering between these methods with clear large gaps (table 1), but also the ability of our method to handle gradations of contribution input noise source  (figure 1). c) we have also attempted to connect the real-world experiments to each of these scenarios, showing that our gains in synthetic settings generalize. \n\n3. Proofs: As mentioned above, our approach smoothly interpolates between two sources of noise, when their contributions are varied. [1,2] provide theoretical justifications for the target weightings in Table 1, and do so by explicitly estimating the uncertainty measure (importance sampling ratio in the latter and label noise variance in the former) for calculating weights. Our meta-network does this implicitly without any estimation, and can moreover also interpolate. Theoretical justification of these empirical findings will therefore need to integrate a number of scenarios & corner cases requiring very different ideas spanning almost a decade of work, alongwith the challenges of analyzing the bi-level training dynamics; it is hence out of scope for this paper although an active area of work for us.\n\n[1] Near Optimal heteroscedastic regression with symbiotic learning. COLT 2023\n\n[2] Direct importance estimation with model selection and its application to covariate shift adaptation. NeurIPS 2007."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 10:40 (modified: 21 Nov 2023, 10:41)EveryoneRevisions", "Content": "Comment:\n* **Additional data showing replication of all results in table 1 for ViT-Small/WRN-28-10 architecture.** \n\nAs discussed above, we have already conducted experiments with various architectures for classifier and U-Score in appendix F.1 and F.2 (E.1, E.2 in the original draft). However, given the reviewer's concerns, we provide further results replicating table 1 for the ViT-Small and WRN-28-10 architectures for the classifier in appendix section L in the updated draft. The performance gains either have a minor increase or are same as Table 2 in the main paper when using these architectures. This further verifies the effectiveness of our method and advocates for its usefulness for various tasks requiring different kinds of neural network architectures. \n\nWe're happy to address any additional questions or concerns; we request the reviewer to consider our responses above."}, {"Heading": "Response", "Subheading": "Official CommentbyReviewer f1Z822 Nov 2023, 06:42Everyone", "Content": "Comment:\nThank you for a detailed response and addressing the concerns I had, it's highly appreciated. I feel many of them stemmed from the original lack of clarity in the draft. Having seen the new draft had my initial concerns addressed I have decided to raise my score accordingly."}]}, {"Heading": "Official Review of Submission9383 by Reviewer 1jLE", "Subheading": "Official ReviewbyReviewer 1jLE24 Oct 2023, 22:35 (modified: 19 Nov 2023, 13:11)EveryoneRevisions", "Content": "Summary:\nThe authors propose ReVar technique for predicting model uncertainty at train and test time. In particular, ReVar is notable for aiming to capture various different sources of uncertainty, including covariance shift and high label noise. ReVar uses bi-level optimization to learn both a primary model f(x) and auxiliary uncertainty model g(x), which serves as an instance-dependent weight function for training data and an uncertainty score. The technique is evaluated favorably against prior works, both on synthetic data and on real datasets for many tasks including calibration, data with label noise and selective classification.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\n- The general premise of an all-purpose uncertainty evaluation tool, useful for both train and test time and adaptive to various sources of uncertainty, is a significant and original contribution that would be very useful\n- The evaluation against prior works on a variety of uncertainty-related tasks is very comprehensive\n- In section 4, the classifications into types 1-3 uncertainty and discussion of how instance weights should respond to these types was a useful step towards putting these different uncertainty problems under one theoretical framework\nWeaknesses:\n- Section 4's work with synthetic data has good potential to be interesting and illustrative of how ReVaR works differently in desired ways for different uncertainty types. However, I found it unclear how the \"theoretical ideal for the instance dependent weights\" listed in table 1 were determined. Some more information on their derivation might be helpful.\n- Occasional minor notational things: Equation 3, definition of $\\theta^*$, should $g_\\Theta$ might instead be $g_{\\Theta^*}$. The text following/explaining equation 6 introduces variables not used in equation 6; some minor rewriting could be useful here. Missing reference to a theory in section 4, scenario 1.\nQuestions:\n- How were the targets in table 1 derived; why are these targets desirable?\n- In distribution shift settings where we assume access to a validation set from the test distribution, is it not better sometimes to just fine-tune on the validation set (or a portion of it)? It could potentially be a good baseline comparison.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 00:25 (modified: 17 Nov 2023, 00:30)EveryoneRevisions", "Content": "Comment:\nThank you for your thorough review, constructive feedback, and positive comments! We have addressed the raised questions and comments below. Since the reviewer assesses our work as having significant and original contributions with comprehensive evaluation, and has not expressed any major concerns with the work, may we request them to re-visit their rating for the work? We are of course happy to address any additional concerns or questions they may have.\n\n* *Section 4 \u2026 I found it unclear how the \"theoretical ideal for the instance dependent weights\" listed in table 1 were determined.*\n\nSince we control the amount and type of input-dependent noise we have introduced, we posit that the ideal weight should be proportional to the inverse of the introduced input-dependent noise [1] and directly proportional to the uncertainty due to covariate shift, i.e., $h:=(x-\\mu)^2$ [2].  Apologies for the broken citation in the paper. In two-factor settings such as scenarios 2,4, we suspected that the weight would be a linear combination of the two contributing factors. Certainly, when either uncertainty from shift or label noise is increased while the other remains the same, we should expect the \u201cideal\u201d weighing scheme to follow the larger noise source. So linear interpolation is a natural simple hypothesis.  Surprisingly, even this fairly rudimentary model is an excellent fit for the weights identified by our model; what's more, the different scenarios help dissociate the 3 methods -- loss-dependent reweighting (MWN), instance-based reweighting (our own novel baseline), and our full approach with variance-minimizing meta-regularization. For scenario 3, it is somewhat similar to scenario 1 as the missing features can be interpreted as labelled noise since their contribution cannot be modeled. Please refer to the updated draft for more details on deriving the targets for the scenarios 2 and 3. For scenario 5, since it is the shift in spurious features which do not play any role in deciding the output (given $W_e=0$), the weighting for all the instances should be uniform.\n\n* *Occasional minor notational things: Equation 3,6 [etc]. some minor rewriting could be useful here. Missing reference to a theory in section 4, scenario 1.*\n\nThank you! These changes have been incorporated in the updated draft. Also, for eq. 3, we have added defined $\\theta^*$, $\\Theta^*$  and also it should be $g_\\Theta$ only in eq. 3 as against $g_\\theta^*$ since $\\Theta$ is optimized in the outer loop in the exact bi-level formulation.\n\n* *In distribution shift settings where we assume access to a validation set from the test distribution, is it not better sometimes to just fine-tune on the validation set (or a portion of it)?*\n\nWe clarify that any experiments we\u2019ve shown for our method on domain shift data have used only ***unlabeled data*** from the test distribution, and not any labeled data whatsoever. Our approach can incorporate unlabeled data via the variance-minimization meta-loss (which is label-free). Fine-tuning, say, an ERM model in domain-adaptation settings is conventionally done using small amounts of ***labeled data*** from the test domain.\n\nNevertheless, we did experiment with adding the same variance minimization loss as \u201cfine-tuning\u201d for an ERM model including unlabelled examples from the test domain in the validation set. The model is tuned with cross entropy loss for labelled examples and our unsupervised variance minimization objective for the unlabelled examples. We did this for two setups: first where train, val and test all belong to different domains (Chameleon, iWildcam) and second where train, val are from same domain but test from a different domain (DR country shift OOD). This method, labeled MCD(val-tuned) below, was not competitive. Please refer to appendix section J in the updated draft for more details.\n\n| | Camelyon | iWildCam | DR (OOD) |\n| --- | ----------- | ----------- | ------------ |\n| Revar | 76.32 | 77.98 | 89.94 |\n| Revar-PV | 78.12 | 79.86 | 91.23 |\n| MCD (val-tuned) | 75.25 | 76.34 | 88.06 |\n\nWe would be happy to provide any further analysis.\n\n\n[1] Near Optimal heteroscedastic regression with symbiotic learning. COLT 2023\n\n[2] Direct importance estimation with model selection and its application to covariate shift adaptation. NeurIPS 2007."}, {"Heading": "Official Comment by Reviewer 1jLE", "Subheading": "Official CommentbyReviewer 1jLE19 Nov 2023, 13:11Everyone", "Content": "Comment:\nThank you for the detailed response; with these clarifications and revisions I will raise my review to a 6."}]}]}, "DwcV654WBP": {"paper_info": {"Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Video Representation Learning, Out-of-the-box Video Representation, Scalable Video Pre-training", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We tackle the language supervision distortion issue and scale up video training via masking and transcript sorting, achieving state-of-the-art performance in out-of-the-box evaluation.", "Abstract": "The ultimate goal for foundation models is realizing task-agnostic, i.e., supporting out-of-the-box usage without task-specific fine-tuning. Although breakthroughs have been made in natural language processing and image representation learning, it is still challenging for video models to reach it due to the increasing uncertainty of spatiotemporal signals. To ease training, existing works leverage image foundation models' prior knowledge and equip them with ef\ufb01cient temporal modules. Despite the satisfactory fine-tuning performance, we empirically find they fall short of out-of-the-box usage, given the even degraded performance in zero-shot/linear protocols compared to their baseline counterparts. In this work, we analyze the factor that leads to degradation from the perspective of language supervision distortion. We argue that tuning a text encoder end-to-end, as done in previous work, is suboptimal since it may overfit in terms of styles, thereby losing its original generalization ability to capture the semantics of various language registers. The overfitted text encoder, in turn, provides a harmful supervision signal, degrading the video representation. To tackle this issue, we propose a degradation-free pre-training strategy to retain the generalization ability of the text encoder via freezing shallow layers while enabling the task-related semantics capturing in tunable deep layers. As for the training objective, we adopted the transcript sorting task in TVTS incorporated with masking techniques to enable scalable training. As a result, we produce a series of models, dubbed TVTSv2, with up to one billion parameters. We achieve new state-of-the-arts on various video benchmarks with a frozen backbone, surpassing the recent ImageBind, InternVideo, etc. Code and models will be released publicly.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9381", "PDF Url": "https://openreview.net/pdf?id=DwcV654WBP"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9381 by Area Chair JbxQ", "Subheading": "Meta ReviewbyArea Chair JbxQ08 Dec 2023, 18:28 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper provides an analysis of the overfitting issue when finetuning pretrained VL models for building a video encoder. Based on their finding that the end-to-end text encoder tuning is a source of degradation, the paper trains a new model whose text encoder is tuned only partially. The authors claim that this model realizes task-agnostic video representation learning.\nThe paper received two weak rejects and two accepts. While their finding of the importance of the frozen text encoder is appreciated by all the reviewers, two of them strongly think that the technical contribution of this paper is limited. They argue that the proposed freezing technique is more like an engineering trick and is not significant enough for a standalone full conference paper concerning the minor difference compared to the existing model TVTSv1. On the other hand, the other two positive reviewers raise concerns about limited experiments to claim the proposed learns a task-agnostic representation. The authors provided some additional experimental results to resolve these concerns but it seems like they are not fully addressed.\nOverall, the AC believes that the drawbacks outweigh the benefits of the paper recommending rejection.\nJustification For Why Not Higher Score:\nDespite a few positive scores, some critical issues are not fully addressed during the rebuttal.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "A Kind Reminder Regarding Our Response", "Subheading": "Official CommentbyAuthors23 Nov 2023, 03:47Everyone", "Content": "Comment:\nWe thank all reviewers for your time and effort in reviewing our paper. We have responded to all comments in the rebuttal. We would like to remind you that\nthe rebuttal period is approaching its end (within 3 hours).\nIf you have any other comments or questions, please let us know.\nThank you for your attention ^_^"}, {"Heading": "General Response to All Reviewers", "Subheading": "Official CommentbyAuthors19 Nov 2023, 11:04Everyone", "Content": "Comment:\nWe sincerely thank all reviewers for your reviewing efforts :)\nWe have uploaded a revised version of our manuscript to raise your concerns. The figures, tables, and some paragraphs are reorganized for better readability.\nAll major revisions are highlighted using red fonts\n, please refer to the revised version for the table/figure numbers mentioned in the response unless specifically claimed.\nPlease feel free to reach out if you have any further questions."}, {"Heading": "Official Review of Submission9381 by Reviewer NPSQ", "Subheading": "Official ReviewbyReviewer NPSQ31 Oct 2023, 22:49 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn this paper, the authors focus on building large-scale robust video models for out-of-the-box usage, which means the learned features can be used directly for novel tasks.\nThe authors have conducted detailed experiments and found that tuning text encoder end-to-end causes overfitting, thus losing generalization ability. To fix the issue, they propose to tune the text encoder partially.\nFinally, they adopt the transcript sorting task and masking techniques to scale up pretraining. The 1B model achieves new SOTA results on out-of-the-box tasks.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper is well-written and organized, with clear figures and tables.\nThe logic is clear and easy to follow.\nExtensive ablation studies and analysis demonstrate the authors' statements.\nWeaknesses:\nOverall, I appreciate the simple yet effective techniques in this paper. However, considering the differences between TVTSv2 and TVTSv1, the current paper may not be suitable for a conference but a journal as an extension:\nDifferent tuning: The key difference between the two versions is how to tune the text encoder. It is an interesting finding but may not be a qualified novelty for a new conference paper. And the poor performances caused by the weak initialization (Appendix D)?\nSame objectives/architecture/masking: The transcript sorting task and masking techniques have also been used in TVTSv1, though the masking strategies are different. And the architectures are the same (as Frozen[1]), where the residuals are skip-connected.\nConsidering the minor difference, I suggest the authors submit the paper as an extensive journal paper, but not a novel conference paper.\nReference:\n[1] Bain, Max et al. \u201cFrozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval.\u201d ICCV 2021.\nQuestions:\nFor DiDeMo, the code shows that it was tested on test split. Should it be tested on validation split?\nIn Table 2, why the single-stream models are de-emphasized?\nIn Table 2, should the authors list the size of the pretraining data for a clear comparison? It seems that the results for UMT are on a small 5M data, but others are on larger data.\nIn Table 2, why the authors do not consider ViT-L and directly scale it to ViT-H?\nIn Table 3, do those models good at retrieval also perform well, like OmniVL, CLIP-ViP, and UMT?\nReference:\n[1] Wang, Junke et al. \u201cOmniVL: One Foundation Model for Image-Language and Video-Language Tasks.\u201d NeuIPS 2022.\n[2] Xue, Hongwei et al. \u201cCLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language Representation Alignment.\u201d ICLR2023.\n[3] Li, Kunchang et al. \u201cUnmasked Teacher: Towards Training-Efficient Video Foundation Models.\u201d ICCV2023.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer NPSQ", "Subheading": "Official CommentbyAuthors19 Nov 2023, 11:23Everyone", "Content": "Comment:\nW1: Minor difference between TVTSv1 and TVTSv2\nW1.1: The partially frozen tuning strategy lacks novelty.\nA:\nThanks, we are willing to emphasize the novelty of the proposed partially frozen tuning. Note that it plays a vital role (rather than a trick) in training on the easy-to-scale-up ASR-video pairs, which is not trivial given that few previous papers consider tackling the text distortion issue. We carefully break down the experiment step and pinpoint the problem. We identify the problem via comprehensive experiments and figure out a simple yet effective solution that is in favor of practical use and can be well transferred to different datasets (Table 6) and vision models (Table 7). The logic, motivation and ablation studies are mostly acknowledged by all reviewers.\nTo further underscore our contribution, we introduce a ViT-B/32-based alternate baseline, integrating adapters [1] between text encoder layers, denoted as M$_{\\text{adapter}}$. During training, only the adapter-introduced parameters are trainable. The MSR-VTT retrieval results, detailed in the subsequent table, show that this alternative method yields comparatively lower performance. This outcome reinforces our assertion that end-to-end tuning can cause style overfitting, even when the text encoder remains unaltered. It also confirms that our approach of partially frozen tuning is not just a superficial fix, but a substantive and effective solution to the identified problem. We have added this discussion in our revised manuscript (Appendix D Table 16).\nMethod\nR@1\nR@5\nR@10\nMdR\nCLIP\n30.6\n54.4\n64.3\n4.0\nM$_{\\text{ours}}$\n34.5\n58.5\n67.7\n3.5\nM$_{\\text{adapter}}$\n28.8\n54.8\n65.7\n4.0\nWe believe that a paper's contribution should not be limited to proposing novel methods. Extensive empirical studies (i.e., analyzing why performance degrades), useful findings/insights (i.e., the overfitted text model), scalable training schemes (i.e., the simple yet practical partial freezing), and foundation models (i.e., TVTSv2 models that can generalize to various tasks) are also essential to the community, especially in the era of big models. Such contributions are also acknowledged by Reviewer hjUh (Task-Agnostic Focus, Novel Pre-training Strategy, etc.) and Reviewer A6Wr (Effective Pre-training Strategy).\n[1] Parameter-Efficient Transfer Learning for NLP, ICML 2019\nW1.2 TVTSv1's poor performances may be caused by weak initialization (Appendix D).\nA:\nWe admit that a strong initialization yields better performance, as reported in Appendix D Table 20.\nHowever, naively relying on stronger initialization leads to degraded performance when pre-training on large-scale ASR-paired videos.\nAs shown in Table 1 in our initial manuscript (the subsequent Table) , after equipping CLIP weights, all fully tuned variants still lag behind the partially tuned competitors (L3 vs L7, L5 vs L8), and they even degrade compared to the CLIP baseline (L1 vs L3, L5), indicating the importance of the proposed partial frozen tuning strategy for producing general-purpose video representations.\nNo\nMethod\nASR\nAlt-text\nKinetics-400 (ZS AR)\nDiDeMo (ZS T2V)\nL1\nCLIP\n$\\times$\n$\\times$\n42.7 (+0.0)\n24.7 (+0.0)\nL3\nM$_{\\text{ASR-Full}}$\nYT-Temporal\n$\\times$\n45.7 (+3.0)\n19.3 (-5.4)\nL5\nM$_{\\text{All-Full}}$\nYT-Temporal\nWebVid-2.5M\n47.9 (+5.2)\n24.2 (-0.5)\nL7\nM$_{\\text{ASR-Partial}}$\nYT-Temporal\n$\\times$\n48.1 (+5.4)\n26.8 (+2.1)\nL8\nM$_{\\text{All-Partial}}$\nYT-Temporal\nWebVid-2.5M\n50.8 (+8.1)\n29.8 (+5.1)"}, {"Heading": "Response to Reviewer NPSQ (cont.)", "Subheading": "Official CommentbyAuthors19 Nov 2023, 11:28Everyone", "Content": "Comment:\nW1.3: TVTSv1 and TVTSv2 share similar objectives/architecture/masking strategy.\nA:\nThanks. We would like to first emphasize that the central focus of our research is on scalable pre-training, not on introducing new methods or modules. Scalability is a significant and complex area of study, as acknowledged by Reviewer hjUh. There is a wide range of cutting-edge research in this field that doesn't necessarily involve new network architectures, as seen in works like VideoMAE V2 [1] and FLIP [2]. In line with this, we plan to release all our codes and pre-trained models, along with user-friendly APIs, upon acceptance. We believe that these foundational models will be a valuable asset to the community, particularly for academic labs with limited resources for large-scale experiments. The substantial contributions of our work are worthy of recognition by top-tier conferences like ICLR.\nIn addition, we would like to point out that the differences between TVTSv1 and TVTSv2 are significant, for two primary reasons:\n(i)\nOur approach in TVTSv2 involves a thorough and logical analysis for selecting the best attention mechanism for video representation learning. We start with a key question: which type of attention is most effective for this purpose? While TVTSv1 uses joint attention, we introduce a new baseline in Appendix D Table 19 for comparison. This new baseline shows that simply extending the attention range can actually degrade spatial understanding. Furthermore, we explore the optimal method to initialize temporal weights. As demonstrated in Appendix D Table 19, initializing temporal weights with zeros beats its random initialization competitor, indicating that growing temporal reasoning ability out of nothing avoids hurting the well-learned spatial prior, thus more suitable for training video foundation models.\n(ii)\nWe also pioneer the exploration of masked contrastive learning in large-scale pre-training in the video domain. Previous methods, like MAEs [1, 3, 4], focused on pixel-level rather than semantic-level learning, which limited their utility in learning versatile features, as evidenced by weak linear classification results in Appendix D Table 13. In contrast, TVTSv2 employs direct contrastive learning without pixel reconstruction, leading to promising results that underscore the benefits of semantic-level pre-training based on masked representations.\n[1] VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking, CVPR 2023\n[2] Scaling Language-Image Pre-Training via Masking, CVPR 2023\n[3] VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training, NeurIPS 2022\n[4] Masked Autoencoders As Spatiotemporal Learners, NeurIPS 2022\nQ1: For DiDeMo, the code shows that it was tested on test split. Should it be tested on validation split?\nA:\nThanks for your concern. We follow the prior works [1, 2, 3] to conduct paragraph-to-video retrieval on the DiDeMo test split for a fair comparison. And we have double-checked the split used in their official code implementation to avoid any unfairness.\n[1] CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval, Neurocomputing 2022\n[2] CLIP-ViP: Adapting Image-Text Pre-training to Video-Language Representation Learning, ICLR 2023\n[3] Bridging Video-text Retrieval with Multiple Choice Questions, CVPR 2022\nQ2: In Table 2, why are single-stream models de-emphasized?\nA:\nThe single-stream model refers to those using a fusion module to encode multimodal entangled representations. Besides the much higher computational complexity during indexing (i.e., $O(N*M)$ for single-stream models and $O(N+M)$ for ours), the single-stream models are incapable of out-of-the-box usage, deviating from the motivation of this work. For instance, these models cannot serve for linearly probing action recognition (Appendix D Table 13) since they cannot encode video-only representations, while our pre-trained foundation models are capable of various downstream tasks without any adaptation. We have revised our manuscript for a clearer statement."}, {"Heading": "Response to Reviewer NPSQ (cont.)", "Subheading": "Official CommentbyAuthors19 Nov 2023, 11:47Everyone", "Content": "Comment:\nQ3: In Table 2, should the authors list the size of the pretraining data for a clear comparison? It seems that the results for UMT are on small 5M data, but others are on larger data.\nA:\nThank you for the advice. We have listed the pre-trained datasets and their scales in Appendix D Table 11. Generally speaking, models are expected to achieve better performance with an increasing number of training data given the same training recipe. However, the performance does not always improve since more data bring more noise. Moreover, video data with curated alt-text, e.g., WebVid, is generally hard to scale up. Therefore, it is important to study scalable and robust training schemes (our motivation) that can learn from large-scale noisy video data with naturally associated text knowledge, e.g., ASR transcripts.\nWhen referring to UMT, we choose the UMT-5M that was trained under a comparable data scale (6.15M) as ours (7.5M). The other variants using 17M and 25M corpus are not considered as relatively fair competitors in our work.\nQ4: In Table 2, why do the authors not consider ViT-L and directly scale it to ViT-H?\nA:\nOur initial focus was to assess the efficacy of our proposed pre-training framework on base-sized models. Subsequently, we sought to evaluate its effectiveness when scaled up to larger models. However, this scaling presents significant challenges in terms of time and resource consumption. For instance, training the ViT-H/14 model required a substantial investment of time and resources, taking 10 days on 80 V100 GPUs (detailed information can be found in Appendix B Table 10). Given our limited computational resources, it was impractical to train both the ViT-L/14 and ViT-H/14 models simultaneously within our submission deadline. Consequently, to more effectively demonstrate scalability, we opted to train the larger ViT-H/14 model.\nWe have since completed training on the ViT-L/14 variant and its performances are presented in the following table. These comprehensive results are now included in the updated Table 2. In summary, the ViT-L/14 model's performance aligns with the expected scaling rule, positioning itself performance-wise between the ViT-B/16 and ViT-H/14 models.\nMethod\nMSR-VTT R@1\nMSR-VTT R@10\nDiDeMo R@1\nDiDeMo R@10\nLSMDC R@1\nLSMDC R@10\nOurs-B/32\n34.5\n67.7\n31.2\n68.3\n16.1\n38.7\nOurs-B/16\n35.9\n71.3\n33.4\n70.6\n16.9\n38.2\nOurs-L/14\n36.9\n72.9\n33.9\n71.0\n17.1\n40.6\nOurs-H/14\n38.2\n73.2\n34.6\n71.5\n17.3\n41.4\nQ5: In Table 3, do those models good at retrieval also perform well, like OmniVL, CLIP-ViP, and UMT?\nA:\nNice suggestion. Since OmniVL is not publicly available yet, we face challenges in conducting a timely comparison with it. On the other hand, we test the performances of the officially released CLIP-ViP [1] and UMT [2] based on ViT-B/16. In line with what was discussed in Q2, models like UMT typically depend on multimodal entangled representations from a cross-modal encoder. To make a fair and meaningful comparison, we remove the cross-modal encoder and directly use the features outputted by the text and visual branch, namely UMT$ _{\\text{dual}}$. The results are reported in the following table. Similar to Table 2, CLIP-ViP degrades due to the overfitted text encoder. Notably, UMT$ _\\text{dual}$ exhibits the weakest performance, reinforcing our point that single-stream models are heavily dependent on entangled multimodal representations and are not suitable for out-of-the-box usage. In contrast, our approach, which utilizes a simpler dual-stream architecture, clearly outperforms both CLIP-ViP and UMT$ _\\text{dual}$, and the improvement to the CLIP baseline is also significant, making them eligible to serve as foundation video models. We have updated Table 3 to include these results.\nMethod\nHMDB-51\nUCF-101\nK400\nK600\nSSV2-MC\nCLIP\n43.2\n68.9\n48.0\n62.4\n29.6\nCLIP-ViP\n41.2\n58.9\n37.6\n46.7\n35.5\nUMT$_{\\text{dual}}$\n32.7\n46.4\n34.1\n44.0\n23.5\nOurs-B/16\n50.4\n69.8\n54.3\n68.1\n42.1\nOurs-H/14\n52.1\n78.0\n59.6\n73.2\n48.4\n[1]\nhttps://github.com/microsoft/XPretrain/tree/main/CLIP-ViP\n[2]\nhttps://github.com/OpenGVLab/unmasked_teacher/tree/main"}, {"Heading": "Looking forward to your feedback", "Subheading": "Official CommentbyAuthors21 Nov 2023, 23:07Everyone", "Content": "Comment:\nThanks for your constructive advice. We value your comments and have made efforts to revise the paper. Please kindly let us know if our response addressed your concerns. We are willing to respond to any further questions before the rebuttal ends\n(within 36 hours)\n:-)"}, {"Heading": "Response for the authors", "Subheading": "Official CommentbyReviewer NPSQ22 Nov 2023, 10:19Everyone", "Content": "Comment:\nSorry for the late response. As I claimed before,\nI sincerely appreciate the simple yet effective techniques\nand the authors's effort in my questions.\nI would like to first articulate my viewpoint.\nFor me, the paper's key finding of\npartial tuning text encoder\nis surprising, just like\nmask pretraining\nin FLIP. However, such a finding may not be enough for a conference paper. I acknowledge scalability is vital for current foundation models, but it's not well verified in this paper. For example, how about the\nViT-g\nand how about\nlarge noisy dataset (e.g., 25M/100M)\n.\nI understand the authors' constraints due to limited GPU resources, which hinder thorough verification.\nSo it's really hard for me to decide whether the paper should be accepted and I intend to consult with other reviewers for a final decision.\nCurrently, considering the relation between\nV1\nand\nV2\n, a  journal extension might be a more fitting avenue for this paper.\nAs for the authors' responses:\n(1)\nThe concept of\nsingle-stream\nin the paper remains unclear to me. Could you please elucidate the meaning of\nN & M\nin the context of computational complexity during indexing? Additionally, why not opt for a simpler approach by utilizing the visual encoder and incorporating an additional classification head for linear probing?\n(2)\nConcerning models with a\ncross-modal encoder\n, i.e., UMT in the table, would performance be enhanced by an additional encoder? Based on my experience with ALBEF-style architectures, the use of a matching loss via a\ncross-modal encoder\ntypically bolsters performance.\nAnother minor suggestion: The table orders can be adjusted for better reading in the Appendix."}, {"Heading": "Additional Response to Reviewer NPSQ", "Subheading": "Official CommentbyAuthors22 Nov 2023, 12:53Everyone", "Content": "Comment:\nThank you for sharing your concerns in a timely manner. Regarding the follow-up queries, we aim to provide a more explicit explanation:\nAs you know, the cross-modal encoder is typically trained with a matching loss,\nbased on the cross-attention between visual and textual representations.\nThe elaborate interaction within the cross-modal encoder generally bolsters performance. However, it was exactly the paradigm that\nsacrificed efficiency\nand made them\nincapable of producing out-of-the-box features.\nThe reasons are as follows:\n(1) Efficiency:\nThe cross-modal encoder intertwines visual and textual representations, requiring joint visual-textual inputs. Given $N$ queries and $M$ database items, each query needs to be paired with the $M$ database items to yield $M$ discriminative representations, leading to an overall inference complexity of $O(N\\times M)$. Since the output relies on the merged visual and textual representations, such models are called \"single-stream\" ones. In contrast, our \"dual-stream\" model generates independent modality-specific representations. For the same $N$ queries and $M$ items, we encode $N$ query representations and $M$ item representations separately, allowing for swift cosine similarity calculations. This method significantly reduces inference complexity to $O(N+M)$, offering a more efficient solution than single-stream models.\n(2) Incapable of producing out-of-the-box features:\nAs mentioned above, single-stream models rely on entangled multimodal representations during inference. To further address this, we directly use the visual and textual representations output by UMT's video and text encoder, namely UMT$ _{\\text{dual}}$. However, the resulting video-specific representations are inadequate for immediate application evidenced by UMT$ _{\\text{dual}}$'s poor performance, indicating that focusing on visual-textual interaction via matching loss does not substantially improve the quality of video representations themselves.\nLinear Probing:\nUtilizing the visual encoder and incorporating an additional classification head for linear probing is a reasonable suggestion, and it is indeed one of our evaluation metrics. As reported in Appendix D Table 13, our models outperform both self-supervised and language-guided models in these tests. This further demonstrates the effectiveness and versatility of our proposed training methodology. Since such a metric still needs to tune a classifier, instead of being directly used out-of-the-box, we make the zero-shot-based evaluation a priority in our manuscript.\nMinor suggestion:\nWe appreciate your helpful suggestion and will strive to rearrange the tables in the Appendix to enhance their readability :)\nScalability Concerns:\nWe totally understand your concerns, as training such large-scale models is indeed a tough task even for industrial organizations. Here we want to emphasize a few key points.\nWe have 18 ablation studies in the main paper and Appendix in total to figure out the best scalable training recipe. We follow the common practice in the community (e.g., InternVideo and VideoMAE V2) to conduct ablation studies on the base-size model and directly scale up to larger models with the best recipe. Note that successfully obtaining performance gains compared to the baseline counterparts (CLIP in our work) on large models is non-trivial and already verified the effectiveness of our strategy to a large extent, as shown in the following Table.\nMethod\nMSR-VTT R@1\nMSR-VTT R@5\nMSR-VTT R@10\nMSR-VTT MdR\nKinetics-400 Top-1 Acc\nKinetics-400 Top-5 Acc\nSSV2-MC Top-1 Acc\nSSV2-MC Top-5 Acc\nCLIP-H/14\n36.1\n60.4\n70.7\n3.0\n52.0\n79.1\n40.2\n69.2\nOurs-H/14\n38.2\n62.4\n73.2\n3.0\n59.6\n84.1\n48.4\n77.0\nBesides, to our best knowledge, the released ViT-H/14 model is one of the largest open-sourced video models, anticipated to significantly advance the boundaries of research in this field.\nHope this response helps. It is delightful to have a constructive discussion, and please feel free to drop any further questions :-)"}]}, {"Heading": "Official Review of Submission9381 by Reviewer hjUh", "Subheading": "Official ReviewbyReviewer hjUh31 Oct 2023, 12:16 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper presents TVTSV2, an ambitious attempt to create a task-agnostic foundation model for spatiotemporal visual representations. The authors extend the dual-stream framework of CLIP and introduce a degradation-free pre-training strategy to maintain performance. While the work shows promising results in text-to-video retrieval tasks, it could benefit from a deeper evaluation of generalizability across various downstream applications. Furthermore, the paper's focus on scalability is commendable but lacks an in-depth computational and memory usage analysis, which is vital for high-dimensional video data. Robustness against noisy or incomplete data remains unexplored, posing questions on the model's applicability in real-world scenarios. Overall, the paper makes a notable contribution but requires further scrutiny in these areas to substantiate its claims fully.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nTask-Agnostic Focus: The paper aims to create a foundation model that is task-agnostic, addressing a significant need for models that can generalize across various applications without requiring fine-tuning.\nNovel Pre-training Strategy: The introduction of a degradation-free pre-training method is a notable innovation. It suggests a way to train complex models without losing performance, which is particularly challenging in the realm of video data.\nExtension of Existing Architectures: The paper builds upon well-established models like CLIP but adapts them for spatiotemporal data. This approach leverages existing successes in the field while pushing into new domains.\nInitial Empirical Success: The paper demonstrates promising results in text-to-video retrieval tasks, indicating that the model is not just theoretically sound but also empirically effective.\nScalability: The paper addresses the important issue of scalability, which is crucial for the practical application of machine learning models, especially for high-dimensional data like video.\nComprehensive Evaluation: The paper seems to include a variety of evaluation metrics and comparisons with state-of-the-art models, adding credibility to its claims.\nThe idea seems to follow the surgical fine-tuning [1]  idea by freezing shallow layers during the fine-tuning.\nReference :\n1- Lee, Yoonho, et al. \"Surgical fine-tuning improves adaptation to distribution shifts.\" arXiv preprint arXiv:2210.11466 (2022).\nWeaknesses:\nThe paper primarily focuses on text-to-video retrieval tasks for its empirical evaluation, which may not sufficiently support its claim of being a task-agnostic foundation model. To fully establish its task-agnostic capabilities, the model should be rigorously evaluated on multiple downstream tasks such as action recognition, video summarization, and anomaly detection. Assessing performance on these additional tasks would provide a more comprehensive view of the model's adaptability and generalizability\nThe paper discusses scalability but falls short of providing a detailed computational and memory complexity analysis. This is crucial for practical applications involving high-dimensional video data. The authors should include empirical evaluations that quantify the model's computational time and memory usage during both training and inference.\nQuestions:\nCould you elaborate on the choice of tasks for empirical evaluation? How do you envision the model's performance on other types of spatiotemporal tasks like action recognition or anomaly detection?\nHow does the model perform under conditions of noisy or incomplete data? Have you considered evaluations that specifically test the model's robustness?\nWhile the paper discusses scalability, it lacks specific metrics on computational and memory requirements. Could you provide more detailed analyses on these aspects?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer hjUh", "Subheading": "Official CommentbyAuthors19 Nov 2023, 11:58Everyone", "Content": "Comment:\nW1&Q1: Elaborate on the choice of tasks for empirical evaluation and envision the model's performance on other types of spatiotemporal tasks like action recognition or anomaly detection.\nA:\nThanks for your advice! We have conducted relative experiments to envision the model's performance in the revision.\nFor action recognition, the results are reported in Table 3 in our initial manuscript. We use the prompt template \"a person [CLASS]\" (e.g., a person running) for HMDB-51 [1], UCF-101 [2], Kinetics-400 [3], and Kinetics-600 [4], and evaluate SSV2 on a multi-choice setting, namely SSV2-MC. The detailed settings are stated in Appendix A. Our model brings significant improvements, i.e., 8.9%, 9.1%, 11.6% and 12.9% absolute gain on HMDB-51, UCF-101, Kinetics-400, Kinetics-600 and SSV2-MC respectively. The prompt-based method, i.e. ActionCLIP [5], also degrades on this test, possibly due to overfitting to manually constructed templates. When it turns to larger models, we even surpass X-Florecnce [6], a single-stream model with comparable video encoder parameters, by a large margin, revealing the superior scalability of our training paradigm. Even for the challenging SSV2-MC that contains various motion dynamics, our model still achieves promising results, solidifying the contribution of masked transcript sorting that promotes fine-grained spatiotemporal representation learning. In addition, we provide the liner classification results in Appendix D Table 13, where we surpass either  self-supervised or language-guided models.\nFor anomaly detection, we evaluate the performance on UCF-Crime [7] test split, which aims to recognize 13 anomaly events. According to Table 3 in our revised manuscript, our models also made remarkable improvements compared to the CLIP baseline and CLIP-ViP, unveiling their adaptability and generalizability.\n[1] HMDB: A large video database for human motion recognition, ICCV 2011\n[2] UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild, arXiv 2012\n[3] The Kinetics Human Action Video Dataset, arXiv 2017\n[4] A Short Note about Kinetics-600, arXiv 2018\n[5] ActionCLIP: A New Paradigm for Video Action Recognition, arXiv 2021\n[6] Expanding Language-Image Pretrained Models for General Video Recognition, ECCV 2022\n[7] Real-world Anomaly Detection in Surveillance Videos, CVPR 2018\nW2&Q3: Providing a detailed computational and memory complexity analysis during both training and inference.\nA:\nNice suggestion. We've updated our manuscript to include a comprehensive analysis of computational and memory complexity, which you can find in Appendix D Table 12. During the training phase, we optimized the batch sizes to fully utilize available GPU memory. Our analysis, especially the GFLOPs comparison between the video and text encoders, reveals that the most computationally intensive part is video encoding, particularly the spatiotemporal attention module. However, the use of an efficiently designed divided space-time attention mechanism ensures that even our largest model, i.e., ViT-H/14, can be run on consumer-level GPUs like the RTX 3090, thanks to its relatively modest memory requirements during inference.\nModel\nTraining BS $\\times$ GPU\nTraining Mem\nInference Mem\nVideo GFLOPs\nText GFLOPs\nB/32\n24 $\\times$ 32\n30.2 GB\n3.3 GB\n69\n3\nB/16\n12 $\\times$ 64\n27.5 GB\n4.5 GB\n278\n3\nH/14\n2 $\\times$ 80\n31.3 GB\n8.8 GB\n2650\n24\nQ2: How does the model perform under conditions of noisy or incomplete data?  Consider evaluations that specifically test the model's robustness.\nA:\nThanks for the constructive advice! To test the robustness of our model, we randomly mask some patches in each frame during inference to simulate corrupted data. The retrieval performance under different masking ratios on MSR-VTT is reported in Appendix Table  18. Thanks to the masked contrastive pre-training, our models are robust to data corruption. Impressively, even minor data distortions, such as 10% or 20% masking, do not significantly impact performance. More notably, our models demonstrate commendable robustness, maintaining considerable effectiveness even under substantial data incompleteness, with a masking ratio as high as 50%. This clearly underscores the reliability and adaptability of our models in handling corrupted data scenarios.\nModel\nMasking Ratio\nR@1\nR@5\nR@10\nMdR\nB/16\n0\n35.9\n61.2\n71.3\n3.0\n10\n35.4\n61.1\n71.0\n3.0\n20\n35.0\n60.6\n70.4\n3.0\n50\n32.6\n60.0\n69.9\n3.0\nH/14\n0\n38.2\n62.4\n73.2\n3.0\n10\n37.3\n62.1\n72.7\n3.0\n20\n36.0\n61.6\n72.1\n3.0\n50\n35.2\n60.4\n70.1\n3.0"}, {"Heading": "Looking forward to your feedback", "Subheading": "Official CommentbyAuthors21 Nov 2023, 23:10Everyone", "Content": "Comment:\nThanks for your insightful comments and acknowledgment of our work. Please kindly let us know if our response addressed your concerns. We are willing to respond to any further questions before the rebuttal ends\n(within 36 hours)\n:-)"}]}, {"Heading": "Official Review of Submission9381 by Reviewer tEsw", "Subheading": "Official ReviewbyReviewer tEsw30 Oct 2023, 20:44 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper, TVTSv2, is the second version of TVTS paper. It focuses on the foundation model of video representation learning. Specifically, this paper first points out the so called degradation issue existing in video representation field. Based on this degradation observation, this paper proposes a hypothesis that such degradation is from the noisy text data. Accordingly, it freezes the shallow layers of text encoder while training the deeper layers to alleviate this issue. In this way, the zero-shot performance is significantly improved to show the great generalization ability of the proposed training strategy. Very comprehensive experiments empirically validate the model effectiveness.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nVideo representation learning is a very challenging task, especially for large-scale scenario. I recognize such an exploration in this field.\nThe stated degradation issue is interesting observation. Proposing solution based on it is well-motivated.\nThe large-scale experiments are definitely an advantage of this work. They cover several evaluation scenarios.\nWeaknesses:\nI mainly concern about the technical contribution. As mentioned in the draft, the proposed degradation-free training strategy freezes the shallow layers while tuning the deeper layer of text encoder. This training strategy is more like an engineering trick by tuning parts of the large-scale model, which can be commonly used for practical large-scale training.\nQuestions:\nPlease refer to above sections for details. As mentioned in the weakness part, I mainly concern the technical contribution. On the other hand, I recognize the other parts of contribution of this paper. I would like to encourage the author to further emphasize the technical contribution of this paper for discussion. In addition, I am also willing to check other reviewers' comments for my final decision.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer tEsw", "Subheading": "Official CommentbyAuthors19 Nov 2023, 12:06Everyone", "Content": "Comment:\nW1: Concern about technical contribution. The degradation-free training strategy is more like an engineering trick.\nA:\nThanks, we are willing to highlight the technical merits of our work, both from\nexperimental results\nand the\nunderlying motivation\n.\n(i)\nExperimentally, to demonstrate that our degradation-free training strategy goes beyond a mere engineering workaround, we introduced an alternative baseline. This baseline involves a ViT-B/32 model equipped with adapters [1] (M$ _{\\text{adapter}}$) inserted between layers of the text encoder, where only the adapter-introduced parameters are adjustable during training. The retrieval results on MSR-VTT, detailed in Appendix D Table 16, show that this approach is inferior to our method. This reinforces our assertion that end-to-end tuning can lead to style overfitting, even when the text encoder remains unchanged, proving that our partially frozen strategy is not a simplistic fix but a considered solution.\n(ii)\nFrom a motivational standpoint, scalability remains a significant and challenging research area, as recognized by Reviewer hjUh. This field is marked by several pioneering works featured in leading conferences, like VideoMAE V2 [2] and FLIP [3]. In our view, it is the simplicity and efficacy of these methods that render them ideal as foundational models, requiring minimal code adjustments for integration into existing frameworks. Upon acceptance, we plan to release all relevant codes, pre-trained models, and well-crafted APIs for immediate application. We are confident that these foundational models will greatly benefit the broader community, particularly academic institutions with limited resources for large-scale experiments. Our contributions, we believe, merit recognition at prestigious conferences such as ICLR.\nMethod\nR@1\nR@5\nR@10\nMdR\nCLIP\n30.6\n54.4\n64.3\n4.0\nM$ _{\\text{ours}}$\n34.5\n58.5\n67.7\n3.5\nM$ _{\\text{adapter}}$\n28.8\n54.8\n65.7\n4.0\n[1] Parameter-Efficient Transfer Learning for NLP, ICML 2019\n[2] VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking, CVPR 2023\n[3] Scaling Language-Image Pre-Training via Masking, CVPR 2023"}, {"Heading": "Looking forward to your feedback", "Subheading": "Official CommentbyAuthors21 Nov 2023, 23:08Everyone", "Content": "Comment:\nThanks for your constructive advice. We value your comments and have made efforts to revise the paper. Please kindly let us know if our response addressed your concerns. We are willing to respond to any further questions before the rebuttal ends\n(within 36 hours)\n:-)"}]}, {"Heading": "Official Review of Submission9381 by Reviewer A6Wr", "Subheading": "Official ReviewbyReviewer A6Wr30 Oct 2023, 17:00 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a video foundation model called TVTSv2 for learning out-of-the-box spatiotemporal visual representations.\nIt aims to solve the issue of performance degradation compared to image foundation models when adapting them to video.\nThe degradation is attributed to distortion in language supervision from end-to-end tuning of the text encoder on noisy ASR transcripts.\nA partially frozen text encoder is proposed, freezing shallow layers while tuning deep layers, to retain generalization and learn new semantics. The authors state that SOTA results were achieved on zero-shot action recognition and text-to-video retrieval: TVTSv2 surpasses recent methods like CLIP-ViP, ImageBind, and InternVideo on several metrics. Ablations showed partially frozen text training avoids degradation and enables knowledge transfer. Masking was shown to improve efficiency for large models without sacrificing too much performance. Fine-tuning performance was also competitive, suggesting the approach does not hurt downstream training.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe strengths of the paper include:\nProduces strong out-of-the-box spatiotemporal representations for zero-shot usage and surpasses recent state-of-the-art methods substantially in zero-shot action recognition, including models trained on more data.\nAchieves new state-of-the-art results on multiple video understanding benchmarks.\nProvides an effective strategy for pre-training on large, noisy video transcript datasets as it retains performance on downstream fine-tuning, unlike some other self-supervised methods.\nThe approach facilitates scaling up to large models by incorporating masking techniques. It avoids catastrophic forgetting of language knowledge via partially frozen training\nIn conclusion, the paper strongly suggests potential for pre-trained models to support out-of-the-box video applications.\nThe claims seem reasonably well supported by the results, as the proposed TVTSv2 models clearly surpass prior state-of-the-art in zero-shot action recognition and retrieval across multiple datasets. The ablation studies also provide evidence for the benefits of the partial freezing strategy and incorporation of masking techniques.\nWeaknesses:\nLimitations:\nThe paper is a bit disorganized. THe architecture is followed by the empirical study followed by further description of the model (trainig objectives etc.). It would read better if the approach description was in one place. If the empirical degradation study calls for rmodification of the training objective, that should be spelled out more explicitly. \nThe attention masks in hte figures are used as an argument for good performance. However, it is not clear what woud be the ground truth atteniton mask. COuld it be that in the video clips the objeects/actions of interest were the only moving parts in the scene causing the attention grab?\nThe joint attention module is not described clearly. Is it the same as in CLIP?\nFine-tuning performance was not extensively benchmarked on more diverse downstream tasks, so the claims about out-of-the-box task-agnostic approach could be substantiated better.\nThe largest model studied is still limited compared to huge image models, so scalability past 1 billion parameters is unvalidated.\nPotential societal impacts of large foundation models were not addressed.\nQuestions:\nWas any experimentation done with different freeze ratios or objectives for the text encoder?\nHow much performance gain was directly attributable to the partially frozen text training versus other modifications?\nThe narrative around the attentional maps could be stronger.\nWhat can the authors say about model biases? Are actions of all sexes/races recognized at comparable accuracy?\nMore extensive evaluation of fine-tuning performance on diverse downstream tasks would be desirable for supporting the \"out-of-the-box\" claim.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer A6Wr", "Subheading": "Official CommentbyAuthors19 Nov 2023, 12:11Everyone", "Content": "Comment:\nW1: The paper is a bit disorganized.\nW1.1: It would read better if the approach description was in one place.\nA:\nThanks for the advice. We have reorganized the paragraphs and put the approach description together in the revised version.\nW1.2: If the empirical degradation study calls for modification of the training objective, that should be spelled out more explicitly.\nA:\nThe empirical degradation study is disentangled from the training objective, and it corresponds to the partially frozen pre-training strategy. Sorry for the confusion, we have reorganized the paragraphs to make readers easier to follow.\nW2: It is not clear what the ground truth attention mask is. Could it be that in the video clips the objects/actions of interest were the only moving parts in the scene causing the attention grab?\nA:\nThat's an insightful query. Indeed, selectively masking objects or actions that are semantically linked could potentially enhance model performance. However, creating accurate ground truth masks for this purpose is a labor-intensive task, especially considering the scale of pre-training that involves millions of videos. Therefore, we've opted for a more feasible approach: employing a random masking strategy that does not depend on ground truth data. Despite its simplicity, this method proves quite effective due to the vast amount of training data we use. Our models demonstrate excellent out-of-the-box performance, highlighting the capability of this straightforward technique to learn robust representations (Appendix D Table 18).\nW3: The joint attention module is not described clearly. Is it the same as in CLIP?\nA:\nNo, we adopt the divided space-time attention instead of the joint attention. An illustration of the detailed architecture is provided in Appendix C Figure 3. For the intra-frame tokens, i.e., spatial-related tokens, we add the same spatial positional embeddings, and for tokens at the same position across different frames, i.e., temporal-related tokens, we add the same temporal positional tokens. For each token, it first attends to the temporal-related tokens, then attends to the spatial-related tokens. Note that the [CLS] token is attended in both temporal and spatial self-attention.\nIn addition, we also compared the performance between CLIP-style joint attention and the divided space-time attention. Please refer to Appendix D Table 19 for details.\nW4&Q4: More extensive evaluation of fine-tuning performance on diverse downstream tasks would be desirable for supporting the \"out-of-the-box\" claim.\nA:\nThank you for your insightful feedback. In our paper, the phrase \"out-of-the-box\" refers to creating versatile video representations that can be immediately applied to various downstream tasks without the need for further fine-tuning. Our goal is to offer such foundational models to the community, potentially accelerating its progress by eliminating the need for costly pre-training and fine-tuning.\nWe value your advice and recognize that a strong out-of-the-box representation should yield good fine-tuning performance. To this end, we conducted basic fine-tuning of our pre-trained models on DiDeMo and LSMDC datasets, deliberately avoiding complex techniques like optimal parameter searching. The findings, presented in Appendix D Table 15, indicate that our straightforward approach does enhance fine-tuning performance to a certain extent. Furthermore, we have included linear classification results where a classifier was trained on top of the frozen model backbone. Our models outperform both self-supervised and language-guided models in these tests, as detailed in Appendix D Table 13. This further demonstrates the effectiveness and versatility of our proposed training methodology."}, {"Heading": "Response to Reviewer A6Wr (cont.)", "Subheading": "Official CommentbyAuthors19 Nov 2023, 12:23Everyone", "Content": "Comment:\nW5: The largest model studied is still limited compared to huge image models, so scalability past 1 billion parameters is unvalidated.\nA:\nWe admit there is uncertainty about the scalability for larger models. However, training large models requires substantial training costs, which we find a bit hard to afford for models with more than 1B parameters. For example, InternVideo uses 128 A100-80G and trains for two weeks, while VideoMAE V2 uses 64 A100-80G for around ten days. In our case, we use 80 V100-32G and train for 10 days. We have 18 ablation studies in the main paper and Appendix in total to figure out the best scalable training recipe. We follow the common practice in the community (e.g., InternVideo and VideoMAE V2) to conduct ablation studies on the base-size model and directly scale up to larger models with the best recipe. Note that successfully obtaining performance gains compared to the baseline counterparts (CLIP in our work) on large models is non-trivial and already verified the effectiveness of our strategy to a large extent, as shown in the following Table.  Besides, to our best knowledge, the released ViT-H/14 model is one of the largest open-sourced video models, anticipated to significantly advance the boundaries of research in this field.\nMethod\nMSR-VTT R@1\nMSR-VTT R@5\nMSR-VTT R@10\nMSR-VTT MdR\nKinetics-400 Top-1 Acc\nKinetics-400 Top-5 Acc\nSSV2-MC Top-1 Acc\nSSV2-MC Top-5 Acc\nCLIP-H/14\n36.1\n60.4\n70.7\n3.0\n52.0\n79.1\n40.2\n69.2\nOurs-H/14\n38.2\n62.4\n73.2\n3.0\n59.6\n84.1\n48.4\n77.0\nW6: Potential societal impacts of large foundation models were not addressed.\nA:\nThanks for the reminder. We have added a \"Broader Impact\" section to Appendix E in the revised version. The negative social impacts of our model may lie in intensifying global warming because of the large amount of carbon emission produced by GPU clusters. Though the pre-training phase is energy-consuming, the model can be used out-of-the-box, saving the potential carbon emission in fine-tuning. Since the model produces general-purpose representations, it might also raise the risk of abuse, such as unauthorized biometric recognition.\nQ1: Was any experimentation done with different freeze ratios or objectives for the text encoder? How much performance gain was directly attributable to partially frozen text training versus other modifications?\nA:\nTo evaluate the impact of varying the freezing ratios in the text encoder, we experimented with different numbers of tunable layers and observed their performance differences. As shown in Table 5 (b) of our revised manuscript, models with either completely fine-tuned (L$ _{\\text{tune}}$=12) or entirely frozen text encoders (L$ _{\\text{tune}}$=0) underperform compared to those with partially frozen encoders. This result solidly supports the efficacy of our proposed degradation-free pre-training strategy.\nRegarding training objectives, we consistently applied the basic Video-Text Contrastive objective (L $ _{\\text{VTC}}$) and explored the impact of including the Transcript Sorting objective (L$ _{\\text{TS}}$) on the text encoder. The findings, presented in Table 4, demonstrate that models without gradient stopping (indicated as \"sg\") towards the text encoder, such as M$ _{\\text{w/o sg}}$, are less effective than our approach (M$ _{\\text{ours}}$). This suggests that L$ _{\\text{TS}}$ encourages the text encoder to develop shortcuts, optimizing transcript representation in ways that ultimately hinder training efficiency. Thus, we conclude that L$ _{\\text{TS}}$ should not be used to optimize the text encoder.\nThe advantages of partially freezing the text encoder during training are evident in two aspects:\n(i)\nTable 1 compares L4 with L7 and L5 with L8, showing that partially frozen variants significantly outperform their fully tuned counterparts.\n(ii)\nIn Table 5 (b), the fully fine-tuned model (L$ _{\\text{tune}}$=12) falls behind the partially frozen models (L$ _{\\text{tune}}$=3 and L$ _{\\text{tune}}$=6), further highlighting the benefits of this approach."}, {"Heading": "Response to Reviewer A6Wr (cont.)", "Subheading": "Official CommentbyAuthors19 Nov 2023, 12:26Everyone", "Content": "Comment:\nQ2: The narrative around attentional maps could be stronger.\nA:\nThank you for bringing this to our attention. We regret the earlier exclusion of Figure 1 (b) from our manuscript. In Figure 1 (b), we visualize the zero-shot self-attention map of the visual [CLS] token. It effectively highlights how our model precisely captures key spatiotemporal elements, such as the cake being held and the two small dogs near the people, demonstrating the model's remarkable out-of-the-box transferability. We've updated our manuscript to include a discussion on this aspect. Additionally, to provide a more thorough understanding of our model's capabilities, we have included additional visualization results in Appendix D Figure 4.\nQ3: Concerns about model biases. Are actions of all sexes/races recognized at comparable accuracy?\nA:\nWe acknowledge the importance of ensuring minimal bias in our foundational models before their release. Addressing your concerns, we carefully selected 30 videos from Kinetics-400, ensuring a balanced representation of male and female subjects, as well as individuals of black, yellow, and white racial backgrounds. We then evaluated the zero-shot action recognition accuracy (counted by the correct predicted video number, e.g., 16/30) of these videos, with results tabulated in the subsequent table. Owing to the diverse and extensive open-domain training corpus we utilized, the accuracy rates across different demographic categories are notably similar. This consistency suggests that our model is likely to exhibit minimal bias towards any specific group, thereby upholding our commitment to fairness and inclusivity in model development.\nModel\nMale\nFemale\nBlack\nYellow\nWhite\nOurs-B/16\n16\n17\n14\n15\n17\nOurs-H/14\n20\n20\n17\n18\n21"}, {"Heading": "Looking forward to your feedback", "Subheading": "Official CommentbyAuthors21 Nov 2023, 23:11Everyone", "Content": "Comment:\nThanks for your insightful comments and acknowledgment of our work. Please kindly let us know if our response addressed your concerns. We are willing to respond to any further questions before the rebuttal ends\n(within 36 hours)\n:-)"}]}]}, "SLw9fp4yI6": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Controlled text generation, LLM, Natural Language Processing", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We provide a principled and intuitive way to combine multiple LLMs and bias them towards and away from attributes.", "Abstract": "As Large Language Models (LLMs) are deployed more widely, customization with respect to vocabulary, style, and character becomes more important. In this work, we introduce model arithmetic, a novel inference framework for composing and biasing LLMs without the need for model (re)training or highly specific datasets. In addition, the framework allows for more precise control of generated text than direct prompting and prior controlled text generation (CTG) techniques. Using model arithmetic, we can express prior CTG techniques as simple formulas and naturally extend them to new and more effective formulations. Further, we show that speculative sampling, a technique for efficient LLM sampling, extends to our setting. This enables highly efficient text generation with multiple composed models with only marginal overhead over a single model. Our empirical evaluation demonstrates that model arithmetic allows fine-grained control of generated text while outperforming state-of-the-art on the task of toxicity reduction. We release an open source easy-to-use implementation of our framework athttps://github.com/eth-sri/language-model-arithmetic.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "generative models", "Submission Number": "9377", "PDF Url": "https://openreview.net/pdf?id=SLw9fp4yI6"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (spotlight)"}, {"Heading": "Meta Review of Submission9377 by Area Chair YLtW", "Subheading": "Meta ReviewbyArea Chair YLtW10 Dec 2023, 21:24 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe submission introduces a new method for controlled text generation through 'language model arithmetic', in which different models and classifiers are combined to give fine-grained control over generation. Reviewers found the approach to be novel, elegant and well motivated. It's great that the paper gives both theoretical motivations and more practical compatibility with speculative sampling for efficient inference. The main limitation is the relatively narrow scope of the evaluation, which focuses on toxicity and (in the revision) sentiment. Overall this is a creative and interesting paper that I recommend for acceptance.\nJustification For Why Not Higher Score:\nLimited evaluation\nJustification For Why Not Lower Score:\nI think some people will find this pretty interesting, so might be worth a spotlight"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 04:25Everyone", "Content": "Comment:\nWe thank the reviewers for their feedback and comments. In particular we are delighted that they found model arithmetic to be an interesting (bqfK) and inventive (Gru5) method that unifies multiple prior approaches (dPAm, Ne4m), supported by interesting theoretical underpinnings (Ne4m, Gru5) and promising experiments (especially on toxicity reduction \u2013 bqfK, dPAm, gF67, Gru5).\nHere we briefly outline the changes made to the manuscript and recurring points in the reviews.\nChanges to the Manuscript\nExtended Evaluation\nWe use GPT-4 to compare our toxicity reduction results with the strongest baseline, PreAdd, to validate our conclusions. See Table 6 of Section 5.1.\nInclusion of the GPT-2 model family on the toxicity task in Appendix I.1\nAdditional evaluation of model arithmetic on sentiment control in Appendix F.\nWe included the perplexity plots for the conversational task in Section 5.2 in Appendix I.2 and included randomly selected samples.\nWe updated several numbers in Table 5 for the toxicity reduction task.\nWe adjusted the biasing coefficient for PreAdd to 0.6 instead of 0.5 in Section 5.1 after a more thorough search for the optimal parameter of this baseline.\nWe fixed a minor bug in our code that caused approximation errors when using very high strengths for the Pythia-12b and MPT-7b models. To ensure reproducibility, we reran all experiments which did not significantly alter the results for other methods.\nWe also made minor edits to fix typos and enhance grammar.\nQ1: Can you compare Model Arithmetic and baselines using GPT-4?\nCertainly! We included an analysis by GPT-4 comparing our results with the strongest baseline, PreAdd, to validate our results. We presented GPT-4 with continuations of both methods and prompted it to reason about the replies and select the better continuation.  We found that GPT-4 also prefers our method over PreAdd for all evaluated models, both when we only use the union operator (6% average difference) and when we combine both the union operator and the classifier (8% average difference). We present these results in Table 6 of Section 5.1\nQ2: Can you broaden the scope of the evaluation further to another task found in prior CTG work?\nOf course! We included an extra experiment evaluating model arithmetic on sentiment control in Appendix F showing that our method also outperforms existing work on this task as well. Closely following the setup used by PreAdd, we evaluate the ability to change the sentiment of a movie review given the first few sentences. We find our union operator again significantly outperforms prior work. Using GPT-4, we find that it is preferred over the best baseline, PreAdd, in all cases with an average lead of 5%.\nFurthermore, we find that combining the union operator with the classifier as in the toxicity reduction task massively outperforms all baselines, and is preferred by GPT-4 over the best baseline in all cases with an average lead of 12%.\nQ3: Can you include other prior work in your evaluation for the toxicity reduction task?\nWe currently compare our method with SelfDebias, Fudge and PreAdd, which form a representative sample of existing prior work. Other prior work focuses on different settings and applications. Most prior research requires training data, while we focus on the zero shot regime. This excludes methods such as DExperts, GeDi and Quarks which all rely on expensive finetuning with training data for the task at hand. Furthermore, DExperts and GeDi require the existence of a small language model from the same model family, which does not exist for two of the three evaluated models.\nOther methods that do not require training data often require expensive backward passes through the language model during generation. These approaches are therefore impractical and do not generalize to larger models. Moreover, most prior approaches were specifically implemented for GPT-2, requiring non-trivial adaptations and changes of their codebases to make them work for larger and more modern models.\nQ4: Can you provide an explanation on how the formulas presented in the text were constructed?\nBased on our theoretical results we found it easy to choose coefficients in the formulas intuitively as relative strength. The examples provided throughout our paper (e.g., Table 5) were all constructed by relying on this interpretation without requiring finetuning of the constants. Intuitively chosen constants typically align well with the intended outcome, without requiring extensive tweaking. For example, while the coefficient in front of the classifier term (e.g., Table 5) might seem unintuitive, it ensures that the relative strength of the classifier is $1$ (as in Fudge). Prompts were not changed after initialization and specifically chosen to be simple, since we want to avoid extensive prompt tuning in our setting, to better demonstrate the benefits of model arithmetic at a foundational level."}, {"Heading": "Official Review of Submission9377 by Reviewer bqfK", "Subheading": "Official ReviewbyReviewer bqfK10 Nov 2023, 23:57Everyone", "Content": "Summary:\nThis paper proposes an inference framework for composing and biasing LLMs without training on task-specific datasets, which may allow for more precise control of generate text. Speculative sampling, which is a popular technique for LLMs, can also extend to the proposed method. Experimental results demonstrate that the proposed method outperforms several baselines on the task of toxicity reduction.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe proposed method based on model arithmetic is interesting and general.\nExperimental results show its effectiveness on toxicity reduction and fine-grained controlled text generation tasks.\nWeaknesses:\nThe proposed method needs heavy human design for specific tasks. The formulas for toxicity reduction (Table 5) and fine-grained control (Section 5.2) is not intuitive. I wonder whether there is a principle or a theoretically-supported method to choose operators and determine their coefficients for different tasks. If these are just empirical tries, the applicability of the proposed method may be largely degraded.\nThe position of this paper needs to be further considered. In my view, the proposed method seems like a general form of existing works because the operators based on linear combinations and classifiers are not first proposed by this paper. They have been already studied in the line of work on controlled text generation. The current position may exaggerate the contribution and novelty of the proposed method.\nQuestions:\nI have included my questions in the weaknesses part.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 04:26Everyone", "Content": "Comment:\nWe thank the reviewer for their insightful questions, which we address below and are encouraged to hear that they find model arithmetic to be interesting and the experiments to show its effectiveness.\nQ: Can [model arithmetic] operators and their coefficients be determined in a theoretically-backed manner?\nAs discussed in Q4 of our main reply, we used Theorem 1 in our paper to choose parameters and terms in a theoretically grounded manner. This allowed us to quickly and intuitively construct formulas for all the examples presented in the entire paper, such as the ones in Figure 1, Table 2, Table 3, Table 4 and Table 17, without any finetuning of the coefficients being required. We note it is possible to determine the coefficients by optimizing them via gradient descent on a small number of samples. However, in the paper we focus on applications in the zero-shot setup and we found that a correct ballpark for all our examples was sufficient without requiring any finetuning.\nQ: Can you clarify the contributions and novelty of the proposed method?\nSure! Model arithmetic improves in several ways over prior work:\nFirst, previous works (using log probabilities) lack theoretical foundations when it comes to model biasing, which often prevents the introduction of multiple attributes. In contrast, our work addresses this by framing CTG as a minimization problem, finding the correct normalization required to bias towards more than one attribute and providing a natural extension to prior work. This allows us to express a lot of existing methods, provides a theoretical foundation for their constructions and naturally extends CTG \u2013 for the first time \u2013 to more complicated and relevant examples, such as for the conversational styles discussed in Section 5.2.\nSecond, our theoretical framework enables us to combine classifiers and linear operators and thereby allows for a higher flexibility with better results as shown in Section 5.1. Further, we introduce the novel operator, union, which has better results on the task of toxicity reduction and sentiment control and can be used on top of the other operators we use.\nThird, our use of speculative sampling allows us to use model arithmetic at only a slightly increased cost compared to normal single-model generation. This approach can be used directly, also with prior work, and therefore speeds up any method that we can express.\nWe hope to have been able to address all the reviewers\u2019 concerns, are happy to answer any follow-up questions they might have, and are looking forward to their reply."}]}, {"Heading": "Official Review of Submission9377 by Reviewer dPAm", "Subheading": "Official ReviewbyReviewer dPAm08 Nov 2023, 19:36 (modified: 22 Nov 2023, 21:48)EveryoneRevisions", "Content": "Summary:\nTL;DR\nThis paper generalizes a number of model control techniques to combine different token and classifier distributions as generalized \u201cLanguage Model Arithmetic\u201d expressions that can evaluate arbitrary linear combinations of token probability distributions, binary classifiers, and token distributions combined with union and intersection operators. Furthermore the authors show that speculative sampling can be used to make this process quite efficient. Experiments on toxicity reduction, topic control, and efficiency validate these properties. The paper is well-written and unifies different methods under a novel framework that pushes forward new possibilities. Results are less thorough than I would have hoped, but I believe this paper deserves to be accepted.\nThe paper begins by discussing the downsides of prompting as a method of controlling text generation, referencing past work that has shown that prompting is not reliable, efficient, or interpretable. They then suggest that doing a kind of \u201cmodel arithmetic\u201d where different distributions are composed via an altered version of speculative sampling can result in distributions that match the original intention of the user, though how one decides on the arithmetic formula for models is left unspecified. Necessary background is then reviewed.\nFor their first contribution, the authors describe a framework for weighting various predictions more or less depending on how \u2018important\u2019 they are for some externally defined purpose, as represented by weighting functions f_i. They then prove that given that the sum of weights f_i is positive and independent of which token is being weighted, they can find a weighting that minimizes the KL divergence through a simple softmax computation. While intuitive in retrospect, this is quite an interesting insight when framed as a method of control. They use this framing and result to define Language Model Arithmetic as an arithmetic combination of different weighting functions and distributions that meet the previously described assumptions. It is an elegant trick to first ensure that the weighting functions add up to a constant value to find an easy minimization, and then use further weightings to control what distribution is being optimized for, and the authors describe this method quite clearly.\nHaving described this approach, the authors show how previous controlled text generation methods can actually be expressed in their framework. So far, the authors have only described linear combinations of different token-level distributions, but the authors also show that a binary classifier can be added to the optimization, since we can convert minimizing the classifiers value to a difference of two KL divergence terms. This allows Language Model Arithmetic to further generalize past approaches. However, it\u2019s worth noting that in practice approximations must be used since the described theorems only apply when a distribution based on classifying\nevery possible next word in the vocabulary\ncan be computed, which is generally very expensive since vocabularies are often in the tens or even hundreds of thousands. To be fair, previous work with similar methods also had to approximate the full distribution by using only the top-k highest probability tokens, so while this is a flaw, it is no worse than previous methods.\nNext the authors introduce the union operator for Language Model Arithmetic (and briefly mention the unused intersection operator), which essentially takes distributions Q_1 and Q_2, and expresses an optimization objective to maximize the probability per token under the max given by either Q_1 and Q_2. This is achieved by attaching an indicator function to KL divergence terms, that is non-zero for Q_1 only when its KL divergence is lower for a certain token than Q_2 and vice versa.\nThe authors then move on to showing that speculative sampling, a method recently invented to allow sampling from a cheaper proposal distribution by validating from a target distribution and resampling where necessary, can be generalized to sampling from Language Model Arithmetic expression. In short the authors propose to use individual terms in Language Model Arithmetic expressions as proposal distributions and target distributions that are chained together to sample from the full expression of the desired distribution combination. This only works with full token distributions, but binary classifiers can be used at the first step to essentially limit the hypothesis space. This creates a caveat where multiple binary classifiers can\u2019t be chained together efficiently.\nExperimental validation is done in three parts: toxicity reduction, fine grained control over text generation topics, and speed improvements from speculative sampling.\nFor toxicity reduction, the results shown in Table 5 convincingly show that by combining multiple of the proposed techniques for Language Model Arithmetic, toxicity in generated text (at least according to the given classifier) while achieving lower perplexities than previous methods. The authors show that using large coefficients in Language Model Arithmetic eventually degrades perplexity, but show that multiple different coefficients still perform decently. A more thorough study of sensitivity of Language Model Arithmetic to different coefficients and expressions would have made this set of experiments more convincing.\nFor fine grained controlled text generation, the authors show that over two different Language Model Arithmetic expressions, linearly increasing the strength of a component linearly increases classifier scores for that component over generated text. The one exception is the \u201csports\u201d topic, which is sigmoidal, but still shows relatively clear control. While these experiments are positive. I feel that they could have been shown and done more thoroughly. For instance, three things I would have liked to see:\nAccompanying perplexity graphs to the shown classifier results that  validate whether the model continues to generate sensical text rather than just \u201cfootball football football\u201d, which seems like it may indeed happen at some point given the high perplexities in the toxicity reduction section.\nOnly two different Language Model Arithmetic expressions are tested. They are interesting, complex expressions, but one big question that\u2019s left unanswered is how much fiddling has to be done to find the right Language Model Arithmetic expression? If the complexity of prompting is replaced by the complexity of finding the right expression, then this is less of a win for the proposed method.\nIt would be useful to see what happens when multiple lambda values are changed and whether interference becomes too strong after a certain point.\nThe results in this section are nice, and they are partially substantiated by being a generalization of previous methods, but they feel a little thin.\nFor the final set of results, the authors show that using speculative sampling makes the problem of evaluating Language Model Arithmetic expressions for generation much less onerous. In particular, the metric of \u201cmodel calls per token\u201d is focused on (which I think is exactly the right metric, as it scales with model size). The authors show that model calls per token is reduced with speculative sampling and that this reduction only grows with more complex formulas, which is a big win. It seems that this is because successive terms in a Language Model Arithmetic formula affect the result less, as there is a limited distribution of options that will be possible given that some achieve extremely low probability under certain distributions. It would be interesting to see if the order of evaluation could be optimized, since terms with large coefficients will likely save more time if evaluated first.\nRelated work that was not mentioned in the background or fully connected to the proposed method are reviewed, and the paper concludes.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n4 excellent\nStrengths:\nLanguage Model Arithmetic as expressed seems to be an elegant generalization of a number of past approaches, while adding significantly more expressivity.\nThe use of speculative sampling to speed-up evaluation of what is usually quite costly multi-model inference, in a way that scales better the more models are being sampled from is clever and very promising.\nThe results, while somewhat more limited than I would have hoped, are promising.\nThe paper is well-written and connects to previous work while showing its novelty. The appendices are thorough and I found all the details I was looking for when double-checking the finer points of method and evaluation.\nWeaknesses:\nThe biggest weakness of this paper is the lack of a more thorough evaluation. I think this breaks down into three categories:\nLack of finer grained analysis of generation.\nNeither a human or an LLM-backed evaluation (e.g., with GPT-4) was done, only classifier and perplexity based evaluations (where perplexity is taken under the original vanilla language model). This means that text could be qualitatively strange in some capacity, and none of the evaluations would show it as long as the original model is not too surprised by it. I find this somewhat worrying, as the problem with many model control techniques is the fact that they collapse onto strange parts of the distribution that are low perplexity but still wrong, e.g. the repetition with greedy and beam search.\nLack of different generative scenarios.\nWhile section 5.2 shows fine grained control over the generated topic, this is an extremely limited generation scenario where all the model has to do is speak about a specific topic. Evaluation on controlled generation, personalized summarization or translation, coherent essay writing, or any somewhat more defined generation scenario would have made evaluation more convincing.\nLack of exploration of the space of possible expressions.\nThe authors present an extremely general method for constructing interesting distributions to sample from, but only test a handful. It would be disappointing if it turned out that this technique is extremely brittle to the specific Language Model Arithmetic expression that is used, which would simply have transported the complexity of prompting to the complexity of finding the right arithmetic expression. The results in the paper do not suggest this is the case, but evaluate only 4 different expressions for quality, with the rest of the results only changing the coefficient values or testing speed.\nQuestions:\nN/A\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 04:28Everyone", "Content": "Comment:\nWe thank the reviewer for their extensive review and insightful questions, which we address below. We are delighted to read that they find our work well-written, model arithmetic to be an elegant generalization of prior work and our experiments to be promising.\nQ: Can you include GPT-4 or human evaluation?\nWe included an evaluation by GPT-4 validating our results for both the toxicity reduction (see Table 6, Section 5.1) and sentiment control (see Table 10 and 12, Appendix F) tasks as a surrogate for human evaluation. We find that GPT-4 confirms our results and prefers our method over prior work. For further details, please see Q1 and Q2 of our main reply.\nQ: Can you further explore a more defined generation scenario, such as personalized translation?\nWe included an extra evaluation section in Appendix F on sentiment control, a task commonly found in prior work (Pei et al. 2023, Liu et al. 2021, Krause et al. 2020). We find that model arithmetic significantly outperforms prior approaches for this task, as discussed in more detail in Q2 of our main reply.\nQ: Can you provide the perplexity graphs for the results in Section 5.2 to ensure that results remain sensible?\nWe included plots for the perplexity of the formulas in Section 5.2 in Appendix I.2. As expected, perplexity smoothly changes over different parameter values. Further, perplexity overall remains under the reasonable value of $6.2$ compared to $4.8$ by the highest prompted model.\nManual inspection of the data generated by the extreme points shows that the generated text is still fluent and the unprompted model $M$ associates a slightly higher perplexity to the text due to the high presence of an uncommon attribute that would normally not appear in the generated text by $M$. The only exception here is the educational topic, which uses a classifier with a very high weight ($12.0$) for which we found that a word sometimes gets replaced by a nonsensical one.  We now also include several randomly selected examples of texts generated by the model under these high parameters in Appendix I.2. These examples show the various characters produced by the formulas and show that the generated output is still fluent.\nQ: Is it possible that the proposed technique is brittle to the specific language model arithmetic expressions used?\nWe never encountered any brittle behavior while evaluating and testing on a wide variety of expressions, both in the examples presented in Figure 1, Table 2, Table 3, Table 4 and Table 17 and in the various expressions presented in Sections 5.1, 5.2, 5.3 and Appendix F. Only for the educational attribute in Section 5.2 we found a decreased fluency when using the classifier at very high strengths. We specifically evaluated the expressions from Sections 5.1, 5.2 and Appendix F for perplexity and attribute presence and always found that the formula acts as expected. Furthermore, manual inspection of data generated in all sections shows that generated results are still fluent and do not showcase any weird artifacts with the exception of the slight decrease in fluency for the classifier in Section 5.2.\nQ: How much tweaking do the model arithmetic expressions require?\nAs discussed in Q4 of our main reply, we rely on Theorem 1 and the interpretation of coefficients as relative strengths to construct the formulas for all examples in the paper. This allowed us to easily choose the right ballpark for the examples shown in the paper without requiring any further tweaking.\nQ: Does model arithmetic just shift the complexity of finding the right prompt to finding the right expression?\nAs noted in the previous answer, finding the right expression is relatively simple. More importantly, we note that formulas are more powerful than prompts and therefore do not just shift the complexity to finding the right expression, as shown by our results on toxicity reduction (see Section 5.1) and sentiment control (see Appendix F), and by examples showcasing interesting possibilities such as overstressing a specific attribute by biasing away from the standard model output (see e.g., Table 2) and using a classifier to generate more human-like text (see e.g., Table 3).\nQ: Can the order of evaluation for speculative sampling be optimized, since terms with large coefficients will likely save more time if evaluated first?\nYes, terms with higher coefficients are evaluated more often with our speculative sampling method. Terms that have a higher influence on the output distribution, have a higher probability of rejecting a specific token after their evaluation, ensuring that the optimal speculative factor, according to the procedure outlined in Appendix E.1, is lower. This implies that these terms are evaluated more often in the sampling procedure."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 04:28Everyone", "Content": "Comment:\nQ: What happens when multiple $\\lambda$ values are changed?\nChanging multiple $\\lambda$ values at the same time would not significantly change our results. As the strength parameters only influence the output distribution by their relative value compared to each other (see the normalization in Theorem 1), increasing several values of $\\lambda$ at the same time does not change the relative comparison that much and therefore has little effect on the output distribution. However, if we were to increase two specific terms at the same time, their relative strengths would both increase and thus the attribute associated with both of these terms would increase in presence.\nQ: Can interference become too strong after a certain point for the experiments in Section 5.2?\nMuch higher values of $\\lambda$ will eventually result in the degradation of fluency. However, this only starts to happen in extreme cases. When using only positive coefficients in the formula, we interpolate between two distributions and therefore never get any degraded fluency. It is only when using very strong negative coefficients, or when using a very high coefficient with a classifier that fluency starts to degrade. This is to be expected based on the optimization problem: strong negative coefficients will maximize the associated KL-divergence and thus decrease fluency if the other terms are not strong enough to compensate for that effect.\nWe hope to have been able to address all the reviewers\u2019 concerns, are happy to answer any follow-up questions they might have, and are looking forward to their reply."}, {"Heading": "Official Comment by Reviewer dPAm", "Subheading": "Official CommentbyReviewer dPAm22 Nov 2023, 21:49Everyone", "Content": "Comment:\nThank you for the very thorough answer to my questions! After reviewing the paper with these answers and added results, I feel more confident. I still feel the scope of tasks is somewhat limited, so I don't feel comfortable raising my score to a 10, but I think this is a solid paper and definitely deserves to appear in the conference."}]}, {"Heading": "Official Review of Submission9377 by Reviewer Ne4m", "Subheading": "Official ReviewbyReviewer Ne4m08 Nov 2023, 07:30 (modified: 22 Nov 2023, 07:21)EveryoneRevisions", "Content": "Summary:\nThis paper introduces \"model arithmetic,\" a framework for combining multiple large language models (LLMs) to modulate \nspecific attributes in controlled text generation (CTG). The framework employs a structured, formulaic method to accomplish \nits objectives and encompasses many existing CTG methods. Empirical evidence demonstrates its superiority in reducing toxicity\nover previous approaches. Additionally, the authors propose an innovative speculative sampling technique to \nminimize the computational demands of model arithmetic.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n3 good\nStrengths:\nThis ia a pretty principled framework for CTG. Many prior work can also be expressed in the framework.\nIt is grounded on the concept of KL-optimality, offering a fresh perspective and strengthening its theoretical foundation.\nThe proofs presented are thorough and complete, bolstering the theoretical underpinning of the framework.\nIt presents innovative speculative sampling technique.\nWeaknesses:\nThe core concept closely resembles \"PREADD\" (Pei et al., 2023), which also relies on composing multiple LLMs to control desired attributes and using prompts to construct different LLMs with desired attributes.\nThe comparison in Table 5, showing the toxicity reduction results, appears biased. PREADD is tested in a single ad-hoc configuration, whereas model arithmetic is assessed across six, potentially skewing fairness.\nThe toxicity reduction comparison in Table 5 is limited, omitting works like Liu et al. 2021, despite its relevance mentioned on page 16.\n(In the discussion period, the authors pointed out that work of Liu et al. 2021 relies on expensive fine-tuning with training data, which is different from their zero-shot regime.)\nThe evaluation is restricted to toxicity reduction, whereas other CTG studies often explore sentiment or topic control as well. It is recommended to broaden the evaluation scope to these areas as well. (In the discussion period, the revised version added an extra experiment evaluating model arithmetic on sentiment control in Appendix F, showing that their method also outperforms existing work.)\nQuestions:\nPlease respond to Weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 04:30Everyone", "Content": "Comment:\nWe thank the reviewer for their insightful questions, which we address below and are encouraged to hear that they find model arithmetic to be a principled and theoretically founded CTG framework.\nQ: How does model arithmetic differ from PreAdd?\nModel Arithmetic improves upon PreAdd (Pei et al., 2023) in several significant ways: First, PreAdd only allows the use of 2 different LLMs with a negative coefficient between them. This restriction is a consequence of the limited theoretical framework which model arithmetic does provide, giving us the correct normalization and allowing us to compose more than 2 LLMs with positive and negative coefficients. Second, our method is able to use classifiers and the union operator. These expand the possible applications of model arithmetic by allowing attributes that cannot be expressed in natural language and provides a stronger biasing method. Specifically, the union operator has much better results than PreAdd on the task of toxicity reduction (see Section 5.1) and sentiment control (see Appendix F). Finally, our extension of speculative sampling allows us to increase the speed of inference and can also be applied on top of PreAdd.\nQ: Can you run prior work for more parameters, such that the results in Table 5 become unbiased?\nWe extended the amount of parameters on which previous methods were evaluated and included updated values in Table 5. While we tried several parameters before, we now more thoroughly investigated the possible parameters and found that the parameters provided for SelfDebias and Fudge were already optimal, while the parameter for PreAdd could be increased slightly without sacrificing the perplexity of any model. We note that this does not change our conclusions and that our method still outperforms PreAdd.\nQ: Can you compare to more prior work in Table 5?\nPlease see Q4 of our main reply.\nQ: Can you broaden the scope of the evaluation further to tasks found in prior CTG work?\nPlease see Q2 of our main reply.\nWe hope to have been able to address all the reviewers\u2019 concerns, are happy to answer any follow-up questions they might have, and are looking forward to their reply."}, {"Heading": "increased the rating to 6", "Subheading": "Official CommentbyReviewer Ne4m22 Nov 2023, 07:16Everyone", "Content": "Comment:\nI increased the rating to 6 because, during the discussion period, the authors' answers and their revised version mitigated some of my concerns:\nThe toxicity reduction comparison in Table 5 is limited, omitting works like Liu et al. 2021, despite its relevance mentioned on page 16. (In the discussion period, the authors pointed out that work of Liu et al. 2021 relies on expensive fine-tuning with training data, which is different from their zero-shot regime.)\nThe evaluation is restricted to toxicity reduction, whereas other CTG studies often explore sentiment or topic control as well. It is recommended to broaden the evaluation scope to these areas as well. (In the discussion period, the revised version added an extra experiment evaluating model arithmetic on sentiment control in Appendix F, showing that their method also outperforms existing work.)"}]}, {"Heading": "Official Review of Submission9377 by Reviewer gF67", "Subheading": "Official ReviewbyReviewer gF6701 Nov 2023, 02:44 (modified: 22 Nov 2023, 23:23)EveryoneRevisions", "Content": "Summary:\nThe authors present a framework during inference time that can compose models together using arithmetic for controllable text generation without the need for additional fine-tuning. They present proofs that seem to simplify prior controllable text generation algorithms and provide regions or ways to extend them effectively. They show performance gains for 3 large models on toxicity.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nI think the motivation here is clear. It'd be great to do this kind of a thing with already trained models. You really do want to compose them and do arithmetic with them, especially as these models become more expensive to train and impossible for the vast majority of us to do any development or even significant fine-tuning, instruction-tuning, rlhf etc. on them.\nThe empirical results on toxicity are nice; the methods seem to reduce them in so far as the perspective api can adjudicate.\nWeaknesses:\nExperimentation seems a little weak. It'd be great to compare with some of the work that's come out of UW/AI2 in the past couple of years like DExperts, which you cite but dont compare with, and Quark (Lu et al. 2022). It'd also be great to compare with GeDi and a few other baselines. That'd strengthen the experimental component.\nOn the experimentation side again, it'd be great to have a section on using human eval to evaluate a small subset of the generations to see if humans agree that it indeed is reducing toxicity or whether its an artifact or oddity of the perspective api evaluation.\nOn the experimentation side, it'd be nice to see how well these methods work for smaller models (e.g. GPT2, GPT2-large)\nQuestions:\nHow do you think model averaging via output distributions could compare with weight averaging of the model parameters? Would be curious to know your thoughts here.\nHow straight forward and performant would it be to swap in different models for each part here and capture the output distribution, if the vocabulary was shared?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 04:31Everyone", "Content": "Comment:\nWe thank the reviewer for their insightful questions, which we address below and are encouraged to hear that they find our work to be clearly motivated and appreciate our results on toxicity reduction.\nQ: Can you compare to more prior work in Table 5?\nPlease see Q3 of our main reply.\nQ: Can you include human evaluation for the experiments in Table 5?\nWe included an evaluation by GPT-4 for both the toxicity reduction (see Table 6, Section 5.1) and sentiment control (see Table 10 and 12, Appendix F) tasks as a surrogate for human evaluation. We find that GPT-4 confirms our results and prefers our method over prior work. For further details, please see Q1 and Q2 of our main reply.\nQ: Can you evaluate how well model arithmetic works for smaller models (e.g., GPT2, GPT2-large)?\nWe extended the toxicity results with results for the GPT-2 model family in Appendix  I.1. Interestingly, we find that Fudge is more powerful for the smallest model GPT-2. This is caused by the smaller capacity of GPT-2 (with only 124M parameters, compared to the 355M parameters of the classifier) which makes it harder for a prompt-based method to generate non-toxic samples. For the larger models in the model family, our union operator performs better than prior work. Furthermore, we can leverage the flexibility of model arithmetic by applying a combination of a classifier and the union operator. This formula doubles the toxicity reduction with respect to previous work for the entire GPT-2 model family, thereby validating the results that model arithmetic is more effective at toxicity reduction.\nQ: How do you think model averaging via output distributions could compare with weight averaging of the model parameters?\nWeight averaging of model parameters, e.g., with task vectors (Ilharco et al., 2023), can be useful to create new model weights that exhibit the behavior and attributes of all used models. It is therefore similar to model arithmetic, but suffers from a couple drawbacks. First, it requires that the LLM is finetuned several times, which requires both data and computational power. Furthermore, it makes the assumption that the weights of the model behave very similarly to vectors, and that performance increases linearly as one goes from the starting weights to the fine-tuned weights. Finally, it requires that all models come from the same architecture and does not allow for the inclusion of classifiers. On the other hand, averaging the weights ensures that model inference speed does not increase, whereas for model arithmetic it does increase even with the proposed generalization of speculative sampling.\nQ: How straight forward and performant would it be to swap in different models for each part here and capture the output distribution, if the vocabulary was shared?\nSwapping different models is very easy, but the exact performance would depend on the use case.\nA formula can use a mixture of several models under the mentioned condition that the vocabulary is shared. The current implementation is built on top of the popular transformers Python package from HuggingFace (Wolf et al., 2020) allowing us to use all models from its library and making the operation of swapping models as simple as changing a string from one name to another.\nHow performant the resulting formulas are depends on the underlying task and the models themselves. For example, we see that the same formula works very well for all tested models in Section 5.1 and Appendix F. In Appendix I.1, when applying the formulas on the smaller and less performant model family, the performance of the formulas is a bit different, with the Fudge method now being almost as good as our union operator.\nWe hope to have been able to address all the reviewers\u2019 concerns, are happy to answer any follow-up questions they might have, and are looking forward to their reply."}, {"Heading": "Official Comment by Reviewer gF67", "Subheading": "Official CommentbyReviewer gF6722 Nov 2023, 23:26Everyone", "Content": "Comment:\nThank you for the thoughtful answers to my and the other reviewers' concerns and feedback. After reading the rebuttal and looking at the feedback and concerns of the other reviewers, I've increased my score to an 8. I think the paper is good and warrants acceptance, even if it could be strengthened further with more empirical results and contextualization of those empirical results."}]}, {"Heading": "Official Review of Submission9377 by Reviewer Gru5", "Subheading": "Official ReviewbyReviewer Gru531 Oct 2023, 03:31 (modified: 22 Nov 2023, 23:41)EveryoneRevisions", "Content": "Summary:\nThis paper introduces model arithmetic, a new method for controlled text generation (CTG). Model arithmetic works by solving for combinations of divergences between a base distribution and attribute distributions that may be full token-wise probabilities or classifiers. Particularly, model arithmetic allows weighted linear combinations of such distributions (positive or negative) and a union operator which is defined to allow probability mass to come from either the base distribution or the attribute distribution. The authors find the method works well for toxicity reduction, as well as for different attributes in a conversation model. The authors also demonstrate that speculative sampling works with the proposed technique to increase efficiency.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe method of combining attributes in model arithmetic is inventive\nDerivations of the solutions to the model arithmetic optimizations are interesting\nIt is useful to know that this works with speculative sampling\nResults seem to generally support that the framing of attribute combination works, particularly the toxicity results\nWeaknesses:\nThe paper largely frames against other CTG methods, which use a magnitude variable lambda to control the effect of the given attribute. However, model arithmetic does not seem to provide a more principled definition of magnitude of effect--users will still simply pick a weight, that does not necessarily have an intuitive interpretation\nSimilarly, it is not quite clear how or when such a method can be applied. Two example applications are given.\nThe first is toxicity which does use both the linear and union operators but only in conjunction with weights that seem to be quite hand tuned (0.9, 0.96, 0.99). It would be useful to also see a simpler framing of this problem with model arithmetic, e.g. simply subtracting the M_toxic instead of the union. The question I am trying to get at here is: does toxicity require the full complexity of model arithmetic? It seems like a fairly simple application which may simply require a subtraction, in which case the need for more complex proposed model arithmetic might not be supported here.\nWhile the second application, conversation, presents a more complex use-case for model arithmetic, it seems that the complex application space means that no baselines would work or be comparable here. So this application also does not make a complete case for the full complexity of model arithmetic improving on past work.\nQuestions:\nDo the authors have other examples of how model arithmetic might intuitively be used?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 04:32Everyone", "Content": "Comment:\nWe thank the reviewer for their insightful questions, which we address below and are encouraged to hear that they find our work to be inventive and interesting.\nQ: Does model arithmetic provide a more intuitive definition of magnitude of effect than prior work?\nPlease see Q4 of our main reply.\nQ: How did you select the weights for model arithmetic in Table 5?\nWe selected these weights by gradually increasing the biasing strength until we found a degradation in the perplexity of the results. In an initial version of model arithmetic, we denoted these formulas using the equivalent notation $5M - 4M_\\text{toxic}$, $25M - 24M_\\text{toxic}$ and $100M - 99M_\\text{toxic}$. We thus increased the first term from 5 to 25 to 100 because we noticed that increasing the strength remained fluent.\nQ: Does toxicity reduction require the full complexity behind model arithmetic?\nWhile toxicity reduction does not require the full depth in which we introduced model arithmetic, it can make use of all the parts we introduced. In particular it allows us to showcase that our newly derived operator, union, empirically outperforms prior work and further that model arithmetic allows for combining different methods, leading to even better results.  Note that subtraction expresses the baselines, PreAdd, which we clearly outperform.\nQ: Where can the full feature set of model arithmetic be best utilized to improve over prior work?\nWe use the full feature set of model arithmetic in several places to significantly outperform previous work. First, in Section 5.1, while the union operator by itself suffices to outperform existing work, the ability of model arithmetic to combine the union operator with a classifier allows us to widen the gap even further. The new sentiment control task presented in Appendix F displays this utility even further, as the combination widens the gap by a much bigger margin, especially as evaluated by GPT-4. This shows that the feature set of model arithmetic can be used to improve results, even on the simple tasks that can be expressed using prior work. Secondly, Section 5.2 discusses the application of conversational agents, with fine grained control over specific attributes. The examples discussed there cannot be expressed using prior CTG works because of the added features of model arithmetic. Since we show that model arithmetic indeed has fine grained control over the attributes at almost no cost in perplexity, it essentially solves this specific task and its improvement over prior work lies in the fact that we can express this.\nQ: Do you have other examples of how model arithmetic might intuitively be used?\nModel arithmetic can intuitively be used in several areas. Firstly, as shown in the example in Table 3, model arithmetic can be used to avoid detection of AI generated text, by biasing away from the classifier. This can in turn be used to train better detectors, since we can use this ability to generate adversarial examples to the current detector.\nFurthermore, ensembling models or prompts to achieve better performance can be achieved by using linear operators and the union/intersection operators. Classifier-Free Guidance (Sanchez et al, 2023), a method we subsume, for example shows that performance of language models can be improved by biasing away from models that do not get any context (e.g. by omitting the input question).\nFinally, by using the fact that one can simply optimize the constants over a certain corpus, model arithmetic can characterize texts. This makes it possible to identify whether a newspaper is politically more left- or right-leaning, or to replicate personal styles by analyzing personal messages.\nWe hope to have been able to address all the reviewers\u2019 concerns, are happy to answer any follow-up questions they might have, and are looking forward to their reply."}, {"Heading": "Official Comment by Reviewer Gru5", "Subheading": "Official CommentbyReviewer Gru522 Nov 2023, 23:41Everyone", "Content": "Comment:\nThank you for an in-depth response. Based on your response and reading through comments of other authors, I have decided to raise my score to 8."}]}]}, "fI6TkT050a": {"paper_info": {"Keywords": "Cognitive ability, benchmark, Large Language Models, Piaget's theory of cognitive development", "TL;DR": "We construct a benchmark (CogLM)  based on Piaget's Theory of Cognitive Development  to reveal the development of cognitive abilities in Large Language Models", "Abstract": "Large Language Models (LLMs) have recently shown tremendous performance on a large variety of Natural Language Processing tasks, ranging from text comprehension to mathematical problems.  However, the mechanism regarding why and how such performance has been achieved remains unknown, and it is unclear whether LLMs can achieve human-like cognitive abilities or whether these models are still fundamentally limited. To bridge this gap, we introduce Piaget's Theory of Cognitive Development (PTC) as a tool to reveal the development of cognitive abilities of LLMs. We construct a benchmark (CogLM) based on the scenario experiments in PTC to evaluate the cognitive level of LLMs, covering 10 abilities and 1220 questions created by more than 20 human experts. Through extensive experiments across multiple LLMs on CogLM, we find that: (1) Human-like cognitive abilities have emerged in State-of-the-art LLMs (GPT4), comparable to those of 20-year-old humans. (2) The parameter size and optimization objective are two key factors affecting the cognitive abilities of LLMs. (3) The ability of downstream tasks highly depends on the level of cognitive abilities. These findings provide guidance for the future development of advanced abilities of LLMs from the perspective of ability evolution, and shed light on the mystery behind the emergence of advanced abilities of LLMs.", "Primary Area": "datasets and benchmarks", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9374", "PDF Url": "https://openreview.net/pdf?id=fI6TkT050a"}, "review_info": [{"Heading": "Official Review of Submission9374 by Reviewer LvrM", "Subheading": "Official ReviewbyReviewer LvrM02 Nov 2023, 06:43 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper adopted a cognitive framework from psychology (PTC framework) to evaluate LLMs. The authors created a human-annotated benchmark dataset based that contains questions from 10 cognitive levels and 4 cognitive stages. The number of questions increases with cognitive difficulty levels. The questions are formatted as multiple choice questions and the main evaluation metric for this dataset is calibrated accuracy. The authors benchmarked various popular language models on this dataset, showing that the current best model GPT-4 has a similar cognitive ability of a 16-year-old human. This paper provided some additional analysis of LLMs' cognitive abilities. However, the analysis was not convincing to me personally. I will elaborate on the details in the following sections.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nBenchmarking LLMs (or general AI models) on human-level tasks is an important topic. Besides, this paper constructed an expert-annotated benchmark dataset, which could be useful to the research community.\nWeaknesses:\nEven though the resources of this paper could be useful, the analysis of the CogLM benchmark could be improved. From Section 4.3.1,  the two findings are LLMs with larger parameter size have better cognitive abilities and optimization objective significantly improves cognitive abilities. However, the authors reached the latter conclusion by comparing the cognitive abilities of llama-2-text and llama-2-chat. However, the differences between these two models are not just optimization objectives (word prediction vs. RLHF). The llama-2-chat was finetuned on a large amount of labeled instruction data. Whereas the main motivation for RLHF of LLMs is to align the values and preferences of humans. I believe is inconclusive to say the differences in cognitive abilities are mainly from the optimization objective, and the improvements could be resulted from the instruction tuning with the same language modeling objective.\nIn 4.3.2, the authors mentioned that CoT does not bring significant performance improvement in terms of average calibrated accuracy, and hypothesized that cognitive skills are inherent and cannot be improved by CoT. However, from Table 5, we can see CoT\u2019s effects vary according to different cognitive levels, and CoT clearly showed a performance improvement in planning and propositional operations. This is expected as CoT itself was proposed to solve problems of a more complex nature. Hence, using the average result of all cognitive levels is questionable in analyzing CoT. \nBesides, from Table 4 and Table 5, we can see the results of GPT3.5-turbo in Table 4 correspond to the row \u2018With CoT\u2019 in Table 5 instead of \u2018Base\u2019. This raised a serious question, so are all results in Table 4 are prompted with CoT? If so, why there is no description of this at all? CoT only showed up in section 4.3.2 of this paper. The authors need to double-check whether Table 4\u2019s results are \u201cwith CoT\u201d or GPT3.5-turbo\u2019s result in Table 4 should be \u2018Base\u2019.\nOn the clarity side, the notation of \u2018chain-of-cognition\u2019 is highly confusing. This term refers to \u2018chain-of-thought\u2019 in Section 4.3.2 and somehow became \u201cCoC\u201d in Section 4.3.4 and Table 7. Simply coming up with some terms does not add novelty to this work but only adds confusion to readers.\nQuestions:\nFrom Table 4 and Table 5, we can see the results of GPT3.5-turbo in Table 4 are corresponding to the row \u2018With CoT\u2019 in Table 5 instead of \u2018Base\u2019. This raised a serious question, so are all results in Table 4 are prompted with CoT?\nWhy do you need to introduce \u2018chain-of-cognition\u2019 when it essentially refers to CoT?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9374 by Reviewer sSK2", "Subheading": "Official ReviewbyReviewer sSK231 Oct 2023, 23:51 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a new dataset for evaluating LLM cognitive capacity. The dataset is inspired by Piaget\u2019s Theory\nof Cognitive Development (PTC) which is highly influential in developmental psychology. The authors design language-based tasks that target skills developed at different stages of human life, validate their data on human participants, and create a conversion procedure allowing to estimate one's cognitive development age based on their task performance. They evaluate a number of LLMs on the newly proposed tasks, showing that generally, more parameters and RLHF-fine-tuning corresponds to higher cognitive age.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nI highly resonate with the goals of the paper. Given extremely fast advances in LLM performance, it is crucial to devise thoughtfully designed and thoroughly validated datasets to better understand the capacity and limitations of LLM cognitive abilities.\nI believe that this work, therefore, tackles an extremely important topic that is of high interest to a large portion of AI, ML, and Cognitive Science communities.\nWhat further strengthens the paper is that they based their assessment tool on a highly established theory of cognitive development, which adds additional credibility to the research.\nWeaknesses:\nQuality\nThe paper creates a very uneven impression when it comes to the quality of the experimental support of its claims. On the one hand, I find the experiments interesting, and I deeply appreciate that the authors include human evaluation of the generated dataset.\nOn the other hand, there is a number of substantial limitations:\nWeakly justified design choices\nMany of the design choices seem to be poorly justified or not justified at all. For example, the choice of the calibration function is not explained nor is it compared to alternatives (e.g. F-measure). In this context, it's also not clear why the number of answer options was not standardized in the first place. For example, some questions have very restrictive answer options \"Yes\" and \"No\" while others are more open-ended and have more options. This situation could have been easily avoided by changing question-writer instructions.\nStatistical reporting\nI also believe that statistical result reporting could be improved. For example, on page five, in the first paragraph, the authors say \"We observe that w1 : w2 : w3 : w4 = 1 : 2.6 : 1.4 : 2.5, indicating that cognitive abilities in the second and fourth stages are better at reflecting cognitive age under the evaluation of CogLM\". Such hypotheses need to be directly tested on the available data. Without uncertainty estimates on these parameters, it's impossible to gauge the reliability of this conclusion. Since this is a result of secondary importance, I would suggest removing this phrase entirely or adding appropriate statistical tests (e.g. method of contrasts, and, before that, comparing the restricted model (with all coefficients equal) and unrestricted models to show that these differences between w_is are significant).\nSpeculative claims\nI find some claims to be highly speculative and not supported by the data. For example,\n\"Specifically, the cognitive abilities of LLMs continuously improve as the size of model parameters increases, which follows the same pattern as human cognitive abilities continuously improving with age. We hypothesize that the reason for this phenomenon is that the parameter size of LLMs can be analogous to a child\u2019s brain capacity, and cognitive abilities continuously improve with the development of the brain, as stated in Piaget et al. (1952).\"\nThe paper does not go into sufficient depth to rigorously define terms like \"child's brain capacity\". As a result, the claims like above seem highly speculative and/or vacuous. If we condense the claim above, removing terms that are hard to define, it simply says that \"higher parameter count is associated with better cognitive task performance\", which we already know since all standard model evaluation tasks are cognitive tasks as well.\nI believe that it's better to restrict the amount of such claims as much as possible, as it hurts the credibility of the paper.\nIn general, the pattern observed in the paper can be formulated as \"better models tend to perform better on the proposed task\". The paper does relatively little to establish the correspondence between model development and human cognitive development.\nTo clarify what I mean - in order to show that LLMs actually follow a path similar to human development, one would need to demonstrate something that goes beyond the general pattern of better models performing better on a new task. The paper has some results of that kind - specifically, tasks that correspond to later stages in cognitive development seem to be generally harder for LLMs.\nIt's crucial, however, to look into alternative explanations, one of which is that these tasks might also be harder to generate in unambiguous ways. In other words, we need to validate the data and see (adult) human accuracies on tasks corresponding to different stages of development. This is especially important given that the authors found out that a large proportion of initially generated questionnaires was not valid (i.e. the data generation process is quite noisy).\nIn a similar vein, I do not fully agree with the statement \"3\" in the abstract:\n\"(3) The ability of downstream tasks highly depends on the level of cognitive abilities.\" - I don't believe that the authors showed the causal direction. I.e. performance on downstream tasks correlates with their cognitive abilities, as measured by the authors, but the claim that there is a causal relationship is much stronger, and would require a lot of additional experimentation and analyses.\n\"Ability erasure\" experiments\nWhile I find the idea interesting, I find the experiments deeply flawed and presentation slightly misleading. While in the main paper, the authors said that the model was prompted with phrases like \"you have not yet developed a sense of empathy\", in fact the prompts were very different (as given in the appendix):\nFor example:\n\"Please imagine yourself as a child aged 0-2 years old. According to Piaget\u2019s theory of cognitive development, you are currently unable to recognize that objects exist both within and outside the field of vision and maintain a certain level of stability.\"\nGiven this prompt, the apparent results that we see (later abilities \"depending\" on earlier ones) are explained by the model being able to imitate the behavior of a human of the requested age. I.e. the authors don't say \"do everything as usual, but pretend that you don't have empathy\" to surgically remove empathy, but rather ask the model to imitate a person at a given age, specifically requesting it to conform to the Piaget's theory.\nIn other words, the authors (inadvertently) directly asked the model to generate the results that they observed.\nInsufficient data validation\nIn general, given how much the paper's claims depend on the quality of the generated data, I find the data validation experiments insufficient. We do see that age correlates with performance on the proposed dataset, but I believe that a much more detailed look into human performance is warranted (in the very least, splitting humans by age and showing how they perform on different subtasks).\nClarity\nUnfortunately, the paper is not very clearly written, and in general, the presentation can be substantially improved.\nFor example, consider this sentence in the section 3.3\n\"Out of the 207 completed questionnaires, 141 are deemed valid (based on the reasonableness of test duration).\" \n\"Duration\" was never mentioned before that snippet, and is never mentioned after. It is also not clear what criterion was used to see whether a questionnaire was \"valid\".\nUnfortunately, this is not the only case when the paper does not fully define its terms or procedures.\nTypos & Phrasing suggestions\n\"recently challenging tasks have been proposed\" -> \"recently, challenging tasks have been proposed\"\n\"Theory of Cognitive Development (PTC) is the most authoritative theory in the development of psychology, developed by Jean Piaget\" -> perhaps should be rephrased to avoid three-fold repetition of the word \"development\". More importantly, it should, perhaps, be \"developmental psychology\", not \"development of psychology\".\n\"cognitive abilities of PTC\" -> \"cognitive abilities proposed by PTC\"\n\"the ability of downstream tasks\" -> \"the ability of [performing?] downstream tasks\"\nConclusion\nOverall, I do highly resonate with the theme of the paper and I find many of the ideas promising. At the same time, unfortunately, I believe that there are serious flaws with the experimental design, substantial inaccuracies when it comes to result interpretation, and (less importantly), presentation clarity concerns. At present, I can not recommend its acceptance.\nAt the same time, I believe that the paper has most of the elements it needs to be published in a good venue. I deeply hope that the authors will rework the framing of the paper, scaling down some of the claims, and/or adding new experiments to get a more thorough comparison between human and LLM development.\nQuestions:\nLack of actual LLM developmental data\nThe authors make an analogy between human development and fully-trained LLMs of different capacity. At the same time, for humans, the process is fundamentally different - as the brain develops, it realizes its potential rather than simply increases in capacity. A more natural analogy, therefore, seems to be a single LLM evaluated on different training stages.\nIt would highly increase the impact of the paper if the authors evaluated LLM cognitive task performance at different stages of training. I understand that for some models, such an experiment would not be feasible. But perhaps it might be possible to find open-source model training checkpoints to evaluate the model on these tasks in different stages of training.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9374 by Reviewer BFZ5", "Subheading": "Official ReviewbyReviewer BFZ529 Oct 2023, 12:22 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper focuses on an assessment of LLMs\u2019 cognitive levels. The authors use Piaget\u2019s Theory of Cognitive Development (PTC) as a tool to evaluate the \"cognitive abilities\" of various generative LLMs, and construct a benchmark test suite (CogLM) for this purpose. CogLM demonstrates the stages of PTC, except the first stage of PTC has not been considered (CogLM excludes reflexes and sensorimotor aspects of multimodal interaction). Multiple LLMs such as OPT, LLaMA2-chat-base, GPT-3.5-Turbo, and GPT-4 have been evaluated on CogLM. CogLM consists of questions in a multiple-choice format. Part of paper attempts to assess the consistency of CogLM with PTC and ensure the alignment between CogLM and PTC. In order to do so, humans between the age of 6 and 20 have been recruited to respond to CogLM questions. Spearman and Pearson correlation coefficients between the age of participants and the questionnaire scores have been computed to validate the effectiveness of the standard annotation guidelines.  Furthermore, the mapping function between the accuracy of response and age of participants have been computed through regression. The authors claim to show that GPT-4 exhibits human like cognitive abilities commensurate with a 20-year-old human.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nThe CogLM benchmark is novel and would likely to be valuable to the community for different evaluations and assessments.  I appreciate the level of work that must have gone into creating it.  There is a wide variety of experiments performed and results presented in a fairly clear and concise fashion.\nWeaknesses:\nUnfortunately there are a number of serious, I would say fatal, flaws to the paper, in that the entire endeavor rests on faulty assumptions and a non-trivial number of false statements.  The authors seem to set out with the goal to demonstrate that LLMs have human-level \"cognitive\" abilities and then construct an experimental protocol in order to arrive at that conclusion, which is begging the question.\nThere is a fundamental category error being made in the statement that the abilities demonstrated by LLMs are fundamentally cognitive.  LLMs are sophisticated word-prediction machine, and this capacity happens to provide ability in tasks like summarization and question answering.  The statement \"However, there is little theoretical evidence regarding why and how this performance has been achieved\" is frankly not true.  There is plenty of theorizing that the ability to learn statistical patterns in language is precisely why LLMs are able to reproduce human-like outputs. Due to the large amount of data and large model size, they are good predictors of what a human would say, but doing so does not mean the same cognitive processes are at play.  A fairly simple neural net can accurately predict how a human would move in a given task.  It doesn't mean that network has the same sensorimotor processes as a human.  Prediction is not experience.  In general, the underlying definition of \u201ccognitive abilities\u201d being used here is faulty because LLMs are not cognitive systems, but rather statistical models based on sophisticated word occurrence correlation, to say nothing of studies of GPT\u2019s varying ability over time: e.g.,\nChen, L., Zaharia, M., & Zou, J. (2023).\nHow is ChatGPT's behavior changing over time?\n. arXiv preprint arXiv:2307.09009.\nSpeaking of sensorimotor, by excluding the reflex and sensorimotor aspects of multimodal interaction with the world destroys the scaffold upon which successive Piagetian stages are built.  Piaget\u2019s theory is that the development of the different stages are supervenient upon passing through the previous stages.  How can an LLM have achieved a certain level of cognitive functioning according to Piagetian theory if it was trained to that level without passing through the previous stages first?  Without sensorimotor capability, and LLM lacks the mechanism to experience the sensorimotor stage. This invalidates the entire construct of using PTC as a measure of cognitive ability, as the foundation has been pulled out.  This renders the entire comparison invalid, and makes PTC an inapprorpriate evaluation tool, since the entire first stage of PTC is explicitly the sensorimotor phase and everything else is scaffolded on top of that.\nPiaget is well-known but also quite contentious within dev-psych circles. Piagetian theory was based primarily on case studies and only some (not all) of his ideas have been supported through experimental methodologies.  This makes PTC in general a dubious metric by which to assess cognitive ability.\nGPT-2 is not similar to a human infant.  GPT-2's vocabulary is far larger than an infant but its ability to produce coherent, grammatical, on-topic, contextually-correct text is inferior to more recent models, as well as to toddlers given a toddler's vocabulary. GPT-2 is still an autoregressive next word predictor, explicitly trained for generation over text mostly written by adults.  This is not how human children learn language.  The fact that the data and compute power available at the time rendered GPT-2 inferior to GPT-4 does not make it at all like a human infant.  Did the authors forget how state of the art GPT-2 was considered at the time of its release?\nThe benchmark is all multiple choice questions.  This would be fine if humans only thought in multiple choice questions but we know that is obviously not the case.\nIn Section 3.4, the definition of accuracy is changed between construction of the benchmark and using it for LLM evaluation.  \"After confirming the positive correlation between answer accuracy and cognitive age, we aim to further construct the mapping function between them. We first make adjustments to the method of calculating accuracy.\"  After demonstrating a correlation between accuracy and cognitive age, the authors then change how they calculate accuracy?  The authors seem to be in search of a result that fits their narrative that LLMs are somehow following a human-like evolutionary path.\nAn assertion in Section 4.2: \"Overall, the cognitive abilities of the OPT, LLaMA2-chat 70B, GPT-3.5-Turbo, and GPT4 models successively increase, and the performance of each model gradually declines with the increase of stage, consistent with humans.\" is not self-consistent, and the assertion that human cognitive performance declines as they progress through PTC stages, is also not true.\nThe authors claim that GPT-3.5 and GPT-4 surpass humans at empathy.  Empathy is the ability to understand feelings and emotions.  Even if we allow that LLMs are accurate reproductions of the language faculty in the brain, emotions are governed by different regions and mechanisms.  LLMs can no more understand emotions than ELIZA could.\nTable 5 claims that the results are demonstrations of human-like cognitive abilities but these number measure the ability to correctly answer multiple choice questions.  The ability to answer multiple choice questions is not in anyway a global indicator of cognitive ability at the \u201cages\u201d being tested.\nQuestions:\n\"As the most authoritative theory in the development of psychology\" (should \"the development of\" be \"development\nal\n.\"  Piaget is not as influential in other branches of psychology outside dev-psych.\n\"Out of the 207 completed questionnaires, 141 are deemed valid (based on the reasonableness of test duration)\".  What is \"reasonableness of test duration\"?  This is a qualitative and unjustified assertion.\nHow could a human in PTC's first stage (0-2 years old) answer questions in language like those presented in Table 1?\nIn general, I wonder what the point is of doing a simple performance-based evaluation of evaluating anything on GPT-4, given that we know nothing about its data or training.\n\"For text-completion models, as they lack the ability to follow instructions and their output format is difficult to control, we concatenate each option with the corresponding question as input, and take the option with the highest generation probability as the model\u2019s prediction.\" So the input is different for the different models, therefore the input has to be tuned (how so? manually?) to extract the \u201cbest\u201d output format from the different models. The input format is not controlled.\nWhy would accuracy be the important metric for most of the factors evaluated (as in Table 4)?\n\"We explore this question from two perspectives: the parameter size and the optimization objective of LLMs, as they are the most natural assumptions.\"  Why are they the most natural assumptions?\nTable 5: 1) No particular approach comes out on top. Are these results supposed to show anything about a general purpose capacity of LLMs?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n1: strong reject\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9374 by Reviewer Fc8y", "Subheading": "Official ReviewbyReviewer Fc8y29 Oct 2023, 00:52 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nTo reveal and evaluate the cognitive abilities of LLMs, this paper introduces Piaget\u2019s Theory of Cognitive Development (PTC) in psychology and construct a corresponding benchmark (CogLM). Through extensive experiments on various LLMs, it shows some interesting findings and provides guidance for the future development advanced abilities of LLMs.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n1 poor\nStrengths:\nThe paper is well organized and the ideas are skillfully presented. However, this paper is not innovative enough and the key content is not clear enough. As far as I am concerned, the main advantages are as follows.\nThe paper is easy to follow and understand. No matter the motivations, methods, experiments, and analysis in this paper, they are all flowing and graceful.\nSome findings and conclusions in this paper are interesting and meaningful. For example, \u201ccognitive abilities are inherent to the LLMs and cannot be enhanced through multi-step reasoning.\u201d, \u201cthe parameter size of LLMs can be analogous to a child\u2019s brain capacity, and cognitive abilities continuously improve with the development of the brain\u201d.\nAlthough it is not the first time that human evaluation methods are applied to LLMs and some details are not clearly explained, the solution seems to be effective and reasonable. This paper is able to evaluate the model from the perspective of psychology and provide some future development suggestions for LLMs.\nWeaknesses:\nI still have some concerns which, in my opinion, are the weaknesses:\nI am skeptical about using PTC to evaluate LLMs. The paper needs to further emphasize whether it is reasonable to use PTC to evaluate the model, or give some basis or experimental results. More about the deep introduction of PTC in psychology and its correlation with model evaluation need further elaboration, otherwise it will obviously not be able to convince readers by directly applying human evaluation datasets to the LLMs\u2019 evaluations.\nThe expressions such as \u201ctracking\u201d, \u201cdifferent stages\u201d, \u201cevolution process\u201d in the paper are confusing. What exactly are the different stages of LLM? The paper mentions that \"PTC suggests that intelligence grows and develops through a series of stages.\" However, the LLM in the paper is fixed and does not \u201cgrow\u201d continuously. I think it would be best to truly evaluate the LLM at different stages. For example, can different amounts of data using in the pre-training and fine-tuning processes be regarded as different stages? It is more appropriate to apply PTC to provide evaluation services along the LLM growth cycle.\nThe benchmark CogLM constructed based on PTC in this paper only uses multiple-choice questions as the assessment format. Is the generative ability also a manifestation of the LLMs\u2019 \"cognitive ability\"? I believe that most human cognitive testing programs are more about answering each test question fluently than multiple-choice questions. The model's complete response is clearly more informative than the selected options.\nQuestions:\nSee above.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes"}]}, "efxXzrbgrX": {"paper_info": {"Keywords": "Black-box attack, adversarial robustness, segment anything", "TL;DR": "Black-box Targeted Adversarial Attack on Segment Anything (SAM)", "Abstract": "Deep recognition models are widely vulnerable to adversarial examples, which change the model output by adding quasi-imperceptible perturbation to the image input. Recently, Segment Anything Model (SAM) has emerged to become a popular foundation model in computer vision due to its impressive generalization to unseen data and tasks. Realizing flexible attacks on SAM is beneficial for understanding the robustness of SAM in the adversarial context. To this end, this work aims to achieve a targeted adversarial attack (TAA) on SAM. Specifically, under a certain prompt, the goal is to make the predicted mask of an adversarial example resemble that of a given target image. The task of TAA on SAM has been realized in a concurrent arXiv work in the white-box setup by assuming access to \\textit{prompt} and \\textit{model}, which is thus less practical. To address the issue of prompt dependence, we propose a simple yet effective approach by only attacking the image encoder. Moreover, we propose a novel regularization loss to enhance the cross-model transferability by increasing the feature dominance of adversarial images over random natural images. Extensive experiments verify the effectiveness of our proposed simple techniques to conduct a successful black-box TAA on SAM.", "Primary Area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9373", "PDF Url": "https://openreview.net/pdf?id=efxXzrbgrX"}, "review_info": [{"Heading": "Official Review of Submission9373 by Reviewer JQeG", "Subheading": "Official ReviewbyReviewer JQeG03 Nov 2023, 10:49 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents a novel approach to targeted adversarial attacks (TAA) on the Segment Anything Model (SAM), a computer vision model. The contributions of the paper are noteworthy and add to the existing body of knowledge in this field. The introduction of \"prompt-agnostic target attack\" (PATA) is designed to generate adversarial examples that resemble a given target image's mask without relying on specific prompts. This approach has the potential to enhance the robustness and practicality of adversarial attacks on SAM, making it more applicable to real-world scenarios. The paper's emphasis on relative feature strength is another valuable contribution. This concept offers a new perspective on assessing the dominance of adversarial features over clean images, which is crucial for understanding the transferability of adversarial examples. It adds depth to the evaluation of adversarial attacks and their impact on computer vision models. Furthermore, the regularization method proposed to boost feature strength is a practical and effective addition. The authors show that this regularization significantly enhances the transferability of adversarial features across different models. This has implications for improving the overall effectiveness of TAA methods and their ability to fool various models. In summary, this paper provides novel insights and approaches for TAA on SAM, enhancing the field of adversarial attacks in computer vision. The contributions made in this paper can lead to improved robustness and security in computer vision models, particularly those like SAM.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper is well-structured, written clearly, and logically presented. The introduction of \"prompt-agnostic target attack\" (PATA) and the concept of \"relative feature strength\" are innovative perspectives in adversarial attacks.\nWeaknesses:\n(1)\tThe paper does not provide a comprehensive comparison or benchmarking against existing methods. A more in-depth evaluation against other state-of-the-art adversarial attack techniques would help assess the uniqueness and effectiveness of the proposed approach. For example, I recommend the results of adding Attack-SAM methods in the section 5.\n(2)\tThe author mentioned in the qualitative results that the prompt information was randomly selected, but the result in the figure 4 and 5 only gives the result in the case of the prompt information to a significant area. This is not rigorous, and this ignores the important position of the prompt-guided to attack. I suggest adding experiments under the condition of different prompt-guided selection conditions.\nQuestions:\n(1)\tI think that if the prompt-guided is ignored, the process of generating confrontation disturbances will transfer the highly concerned area in the original picture to the regional of strong attention in the target picture. Therefore, when the prompt information is characterized by a more obvious area, it will have a good attack effect, which does not prove the effectiveness of the method. I think the results of comparative experiments to prove the effectiveness of the method.\n(2)\tDo you verify the concealment of the attack? From Figure 4, we can clearly see that the watermarks are similar to the outline of the target picture.\n(3)\tWhat is the direct regularization loss on Page 7? You should use formulas to explain to facilitate readers to understand.\n(4)\tCould you explicitly outline the limitations of the proposed approach? For instance, are there specific scenarios or model architectures where PATA may not be as effective? Addressing potential vulnerabilities or shortcomings would enhance the paper's transparency.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9373 by Reviewer Rvz4", "Subheading": "Official ReviewbyReviewer Rvz402 Nov 2023, 14:41 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a Targeted Adversarial Attack (TAA) on the Segment Anything Model (SAM) called Prompt-Agnostic TAA (PATA). Different from prior works, this paper doesn't require the prior knowledge of user's prompt to the SAM for choosing the object and replace with the target object.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nAdversarial attack on SAM is interesting.\nWeaknesses:\nI do not believe Eq. 2 has to be interpreted as a classification task. If you are focussing on the image encoder, you can just compare the features from the encoder. This Eq. 2 seems unnecessary.\nFig. 1 should accompanied by the example how TAA works with SAM, e.g. visualizing $Mask_{target}$ and $Mask_{adv}$ within the attack framework.\nUsing MSE loss over other mentioned loss functions is a known phenomenon [A, B]. Table 1 is unnecessary.\nEq. 6 is similar to loss functions used in generative adversarial attacks, where information from \"other clean images\" are used to create perturbations. The behavior of Eq. 6 is expected in Fig. 3.\nThe paper severely lacks in comparison with prior dense prediction attacks. SAM doesn't ensure the proposed method is incomparable with these prior works.\n[A] Learning transferable adversarial perturbations, NeurIPS 2021\n[B] GAMA: Generative Adversarial Multi-Object Scene Attacks, NeurIPS 2022\nQuestions:\nNone.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n1: strong reject\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9373 by Reviewer bXHA", "Subheading": "Official ReviewbyReviewer bXHA01 Nov 2023, 11:21 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a targeted adversarial attack with black-box setting on Segment Anything Model (SAM), where given an adversarial image, the SAM will constantly output a predefined mask. The paper conjectures that white-box access to SAM models is impractical, where SAM works in online modes and allows users to specify random prompts. Conversely, the paper relaxes the white-box access assumption and utilizes a surrogate SAM for black-box adversarial optimizations, and ensures the attack\u2019s effectiveness in a prompt-agnostic manner. The paper proposes a regularization loss term to further improve the adversarial attack effectiveness and computational efficiency.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nRelaxed the assumption of white-box access for adversarial attacks on SAM, where the paper proposes to use a surrogate SAM and optimize adversarial examples from it\nImproved the threat model in adversarial attacks on SAM by introducing a prompt-agnostic adversarial attack. Previous method focuses on attacking SAM with a predefined prompt position, whereas with the proposed method, the users are susceptible to a wider range of adversarial attacks, even with different prompt positions.\nAnalyzes the relative feature strength between the clean image and adversarial image to identify the feature dominance between adversarial features and clean features. The paper provides a clear analysis and explanation on the impact of adversarial features and clean features, and gain insights to improve the strength of adversarial features by introducing a regularization term.\nWeaknesses:\nThe claim of black-box might be too strong, as in usual adversarial attacks, black-box settings require validation on the transferability of adversarial attacks onto different families of model. The current setting in this paper is restricted to only ViT image encoder in SAM, which is not a proper evaluation of black-box adversarial attacks\u2019 transferability.\nThe formulation of Loss_reg is unclear in Eqn. 7, and the difference between the Loss_reg for PATA+ and PATA++ is not shown.\nCross-model results are not convincing, as the surrogate model is essentially coming from the same genre of models as the evaluated victim model. All models have similar encoder and decoder structures, but with different scales and number of parameters.\nInsufficient qualitative results to show the prompt-agnostic behavior of the proposed adversarial attack. There is no similar visualizations as Fig. 4 to demonstrate the proposed adversarial attack\u2019s prompt-agnostic behavior.\nTypo in Eqn. 1: promt \u2192 prompt\nQuestions:\nPlease see weaknesses\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9373 by Reviewer ifzZ", "Subheading": "Official ReviewbyReviewer ifzZ28 Oct 2023, 23:29 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nthis work studies the adversarial robustness of SAM in a more practical black-box setup. This cross-model transferability is conjectured to be limited by the strength of adversarial features indicated by their dominance over other clean images for determining the feature response. It verifies this conjecture by adding a regularization loss to increase the feature dominance. To avoid dependence on other natural images, it proposes to replace them with random patches cropped from the to-be-attacked clean image.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nIt identifies the challenges in end-to-end approaches for realizing cross-prompt transferability and mitigate it in a prompt-agnostic manner by only attacking the image encoder.\nIt identifies relative feature strength as a factor that influences the cross-model transferability, and propose to boost them by a regularization loss.\nWeaknesses:\nAlthough it claims to be black-box attack, the techniques are mainly white-box attack method and transfer attack increasing the transferability of adversarial examples. Besides, in the white-box, it uses SAM-B as the surrogate model to attack. In the black box setting, it uses the adversarial examples generated with SAM-B to attack other models with very similar architectures. It is better to transfer from an architecture to another different architecture, such as from vgg to resnet in related previous papers. Transferring with the same model architecture family makes the problem much easier.\nIt only tests with 100 images and report the results on the 100 images. 100 images seem to be a very small number and there may be some randomness in the results. It is better to discuss why 100 images is a reasonable number.\nIt is better to discuss the complexity of the proposed method, like computation complexity or what are the costs to run the algorithm.\nIt is hard to understand equation (5). The specific definition of $SAM_{embedding}(prompt, x_{target})$ is not provided. Equation (5) is claimed to be prompt-free. However, it still has prompts as the inputs for $SAM_{embedding}$. So it seems that equation (5) depends on prompts.\nThere are no baselines. Since the paper mainly uses white-box attack methods and transfer the adversarial examples. It is better to use some white-box attacks to generate and transfer the adversarial examples as a baseline. Without a baseline, we are not sure if the mIoU results are good or not. It is better to provide some basic baselines.\nThe technique contribution may be limited. In general, it seems that the mse loss is basically requiring the model outputs of adversarial examples and target images to be the same. This objective and the optimization is very basic in adversarial attacks. The regularization loss mainly follows Zhang et al. (2020). The novelty may be limited.\nQuestions:\nsee the weakness.\nFlag For Ethics Review:\nYes, Privacy, security and safety\nDetails Of Ethics Concerns:\nAs the paper proposes practical blackbox attacks for large models SAM, it is better to discuss the potential social effects in the paper.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}]}, "My7lkRNnL9": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Forward-only learning, Biologically inspired learning, Artificial neural networks, Analytical characterization", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We discuss \"forward-only\" algorithms, provide an analytical characterization and test strategies to improve their performance.", "Abstract": "\"Forward-only\" algorithms, which train neural networks while avoiding a backward pass, have recently gained attention as a way of solving the biologically unrealistic aspects of backpropagation. Here, we first address compelling challenges related to the \"forward-only\" rules, which include reducing the performance gap with backpropagation and providing an analytical understanding of their dynamics. To this end, we show that the forward-only algorithm with top-down feedback is well-approximated by an \"adaptive-feedback-alignment\" algorithm, and we analytically track its performance during learning in a prototype high-dimensional setting. Then, we compare different versions of forward-only algorithms, focusing on the Forward-Forward and PEPITA frameworks, and we show that they share the same learning principles. Overall, our work unveils the connections between three key neuro-inspired learning rules, providing a link between \"forward-only\" algorithms, i.e., Forward-Forward and PEPITA, and an approximation of backpropagation, i.e., Feedback Alignment.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "pdf", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "applications to neuroscience & cognitive science", "Submission Number": "9371", "PDF Url": "https://openreview.net/pdf?id=My7lkRNnL9"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9371 by Area Chair 9zKv", "Subheading": "Meta ReviewbyArea Chair 9zKv05 Dec 2023, 23:52 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper focuses on forward-only learning algorithms, which are an alternative to backpropagation. The authors draw connections between forward-only algorithms, particularly PEPITA, and feedback alignment. The reviewers generally agree that the insights are useful and the paper is well written. However, they have raised concerns, e.g., about the limited scope of the empirical and theoretical evaluation. The authors have somewhat addressed these concerns, however, as with much of the \u2018biologically-plausible\u2019 neural network literature, the results are obtained using small networks on relatively simple datasets and do not completely match/outperform backpropagation.\nJustification For Why Not Higher Score:\nThe paper explores a relatively restricted empirical setting. While the results of the paper are interesting, the empirical evaluation is not sufficiently significant to warrant a spotlight or oral.\nJustification For Why Not Lower Score:\nThis paper is borderline, with two reviewers recommending acceptance and two reviewers recommending marginal rejection. The main weaknesses pointed out by the reviewers with lower scores pertain to the empirical evaluation. While I share their concerns, I believe that these evaluations are inline with previous works in the literature. Thus, given that the reviewers found the insights of the paper worthwhile, I would tend to favor acceptance."}, {"Heading": "Official Review of Submission9371 by Reviewer sGVa", "Subheading": "Official ReviewbyReviewer sGVa01 Nov 2023, 02:13 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nForward-only learning algorithms are an alternative to backpropagation (BP), which are potentially more biologically plausible, more memory efficient, and more computationally efficient.\nTwo of these forward-only learning algorithms are Forward-Forward (FF) and PEPITA, the Present the Error to Perturb the Input To modulate the Activity learning rule; both algorithms rely on two forward passes to learn, rather than a forward and a backward pass.\nHowever, the learning dynamics of these algorithms are not well understood, and both still include components that are biologically implausible.\nIn this work, the authors offers an explanation of how PEPITA learns by connecting them to feedback alignment.\nThey then use their insight to improve the performance of PEPITA by combining it with weight mirroring, a technique to improve performance of feedback alignment, as well as weight decay and activity normalization.\nFinally, they propose PEPITA-time-local, an alternative learning rule that improves the biological plausibility of PEPITA by keeping updates local in time (in addition to space), at the cost of some accuracy.\nSoundness:\n4 excellent\nPresentation:\n3 good\nContribution:\n4 excellent\nStrengths:\nThis paper exposes a novel connection between feedback alignment and forward-only algorithms. This connection is particularly interesting because both type of algorithms have improving biological plausibility as a principal goal; exposing underlying relationships may mutually benefit researchers for both types of algorithms. In fact, the authors have already taken a step in this direction, by empirically showing that weight mirroring, a technique developed for feedback alignment, can also be used to improve the performance of PEPITA.\nAs the authors also point out, while forward-only learning algorithms have gained traction in recent years, and are gradually catching up to the performance of backpropagation on increasingly complex tasks, theoretical understanding of their learning dynamics is mostly lacking; work that shed light on how forward-only learning works is very welcome.\nThe experiments performed are extensive, and the results are convincing.\nWeaknesses:\nThe theoretical analysis focuses only on shallow 2-layer networks, and I\u2019m uncertain that the Adaptive Feedback rule can be easily extended to analyze deeper networks, as the error signal has to pass through multiple hidden layers either forwards (forward-only) or backwards (feedback alignment). This limits the applicability of the analysis, making it disjoint from the experimental results on multi-layer PEPITA networks.\nQuestions:\nFigure 3 shows the performance of PEPITA-Hebbian, PEPITA + weight decay, and PEPITA + weight mirroring on CIFAR-10. Do the same trends hold for MNIST and CIFAR-100?\nI\u2019m a bit confused on how much the PEPITA-Hebbian approximation impacts the accuracy of the model. Figure 3a shows that the impact is very small on CIFAR-10, maintaining over 50% accuracy on CIFAR-10 for 1, 2, and 3 hidden layers, but in Figure S1 the accuracy of a 1-layer PEPITA-TL model drops to around 40%. Could you explain why this is? If this is due to hyperparameter differences, how well would a non-TL PEPITA model compare in performance under the same hypersparameters/conditions as those used for Figure S1?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 21:46Everyone", "Content": "Comment:\nWe thank the reviewer for highlighting the strengths of our paper. Below, we provide detailed answers to the reviewer's concerns.\nWeaknesses\nThe reviewer is right in observing that our theoretical analysis is limited to one-hidden layer networks. Our goal is to elucidate the alignment phenomenon initially observed in the paper introducing the PEPITA algorithm [Dellaferrera & Kreiman, 2022], which considers one-hidden layer networks. Further work would be required to study the multi-layer case, but our approximation suggests that a perturbative approach could be useful in this direction. We stress that the analytical frameworks to study the dynamics of learning in deep networks are still very limited, and \u2013 to the best of our knowledge \u2013 tracking analytically the average performance of deep nets with non-linear activations is still an open problem even for networks trained with back-propagation. One possible preliminary step to elucidate the alignment phenomenon in the multi-layer case would be to consider deep linear networks. We added a comment in Sec. 7.\nQuestions\nAs shown in Table S1, the performance decreases for 3-hidden-layer networks for MNIST (95.07% accuracy) and CIFAR-100 (drops to random chance). For CIFAR-100 weight decay allows us to train the 3-hidden-layer network (23.13% accuracy). We run additional experiments to test PEPITA Hebbian in MNIST and CIFAR-100 with 1-, 2-, and 3-hidden layer networks and we observe less than 0.15% difference (statistically insignificant) in accuracy between PEPITA and PEPITA Hebbian.\nIn the work by [Dellaferrera and Kreiman, 2022], the authors show that the presynaptic term ($h_{\\ell - 1}^{err}$) can be replaced with the same term computer in the first forward pass ($h_{\\ell - 1}$) without changing the performance. For this reason, we expected the Hebbian learning rule in eq. 8 to perform equivalently to the original learning rule, which is empirically the case. In the time local version, the updates are computed separately, meaning that the update computed during the second forward pass is operating on the weights that have already been updated in the first forward pass. We suspect that separating the Hebbian and anti-Hebbian updates changes the loss landscape, although we leave this analysis for further work. With the same choice of hyperparameters, standard PEPITA also reaches around 40% accuracy, due to the low learning rate. Though these parameters were chosen using a grid search for PEPITA-TL, we conclude that the hyperparameter choice is not sufficient to explain the performance gap."}, {"Heading": "Official Comment by Reviewer sGVa", "Subheading": "Official CommentbyReviewer sGVa04 Dec 2023, 16:54 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nThank you for the clarifications. I believe this is a strong paper and maintain my stance on acceptance."}]}, {"Heading": "Official Review of Submission9371 by Reviewer QDBz", "Subheading": "Official ReviewbyReviewer QDBz31 Oct 2023, 14:17 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper connects several forward pass-only learning methods as biologically plausible alternatives to backprop, analyses their performance and error dynamics, and also proposes Hebbian and temporally local approximations for one of those methods.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n3 good\nStrengths:\nThe paper is well-written and does a good job articulating its aims and contributions.\nThe paper provides a theoretical link between several algorithms, and derives error dynamics (for a simple problem) for one of them.\nThe Hebbian/anti-Hebbian approximation works as well as the PEPITA algorithm, which is a good sign for bio plausibility (of both PEPITA and FF, since they work similarly).\nWeaknesses:\nPerformance on CIFAR10/100 of algorithms is lacking compared to backprop (although surprisingly much less so for CIFAR100). This performance gap would likely increase for larger networks.\nNo experiments with convnets, and I haven't found a justification for that. Since cifar10/100 performance gets much better with introducing convolutions (for backprop), it'd be interesting to look at the performance gap there.\nQuestions:\nIf I understand correctly, PEPITA-TL differs from PEPITA-Hebbian by one feature: the anti-Hebbian error term is computed for the updated weights. Based on that, I have two questions:\nWould performance of both algorithms match if we reduce the learning rate of PEPITA-TL? Intuitively it should, since the anti-Hebbian error terms would match.\nCan we consider PEPITA-Hebbian temporally local since it's a long-term plasticity rule? Since the network is trained with two passes over the same input, the PEPITA-TL approximation adds the first Hebbian term immediately after the first forward pass, so 10s/100s of ms. This would be too short for long-term Hebbian changes (as far as I know), so in your model you can treat both parts of the update rule as if they happen for the same network state -- meaning that PEPITA-Hebbian would be temporally local. (I guess you can account for short-term plasticity as a result of the first forward pass (so non-Hebbian changes proportional to input activity only).)\nSmall comments:\nTab1 should have PEPITA-Hebbian performance too.\nThe appendix can be included in the main pdf in this conference.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 21:48Everyone", "Content": "Comment:\nWe thank the reviewer for the positive comments on our work. We address the concerns and questions below.\nWeaknesses\nGenerally, achieving superior outcomes compared to back-propagation in the field has proven challenging. Typically, we resort to utilizing approximations to back-propagation. For instance, DFA [Nokland 2016], among various examples, initially employed relatively shallow networks and exhibited poorer performance than back-propagation. It took a few years for the community to enhance it for deeper networks. We believe that our work provides the insights necessary to improve the performance of these types of algorithms.\nIn [Dellaferrera & Kreiman, 2022], the authors show that the algorithm can work well on CNNs too. In this work, we focused on other aspects, in particular on the theoretical analysis, which can be performed on fully connected networks. We leave the extension of our results to future work.\nQuestions\nWe have run experiments with PEPITA using the same hyperparameters as the best ones for PEPITA-TL. With this choice of hyperparameters, standard PEPITA also reaches around 40% accuracy, due to the low learning rate. Though these parameters were chosen using a grid search for PEPITA-TL, we conclude that the hyperparameter choice is not sufficient to explain the performance gap.\nWe thank the reviewer for the interesting insight. We provide an answer from two different perspectives. From the hardware implementation perspective, we say that a rule is temporally local if the updates are computed without the need to store any information in memory. This is the case for PEPITA-TL, which computes updates on the fly without any need to keep activations in memory. Instead, PEPITA-Hebbian needs to store the activations of the first forward pass and then use them for the update. From the biological perspective, we believe that the reviewer\u2019s insight is very interesting: on the timescale of neural plasticity, we agree that PEPITA-Hebbian might be temporally local, which would also mean that PEPITA is.\nSmall comments:\nWe agree with the reviewer, and we added PEPITA-Hebbian and PEPITA+WM in Table 1."}, {"Heading": "Official Comment by Reviewer QDBz", "Subheading": "Official CommentbyReviewer QDBz21 Nov 2023, 13:43Everyone", "Content": "Comment:\nThank you for the response! Having looked at this and other responses/reviews, I keep my current score/recommendation of accept."}]}, {"Heading": "Official Review of Submission9371 by Reviewer uKzr", "Subheading": "Official ReviewbyReviewer uKzr30 Oct 2023, 02:53 (modified: 22 Nov 2023, 01:07)EveryoneRevisions", "Content": "Summary:\nThis paper analyzes the Present the Error to Perturb the Input To modulate the Activity (PEPITA) learning algorithm, showing its connection to Direct Feedback Alignment (DFA) as well as Forward-Forward (FF) algorithm with negative samples being the \u201cmodulated\u201d samples in PEPITA. Some empirical experiments also study PEPITA on deeper networks and with several techniques.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThis paper studies the connections between several biologically more plausible algorithms, providing insights from empirical and analytical perspectives.\nWeaknesses:\nI think this paper requires a clearer definition of the considered \u201cforward-only\u201d algorithms. In the abstract, it is defined as \u201cavoiding a backward pass\u201d. However, PEPITA, different from local FF, indeed requires a direct global error feedback to inputs. If PEPITA is considered as \u201cforward-only\u201d, is DFA also \u201cforward-only\u201d, as it shares the similar form of direct global error feedback without layer-by-layer BP? In the sense of \u201cforward-only\u201d algorithms, I don\u2019t think PEPITA is parallel to FF with local learning.\nIn Table 1, why the considered rule has a much worse performance? It is unclear why we should consider it as it does not introduce additional properties over several algorithms while being worse. Additionally, what\u2019s the detailed definition for \u201clocal\u201d and \u201cactivity freezing\u201d? For PEPITA, it requires global error feedback to inputs, and storage of activations of the first forward propagation until the second forward propagation ends. Why it is considered \u201clocal\u201d and solving \u201cactivity freezing\u201d? And why PEPITA outperforms DFA in these aspects?\nIn Section 3.1, the similarity to DFA only holds for the first layer. It is unclear for other layers (Eq. (4)).\nIn Section 4, the networks are still quite shallow and experimental results are quite poor. DFA can scale to large datasets and networks [1], and WM also scales to large-scale scenarios [2].\nSome derivations are not strict and may be contradictory. For example, in Section 3 and Section 5, it is assumed for several times that $Fe$ is much smaller than $x$ so it can be ignored. In Section 5, however, it is also assumed that the \u201cmodulated\u201d samples can be used for negative samples in the FF framework. If the modulation is small enough, why can it formulate a valid negative sample? This largely reduces the reliability of the connection between PEPITA and FF.\nOverall, I think there is no enough contribution in empirical or theoretical perspectives.\n[1] Direct feedback alignment scales to modern deep learning tasks and architectures. NeurIPS, 2020.\n[2] Deep learning without weight transport. NeurIPS, 2019.\nQuestions:\nIn Section 3.2, what\u2019s the difference between the analysis and previous analyses for DFA?\nIn Section 5.1, what\u2019s the connection of the derivation with contrastive Hebbian learning [1] or equilibrium propagation [2], which also takes the form of Hebbian and Anti-Hebbian phases?\n[1] Equivalence of backpropagation and contrastive Hebbian learning in a layered network. Neural Computation, 2003.\n[2] Equilibrium propagation: bridging the gap between energy-based models and backpropagation. Frontiers in Computational Neuroscience, 2017.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 21:50Everyone", "Content": "Comment:\nWe thank the reviewer for their insightful comments. The point-to-point answer is provided below.\nWeaknesses\nA key difference between DFA and PEPITA/FF is that DFA requires the computation of gradients of activation explicitly. This means that because the feedback is added after the non-linearity, an additional backward computation is needed. In FF and PEPITA, instead, the update only depends on activations computed during the forward pass. We also note that in [Hinton, 2022], the author mentions the possibility of negative samples constructed using top-down connections, which is the case for PEPITA. Moreover, we note that in forward learning algorithms, the error does not travel by itself throughout the network and that the networks continuously respond to inputs (original or modulated/negative), unlike in DFA where a forward pass is followed with a backward pass containing the error info.\nWe thank the reviewer for the questions. First, we want to clarify the difference between spatial and temporal locality. Spatial locality refers to rules that use only local information (unit activation). In [Nokland, 2016], the author mentions that the update is \u201calmost local\u201d. This is due to the fact that the feedback is added after the nonlinearity, and the update needs to compute the derivative of the activation, causing the update to be non-local (it would be local with linear activation). Instead, PEPITA does not require any computation that does not depend on local signals (unit activation). Temporal locality refers to rules that do not need to store the activations in memory, and are able to compute updates on only temporally-local information. This is the case for PEPITA-TL, which updates the weights on the fly. We note that PEPITA-TL is the only temporally-local rule in Table 1. Second, in DFA - similarly to BP - activity freezing is a consequence of alternating a forward pass (the network responds to an input, and the nodes are \u201cactive\u201d) and a backward pass (the error information travels through the network from the top to the bottom layers, but the network does not process any inputs, thus the nodes are \u201cinactive\u201d or \u201cfrozen\u201d). In PEPITA and in FF, the error never travels through the network \u201cby itself\u201d to drive the updates. The network always responds to an input in a forward fashion - the input is modulated through the error in PEPITA, the negative samples in FF. Last, we would like to note that this paper is not proposing the PEPITA algorithm, but rather an analytical characterization of the latter. Locality and activity freezing are explained thoroughly in the work by [Dellaferrera & Kreiman, 2022].\nAs specified at the beginning of Sec. 3, we focus on two-layer networks for our theoretical results. Sec. 3.1 is aimed at providing an analytical understanding of the alignment phenomenon observed in the paper introducing the PEPITA algorithm [Dellaferrera & Kreiman, 2022] that considered two-layer networks. Our approximation suggests that a perturbative approach could be insightful to understand the PEPITA learning rule in deeper networks. The analytical characterization of the dynamics of deep non-linear networks is to a large extent still an open problem even for networks trained with back-propagation and goes beyond the scope of our work.\nWe thank the reviewer for pointing out the work of [Launay et al 2020] and [Aktrout et al 2019], which we now cite. The reviewer raises valid points. In general, it has been hard to get better results than using back-propagation in the field. We usually refer to approximations to back-propagation. As one example of many, DFA [Nokland 2016] also started with relatively shallow networks and worse performance than back-propagation and it took a few years for the community to extend it to deeper networks [Launay et al 2020, as cited by the reviewer], and even in these deeper networks, back-propagation generally outperforms DFA (though DFA is a very reasonable approximation, [Laynay et al 2020]). Such approximations can still be interesting due to their biological plausibility, theoretical understanding of learning, and the possibility of implementing them in neuromorphic hardware."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 21:51Everyone", "Content": "Comment:\nWe respectfully disagree with the reviewer\u2019s point that the magnitude of $Fe$ impacts the connection between PEPITA and FF. First, we point out that the small magnitude of $Fe$ is not an assumption, but it is instead a result that we confirmed empirically. Indeed, the approximation of the PEPITA rule (eq. 6) can only hold if $|Fe|\\ll| x|$. The latter is confirmed by Figure 2a and Figure S3: in this figure, we compare models trained with PEPITA versus identically-initialized models trained with AFA (eq.6). The almost identical training curve confirms that the approximation holds, and consequently that $|Fe|\\ll| x|$. Having proved this, we use the same result (not assumption) for Section 5. The fact that despite the small magnitude the feedback can generate valid negative samples is proven by the empirical results we obtain when training networks (Table 2). To answer \u201cwhy\u201d this is possible, we present an analysis of the learning mechanism of PEPITA (Section 3), we show that our theory matches the empirical results (Figure 2A-B, Appendix D) and we further elucidate the dynamics of learning, and the alignment mechanism (Appendix E).\nQuestions\nFrom a technical point of view, the main difference between the analysis of DFA in [Refinetti et al., 2021a] and our derivation in Sec. 3.2 is that our formalism requires an additional ODE for the dynamics of the adaptive feedback. The emergence of adaptive feedback as a natural order parameter governing the dynamics of learning is a theoretical confirmation of the experimental insight in [Dellaferrera & Kreiman, 2022]. Moreover, our results suggest that a perturbative approach (which is not necessary for DFA) is insightful for the analysis of PEPITA.\nWe thank the reviewer for the interesting question. In both [Xie and Seung, 2003] (equation 2.6) and [Scellier and Bengiom 2017] (Section 2.4) we find very clear similarities with PEPITA-Hebbian in terms of the update rule. Moreover, both algorithms, as well as PEPITA, work on perturbations that are propagated through the network, which treats clean and perturbed signals differently (Hebbian and anti-Hebbian phases). The main difference stems from how the perturbation is propagated through the network: while PEPITA adds the perturbation to the input using a random feedback matrix (thus avoiding the weight transport problem), in both [Xie and Seung, 2003] and [Scellier and Bengiom 2017] the perturbation is fed to the output layer and propagated through weights symmetrical to the forward weights, which is an issue from the biological perspective."}, {"Heading": "Official Comment by Reviewer uKzr", "Subheading": "Official CommentbyReviewer uKzr22 Nov 2023, 01:06Everyone", "Content": "Comment:\nThank you for the response. Some of my questions are addressed, e.g., the comparison with DFA and the magnitude of $Fe$, and I raise my score to 5. I have some additional comments.\nIn PEPITA, there is also a traveling of error from top to input, while DFA propagates errors to each layer. To what extent the error traveling you think is more acceptable? From the neuroscience perspective, three-factor learning rules with a top-down signal are valid and have been verified [1]. And considering biological spiking neural networks, errors from DFA can be combined with local eligibility traces [2] (the presynaptic activities and derivatives of the nonlinearity of postsynaptic neurons can be maintained in the trace), not necessarily breaking locality. On the other hand, a two stage of \u201cclean\u201d and \u201cmodulated\u201d passes poses challenges for neural systems to distinguish the stage for update rules, and while PEPITA-TL is considered temporally local, it requires some temporal information to distinguish the stage for Hebbian or anti-Hebbian, so it is still not fully local.\nIf PEPITA-Hebbian mainly differs from previous Hebbian and anti-Hebbian methods considering the weight transport problem, there seems some previous works also consider this problem with random feedback [3].\n[1] Control of synaptic plasticity in deep cortical networks. Nature Reviews Neuroscience, 2018\n[2] A solution to the learning dilemma for recurrent networks of spiking neurons. Nature Communications, 2020.\n[3] Contrastive Hebbian learning with random feedback weights. Neural Networks, 2019."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 21:12Everyone", "Content": "Comment:\nWe thank the reviewer for the interesting questions and for raising the score. Here are our replies to the additional questions:\nWe thank the reviewer for the references, which we are now citing. We do not have a clear answer on whether three-stage or two-stage algorithms are more consistent with plasticity in biological systems. Regarding DFA\u2019s locality, we agree that DFA can be considered local in the case of spiking neural networks. The current work and a large number of discussions around approximations to backpropagation focus on non-spiking artificial neural networks. We thank the reviewer for suggesting [1], which we are now citing in our discussion section to explain a possible biological mechanism for PEPITA-TL. Indeed, in [Dellaferrera & Kreiman, 2022], the authors speculate that the projection matrix can be linked to the cortico-thalamo-cortical loops throughout the neocortex, while the first forward pass is computed directly on the input (sensory pathway). Thus, different modulatory signals might be activated during the first and second forward passes. Specifically, the different modulatory signals might indicate whether the activity should be maximized or minimized in the case of PEPITA-TL. The literature supports the anatomical separation between pathways (a summary of which can be seen in Fig. 4 in [Lillicrap et al., 2020]). This view is compatible with the reviewer\u2019s perspective on DFA and with the PEPITA update rule.\nWe thank the reviewer for suggesting [3]. We agree with the reviewer about the similarity in Hebbian and anti-Hebbian terms between [3] and PEPITA, although the algorithm in [3] still suffers from the activity-freezing problem and the update-locking problem, similar to FA. Despite these differences, given that the update rules (not considering the feedback path) suggested by the authors in this and the previous comment have a high degree of similarity with PEPITA, we are now citing [Detorakis et al., 2019; Xie & Seung, 2003;  Scellier & Bengio, 2017] in Section 5.1."}]}, {"Heading": "Official Review of Submission9371 by Reviewer knnT", "Subheading": "Official ReviewbyReviewer knnT25 Oct 2023, 08:52 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper provides further analysis of the PEPITA learning rule, a biologically-inspired \"forward-only\" approach to train neural networks by replacing the backward pass with another forward pass. In connects PEPITA theoretically to two other biologically-inspired approaches, namely an adaptive version of Feedback Alignment and Forward-Forward. Additionally, the paper explores how the initialization of the feedback weights and applying techniques like weight decay, activation normalization, and weight mirroring can improve PEPITA's performance. The experimental findings demonstrate minor improvements through normalization and weight mirroring.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nBiologically-inspired and forward-only training approaches are a relevant and timely topic.\nIt would be very useful to unify the multitude of different approaches into a common framework. By connecting three major biologically-inspired approaches, this paper takes an important step towards that goal.\nGiven the still-remaining gap between backpropagation and forward-only approaches, analyzing and improving their performance is essential for their practical relevance.\nSection 4.2 gives a well-structured summary of the experimental results. It would have been nice, to include a discussion of the impact of weight decay, activation normalization, and weight mirroring\nWeaknesses:\nThe experimental improvement and evaluation of PEPITA on their own offer only limited novelty. However, together with the analysis connecting PEPITA, FA, and Forward-Forward, this paper amounts to a considerable contribution.\nexperimental evaluation:\nonly small, fully-connected networks, not that suited to more complex vision datasets\nonly image classification (MNIST, CIFAR10, CIFAR100)\nno experimental comparison to Forward-Forward\nonly minor improvements in accuracy\nMinor Issues:\nFigures can be a bit hard to read\nin Fig 2 (especially 2b) the overlap of PEPITA and AFA is hard to see without zooming in\nFig 3 would benefit from more contrasting colors\nthe references to Figure 2c in the last paragraph of Section 3.2 seems to be mismatched with the actual order of subfigures in Figure 2\nTable 1, line 1 seems to have the wrong citation for FA\nSpelling:\nin contribution (vi) \"analitically\"\nin the last sentence of Section 1: \"gpus\" should probably be in uppercase, i.e. \"GPUs\"\nQuestions:\nWhich approach do the authors considers their primary contribution? Table 1 the authors refer to PEPITA-TL as \"ours\" yet this is only discussed briefly in Section 5.1 and left mostly to future work.\nWhy are the combinations \"weight-decay + normalization + WM\" and \"weight-decay + normalization + no WM\" missing in Table 2? Can weight decay and activation normalization not be combined?\nIn Figure 3c: shouldn't pre-mirroring increase the alignment (thus decreasing the angle) before the first epoch? Yet, in Figure 3c, all three lines seem to start at the same value.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 21:56 (modified: 20 Nov 2023, 11:31)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewer for their insightful comments. The point-to-point answer is provided below.\nWeaknesses\nWe thank the reviewer for appreciating the value of our theoretical results, beyond simple contributions in performance and accuracy.\nExperimental evaluation:\nOur work extends previous work that impeded training deeper networks with the original PEPITA method, and so improves on the complexity of networks that PEPITA can work with. Overall, many local or biologically plausible training algorithms in present-day literature are not yet ready to be tested on challenging large-scale datasets and highly complex network architectures.\nIt is unfortunately common in the literature to use image classification tasks as the initial benchmark of new training algorithms. We share this choice with Hinton\u2019s FF paper and others in the same area (e.g. [Ororbia and Mali, 2023]). We do think it would be interesting to extend this work to other types of tasks, particularly to time-dependent datasets, where a forward-only algorithm can be especially useful for analyzing incoming data in real-time. However, this is best treated in a separate paper, where we can focus on the specific needs of such a case.\nAt this time, we are not aware of any implementation of Forward-Forward which utilizes feedback connections to generate the negative samples, as proposed by [Hinton, 2022]. Given the significant difference, we decided not to compare PEPITA to Forward Forward with externally generated samples. Despite this, for completeness, we have added the results that FF achieves on MNIST as reported in [Hinton, 2022].\nAs was pointed out above by reviewer sGVa, the performance of forward-only algorithms has been catching up in recent years, but what is lacking is the theoretical understanding of their learning dynamics. Our aim is not yet to apply PEPITA to real-world tasks but to understand which tools may or may not lead to performance improvements, and why, in order to guide further development. In this respect, small improvements are also informative, and even negative results are valuable lessons.\nMinor issues:\n6-7-8. We thank the reviewer for these suggestions, we are currently working to implement them in the paper.\nWe thank the reviewer for noticing this mismatch. We have now correctly referred to Fig.2d at the end of Sec. 3.2\nWe thank the reviewer for noticing this. The table now reports Lillicrap 2016 instead.\nSpelling:\nWe thank the reviewer for catching the typo. We have corrected this in the revised version of the manuscript.\nWe thank the reviewer for the suggestion. In the revised version you will now find \u201cGPUs\u201d.\nQuestions\nWe thank the reviewer for the fair question. We consider our primary contribution the theoretical analysis of the nonintuitive learning dynamics of PEPITA, the study of training techniques that lead to improved performance, and the connections with FF and DFA. Overall, we believe that these different characterizations help us build a common framework to study forward-learning rules. The reason why we included PEPITA-TL in Table 1 is to have a complete comparison. Figure S1 shows that training with PEPITA-TL is possible, but we leave the study necessary to make its performance competitive for future work. Moreover, we have added PEPITA-Hebbian and PEPITA+WM in Table 1.\nWe thank the reviewer for the question. To find the best hyperparameters for training with activation normalization we run a grid search, which includes searching for the optimal value of weight decay. In all cases with normalization, the grid search returns no weight decay, for this reason, we did not include the combination of normalization and weight decay in the table.\nWe thank the reviewer for the question. The fact that at the start of the training, the angles look identical is due to the small learning rate for WM that the grid search has returned (Table S3). This causes pre-mirroring to have a small effect on the angle, although the effect is noticeable in terms of slowness (Table S2). For MNIST and CIFAR-100, the grid search returns higher learning rates for WM (Table S3), and the effect is more noticeable both in the angles (Figure S6) and in the slowness (Table S2)."}]}]}, "xibcBSuuq0": {"paper_info": {"Primary Area": "reinforcement learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "MARL, Trembling Hands, Exploration, Exploration, Prefix Policy", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "In multi-agent reinforcement learning (MARL), the $\\epsilon$-greedy method plays an important role in balancing exploration and exploitation during the decision-making process in value-based algorithms. However, we find that $\\epsilon$-greedy can be deemed as the concept of \"trembling hands\" in game theory when the agents are more in need of exploitation, which may result in the Trembling Hands Nash Equilibrium solution, a suboptimal policy convergence. Besides, eliminating the $\\epsilon$-greedy algorithm leaves no exploration and may lead to unacceptable local optimal policies. To address this dilemma, we use the previously collected trajectories to plan an existing optimal template as candidate policy, which we call \\textbf{Stable Prefix Policy}, in contrast to trembling hands. When the policy is close to the optimal policy, the agents follow the planned template, and when the policy still needs exploration, the agents will adaptively dropout. We scale our approach to various value-based MARL methods and empirically verify our method in a cooperative MARL task, SMAC benchmarks. Experimental results demonstrate that our method achieves not only better performance but also faster convergence speed than baseline algorithms within 2M time steps.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9370", "PDF Url": "https://openreview.net/pdf?id=xibcBSuuq0"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9370 by Area Chair JuQz", "Subheading": "Meta ReviewbyArea Chair JuQz05 Dec 2023, 23:54 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper studies the exploration-exploitation tradeoff in multi-agent reinforcement learning, by proposing a new method of constructing some Stable Prefix Policy using Monte-Carlo Trajectory Tree. The paper studies an interesting problem, with new algorithmic ideas. However, it reaches a consensus that the paper could be improved by providing more effective and sufficient experimental results, in terms of comparisons with baselines, and testing the settings beyond the cooperative ones. The theoretical results and writing may use some improvement also. Thus, I suggest the authors incorporate all the feedback and resubmit to some upcoming ML venues.\nJustification For Why Not Higher Score:\nThe paper has a number of aspects that might need to be further improved. The rebuttals have not fully addressed all the comments from the reviewers.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9370 by Reviewer RkkR", "Subheading": "Official ReviewbyReviewer RkkR10 Nov 2023, 04:52 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn order to balance between exploration and exploitation during the training process, the authors encourage the policy to follow the optimal trajectory as planned by a Monte-Carlo Trajectory Tree (MCT\u00b2). The MCT\u00b2 is built upon historical trajectories, wherein states are organized into clusters via KMeans clustering. Within the MCT\u00b2 framework, state values within the same cluster node are concurrently updated. The authors leverage PUCB values to find the optimal path across these clusters. During the rollout, when the actual state (cluster) diverges from the predicted state (cluster), the policy adopts an \u03b5-greedy approach to facilitate exploration.\nExperiments conducted within the SMAC benchmark show that the proposed method accelerates training and can be integrated into various MARL algorithms, including QMIX, QPLEX, and OW_QMIX.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe authors innovatively apply Monte-Carlo Tree structure into MARL context, leading to increased training speed. The proposed method may be applied to various existing MARL algorithms, thereby potentially contributes to the field of MARL research.\nWeaknesses:\nThe experiment results do not conclusively demonstrate the effectiveness of the proposed method. In Figure 8, the performance of the proposed policy closely mirrors that of the original QMIX implementation. I would suggest the authors to test on more challenging MARL benchmarks, though those benchmarks often require more exploration, which may pose challenges for the proposed method.\nAlso, many MARL algorithms already suffer from a lack of exploration. The proposed method, in its pursuit of faster convergence, makes the additional trade-off of further diminishing exploration in favor of exploitation. This strategy necessitates careful consideration due to the potential consequences it may have on the algorithm's overall effectiveness.\nQuestions:\nIn Section 6, the authors claim that the proposed method can be applied to the critic training in Actor-Critic MARL alrogithms. Can you briefly describe how to implement the proposed method in, say, MAPPO? And what is the performance improvement when applying to MAPPO?\nIn the matrix game presented in Section 1, should the $epsilon$ for player 1 be 0.1?\nCan the proposed method be applied to scenarios with continuous action spaces?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Respond to Weaknesses", "Subheading": "Official CommentbyAuthors20 Nov 2023, 23:04Everyone", "Content": "Comment:\nWe thank the reviewer for the detailed review of our paper. After reading the reviews, we address your concerns below and update a revision of our paper. Please let us know if further clarification is needed.\nIn Figure 8, the performance of the proposed policy closely mirrors that of the original QMIX implementation. I would suggest the authors test on more challenging MARL benchmarks.\nIn this paper, we provide our main experimental results in Figure 5 which contains the challenging subtasks of the SMAC environment. Among the subtasks, the 5m_vs_6m, 3s_vs_5z, and 2c_vs_64zg tasks are hard tasks. Not all the baseline algorithms can achieve good results. Additionally, the subtasks including MMM2, 3s5z_vs_3s6z, and 6h_vs_8z are super-hard tasks. Experimental results on these tasks within 2M time steps can show the better performance of our approach. In contrast, Figure 8 shows the other tasks in the SMAC environment and most of them are easy tasks in which the original QMIX as well as other baseline algorithms can achieve acceptable results. This might be the reason why our proposed policy closely mirrors that of the original QMIX.\nThe proposed method, in its pursuit of faster convergence, makes the additional trade-off of further diminishing exploration in favor of exploitation.\nOur method suggests dividing the decision-making of the existing MARL methods into two phases: our Stable Prefix Policy and vanilla policy. SPP balances the exploration and exploitation during the trajectory planning process with UCT, and we further apply Dirichlet noise to the planning phase, which gives more explorations. SPP explores more globally and centrally compared to existing popular MARL methods."}, {"Heading": "Resond to Questions", "Subheading": "Official CommentbyAuthors20 Nov 2023, 23:07 (modified: 20 Nov 2023, 23:12)EveryoneRevisions", "Content": "Comment:\nIn Section 6, the authors claim that the proposed method can be applied to the critic training in Actor-Critic MARL algorithms. Can you briefly describe how to implement the proposed method in, say, MAPPO? And what is the performance improvement when applying to MAPPO?\nIn the Actor-Critic MARL algorithms, actor networks are responsible for training the action distributions conditioned on observations and the critic networks train the values of states. Applying our SPP method to the Actor-Critic method includes (i)assembling the values with the same cluster nodes and (ii)removing the actors' explorations by taking the maximum of the distributions and using the trajectory templates generated by the planning process to determine whether to interrupt the process and resume single-step explorations like non-SPP-augmented methods. Our approach contributes to the performance improvement of the Actor-Critic method in two ways: on the one hand, assembles the values with the same cluster nodes so that the values for training are more accurate; on the other hand, it determines whether the elimination of the exploration of the first half of the strategy can lead to more fine-grained improvements in the second half of the strategy by planning, which has already balanced exploration and exploitation by UCT.\nTo focus on the efficiency aspects, we chose three subtasks to show the performance of the MAPPO and our SPP-augmented MAPPO within 2M time steps. The experimental results indicate that our method can improve the performance of Actor-Critic MARL methods. The items in the table are the average winning rates (%) among 5 seeds and their variances.\nMMM2\n0.5M\n1M\n1.5M\n2M\nMAPPO\n4.46$\\pm$9.97\n17.27$\\pm$30.11\n34.27$\\pm$35.44\n42.65$\\pm$37.72\nSPP+MAPPO\n9.34$\\pm$5.54\n46.81$\\pm$19.63\n51.03$\\pm$14.95\n62.42$\\pm$14.98\n5m_vs_6m\n0.5M\n1M\n1.5M\n2M\nMAPPO\n6.57$\\pm$1.47\n17.83$\\pm$16.47\n45.38$\\pm$15.48\n49.58$\\pm$23.32\nSPP+MAPPO\n36.58$\\pm$6.54\n53.32$\\pm$11.27\n57.57$\\pm$11.19\n60.65$\\pm$10.56\n3s5z_vs_3s6z\n0.5M\n1M\n1.5M\n2M\nMAPPO\n8.00$\\pm$1.79\n1.96$\\pm$3.92\n9.17$\\pm$17.84\n13.09$\\pm$21.71\nSPP+MAPPO\n5.63$\\pm$0.97\n7.29$\\pm$12.63\n15.02$\\pm$26.02\n20.80$\\pm$35.85\nIn the matrix game presented in Section 1, should the epsilon for player 1 be 0.1?\nYour concerns are much appreciated. We double-check the corresponding section. With $\\epsilon$ set to 0.2, the player will have a 0.8 probability of going into the greedy mode and a 0.2 probability of going into a mode where the action is chosen randomly; however, since there is also a 0.1 probability that the original greedy action will be chosen in random mode, the value of $\\epsilon$ should be taken as 0.2, at which point the greedy action will take the value of 0.1\nCan the proposed method be applied to scenarios with continuous action spaces?\nThe original intent of our paper was to address the problem of trembling hands that exists in value-based MARL methods. However, our SPP method contains major components: the UCT planning[1], Q-value assembling and cancelation of action noise are technically applicable to continuous action spaces. We have found that our approach is surprisingly able to improve the performance of Actor-critic based, so we are reasonably confident that our SPP approach is also capable of applying to continuous action spaces. We will actively search for suitable benchmarks for testing and welcome your further suggestions.\nIn the remaining time we would like to address the remaining concerns that you have that prevent you from accepting the paper. We would appreciate it if you could engage with us on the remaining concerns, as we want to address them.\n[1] Hubert, Thomas, et al. \"Learning and planning in complex action spaces.\" International Conference on Machine Learning."}, {"Heading": "Official Comment by Reviewer RkkR", "Subheading": "Official CommentbyReviewer RkkR22 Nov 2023, 22:15Everyone", "Content": "Comment:\nSorry for the late reply. I appreciate authors for the detailed response addressing my concerns. However, there are a few additional queries I have regarding the paper.\nFinal Performance Comparison. While the use of SPP appears to accelerate training during the early phase, I am interested in the final performance of MARL algorithms with and without SPP. Can you provide the final performance comparison of QMIX and MAPPO on SMAC?\nSPP's Performance Beyond SMAC Scenarios. Your experiments suggest that most scenarios in SMAC are not challenging enough and therefore weaken your results. Can you test SPP in other environments?\nYour response mentioned that \"SPP explores more globally and centrally compared to existing popular MARL methods.\" Could you further explain how it explores globally and centrally at the same time?\nOverall, I would like to keep my score as it stands now."}, {"Heading": "Additional results and answers", "Subheading": "Official CommentbyAuthors23 Nov 2023, 03:07Everyone", "Content": "Comment:\nWe thank the reviewer for the detailed review of our paper and the reply. Based on the three points, we will try our best to address your concerns.\nFinal Performance Comparison. While the use of SPP appears to accelerate training during the early phase, I am interested in the final performance of MARL algorithms with and without SPP. Can you provide the final performance comparison of QMIX and MAPPO on SMAC?\nWe have provided the final performances within 2M time steps in the appendix of our paper. Most of the easy tasks and hard tasks have already converged to near-optimal results and reached nearly 100% winning rates in later time steps. Thus we select some super-hard scenarios and test our approach against QMIX and MAPPO within 10M time steps. Due to the time limit and the new MAPPO integration, we only have time to finish the experiment of SPP+QMIX. The items in the table are the average value among 5 seeds.\nSPP+QMIX\nQMIX\nMAPPO\n3s5z_vs_3s6z\n0.928\n0.847\n0.894\ncorridor\n0.997\n0.851\n0.991\n5m_vs_6m\n0.905\n0.841\n0.915\n27m_vs_30m\n0.999\n0.998\n0.953\n6h_vs_8z\n0.873\n0.842\n0.903\nMMM2\n0.962\n0.875\n0.921\nSPP's Performance Beyond SMAC Scenarios. Your experiments suggest that most scenarios in SMAC are not challenging enough and therefore weaken your results. Can you test SPP in other environments?\nDuring this time, we also tested our approach on four academic scenarios from the Google Football environment against the QMIX algorithm. We do not have sufficient time to test many algorithms. The results are the average test scores among 5 seeds and are shown below:\ncounterattack_easy\n0.5M\n1M\n1.5M\n2M\nSPP+QMIX\n0.0014\n0.0292\n0.0675\n0.1367\nQMIX\n0.0008\n0.0085\n0.0178\n0.0178\ncounterattack_hard\n0.5M\n1M\n1.5M\n2M\nSPP+QMIX\n-0.0112\n0.0190\n0.0226\n0.0690\nQMIX\n-0.0005\n-0.0017\n-0.0001\n0.0193\n3v1_with_keeper\n0.5M\n1M\n1.5M\n2M\nSPP+QMIX\n0.0460\n0.0743\n0.1118\n0.1827\nQMIX\n0.0288\n0.0547\n0.0449\n0.1047\ncorner\n0.5M\n1M\n1.5M\n2M\nSPP+QMIX\n0.0178\n0.0233\n0.0500\n0.0668\nQMIX\n0.0103\n0.0205\n0.0150\n0.0232\nYour response mentioned that \"SPP explores more globally and centrally compared to existing popular MARL methods.\" Could you further explain how it explores globally and centrally at the same time?\nOur method suggests dividing the decision-making of the existing MARL methods into two phases: our Stable Prefix Policy and vanilla policy. SPP balances the exploration and exploitation during the trajectory planning process with UCT. 1) We sample a large number of trajectories to construct the MCT$^2$, so the UCT planning is based on most of the transitions in the replay buffer. Compared with TD updates within a mini-batch of trajectories, planning through the replay buffer provides more\nglobal\nexplorations. 2) The planning process does not consider the distributed execution and the credit allocation problem in MARL. Our method uses the global state or the observation concatenation of all the agents to perform feature abstraction for each step of the decision planning, which is more\ncentral\ncompared to the existing MARL approaches.\nIn the remaining time, we would like to address the remaining concerns that you have that prevent you from accepting the paper. We would appreciate it if you could engage with us on the remaining concerns, as we want to address them."}]}, {"Heading": "Official Review of Submission9370 by Reviewer 3kTw", "Subheading": "Official ReviewbyReviewer 3kTw30 Oct 2023, 03:44 (modified: 21 Nov 2023, 01:49)EveryoneRevisions", "Content": "Summary:\nIn order to alleviate the Trembling Hands Nash Equilibrium solution caused by the $\\varepsilon$-greedy method in multi-agent reinforcement learning, this paper proposes a Stable Prefix Policy (SPP). SPP can rebalance the exploration and exploitation process when the policy of agents is close to the optimal policy during the training process. The specific method is to implement a Monte-Carlo Trajectory Tree (MCT$^2$) to preserve the structure of previous trajectories, which can plan the existing optimal trajectory template. When agents follow this template during rollouts, the target value is assembled with other target values with the same trajectories. When the agents drop out from the template, the $\\varepsilon$-greedy method is activated afterward. SPP can be applied to any value decomposition framework, and experimental results in SMAC and MPE show that it can improve the performance of the basic algorithm.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThis paper introduces the concept of the trembling hands into cooperative multi-agent reinforcement learning, which is reasonable and novel. The two didactic tasks in the introduction section fully demonstrate that the Trembling Hand Perfect Nash Equilibrium does exist in multi-agent tasks, which provides sufficient reasons for the proposal of the Stable Prefix Policy.\nThis paper implements MCT$^2$, which can plan an existing optimal trajectory (EOT) based on the trajectories in the replay buffer. SPP calculates the target value for TD update by comparing the actual trajectory of the agent with EOT, which is indeed a very novel approach.\nKey resources (proofs, code, and replay videos) are available, and sufficient details are described such that an expert should be able to reproduce the main results.\nThe experimental results are thoroughly analyzed. For example, The dropout time step ratio in Figure 7 illustrates the working mechanism of SPP and is intuitive.\nWeaknesses:\nThe proposed method is based on the premise that agents should be capable of finding a policy toward success from historical interactions. In other words, SPP relies heavily on the performance of the underlying algorithm.\nThe trembling hands is a concept in multi-agent games, but this paper only provides solutions in cooperative scenarios (Dec-POMDP problems). At the same time, SPP is only applied to value decomposition methods.\nMCT$^2$ introduces more hyperparameters, which increases the difficulty and workload of hyperparameter tuning.\nThe proposed method was only evaluated on SMAC (the description of the experimental results in MPE is skimpy and unconvincing). SMAC is a popular multi-agent experimental platform but has been pointed out to have many shortcomings [1]. More and more researchers in the MARL community advocate conducting experiments in multiple different domains to evaluate the proposed algorithm comprehensively [2].\nReference\n[1] Ellis, Benjamin et al. SMACv2: An Improved Benchmark for Cooperative Multi-Agent Reinforcement Learning. 2022.\n[2] Gorsane, R. et al. Towards a Standardised Performance Evaluation Protocol for Cooperative MARL. 2022.\nQuestions:\nWhat is the value of the hyperparameter $t_{inter}$? How does its value affect the performance?\nThe target value $y_t$ in vanilla QMIX is $y_t = r_t+\\gamma\\max_{a^{t+1}}Q_{tot}(s^{t+1}, a^{t+1} )$, which is related to $s^{t+1}$. Why is $y^t$ still related to $s^t$ in Eq. (3)?\nIs there any theoretical basis to prove that $Q^t_{assem}$ is more accurate than the original $Q_{tot}$?\nI think that in some scenarios, the SPP variant may be more likely to fall into a local optimal solution. Suppose that in such a scenario, agents can easily access the state corresponding to the suboptimal solution, while the state corresponding to the global optimal solution is in the opposite direction and relatively difficult to access (for example, further away from the initial position of the agents). The SPP variant may directly give up early exploration and find it difficult to converge to the global optimal solution. Of course, the above issue can be alleviated by adjusting $c_{ucb}$, but this requires sufficient prior knowledge.\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nN/A\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Respond to Weaknesses", "Subheading": "Official CommentbyAuthors20 Nov 2023, 23:45Everyone", "Content": "Comment:\nWe thank the reviewer for the detailed review of our paper. We are motivated that you found the new perspective interesting and inspiring. After reading the reviews, we address your concerns below. Please let us know if further clarification is needed.\nThe proposed method is based on the premise that agents should be capable of finding a policy toward success from historical interactions. In other words, SPP relies heavily on the performance of the underlying algorithm.\nOur SPP approach divides the decision-making process into two stages: pre-decision based on planning and post-decision with action noise. Where the pre-decision is given through UCT planning, it is not necessarily required that the historical interactions contain a successful policy, which means that even if there are no successful policies in the historical trajectory, UCT planning is still able to select the regions with the highest value or exploration potential at the moment based on the existing interactions. In contrast to relying heavily on the base policy, our SPP approach takes advantage of this favorable property of UCT planning and instead improves the performance of the base policy. Our experimental results on SMAC benchmarks can fully validate this.\nThe trembling hand is a concept in multi-agent games, but this paper only provides solutions in cooperative scenarios (Dec-POMDP problems). At the same time, SPP is only applied to value decomposition methods.\nThank you very much for your comments. For the perspective of better demonstrating the performance improvement of our SPP method compared to the original MARL method, we choose to test our method on the most popular benchmarks with MARL algorithms in the current MARL community, which mostly require computing the joint utility function to reach a better equilibrium of the game, and thus focus on solving the problem of credit allocation for cooperative MARL. Technically, our SPP method works for those scenarios with suboptimal equilibria due to trembling hands. We will actively look for MARL benchmarks other than cooperative scenarios for testing and welcome your further suggestions.\nSMAC is a popular multi-agent experimental platform but has been pointed out to have many shortcomings [1]. More and more researchers in the MARL community advocate conducting experiments in multiple domains to evaluate the proposed algorithm comprehensively [2].\nWe also fully agree with this comment that the SMACv1 environment lacks randomness in initializing the task settings. SMACv2 in contrast provides the configuration settings including the number of agents and enemies, the initialized positions, and the probability of generating an agent type. However, as far as we are concerned, this configuration provides too much randomness (I'd like to call it unstable). We believe SMACv2 is more suitable to test the migration capability and few-shot scenario adaptation ability of an algorithm. Despite that, we tested our approach on three scenarios of the SMACv2 environment. The items in the table are the average winning rate among 5 seeds and their variance.\n5_vs_5\n0.5M\n1M\n1.5M\n2M\nMAPPO\n8,67$\\pm$4.82\n21.39$\\pm$7.91\n28.77$\\pm$6.56\n35.94$\\pm$9.24\nQMIX\n20.15$\\pm$4.59\n32.68$\\pm$5.80\n41.48$\\pm$5.74\n50.21$\\pm$3.12\nOur Approach\n19.07$\\pm$5.62\n38.97$\\pm$9.32\n45.11$\\pm$8.34\n52.24$\\pm$6.73\n10_vs_10\n0.5M\n1M\n1.5M\n2M\nMAPPO\n3.54$\\pm$2.50\n11.84$\\pm$1.85\n16.98$\\pm$2.18\n30.85$\\pm$7.77\nQMIX\n11.09$\\pm$2.24\n20.56$\\pm$4.48\n31.54$\\pm$6.75\n42.29$\\pm$12.41\nOur Approach\n6.70$\\pm$2.87\n24.48$\\pm$8.78\n37.75$\\pm$10.35\n43.45$\\pm$9.80\n10_vs_11\n0.5M\n1M\n1.5M\n2M\nMAPPO\n0.76$\\pm$0\n0.83$\\pm$0.91\n0.74$\\pm$0.47\n1.84$\\pm$1.29\nQMIX\n0.57$\\pm$0.44\n4.29$\\pm$2.61\n11.6$\\pm$3.62\n14.95$\\pm$2.05\nOur Approach\n0.34$\\pm$0.75\n4.51$\\pm$1.92\n10.3$\\pm$4.54\n12.67$\\pm$5.26\nAccording to the results, our proposed method can follow the performance of the baseline algorithm in the so-called unstable environments in 2M time steps."}, {"Heading": "Respond to Questions", "Subheading": "Official CommentbyAuthors20 Nov 2023, 23:50Everyone", "Content": "Comment:\nWhat is the value of the hyper-parameter $t_{inter}$? How does its value affect the performance?\nThe $t_{inter}$ value is the number of warm-up episodes. We need state data to train a KMeans classifier and this state data is collected within the $t_{inter}$ episodes. Additionally, the classifier and the MCT$^2$ are reconstructed every $t_{inter}$ episode to overcome the influence of policy shifts. In this paper, this hyper-parameter is empirically set as 500.\nThe target value $y^t$ in vanilla QMIX is $y^t=r^t+\\gamma \\max_{a_{t+1}}Q_{tot}(s^{t+1},a^{t+1})$, which is related to $s^{t+1}$. Why is $y^t$ still related to $s^t$ in Eq. (3)?\nSorry for the confusion caused by our mistakes. The $y^t$ is related to $s^{t+1}$ in Eq.(3) (currently Eq.(4) in the revised version). The revised formula is\n$$\ny^t=r^t + \\gamma[\\mathbb{1}(c^{t+1}=\\phi(s^{t+1}))\\cdot Q_{assem}^{t+1}(s^{t+1}) +(1-\\mathbb{1}(c^{t+1}=\\phi(s^{t+1})))\\cdot Q_{tot}(\\tau,a^{t+1})]\n$$\nand we have updated it in the paper.\nIs there any theoretical basis to prove that $Q_{assem}^t$ is more accurate than the original $Q_{tot}$?\nIn this paper, similar states belong to a prototype cluster with a value, so similar states share the same value. The $Q_{assem}^t$ is the average value of $Q_{tot}$. In such a way, the expectation of $Q_{assem}^t$ is the same as the expectation of original $Q_{tot}$. The $Q_{assem}^t$ provides lower variance.\nI think that in some scenarios, the SPP variant may be more likely to fall into a local optimal solution. Suppose that in such a scenario, agents can easily access the state corresponding to the suboptimal solution, while the state corresponding to the global optimal solution is in the opposite direction and relatively difficult to access (for example, further away from the initial position of the agents). The SPP variant may directly give up early exploration and find it difficult to converge to the global optimal solution. Of course, the above issue can be alleviated by adjusting cucb, but this requires sufficient prior knowledge.\nThank you very much for your comments, we would love to discuss this scenario with you. You say that states oriented to suboptimal solutions are very easy to reach while states oriented to global optimal solutions are very difficult to collect and that the vast majority of data collected by algorithms focusing on exploration in this scenario are suboptimal, and we believe that obtaining an accurate value estimation of the global optimal state that is distinguishable from the suboptimal data is also a very difficult task to solve in this case. Our approach includes an annealing-like process to target such scenarios, in addition to the possibility of tuning the parameters of the UCT to encourage exploration. During annealing the tree in $\\text{MCT}^2$ is destroyed and reconstructed, at which point the MARL algorithm resumes single-step exploration.\nIn the remaining time we would like to address the remaining concerns that you have that prevent you from accepting the paper. We would appreciate it if you could engage with us on the remaining concerns, as we want to address them."}, {"Heading": "I have raised my score to 5.", "Subheading": "Official CommentbyReviewer 3kTw21 Nov 2023, 01:49Everyone", "Content": "Comment:\nThanks to authors for the reply. Most of my concerns have been solved. But I still hope to see the results in more representative multi-agent domains, such as Google Research Football, and some other environments that are not Dec-POMDPs. After all, the trembling hand is a concept in general multi-agent games. And I think this paper still has a lot of room for improvement.\nI have improved my score, but I think the contribution of SPP still needs more convincing experimental results to support it."}, {"Heading": "Partial experimental results on Google Research Football", "Subheading": "Official CommentbyAuthors23 Nov 2023, 03:10Everyone", "Content": "Comment:\nThank you for your reply and raising the score. During this time, we also tested our approach on four academic scenarios from the Google Football environment against the QMIX algorithm. We do not have sufficient time to test many algorithms. The results are the average test scores among 5 seeds and are shown below:\ncounterattack_easy\n0.5M\n1M\n1.5M\n2M\nSPP+QMIX\n0.0014\n0.0292\n0.0675\n0.1367\nQMIX\n0.0008\n0.0085\n0.0178\n0.0178\ncounterattack_hard\n0.5M\n1M\n1.5M\n2M\nSPP+QMIX\n-0.0112\n0.0190\n0.0226\n0.0690\nQMIX\n-0.0005\n-0.0017\n-0.0001\n0.0193\n3v1_with_keeper\n0.5M\n1M\n1.5M\n2M\nSPP+QMIX\n0.0460\n0.0743\n0.1118\n0.1827\nQMIX\n0.0288\n0.0547\n0.0449\n0.1047\ncorner\n0.5M\n1M\n1.5M\n2M\nSPP+QMIX\n0.0178\n0.0233\n0.0500\n0.0668\nQMIX\n0.0103\n0.0205\n0.0150\n0.0232\nIn the remaining time, we would like to address the remaining concerns that you have that prevent you from accepting the paper. We would appreciate it if you could engage with us on the remaining concerns, as we want to address them."}]}, {"Heading": "Official Review of Submission9370 by Reviewer 4uBa", "Subheading": "Official ReviewbyReviewer 4uBa29 Oct 2023, 12:22 (modified: 22 Nov 2023, 14:55)EveryoneRevisions", "Content": "Summary:\nThe paper addresses the problem of trembling hands in multi-agent systems, namely the negative effect that exploration has on the coordination between agents. This effect is particularly evident when $\\espilon$-greedy policies are used as template policies. This work proposes a method to compute a template policy to be followed, instead of greedy policies, and offers some empirical evidence that the proposed method can be competitive on some experimental settings.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThe trembling hands problem plays a central role in multi-agent coordination and the idea to follow specifically designed policies instead of more standard policies might lead to original results.\nWeaknesses:\nUnfortunately, the limitations of this work are extensive and I believe structural. The exposition is the main factor concerning this feedback, both from the point of view of the rhetorics and for the clarification of the original contributions. Here is a (non-exhaustive) list of points:\nIn the abstract it is claimed that [you] \" find that $\\epsilon$- greedy policies can be deemed...\", it is unclear how and why this was not already known. In its second part unclear. How do you compute such policies? What do you mean by \"plan an existing optimal policy\"? The description of what was done is unclear to me, and how this was done is absent.\nThe related works section addresses the background rather than the related works, and the background is insufficient in the exposition to provide tools to understand what will be done later. Trembling Hands Nash Equilibria are never defined, for example. This leads to the fact that in the proposed method, it was unclear to me what portions of the whole regime are proper contributions of the work and what are not.\nThe Theoretical Analysis is absent, meaning that in the way it is done is mostly unclear what it should suggest.\nThe Experimental Evaluation suggests some cases of competitiveness but does not compare the methods from a computational point of view, which I believe would help understand the pros and cons of the proposed method. Finally, it was not clear to me how the hyper-optimization of the Sota algorithms used as baselines was done, both in the standard case and in the SDD-augmented case.\nA scientific analysis of the limitations would be needed.\nFinally, some English phrasing is wrong and some typos are present (for example there should be an $\\epsilon$ at the 9th line of the first page I believe)\nQuestions:\nUnfortunately, the limitations seem extensive, and I believe a refactoring of the work is needed, I hope the comments suggest the portions of the work to be addressed, but I am open to further provide insights and discuss.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Respond to Weaknesses", "Subheading": "Official CommentbyAuthors21 Nov 2023, 00:01Everyone", "Content": "Comment:\nThank you for your comments and suggestions. After reading the summary as well as the weaknesses, I think there might be some gaps between your understanding of our paper and the contents we want to express. From my perspective, you are interested in the topic that how our approach solves the trembling hands' problems. However, we find the $\\epsilon$-greedy methods in MARL are similar to the THPNE problem in game theory. We aim to solve the exploration-exploitation dilemma taken by the epsilon-greedy algorithm. Therefore, the paper is about the sequence of MARL problems instead of the one-step THPNE problem.  Despite of that, I will try my best to respond to your comments.\nIn the abstract it is claimed that [you] \" find that $\\epsilon$- greedy policies can be deemed...\", it is unclear how and why this was not already known. In its second part unclear. How do you compute such policies?  What do you mean by \"plan an existing optimal policy\"?\nBased on the $\\epsilon$-greedy algorithm, agents choose the best action with the probability of 1-$\\epsilon$ and a random action otherwise. In game theory, players who make decisions with trembling hands will choose actions greedily with a probability of $p$ and other (random) actions with $1-p$. In such a way, the $\\epsilon$-greedy method and the trembling hands' decision-making are correlated. Meanwhile [1] also states the relationship between $\\epsilon$-greedy and the trembling hands process.\nIn this paper, the stable prefix policy can be considered as a trajectory template. We establish a trajectory tree based on multiple historical interactive trajectories. In each episode, agents are in the initial state at the first time step. The trajectory tree will generate a potential optimal route of states from that initial state by greedily selecting the subsequent states with the largest value, which is the process of 'plan an existing optimal policy'.\nThe related works section addresses the background rather than the related works, and the background is insufficient in the exposition to provide tools to understand what will be done later.\nIn this paper, we are focusing on the MARL exploration problem rather than the solution to the THPNE problem. Thus, we introduce MARL and some NE definitions in the Related Work section and introduce MARL basic notations and settings in the Background section. These contents might be sufficient for introducing the subsequent MARL methods.\nThe Theoretical Analysis is absent, meaning that in the way it is done is mostly unclear what it should suggest.\nWe provide some theoretical analysis of the convergence guarantee and computational complexity of our algorithm in section 4.4. The THPNE problem is used for introducing the exploration dilemma, so we did not provide the theoretical analysis of the THPNE, which, we think, is not quite relevant to MARL problems in this paper.\nit was not clear to me how the hyper-optimization of the Sota algorithms used as baselines was done, both in the standard case and in the SDD-augmented case.\nThese Sota algorithms aim at solving the MARL problem instead of the THPNE problem, so none of them introduce their methods to solve that. Based on their algorithms, our approach does not focus on the problem either.\nsome English phrasing is wrong and some typos are present (for example there should be an $\\epsilon$ at the 9th line of the first page I believe)\nWe will double-check the expression methods and typos in this paper. However, at the 9th line of the first page, we want to express that agents choose the best actions with the largest values. Thus, agents choose actions greedily and there should not be an epsilon here.\nIn the remaining time we would like to address the remaining concerns that you have that prevent you from accepting the paper. We would appreciate it if you could engage with us on the remaining concerns, as we want to address them.\n[1] Lee, Kiyeob, et al. \"Reinforcement learning for mean field games with strategic complementarities.\" International Conference on Artificial Intelligence and Statistics."}, {"Heading": "Official Comment by Reviewer 4uBa", "Subheading": "Official CommentbyReviewer 4uBa22 Nov 2023, 11:33 (modified: 22 Nov 2023, 16:31)EveryoneRevisions", "Content": "Comment:\nI would like to thank the Authors for the clarifications. I will proceed by points. What I was trying to point out is that the exposition of the work is the main concerning point to me, and I hope my comments will help:\nIn the abstract it is claimed that [you] \" find that - greedy policies can be deemed...\", it is unclear how and why this was not already known. In its second part unclear. How do you compute such policies? What do you mean by \"plan an existing optimal policy\"?\nIn general what I was trying to say is that the abstract is not clear in what will be done, and it is imprecise in some parts as well. As an example of the general, unprecise exposition, I commented that in the abstract it is said that \"[you] find that epsilon-greedy can be deemed as the concept ...\". As you suggested as well, this result was not \"found\" in this work, it is a known fact. This is not a big issue, but the comment was to suggest that the phrasing of the work might be substantially revisited.\nThe related works section addresses the background rather than the related works, and the background is insufficient in the exposition to provide tools to understand what will be done later.\nI agree with the authors saying that \"[they] are focusing on the MARL exploration problem rather than the solution to the THPNE problem\". For this reason indeed, I suggested inserting in the related works some comments on how the problem of exploration in MARL is managed, rather than a few lines on MARL algorithms that do not tackle the problem of exploration, and a section on the Trembling Hands Problem, that is not the focus of the paper. In this sense, the related works section is rather unrelated to the work.\nThe Theoretical Analysis is absent, meaning that in the way it is done is mostly unclear what it should suggest.\nIndeed a theoretical analysis of the THPNE was not requested at all. What I was trying to say is that:\nTheorem 1 is by [2]. Assumption 1 is not discussed, how likely is it to be verified? Theorem 2 is by [1]\nWhat I mean is that the authors should better discuss how the proposed approach maps to pre-existing theoretical results, otherwise this section is rather poor and unjustified as a \"Theoretical Analysis\".\nsome English phrasing is wrong and some typos are present (for example there should be an at the 9th line of the first page I believe).\nI am still a little confused here, mostly by the fact that the revised version has indeed $1-\\epsilon$, so I really don't understand the answer \"there should not be an epsilon here\".\nGenerally, then, I think the global exposition of the work still hinders the overall quality, and I don't see substantial changes done to address that. Nonetheless, I am positive about raising my score in view of the other's comments.\n[1] Koenig & Simmons (1993)\n[2] Uchendu et al. (2023)"}, {"Heading": "Clarifications of the four concerns", "Subheading": "Official CommentbyAuthors23 Nov 2023, 03:14Everyone", "Content": "Comment:\nThank you for your comments and suggestions and for raising the score. After reading these comments, I realized that I misunderstood some of the comments above. Focusing on the four concerns, we will try our best to respond and hopefully address your concerns.\nIn the abstract it is claimed that [you] \" find that - greedy policies can be deemed...\", it is unclear how and why this was not already known. In its second part unclear. How do you compute such policies? What do you mean by \"plan an existing optimal policy\"?\nIn the abstract of the previous version, the expression 'we found that the $\\epsilon$-greedy policies can be deemed...' is overclaiming. Thus, we delete the 'we found that' and rephrase it to 'The $\\epsilon$-greedy policies can be deemed as ...' in the latest revised version. Meanwhile, we clarify that we use the previously collected trajectories to\nconstruct a Monte-Carlo Trajectory Tree\nand plan an existing optimal template (a sequence of state prototypes) from the MCT$^2$ according to the largest value of PUCB calculation. When the agents are in the state prototype which is the same as the template (agents are following the template), the agents select actions according to the policy from the utility network without $\\epsilon$-greedy exploration, which we call\nStable Prefix Policy\n. In other words, the SPP is the policy generated from the utility network without exploration. Meanwhile, when to start the exploration process is determined by the 'whether agents are following the template'. If the agents arrive at a state that is not inside the potential optimal template, agents start to explore from this point.  Hopefully, we have explained the process clearly.\nThe related works section addresses the background rather than the related works, and the background is insufficient in the exposition to provide tools to understand what will be done later.\nIn the related work section, we introduce several MARL algorithms and some works of Trembling Hands. The Trembling Hands problem is not focused in this paper,  so we delete this subsection and replace it by introducing the exploration methods in MARL algorithms, including $\\epsilon$-greedy, distributional noises, coordinated exploration, and influence-based exploration. In this paper, our approach is based on the $\\epsilon$-greedy exploration method and QMIX algorithm for reward credit allocation. We have already updated it in the latest revision version.\nThe Theoretical Analysis is absent, meaning that in the way it is done is mostly unclear what it should suggest.\nIn the theoretical analysis section, we want to express the point that the vanilla $\\epsilon$-greedy exploration method suffers from a sample complexity that is exponential in horizon $H $ (the length of an episode) for episode MDP, and our SPP method may achieve a lower polynomial sample complexity. The difference in the sample complexity contributes to the faster convergence of our approach and higher performance within early time steps.\nIn such a way, Theorem 1 states that the sample complexity is exponential in the horizon to find a policy with sub-optimality smaller than 0.5. Then Assumption 1 introduces how the sub-optimality is evaluated. To make sub-optimality smaller, the distributions of states being visited by each of the feature extractors corresponding to SPP $\\pi^{spp}$ and utility policy $\\pi$ should not be too different from each other. Given assumption 1, our method explores the current time step without dropout of any state which gives good performance guarantees for MDP with general function approximation. Then theorem 2 indicates that the two-phase decision-making process guarantees a near-optimal bound up to a factor of $C \\times poly(H)$.\nSome English phrasing is wrong and some typos are present (for example there should be an at the 9th line of the first page I believe)\nSorry for our misunderstanding on this comment. In the previous version, during the introduction of the $\\epsilon$-greedy method, we used $1-p$ as the probability of choosing the best action. We realized that the $p$ is identical to the $\\epsilon$ in this setting, so we have changed it to $1-\\epsilon$ in the latest version.\nIn the remaining time, we would like to address the remaining concerns that you have that prevent you from accepting the paper. We would appreciate it if you could engage with us on the remaining concerns, as we want to address them."}, {"Heading": "Some Final Comments", "Subheading": "Official CommentbyReviewer 4uBa23 Nov 2023, 04:30Everyone", "Content": "Comment:\nFirst of all, I am glad that the initial misunderstanding was solved. I believe the concerns I raised were mostly solved. \nI am aware that this work has more of an experimental contribution, but I would propose the following modifications to the \"Theoretical Analysis\" Section to reach what I believe would be more of a sound statement.\nWhat the authors show is that:\nthere exists an MDP instance with exponential sample complexity when $\\epsilon$-greedy is used.\nprovided the Assumption 1, Theorem 2 could be applied to show polynomial sample complexity upper bound.\nWhat I suggest for the current version is to just use the second portion, namely :\nprovided the Assumption 1, Theorem 2 could be applied to show polynomial sample complexity upper bound and explain what in your setting corresponds to the \" appropriate choice of training and evaluation process\", as it was done in the original paper.\nThe reason to avoid the first claim is that the link between a lower bound for $\\epsilon$-greedy and an upper bound of the proposed method is vacuous since you are comparing different algorithms. $\\epsilon$-greedy has exponential lower bounds yet it does not require any assumption, and I am not confident excluding that there might exist another MDP where your assumption is not satisfied and the exponentiality returns\nGenerally, then, I would call the section \"Sample Complexity Analysis\", since it is too limited to be called a Theoretical Analysis.\nMore generally:\navoid claiming that \"[you] showed that\", since this would be an over-statement. The correct phrasing would be something like  \"We linked our algorithm to the framework in ..\"\nwhen using another work's theorem, please use the format \"Theorem i [ Cite, theorem k]\" where the first number is in your ordering and the second links to the theorem in the original paper. This is needed for theoretical reproducibility."}, {"Heading": "Comments for the Area Chair", "Subheading": "Official CommentbyReviewer 4uBa23 Nov 2023, 04:39 (modified: 23 Nov 2023, 06:07)EveryoneRevisions", "Content": "Comment:\nProvided that the Authors refactor the section \"Theoretical Analysis\" as suggested, most of my concerns have been solved but I think the is still room for improvement. I am mostly worried about other's reviewer's doubts about the empirical corroboration, which can be shared, but I think I would need to know Reviewer RkkR's impression to give a final judgment."}, {"Heading": "Section 'Sample Complexity Analysis'  rephrased", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:56Everyone", "Content": "Comment:\nThank you for your comments and suggestions. We refactor the section 'Theory Analysis' as 'Sample Complexity Analysis' as suggested. Meanwhile, we have updated our paper following the second portion and cite the theorem as 'Theorem 1 (Uchendu et al. (2023) theorem 4.3) '. Additionally, we revised our paper and rephrased the expression 'we show the SPP...' to 'we link our SPP method to the framework in Koenig & Simmons (1993)'. The newly rephrased contents in the section 'Sample Complexity Analysis' are marked in red in the new revision.\nThank you again for your constructive feedback."}]}]}, "RKw6AzP2BY": {"paper_info": {"Keywords": "Transformation Matrices, Intrinsic Dimensionality, Causal Inferencing, In-Context Learning (ICL)", "TL;DR": "Through a mathematical lens, this paper explores how Large Language Models (LLMs) function, emphasizing their pattern-matching nature, the role of input complexity, and the benefits of training on reasoning tasks", "Abstract": "In the realm of Large Language Models (LLMs) like GPT-3, methodologies such as In-Context Learning (ICL) and the \"Chain of Thoughts\" (CoT) approach have become prominent. Yet, a significant research gap persists: the underlying mechanics explaining their efficacy remain vague. While existing hypotheses provide some insights, they fall short in offering a comprehensive understanding. To bridge this gap, we introduce a rigorous mathematical analysis, interpreting LLM parameters as transformation matrices that convert the complexities of textual data into high-dimensional vector spaces. Our analysis robustly postulates the correctness of this interpretation, providing a fresh perspective on LLM behaviors. At their heart, LLMs primarily operate as pattern matchers. They recognize patterns from the input text, drawing from their vast training, and produce outputs. Here, the complexity of the input prompts becomes crucial. A complex input can nudge the LLM to generate a more refined response, hinting at the concept of intrinsic dimensionality, which gauges the inherent complexity of input. In light of our insights, we advocate for a strategic shift in fine-tuning LLMs. We propose fine-tuning them on logical reasoning tasks, specifically leveraging reasoning questions (Verbal Reasoning, Probability, Assertion and Reason). This approach, rooted in our mathematical framework, enables LLMs with the technique to decipher the logical layers in the data, promising to harness the true potential of LLMs, guiding them beyond mere pattern matching to deeper textual comprehension. This in turn also improves their causal inferencing ability. In essence, our paper offers a structured blueprint, seamlessly transitioning from identifying research gaps to actionable strategies, aiming to elevate the capabilities and understanding of Large Language Models.", "Primary Area": "visualization or interpretation of learned representations", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9368", "PDF Url": "https://openreview.net/pdf?id=RKw6AzP2BY"}, "review_info": []}, "B0wJ5oCPdB": {"paper_info": {"Primary Area": "general machine learning (i.e., none of the above)", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Large Language Models, Prompting, Spatial Planning, Reasoning", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "A symbolic prompting methods representing complex spatial relationships by using simple symbols for LLMs.", "Abstract": "While conventional Chain-of-Thought prompting shows promising performance on various language tasks for LLMs, the spatial scenarios are nearly unexplored. In this paper, we first investigate the performance of LLMs on complex spatial planning and understanding tasks that require LLMs to understand a virtual spatial environment simulated via natural language and act or reason correspondingly in text. By evaluating on classic spatial planning scenarios through natural language descriptions, we found that current popular LLMs such as ChatGPT still lack abilities to handle spatial relationships in texts. This arises a question -- do the natural language is the best way to represent complex spatial environments for LLMs, or maybe other alternatives such as symbolic representations are both more efficient and effective for LLMs? To this end, we propose a novel method calledCoS(Chain-of-Symbol Prompting) that represents the spatial relationships with condensed symbols during the chained intermediate thinking steps. CoS is easy to use and does not need additional training on LLMs. Extensive experiments indicate that CoS clearly surpasses the performance of the Chain-of-Thought (CoT) Prompting described in natural langauge in all three spatial planning tasks and existing spatial QA benchmark, with even fewer tokens used in the inputs compared with CoT. The performance gain is strong, by up to 60.8% accuracy (from 31.8% to 92.6%) on Brick World scenarios for ChatGPT. CoS also reduces the number of tokens in the prompt obviously, by up to 65.8% of the tokens (from 407 to 139) for the intermediate steps from demonstrations on the Brick World task.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9367", "PDF Url": "https://openreview.net/pdf?id=B0wJ5oCPdB"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9367 by Area Chair Ya4o", "Subheading": "Meta ReviewbyArea Chair Ya4o12 Dec 2023, 19:28 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper considers the ability of large language models (LLMs) to perform tasks that involve spatial reasoning in support of planning. The paper highlights deficiencies with existing methods and proposes Chain-of-Symbols (CoS), a framework that converts Chain-of-Thought (CoT) reasoning into a sequence of symbols that capture relevant spatial relationships. The method is evaluated on a series of synthetic datasets and shown to outperform a CoT baseline.\nThe paper is highly topical---much attention is being paid to the ability to utilize LLMs for robot reasoning and a better understanding of their spatial reasoning capabilities is of interest to the community. Beyond the paper's relevance, the reviewers appreciate the simplicity of the method and its improvements over the CoT baseline, as well as the clarity of the presentation. However, the performance gains primarily result from the approach to prompt engineering and the algorithmic contributions of the work are unclear. The authors acknowledge this in their response, which the AC appreciates, yet the suggested benefits to future work are not obvious.\nJustification For Why Not Higher Score:\nThe paper does not contribute new algorithms nor are the insights into how LLMs can be used for spatial reasoning particularly impactful.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 21:49 (modified: 22 Nov 2023, 21:50)EveryoneRevisions", "Content": "Comment:\nDear reviewers,\nThere are only several hours left. Thank you for your review. We added experiment results and responses to your review several days ago. And we really hope you can reply our response or discuss with us. Thanks.\nBest,\nAuthors"}, {"Heading": "Read Authors' Responses and Reply Accordingly", "Subheading": "Official CommentbyArea Chair Ya4o16 Nov 2023, 13:23Everyone", "Content": "Comment:\nHi,\nThanks for your help reviewing this paper.\nThe authors have provided a detailed response to each of your reviews as well as a shared response to all reviewers. Please be sure to read through their responses and respond accordingly so that we can have a healthy discussion of the merits of this paper.\nBest,\nAC", "Replies": [{"Heading": "Bump...", "Subheading": "Official CommentbyArea Chair Ya4o20 Nov 2023, 08:41Everyone", "Content": "Comment:\nThere are only\ntwo days remaining\nfor the author-reviewer discussion (November 22nd). Please read through the authors' response to your review and comment on the extent to which it addresses your questions/concerns."}]}, {"Heading": "General response for all reviewers", "Subheading": "Official CommentbyAuthors15 Nov 2023, 00:06 (modified: 15 Nov 2023, 14:49)EveryoneRevisions", "Content": "Comment:\nWe first thank for all reviewers to provide valuable advices, which encourages us to have more findings.\nWe are glad that reviewers think our work is simple but effective, and novel: Reviewer tveC said \"a novel method\", Reviewer c5jB said \"The proposed method is very simple, but the results show a significant improvement\", Reviewer LjHX said \"findings are very interesting!\".\nWe are also glad that reviewers think our work is easy to read and understand: Reviewer c5jB said \"easy to understand. All the sections are easy to read\", Reviewer LjHX said \"well-organized and easy to read.\"\nThen we aim to solve\nmajor common concerns\nprovided by reviewers, and we concluded into three main parts:\nResults of open-source models: provided by Reviewer Doc8 and Reviewer tveC\nScalability and Generalization of our proposed method: provided by\nall reviewers\nFundamental explaination and insights: provided by Reviewer c5jB and Reviewer LjHX\nWe solve them one by one as below:\n1. Results of open-source models:\nWe use llama-2 as our representative open-source LLM, we test our method in all sizes (7B, 13B, and 70B) in the three tasks for limited time and computing resource.\nBrick-1D:\nMethod / Model Size\n7B\n13B\n70B\nCoT\n0.04\n0.21\n0.50\nCoS\n0.02\n0.09\n0.69\nNavigation:\nMethod / Model Size\n7B\n13B\n70B\nCoT\n0.17\n0.23\n0.45\nCoS\n0.12\n0.18\n0.53\nTemporal Sequence:\nMethod / Model Size\n7B\n13B\n70B\nCoT\n0.15\n0.33\n0.70\nCoS\n0.20\n0.29\n0.93\nTemporal-sequence is the new tasks we inpired from the review of Reviewer c5jB, we find similar scenarios in BBH benchmark [1], and tested on it to further verify the effectiveness and generalization of our method.\nIn these three tables, we surprisingly find that although in 7B and 13B, our method is lower than or near to the performance of CoT, our method can outperform CoT in 70B clearly in all tasks!  This indicates:\nThe\nscaling curve\nof CoS is steeper than CoT\u2019s.\nIt shows the\nemergent ability\nof LLMs for understanding CoS (symbols) when size increases.\nWe also upload the figure about scaling curve in the\nfigure 4\nin the latest version of our paper, which is very clear and impressive.\nThe experimental results matched with the intuition that larger models have stronger basic capabilities, so they might have the ability to understand complex parterns represented by symbols.\n2. Scalability and Generalization of our proposed method:\nWe decompose this into two dimension:\ntask domain and task complexity\nFor task domain:\nAs described above, we inpired from the review of Reviewer c5jB, use similar scenarios in BBH benchmark, called \"temporal sequence\", it is a reasoning task which provided a sequence of time slots and related scenarios, and model should answer which time is available based on given descriptions. And in the above second table, we can see that using CoS can outperform CoT significantly (from 70 to 93.) We also conduct experiments on GPT-3.5-Turbo, and shows CoS can outperform CoT from 66.5 to 76.2\nFor tasks complexity:\nWe conduct control experiments where we control the complexity of the task by setting the number of bricks in brick-1d scenarios. When the number of bricks increases, which means the complexity of the task increases, the performance of CoS can outperform CoT. It verify the robustness of CoS when task becoming hard.\nComplexity control experiment on GPT-3.5-Turbo:\nMethod / Length\n6\n8\n10\n12\n14\nCoT\n0.62\n0.56\n0.40\n0.35\n0.32\nCoS\n0.64\n0.62\n0.56\n0.52\n0.50\n3. Explanation and insights:\nWe use CoS for two reasons:\nUsing symbols rather than text words can improve the representation space in prompting.\nCoS uses symbols to replace parts of natural languages, hence reducing noises brought from redundant natural languages.  One assumption is that words of natural languages might have more context information during pre-training, which might bring potential additional information, but using symbols can avoid these, by connecting objects without potential additional information, and make prompting more clear and structural.\n[1] Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them.  ACL 2023 Findings"}, {"Heading": "Official Review of Submission9367 by Reviewer Doc8", "Subheading": "Official ReviewbyReviewer Doc804 Nov 2023, 22:27 (modified: 23 Nov 2023, 01:56)EveryoneRevisions", "Content": "Summary:\nThe authors first investigated the performance of ChatGPT on spatial relationship tasks. They find that it still struggles, and proposed a novel prompting method called Chain-of-Symbols (CoS), which converts Chain-of-Thought (CoT) prompts into a sequence of symbols that represent spatial relationship described in the problem of interest. They experimented with synthetic datasets (Brick World, NLVR-based Manipulation, and Natural Language Navigation) and more realistic dataset (SPARTUN), and showed that CoS improves over CoT.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nShow that LLMs still struggle with spatial relationship understanding from natural language\nProposed a new prompting method called Chain-of-Symbol to improve the performance on spatial relationship tasks.\nWeaknesses:\nThe paper focuses only on Text-Davinci-003 and GPT-3.5-turbo. However, it would be beneficial to include other promising open-source large language models like the Llama-2 series in their study to see the effect of model size, different base models, etc.\nThe authors claim that they achieved a significant improvement of up to 60.8% in accuracy (from 31.8% to 92.6%) on the Brick World dataset. While this is technically correct given the results, the reported improvement is a little misleading because it's comparing zs-CoT vs. CoS and also such a dramatic gain isn't seen in most cases, especially when comparing the performance of CoS to CoT. In more realistic datasets like SPARTUN, the improvement is marginal. This suggests that the impressive gains are more about the simplicity of the Brick World dataset than any substantial leap in CoS performance. Thus, I believe the claim should be more moderate.\nApart from the previously mentioned issues, I find the contribution is limited for the following reason: the paper does demonstrate how you can condense the chain of thought (CoT) into a series of symbols, and that this is enough for tasks involving spatial relationships. However, this method of prompting might only be effective for spatial relationship tasks. Also, when you look at the final experiment (Table 5), it suggests that this method might not work as well in real-life situations. It seems that the success of this method, referred to as CoS, might be limited to simpler, more straightforward spatial tasks.\nQuestions:\nThe authors used GPT-4 exclusively for the final experiment. Why not present GPT-4 results in the other sections as well?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors15 Nov 2023, 00:54 (modified: 15 Nov 2023, 15:44)EveryoneRevisions", "Content": "Comment:\nThanks for your reply and advice, we follow your advice and complete several new experiments, which described in the general response for all reviewers. Below is some response for weakness and question.\nFor weakness 1\n:\nYou can see the part 1 of general response for all reviewers, we add the experiments of open-source LLMs, llama-2 with different sizes. And you can also see the figure 4 in latest uploaded version of our paper very clearly about the more steep scaling curve of our method across different tasks compared with CoT. It shows the effectiveness of our method compared with CoT and the enmergent ability of understanding CoS.\nFor weakness 2\n:\nThanks for pointing out our misleading part, We revised our claim in the revision version.\nFor the concern of marginal improvements, we add further experiments about using longer description instances (e.g. from 6 to 14 bricks) and find that CoS can gain more improvements compared with CoT in these scenarios compared with more simple scenarios, which is reported in part 2 of general response for all reviewers.\nFor \"the impressive gains are more about the simplicity of the Brick World dataset\", actually the \"shuffle both\" results of brick 1d shows it is not a simple task as it looks like, where CoT only gains 43.0 accuracy. This actually shows that LLMs do not have good spatial understanding capabilities, because they cannot do spatial reasoning tasks which human think is easy well.\nFor weakness 3\n:\nWe add experiments on the temporal sequence tasks from the BBH benchmark [1]. This is another task which is not related with spatial relationships, and which also contains a more real-life situation. We report the results in table 2, part 1 of general response for all reviewers, and also tested on GPT-3.5-Turbo, and shows CoS can outperform CoT from 66.5 to 76.2.\n\"It seems that the success of this method, referred to as CoS, might be limited to simpler, more straightforward spatial tasks.\"\nWe use complexity control experiment and task of temporal sequence of BBH benchmark to shows the contribution of our proposed method, and we also want to describe our method in a more general way:\nWe will add this into Section 3 in our paper: we can formulate the tasks which our method is suitable as a set of tasks which has sequential and limited number of relationships, and the relationships can be spatial, and also can be other kinds such as temporal.\nFor converting natural languages into symbols, we can use human, NER system or even rule-based codes to automatically recognise objects in the sequential relationships described by natural languages, and then connect them with each other using random symbols ( e.g. '/', '-', etc). By doing this, we actually use symbols to replace original relationships which connect objects together.\nGenerally, we want to provide insights about using symbols in demonstration of the prompting, and we provide a particular way to use symbols to make LLMs to be more effective and efficient when handle sequential tasks.\nFor question:\nWe only have limited access of GPT-4 API currently, we will add the related results when we can access GPT-4 API in our future version.\n[1] Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them. ACL 2023 Findings"}, {"Heading": "Reply", "Subheading": "Official CommentbyReviewer Doc823 Nov 2023, 01:55Everyone", "Content": "Comment:\nThank you for your responses and additional experiments. My questions regarding generalizability of this method and other LLMs have been addressed.\nThe scaling curve that shows CoS improves more on larger models (e.g. 70B or more) across different datasets (Brick 1D, Navigation, and Temporal Sequence) is indeed interesting. \nRegarding GPT-4 API, it has been accessible to everyone at least for the past few months. I've updated my score assuming that GPT-4 experiments will be included in the final revision."}]}, {"Heading": "Official Review of Submission9367 by Reviewer tveC", "Subheading": "Official ReviewbyReviewer tveC03 Nov 2023, 18:49 (modified: 04 Dec 2023, 16:39)EveryoneRevisions", "Content": "Summary:\nThis paper presents an exploration into the capabilities of large language models (LLMs) to understand and process spatial relationships, a relatively unexplored domain for such models. They propose a new method termed Chain-of-Symbol (CoS) prompting. This approach aims to improve the spatial reasoning capabilities of LLMs. They observe notable performance gains in tasks that involve spatial planning and understanding. For instance, in the Brick World task, which involves a series of steps to achieve a final goal, CoS considerably outperformed traditional CoT. The findings could have broad implications for tasks that reuiqre advanced spatial understanding.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper presents a novel method, CoS, which addresses the limitations of existing techniques in spatial understanding.\nMultiple spatial tasks such as Brick World, Natural Language Navigation, and NLVR-based Manipulation were used to validate the efficacy of the proposed method.\nCoS consistently outperformed traditional CoT, showcasing its potential as a superior method for spatial reasoning tasks. In addition, a thorough analysis of the results, considering different configurations are also provided.\nWeaknesses:\nThe heavy reliance on symbolic representations might limit the model's flexibility in real-world scenarios where such symbols might not be explicitly available. There also lack a clear definition or universal guideline to convert tasks into condensed symbols.\nThe process of converting spatial tasks into symbolic representations could introduce additional complexity and computational overhead. Besides, it require annotations, which seems more difficult to obtain compared with natural language based chain-of-thought or program-based program-of-thought.\nThe open-source LLM remain under-explored, only ChatGPT series are tested in the experiments. It could have been more solid if the same trend can be observed in other LLMs. Besides, the design of prompt may also influence the results a lot, perhaps a through comparison on the robustness of the prompt should also be included, so that the CoT performance is really revealed in terms of capturing spatial relationship.\nQuestions:\nHow scalable is the CoS method, especially for larger and more complex spatial environments? Is there an automatic way to converse into chain of symbols, or does it require manual rules and symbols design for each task and even each in-context sample?\nHow does CoS perform when compared to other potential solutions or methods that might address spatial reasoning in LLMs? Such as program-based CoT that involve symbolic reasoning?\nHow is the computation required to further convert to chain of symbols? And how about the tasks that do not have manually annotated symbols, how to extend your CoS method to a broader range of tasks?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors15 Nov 2023, 07:20 (modified: 15 Nov 2023, 15:54)EveryoneRevisions", "Content": "Comment:\nThanks for your valuable reply and advice, we add open-source experiments in the response for all reviewers.\nFor weakness\n:\nPoint 1:\nWe will add a clear definition of universal guideline to convert tasks into condensed symbols in Section 3 of the paper.\nWe first define our task in a more general perspective:\nWe can formulate the tasks which our method is suitable as a set of tasks which has sequential and limited number of relationships, and the relationships can be spatial, and also can be other kinds such as temporal (which we extend as new experiments in the response for all reviewers).\nThen we define the procedure of our conversion from natural lanugages of CoT to our CoS:\nFor converting natural languages into symbols, we can first use a recognizer to recognize objects and entities in the natural language descriptions, e.g. using human, NER system or even rule-based codes to automatically recognise objects in the sequential relationships described by natural languages, and then connect them with each other only using\nrandom symbols\n( e.g. '/', '-', etc). By doing this, we actually use symbols to replace original relationships which connect objects together.  For simplicity, we can pre-defined the set of symbols, and the mapping between each kinds of symbols to each kinds of relationships.\nWhat's more, although we only verified on specific task examples, the idea itself can provide insights for future research: (e.g. customizing the conversion process, customizing mapping between symbols and relationships, even customizing the way of using symbols in in-context learning), what important is, we provide insights to\nuse symbols to replace natural languages\nin demonstration / prompting, which\nwould be a promising direction to further explore for future works\n, for using symbols can wider the representation space in prompting, and reducing potential noises brought from natural languages.\nPoint 2:\nBased on guideline we give in the point 1 and in the section 3 of the paper, we can easily transform any sequential natural language exemplars which meet the conditions to chain-of-symbol exemplars. The guideline is suitable for all tasks which meet the conditions, we have proved its effectiveness in spatial relationships and temporal sequence reasoning tasks as examples, and future work can explore more tasks.\nPoint 3:\nFor open-source models, the results and analyses are concluded in part 1 of general response for all reviewers. Figure 4 in our latest uploaded version of paper gives a clear results about scaling curves of CoS compared with CoT, it shows CoS has more steep curve for all tasks, which indicates it is a general ability that LLMs can understand abstract symbols better when size increases.\nFor questions\n:\nPoint 1:\nWe conclude this point in the second part of general response for all reviewers, specifically, we decompose this into two dimension: task domain and task complexity.\nFor task domain, inspired from Reviewer c5jB, we use similar scenarios in BBH benchmark, called \"temporal sequence\", it is a reasoning task which provided a sequence of time slots and related scenarios, and model should answer which time is available based on given descriptions. And in the above second table, we can see that using CoS can outperform CoT significantly (from 70 to 93.) We also conduct experiments on GPT-3.5-Turbo, and shows CoS can outperform CoT from 66.5 to 76.2\nFor tasks complexity:\nWe conduct control experiments where we control the complexity of the task by setting the number of bricks in brick-1d scenarios. When the number of bricks increases, which means the complexity of the task increases, the performance of CoS can outperform CoT. It verify the robustness of CoS when task becoming hard.\nFor whether there is an automatical way to convert or not, see the point 1 for weakness above.\nPoint 2:\nFor other methods, for example program-based CoT, can you be more specific? We only find this related work\nhttps://openreview.net/pdf?id=YfZ4ZPt8zd\n, which uses an external program executor to help calculate, but to be honest it is not a fair comparison with our CoS method which only does the inference by LLMs on their own, but we can list these kinds of works in our related work section.\nPoint 3:\nThe computation required to convert symbols is down to 10ms through Python program based on given CoT exemplars. For those tasks which do not have manual annotated symbols, we can follow the procedure described in the part 1 of weakness above. For a broader range of tasks, just as the description in part 2 of general response for all reviewers, we explore temporal sequence tasks and verified the effectiveness of our method."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:20Everyone", "Content": "Comment:\nDear reviewer tveC,\nWe greatly appreciate your valuable feedback. We conduct additional experiments and write a detailed shared response and specific response for your review.\nAs you may know, unlike previous years, the discussion period this year can only last until today (only 3 hours left).\nIf you are satisfied with our response, please consider updating your score. If you need any clarification, please feel free to discuss with us.\nBest,\nAuthors"}, {"Heading": "Thanks for the detailed response.", "Subheading": "Official CommentbyReviewer tveC04 Dec 2023, 16:40 (modified: 15 Mar 2024, 00:27)EveryoneRevisions", "Content": "Comment:\nThanks for the detailed response. Most of the concerns are addressed, and in general I do favor this paper idea. I raise from 5 to 6."}]}, {"Heading": "Official Review of Submission9367 by Reviewer c5jB", "Subheading": "Official ReviewbyReviewer c5jB31 Oct 2023, 18:51 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a new prompting approach, called chain-of-symbol. The idea is simple, instead of providing a language description about spatial relation of objects, this paper proposes to use symbols to represent the object relationship. By doing this, this method improves the off-the-shelf LLMs capability to reason about the spatial relationship. Five tasks are evaluated. The first task is called natural language spatial planning, in which the LLM is asked to move the object so that this location of objects will be in the desirable location. The second task is brick world, which is similar to the first task. And the third task is NLVR-based manipulation, in which the agent again needs to rearrange the object based on the textual instruction. And the fourth task is natura language navigation, in which the agent needs to navigate to different landmarks given the instructions. Finally, the spatial QA is a traditional benchmark for testing reasoning capability of LLMs. Table 1 and Table 2 show that CoS significantly improves the performance over CoT. And from Figure 3, the performance does not affect by the symbols that are used, which leads to that this method is robust to the symbols chosen. Overall, the paper demonstrates a nice result to verify the idea.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe paper is easy to understand. All the sections are easy to read\nThe proposed method is very simple, but the results show a significant improvement over CoT.\nWeaknesses:\nThis is another prompting paper in the era of LLMs, and there is no new algorithm, but a trick (finding) to make the LLMs more robust.\nQuestions:\nHow about other tasks such as problems concerning the \"sequential relation\"? For instance, Alice was doing cooking this morning, and in the afternoon, Alice was working, and during the night, Alice was relaxing with the family. Question: what did Alice do between 12:00 PM to 6:00 PM? something like this type of question.\nWhat is the fundamental explanation that this method works well?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors15 Nov 2023, 14:27Everyone", "Content": "Comment:\nThanks for your valuable advice.\nFor weakness:\nAlthough we don't propose new \"algorithm\", we provide insights to use symbols to replace natural languages in demonstration / prompting, which we think would be a promising direction to further explore for future works, for using symbols can wider the representation space in prompting, and reducing potential noises brought from natural languages. What's more, in our additional experiments about open-source LLMs, we find the scaling curve of CoS is steeper than CoT\u2019s and the emergent ability of LLMs for understanding CoS (symbols) when size increases, which is very interesting. We also add different tasks of scaling curve in the latest uploaded version of the paper in figure 4, shows the general trend across tasks.\nFor question 1:\nIn addition to spatial tasks, we add experiments on the temporal sequence tasks from the BBH benchmark, which is very similar to the situation you mentioned, and results is reported in the response for all reviewers. The prompting demonstration and examples are added in latest uploaded version of our paper in the table 16.\nFor question 2:\nWe use CoS for two reasons:\nNot only using natural languages but also using symbols can make the representation space wider in prompting.\nCoS uses symbols to replace parts of natural languages, hence reducing noises brought from redundant natural languages. One assumption is that words of natural languages might have more context information during pre-training, which might bring potential additional information, but using symbols can avoid these, by connecting objects without potential additional information, and make prompting more clear and structural."}]}, {"Heading": "Official Review of Submission9367 by Reviewer LjHX", "Subheading": "Official ReviewbyReviewer LjHX30 Oct 2023, 13:21 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents a novel prompting paradigm called Chain-of-Symbol (CoS) Prompting that represents the spatial relations in the symbol chain. The authors claim that the proposed CoS outperforms CoT in all existing spatial QA benchmarks, with fewer tokens compared to CoT.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n3 good\nStrengths:\nThe proposed CoS prompting and findings are very interesting!\nThe paper is overall well-organized and easy to read.\nThe experimental results are strong.\nWeaknesses:\nThe step (ii) in CoS prompting is not clear enough. How do authors correct the zero-shot CoT\u2019s output, is it manually checking or prompting LLMs to do so?\nThere is an overlap between \u201cNatural Language Navigation\u201d and the text in the box in Figure 2.\nI am curious about the generalization ability of the proposed CoS prompting. I would encourage authors to report performance in more general domains rather than just spatial question answering, such as some open-domain QA tasks.\nThis paper presents very interesting findings, I would encourage authors to discuss more about its mechanisms and give some insights.\nThough authors list some advantages of the proposed CoS, at the same time, CoS is more difficult to track LLMs reasoning path. I would encourage authors to discuss some limitations of this work.\nThe CoS prompting exemplars are generated with zero-shot CoT. I would encourage authors to discuss the motivation of selecting 0-shot CoT and its implications on CoS performance.\nQuestions:\nN/A\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors15 Nov 2023, 15:39Everyone", "Content": "Comment:\nThanks for your valuable advice.\nFor weakness:\nWe manually correct zero-shot CoT's output, which described in Appendix B.2 .\nThanks for your kindly mention! We will adjust it in our paper.\nIn addition to spatial tasks, we add experiments on the temporal sequence QA tasks from the BBH benchmark which is shown in the third table of part 1 in general response for all reviewers.\nThank you for your encouragement. One intuition we think might be useful is that CoS uses symbols to replace part of natural languages, hence reducing noises brought from redundant natural languages. Neural network might only needs to know the relationship between entity A and other entities to conduct the complex reasoning or planning task. We postulate that removing irrelevant information contained in the natural language can help model to focus on the real task. And using symbols might can reduce potential context information gained from pre-training stage compared with natural languages.\nWe will add more limitation about this aspect in our paper. Although our method uses less natural languages compared with CoT, we actually contains some information of input in CoS ( e.g. objects / entities ), which is easy to trace them back to input descriptions, which can then track the reasoning path.\nZero-shot CoT is the most straightforward clue that one could have to use CoS in their own application. While other format can be useful, the search space is huge and it can be spend more time in writing the demonstration fully manually. Also, we tried in our preliminary experiments on human-written CoS and CoT. We did not have promising performance on both CoS and CoT when human writting, and we postulate that LLMs adapts better to the zero-shot CoT format produced by themselves."}]}]}, "IefMMX12yk": {"paper_info": {"Primary Area": "learning on graphs and other geometries & topologies", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "graph neural network, neural architecture search, graph sparsification", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Graph Neural Architecture Search (GNAS) has achieved superior performance on various graph-structured tasks. However, existing GNAS studies overlook the applications of GNAS in resource-constraint scenarios. This paper proposes to design a joint graph data and architecture mechanism, which identifies important sub-architectures via the valuable graph data. To search for optimal lightweight Graph Neural Networks (GNNs), we propose Lightweight Graph Neural Architecture Search with Graph SparsIfication and Network Pruning (GASSIP). In particular, GASSIP comprises an operation-pruned architecture search module to enable efficient lightweight GNN search. Meanwhile, we design a novel curriculum graph data sparsification module with an architecture-aware edge-removing difficulty measurement to help select optimal sub-architectures. With the aid of two differentiable masks, we iteratively optimize these two modules to efficiently search for the optimal lightweight architecture. Extensive experiments on five benchmarks demonstrate the effectiveness of GASSIP. Particularly, our method achieves on-par or even higher node classification performance with half or fewer model parameters of searched GNNs and a sparser graph.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9366", "PDF Url": "https://openreview.net/pdf?id=IefMMX12yk"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9366 by Area Chair yXyj", "Subheading": "Meta ReviewbyArea Chair yXyj15 Dec 2023, 08:54 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper addresses a gap in the existing research on Graph Neural Architecture Search (GNAS) by focusing on its applications in resource-constrained scenarios. Introducing a joint mechanism for graph data and architecture, the proposed method, Lightweight Graph Neural Architecture Search with Graph Sparsification and Network Pruning (GASSIP), identifies crucial sub-architectures using valuable graph data. GASSIP incorporates an operation-pruned architecture search module for efficient lightweight Graph Neural Network (GNN) search, and a curriculum graph data sparsification module with an architecture-aware edge-removing difficulty measurement to select optimal sub-architectures. The iterative optimization of these two modules, facilitated by differentiable masks, efficiently searches for the optimal lightweight architecture. Experimental results on five benchmarks demonstrate the effectiveness of GASSIP. Notably, the method achieves node classification performance comparable or superior to existing GNNs, with half or fewer model parameters, and a sparser graph.\nThe reviewers raise important points regarding the evaluation of the proposed method and suggest expanding the comparison to include more recent GNAS methods, especially on large-scale datasets such as OGB datasets, and considering benchmarks like NAS-Bench-Graph.\nThe citation and comparison with more recent works, including GUASS [1] and NAS-Bench-Graph [2], is recommended to ensure the paper reflects the latest advancements in the field. Additionally, acknowledging and discussing the contributions and distinctions compared to recent works like HM-NAS [3], which introduced hierarchical masking, would enrich the discussion on the proposed method.\nThe reviewers have also expressed confusion about the workflow in Figure 1, suggesting a clearer illustration of the iterative training process involving the structure mask, and separation of the training part from the procedures after binarizing masks for better clarity.\nAddressing these suggestions would contribute to a more comprehensive evaluation and discussion of the proposed method in the context of recent advancements in GNAS and graph sparsification methods.\nOverall, the reviewers tended to reject the paper. One reviewer scored the paper with an 8 but was unfortunately not available during the rebuttal period and also provided the least rigorous review. Hence, I have placed more weight on the reviewers leaning or advocating for rejecting the paper.\nJustification For Why Not Higher Score:\nSeveral weaknesses\nJustification For Why Not Lower Score:"}, {"Heading": "Response to the Common Question", "Subheading": "Official CommentbyAuthors21 Nov 2023, 06:56Everyone", "Content": "Comment:\nWe thank all of the reviewers for their thoughtful feedback and recognition of our paper\u2019s contributions. We have addressed the common question here, individual reviewers\u2019 comments in their replies, as well as updated the manuscript PDF with the changes suggested. All changes in the PDF are marked in pink for ease of reference.\nCommon Question: Experiments on large-scale graphs with massive nodes such as Ognb-products or Ogbn-Paper100M\nWe would like to thank all three reviewers for their curiosity about the performance of our method on very large-scale graphs such as Ognb-products or Ogbn-Paper100M.\nOn one hand, we admit that the current implementation of the GNAS-based methods (such as the SOTA GNAS method [1-3]) could barely be extended to graphs at such a scale without a specifically designed sampling strategy (except [4] as pointed out by Review WS6Y). Indeed, this is a common obstacle for this line of research since naively applying sampling techniques to the current supernet training in GNAS will result in consistency collapse issues [4]. This problem becomes more troublesome under our setting where the graph sparsification also needs to be optimized since the joint optimization of graph sparsification and large-scale graphs is also not well studied [5].\nOn the other hand, we kindly clarify that the extension to heavyweight scenarios with very large-scale graphs is not the main focus of our work. As we mentioned in the introduction, the main purpose of this paper is to search for a lightweight GNN (i.e., lightweight GNN design) that offers a wider range of application scenarios (e.g. edge computing) by limited computational resource requirements. We utilize graph structure to help identify effective optimal sub-architectures to reach the lightweight GNN goal, which is one of our main contributions.\nIn conclusion, we value the question of how to integrate our method with graphs with billions of nodes, but we aim to tackle the practical situation where the computational resources are limited. Note that this difficulty of scalability commonly hinders both graph sparsification and GNAS research in applications with contained resources. Therefore, we revised our manuscript to reflect this limitation and chose to leave this as a future work. Meanwhile, we hope the reviewers show solicitude to our main contributions as mentioned in the introduction.\n[1] DFG-NAS: Deep and Flexible Graph Neural Architecture Search, ICML 2022\n[2] Do Not Train It: A Linear Neural Architecture Search of Graph Neural Networks, ICML 2023.\n[3] Graph differentiable architecture search with structure learning, NeurIPS 2021\n[4] Large-scale graph neural architecture search, ICML 2022\n[5] Survey on Graph Neural Network Acceleration: An Algorithmic Perspective, IJCAI 22"}, {"Heading": "Official Review of Submission9366 by Reviewer WS6Y", "Subheading": "Official ReviewbyReviewer WS6Y30 Oct 2023, 08:48 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposed an lightweight GNAS algorithm. It iteratively optimizes graph data and architecture through curriculum graph sparsification and operation-pruned architecture search.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper proposes a GNAS method with graph sparification, which is an interesting exploration.\nThe paper applies the method to extensive experiments and shows good results on multiple datasets.\nWeaknesses:\nGNAS methods nowadays have been expanded to large-scale datasets, while the paper only showed the results on Physics and Ogbn-Arxiv datasets. Could you please give a more overall perfomance comparison with other GNAS methods like GUASS  on large-scale OGB datasets?\n[1] Large-scale graph neural architecture search, ICML 2022.\nMore comparsion on the unified benchmark will be appreciated, such as NAS-Bench-Graph.\n[2] Benchmarking Graph Neural Architecture Search, NIPS 2022.\nCited works in Section 2 are mostly before 2022 and the methods compared in Table 1 are all before 2021 which make the work out-dated. I do know there were multiple GNAS and graph sparsification methods proposed in 2022/2023. Maybe more cutting-edge research work as well as comparisions should be added.\nThe first contribution is proprosing a operation-pruned search method with learnable weight mask. However, the work of HM-NAS introduced this hierarchical masking on redundant operations, edges, and even the weights of supernet. It seems like transfering the idea on graphs. Maybe you should add this work and discuss the noble part of the first contribution compared with the learnable weight mask idea on edges in HM-NAS.\n[3] HM-NAS: Efficient Neural Architecture Search via Hierarchical Masking, ICCV 2019.\nI feel a little confused about the workflow in Figure 1. I understand that the iterative training process of structure mask is between the gradient update of operations and architectures. However, the training process probably need to point back to the architecture searching part to illustrate the interactive training not directly getting the final sparsed graph and connecting to the pruned architecture. Maybe the training part and the procedures after binarizing masks can be seperated.\nQuestions:\nSee weakness.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to reviewer WS6Y", "Subheading": "Official CommentbyAuthors21 Nov 2023, 07:01Everyone", "Content": "Comment:\nThank you for your time and detailed feedback. We are happy to adapt our work to answer your questions and include all your suggested changes.\nQ1. Comparison with GUASS\nA1: Thank you for this question. For the issue of large-scale datasets, please kindly refer to the reply to the common question. Since it requires calculating the output of every operation within the supernet on the full graph to estimate reliable architecture parameters, it is difficult for most of the GNAS methods to scale to Ogbn-product and Ogbn-Paper100M without a specifically designed sampling strategy. We, therefore, report the results compared with GUASS on the scalable benchmarks as below:\n| Method   | Cora | CiteSeer | PubMed | Physics | Ogbn-Arxiv |\n| GUASS  | 82.05\u00b10.21 | 70.80\u00b10.41 | 79.48\u00b10.16 | 96.76\u00b10.08 | 71.85\u00b10.41 |\n| GASSIP | 83.20\u00b10.42 | 71.41\u00b10.57 | 79.50\u00b10.30 | 98.46\u00b10.06 | 71.30\u00b10.23 |\nWe can find that GASSIP achieves better performance than GUASS on smaller graphs, but GUASS could handle graphs with more nodes and edges (Ogbn-Arxiv) as it is specially developed for large-scale datasets. However, our trained model is more lightweight and therefore can be applied in practical scenarios where computational resources are limited, which is not applicable to GUASS.\nQ2: Comparision with NAS-Bench-Graph.\nA2: Thank you for bringing up this suggestion. However, NAS-Bench-Graph only designs general search space without considering the pruning on either the graph structure or the GNN architecture. As a result, directly applying GASSIP on the NAS-Bench-Graph is inappropriate and induces less meaningful comparison. We appreciate your opinion and would leave the efforts to develop a unified benchmark for lightweight GNAS as future work.\nQ3: Maybe more cutting-edge research work as well as comparisons should be added.\nA3: Thank you for this suggestion. We have done our best to conduct supplementary research on the GNAS and graph sparsification methods proposed in 2022/2023. We have included them [1-4] in the Related Work section with the corresponding discussion. We have also included GUASS as an additional baseline as you suggested. Please provide any missing related work that you imply and we will also include them in the discussion. Nevertheless, to the best of our knowledge, our proposed GASSIP is the first work to search for a lightweight GNN design while considering sparsifying the graph structure simultaneously.\nQ4: Difference with HM-NAS.\nA4: Thank you for the information about HM-NAS and we are sorry for not being aware of this wonderful work before. We have added the corresponding discussion with HM-NAS in the related works. Specifically, HM-NAS aims to improve the architecture search performance by loosening the hand-designed heuristics constraint with three hierarchical masks on operations, edges, and network weights. In contrast, our focus is different from HM-NAS as we aim to search for a lightweight GNN considering co-optimizing the graph structure. To achieve this lightweight goal, a mask for network weight is naturally introduced, which is commonly used for network pruning.\nQ5: The workflow in Figure 1.\nA5: Thanks for your suggestion and we are sorry for the confusion. The \"sparsified graph\" mentioned in the original figure refers to the masked graph rather than the final binarized sparsed\u00a0graph. The arrow is not directly connecting to the pruned architecture but connecting two different iterative parts. We adjust the arrows to make this clear. After revision, we do not include the final mask binarizing step which is illustrated in Line 7 in Algorithm 2. Figure 1 only displays the iterative training process which is shown in Lines 1-6 in Algorithm 2. We have also updated the caption of Figure 1 to make this illustration clear.\n[1] DFG-NAS: Deep and Flexible Graph Neural Architecture Search, ICML 2022\n[2] Do Not Train It: A Linear Neural Architecture Search of Graph Neural Networks, ICML 2023\n[3] Ricci Curvature-Based Graph Sparsification for Continual Graph Representation Learning, TNNLS 2023\n[4] DSpar: An Embarrassingly Simple Strategy for Efficient GNN Training and Inference via Degree-Based Sparsification, TMLR 2023"}, {"Heading": "Response to Authors", "Subheading": "Official CommentbyReviewer WS6Y22 Nov 2023, 06:29 (modified: 22 Nov 2023, 06:31)EveryoneRevisions", "Content": "Comment:\nDear Authors,\nThanks for your feedback. The response to the scalability concern is not convincing for me. The authors argued that the extension to heavy-weight scenarios with very large-scale graphs is not the main focus of our work. In my view, large-scale graphs have not direct relationship with the meaning of \u2018heavy-weight\u2019. \u2018Light-weight\u2019 is reflected in the complexity of GNN. Instead, search a lightweight GNN for large-scale graphs could also be considered in the paper. Intuitively, both graph sparsification and operation pruning help to improve the efficiency of searching a lightweight GNN for large-scale graphs. Maybe, joint optimization of graph sparsification and GNN NAS is not a scalable solution.\nConsidering this concern, I keep my rating unchanged."}, {"Heading": "Thank you for the response", "Subheading": "Official CommentbyAuthors22 Nov 2023, 10:03Everyone", "Content": "Comment:\nDear Reviewer WS6Y:\nThank you for your reply and we appreciate your feedback. We are sorry for any confusion raised in our rebuttal for the scalability concern. By the term \"heavyweight\", we denote the large-scale graph that involves billions of nodes and adequate computational resources. There is another line of research focusing on the scalable GNNs that meet this demand by incorporating additional pre-processing and post-processing stages[1], developing a system with a search engine[2], and co-designing the GNN algorithm and system [3], etc. You are right about our motivation to develop lightweight GNNs with low complexity, and we do not claim that our main focus is to propose scalable GNNs. We will update the revision to add a discussion with these scalable GNNs in the related works soon.\nWe agree with you on the advantages of graph sparsification and operation pruning in searching for a lightweight GNN for large-scale graphs. It is indeed possible to apply this work in large-scale graphs by combining our current implementation with a sampling technique. We have tried an experimental attempt on the Ogbn-Product dataset (millions of nodes rather than billions of nodes though) with a widely used neighbor sampling [4], and the result is indeed weaker than GUASS (79.65 vs. 81.26), which is as expected since naively applying sampling techniques to the current supernet training in GNAS will result in consistency collapse issues [5]. Therefore, we would like to leave the design of scalable and optimized sampling strategy and the scalable choices of search space as future work to extend GASSIP to graph with a much larger scale.\nMany thanks again for your reply and we are happy to discuss more on your further concerns.\n[1] Node Dependent Local Smoothing for Scalable Graph Learning, NeurIPS 2021\n[2] PaSca: A Graph Neural Architecture Search System under the Scalable Paradigm, WWW 2022\n[3] Algorithm and System Co-design for Efficient Subgraph-based Graph Representation Learning, VLDB 2022\n[4]\nhttps://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/loader/neighbor_loader.html\n[5] Large-scale graph neural architecture search, ICML 2022"}]}, {"Heading": "Official Review of Submission9366 by Reviewer CX38", "Subheading": "Official ReviewbyReviewer CX3830 Oct 2023, 02:40 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces a new approach to lightweight graph neural network architecture search called GASSIP. What sets it apart is that during the search process, it jointly considers graph data sparsification and operation pruning, allowing the discovered sub-architectures to achieve better performance with fewer parameters. It also exhibits a degree of robustness. Ultimately, it yields both sparse graphs and lightweight sub-architectures, enhancing search efficiency.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nFirst jointly considers operation pruning and graph data sparsification in graph neural architecture search, which can efficiently search lightweight GNNs.\nUses curriculum learning strategy in graph data sparsification, which can more accurately identify redundant edges and obtain a sparse graph structure beneficial for downstream tasks\nWeaknesses:\nConsiders graph sparsification and operation pruning at the same time, but does not provide a theoretical analysis of whether this iterative optimization converges.\nInsufficient experiments on large-scale graph data: The large-scale graph data set used in the experiments of this article only contains OGBN-ARXIV. Therefore, more experiments on large-scale graph data are needed to verify the performance of the GASSIP method.\nQuestions:\nIs the search result sensitive to the choice of random seed?\nSimultaneous optimization of operation pruning and graph data sparsification may interfere with each other and lead to performance degradation. Could you provide some theoretical analysis on the convergence of the joint optimization process?\nIn equation (3), operation pruning and graph sparsification are combined with a logical OR operation. What is the rationale behind this design choice?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to reviewer CX38", "Subheading": "Official CommentbyAuthors21 Nov 2023, 07:02Everyone", "Content": "Comment:\nWe sincerely thank the reviewer for your detailed comments and insightful questions. We are happy to address the concerns you mentioned:\nQ1: Theoretical convergence analysis.\nA1: Thank you for pointing out this weakness. We admit that it is difficult to conduct a theoretical analysis on the convergence of our iterative optimization algorithm without proper assumptions as the convergence of single graph sparsification proved in [1]. Therefore, we include this as one limitation of our work as well as a future direction. On the other hand, we found that GASSIP converges well during practice.  Table 2 in Section 5.3 provides\nsearching time comparison\nin comparison with other baselines. We could see that our proposed method is far faster than DARTS+UGS (a first-search-then-prune method that disentangles the co-optimization method by first searching architectures and then conducting network pruning and graph data sparsification). This indicates that both simultaneous optimization of operation pruning and graph data sparsification and first-search-then-prune show satisfactory convergence behavior in practice.\nQ2: Is the search result sensitive to the choice of random seed?\nA2: Thank you for this question. Here are the experimental results for GASSIP on node classification that is averaged for 100 runs (mean\u00b1std) using different random seeds:\n| Method   | Cora | CiteSeer | PubMed | Physics | Ogbn-Arxiv |\n| GASSIP | 83.20\u00b10.42 | 71.41\u00b10.57 | 79.50\u00b10.30 | 98.46\u00b10.06 | 71.30\u00b10.23 |\nWe can observe that the stds are relatively small, therefore the searched result is not sensitive to the choice of random seed. We have added this observation to the experimental results.\nQ3: In equation (3), operation pruning and graph sparsification are combined with a logical OR operation. What is the rationale behind this design choice?\nA3: We are sorry for this confusion. The symbol denotes the element-wise product operation. We have updated our manuscript to reflect this accordingly.\nQ4: Experiments on large-scale graphs.\nA4: Thank you for this concern. For the issue of large-scale datasets, please kindly refer to the reply to the common question. Since it requires calculating the output of every operation within the supernet on the full graph to estimate reliable architecture parameters, it is difficult for most of the GNAS methods to scale to Ogbn-product and Ogbn-Paper100M without a specifically designed sampling strategy.\n[1] Graph Sparsification by Universal Greedy Algorithms, Journal of Computational Mathematics 2023"}]}, {"Heading": "Official Review of Submission9366 by Reviewer hwTX", "Subheading": "Official ReviewbyReviewer hwTX29 Oct 2023, 01:16 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper introduces a novel approach called GASSIP (Lightweight Graph Neural Architecture Search with Graph Sparsification and Network Pruning) for automating the design of efficient Graph Neural Networks (GNNs). It highlights the needs for lightweight GNAS and data sparsification to reduce resource requirements. GASSIP employs operation pruning and curriculum graph data sparsification to iteratively optimize GNN architectures and graph data, resulting in more efficient and accurate lightweight GNNs. Experimental results demonstrate its superiority over traditional GNNs and GNAS, achieving substantial performance improvements with significantly reduced search time.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nGASSIP is shown to significantly improve the efficiency of GNAS by reducing search time while maintaining or even enhancing the performance of GNNs.\nThe writing is easy to follow.\nWeaknesses:\nThe research problem is not novel to the community. There have been a series of work for the co-optimization of neural architecture and data, even at the domain of graph NAS and graph data.\nI am still concerned about the motivation to work on graph NAS. Different to other neural architectures, there are only several layers in GNNs, and the number of candidate operations is limited. I believe if one only applies the popular toolkit of hyperparameter tuning, the much higher performance will be obtained.\nThe unstructured pruning of model weights makes no sense in the practical efficiency improvement. Based on the current parallel hardware (with processing of single instruction multiple data), the unstructured matrix multiplication has almost the same cost with the dense matrix multiplication.\nQuestions:\nPlease address my concerns listed in the weaknesses.\nIt is unscalable to apply a learnable mask with shape of N\\timesN in graph data. The node number in most of the graphs are at the scale of millions or even billions.\nFollowing the last question, I need to check the possibility of applying this work in the benchmark datasets of ogbn-products and paper100m.\nGraph sparsification is a very old topic, and there have been many researches being conducted to provide the principle in how to remove edges without affecting the graph structural properties (e.g., adjacency eigenvalues). For example, one can remove edges based on degrees of 1/d_i + 1/d_j, where d_i and d_j are the degrees of node i and j, respectively. It is easy to remove more than 90% of edges but maintain the comparable performance [1].\n[1] Lov\u00e1sz, L\u00e1szl\u00f3. \"Random walks on graphs.\" Combinatorics, Paul erdos is eighty 2.1-46 (1993): 4\nHow many edges can be deleted in the adopted datasets?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to reviewer hwTX (1/2)", "Subheading": "Official CommentbyAuthors21 Nov 2023, 07:04 (modified: 21 Nov 2023, 07:05)EveryoneRevisions", "Content": "Comment:\nThank you for your feedback and the raised questions. We are happy that you found our proposed approach GASSIP is novel and our effort to improve the efficiency of GNAS is significant. We are glad to address the concerns you mentioned:\nQ1: The research problem of the co-optimization of neural architecture and data, even in the domain of graph NAS and graph data is not novel.\nA1: Thank you for your opinion.\nOn one hand\n, co-optimization of the neural architecture and graph structure is essential to empowering the GNAS ability, given the discrete space of graph structure makes the traditional optimization that solely considers NAS achieve unsatisfactory performance when applied to GNNs [1]. Therefore, the problem of how to co-optimize GNAS with the underlying graph structure is still not fully solved.\nOn the other hand\n, as we mentioned in the introduction, the main purpose of this paper is to search for lightweight GNN (i.e., lightweight GNN design), which is the first work to search for a lightweight GNN design while considering sparsifying the graph structure simultaneously. In order to select useful information in the graph structure to help search, we propose a novel graph learning algorithm (by co-optimizing the graph structure in Eq. (3)) as you pointed out.\nQ2: The motivation to work on graph NAS.\nA2: Thank you for the comment, though we respectfully disagree with this opinion. It is non-trivial to combine the strength of AutoML and graph machine learning given the following challenges [1-2]: 1) Unlike audio, image, or text, which has a grid structure, graph data lies in a non-Euclidean space. Thus, graph machine learning usually has unique architectures and designs (e.g., neighborhood aggregation functions, pooling functions, and edge dropout strategies ) and could also be constructed very deep [3-4]. For example, typical NAS methods focus on the search space for convolution and recurrent operations, which is distinct from the building blocks of GNNs. 2) Graph tasks per se are complex and diverse, ranging from node-level to graph-level problems, and with different settings, objectives, and constraints. How to impose proper inductive bias and integrate domain knowledge into a graph AutoML method is indispensable. 3) As the results are shown in Table 3 of AutoGL [5], naively applying HPO tuning methods could not surpass the performance of the specifically designed GNAS methods. Therefore, if one can simply use a hyperparameter tuning toolkit on GNNs without considering the GNN architecture to obtain SOTA performance, that could be remarkable progress in this research community.\nQ3: The unstructured pruning of model weights makes no sense in the practical efficiency improvement.\nA3: Thank you for pointing out this concern. Pruning with a mask is a common approach in literature[6]. In practice, the pruning mask becomes quite sparse after several iterations, therefore the pruning is mostly sparse matrix multiplication, which is more efficient compared with dense matrix multiplication. We have included this observation in the revision.\nQ4: It is unscalable to apply a learnable mask with the shape of N\\timesN in graph data.\nA4: Sorry for this confusion. In practice, we use sparse matrix-based implementation, which means that our learnable mask is\n|\nE\n|\nand is applied on the edge_index which has shape\n|\nE\n|\n\u00d7\n2\n, where\n|\nE\n|\nis the number of edges in the graph. Given the graph is naturally sparse in practice, therefore it is not the bottleneck for extending to graphs of billions of nodes. We have improved this detail in our revision.\nQ5: The possibility of applying this work in the benchmark datasets of ogbn-products and paper100m.\nA5: Thank you for this concern. For the issue of large-scale datasets, please kindly refer to the reply to the common question. In short, it is possible to apply this work in large-scale graphs by combining our current implementation with a sampling technique. However, naively applying sampling techniques to the current supernet training in GNAS will result in consistency collapse issues [7]. Since our main focus is to search for lightweight GNNs with limited computational resources, we would like to leave this design of scalable and optimized sampling strategy as a future work to extend GASSIP to graph with a much larger scale."}, {"Heading": "Response to reviewer hwTX (2/2)", "Subheading": "Official CommentbyAuthors21 Nov 2023, 07:05Everyone", "Content": "Comment:\nQ6: Graph sparsification is a very old topic.\nA6: Thank you for this opinion and the example. We agree that the problem of graph sparsification is a long-standing research problem. However, it becomes unclear how the performance would be when a new method is applied to the sparsified graph structure. As shown in Figure 4 in the Appendix of our manuscript, the performance varies quite differently when the sparsity of the graph differs. Therefore, it is non-trivial to adopt a GNN architecture to a sparsified graph while maintaining its performance, let alone optimizing the target GNN to be lightweight simultaneously.\nAnother illustration of your example that removes edges based on degrees could fail under a new setting is the adversarial attack on GNNs [8], where the degree-based method is a usually adopted baseline but has fair performance. This indicates that the problem could evolve therefore the research on graph sparsification still needs to be explored to tackle the new challenges.\nQ7: How many edges can be deleted in the adopted datasets?\nA7: Thank you for this question. The number of edges that are deleted in the adopted graphs is controlled by a hyperparameter\np\n, and it would be as low as 5% in the experiments.\n[1] Automated Machine Learning on Graphs: A Survey, IJCAI 2021\n[2] Graph Neural Architecture Search: A Survey, TST 2022\n[3] DeepGCNs: Making GCNs Go as Deep as CNNs, TPAMI 2021\n[4] Training Graph Neural Networks with 1000 Layers, ICML 2021\n[5] AutoGL: A Library for Automated Graph Learning, ICLR 2021 GTRL workshop\n[6] A Unified Lottery Ticket Hypothesis for Graph Neural Networks, ICML 2021\n[7] Large-scale graph neural architecture search, ICML 2022\n[8] Adversarial Attacks on Node Embeddings via Graph Poisoning, ICML 2019"}, {"Heading": "Kindly requesting response from reviewer hwTX", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:00Everyone", "Content": "Comment:\nDear Reviewer hwTX:\nWe deeply appreciate your insightful comments and questions, which have significantly contributed to improve the quality of our manuscript. We look forward to hearing from you whether our answers, additional results, and modifications to the manuscript have satisfactorily addressed your concerns. We welcome any further feedback and we are happy to promptly make any further improvements to our submission."}]}]}, "pYmQId95iR": {"paper_info": {"Primary Area": "datasets and benchmarks", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "reinforcement learning, benchmark, algorithmic reasoning, logic puzzles", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "Algorithmic reasoning is vital for problem-solving, while RL excels in certain tasks, its ability to handle complex algorithms is largely unexplored; we introduce an RL benchmark to assess this and find that RL struggles with algorithmic reasoning.", "Abstract": "Algorithmic reasoning is a fundamental cognitive ability that plays a pivotal role in problem-solving and decision-making processes.\nAlthough Reinforcement Learning (RL) has demonstrated remarkable proficiency in tasks such as motor control, handling perceptual input, and managing stochastic environments, its potential in learning generalizable and complex algorithms remains largely unexplored.\nTo evaluate the current state of algorithmic reasoning in RL, we introduce an RL benchmark based on Simon Tatham's Portable Puzzle Collection.\nThis benchmark contains 40 diverse logic puzzles of varying complexity levels, which serve as captivating challenges that test cognitive abilities, particularly in neural algorithmic reasoning.\nOur findings demonstrate that current RL approaches struggle with neural algorithmic reasoning, emphasizing the need for further research in this area.\nAll of the software, including the environment, is available athttps://github.com/rlppaper/rlp.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "pdf", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9365", "PDF Url": "https://openreview.net/pdf?id=pYmQId95iR"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9365 by Area Chair MmFD", "Subheading": "Meta ReviewbyArea Chair MmFD09 Dec 2023, 16:21 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper proposes a benchmark for neural algorithmic reasoning and evaluates a variety of algorithms on these tasks. While the tasks are interesting, the reviewers and I myself have concerns about the difficulty of these tasks, the quality of benchmarking (MuZero and Dreamer vs PPO), as well as comparison to other procedurally generated benchmarks such as Procgen -- while I see that these tasks focus on algorithmic reasoning, but what different challenges do these pose to the community? What are properties of RL algorithms that we expect would work well on these tasks? Some controlled studies to understand why these tasks are great tasks besides simply evaluating some design choices would be crucial to have in my opinion. This is because given the generality of RL, it is easy to come up with very hard tasks for any class of algorithms, but that does not mean that the task is necessarily best to make progress for a given class of algorithms. Some clarity on this would be important to have.\nI encourage the authors to address the reviewers' concerns for the resubmission.\nJustification For Why Not Higher Score:\nAs I mention in my meta-review, it remains unclear what the significance and impact of this benchmark is, and comparisons to other benchmarking suites.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 18:28Everyone", "Content": "Comment:\nWe would like to thank the reviewers for their thoughtful and constructive feedback. We appreciate the time and effort they have dedicated to reviewing our work.\nWe are happy to see that reviewers find that \u201cdeveloping a new meaningful benchmark for RL is a worthwhile endeavor\u201d and \u201cthe idea of making available this new benchmark based on the Simon Tatham's Portable Puzzle Collection is good.\u201d We also appreciate that reviewers recognize RLP is \u201callowing to study RL agents capabilities in neural algorithmic reasoning\u201d and that \u201cRLP is novel, well-motivated, and could be useful for the community.\u201d\nIn response to the feedback provided, we have considered each suggestion and made corresponding revisions to address the concerns raised. Below, we outline the general improvements made based on the reviewers' input.\nChanges in the revised manuscript:\nIncluded two new RL algorithms (now a total of 9 approaches tested)\nAdded additional experiments on higher difficulty\nSubstantially improved presentation of results\nImproved general readability and clarity"}, {"Heading": "Official Review of Submission9365 by Reviewer gz2k", "Subheading": "Official ReviewbyReviewer gz2k05 Nov 2023, 02:31 (modified: 05 Dec 2023, 05:22)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a novel RL environment (named RLP) for benchmarking RL algorithms on neural algorithmic reasoning tasks. Precisely, they wrap the 40 games of Simon Tatham\u2019s Portable Puzzle Collection as a Gymnasium environment. This enables any current or new RL algorithm to be easily evaluated on those games. They then provide empirical results showing the performance of several RL algorithms on a number of those games.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper is mostly well-written and investigates an important problem.\nRLP is novel, well-motivated, and could be useful for the community.\nIt is great that RLP is based on a popular set of games which includes a wide variety of puzzle games with difficulty levels and customizable configurations. The fact that all of the games have known polynomial-time optimal solutions is also extremely useful to evaluate the performance gap of RL algorithms.\nThe authors evaluate several RL algorithms (PPO, A2C, DQN, and some of their variants) on several games in the RLP environment, with different types of observations (internal states vs RBP pixels).\nWeaknesses:\nAll the experiments report mean episode lengths instead of mean discounted returns. This makes the empirical results not very useful by themselves since some games like \"Mines\" can terminate at failed states.\nThe experiments do not include model-based algorithms, such as state-of-art ones like MuZero [1] and DreamerV3 [2] would perform in this Benchmark. The experiments also do not include RL algorithms designed specifically for such hard puzzle games (e.g [3]) or for neural algorithmic reasoning in general. Hence, it is unclear if this benchmark is indeed a challenge for current RL algorithms as claimed.\nThe authors state that one of the benefits of the proposed benchmark is that all of the games have known polynomial-time optimal solutions, but they do not compare the evaluated RL algorithms with the optimal ones in the reported results. Including the optimal performance in the reported results is useful to judge how good the evaluated algorithms are in each game. It is also unclear if the benchmark comes with these optimal solutions.\nThe paper only evaluates RL algorithms for game difficulties where a random policy can find a solution.\nIt is not clear what this means, since all the games at all difficulty levels are solvable by a random policy (just with low probability for higher difficulties). I am guessing the authors meant that the random policy can find a solution in a maximum number of timesteps with high probability.\nThe authors also claim that this restriction on evaluated games was necessary to enable any learning for the RL agents. This doesn't seem correct, since we know that many RL algorithms like PPO can solve tasks in which a random policy is highly unlikely to find a solution (for example in robot tasks).\nGiven that PPO is solves most of the evaluated tasks, the empirical results do not support the claim that this is a challenging benchmark for current RL. It would have been useful if the paper also evaluated the algorithms for different difficulty levels to show the scaling laws of current RL algorithms for this benchmark.\nTable 3 is referenced on page 9 but does not exist.\n[1] S. Julian, et al. \"Mastering atari, go, chess and shogi by planning with a learned model\". Nature 2020\n[2] D. Hafner, et al. \"Mastering diverse domains through world models\".\n[3] O. Marom et al.. \"Utilising Uncertainty for Efficient Learning of Likely-Admissible Heuristics\". ICAPS 2020\nQuestions:\nIt would be great if the authors could address the concerns I outlined above. I am happy to increase my score if they are properly addressed, as I may have misunderstood pieces of paper.\n### POST REBUTTAL ###\nThank you to the authors for their time and effort spent to address my concerns. I also really appreciate the addition of Muzero and DreamerV3 to the baselines, and the addition of the optimal solutions. Their response has helped clarify some points I had, but I still have some outstanding concerns, and the new results and revised paper indicate that this work is not yet ready for publication. Mainly:\nI expected Muzero and DreamerV3 to do much better than reported. Their performance is only stated with no discussion (this is a general trend in this paper). Why is it that they both \"still cannot pass the\nhuman easy\nsetting of any puzzles\". Why is Muzero able to solve hard reasoning games like Chess and Go with sparse rewards but fails here, even performing worse than PPO? How do they perform on hard tasks relative to the optimal solution and the other baselines? Why are the training curves (steps/episode) not provided?\nThe authors say\nWhen only the final reward is provided, any RL policy behaves identically to a random policy, as there is no reward to guide it. Therefore, we believe our assessment holds: only when a random policy is able to solve a puzzle with a large enough success rate, an RL approach without intermediate rewards is also able to solve a puzzle.\nThis is extremely wrong. This is only true for RL algorithms that use the random policy as their main exploration strategy (e.g DQN). This is not necessarily true for other algorithms like PPO, HER, RND, R2D2, IMPALA, RAINBOW, Options framework, etc. Dealing with sparse rewards, exploration vs exploitation, and long horizon tasks are corner stone areas of research in RL, and there is a vast and rich literature in it. \nThe statement the authors made here is really concerning. It makes me doubt how much thought really went into the choice of algorithms they evaluated. In general, I suggest the authors:\nCategorise the various aspects of this benchmark that make it supposedly challenging for current RL (e.g sparse rewards, exploration, long horizon).\nThen choose 2 or more state-of-the-art algorithms in each category to evaluate.\nEvaluate them on all (or sample/representative) difficulty levels of all 40 games (or a sample/representative subset).\nFinally, provide a detailed discussion on why various algorithms belonging to each category succeed or fail on various tasks with various difficulty levels.\nI really like the proposed benchmark, but the paper just needs a bit more work to provide the details and experiments needed for it to be useful to the community. Hence, I have reduced my score to a 3 and increased my confidence to a 5.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 18:25Everyone", "Content": "Comment:\nWe thank the reviewer for their effort on reviewing our work. We address their concerns in the following.\nAll the experiments report mean episode lengths instead of mean discounted returns. This makes the empirical results not very useful by themselves since some games like \"Mines\" can terminate at failed states.\nReport: Failed states do not count as successfully completed episodes if identified (mines, guess, inertia, flood), otherwise terminate with max number steps possible (same game, pegs). Detailed results are reported in the appendix of the revised manuscript. We have improved the wording accordingly.\nThe experiments do not include model-based algorithms, such as state-of-art ones like MuZero [1] and DreamerV3 [2] would perform in this Benchmark. The experiments also do not include RL algorithms designed specifically for such hard puzzle games (e.g [3]) or for neural algorithmic reasoning in general. Hence, it is unclear if this benchmark is indeed a challenge for current RL algorithms as claimed.\nWe have added additional experiments to the revised manuscript. In particular implemented and tested MuZero and DreamerV3 on RLP, while DreamerV3 demonstrates promising potential both approaches still cannot pass the \u201chuman easy\u201d setting of any puzzles. The \u201chuman easy\u201d refers to the predefined settings found in Simon Tatham\u2019s Portable Puzzle Collection. More details can be found in the revised manuscript.\nThe authors state that one of the benefits of the proposed benchmark is that all of the games have known polynomial-time optimal solutions, but they do not compare the evaluated RL algorithms with the optimal ones in the reported results. Including the optimal performance in the reported results is useful to judge how good the evaluated algorithms are in each game. It is also unclear if the benchmark comes with these optimal solutions.\nWe have added an upper-bound for the number of steps an optimal solution would need in the appendix. We now measure the steps required by an RL approach compared to the number of steps for the optimal solution. More details can be found in the revised manuscript.\nThe paper only evaluates RL algorithms for game difficulties where a random policy can find a solution. It is not clear what this means, since all the games at all difficulty levels are solvable by a random policy (just with low probability for higher difficulties). I am guessing the authors meant that the random policy can find a solution in a maximum number of timesteps with high probability.\nYes, this is what we meant. We ran a random policy for 10\u2019000 timesteps and repeated over 1000 runs. The puzzles that were not solved by a random policy were declared unsolvable under these constraints and were not evaluated using the different RL approaches.\nThe authors also claim that this restriction on evaluated games was necessary to enable any learning for the RL agents. This doesn't seem correct, since we know that many RL algorithms like PPO can solve tasks in which a random policy is highly unlikely to find a solution (for example in robot tasks).\nWhile the reviewer\u2019s statement is correct, this only holds when intermediate rewards are involved. When only the final reward is provided, any RL policy behaves identically to a random policy, as there is no reward to guide it. Therefore, we believe our assessment holds: only when a random policy is able to solve a puzzle with a large enough success rate, an RL approach without intermediate rewards is also able to solve a puzzle.\nGiven that PPO is solves most of the evaluated tasks, the empirical results do not support the claim that this is a challenging benchmark for current RL. It would have been useful if the paper also evaluated the algorithms for different difficulty levels to show the scaling laws of current RL algorithms for this benchmark.\nPPO only manages to solve half of all tasks on the easiest possible setting by surpassing the performance of the random baseline. The easiest possible setting is beyond trivial for humans. In light of these results, we disagree with the reviewer\u2019s statement \u201cPPO solves most of the evaluated tasks\u201d, and continue to argue that this is a challenging benchmark.\nTable 3 is referenced on page 9 but does not exist.\nTable 3 is located in the appendix. We have changed the references to better reflect this."}]}, {"Heading": "Official Review of Submission9365 by Reviewer K1q1", "Subheading": "Official ReviewbyReviewer K1q101 Nov 2023, 17:03 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a benchmark, dubbed RLP, for reinforcement learning (RL) based on Simon Tatham's Portable Puzzle Collection. The collection includes 40 logic puzzle games, and results are provided for multiple commonly used model-free RL algorithms.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nDeveloping a new meaningful benchmark for RL is a worthwhile endeavor.\nThe paper evaluates multiple commonly used RL algorithms.\nThe source code for the software is publicly available.\nWeaknesses:\nThe paper does not propose a new method to address the presented challenges.\nThe paper does not address the need for the proposed benchmark, provide a detailed analysis of the tested methods' failures, or give a list of open RL problems (related to the challenges offered by RLP).\nMethods tested in this work do not include the newest development in the RL field. One method is from 2022, another from 2020, and the rest are from 2017 or older.\nQuestions:\nN/A\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 18:25Everyone", "Content": "Comment:\nWe thank the reviewer for their effort on reviewing our work. We address their concerns in the following.\nThe paper does not propose a new method to address the presented challenges.\nAlthough our study does not present a new approach to address the identified challenges, it makes a significant contribution by providing a comprehensive benchmark for evaluating RL algorithms in the area of logical reasoning. This benchmark, focused on classic logic puzzles, reveals the current limitations of existing RL approaches and sets a clear direction for future research. Our work serves as a foundational platform, encouraging and enabling the development of new methods to address these complex problem-solving challenges in reinforcement learning.\nThe paper does not address the need for the proposed benchmark, provide a detailed analysis of the tested methods' failures, or give a list of open RL problems (related to the challenges offered by RLP).\nAs we stated in the introduction and in the contributions section of our work, RLP is a necessary benchmark for researchers to test RL agents\u2019 logical and algorithmic reasoning abilities in controlled environments. Furthermore, we demonstrate that this task is far from solved and an important stepping stone to achieving more competent RL agents. \nRegarding detailed analysis of the tested methods\u2019 failures, we found that the method worked in the simplest setting in the case that a random policy was able to find a solution. In all other cases, i.e., where a random policy was not able to find a solution within the given time limit, the tested methods were also not able to learn a policy.\nRegarding the reviewer\u2019s last point, a list of open RL problems; we pose a single problem: How can RL agents learn logical and algorithmic reasoning? Logical reasoning is a foundational requirement for general intelligence. Logic puzzles are at the pinnacle of logical reasoning under perfect testing conditions, yet current RL approaches fail in all but the most trivial cases. Therefore, we provide this benchmark as a building block for future work towards solving this challenge.\nMethods tested in this work do not include the newest development in the RL field. One method is from 2022, another from 2020, and the rest are from 2017 or older.\nWe have added two more recent approaches, MuZero and DreamerV3, to the tested methods. Unfortunately, both methods still fail to solve any puzzle beyond the most trivial setting, highlighting the need for our benchmark. More details can be found in the revised manuscript."}]}, {"Heading": "Official Review of Submission9365 by Reviewer X31L", "Subheading": "Official ReviewbyReviewer X31L31 Oct 2023, 09:59 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe work introduces a novel benchmark for reinforcement learning tailored to understanding capabilities in neural algorithmic reasoning. The benchmark consists of 40 logic puzzle environments, all of which are configurable such that they provide various degrees of difficulty to agents. With a highly sparse reward signal, already small, and, supposedly easier puzzles pose a significant challenge to common model-free RL agents. In an example case study, the proposed RLP benchmark is used to study multiple RL algorithms capabilities in algorithmic reasoning.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe work proposes a novel benchmark to which is relevant to (a subset of) the RL community.\nThe benchmark covers a variety of logic puzzles, allowing to study RL agents capabilities in neural algorithmic reasoning. In particular, the proposed puzzles are all highly configurable such that multiple degrees of difficulty are achievable, making the benchmark also suitable for targeted curriculum learning.\nDetails of the benchmark are adequately listed and the code is made openly available such that it is straight forward to try out the benchmark with a variety of different RL algorithms.\nThe experiments show an example use case of studying how commonly used RL agents perform in the realm of algorithmic reasoning, highlighting that many algorithms struggle to outperform even a random policy.\nWeaknesses:\nThe presentation of the results could be made a bit clearer as the figures is quite crowded and dense. An aggregate result showing how algorithms perform on average across all environments would likely better highlight that PPO and TRPO have a better performance than other algorithms.\nThe analysis of results might be a bit more detailed. For example, what separates a game like fifteen (where all algorithms seem to perform well) from a game like pegs, pearl or solo? Such a more detailed analysis might help to better convey the usefulness of the proposed benchmark.\nTo my understanding, the presented results are all for the \"easiest\" instantiation of the puzzles but no other difficulty levels are provided. If some curated settings for different difficulties would be provided, it would make future comparisons on the benchmark much more straight forward. Without such curated settings users are free to report any setting that works for them, which limits potential comparisons in the future.\nSmall side note: The Atari 2600 was introduced by Bellemare et al.. Mnih et al. popularized it due to their success with DQNs.\nQuestions:\nWhat are the episode lengths for the individual environments?\nHow expensive is training on RLP? Are episodes quick to run due to the c-backend (similar to brax training) or is everything slow due to the pygame bindings?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 18:24Everyone", "Content": "Comment:\nWe thank the reviewer for their effort on reviewing our work. We address their concerns in the following.\nThe presentation of the results could be made a bit clearer as the figures is quite crowded and dense. An aggregate result showing how algorithms perform on average across all environments would likely better highlight that PPO and TRPO have a better performance than other algorithms.\nWe agree that some aggregation is needed to reduce the crowdedness of the figures. We have updated these figures in the revised manuscript.\nThe analysis of results might be a bit more detailed. For example, what separates a game like fifteen (where all algorithms seem to perform well) from a game like pegs, pearl or solo? Such a more detailed analysis might help to better convey the usefulness of the proposed benchmark.\nWe observe two dimensions of difficulty in the logic puzzle collection. One dimension is the inherent difficulty of the puzzle, the other dimension is the difficulty of the puzzle when played with the provided action space (e.g., moving the cursor using keyboard actions). Certain puzzles (e.g., maps) weren\u2019t solved by our agents in the 3x3 setting better than a random policy, which is trivial for humans. We believe this is because of the more complicated sequence of moves that need to be learned to solve this with only keyboard inputs. Using this explanation we conclude that the puzzles which were solved by our agents were easy in both dimensions of difficulty. We have added a more detailed explanation of this topic in the revised manuscript.\nTo my understanding, the presented results are all for the \"easiest\" instantiation of the puzzles but no other difficulty levels are provided. If some curated settings for different difficulties would be provided, it would make future comparisons on the benchmark much more straight forward. Without such curated settings users are free to report any setting that works for them, which limits potential comparisons in the future.\nWe agree with the reviewer. For now we have looked into the easiest human-level difficulty settings as the next milestone for RL agents. While we have looked into generalizing this approach, we believe preset difficulties are too constraining for future evaluations. Especially since the preset difficulty settings found in Simon Tatham\u2019s Puzzle Collection are not consistent across puzzles. We have included formulae for upper-bound optimal number of steps to solve puzzles in the appendix of the revised manuscript. We believe this is a good proxy for the difficulty of any puzzle (i.e., how many steps are needed by an optimal algorithm to solve it). Therefore, while the puzzle setting can be chosen freely, the number of steps needed by an optimal solution is given.\nSmall side note: The Atari 2600 was introduced by Bellemare et al.. Mnih et al. popularized it due to their success with DQNs.\nWe thank the reviewer for noticing this error. We have corrected this in the revised manuscript.\nWhat are the episode lengths for the individual environments?\nWe have added the episode lengths for the individual environments in the appendix of the revised manuscript.\nHow expensive is training on RLP? Are episodes quick to run due to the c-backend (similar to brax training) or is everything slow due to the pygame bindings?\nUnfortunately, there is no speedup due to the c-backend. However, RLP runs adequately fast. Since RLP cannot compete with the performance of brax environments, we will consider a direct implementation in Jax in the future for improved performance."}]}, {"Heading": "Official Review of Submission9365 by Reviewer phJ7", "Subheading": "Official ReviewbyReviewer phJ723 Oct 2023, 03:35 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors propose and make available through a github repository a new benchmark compatible with the gymnasium interface and dedicated to assessing the logical reasoning capabilities of RL agents, based on the Simon Tatham's Portable Puzzle Collection. They then evaluate 6 RL agents on these benchmarks and conclude that these agents are far from satisfactorily solving these puzzles.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe idea of making available this new benchmark based on the Simon Tatham's Portable Puzzle Collection is good.\nThe paper is clear.\nThe empirical study looks correctly executed.\nWeaknesses:\nPart of the design of the benchmark must be discussed (in my opinion it could be improved, see below)\nWhile the benchmark is proposed to assess the logical reasoning capabilities of RL agents, no serious attempt is made to truly assess these capabilities, nor to evaluate specific agents which may possess such capabilities (see below). It is disappointing that the authors discuss the lack of such capabilities in RL agents in the introduction, but they do not conclude to the need of designing RL agents specifically endowed with such capabilities. They just discuss the way to increase the performance of standard RL agents that do not have such capabilities represented explicitly.\nQuestions:\nQuestions\nCould you categorize the various puzzles in terms of the logical reasoning capabilities they require? Could you then evaluate RL algorithms in terms of displaying such capabilities or not?\nIn the first paragraph of the related work, you list a few RL agents that seem to be endowed with some logical reasoning capabilities. Is the source code of some of these agents available? Could you evaluate some of them on your benchmark?\nEventually, are there some non-RL based agents that can be used as an oracle to determine the shortest number of steps you need to solve a particular maze, or at least a good performance?\nCould you elaborate on the interest of assessing logical reasoning capabilities of RL agents in puzzles rather than in real world situations where reasoning helps? I think I can find some good arguments, but making such points may make the paper stronger.\nWould it be easy to provide a JAX interface so as to speed up the execution of many instances of the puzzles in parallel, as done in Brax and isaac-gym?\nQuestionable design choice\nAll RL algorithms used in the empirical study are episodic, and using them in environments without a time limit raises a number of questions. If an agent fails to solve an environment, do you run it forever? \"Eternity is very long, particularly when you get close to the end\" (Woody Allen, approximate translation from another language). So, probably, you stop it after some time. But what time? How do you make sure it wouldn't have succeeded two steps after you stopped it? If you think of it seriously, a preset time limit is mandatory in RL experiments. You may take as time limit an empirical estimate of the time it takes to a random policy to solve it (not the mean, something closer to an upper quantile estimate).\nEmpirical results\nThe empirical results with \"length bars\" (Figs 3, 4 and several in appendix) are not easy to read. In particular, the error bars in black can hardly be distinguished from the mean performance in Fig 1. Maybe the main paper should rather show aggregated results (mean over puzzles clustered into relevant groups?) and the full view deferred to an appendix, with environments organized horizontally rather than vertically?\nIn particular, it is in no way striking that TRPO and PPO outperform the rest, only a close investigation puzzle by puzzle can reveal this. Maybe tables will numerical results as in appendices and using bold for the 95% best would be more readable without requiring more space?\nI'm not sure Figure 5 brings any important information. Either it should be exploited in more details, or it might move to some appendix, in my opinion.\nTo me, the most important issues with this paper are the first two above and the time limit issue, if the authors can significantly improve their paper in those respects, I'll be happy to significantly increase my evaluation.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 18:23Everyone", "Content": "Comment:\nWe thank the reviewer for their effort on reviewing our work. We address their concerns in the following.\nWhile the benchmark is proposed to assess the logical reasoning capabilities of RL agents, no serious attempt is made to truly assess these capabilities, nor to evaluate specific agents which may possess such capabilities (see below). It is disappointing that the authors discuss the lack of such capabilities in RL agents in the introduction, but they do not conclude to the need of designing RL agents specifically endowed with such capabilities. They just discuss the way to increase the performance of standard RL agents that do not have such capabilities represented explicitly.\nFor each puzzle, we have now included an upper bound of steps required to solve an episode for an optimal policy. Further, we include two new algorithms in our experiments, DreamerV3 and MuZero. In our results, we show that DreamerV3 outperforms the other algorithms, but still only achieves optimal performance for a limited number of puzzles in the easiest difficulty setting. Furthermore, DreamerV3 is also not able to achieve good performance in the easiest human-level difficulty setting.\nWe agree that RL agents would profit from extending their capabilities correspondingly. For this reason we have extended the discussion and conclusion section in the revised manuscript accordingly.\nCould you categorize the various puzzles in terms of the logical reasoning capabilities they require? Could you then evaluate RL algorithms in terms of displaying such capabilities or not?\nWe have chosen to categorize the puzzles into numbers of steps required to solve them. We believe this may be a valid proxy for the complexity of a logical puzzle. These values can be found in the appendix of the revised manuscript.\nIn the first paragraph of the related work, you list a few RL agents that seem to be endowed with some logical reasoning capabilities. Is the source code of some of these agents available? Could you evaluate some of them on your benchmark?\nWhile unfortunately the source code of the mentioned algorithms was not available to us, we now include results for the algorithms DreamerV3 and MuZero.\nEventually, are there some non-RL based agents that can be used as an oracle to determine the shortest number of steps you need to solve a particular maze, or at least a good performance?\nWe have added a table containing an upper-bound for the number of steps needed to solve each puzzle in the revised manuscript.\nCould you elaborate on the interest of assessing logical reasoning capabilities of RL agents in puzzles rather than in real world situations where reasoning helps? I think I can find some good arguments, but making such points may make the paper stronger.\nWhile assessing logical reasoning capabilities in real world situations might serve a clear purpose, it also comes with a set of variables that cannot be controlled. This makes it hard to understand what the underlying factors are, and if logical reasoning was indeed the governing variable in the outcome. In contrast, logic puzzles offer a simple, controlled, and standardized approach to assess logical and algorithmic reasoning capabilities.\nWould it be easy to provide a JAX interface so as to speed up the execution of many instances of the puzzles in parallel, as done in Brax and isaac-gym?\nWe agree that a direct JAX interface would prove beneficial for performance reasons. In principle, this should not be an issue, and we will consider building this in a future work."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 18:23Everyone", "Content": "Comment:\nAll RL algorithms used in the empirical study are episodic, and using them in environments without a time limit raises a number of questions. If an agent fails to solve an environment, do you run it forever? \"Eternity is very long, particularly when you get close to the end\" (Woody Allen, approximate translation from another language). So, probably, you stop it after some time. But what time? How do you make sure it wouldn't have succeeded two steps after you stopped it? If you think of it seriously, a preset time limit is mandatory in RL experiments. You may take as time limit an empirical estimate of the time it takes to a random policy to solve it (not the mean, something closer to an upper quantile estimate).\nFor computational reasons we decided on a time limit of 10k steps. We selected difficulties that were solvable with high probability within these 10k steps, which generally resulted in the simplest non-trivial difficulty setting.\nIn practice, choosing the time limit for each puzzle as an upper quantile of the time it takes a random policy might make sense. But the problem of premature stopping before solving the puzzle will still exist, this is the drawback of a single final reward and possibly endless execution.\nUsing intermediate rewards would be one possible way to alleviate this problem, where an early termination of an episode has a smaller effect if some rewards have already been awarded. Unfortunately, these rewards need to be designed for each puzzle individually.\nThe empirical results with \"length bars\" (Figs 3, 4 and several in appendix) are not easy to read. In particular, the error bars in black can hardly be distinguished from the mean performance in Fig 1. Maybe the main paper should rather show aggregated results (mean over puzzles clustered into relevant groups?) and the full view deferred to an appendix, with environments organized horizontally rather than vertically?\nWe have reworked the figures and added tables in the revised manuscript.\nIn particular, it is in no way striking that TRPO and PPO outperform the rest, only a close investigation puzzle by puzzle can reveal this. Maybe tables will numerical results as in appendices and using bold for the 95% best would be more readable without requiring more space?\nWe have reworked the figures and added tables in the revised manuscript. Figure 3 in the main text now gives a general overview of the performance of each algorithm.\nI'm not sure Figure 5 brings any important information. Either it should be exploited in more details, or it might move to some appendix, in my opinion.\nWe agree and have improved the corresponding Figure in the revised manuscript."}]}]}, "xVoj8AtyQ1": {"paper_info": {"Keywords": "Deep Learning, DNN, Transformer, ViT, DeiT, Tensor Decomposition, Tensor Network, BTD, BTD-LL1, CPD, DNN Compression, DNN Acceleration", "TL;DR": "A novel method for reducing the computation complexity of multi-head self-attention mechanism in Vision Transformer based on BTD-LL1 decomposition.", "Abstract": "Compression of Transformer is a natural request that arose in the computer vision community. Apart from quantization that hardly rely on hardware, sparsification is another way to remove redundant parts, usually based on mask training or sparsity regularization. We propose the novel compressed structure of multi-head self-attention (MHSA) mechanism called Irregular Attention (IAtt). IAtt is built on BTD-LL1 tensor decomposition and is aimed at sparsifying pre-trained Vision Transformer by pruning query and key (QK) contraction dimension in MHSA block. We derive the algorithm of rank selection procedure for BTD-LL1 based on the structure of fusion layer obtained from CP decomposition of original MHSA kernels. In order to improve the compression ratio with least possible quality loss we introduce the fine-tuning schemes that yield each head its own sub-optimal rank for QK in the IAtt. We validated the proposed scheme for DeiT architectures on ILSVRC-2012 dataset. Our results show that IAtt has better performance compared to original MHSA compressed by SVD. It indicates that attention heads have non-uniform importance and require different QK contract dimensions.", "Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9363", "PDF Url": "https://openreview.net/pdf?id=xVoj8AtyQ1"}, "review_info": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 16:52 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\nWe appreciate the reviewer's concern that the comparison with existing compression methods is limited. However, we would like to point out that the domain of neural network compression is very broad and diverse, and it is not feasible to compare our method with every possible approach. Our method is designed to find a sparse representation of MHSA and is closely related to structural pruning. Therefore, we have compared our method with the most recent and relevant structural pruning methods in Table 2. We also note that our method is compatible with other compression techniques, such as quantization and token pruning, and we plan to explore their combination in future work. Other low-rank methods mentioned in Related Works are either applied to different domains, such as NLP, or tested on simpler datasets, such as CIFAR-10/FashionMNIST, and thus are not suitable for comparison. However, to address the reviewer's comment, we will include more pruning methods in the revised version of the paper, which were omitted in the original submission due to space constraints.\nWe justify our choice of focusing on DeiT architecture and ImageNet dataset for several reasons. First, image classification on ImageNet is a challenging task that requires high performance and robustness from the model, and thus exposes the sensitivity of the model to the compression method. This is not always the case for smaller and easier datasets, such as CIFAR-10 or FashionMNIST. Second, DeiT architecture is a good representative of vision transformers, as it is based on a vanilla Transformer from NLP. As our method only modifies the multiplication between $W^Q$ and $W^K$, and between $W^V$ and $W^O$ in MHSA block, it can be easily applied to many vision transformers without affecting their original structure. Third, DeiT mainly consists of MHSA and MLP, which makes it easier to isolate and evaluate the effect of our method, as the result is not influenced by other non-compressed components, such as in object detection or image segmentation. Finally, most of the existing pruning methods for vision transformers presented in Table 2 and in the literature were also tested on DeiT architecture and ImageNet dataset, which allows for a fair and consistent comparison.\nOur paper aims to study different aspects of our method, such as rank selection and initialization of the IrrAtt layer. For rank selection, we use a local compression approach (see Section 3.4) as optimal rank search would require a large number of simulations. For initialization of the IrrAtt layer, we experiment with two cases: initialization with constrained CP or initialization with BTD-(L,L,1) decomposition. The former case assumes fine-tuning with constraint (see Equation (7)), while the latter one is presented in Algorithms (1-3): initialization, single component update, and overall structure. Initially, we used SDF [1] to obtain BTD-(L,L,1) decomposition, but it was much slower, and we had to switch to our proposed method. The comparison of the initializations is discussed in Section 4.3. We believe that this constitutes a sufficient ablation study, but we did not highlight it explicitly in the text. We will revise the paper to make the ablation study more clear and visible.\n[1] Sorber, L., Barel, M.V., and Lathauwer, L.D. (2015). Structured Data Fusion. IEEE Journal of Selected Topics in Signal Processing, 9, 586-600."}, {"Heading": "Official Review of Submission9363 by Reviewer NApC", "Subheading": "Official ReviewbyReviewer NApC01 Nov 2023, 04:45 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes Irregular Attention (IrrAtt) for the compression of multi-head self-attention (MHSA) in vision transformers. IrrAtt is built on top of BTD-(L,L,1) tensor decomposition and is aimed at sparsifying pre-trained vision transformers by pruning the query and key contraction dimension in the MHSA block. The proposed IrrAtt is validated for the DeiT architecture on the ILSVRC-2012 dataset.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThe compression of vision transformers is an important research problem. This paper is well-motivated. The writing is professional and convincing.\nWeaknesses:\nThe comparison with existing methods is very limited, i.e., only three methods are compared. Considering that there has been a very large literature on the compression and efficient design of vision transformers, such a limited comparison cannot demonstrate the effectiveness of the proposed method.\nThe proposed IrrAtt is only validated for the DeiT architecture. Considering that there have been many popular transformer architectures such as Swin Transformer, PVT, and MViT, the only validation for DeiT cannot demonstrate the effectiveness of the proposed method.\nThere is no ablation study in this paper. This paper has many designs and components (Eq. (1) \u2013 Eq. (7), Alg. 1 - Alg. 3), and it is important and necessary to evaluate each of these designs and components. Recently, ablation study is also a necessary part of computer vision papers, especially for deep learning papers.\nWill the code be released? This is not mentioned in the paper. This is important to ensure the reproducibility of the paper.\nQuestions:\nPlease see the above weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 17:18 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\nWe thank the Reviewer for the comments.\nWe have addressed the comments about comparison with other existing compression methods, about experiments with other models and datasets, and about ablation study in the comment to all reviewers. We want to consider the comment about the ablation study in more detail. Equations (1-2) describe the original MHSA, while Equations (3-4) express the Canonical Poliadic decomposition and how it can be applied to MHSA. Equations (1-3)  are known from the literature, and Equation (4) is their implication. Equation (5) formulates our assumption about block diagonal structure for the fusion layer, and Equation (6) shows how CPD could be converted to BTD-(L,L,1) using Equation (6). Constraint in Equation (7) is a modification of the original training loss, and it is a simple way to turn the fusion layer into a block diagonal one. We are going to release the codes."}]}, {"Heading": "Official Review of Submission9363 by Reviewer QrK6", "Subheading": "Official ReviewbyReviewer QrK601 Nov 2023, 03:02 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper aims to compress Transformers. It proposes the Irregular attention build on top of BTD-(L,L,1). It sparsifies pre-trained vision transformers by pruning the query and key contract dimensions in the MHSA. A fine-tuning scheme is also introduced to improve the performance. The proposed irregular attention is validated for DeiT on ILSVRC-2012 dataset. Experiments show the better results of the proposed method.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe studied problem of compressing vision transformers is quite important for the community.\nThe idea of diversing the importance of multi-attention heads in transformers is reasonable.\nUsing BTD-(L,L,1) in this problem is new.\nWeaknesses:\nThe paper only evalutes on one dataset and one vision transformer. It needs more validations to support the paper's arguments.\nThe organization of experiments can be improved. Instead of presenting the results, it is better also to analyze the results and give the readers insights about the improvement if possible.\nIt seems that the paper did not compare to other compression methods. The methods compared in Table 1 are the preliminaries for the proposed one, however, many related works described in Section 5 are not compared.\nThe contributions listed in the end of Section 1 are not significant enough for an ICLR paper.\nThe importance of the obtained results and the derived method need to be further strengthed.\nQuestions:\nIs there any evidence to support the assumption of (5)?\nThe way of presenting Algorithm 1-3 should be revised to improve its readability.\nIt lacks an overview of the proposed irregular attention, and how it can be used in existing vision transformer architectures.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 17:20 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\nWe want to thank the Reviewer. We will revise the manuscript significantly to incorporate the comments and suggestions of the Reviewers. We have addressed the comments about comparison with other existing compression methods, and about experiments with other models and datasets in the comment to all reviewers.\nRegarding the importance of the proposed method, we aimed to study different properties of the proposed method. We took DeiT model as one of the simplest and most widely used vision transformer models in order to show the efficiency and flexibility of our approach. Thus, we decided to concentrate on DeiT to study our method deeply.\nThe assumption (5) is supported by the structure of weights in CP SlimAtt layers for DeiT, one of which is illustrated in Figure 3.\nThe proposed method is general and could be straightforwardly applied to many vision transformers, as it replaces multiplication between $W^Q$ and $W^Q$, and between $W^V$ and $W^O$ with their low-rank counterparts and does not modify other parts."}]}, {"Heading": "Official Review of Submission9363 by Reviewer v2e6", "Subheading": "Official ReviewbyReviewer v2e601 Nov 2023, 02:52 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a mechanism called Irregular Attention to compress the retrained Vision Transformer, which is built based on BTD-(L,L,1) tensor decomposition. The proposed method automatically determines the own rank of attention weight under the constraint of the total ranks of heads.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe paper proposes a method which has the same computation complexity as TruncAtt and performance similar to CP SlimAtt.\nThe paper provides quantitative results to prove the effectiveness of the proposed method.\nWeaknesses:\nThe paper is not very well written. For example, the abbreviation \"CP\" has made multiple prior appearances without prior explanation, only being clarified in Section 4.2, which may confuse the reader.\nThe paper evaluates the effectiveness of the proposed method based on the experimental results on DeiT and ILSVRC-2012 dataset, which is not comprehensive. The paper should conduct experiments on more datasets to have a more solid conclusion.\nQuestions:\nPlease refer to the weakness part.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 17:20 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\nWe thank the Reviewer for the comments.\nWe have addressed the comments about comparison with other existing compression methods, and about experiments with other models and datasets in the comment to all reviewers."}]}, {"Heading": "Official Review of Submission9363 by Reviewer ycW6", "Subheading": "Official ReviewbyReviewer ycW631 Oct 2023, 09:37 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper mainly focuses on the compression of Multi-Head Self-Attention (MHSA) mechanism. This paper introduces a novel compressed structure for MHSA named Irregular Attention (IrrAtt). This structure is built upon the BTD-(L,L,1) and aims to sparsify pre-trained Vision Transformers by pruning the query and key (QK) contraction dimension in the MHSA block. This paper also presents an algorithm for rank selection based on the structure of the fusion layer derived from the CP decomposition of original MHSA kernels. The main goal is to achieve better compression ratios without compromising the quality of the model.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nIrregular Attention (IrrAtt) provides a new perspective on compressing the Multi-Head Self-Attention mechanism, especially for computer vision tasks. It is applicable to pretrained Transformer models, and holds substantial research value in the field of Machine Learning system and model deployment.\nThe Vision Transformer can be significantly sparsified by using BTD-(L,L,1) tensor decomposition for constructing IrrAtt, which results in a more compact model. It theoretically holds certain feasibility, and is thoroughly discussed.\nThe proposed rank selection algorithm, derived from the fusion layer structure, enables each attention head to have its optimal rank for the Query-Key (QK) contraction.\nThe experiments have validated that the proposed method can achieve a good balance between performance maintenance and model compression.\nWeaknesses:\nThe paper presents a number of conceptual and technical difficulties, and the ambiguous explanations make it challenging for readers to understand the paper. The introduction of the methods is not detailed enough, making it hard to grasp the true contributions of the author.\nIt may be necessary to carefully adjust the rank for the QK contraction in the IrrAtt for each attention head in order to achieve optimal performance.\nThe proposed rank selection algorithm, derived from the fusion layer structure, may result in extra computing overhead, particularly when the model is being trained.\nAlthough validation on a single dataset can provide valuable insights for research, it's beneficial for the model's robustness and generalization to be validated on multiple datasets.\nThe paper did not conduct ablation experiments on various modules of the method, such as initialization, making it difficult for me to judge its true effectiveness.\nThere are several mistakes in the article, such as the MHSA formula in Equation 2. Please clarify or provide references if my understanding is incorrect. English abbreviations appearing for the first time in the paper should be followed by their full names or explanations.\nQuestions:\nAre the comparison methods TruncAtt and CP SlimAtt first introduced in this paper? If not, please indicate the reference. If they are, there is a lack of comparison with existing methods, making it difficult to evaluate the level achieved by the proposed method.\nHow is the compression ratio controlled to reach the target compression ratio in this method? Are the significant discrepancies in the FLOPs and params CR values in Table 1 due to different target compression ratios set by the comparison methods?\nThe current version leaves me doubting its reproducibility.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 17:25 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\nWe want to thank the Reviewer. We will revise the manuscript significantly to incorporate the comments and suggestions of the Reviewers. We have addressed the comments about comparison with other existing compression methods, and about ablation study in the comment to all reviewers.\nFinding the optimal rank for tensor decomposition is a complicated task. This paper used a local compression approach in which each transformer block has the same compression ratio. Still, the proposed method simplifies the rank search procedure as with the given total rank of MHSA (the rank of CP SlimAtt), we get a rank for each head based on the block diagonal structure of a fusion layer.\nThe proposed rank selection algorithm needs either extra decomposition or fine-tuning with regularization. Still, the decomposition could be done in parallel and needs no forward and backward passes, while fine-tuning with regularization may take only a few iterations.\nThe proposed method is for post-training compression. In this scenario, the smaller model is initialized with weights obtained after the approximation of weights in the original model. Hence, there is no option to change the initialization for the model.\nWe thank the Reviewer and will correct Equation (2), which has an extra $XW^V_h$ in the sum. It should be $O = \\sum_{h=1}^H W^O_h A_h$. To get this, we transform equation $O = W^O \\times \\text{concat} (A_1, \\dots, A_H)$ \ninto $O = \\sum_{h=0}^{H-1} W^O(:, Dh+1:D(h+1))A_h = \\sum_{h=1}^{H} W^O_h A_h$.\nThe compression ratio is controlled by the choice of the rank for a decomposition. IrrAtt, TruncAtt, and CP SlimAtt each have different elements; thus, the dependency between FLOPs and the number of parameters varies among compression methods.\nThe results are reproducible. We use DeiT checkpoints from the official PyTorch repository and fine-tune a pipeline similar to DeiT one with some changes described in Experimental Setup (Section 4.1). Besides, CPD with different initializations gives a similar structure, close to the block diagonal one, like the one shown in Figure 3."}]}]}, "AZGIwqCyYY": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "hamiltonian dynamics, cross domain generalization, learning physics, meta learning", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We explore cross domain generalization across dynamical system of diverse functional form of Hamiltonian.", "Abstract": "Recent advances in deep learning for physics have focused on discovering shared representations of target systems by incorporating physics priors or inductive biases into neural networks. While effective, these methods are limited to the system domain, where the type of system remains consistent and thus cannot ensure the adaptation to new, or unseen physical systems governed by different laws. For instance, a neural network trained on a mass-spring system cannot guarantee accurate predictions for the behavior of a two-body system or any other system with different physical laws.\nIn this work, we take a significant leap forward by targeting cross domain generalization within the field of Hamiltonian dynamics. \nWe model our system with a graph neural network (GNN) and employ a meta learning algorithm to enable the model to gain experience over a distribution of systems and make it adapt to new physics. Our approach aims to learn a unified Hamiltonian representation that is generalizable across multiple system domains, thereby overcoming the limitations of system-specific models. \nWe demonstrate that the meta-trained model captures the generalized Hamiltonian representation that is consistent across different physical domains.\nOverall, through the use of meta learning, we offer a framework that achieves cross domain generalization, providing a step towards a unified model for understanding a wide array of dynamical systems via deep learning.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "applications to physical sciences (physics, chemistry, biology, etc.)", "Submission Number": "9361", "PDF Url": "https://openreview.net/pdf?id=AZGIwqCyYY"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9361 by Area Chair 9tyn", "Subheading": "Meta ReviewbyArea Chair 9tyn05 Dec 2023, 11:42 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper introduces an approach for meta-learning across a variety of cross-domain Hamiltonian systems. The reviewers generally found the paper well-written and well-motivated and the experiments interesting and compelling within the setting of Hamiltonian systems. The discussion highlighted some weaknesses of the paper, particularly related to experimental baselines and limitations. The author response and updated manuscript addressed many of the most significant weaknesses, and as such I recommend acceptance.\nJustification For Why Not Higher Score:\nThe limitations of the approach and setting are not clearly defined or investigated, and therefore the scope of applicability and broader appeal remains unclear.\nJustification For Why Not Lower Score:\nThe paper is well-written and interesting, the approach sensible, and the qualitative and quantitative results are strong and the benefit of meta-learning appears clear."}, {"Heading": "Overall response", "Subheading": "Official CommentbyAuthors21 Nov 2023, 05:04 (modified: 21 Nov 2023, 05:11)EveryoneRevisions", "Content": "Comment:\nWe would like to thank all of the reviewers for their constructive and valuable feedback on our work, and furthermore recognizing the strengths of our paper as follows;\nthe originality of our work in contrast to previous studies; learning the unified representation across diverse Hamiltonian system domains (\nReviewer xLig\nand\nReviewer GtBu\n)\nthe importance of the experimental aspects of our work; analysis of the unified representation of Hamiltonian dynamics using CKA (\nReviewer hDu2 and Reviewer jozM\n)\nWe rigorously addressed and incorporated the feedback to strengthen our work. Below are the main points of the revised manuscript (the changes in the manuscript are indicated as\nbold\n).\nMost reviewers suggested a comparison with the baseline of the existing methods described in sections 2.2, and 2.3. The reason we did not include the previous generalization methods was that it was rather difficult to make a direct comparison with our model. Our model aims to learn a unified representation of the Hamiltonian dynamics across the types of physical systems, while the previous studies focus on the scenario of generalizing the dynamics across multiple environments within a fixed system situation. However, we agree with the reviewers that adding the existing baselines would give more concreteness to our result, and added the CoDA (\nKerchmeyer et al. 2022\n) (which showed a significantly high performance among various generalization methods across environments within a system, according to the CoDA authors) baseline experiment.\nWe updated Section 4.4 and SM C.3 with the CoDA baseline and again verified the originality and superiority of our approach.\nWe have added experiment to further discuss the limitation of our method, which is indeed a crucial point to make an argument from our experimental point of view. The added experiment is an adaptation task to the dissipative mass-spring system with the meta-trained model with conservative other systems. The meta-trained model fails to adapt to the dissipative system, indicating a possible limitation of our approach.\nWe updated Section 4.5 and SM C.4 with the corresponding additional experiments and discussions to explore the limitations of our work.\nAlthough all reviewers commented that the motivation and presentation of our paper are clearly written, there were some missing points regarding the implementation challenges solved. Although the existing generalization methods (as noted in the first numbered point above) propose new frameworks to learn the generalized dynamics across environments, their applications are limited when we want to generalize across the system type itself, and especially when the degree of freedom of the system changes in the data distribution.\nWe updated Section 2.3 to clearly state that our approach straightened out the challenges.\nSome of the text, such as section titles and figure captions, has been updated to reflect the comments made by reviewers.\nWe fixed the title of Section 2.2, 2.3, the caption of Figure 3, and moved Table 1. to SM A.3\nOur manuscript has been revised accordingly (blue; major updates, red; minor updates such as typos) and we kindly ask all reviewers to check the updated part of the paper. We hope that our revised manuscript and responses will have a positive impact on the final evaluation.\nOnce again, we thank all reviewers for their efforts in this review and look forward to further discussions.", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 21:13 (modified: 22 Nov 2023, 22:58)EveryoneRevisions", "Content": "Comment:\nDear reviewers, we would like to inform you that several additional experiments are updated in our manuscript as follows.\nUpdates\n:\nDyAd (\nWang et al. 2022\n) baseline results tested on magnetic-mirror system are added in Section 4.4 and SM C.5.\nTo further emphasize the generalization ability of multi held-out systems, the adaptation task to a new 2D harmonic oscillator system is added in Section 4.4 and SM C.3.\nSection 2.2 has been revised to provide a more discussion of methods of generalizing dynamics based on meta-learning. This revision outlines the inherent limitations of these methods and describe how our approach differs.\nWe are grateful for the opportunity to provide further clarification and deeply appreciate the consideration given to our responses, especially within the limited discussion period. We hope that our additional responses will have a positive impact on the final evaluation."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:52Everyone", "Content": "Comment:\nDear reviewers, we would like to inform you that the Section 4.4 and SM C.3 are updated with an additional test system; Kepler system, to add more concreteness to the ability of generalization of multi held-out systems.\nOnce again, we deeply appreciate the consideration given to our responses, especially within the limited discussion period."}]}, {"Heading": "Official Review of Submission9361 by Reviewer hDu2", "Subheading": "Official ReviewbyReviewer hDu231 Oct 2023, 10:03 (modified: 22 Nov 2023, 23:12)EveryoneRevisions", "Content": "Summary:\nThis paper proposes to use meta-learning to learn generalized representations across different types of dynamical systems. The meta-learning step helps improve the adaptation to unknown systems with fewer data points (compared to randomly initialized and pre-trained baselines) by virtue of generalized representations. The authors also analyze the representations learned by different baselines and meta-learning by using centered kernel alignment (CKA) to gain insights into better performance by the meta-learning model.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe paper is easy to follow and the motivation to learn a generalized model is clear.\nThe experiments are performed with different numbers of data-points for the adaptation task to evaluate the robustness of the approach.\nThe analysis using CKA gives further insight into how the meta-learning model learns closer representations of the adaptation task.\nThe implementation and task curation are described in detail for reproducibility.\nWeaknesses:\nThe main contribution of the paper seems to be utilizing meta-learning to efficiently adapt to new systems. However, it is not clear from the paper if it is as simple as just using off-the-shelf implementation or if there are some challenges to doing this.\nAlso, I would like to see some discussion around why meta-learning is preferred over other representation learning methods e.g. Domain Generalization, and why optimization-based methods surpass other approaches in meta-learning.\nThe experiments are not sufficient. First, there is no comparison with existing baseline models in domain generalization or meta-learning. Second, the comparison of the meta-model and pre-trained model is not fair, and I would suggest the author fine-tune the pre-trained model on the K-shot support set. Third, no visual comparison of the predicted dynamics and the ground truth, making the conclusion less convincing.\nQuestions:\nPlease check the weaknesses above.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer hDu2", "Subheading": "Official CommentbyAuthors21 Nov 2023, 05:07Everyone", "Content": "Comment:\nWe sincerely appreciate your efforts in reviewing our paper. We are pleased that the reviewer noticed the strengths regarding the CKA analysis of the learned representations. We have carefully reviewed the weaknesses pointed out by the reviewer and have revised our manuscript as follows (we also recommend the reviewer review the overall response).\nList of changes in the manuscript\n:\nSection 2.3 is revised to add clarity to the paper based on W1, and W2.\nSection 4.4 and SM C.3 are revised to add existing baseline results following W3.\nThe titles of Sections 4.1, and 4.2 and the caption of Fig. 3 are updated based on W3.\nW1\nThe main contribution of the paper seems to be utilizing meta-learning to efficiently adapt to new systems. However, it is not clear from the paper if it is as simple as just using off-the-shelf implementation or if there are some challenges to doing this.\nW2\nAlso, I would like to see some discussion around why meta-learning is preferred over other representation learning methods e.g. Domain Generalization, and why optimization-based methods surpass other approaches in meta-learning.\nA1, A2\nWe presume that weaknesses 1 and 2 arise from the lack of clarity that we have written in the paper. Existing previous methods have clear limitations; 1) they do not guarantee generalization across diverse systems, and 2) to do so, they need to be flexible with respect to the varying degrees of freedom of the systems. Our approach aims at resolving these challenges by jointly using GNNs and meta-learning. Accordingly, we have revised section 2.3 to clearly state the points mentioned by the reviewer in Q1 and Q2.\nW3\nThe experiments are not sufficient. First, there is no comparison with existing baseline models in domain generalization or meta-learning. Second, the comparison of the meta-model and pre-trained model is not fair, and I would suggest the author fine-tune the pre-trained model on the K-shot support set. Third, no visual comparison of the predicted dynamics and the ground truth, making the conclusion less convincing.\nA3\nFirst, we acknowledge the insufficient comparison with existing baselines. Originally, we considered it to be hard to directly compare our method with other prior baselines due to the different definitions of the scope of generalization, we added a baseline experiment with CoDA (\nKerchmeyer et al. 2022\n) which is considered a representative method for domain generalization in learning physical dynamics (as it is reported to be superior among other related methods according to the CoDA authors). As expected, CoDA failed to adapt to an unseen system with the same number of steps, even for sufficient steps up to 10000. We have revised Section 4.4 and SM C.3 of our manuscript with the CoDA baseline results and discussion.\nSecond, while we appreciate the reviewer's perspective, our work is at the cornerstone in our scope of the problem definition, and thus to show both the possibility and the effectiveness of the unified representation of Hamiltonian dynamics, we chose as baselines the 1) pre-trained model that used the same total number of gradient steps during meta-training, and the 2) randomly initialized model, following the approach of the prior work of\nFinn et al. 2017\nand\nLee et al. 2021\n.\nThird, we respectfully ask the reviewer to check Section 4.2, where the dynamics of the predicted systems are discussed using Figure 3. However, we acknowledge that the presentation of the predicted dynamics written in the paper should be more explicit and accordingly we have updated the title of Sections 4.1, 4.2 and the caption of Figure 3."}, {"Heading": "Official Comment by Reviewer hDu2", "Subheading": "Official CommentbyReviewer hDu221 Nov 2023, 14:09Everyone", "Content": "Comment:\nThank you for your detailed response. Although some of my concerns have been addressed, there are still major questions remaining to be answered:\nThe description of the methodology is not clear. Both the proposed work and CoDA are based on optimization-based meta-learning and one of the key differences is the use of graphs. However, the details of what the vertices and edges in the graph represent and how the graph is constructed are missing. Also, it would be good to have an ablation study on the proposed method without graph representation.\nThere are lots of non-MAML-based meta-learning models working on physics dynamics and they deserve to be compared. For instance, DyAd [1] is a model-based meta-learning with weak supervision for turbulence flow on heterogeneous domains; Sequential Neural Processes [2] has a similar see,tting of generalizing on sequential dynamics; meta-SLVM [3] addresses the adaptation across dynamics via Bayesian meta-learning and has experimented on different physics model. These works should be mentioned as related works and compared to demonstrate how the proposed work improves the generalization across different dynamics.\nI choose to keep my score unless the concerns above are addressed.\n[1] Wang et al, Meta-learning dynamics forecasting using task inference, 2022 \n[2] Singh et al, Sequential neural processes, 2019\n[3] Jiang et al, Sequential Latent Variable Models for Few-Shot High-Dimensional Time-Series Forecasting 2023"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 21:27 (modified: 22 Nov 2023, 22:54)EveryoneRevisions", "Content": "Comment:\nWe acknowledge your detailed comment regarding our response. Below we provide a response for the reviewer\u2019s additional comments.\nAs the reviewer pointed out, one of the key differences between our proposed work and CoDA is the usage of graphs. We would like to add one more major difference as follows. According to the CoDA paper, CoDA is based on the assumption that the\nenvironment\n$e \\in \\mathcal{E}$ is from a specific dynamics $f$ (where $\\frac{dx(t)}{dt} = f(x(t))$) such that the functional form of the dynamics set from the training data and the dynamics set of the unseen data should be the same. In other words, the context of environment-specific parameters is the same across the environments. This way of formulation can also be found for DyAd [1], and meta-SLVM [3]. However, in our setting, we do not impose such assumptions such that the term\nenvironment\n(which was a generalization within a fixed dynamics form) can be extended in the context of the term\ndomain\n(now a generalization across different dynamics) we used in our manuscript. \n And for the missing details about how the graphs represent the system, we followed the settings from\nSanchez-Gonzalez et al. 2019\n, and\nBishonoi et al. 2023\nsuch that the nodes represent the state $(\\vec{q}, \\vec{p})$, while the edge features are not used for now. We revised Section 3.2 accordingly.\nWe acknowledge the reviewer's observation regarding potential misunderstandings on our part. We focused on reporting baseline results for DyAd [1] within a specific system context. Our additional evaluation included testing the magnetic-mirror system adaptation task using a meta-trained model, which encompassed systems of mass-spring, pendulum, and H\u00e9non-Heiles. Notably, DyAd showed limited adaptation capabilities in this context, struggling significantly with the magnetic-mirror system.\n This observation leads us to a critical point: methods such as CoDA, DyAd, and meta-SLVM, which aim to generalize within a fixed functional form of dynamics, may not be directly applicable to our concept of domain generalization (as we have previously discussed in the above-numbered point 1.). To align DyAd more closely with our generalization scope, we made a subtle modification to the parameter $c$ in the encoder loss's first term (weak supervision term), representing it as the Hamiltonian of the system. While it may be hard to argue that the explicit form of Hamiltonian is not shared across the system, we viewed this as a minimal form of weak supervision, leveraging the universal concept of energy in dynamical systems.\n And for the meta-SLVM, although it adapted well to several physical scenarios (namely bouncing balls under 4 gravity, pendulums, and mass springs with each four different physical constants), their adaptation was tested under the same type of physics; among the four dynamics for each physical scenarios, three were used for meta training, and the remaining one was used for meta testing.\n Therefore, despite the inherent limitations of DyAd and similar methods in this context, we posit that our approach, leveraging a vanilla MAML-based method, demonstrates superior adaptability and effectiveness compared to these baselines. This distinction underscores the rationale behind our methodological choices and the results we observed. Accordingly, we revised Section 2.3 with the discussions and Section 4.4 and SM C.5 with DyAd results. We hope that the additional response will address the concerns raised and appreciate the opportunity to clarify these aspects within the limited discussion period."}, {"Heading": "Official Comment by Reviewer hDu2", "Subheading": "Official CommentbyReviewer hDu222 Nov 2023, 23:11Everyone", "Content": "Comment:\nThank the authors for the clarification and additional experiments. Below are some suggestions that may improve the presentation of the work based on the discussion above:\nThe authors could highlight the method is able to process unseen domains and add the details of the graph to the main text. The comparison of the proposed work and existing meta-learning works, including the non-MAML-based works, could be discussed in the related works.\nI appreciate the effort of adding experiments in such limited discussion time, although I still encourage the authors to make more effort on the non-MAML-based works, including the reasons of their inability to adapt to unseen domains and whether the proposed models can be applied to these frameworks.\nI modified my evaluation accordingly."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 07:01Everyone", "Content": "Comment:\nWe thank the reviewer for considering the additional baseline results and discussions. With the additional comments that the reviewer has given to us, we will revise our manuscript including the highlight that our method is able to process to unseen domains and so on. Once again, we heartily thank the reviewer for the effort in reviewing our work."}]}, {"Heading": "Official Review of Submission9361 by Reviewer jozM", "Subheading": "Official ReviewbyReviewer jozM31 Oct 2023, 09:08 (modified: 21 Nov 2023, 08:26)EveryoneRevisions", "Content": "Summary:\nThe paper reports the performance of MAML applied to domain generalization over different Hamiltonian dynamics. The performance gain by MAML is analyzed with multiple indices over different combinations of meta-training and meta-test data. The key findings include the superiority of the meta-trained models compared to the pre-trained and randomly initialized models and an implication that by meta-learning, the representations obtained by the models tend to be more specific to each system.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe experiments clearly show the superiority of meta-learning, at least within the limited number of Hamiltonian systems.\nThe paper is well written. The motivation, the method, and the experimental results are very clearly reported.\nWeaknesses:\nThe limitation of meta-learning for (Hamiltonian) dynamics is not clearly investigated. This makes it difficult to assess the range where the claims made in the paper should be valid. In other words, the claims are rather weak because their applicability seems unbounded with the current set of experiments. When the meta-learning approaches for dynamics may not be beneficial? For example, what happens if you meta-train a model only with conservative systems and try to adapt it to a dissipative system? Such experiments to investigate the limitations of the empirical findings would strengthen the paper.\nThe paper only reports the performance of a well-known method (MAML) merely applied to a particular setting. This could certainly be a kind of contribution in which ICLR audience may be interested, but I think that in such a paper, with a purely experimental point of view, the claims should be made more carefully. Specifically, as stated above, the cases where meta-learning is not necessarily beneficial should also be revealed, with which the claims would become more falsifiable and convincing.\nQuestions:\nI don't have particular questions. It would be great if the authors could additionally report the results of some experiments to investigate the limitation of meta-learning in this context, although this is not a question.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer jozM", "Subheading": "Official CommentbyAuthors21 Nov 2023, 05:08Everyone", "Content": "Comment:\nThank you for your efforts in providing valuable comments on our work. We appreciate the reviewer's comment about the points that should be further considered from the aspect of our experimental point of view. We have thoroughly considered the concerns raised by the reviewer and revised our manuscript as follows (we also recommend the reviewer check the global response).\nList of changes in the manuscript\n:\nSection 4.5 and SM C.4 are revised to add additional experiments according to W1\nW1\nI don't have particular questions. It would be great if the authors could additionally report the results of some experiments to investigate the limitation of meta-learning in this context, although this is not a question.\nA1\nIt should be noted that, in an attempt to provide further insight beyond the experimental results for the generalized model, we have provided the CKA analysis of the learned representations for each of the models. This was also the reason why we only compared the meta-trained model with the pre-trained and randomly initialized model, and not with the existing baselines in the first place. Nevertheless, we strongly agree with the reviewer that our results and claims should be made more carefully from our paper\u2019s experimental point of view, and we appreciate the suggestion to make our claims more thorough by exploring the limitations of meta-learning for learning a unified representation of Hamiltonian dynamics.\nConsequently, we consider the example suggested by the reviewer (meta-training the model with conservative systems and adapting it to a dissipative system), which we believe is a good way to explore this. As expected, the meta-trained model (as well as the pre-trained and randomly initialized model) failed to adapt to a dissipative system, showing a clear limitation of our approach. We discuss the reason why, for the case of a dissipative system, Hamilton's equation (Equation 1 in the manuscript) does not hold, and thus the HNN loss (Equation 2 in the manuscript) is not appropriate for dissipative systems. We argue that to make use of our method, both the system in the data distribution for meta-training and adaptation should share the same nature so that both satisfy the given loss of the implementation. We have added the corresponding experimental results and discussions in Section 4.5 and SM C.4."}, {"Heading": "Official Comment by Reviewer jozM", "Subheading": "Official CommentbyReviewer jozM21 Nov 2023, 08:28Everyone", "Content": "Comment:\nThanks for the response. The revised manuscript is clearer in terms of the specific contribution, and the limitation shown in the new experiments is convincing. I modified my evaluation accordingly."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:59Everyone", "Content": "Comment:\nWe are glad to hear that the concerns from the reviewer were relieved with the additional experiments that the reviewer has suggested. Once again, we greatly appreciate your effort in reviewing our work."}]}, {"Heading": "Official Review of Submission9361 by Reviewer xLig", "Subheading": "Official ReviewbyReviewer xLig31 Oct 2023, 00:11 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposed a novel meta-learning method aiming to learn a unified Hamiltonian representation such that it can be generalized to unseen physical systems. Hamiltonian Neural Networks were utilized as the backbone of the method for learning the unified Hamiltonian representations of different physical systems, via meta-learning pipelines of a variation of MAML. Experiments demonstrated the proposed methods achieved lower relative error of trajectories and energy when adapted to different systems.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\n(1) Unlike many existing works that focus on learning system dynamics under similar\u00a0physical law, the proposed methods aim to learn the unified representations across diverse system domains via meta-learning the\u00a0Hamiltonian of the given system. This sounds\u00a0significant\u00a0and promising.\n(2) Both quantitative and qualitative results demonstrated the proposed method achieved\u00a0better adaptation\u00a0to various new systems compared with baselines.\nWeaknesses:\nThe evaluation can be strengthened\u00a0by considering comparing the proposed methods with other\u00a0Few-shot Learning and\u00a0Physics-informed Neural Networks methods for\u00a0system domain generalization under both \"consistent\" and \"different\" physical laws.\nQuestions:\nIn Figure 4, why does a lower CKA value of the meta-trained model suggest it learned more similar representations during adaptation? As the authors mentioned, should a low CKA value indicate different representations?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer xLig", "Subheading": "Official CommentbyAuthors21 Nov 2023, 05:08Everyone", "Content": "Comment:\nWe appreciate your thoughtful effort in reviewing this work. We are delighted to hear that the reviewer has recognized the contribution of our work in contrast to many existing works. We have carefully considered the points raised by the reviewer and have revised our manuscript as follows (we also recommend that the reviewer check the overall response).\nList of changes in the manuscript\n:\nSection 4.4 and SM C.3 are revised to add existing baseline results according to W1\nW1\nThe evaluation can be strengthened by considering comparing the proposed methods with other Few-shot Learning and Physics-informed Neural Networks methods for system domain generalization under both \"consistent\" and \"different\" physical laws.\nA1\nWe first thought that it would be difficult to directly compare our method with other previous baselines, as the definition of the scope of generalization is different. However, we strongly agree with the reviewer that our evaluation can be strengthened by comparing the proposed approach with other existing methods. We added a baseline experiment with CoDA (\nKerchmeyer et al. 2022\n) which is considered a representative method for domain generalization in learning physical dynamics (as it is reported to be superior to other related methods according to the CoDA authors). As expected, CoDA failed to adapt to an unseen system with the same number of steps, even for sufficient steps up to 10000. We have revised section 4.4 of our manuscript with the CoDA baseline results and discussion.\nQ1\nIn Figure 4, why does a lower CKA value of the meta-trained model suggest it learned more similar representations during adaptation? As the authors mentioned, should a low CKA value indicate different representations?\nA1\nWe acknowledge that our label notation in Figure 4 could be quite misleading. The y-axis represents the 1-CKA (1 minus CKA) value, not the raw CKA value. Therefore, the lower y-axis in Figure 4 indicates a high CKA value, which leads to more similar representations during adaptation."}, {"Heading": "Official Comment by Reviewer xLig", "Subheading": "Official CommentbyReviewer xLig22 Nov 2023, 12:46Everyone", "Content": "Comment:\nThank the authors for their clarification and the additional experiments. I will maintain my score."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:58Everyone", "Content": "Comment:\nAlthough there were some additional results were presented in a rush within the limited discussion period (including additional DyAd baseline results), we hope that these points can resolve the remaining concerns. Once again, thank you for your effort in reviewing our work."}]}, {"Heading": "Official Review of Submission9361 by Reviewer GtBu", "Subheading": "Official ReviewbyReviewer GtBu28 Oct 2023, 06:18 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work leverages the power of meta-learning algorithms coupled with graph neural networks to find a shared representation of physical systems across various functional forms of Hamiltonian. In contrast to previous work, here the focus is on obtaining a representation which is valid across different physical systems. The performance of the framework is evaluated over a range of physical systems aiming to showcase its adaptivity to unseen settings.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\n$\\underline{\\textrm{Originality}}$: the paper presents great originality in providing a Hamiltonian representation learning framework that can generalize across multiple system domains. This is in contrast to the common approach of providing system-specific models.\n$\\underline{\\textrm{Quality}}$: the paper is very well written. First, it provides the reader with all necessary background as well as motivation for the task addressed. Next, methods and results are well constructed.\n$\\underline{\\textrm{Clarity}}$:  the main ideas conveyed in this paper are clearly constructed and explained and supplementary information assists with providing further details and ablation studies.\n$\\underline{\\textrm{Significance}}$:  the main significance of the paper is in defining a new task, generalizing upon existing approaches, and suggesting to derive a framework that learns a representation that is not domain-specific.\nWeaknesses:\nThe paper presents an appealing goal, providing generalized Hamiltonian representations consistent across different physical domains. However, given the presented quantitative and qualitative results it is hard to judge the actual generalization and performance of the framework as detailed in the following points:\nThe notion of $\\textit{generalization}$: ideally when discussing generalization in DL we would like to obtain a single pre-trained model which can then be used for diverse applications. With respect to the presented framework, this would suggest training the model(s) on a single task and then using the same network for prediction on all held-out systems. Similar to the setting presented in Ricci et al. (2023). However, here presented results always consider a single held-out-system. Providing an ablation over the number of systems used for training will allow for strengthening the claim of generalization and applicability for real-world applications.\nBaselines: it would be beneficial to extend the baselines presented in the paper in two directions:\n(i) optimal;  Training over the tested task, using all regimes (meta-, pre-, and vanilla HNN). This will allow a better assessment of the quality of the generalized model and (ii) within system generalization; following the background presented in section 2 it will be valuable to add a comparison to frameworks that are similar in nature and allow $\\textit{within}$ model generalization, e.g. CoDA (Kirchmeyer et al. 2022) or within the same functional form of the Hamiltonian, e.g. iMODE (Li et al. 2023). Here training over the same train-test splits.\nQuestions:\nCan the authors provide additional ablation studies following the weaknesses presented above? Specifically, it will be beneficial to present the performance as a function of the number of systems used in training (see weaknesses 1.) and add additional baselines  (see weaknesses 2.)\nJudging from the presented results the current framework is not suitable for larger systems, could the authors suggest possible extensions that may allow? What would be the necessary refinements that could be incorporated in the meta-learning configuration to allow for that?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer GtBu", "Subheading": "Official CommentbyAuthors21 Nov 2023, 05:09Everyone", "Content": "Comment:\nThank you for your efforts in providing insightful feedback on our work. We appreciate the reviewer's recognition of the originality of our work compared to other related works. We have thoroughly examined the weaknesses and questions and revised our manuscript as follows (we also recommend the reviewer check the overall response).\nList of changes in the manuscript\n:\nSection 4.4 and SM C.3 are revised to add existing baseline results according to Q1\nQ1\nCan the authors provide additional ablation studies following the weaknesses presented above? Specifically, it will be beneficial to present the performance as a function of the number of systems used in training (see weaknesses 1.) and add additional baselines (see weaknesses 2.)\nA1\nWe appreciate the reviewer for suggesting additional experiments to strengthen our paper.\nRegarding weakness 1, it's important to clarify that our primary objective was to explore the generalization of Hamiltonian dynamics for predicting a single, unknown held-out system, underpinned by ample data. While the experiment proposed by the reviewer is indeed beneficial, it aligns more closely with further challenging scenarios involving adaptation to multiple unknown systems. Such situations extend beyond the current scope of our research, which focuses on a singular system context.\nFor weakness 2, we originally thought that it was hard to directly compare our method with other prior baselines as the definition of the scope of generalization is different. However, we agree that adding such baselines would be beneficial. As such, we choose CoDA (\nKerchmeyer et al. 2022\n) as a representative method for domain generalization in learning the physical dynamics (as it is reported to be superior among other related methods according to the CoDA authors). As expected, CoDA failed to adapt to an unseen system with the same number of steps, even for sufficient steps up to 10000. We have revised Section 4.4 and SM C.3 of our manuscript with the CoDA baseline results and included the corresponding discussion.\nQ2\nJudging from the presented results the current framework is not suitable for larger systems, could the authors suggest possible extensions that may allow? What would be the necessary refinements that could be incorporated in the meta-learning configuration to allow for that?\nA2\nAlthough the results for the large systems are quite poor in the reported results, we want to mention that our approach can handle the problem when the degree of freedom of the prepared data is not consistent throughout the system, noting that the previous methods discussed in Section 2.2 and 2.3 cannot be used in such scenarios. Although we cannot give the exact refinements in our preliminary results, possible ways could be 1) tune the update method in meta-learning, e.g.\nLee et al. 2021\nreport that using ANIL variation gives more accuracy compared to vanilla MAML, and 2) strictly search the hyperparameter space."}, {"Heading": "Official Comment by Reviewer GtBu", "Subheading": "Official CommentbyReviewer GtBu21 Nov 2023, 09:04Everyone", "Content": "Comment:\nThank you for the detailed response; while some of my concerns have been addressed others remain hence i choose to keep my score (mainly, while not set as a primary objective, i believe the\ngeneralization\nnotion stands as a big weakness)."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 21:28 (modified: 22 Nov 2023, 22:55)EveryoneRevisions", "Content": "Comment:\nWe acknowledge the reviewer's concern regarding the generalization aspect of our study. The absence of the suggested ablation experiment in our work stemmed from our assessment that the number of systems (1 to 3) required for such an experiment would not be adequate for the adaptation task at hand. Instead, to evaluate such generalization, we directly tested the meta-trained model's performance on multiple held-out systems. Following the reviewer's suggestions, we extended our analysis to include the 2D harmonic oscillator system, utilizing the same meta/pre-trained models from our initial experiments. This approach aimed to assess the model's capability in generalizing across multiple held-out systems. The results showed that the meta-trained model significantly outperformed the baselines in terms of both coordinate prediction and energy estimation, thus reinforcing its generalization ability on a broader range of systems. We have updated Section 4.4 and SM C.3 in our manuscript to incorporate these findings and the corresponding discussions. We hope that the additional response will address the concerns raised and appreciate the opportunity to clarify these aspects within the limited discussion period."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:55Everyone", "Content": "Comment:\nPreviously, we have only added 2D harmonic oscillator system as a new example to check the adaptation to multi held-out systems. To give more concreteness to the point of the\nnotion of generalization\nthat the reviewer has given to us, we also added Kepler system as a new system to test. Accordingly, we have revised Section 4.4 and SM C.3. We deeply appreciate the consideration given to our responses, especially within the limited discussion period."}]}]}, "Q3aKBKCqG8": {"paper_info": {"Keywords": "Early exits, Deep Neural Networks, BERT", "TL;DR": "Adaptive threshold learning to decide early exits during inference.", "Abstract": "Inference latency is an issue in pre-trained networks like BERT due to their large size. To overcome this, side branches are attached at the intermediary layers with provision for early inference instead of inference only at the last layer. This facilitates the early exit of 'easy' samples and requires only 'hard' samples to pass through all layers, thus reducing inference latency.  However, the hardness of the samples is unknown a priori. This leads to the question of how to exit so that the accuracy and latency are well balanced. Also, the optimal choice of parameters involved in deciding exits can depend on the sample domain and hence need to be adapted. We develop an online learning algorithm named UBERT to decide if a sample can exit early. The decisions are based on confidence in inference exceeding a threshold at each exit point, and the algorithm simultaneously learns the optimal thresholds for all the exits. UBERT learns the optimal threshold for the sample domain using confidence observed at the intermediary layers without requiring any ground truth labels. We perform extensive experiments on five datasets with one and two early exits. We compare the performance against the case with no early exits, i.e., all samples exit at the last layer. UBERT achieves a 10%-53% reduction in time with a drop in accuracy in the range of 0.3% - 5.7% with one early exit. For the case with two exits, the time reduction increases to 32%-70% with only a marginal drop in accuracy of 0.1%-3.9%. The anonymized source code is available athttps://anonymous.4open.science/r/UBERT-F2DF/README.md.", "Primary Area": "general machine learning (i.e., none of the above)", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9356", "PDF Url": "https://openreview.net/pdf?id=Q3aKBKCqG8"}, "review_info": [{"Heading": "Official Review of Submission9356 by Reviewer nNLW", "Subheading": "Official ReviewbyReviewer nNLW02 Nov 2023, 17:02 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work presents an early exit method for BERT. The authors use MAB to adaptively find threshold value in an online manner. The evaluation is conducted on 5 classification tasks.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThe ablation seems good.\nThe concept of finding adaptive threshold seems interesting.\nThe proposed method outperforms the compared baselines.\nWeaknesses:\nEvaluation is restricted.\nThe authors claim are often missing supporting literature or validating experiments.\nAuthors exaggerates the efficacy of their method, even though they cannot also resolve the problem.\nThe paper is missing the essential information, which prevents the paper to stand alone.\nMissing details.\nQuestions:\n1-1 Considering recent SOTA NLP models/LLMs, BERT variants are quite older and their size is much smaller, which can already run smoothly with restricted resources under the current HW. Therefore, the only evaluation with BERT-variant in this work makes me doubt about the motivation of this work. The authors should've considered larger language models and showed the generalizability of the proposed work. If the scope is only limited to BERT, its applicability/practicability is questionable as BERT is barely used in real applications.\n1-2 One of closely related work is F-PABEE that outperforms all existing methods in the literature. I highly recommend to add its result for comparison and analysis.\n1-3 Other previous papers like PABEE and F-PABEE, CoLA MNLI MRPC QNLI QQP RTE SST-2 (STS-B) are standardized for comparison. However, authors does not follow.\n2-1 \"Even though it is anticipated that the final layer of the NN can have better accuracy than the intermediate layer\": any support literature or experiments? This is the fundamental assumption, which is not validated throughout the paper.\n2-2 \"The threshold is often determined using a labeled dataset during training and serves as a crucial reference point for decision-making during inference.\": in what cases or papers?\n2-3 \"The optimal threshold value depends on the distribution of confidence levels at the attached exit, which can vary depending on the data distribution. \": any proofs?\n2-4 \" UEE-UCB Hanawal et al. (2022) leverage the MAB framework to learn the optimal exit in EENNs\": How is their use of MAB different from this work?\n2-5 In Sec.2 in lines starting \"LEE Ju et al. (2021b), DEE...\", these works seem quite close to the proposed method. It would be recommended to have details comparison against the proposed work.\n3-1 As authors noted, using a fixed threshold may yield suboptimal results. However, the proposed method finds the threshold based on the observations of previous samples, which cannot be also free from the same issue. So it seems \"Consequently, UBERT sets itself apart\" is not an appropriate claim.\n3-2 The term online learning is quite confusing in this work. As in Sec. 6, the pretrained model is finetuned and this finetuned model is used to adaptively find threshold in an online manner. The adaptive finding is of course online, but this term (online learning/algorithm) is exaggerated and providing confusion.\n3-3 The authors keep using the term \"optimal threshold\" throughout the paper. However, it is optimal only if the given specific setting in Algorithm 1 and 2 is used. With naive changing the cost such as adding a value or scaling, it varies. It is hard to conclude that the proposed method optimally trade-off between latency and accuracy. Is there a curve, for example, UBERT-2 shows best accuracy with -59.5 time while the accuracy reduces with -58 or -60 time? If not, the use of this term seems not proper in this context.\n4-1 The detailed description of ElasticBERT and MAB is not provided.\n5-1 \"Though confidence and latency are in different units, we add them after using a conversion factor.\": I cannot find details of this process in the paper.\n5-2 What should I do if I want to improve the latency while sacrificing the performance or vice versa? The new model should be trained again? If so, although the authors adaptively find the threshold with reward, it is hard for me think it as a benefit compared to other exiting methods. Other work simply change the number and run the model to adjust latency-performance.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal", "Subheading": "Official CommentbyAuthors21 Nov 2023, 16:32Everyone", "Content": "Comment:\nThanks for the reviews!\nA1: For simple tasks such as text classification, we believe that even the BERT model is overparameterized. Also, not only having resources is enough but also the efficient exploitation of these resources is important. Another reason to use ElasticBERT backbone is that it is a pre-trained model with a joint training strategy hence very minimal fine-tuning is required to create the early exit model for specific tasks.\nHowever, the scope is not limited to the BERT model but in this setup, we consider only text classification models and BERT still performs comparable to the SOTA NLP models while maintaining a smaller size. Hence ElasticBERT becomes a good testbed for our algorithm.\nA2: Since it is very recently published, we could not add this as our baseline for comparison as well as reference, however, we added older version of this PABEE as one of our baselines.\nWe will surely compare our method with F-PABEE.\nA3: We already compared our work with PABEE, and also we used the datasets such as MNLI, MRPC, QNLI, QQP, RTE, and SST-2. However, we used some of them as pre-training datasets. For instance, from Table 1, we use the MRPC for fine-tuning the backbone and then we test it on the QQP dataset where not a single ground-truth is used from QQP. In table 1, we use all the datasets from GLUE and ELUE tasks.\nA4: In the appendix, we added Figure 2 which provides the accuracy of different layers for two datasets which is seen to be increasing, this suggested that the accuracy increases as we go deeper into the backbone and start saturating as well. This was the case with other datasets as well. Due to space constraints, we could not add this figure to the main body.\nPlease note that here we are talking about the average accuracy of the complete dataset. However, for a subset of the dataset, things might not be the same.\nA5: All the referred papers in our work except AdaEE, use a threshold value that is either learned on a labeled validation set or it is fixed to maintain a good speed-up ratio on the validation set. The most relevant are: DeeBERT, ElasticBERT, \"You need multiple exiting\", PABEE, etc.\nA6: Yes, we experimentally validate this claim, IMDb and Yelp are two datasets that are similar to each other, one has movie review classification and the other has reviews from hotels, restaurants, etc. Hence these two datasets have different distributions (or domains) but similar tasks. We provide the confidence values in Figure 3, which show that there is some difference between these values and the confidence gain analysis (figure 4, 5) also states that the gain in confidence also changes with change in distribution.\nA7: Their objective is different from ours, they are trying to find the optimal layer (layer up to which DNN should be deployed on the edge device so that a particular text classification task is efficiently completed.) that should be incorporated on the edge device. After choosing the split, they deploy the DNN till the splitting point on the edge device to perform inference on edge only. In contrast, our work utilizes the MAB setup, to adaptively adjust the thresholds based on the task at hand and changing the distribution of the dataset.\nA8: We could not make a direct comparison with these methods as they are developed to find the best intermediate classifier in a service outage scenario such as network connectivity issues etc. In contrast, our work finds the best threshold given latency costs, however, they also use MABs to find the best intermediate classifier for a given service outage scenario.\nA9: By fixed threshold we mean similar thresholds across different layers, but in our method, every layer has a different threshold value that is adapted based on the confidence distribution at that exit point.\nBy fixed thresholds, we also mean that the threshold values should be adapted based on the changing distribution during test time and not merely applying the same threshold that was learned at the training time. However, after convergence to the optimal threshold values given the cost structure, the threshold might be fixed in our setup as well but with different values for different distributions as well as different exit layers. It is not fixed across the changing distribution of datasets.\nA10: Since the data arrives in an online fashion, and for an incoming sample, our algorithm on the fly decides the threshold values hence the threshold is being learned when data arrives in an online fashion, hence, we call our method an online learning algorithm. Our method updated the reward function given in Equation 1 after it received a sample, hence it also learns in an online fashion."}, {"Heading": "Answers to other questions", "Subheading": "Official CommentbyAuthors21 Nov 2023, 16:33Everyone", "Content": "Comment:\nA11: Observe that the input to algorithms 1 and 2 are the latency costs and the exploration parameter, The exploration parameter decides if the user wants to explore more or exploit early, hence we fix it to 2. The only thing that our algorithm depends on is the input latency costs. You are right that the optimal threshold is only with respect to the values of input to the algorithm which should always be the case. Based on the cost structure given by the user, it will find the optimal thresholds to decide an early exit depending on the distribution of the dataset and the computational power of user's device.\nTo make it clear, we only say optimal thresholds based on the given latency cost values. We have already stated that there is a accuracy-cost trade-off, hence if one of the metric improves other declines. Hence we are optimal in modelling this trade-off given the latency cost at the user's end.\nA12: The description of ElasticBERT is given in the Appendix C. Also, MAB framework is very classic framework to solve the online learning problem, hence, we do not provide details on that.\nA13: The details are provided in the paper, we have a subsection named \"latency cost\" inside the experimental section, where we have provided the details of the how we scale the latency cost and how users can choose them.\nA14: If the user wants to improve the latency while sacrificing the accuracy then increase the latency cost values to higher values that are input to the algorithm. Higher latency costs will increase the negative impact of processing the sample deeper in the backbone. If a sample is processed till deeper layers due to higher threshold values chosen for initial layers, then the reward will take a hit and then the chosen action values will lower its reward and will not be explored much. In our case also, it is easy"}]}, {"Heading": "Official Review of Submission9356 by Reviewer sWQ2", "Subheading": "Official ReviewbyReviewer sWQ231 Oct 2023, 11:03 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nInference latency is a key issue in any pre-trained large language models like BERT. Typically, side branches are attached at the intermediate layers with provision of early exit to minimize the inference time. This paper proposes an online learning algorithm, dubbed as, \"UBERT\" to decide if a sample can exit early through an intermediate branch.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nPaper is well-written and the problem setup is mostly clear.\nWeaknesses:\nI am not an expert in this domain. However, I have few concerns.\nIs it necessary to formulate the problem as multi-armed bandit setup? As RL usually resource hungry algorithms and they can take huge time to optimize.\nQuestions:\nRefer to weaknesses section.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal", "Subheading": "Official CommentbyAuthors21 Nov 2023, 16:27Everyone", "Content": "Comment:\nThanks!\nThere are multiple ways in which the thresholds could be modeled e.g. using the validation dataset (in DeeBERT, BranchyNet, ElasticBERT, etc.), distributing the samples to each exit based on the budget available (MSDNet etc.). However, when it comes to adapting to the distribution changes i.e. when the backbone was fine-tuned on a training dataset and thresholds were learned on the validation dataset (with the same distribution) but if the test dataset has a different distribution than the training and validation dataset. We proposed an algorithm that when the latent data distribution of the incoming samples changes we can get good performance by just adjusting the thresholds without any further retraining.\nIn our case, we are reducing the complete fine-tuning and validation task by introducing the RL algorithm."}]}, {"Heading": "Official Review of Submission9356 by Reviewer P3Sw", "Subheading": "Official ReviewbyReviewer P3Sw29 Oct 2023, 14:35 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes an online algorithm based on multi-armed bandits for adjusting the confidence threshold of BERT model with early exit gates. The objective is to reduce the model latency while maintaining high accuracy. The authors build on the existing rich literature of adding early exit classifiers on top of intermediate layers. Here, they focus on the challenge of selecting a good confidence threshold for deciding for each exit gate if to \"exit\" or not. Specifically the authors assume a domain shift of the test data and propose an online algorithm for adjusting the threshold according to the observed data.\nA multi-armed bandit online algorithm is proposed for updating the exit threshold. The reward is designed as the difference in confidence between the last layer and exit layer subtracted by the increased cost, for instances that didn't exit. To normalize the two measures to a similar range, the cost $o$ is some value in [0,1].\nFirst, an algorithm for single exit is described, then extension to multiple exits is presented. The experimental setting is focusing on OOD evaluation and examines the number of transformer layers computed vs. accuracy: training on one classification task and evaluating on another related dataset with similar classification task (repeated for 5 pairs).\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nFocusing on online adjustment of the early exit threshold is novel and interesting. The proposed method is based on multi-armed bandit and provides  an upper bound on the regret. Detailed algorithms are provided and experiments on 5 classification NLP datasets.\nWeaknesses:\nI value the novelty of the method and find it interesting. However, I see several weaknesses in the current paper:\nWhile the proposed method is presented as general, the applicability beyond a single exit layer significantly increases the complexity and the solution space, possibly leading to long exploration stage before converging (the regret bound is only in expectation).\nAlso, many of the hyper-parameters feel pretty specific to the examined setting and justified in the paper with hand-wavy statements (e.g. \"strategically positioned\", \"due to overthinking similar to overfitting during training\" etc.), or with references to the appendix that don't fully explain them. This limits the generalizability of the solution.\nThe value of the cost parameter $o$ that is given to the end-user as a handle for controlling the desired cost is a uninterpretable value between [0,1]. Therefore, at the end of the day it feels like the user will still need to have some further calibration for tuning the value of $o$ to match whatever practical cost they can afford in their own measure and units.\nWhile I see novelty and value in online adjustments of the threshold. The unsupervised novelty is less clear: see for example [1, 2, 3]. [1] and [3] seem to work with unlabeled data, and [3] seem to focus on threshold calibration which might be good to compare against.\nThe experiments feel a bit underwhelming and unclear:\nThe evaluation metric only measures the number of transformers layers and doesn't take into account any potential overhead of the exits and the calibration (and the use of \"Time\" as the column heading) is confusing.\nSince the method focuses on online setup, it would be interesting to see the patterns over time.\nThe baselines model are not described well (for example, unclear what is the difference between ElasticBERT and DeeBERT).\nIt is unclear how come the UBERT models could be better than the baselines in both accuracy and cost? If the backbone model is identical and roughly monotonic (as assumed throughout the paper), then the threshold should only control the tradeoff between the two but cannot improve on both?...\n[1]\nhttps://aclanthology.org/2020.acl-main.537/\n[2]\nhttps://aclanthology.org/2020.acl-main.593/\n[3]\nhttps://aclanthology.org/2021.emnlp-main.406/\nQuestions:\nsee points in weakness section above. Also:\nIn eq.1 : are $C_p$ and $C_l$ always computed by max over softmax? the argmax can be different between the layer $p$ and $l$, making the use of the delta as reward less convincing.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal", "Subheading": "Official CommentbyAuthors21 Nov 2023, 16:18Everyone", "Content": "Comment:\nThanks for the feedback!\nA1: Yes, for multiple exits the exploration period be large if we naively apply the classifical UCB. To address this issue, we have exploited the side observations to improve the convergence rate. And reduce exploration length. In Section 5, extension to multiple exits, we have discussed this. Also, in Proposition 5.1, we provide the probability of observing a particular arm without actually being played by the algorithm. Note that this probability increases with an increasing number of exits.\nA2: For positioning of early exits, we utilize some of the previous works referred to in the subsection 'exit selection'. We have referred to these papers where we mentioned this. \nAlso, when we say \"due to overthinking similar to overfitting\", we provide the justification for why we are getting better accuracy even from the final layer. Overthinking is the process when a sample is correctly classified in some of the initial layers and in deeper layers, it is again misclassified.\nA3: We agree that the user has to provide a cost after calibrating it to match practical values. We have discussed clearly how to do this. For example, we have discussed about flops-based calibration. We believe that these calibrations are required to be input by the users as per their cost perception and there is no fixed way to define this.\nA4: Note that we are using pre-trained models. During the inference time, the data may not follow the same distribution as that used in the training and validation. This is indeed the practical case. In this inference stage, we may not have access to any ground truth label, However, we aim to find a threshold that is optimal. Here the optimality is with respect to the latent ground truth distribution. Hence we refer to our setup as unsupervised.\nAlso note that in  [1, 2, 3], the validation data is assumed to follow the same distributions as that of training data. Whereas in our case, during the inference time, the data distributions of incoming samples may have deviated from that of the training data. For example, the ElasticBERT may have been tuned on SST-2, but inference is done on the IMDb and Yelp datasets.\nA5-(i) We note that we are focusing on NLP tasks using ElasticBERT backbone where each transformer layer is of the same size and complexity. Thus, the cost is directly proportional to the number of transformer layers used. In the evaluation metric, we have separately shown accuracy as well as the cost. The cost here corresponds to the overheads and can also be interpreted as time as each layer is of the same complexity. \n Many previous works already treat it as time measurements to provide a fair comparison. Ex- \"You need Multiple exiting\" [tang et.al.].\nA5-(ii) For the online learning algorithms the patterns over time are observed by plotting the regret curves. We have already provided these details in Figures 8 and 9 in the Appendix which provide the cumulative regret over time.\nA5-(iii) The main difference between DeeBERT and ElasticBERT is: that DeeBERT uses a separate training where the BERT backbone is first fine-tuned the weights of the backbone are freeze and later exits are attached for further training while ElasticBERT does a joint training. We have detailed the setup of ElasticBERT in Appendix C. We will provide more details about the difference in the updated version.\nA5-(iv) The main advantage that UBERT has: is its adaptation of the threshold values. However, all the other baselines use a fixed threshold across all the exits so in those cases which were learned from the validation dataset, which was specific for that dataset. But during test time, the distribution of the sample could deviate from that of the training distribution which in turn changes the confidence distribution. Note that our finetuning and testing data are different.\nAlso, fixed thresholds make the model more restrictive. We explained this in the paper in the results section \"Previous methods like DeeBERT, ElasticBERT, PABEE, and MuE relied on fixed thresholds across layers and domains, resulting in either early exits from initial layers, leading to accuracy loss, or processing until the final layer, incurring higher inference costs.\nA6: Yes, Cp and CL are always computed by max over the softmax.\nYes, the arg max can be different for different layers however if the given layer gives a misclassification then the confidence output of that layer will be very small. It is very rare to have a misclassification with very high confidence. Lower confidence will not let the sample exit the backbone and the sample will be processed to the next layer. Even if somehow the sample exits the backbone at the layer with misclassification then its reward will take a hit as lower confidence will in turn lower the reward value for that layer hence for future samples a higher threshold value will be chosen for that layer."}]}, {"Heading": "Official Review of Submission9356 by Reviewer isHH", "Subheading": "Official ReviewbyReviewer isHH25 Oct 2023, 22:59 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper studies the settings for early-exiting thresholds, which determines which samples will be output at each early exit during inference. This is an interesting topic in both NLP and CV. An algorithm is proposed to decide the confidence thresholds without groud-truth labels. Experiments on NLP tasks show that the method outperforms existing early-exiting approaches. However, there are some overclaims, and important references are missing. Moreover, the experiment results are not convincing enough (see weakness).\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe studied topic is interesting, and the motivation is clearly explained;\nThe method is technically sound.\nWeaknesses:\nOverclaim\n. The authors claimed that existing methods usually use labeled datasets to determine the early-exiting thresholds, and the proposed method removes the need for ground-truth labels. This is not correct. Maybe the cited baselines in NLP do need ground-truth labels. But if the authors pay attention to the dynamic models in the CV field (see the second part,\nMissing references\n), they can find that the decision of confidence thresholds can purely rely on the confidence distribution on the training/validation set. Specifically, one can decide the ratio of samples exiting at different exits, and solve the threshold based on the confidence scores of each exit without touching the ground-truth labels. In summary, the main contribution claimed by the authors, may not hold.\nMissing references\n. It is recommended that the authors compare their method with the aforementioned strategies in the CV field [1,2,3].\nInconvincing experiments\n. In Tab. 2, the proposed method is compared with other baselines at a\nfixed\ncomputational cost. However, the main advantage of dynamic early exiting is one can adjust the thresholds for different computational budgets (see the smooth curves in [1,2,3]. It is kindly suggested that the proposed method is compared with the \"ratio -> threshold\" pipeline in the CV field.\n[1] Huang et al, Multi-Scale Dense Networks for Resource Efficient Image Classification.\n[2] Yang et al, Resolution Adaptive Networks for Efficient Inference.\n[3] Han et al, Dynamic Perceiver for Efficient Visual Recognition.\nQuestions:\nSee weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal", "Subheading": "Official CommentbyAuthors15 Nov 2023, 14:32 (modified: 16 Nov 2023, 03:32)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewer for the feedback!\nQ1: The authors claimed that existing methods usually use labeled datasets to determine the early-exiting thresholds, and the proposed method removes the need for ground-truth labels. This is not correct............\nA1: To be clear, we use both the terms online and unsupervised, hence both the combinations have not been tried early. The methods given by the reviewer work in an offline manner.\nAs per our understanding, recent works such as 'DeeBERT,' 'ElasticBERT,' 'FastBERT' in NLP models, alongside image captioning models like 'DeeCap,' 'Multiple exiting,' and image classification models such as 'BranchyNet,' 'AdaEE,' among others, predominantly involve tuning the threshold for early exiting decisions based on the validation dataset, hence being commonly referred to as using this approach.\nWhile previous image-related works have indeed explored learning optimal threshold values based on confidence measures, these values are typically adjusted concerning the confidence distribution within the validation data, which mirrors the distribution of the training dataset in all the referenced studies. The testing and validation datasets share a similar distribution to the training dataset, ensuring the model operates within analogous environments. Also, there is a strong assumption of constant exit probability distribution across all the exits, which is not true in most cases as deeper exit will have higher exiting probability than initial exits as explained in our paper in Appendix D.1.\nIn contrast, our work specifically addresses post-deployment scenarios where a pre-trained DNN encounters testing with datasets possessing differing distributions from those used during training. This variance leads to a distinct confidence distribution during testing. For instance, a model trained for sentiment classification (SST-2) may face testing in movie review classification (IMDb) (we do not use any ground-truth values from IMDb dataset hence calling it unsupervised), signifying a shift in the underlying dataset distribution. Similarly, in image analysis, post-deployment testing encounters distribution shifts due to image distortions caused by environmental factors like time of day and weather, as discussed in AdaEE. This necessitates adaptive threshold selection. Also, budget setups can force some samples to exit early due to finite budget settings and make the model restrictive while our method adapts to the threshold by maximizing a simple reward function that maximizes the confidence while keeping the computational cost low. Also, note that if we test our algorithm on the dataset say IMDb with movie review classification, we train the backbone on SST-2 a sentiment classification dataset. Hence if we use the budgeting methods then we need a validation set to learn the $q$ values, which then makes the method offline which is not the case we considered.\nTo the best of our knowledge, our proposed approach constitutes a zero-shot adaptation given the test data has a similar kind of task, uniquely tailored to accommodate distribution changes in the test dataset, a facet we believe has not been previously addressed in the existing literature.\nAlso, I would like to refer to this paper \"Adaptive Inference through Early-Exit Networks: Design, Challenges and Directions\" which suggests that post-training these exiting policies need to be adapted to facilitate efficient deployment to use-cases with varying\nrequirements and devices with different computational capabilities\nQ3:  In Tab. 2, the proposed method is compared with other baselines at a fixed computational cost. However, the main advantage of dynamic early exiting is one can adjust......\nA3: I guess by computational cost you mean the threshold for exiting For all the reported baselines, we do not change any of the parameters and directly use their codebases to evaluate the results. All the previous baselines in our paper use fixed threshold values for different layers of NLP tasks, we do not make any changes to their original ideas. Since our research was focused on NLP tasks, we compared it with all the works on NLP tasks and a very recent image captioning early exit model named \"You need multiple exiting\".\nQ2: It is recommended that........\nA2: We did not find these references in the existing literature of very recent NLP as well as Image captioning early exiting models. We will surely add them in the final version of the paper."}]}]}, "J562Q8Hjut": {"paper_info": {"Keywords": "Interpretability, Text classification, Global interpretation, Local interpretation", "Abstract": "In this work, we propose a novel tree-based explanation technique, PEACH (Pretrained-embedding Explanation Across Contextual and Hierarchical Structure), that can explain how text-based documents are classified by using any pre-trained contextual embeddings in a tree-based human-interpretable manner. Note that PEACH can adopt any contextual embeddings of the PLMs as a training input for the decision tree. \nUsing the proposed PEACH, we perform a comprehensive analysis of several contextual embeddings on nine different NLP text classification benchmarks. This analysis demonstrates the flexibility of the model by applying several PLM contextual embeddings, its attribute selections, scaling, and clustering methods. Furthermore, we show the utility of explanations by visualising the feature selection and important trend of text classification via human-interpretable word-cloud-based trees, which clearly identify model mistakes and assist in dataset debugging. Besides interpretability, PEACH outperforms or is similar to those from pretrained models. Code and Implementation details will be provided via GitHub after the acceptance.", "Primary Area": "visualization or interpretation of learned representations", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9354", "PDF Url": "https://openreview.net/pdf?id=J562Q8Hjut"}, "review_info": [{"Heading": "Official Review of Submission9354 by Reviewer TT7T", "Subheading": "Official ReviewbyReviewer TT7T01 Nov 2023, 12:08 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a method for explaining the decisions made by a pretrained language model like BERT finetuned on a text classification dataset. The method consists of 4 steps: First, the pretrained model is finetuned in the typical way, i.e., by adding a classifier head on top of the CLS token. The CLS token representation at the last layer then constitutes the text embedding. Secondly, there is a feature dimensionality reduction step by either a) grouping individual dimensions by their correlation or b) by applying K-Means or c) by training a CNN on top. Third, a decision tree is trained on top of the reduced feature set. Finally, the nodes of the resulting decision tree are annotated with TFIDF statistics collected from the text examples associated with each node. These statistics are visualized as word clouds.\nThe method is evaluated on 5 text classification tasks with various datasets. The results indicate that the classification performance of the decision tree classifier reaches comparable performance to the finetuned model alone. A human evaluation is performed to compare the interpretability of the proposed methods to LIME and Anchor, two common baselines, which indicates that the proposed method performs drastically better. Additionally, some ablations and qualitative evaluations are performed.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\n* the paper proposes an intuitive and reasonable method\n* the method is effective, both in the sense that the added interpretability doesn't come at the cost of classification performance and in the sense that the interpretability is much better than for the baseline methods according to human raters.\n* the paper is relevant to the community\nWeaknesses:\n* It is not clear what problem the paper tries to solve. While it is motivated by the lack of trustworthyness of attention-score methods, there is no comparison in the end. Concrete research questions are missing. The introduction asks prominently \"What should be considered a node of the decision tree in NLP tasks?\", but this question is not revisited again.\n* The datasets used during evaluation are quite easy. Many of them are just topic classification, which can be solved by extracting a few keywords. No advanced reasoning is required, which puts the value of the method in question.\n* It is not clear how local explanations are obtained without manual inspection. No automatic procedure is described that would explain the annotations in the example figures.\n* The choice of baselines for the interpretability evaluation is not motivated. Explanations of how the baselines work are missing. There is no explanation of why the proposed method works better by such a large margin, which means that the reader doesn't learn much from the paper.\n* Individual components of the method's pipeline are well known techniques without any novelty apart from their straight forward combination.\nQuestions:\n* visualizations are computed based on word statistics in the documents corresponding to a note. However, those are global statistics, so is there any guarantee that these can serve as local interpretations?\n* since the visualizations are done based on TF-IDF, I wonder what is the added value of training the decision tree based on features from PLMs? What would be the performance if the decision trees were trained on word clusters directly?\n* are the score differences in Figure 2 statistically significant? They seem quite small, and somewhat random.\n* Section 4.3: Why did you choose LIME and Anchor as baselines? There is no description of how they work or how they were trained. The advantage of PEACH over them is very high, which remains unexplained without given further context of how these methods work different.\n* How are the local explanations (Figure 3) generated? Some of the highlighted words have no exact representation in the word cloud. E.g., for ELMo, engaging is highlighted but not present in the word cloud. Conversely, entertaining is highlighted in the word cloud but not present in the text. Are these local explanations generated automatically?\n* The low trustability of attention-score based interpretation methods are referenced as one of the main motivations in the introduction. Why are they not compared against as baselines?\n* A study with human evaluators was conducted. Details regarding this study are missing, and it is not clear whether approval from an ethics board was seeked.\nFlag For Ethics Review:\nYes, Responsible research practice (e.g., human subjects, data release)\nDetails Of Ethics Concerns:\nA study involving human evaluators was conducted in this paper. Details regarding the implementation of the study and the potential approval through an ethics board are missing.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 03:47Everyone", "Content": "Comment:\nQ1. \n* Thanks for saying that it well-represents the global statistics. On top of this, we also demonstrate local interpretability by tracing the reasoning/inferencing process of each case with word statistics trends and highlighting the relevant keywords from each case related to the global word statistics trend. This would support human users in understanding the inference process of each case as a local interpretation. We believe this would be an important finding from the Natural Language Processing domain. \n* As can be seen in Figure 3, our PEACH can visualise the local interpretation that the finetuned ELMo representations do not capture the global pattern to distinguish between the positive class and negative reviews, leading to the wrong prediction for the positive review, and by checking the details of the word clouds against the review text itself we can identify the concept that the ELMo model gets confused about - \u2018amusing/engaging\u2019.\n* In the camera ready, we will add more case studies from some high-risk text classification datasets, which can enhance the importance of tracing the reasoning/inferencing process with word statistics for both global and local interpretation in the Natural Language Processing domain. \n\nQ2. \n* Thank you. We adopted a decision tree representation as a tool in order to interpret the pattern in the PLM representation. In NLP, many researchers/developers train/fine-tune PLM embeddings and use them for solving their downstream NLP tasks, such as text classification, question answering etc. However, there is no successful approach to convince users which PLM representation is trained well on a specific task, and which one can be used eventually. Due to this issue, users tend to try several PLM embedding methods and check the performance. Hence, we believe that it would be much better for users if there is any approach to explain how the trained PLM representations can understand/interpret the corpus (for the specific NLP task) that they trained.  \n* The above aim is directly aligned with the original purpose of decision tree techniques, which aims to adopt tree-like visualisation in order to show a clear pathway to a decision. Hence, we use a decision tree visualisation by adopting word clusters based on word attention and word similarity in order to reason/infer the decision path for each NLP task.\n\nQ3.\n* As mentioned before, it is very important to train and select better PLM embeddings as an input feature for most NLP downstream tasks. Hence, we would like to share the indicators of how the embedding dimension can affect the performance. \n* We found that our PEACH clearly shows the performance pattern, especially when the corpus has larger classes and lower dimensions.\n \nQ4.\n* We chose LIME (2016) and Anchor (2018) as two well-known explainable AI methods, especially in the NLP domain. We referred to the original published paper, but we will update the detailed information on how these methods work in the camera-ready version. \n\n\nQ5.\n* Figure 3 is visualised for showcasing as the user, who uses our PEACH can easily check the decision path by inspection. The words highlighted in yellow (e.g. \u2018engaging\u2019 and \u2018entertaining\u2019 as mentioned by you) share similar meanings. Since words in word cloud visualisation try to demonstrate the representative concept for each node, it does not make sense to only look out for the exact match of the words between the document and the visualization (which is also not possible for datasets with diverse vocabulary).\n\nQ6.\n* LIME is the attention-score based method which we already use in the human evaluation study to compare our PEACH against with, in terms of interpretability.\n* LIME is just a framework to explain any classifier model based on the model weights (e.g. BERT, ALBERT, ELMo, etc., used as our baselines), and does not affect the original performance of the classifier model. That means the performance of LIME on BERT will be the same as the BERT performance itself, which we already included in Table 1.\n\nQ7.\n* We mentioned the brief human evaluation demographics and human evaluation interface in footnote 6 and figure 26. However, we will put more details about the human evaluation demographics, and approval will be attached to the appendix in the camera-ready version."}]}, {"Heading": "Official Review of Submission9354 by Reviewer HiZh", "Subheading": "Official ReviewbyReviewer HiZh31 Oct 2023, 18:51 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\n- This paper introduces a tree-based explanation technique, titled PEACH (Pretrained-embedding Explanation Across Contextual and Hierarchical Structure), designed to elucidate the classification process of text-based documents through a tree-structured methodology.\n- The authors demonstrate the utility of these explanations by employing word-cloud-based trees.\n- Experimental results showcase that the classification outcomes achieved by PEACH either surpass or are on par with those derived from pretrained models.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThis paper attempts to apply decision tree-based interpretations used in the CV field to the NLP domain. Theoretically, it is possible to combine certain explanatory elements under specific conditions to provide a more comprehensive, logical, and human-cognitively consistent interpretation.\nWeaknesses:\nThis article asserts that the proposed word-cloud-based trees are human-interpretable and can clearly identify model mistakes and assist in dataset debugging. However, based on the examples illustrated in the figures of this paper (such as Figure 26), the word-cloud-based trees do not exhibit strong human-interpretability. They also do not align well with the semantics of the input sentences. From a human perspective, they do not provide clear explanations that would reduce cognitive load.\n\nThe experiments related to interpretability only compare the effectiveness of PEACH against LIME and Anchor, but do not conduct comparisons with the more human-intelligible Rationalization series of methods (Rationalizing Neural Predictions and subsequent series of studies).\n\nThere are several aspects of the paper that require improvement. The paper contains minor writing errors. The explanation of PEACH's interpretability in the introduction is not clear, the rationale behind word clouds is not analyzed, there is no systematic diagram, which hinders readability.\n\n- In the description of MR in the DATASETS section, it mentions \"two training documents,\" and it's unclear if this is an error.In the description of IMDB, there is a grammatical error; the word \"and\" should probably be changed to \"has.\"\n- In the IMDB column of Table 1, there are two bolded numbers, but it appears that there should be only one bolded number.\n- In the article, the figures and tables are located far from their corresponding references, which hinders readability.\n- The focus of PEACH should primarily be on interpretability, specifically on whether it can enhance human understanding of the text classification process. The article should emphasize this point in the introduction. However, the introduction lacks a direct comparison and analysis with previous methods, making it less intuitive. Figure 1 is placed in the introduction but is not explained, making it difficult to understand just by looking at it. In comparison, Figure 26 seems to be more fitting for inclusion in the introduction.\n- The paper solely utilizes TF-IDF to construct word clouds without conducting an interpretability analysis. In the provided examples, it is challenging to discern the specific meanings of word clouds within the nodes, and there is limited overlap between the words in the word clouds and the sentences that need to be explained. This approach does not appear to offer stronger interpretability compared to previous methods.\n- PEACH lacks a systematic diagram.\nQuestions:\nIn CV, decision tree nodes commonly employ specific image segments and representative patterns. In NLP, the choice of what to use as nodes is a topic of discussion. For the use of decision tree methods, employing word clouds as nodes in NLP doesn't seem as intuitive as using image segments as nodes in CV. At least, the examples provided in this article demonstrate this point.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 03:48Everyone", "Content": "Comment:\n* We thank you very much for this valuable question and welcome any improvement on this part as future work. \n* Inspired by tree-based interpretable models in CV, we tried to adopt a tree-like visualisation that shows a clear reasoning pathway of trained PLM embeddings to a decision. With our PEACH, it is possible to explain the global trend of PLM representation and helpful for understanding the decision-making process of PLMs. \n* On top of this, we adopt the word cloud for visualising unstructured text data and getting insight into trends and patterns. Note that image segments are elements of an image, and, likewise, word tokens are elements of a textual document. Hence, we adopt this word token-based cloud for representing each node."}, {"Heading": "Thank you for the reply.", "Subheading": "Official CommentbyReviewer HiZh22 Nov 2023, 18:04Everyone", "Content": "Comment:\nI will maintain the current rating."}]}, {"Heading": "Official Review of Submission9354 by Reviewer 1ymx", "Subheading": "Official ReviewbyReviewer 1ymx31 Oct 2023, 05:33 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors present \u201cPEACH: Pretrained-Embedding Explanation across contextual and hierarchical structure\u201d in which they propose an approach for finding a human-understandable interpretation of text classification with pre-trained language models.\nThe proposed approach works as follows: At first, PLMs are fine-tuned to the text classification tasks. The resulting vector representations of the CLS tokens are taken as Document embedding and are processed further. For this second feature processing step, the authors propose three variants, a Pearsons correlation based clustering, a k-means clustering based method, and a CNN. The goal of all three are to reduce the dimensions of the resulting feature matrix, and to identify the most informative dimensions for those features. \nThese features are then used to create a Decision Tree (based on the commonly used algorithms) that are built to solve the text classification task. Since the feature dimensions and the resulting decision tree nodes by themselves do not provide a human interpretable representation, the crucial task is to provide an interpretable decision tree node. This is accomplished by collecting all documents that pass through a specific node and use their tf-idf word-cloud representation as a visualization of this node. This procedure is done with all nodes, so that every node can be visually represented by a specific word cloud built from the documents that pass through them.\nTheir approach is then evaluated on a performance level, and on an interpretability level. In the performance evaluation, they compare their feature based decision tree approaches with the fine-tuned models. The interpretability is evaluated by human participants that evaluate how much they trust a given classification and a corresponding explanation.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\n-\tThe authors adopt an interpretability model from the computer vision domain to pre-trained language models and evaluate it with human study participants\n\n-\tThe presentation quality makes the paper easy to follow\nWeaknesses:\n-\tIt is unclear to me how the improvements over the baselines are related to the interpretability aspect. It would be helpful to explain whether this is just a byproduct of the main research, or if it was a goal by itself.\n\n-\tAlthough the related work is listed and categorized, a little more explanation \u2013 especially for the LIME approach, which is compared to the proposed PEACH approach \u2013 would provide more background for the human evaluation task.\nQuestions:\n-\tTable 1: separate the results from Peach and the baseline models; maybe just add a horizontal line for easier comparison \n-\tAre the feature extraction methods crucial for the increased performance, or just happen to work well?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 03:50Everyone", "Content": "Comment:\nQ1.\n* Thank you very much for the suggestion. We will add it to the camera-ready version.\n\nQ2.\n* It is very crucial, not only for performance but also for interpretability as well as training efficiency.\n* During our trial without any feature extraction methods, we noticed that only a small amount of dimensions of the embedding (out of 768 or 1024 dimensions) would be used as tree-splitting conditions, so we hypothesised that only a small amount of the embedding dimensions matter, probably due to similar concepts are learned across several dimensions, so we tried different feature extraction methods.\n* Without the feature extraction step, \n    - The trained decision tree tends to overfit. Our analysis for those trails shows that having too many features would lead to the generation of a bunch of exception rules for only one or two specific cases in the training set, which may not really apply to the testing set, making the performance a bit worse and the generated tree a lot more difficult to check and interpret (due to a large number of unnecessary rules.)\n    - The decision tree training is very slow and even impossible for large datasets, as most of the time is wasted calculating the information gain/gain ratio/gini coefficient for all of the input dimensions, even if most of them will not be used as splitting conditions."}]}]}, "b0IRscfEOb": {"paper_info": {"Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Information Extraction, Entity Linking, Relation Extraction, Natural Language Processing, NLP", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We propose a new unified framework for closed Information Extraction capable of Entity Linking and Relation Extraction with high performance on an academic-budget.", "Abstract": "Entity Linking (EL) and Relation Extraction (RE) are fundamental tasks in Natural Language Processing, serving as critical components in various applications such as Information Retrieval, Question Answering, and Knowledge Graph Construction. However, existing approaches often suffer from either a lack of flexibility, low-performance issues, or computational inefficiency. In this paper, we propose ReLiK, a Retriever-Reader architecture, where, given an input text, the Retriever module undertakes the identification of candidate entities or relations that could potentially appear within the text. Subsequently, the Reader module is tasked to discern the pertinent retrieved entities or relations and establish their alignment with the corresponding textual spans. Notably, we put forward an innovative input representation that incorporates the candidate entities or relations alongside the text, making it possible to link entities or extract relations in a single forward pass in contrast with previous Retriever-Reader-based methods, which necessitate a forward pass for each candidate. Our formulation of EL and RE achieves state-of-the-art performance in both in-domain and out-of-domain benchmarks while using academic budget training and with up to 40x inference speed with respect to other competitors. Finally, we propose a model for closed Information Extraction (cIE), i.e. EL + RE, which sets a new state of the art by employing a shared Reader that simultaneously extracts entities and relations.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9353", "PDF Url": "https://openreview.net/pdf?id=b0IRscfEOb"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9353 by Area Chair 2WuG", "Subheading": "Meta ReviewbyArea Chair 2WuG04 Dec 2023, 02:17 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper introduces ReLiK, a retriever-reader model for joint entity linking and relation extraction. Using retrieved knowledge, the input is first enriched,  with the retrieved candidate entities and relations, enabling it to link entities and extract relations in a single pass.\nThe use of the retriever-reader approach for this task is interesting.\nHowever, while ReLiK's integration of entity linking and relation extraction is commendable, the architecture of each module within it remains maybe too similar to existing models. Furthermore, the aspect of doing joint IE is also mature, and not novel.\nJustification For Why Not Higher Score:\nWhile ReLiK's integration of entity linking and relation extraction is commendable, the architecture of each module within it remains maybe too similar to existing models. Furthermore, the aspect of doing joint IE is also mature and not novel.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Request for engagement", "Subheading": "Official CommentbyAuthors18 Nov 2023, 05:53Everyone", "Content": "Comment:\nWe wish to highlight to the Reviewers that we have thoroughly addressed their inquiries. We kindly seek further engagement to clarify specific misunderstandings and to receive acknowledgment regarding the effectiveness of our responses in alleviating their concerns. Specifically, we have provided detailed explanations to address the fairness concerns raised by Reviewer 5D75, stemming from a misunderstanding. Additionally, we have highlighted that the baseline systems suggested by Reviewer 2r4r underperform in comparison to the systems we have already reported on. We believe that engaging in a proactive dialogue on these and other key points will not only contribute to the enhancement of our work but also facilitate a more comprehensive evaluation on their part."}, {"Heading": "Official Review of Submission9353 by Reviewer 5D75", "Subheading": "Official ReviewbyReviewer 5D7502 Nov 2023, 08:39 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes ReLiK, a new Retriever-Reader architecture for EL and/or RE. Given an input text, ReLiK allows to extract relations between entities given a reference knowledge base in a single forward pass. The proposed approach achieves state-of-the-art performance for the closed information extraction task (EL + RE) on standard datasets.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe proposed approach offers fast inference and state-of-the-art performance at a reasonably low budget, which is important for various settings. The paper is well-written and easy to follow. The adaptation of the Retriever-Reader paradigm to cIE is original and, to the the best of my knowledge, has not been proposed before.\nWeaknesses:\nThe proposed approach is underpinned by access to external knowledge since ReLiK is given as input the text together with entities and relations from the KB. This impacts the performance and efficiency of the model and raises concerns about the fairness of the proposed benchmarks.\nMore specifically, the fact that ReLiK relies on the entities and relations from the KB already provides the model with the set of possible entities that can be extracted from the text, which can help for demarcating and disambiguating entities, and also for extracting relations.\nThe access to this non-parametric memory is also what enables to considerably lower the number of parameters, thereby offering faster inference time.\nAlso, the following recent prior work [1], which uses an end-to-end Reader-Retrieval approach for EL, should be cited in the paper. It would be interesting to see how both methods compare.\nMinor comments:\nXs and Xt are not defined in section 3.2, in the definition.\nThe wrong template was used for submission (ICLR 2023)\n[1] Bidirectional End-to-End Learning of Retriever-Reader Paradigm for Entity Linking, Li et al., arXiv:2306.12245, 2023\nQuestions:\nWhat is the point of $<ST_{0}>$ ? It is not associated with any passage and we already have the [SEP] special token to dissociate between the text and the retrieved passages.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 5D75", "Subheading": "Official CommentbyAuthors14 Nov 2023, 10:13 (modified: 14 Nov 2023, 10:13)EveryoneRevisions", "Content": "Comment:\nWe first want to thank you for your review and hope to answer your questions as well as clear some possible misunderstandings.\nWeaknesses\nThe statements:\n\u201cThe proposed approach is underpinned by access to external knowledge since ReLiK is given as input the text together with entities and relations from the KB.\nThis impacts the performance and efficiency of the model and raises concerns about the fairness of the proposed benchmarks.\n\u201d, and\n\u201cMore specifically, the fact that ReLiK relies on the entities and relations from the KB already provides the model with the set of possible entities that can be extracted from the text, which can help for demarcating and disambiguating entities\u201d\nMakes us believe this viewpoint might stem from a misunderstanding, which we are eager to resolve.\nEvery system under comparison uses external knowledge and has access to the possible entities that can be extracted from the text\n. Specifically, systems in [De Cao et al. 2021 a] and [De Cao et al. 2021b] both use an external mention-entity index in which, as stated in our paper, every possible mention (e.g., Barack Obama or Washington) is associated with the list of possible entity classes (i.e. Wikipedia titles) that can be associated with them. [Zhang et al. (2022)] and [1], sharing our Retriever approach, access the same non-parametric external knowledge as ours and the set of extractable entities from the text. Therefore, within the tasks of EL and RE,\nexternal knowledge in the form of entity and relation titles, or their definitions, is not a source of unfairness but rather available information for the task\n, analogous to a training set with labels. Finally, along with the previous reasoning, we want to be very clear that,\nat inference time, ReLiK receives the text as input, and solely the text\n. It is the combination of the Retriever and the Reader that is able first to reduce the number of candidates and then link them. The initial search space encompasses the entire set of entities or relations, as is standard in EL and RE systems, thus ensuring fairness in task comparisons against other systems.\n\u201cAlso, the following recent prior work [1], which uses an end-to-end Reader-Retrieval approach for EL, should be cited in the paper. It would be interesting to see how both methods compare.\u201d\n[1] was published in July 2023 as a preprint on Arxiv, with the deadline for ICLR 2024 being in September, and therefore, we were not able to discuss it in the paper at submission time. It is an extension of [Zhang et al. (2022)] with an interesting new end-to-end training approach. Unfortunately, they do not report results on datasets other than AIDA, and the absence of publicly available code impedes direct comparison. Their results on AIDA are in the same ballpark as ours, but the model suffers from the same shortcomings as [Zhang et al. (2022)] in terms of efficiency, or even worse, as they discuss in their Limitations section. For instance, their system requires 50GB of GPU memory, and takes 3.5 hours per epoch on 4 A100 GPUs, while ours can be trained on a single 4090 and takes half an hour per epoch for the Retriever, and the same for the Reader, on its largest version. Exploring the potential integration of our lightweight paradigm into their end-to-end approach remains an intriguing prospect. We will make sure to cover this paper in the final version of the paper.\nMinor Comments\nXs and Xt are not defined in section 3.2, in the definition.\nWe will make it more explicit that\ns\nand\nt\ndenote the indices of start and end tokens of a span in\nX\n.\nThe wrong template was used for submission (ICLR 2023)\nWe are sorry for using the wrong year, and thanks for noticing it. We will update the year number. Luckily, except for the year, the template itself is the same as the 2024 one.\nQuestions\nWhat is the point of \u27e8ST$_0$\u27e9? It is not associated with any passage and we already have the [SEP] special token to dissociate between the text and the retrieved passages.\nThis is explained in the third footnote, found in page 4:\nHere e$_0$ symbolizes NME, i.e. mentions for which the gold entity is not in E, represented by \u27e8ST$_0$\u27e9\nTherefore, it is used for EL and cIE when a span cannot be linked to any entity candidate because either it is not in the KB or the Retriever module failed to retrieve it, and therefore it is not present in the candidates. To avoid confusion we will make sure to mention it earlier, where it is first shown in Equation 2."}, {"Heading": "Papers from Response to Reviewer 5D75", "Subheading": "Official CommentbyAuthors14 Nov 2023, 10:58Everyone", "Content": "Comment:\nCited Papers\nNicola De Cao, Wilker Aziz, and Ivan Titov. Highly parallel autoregressive entity linking with discriminative correction. In Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wentau Yih (eds.), Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, pp. 7662\u20137669. Association for Computational Linguistics, 2021a. doi: 10.18653/v1/2021. emnlp-main.604. URL\nhttps://doi.org/10.18653/v1/2021.emnlp-main.604\n.\nNicola De Cao, Gautier Izacard, Sebastian Riedel, and Fabio Petroni. Autoregressive entity retrieval.\nIn 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021b. URL\nhttps://openreview.net/forum?id=5k8F6UU39V\nWenzheng Zhang, Wenyue Hua, and Karl Stratos. EntQA: Entity linking as question answering. In International Conference on Learning Representations, 2022. URL\nhttps://openreview.net/forum?id=US2rTP5nm\n_."}]}, {"Heading": "Official Review of Submission9353 by Reviewer 2r4r", "Subheading": "Official ReviewbyReviewer 2r4r31 Oct 2023, 22:46 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis article introduces Retriever & Reader pipeline to Entity Linking (EL) and Relationship Extraction (RE) tasks. ReLiK uses retriever instead of classifiers to discover entities and entity relationships in text, the reader module's role is to identify relevant entities or relations retrieved and align them with the corresponding textual spans. The experimental results show that the proposed methodology strikes a balance between effectiveness and efficiency.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe proposed method has several practical advantages. The reader greatly improve the efficiency of entity linking and relationship extraction.\nEmpirical evaluation thoroughly covers a substantial number of datasets.\nWeaknesses:\nThe baseline systems used for comparison were not comprehensive enough in Section 4,  and it was recommended that more baseline systems be added for comparison[1], [2], [3].\nSince the contribution of this paper lies in the novel paradigm, the authors could have devoted a chapter to a brief overview of the developmental lineage of the relevant paradigm in order to describe more clearly the special features of this paper.\n[1] Johannes M. van Hulst, Faegheh Hasibi, Koen Dercksen, Krisztian Balog, and Arjen P. de Vries. 2020. REL: An Entity Linker Standing on the Shoulders of Giants. In\nProceedings of SIGIR\n[2] Nikolaos Kolitsas, Octavian-Eugen Ganea, and Thomas Hofmann. End-to-end neural entity linking. In\nProceedings of the 22nd Conference on Computational Natural Language Learning\n[3] Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen Fu \u0308rstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard Weikum. Robust disambiguation of named entities in text. In\nProceedings of the EMNLP\nQuestions:\nThe author mentioned that \u201cReLiK excels in this regard, surpassing previous systems in terms of performance, memory requirements, and speed\u201d, but did not provide a quantitative comparison of memory requirements with other systems.\nIn the textual description of Section 3, the word \"passage\" is confusing - does it refer to the entities and relationships obtained by the retriever? The authors need further clarification.\nIs there error propagation when the retriever fails to retrieve relationships and entities from top-k results?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 2r4r", "Subheading": "Official CommentbyAuthors14 Nov 2023, 10:15Everyone", "Content": "Comment:\nThank you for the time taken to review our work. We hope we can address your concerns.\nWeaknesses\n\u201cThe baseline systems used for comparison were not comprehensive enough in Section 4, and it was recommended that more baseline systems be added for comparison[1], [2], [3].\u201d\nUnfortunately, we prioritized including the most current and impactful EL systems for our baseline/comparison systems due to the limited space available. The systems suggested by the reviewer, although valuable, exhibit lower performance than our baselines. However, we will include these lower baselines in a more comprehensive EL comparison in the Appendix.\n\u201cSince the contribution of this paper lies in the novel paradigm, the authors could have devoted a chapter to a brief overview of the developmental lineage of the relevant paradigm in order to describe more clearly the special features of this paper.\u201d\nAgain, space constraints led us to focus on the previous trends and systems for each task in sections 4.1.2  and 5.1.2, but we did not have the space to delve into the explanation of Retriever-Reader systems in general. We will add a more detailed explanation of the \u201cdevelopmental lineage\u201d of RR systems in the Appendix.\nQuestions:\n\u201cThe author mentioned that \u201cReLiK excels in this regard, surpassing previous systems in terms of performance, memory requirements, and speed\u201d, but did not provide a quantitative comparison of memory requirements with other systems.\u201d\nWe reported on the GPU requirements of each system, which is indirectly related to memory. However, we will make sure to include a more quantitative comparison for memory. For our systems, training never requires more than 24GB of memory. At inference time, the retriever with e5 base and batch size of 128 uses 881 MB of VRAM. The reader on its larger model (debate-v3-large) with a batch size of 4096 tokens uses 3985 MB of VRAM for EL, 4497 MB of VRAM for RE. As for the passages index for the retriever, it takes 10 GB of VRAM if loaded on the GPU with fp16, and 17 GB of RAM if loaded on the CPU with fp32. For comparison, [Zhang et al. (2022)] index takes 22 GB of RAM with fp32.\n\u201cIn the textual description of Section 3, the word \"passage\" is confusing - does it refer to the entities and relationships obtained by the retriever? The authors need further clarification.\u201d\nShort answer: Yes.\nMore in general, a \u201cquery\u201d is the input text that will be annotated, while the \u201cpassages'' are the textual representations of the entities or relations to be retrieved using the input query. In Section 3, we adopted the terminology from DPR [Karpukhin et al., 2020] to maintain consistency with prior literature on retriever systems and, therefore, not to be specific on the tasks tackled later, to avoid referring to entities and relations and keep the description of the Retriever-Reader paradigm as general as possible. However, we do understand that it might be confusing. Thanks for pointing it out. We will clarify this in the final version of the paper.\n\u201cIs there error propagation when the retriever fails to retrieve relationships and entities from top-k results?\u201d\nYes, whenever the Reader component fails to retrieve an entity/relation, the Reader component cannot link/extract it, and thus either it does not predict it at all (false negative) or it links/extracts a wrong one. However, the retriever has a very high recall, as shown in Table 6 of the Appendix: 99.2 R@100 and 98.8 R@50, and it rarely is the source of errors. We didn\u2019t report on recall for cIE in the paper, but it is R@20 of 99% for relations and R@25 of 98% for entities on the REBEL dataset. We will add these numbers to the paper as well."}]}, {"Heading": "Official Review of Submission9353 by Reviewer 5PKz", "Subheading": "Official ReviewbyReviewer 5PKz30 Oct 2023, 07:36 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes ReLiK, a retriever-reader model for entity linking and relation extraction. ReLiK encodes input text with retrieved candidate entities/relations and can link entities or extract relations in one pass. ReLiK achieves state-of-the-art results on multiple benchmarks while being faster, more parameter efficient, and trainable on a smaller budget than prior art.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe paper generally has a good presentation that clearly allows readers to understand what was done.\nReLiK establishes state-of-the-art results on benchmarks for entity linking and relation extraction. The joint model for closed IE is also insightful.\nReLiK is faster than prior state-of-the-art models, with gains of 10-40x reported on inference speed. This makes it much more usable in real applications.\nWeaknesses:\nAlthough ReLiK integrates entity linking and relation extraction together into one framework, the design for each module is relatively simple and similar to previous works.\nAs one of the emphases of this paper is the integration of EL and RE tasks. The mutual influence between EL and RE should be more clearly demonstrated in the experimental analysis section.\nQuestions:\n1.\"Recent approaches only focus on at most two out of the three properties simultaneously.\" I don't quite understand this sentence. What are the \"three properties\" referring to\uff1f\n2. I recognize the efficiency gains achieved by linking entities and extracting relations in just a single forward pass. Yet, I'm curious about what is the core design that enables the model to achieve state-of-the-art performance?I recognize the efficiency gains achieved by linking entities and extracting relations in just a single forward pass. Yet, I'm curious about what is the core design that enables the model to achieve state-of-the-art performance?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 5PKz", "Subheading": "Official CommentbyAuthors14 Nov 2023, 10:21Everyone", "Content": "Comment:\nWe first want to thank you for your review. We hope to address some of the concerns and answer your questions.\nWeaknesses\n\u201cAlthough ReLiK integrates entity linking and relation extraction together into one framework, the design for each module is relatively simple and similar to previous works.\u201d\nTo the best of your knowledge, we are the first to design an architecture capable of performing EL and RE in a single forward step in the Retriever-Reader paradigm, while achieving state-of-the-art performances and inference speed. Furthermore,\nsimplicity, in our view, is not a drawback\n. While individual components might bear resemblance to existing models (such as using a Retriever for EL), the real innovation of ReLiK lies in the synergy of these components, which, to the best of our knowledge, we are the first to consider for closed Information Extraction. Moreover, the modularity of ReLiK is a key advantage with respect to other approaches, since ReLiK can be easily enhanced and expanded by leveraging any improvement on each of its components separately.\n\u201cAs one of the emphases of this paper is the integration of EL and RE tasks. The mutual influence between EL and RE should be more clearly demonstrated in the experimental analysis section.\u201d\nWe agree, and that is why\nwe explored such interaction in Appendix A.4.2\nand showed how EL helped RE, evidenced by a notable drop in F1 score when RE is isolated. Performance in Table 2 for EL is reported solely on entities present in triplets, but if we check the F1 score for entities in general, validation F1 reached 87.46 for ReLiK small. We ran an experiment where EL was trained with the same data without RE (similar to the experiment reported in A.4.2) and F1 reached 87.5. While, in this case, RE doesn\u2019t seem to provide a benefit to EL, it does not affect negatively either. We would have liked to devote more space to such interactions in the main body; however, in its current shape, the paper already contains a vast array of experiments and ablations that we considered more relevant, at least within the main body. We welcome suggestions for additional experiments to explore this interaction further, and we will happily provide results if there\u2019s time during this rebuttal period, or in the final version of the paper otherwise.\nQuestions:\n\"Recent approaches only focus on at most two out of the three properties simultaneously.\" I don't quite understand this sentence. What are the \"three properties\" referring to\uff1f\nIt refers to \u201cSpeed, Flexibility, and Performance.\u201d, which are mentioned in the previous paragraph. We will make it more clear.\n\u201cI recognize the efficiency gains achieved by linking entities and extracting relations in just a single forward pass. Yet, I'm curious about what is the core design that enables the model to achieve state-of-the-art performance?\u201d\nThe inclusion of verbalized labels in the input was crucial\n, enabling not only the efficiency of a single forward pass but also enhancing overall performance. We theorize that the Reader benefits from contextualizing the linking task with all candidates, rather than considering each in isolation, as some previous work did. This approach allows the Reader to leverage both the other candidates as well as the order in which they are given by the Retriever. Our ablation studies in A.4.2 show a performance decline when the Retriever's order is disregarded for the RE task. This drop was even more significant for EL, 85.8 for ReLiK Large, vs. 86.5 F1 reported in Table 2, a 0.7 drop which we will report in the final version of the paper. This indicates the Retriever's dual role in both filtering and ranking, which significantly contributes to ReLiK's effectiveness. Moreover, it is also important to point out that using a verbalized label as part of the input allows the model to be more flexible for unseen entities, as the hidden representations are always contextual, whether seen during training or not, rather than fixed for each entity. We believe this is one of the key reasons of the strong Out-of-domain performance reported in Table 2."}]}]}, "BTKAeLqLMw": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "data selection, instruction tuning, large language models", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We perform a comprehensive study to understand the characteristics of data samples that are the most effective for alignment, and propose automatic data selection approaches that lead to data-efficient instruction tuning", "Abstract": "Instruction tuning is a standard technique employed to align large language models to end tasks and user preferences after the initial pretraining phase. Recent research indicates the critical role of data engineering in instruction tuning -- when appropriately selected, only limited data is necessary to achieve superior performance. However, we still lack a principled understanding of what makes good instruction tuning data for alignment, and how we should select data automatically and effectively. In this work, we delve deeply into automatic data selection strategies for alignment. We start with controlled studies to measure data across three dimensions: complexity, quality, and diversity, along which we examine existing methods and introduce novel techniques for enhanced data measurement. Subsequently, we propose a simple strategy to select data samples based on the measurement. We present Deita (short for Data-Efficient Instruction Tuning for Alignment), a series of models fine-tuned from LLaMA models using data samples automatically selected with our proposed approach.  When assessed through both automatic metrics and human evaluation, Deita performs better or on par with the state-of-the-art open-source alignment models such as Vicuna and WizardLM with only 6K training data samples -- 10x less than the data used in the baselines. We anticipate this work to provide clear guidelines and tools on automatic data selection, aiding researchers and practitioners in achieving data-efficient alignment.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "general machine learning (i.e., none of the above)", "Submission Number": "9349", "PDF Url": "https://openreview.net/pdf?id=BTKAeLqLMw"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9349 by Area Chair wpp7", "Subheading": "Meta ReviewbyArea Chair wpp705 Dec 2023, 08:19 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper study data selection for instruction tuning for LLMs. The proposed algorithm considers (1) complexity of query, (2) quality of the response, (3) diversity among the example set. They measure (1) and (2) for prompting ChatGPT, and (3) is enforced by greedy iterative addition (add only if they are far enough from its nearest example already chosen). They evaluate by fine-tuning Llama-13B model, showing solid gains over baselines. The paper is overall well-written and easy to follow, and the experiments are comprehensive.\nJustification For Why Not Higher Score:\nI am not sure about the impact of this paper, as the motivation is somewhat week. The instruction tuning part is not the most costly part of LLM training, not super convinced why data selection is very important here. It\u2019s not even active learning, as labels are already all provided.\nJustification For Why Not Lower Score:\nThe paper is clearly written and there\u2019s no technical issues with the approach. The experiments are relatively comprehensive, and there's value in understanding what constitutes a good alignment dataset."}, {"Heading": "General Response to Reviewers and Revision Submitted", "Subheading": "Official CommentbyAuthors20 Nov 2023, 14:02 (modified: 23 Nov 2023, 06:38)EveryoneRevisions", "Content": "Comment:\nWe thank all the reviewers for their insightful comments and suggestions. We have revised the paper to address the reviewers\u2019 concerns. Below we summarize the major revisions (the main revisions are marked with\nblue\ntext in the pdf, we also made some minor layout changes to fit the page limit), while we reply to the comments of each reviewer separately.\nThe major revisions are:\nWe added the Open LLM Leaderboard [1] evaluation results (ARC, Hellaswag, MMLU,and TruthfulQA) besides MT-bench and Alpacaeval in the original submission (Reviewer NSy4, zdke).\nWe supplemented more human evaluation details on the inter-annotator consistency (Reviewer NSy4)\nWe added more baselines such as LIMA and Alpagasus (Reviewer zdke).\nWe reported additional strong experimental results of our approach based on LLaMA 2 and Mistral-7B models in addition to LLaMA 1 in the original submission. Such a comprehensive study marks our method as the\nfirst work\non this research line to compete with SOTA SFT models with very limited training data selected automatically.  We hope these results address the concerns on limited evaluation from Reviewer NSy4, zdke, and the method\u2019s contribution/significance over previous work from Reviewer RtKh.\nWe report a simplified version of some of the added results in the table below, and the detailed complete results are in Table 5,6,7 of the paper.\nModel\nData Size\nMT-Bench\nAlpacaEval\nOpen LLM Leaderboard (Avg.)\nOpen-sourced Models based on Mistral-7B\nMistral-7B-Instruct-v0.1\n--\n6.84\n69.65\n60.45\nZephyr-7B-sft\n200K\n5.32\n75.12\n60.93\nRandom-Select\n10K\n5.89\n56.90\n61.72\n$\\text{DEITA}_{10K}$\n10K\n7.29\n80.59\n64.22\nOpen-sourced Models based on LLaMA-2-13B\nVicuna-13B-v1.5\n125K\n6.57\n78.80\n61.63\nRandom-Select\n10K\n5.78\n65.19\n61.32\n$\\text{DEITA}_{10K}$\n10K\n6.79\n81.09\n62.71\nOpen-sourced Models based on LLaMA-1-13B\nLIMA\n1K\n4.29\n41.98\n59.82\nWizardLM-13B\n70K\n6.35\n75.31\n58.96\nVicuna-13B-v1.3\n125K\n6.39\n82.11\n60.01\nRandom-Select\n10K\n6.03\n71.52\n60.14\n$\\text{DEITA}_{10K}$\n10K\n6.60\n78.01\n64.27\n[1] Beeching et al. Open LLM Leaderboard.\nhttps://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n. 2023"}, {"Heading": "Official Review of Submission9349 by Reviewer NSy4", "Subheading": "Official ReviewbyReviewer NSy401 Nov 2023, 17:39 (modified: 30 Nov 2023, 11:57)EveryoneRevisions", "Content": "Summary:\nThis paper presents a data selection algorithm for instruction tuning that selects data points where 1) the queries are complex (e.g.: in terms of the constraints in the request); 2) the responses are high quality (e.g.: helpfulness, creativity); and 3) the data points are diverse. For quantifying complexity and quality, a dataset is collected for each of the two aspects by prompting ChatGPT in the following way: a seed set of samples are taken from the original dataset, ChatGPT is prompted to iteratively improve the complexity or quality of each of those samples along relevant dimensions, ChatGPT is then asked to score these samples for complexity or quality, a separate model (Llama-7B) is trained to predict these scores and then used to score the entire instruction tuning dataset. For diversity, the selected pool (initialized to be empty) is iteratively grown by adding points only if they are beyond a certain distance to their nearest neighbors already in the pool.\nThe data selection procedure sorts the existing dataset by the product of quality and complexity scores, and uses the diversity based selection procedure to select the points from the sorted set to a prespecified size.\nThe algorithm is evaluated by comparing Llama-13B models trained using the data selection procedure against existing instruction tuned models (trained on other datasets), and random selection baselines (trained on the same datasets of the same sizes with points selected randomly). Comparisons are made in terms of AlpacaEval and MT-Bench, where GPT-4 evaluates the responses and human evaluation on a sample of 100 requests from LIMA's test set. The algorithm outperforms random selection, and also other instruction tuned models based on Llama-1 trained on more data.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe procedure used to quantify complexity and quality is innovative and can be used for other hard to quantify aspects of data quality in future work.\nThe results from the experiments clearly show that the proposed method is indeed selecting important data points (i.e., better than random selection) at least for improving performance on AlpacaEval and MT-Bench.\nWeaknesses:\nThe evaluation in this paper is limited and leaves some important questions unanswered:\nThe main evaluation is done in terms of AlpacaEval and MT-Bench alone. Since these are relatively small evaluation sets and it has been shown that GPT-4 evaluation can be biased (Wang et al., 2023;\nhttps://arxiv.org/abs/2306.04751\n), one wonders if the data selection does better than random only because it is aligned with those biases. Including further evaluation, possibly on targeted benchmarks covering abilities like reading comprehension, complex reasoning etc. can be helpful.\nRelated to the above point, since human evaluation was done on only 100 instances, it would be helpful to quantify the reliability of this assessment, e.g.: using inter-annotator agreement scores and significance, and perform a larger scale evaluation if needed.\nThe procedure used for quantifying complexity and quality can be validated and possibly improved further\nSection 2.3 states that ChatGPT is shown multiple samples evolved from the same seed example are shown to ChatGPT at a time for scoring their complexity (and this is possibly true for quality as well). Are these scores comparable across evalved sets from different seed examples? This is necessary because all these data points are used together as training data for training the Llama-based scorer. If they are not comparable, it might help to randomize the sets shown to ChatGPT for scoring.\nRelatedly, it would help to have humans also score data points in terms of complexity and quality and see if the scores correlate with\nChatGPT's judgments.\nQuestions:\nIs it possible for the diversity criterion to end up selecting outliers in the datasets? How can this issue be fixed?\nDo you need to use the representations from the Llama-13B model for computing distances as well? Can you use a different (smaller?) model for computing distances than the one you instruction-tune?\nDEITA-6K loses more to the random selection baseline than to the Vicuna model according to the human evaluation results in Table 4. This seems surprising. How does the random selection model perform compared to the Vicuna model in this case?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response 1/2", "Subheading": "Official CommentbyAuthors20 Nov 2023, 14:07 (modified: 23 Nov 2023, 06:39)EveryoneRevisions", "Content": "Comment:\nThanks for your helpful comments and we are glad that you acknowledged the strengths of our work! Below we will address your concerns point by point:\nQ1: Limited evaluation and more results on target benchmarks\nThanks for the comments. We have added more evaluation results on the Open LLM Leaderboard benchmark [1] that consists of four tasks, ARC, HellaSwag, MMLU, and TruthfulQA.  Additionally, we have enriched our evaluations by training more pre-trained LLMs on our selected data, such as  LLaMA-2-13B and Mistral-7B besides LLaMA-1-13B in the original submission. We have summarized these results in the table of the general response, while the detailed results are in Table 5,6,7 of the paper. On the Open LLM Leaderboard, our approach outperforms the random baseline and other strong SOTA models across three different backbone models in terms of the average results. In the meanwhile, we would like to note that the performance on benchmarks such as MMLU is largely determined by the underlying base model, thus the gains after alignment tuning is typically not large, unless the training data is specifically crafted for the benchmark. This is why recent works on alignment put more emphasis on MT-bench and AlpacaEval [2].\nNotably, on MT-bench and AlpacaEval, our added results show that our method with the LLaMA-2-13B model surpasses Vicuna-13B-1.5 that trains on 10x more data, and LLaMA-2-13B Chat that has undergone extensive RLHF training. With Mistral-7B, our approach attains an MT-bench score of 7.29 with only 10k training data, marking a state-of-the-art performance on MT-bench\nfor all open-source SFT models at 7B and 13B sizes\n. We also observe that, while the gains of the Mistral DEITA model on AlpacaEval are slightly lower than those on MT-bench, a deeper analysis (as depicted in Figure 4) indicates that the Mistral DEITA model excels particularly in mathematical and complex reasoning tasks, areas not primarily covered by AlpacaEval.\nQ2: GPT-4 evaluation bias\nThis is a good point. As the reviewer cited,\nWang et al. 2023\npoints out that win-rate scores given by GPT-4 correlate with length of responses. However, in section 5.4 of their paper, they also admit that human evaluation results largely correlate with the AlpacaFarm and benchmark-based evaluation due to the same trend in the comparisons among their Tulu-65B model and other models. On the other hand, several previous works have demonstrated that GPT4 annotator greatly correlates with human annotator [3, 4] with agreement ranging from 78%~85%. Based on these findings, while we recognize the limitations of GPT-4-based evaluations, we believe that GPT4-based evaluation is still valuable and able to provide useful insights of the models. In our experience, these evaluations often yield more reliable outcomes than those derived from average human annotators.\nQ3: Inter-annotator agreement of human evaluation\nThanks for the advice! We would like to note that we tried hard to control the quality of human evaluation in the original submission \u2013 as described in Appendix D, we adopted MTurk in the beginning but abandoned their annotations due to low agreement scores among them. To justify our human evaluation, we follow LIMA [3] to randomly sample 50 generation pairs from our human evaluation dataset and compute the author-annotator agreement score \u2013 the resulting agreement score is 77%, which is reasonably high and aligns closely with the agreement levels reported in [3]. We have added the inter-annotator agreement score to Appendix D of the paper."}, {"Heading": "Response 2/2", "Subheading": "Official CommentbyAuthors20 Nov 2023, 14:08 (modified: 23 Nov 2023, 06:41)EveryoneRevisions", "Content": "Comment:\nQ4: Are these scores comparable across evolved sets from different seed examples?\nThis is a good point. To answer this question, we conduct human evaluation on randomly selected 50 sample pairs from the ChatGPT complexity score pool \u2013 any example pair is not from the same evolved set. The authors then score each pair of examples from five categories: \u201cA is significantly more complex than B\u201d, \u201cA is slightly more complex than B\u201d, \u201cneither is more complex\u201d, etc. Then we compute the agreement score between the authors and ChatGPT \u2013 first, we transform the ChatGPT scores to pairwise judgment. We count it as \u201csignificantly better/worse\u201d when the difference between ChatGPT scores is larger than 2, \u201cslightly better/worse\u201d for difference of 1, and tie in the case of 0. If ChatGPT has a high agreement score with the authors, that means the ChatGPT scores are comparable across evolved sets.\nIn the \u201csignificantly better/worse\u201d sample pairs, the ChatGPT scores are highly consistent with the authors, producing 83% agreement rate, which means the ChatGPT scores are comparable across evolved sets when the scores are not very close. In the \u201cslightly better/worse\u201d or tie categories, the authors also assign \u201cslightly better/worse\u201d or tie labels to 96% of such samples, suggesting high coarse-grained consistency. However, the fine-grained agreement on the three labels (slightly better/worse, tie) is only 43% \u2013 we find that it is hard even for humans to be consistent on comparing the slightly different complexity of instructions, especially when the two instructions are not relevant.\nWe tried to repeat the above experiments for quality scores as well, but we found that it is really difficult for humans to compare the quality of two responses that correspond to two very different query instructions.\nQ5: Is it possible for the diversity criterion to end up selecting outliers in the datasets? How can this issue be fixed?\nWe agree with the reviewer that the diversity criterion may select outliers in the dataset. . However, we think the outliers may not be always bad \u2013 being diverse and infrequent, the outliers may actually increase the diversity of the selected SFT dataset. Although outliers in a dataset are often considered as low-quality samples, our score-first data selection approach should have filtered out the low-quality samples in the first step.\nQ6: Can you use a different (smaller?) model for computing distances than the one you instruction-tune?\nWe have performed ablation analysis on the embedding model in Appendix C of the original submission. Figure 4 shows that a smaller model, E5-Large-v2 (a SOTA sentence embedding model), is more sensitive to the threshold $\\tau$, and its performance exhibits a significant decline compared to LLaMA..\nQ7: DEITA-6K loses more to the random selection baseline than to the Vicuna model according to the human evaluation\nWe agree that this is a bit surprising, and we think this may be attributed to the simplicity of the LIMA test set, which fails to effectively distinguish between models that generally perform well. It is worth noting that the random baseline is not weak, as it is derived from a SOTA data pool. This situation highlights a broader challenge in human evaluation: for complex queries like those in MT-bench, human evaluation becomes difficult and costly, even for expert annotators, due to the complex examples which often include extensive mathematical and coding content. Conversely, with simpler queries like the LIMA test, human evaluators struggle to differentiate between strong models that excel in simple scenarios. To provide more clarity, we have included a detailed breakdown of the MT-bench results (based on GPT-4 evaluations) in Figure 4 of our paper. This breakdown clearly shows that the random baseline based on Mistral-7B lag significantly in areas such as coding, mathematics, and reasoning, aspects that are less prominent in the LIMA test and challenging for human evaluators to assess.\n[1] Beeching et al. Open LLM Leaderboard.\nhttps://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n. 2023. \n[2] Tunstall et al. Zephyr: Direct Distillation of LM Alignment.\nhttps://arxiv.org/abs/2310.16944\n. 2023.\n[3] Zhou et al. LIMA: Less Is More for Alignment.\nhttps://arxiv.org/abs/2305.11206\n. 2023.\n[4] Zheng et al. Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena.\nhttps://arxiv.org/abs/2306.05685\n. 2023."}, {"Heading": "A Kind Reminder for Reading the Response", "Subheading": "Official CommentbyAuthors22 Nov 2023, 09:09 (modified: 22 Nov 2023, 09:14)EveryoneRevisions", "Content": "Comment:\nDear Reviewer NSy4,\nWe have revised the paper and added many additional results to address your comments. Since the rebuttal period is closing very soon, can you please check the response to see whether it mitigates your concerns? We would greatly appreciate that!\nThank you,\nThe authors"}]}, {"Heading": "Official Review of Submission9349 by Reviewer zdke", "Subheading": "Official ReviewbyReviewer zdke01 Nov 2023, 01:13 (modified: 20 Nov 2023, 21:46)EveryoneRevisions", "Content": "Summary:\nThis work shows that complexity, quality, and diversity are all important for data selection in instruction tuning. Based on the studies, it proposes a score-first, diversity-aware approach called DEITA to select the \u201cgood\u201d data samples. With their proposed learning-based enhanced data measures, DEITA shows better or on par performance with state-of-the-art LLMs with only 6K training samples.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n2 fair\nStrengths:\nThe paper provides in-depth controlled studies to show the proposed scoring measurements are better than baselines in terms of complexity and quality.\nWith fine-tuned LLaMA-7B models on the 20K Alpaca dataset with the scores from GPT, the measurements can score unseen instructions at a cheap cost.\nThe proposed diversity-aware selection method is efficient and easy to implement.\nClear presentation and easy-to-follow writing.\nWeaknesses:\nLimited evaluation\nNo evaluation result on benchmarks like MMLU and Big-Bench-Hard, which allows verification of commonsense knowledge and reasoning with ground-truth answers. GPT4-based evaluation often includes errors or bias, so not enough.\nMarginal performance improvement. In Table 3, DEITA is worse than Vicuna-13B on AlpacaEval dataset. Also, In Table 4 with human evaluation, Vicuna performs almost similar to DEITA.\nLimited baselines; recent instruction selection works including LIMA and Alpagasus are missing in the evaluation.\nQuestions:\nWhy the complexity measurement is obtained from \u201cinstruction\u201d, and the quality measurement is obtained from \u201cresponse\u201d? Is there any intuition of this?\nTypo: \u201clarge margine\u201d should be\u201clarge margin\u201d in the last sentence of the introduction.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response", "Subheading": "Official CommentbyAuthors20 Nov 2023, 14:12 (modified: 20 Nov 2023, 14:44)EveryoneRevisions", "Content": "Comment:\nThanks for your helpful comments! Below we address your concerns.\nQ1: Limited evaluation\nThanks for the comments. We have added more evaluation results on the Open LLM Leaderboard benchmark [1] that consists of four tasks, ARC, HellaSwag, MMLU, and TruthfulQA.  Additionally, we have enriched our evaluations by training more pre-trained LLMs on our selected data, such as  LLaMA-2-13B and Mistral-7B besides LLaMA-1-13B in the original submission. We have summarized these results in the table of the general response, while the detailed results are in Table 3,4,5 of the paper. On the Open LLM Leaderboard, our approach outperforms the random baseline and other strong models across three different backbone models. However, we would like to note that the performance on benchmarks such as MMLU is largely determined by the underlying base model, thus the gains after alignment tuning is typically not large, unless the training data is specifically crafted for the benchmark. This is why recent works on alignment put more emphasis on MT-bench and AlpacaEval [2].\nNotably, on MT-bench and AlpacaEval, our added results show that our method with the LLaMA-2-13B model surpasses Vicuna-13B-1.5 that trains on 10x more data, and LLaMA-2-13B Chat that has undergone extensive RLHF training. With Mistral-7B, our approach attains an MT-bench score of 7.29 with only 10k training data, marking a state-of-the-art performance on MT-bench\nfor all open-source SFT models at 7B and 13B sizes\n. We also observe that, while the gains of the Mistral DEITA model on AlpacaEval are slightly lower than those on MT-bench, a deeper analysis (as depicted in Figure 2) indicates that the Mistral DEITA model excels particularly in mathematical and complex reasoning tasks, areas not primarily covered by AlpacaEval.\nQ2: Marginal performance improvement. DEITA is worse than Vicuna-13B on AlpacaEval dataset. With human evaluation, Vicuna performs almost similar to DEITA.\nWe emphasize that the purpose of this work is not to set up a new record on the performance, but to achieve top results with much less data, for example, the training of DEITA is far more efficient than Vicuna by using 10x less training data. Furthermore, we note that Vicuna is a SOTA SFT model, and DEITA outperforms it on most of the cases across three different benchmarks and various backbone models (see the table in General Response), except for just one setting on AlpacaEval \u2013\nDEITA is the first automatic data selection approach that achieves comparable performance to SOTA models such as Vicuna and WizardLM with 10x less data\n. Therefore, we view comparable performance to Vicuna as the strength of our approach, rather than weaknesses.\nQ3: Missing comparison with instruction selection works\nThanks for the suggestion! In the original submission,  we have shown that \u201cdirect scoring\u201d from Alpagasus [3] does not work well in Table 2 and 3, and using ChatGPT to score all the samples in the data pool following their paper is too expensive, thus we did not explicitly include them in the main tables. Following the reviewer\u2019s advice, we have added the Alpagasus and LIMA baselines, the comparison of different instruction selection approaches is shown below (based on LLaMA-1-13B):\nModel\nData Size\nMT-Bench\nAlpacaEval(%)\nRandom\n6K\n5.84\n73.91\nAlpagasus\n6K\n5.61\n71.21\nLIMA\n1K\n4.29\n41.98\n$\\text{TagLM}$\n6K\n6.09\n72.80\n$\\text{DEITA}_{6K}$\n6K\n6.46\n77.08\nWe see that DEITA outperforms other instruction selection baselines significantly. We have included the table above as Table 5 in the paper.\nQ4: Why the complexity measurement is obtained from \u201cinstruction\u201d, and the quality measurement is obtained from \u201cresponse\u201d?\nWe measure complexity from instruction only since the evolution procedure of complexity directly follows WizardLM, which takes only the instruction as input and evolves it step by step to increase the instruction complexity.  For quality, our intuition is to measure how effectively a response addresses the query, thus both the instruction and the response are inputs to the scorer. We recognize that in Figure 1, the instruction input was inadvertently omitted in the depiction of the quality scorer. This was our oversight, we have slightly revised Figure 1 to be more clear on this.\n[1] Beeching et al. Open LLM Leaderboard.\nhttps://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n. 2023.\n[2] Tunstall et al. Zephyr: Direct Distillation of LM Alignment.\nhttps://arxiv.org/abs/2310.16944\n. 2023"}, {"Heading": "Rebuttal response", "Subheading": "Official CommentbyReviewer zdke20 Nov 2023, 21:46Everyone", "Content": "Comment:\nThanks to the comprehensive rebuttal. The authors addressed most of my concerns with more results on Open LLM Leaderboard. I will increase my score to 6."}]}, {"Heading": "Official Review of Submission9349 by Reviewer RtKh", "Subheading": "Official ReviewbyReviewer RtKh28 Oct 2023, 16:34 (modified: 22 Nov 2023, 22:26)EveryoneRevisions", "Content": "Summary:\nThis paper investigates the trendy problem of selecting high-quality instructions for fine-tuning pre-trained language models (PLMs). The paper aims to provide an automated pipeline for this selection problem. Following recent works, sample quality is evaluated on three dimensions: complexity, quality, and diversity where this evaluation is conducted by other LMs such as GPT-4. The paper validates the proposed approach with LLaMA-1 and shows that when selecting samples from a larger pool of lower-quality data, the proposed method, DEITA (Data-Efficient Instruction Tuning for Alignment), is able to match the performance of current open-source alignment models with a small fraction of fine-tuning data.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper is, in general, an easy read. Its ideas are presented straightforwardly along with nice tables and illustrations.\nThe problem it investigates is trendy. Quality for each part of the work is generally fine\u2013it is structurally complete, self-contained, and has a reasonable narrative.\nWeaknesses:\nThis paper is \"ok\" but not particularly enticing. The topic is trendy but the approach is not technically challenging or particularly innovative.\nI have recently read a number of papers on this topic of instruction mining with LLaMA/Alpaca\u2013to name a few\na. ALPAGASUS : TRAINING A BETTER ALPACA WITH FEWER DATA\nb. Instruction Mining: High-Quality Instruction Data Selection for Large Language Models\nc. InstructionGPT-4: A 200-Instruction Paradigm for Fine-Tuning MiniGPT-4\nThe technical body of these papers are uncomfortably similar. Combining a number of existing metrics (often in trivial ways) such as quality, diversity, etc. as a new evaluation metric and conducting the evaluations largely with the help of GPTs. And the end goals are also the same\u2013to achieve comparable or better performance with fewer samples. I'm not sure how much \"research gap\" remains there and how individual works may continue to contribute to that\u2013at least, this concern is still not resolved by this paper.\nIn terms of quality, the construction of this paper is simple. It does not have many ablation studies or insightful discussions of design choices/novel findings. No additional results or further discussions are provided in the Appendix.\nIt is an \"okay\" paper without much particular. Given its position in this apparently overly populated track, I would not be very interested in seeing it at the conference and vote against publishing it.\nReproducibility: Code, data, model checkpoints, or data selection tools are not provided during the reviewing phase.\nFormat: Appendix is not cut from the main paper. The PDF provided for the main paper is this 20-page document.\nQuestions:\nIf the authors wish to further develop this work toward publication at a future venue, I suggest the authors to\nspend significant effort in discussing the current research landscape and identify a valid (important and essential) research gap that this work will make a substantial and unique contribution to. This is my main concern for this line of work.\nimprove the quality of the paper. If its extent of innovation is capped by the many other papers out there,  this work needs to have a high quality to be a valid contribution. This includes conducting more experiments and ablation studies and discussing design choices and novel findings.\nimprove the technical approach. The current methods documented in this paper do not seem particularly novel compared to existing works and its technical contributions seem capped by the heavy reliance on GPTs. If the authors could design original technical approaches (new metrics, new evaluation methods, novel ways for combining different metrics), the paper could be made much more attractive.\nAppendix should not be submitted under the main paper.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response 1/2", "Subheading": "Official CommentbyAuthors20 Nov 2023, 14:13 (modified: 22 Nov 2023, 10:03)EveryoneRevisions", "Content": "Comment:\nThank you for the time and comments, we have enriched our evaluation with additional strong results on more benchmarks with different backbone models, please refer to the General Response for details. We address your separate concerns below.\nQ1: How much \u201cresearch gap\u201d remains in instruction mining or SFT data selection? What is the research gap that this work contributes to?\nWe respectfully disagree with the reviewer on these comments about this research line in general, as well as our work\u2019s contribution and significance. While we have no doubt that the reviewer understands these \u201csimple\u201d methods from previous works and our study, we believe there may be an oversight from the reviewer regarding the overall progress and current state of this research direction.\nTo provide context, we would like to briefly summarize recent advancements in SFT data selection, which will illustrate the \"research gap\" and the broader picture. Initial studies like Self-instruct [1] and Alpaca [2] showed that medium-sized datasets (ranging from 50k to 100k samples) could endow pretrained models with effective instruction-following capabilities, though Alpaca was later identified as a weak baseline upon more rigorous evaluations. LIMA [3] highlighted the significance of data selection in SFT by using just 1,000 carefully chosen or human-crafted samples to surpass Alpaca's performance. However, these samples were not selected automatically.\nAlpagasus [4] and Instruction Mining [5], as the reviewer mentioned, began exploring automatic data selection in SFT. Yet, their comparisons were limited to random baselines or the already weak model Alpaca at the time. They did not conduct standard evaluations on challenging benchmarks like MT-bench/AlpacaEval nor did they compete with strong models such as Vicuna and WizardLM. This indicates a clear gap:\nno study in automatic data selection has demonstrated practical effectiveness through evaluations on challenging benchmarks and against SOTA open-source SFT models -- we do not know whether [4] and [5] really work or not from their weak evaluations\n. This gap is significant as it leaves unanswered questions about the potential and practicality of automatic data selection and whether it can lead to SOTA open-source SFT models.\nWe note that [4] and [5] have updated their papers with more evaluations and baselines\nafter\nthe ICLR submission deadline, which we hope the reviewer realizes. However, even in their latest versions, [4] does not compare with any other state-of-the-art open-source SFT model. Our approach has significantly outperformed it (as shown in Table 5 of our paper). Meanwhile, [5] does not report standard MT-bench and AlpacaEval scores.\nQ2: Our contribution and significance over previous/recent works on instruction mining.\nFollowing the response above, our research stands out as the\nfirst\nto propose an automatic data selection approach that consistently demonstrates strong performance across multiple challenging benchmarks, including MT-bench, AlpacaEval, and the Open LLM Leaderboard. Our approach outperforms other data selection methods by a large margin (Table 5), yielding results that are comparable to, or even surpass, those of SOTA open-source SFT models such as Vicuna, WizardLM, and Mistral-Instruct. These empirical results \u2013 being the first to achieve SOTA open-source performance with 10x less data selected automatically \u2013  is particularly noteworthy because it suggests that our approach, the datasets selected, and the data selection tools we have developed can be practically and beneficially applied by a broad spectrum of researchers and practitioners.\nIn terms of technical innovation, our approach diverges from previous methodologies. We utilize an evolving strategy to elicit more faithful complexity and quality scores from ChatGPT, as opposed to a direct scoring method, which our results (shown in Tables 2 and 3) indicate is less effective. While we recognize that the combination of metrics and reliance on GPT models are not novel, we have no reason to complicate things when we find such simple or trivial combinations of our proposed metrics are highly effective. Methodologically, exploring alternatives to GPT reliance is an intriguing future direction, yet it was not deemed essential for the current scope of this paper, particularly given that our data selection tool does not require ChatGPT at the inference stage.\nFurthermore, we would like to remind the reviewer that both Alpagasus and InstructionMining were first arxived within 3 months prior to the ICLR submission deadline. According to the ICLR official reviewer guide (\nhttps://iclr.cc/Conferences/2024/ReviewerGuide#Reviewing%20instructions\n), such works are regarded as concurrent. While we still believe our work represents significant advancements beyond these studies as described above, we urge the reviewer to consider this timing factor as well when evaluating our research."}, {"Heading": "Response 2/2", "Subheading": "Official CommentbyAuthors20 Nov 2023, 14:20 (modified: 20 Nov 2023, 14:20)EveryoneRevisions", "Content": "Comment:\nQ3: Reproducibility: Code, data, model checkpoints, or data selection tools are not provided during the reviewing phase.\nWe have promised to release these resources after the review period in the footnote of the first page, we surely will do when we deanonymize this paper \u2013 it is not common practice to release model checkpoints in an anonymous way during the review period as far as we know.\nQ4: Appendix is not cut from the main paper. Appendix should not be submitted under the main paper.\nAuthors may use as many pages of appendices (\nafter the bibliography\n) as they wish\nquoted from ICLR 2024 Call for Papers (\nhttps://iclr.cc/Conferences/2024/CallForPapers\n).\nQ: Should the appendices be added as a separate PDF or in the same PDF as the main paper?\nEither is allowed: you can include the appendices at the end of the main pdf after the references, or you can include it as a separate file for the supplementary materials.\nquoted from ICLR 2024 Author Guide (\nhttps://iclr.cc/Conferences/2024/AuthorGuide\n)\n[1] Wang et al. Self-Instruct: Aligning Language Models with Self-Generated Instructions.\nhttps://aclanthology.org/2023.acl-long.754.pdf\nACL 2023.\n[2] Taori et al. Stanford Alpaca: An Instruction-following LLaMA model.\nhttps://crfm.stanford.edu/2023/03/13/alpaca.html\n2023.\n[3] Zhou et al. LIMA: Less Is More for Alignment.\nhttps://arxiv.org/abs/2305.11206\n. 2023.\n[4] Chen et al. AlpaGasus: Training A Better Alpaca with Fewer Data.\nhttps://arxiv.org/abs/2307.08701\n. 2023.\n[5] Cao et al. Instruction Mining: When Data Mining Meets Large Language Model Finetuning.\nhttps://arxiv.org/pdf/2307.06290.pdf\n2023."}, {"Heading": "A Kind Reminder for Reading the Response", "Subheading": "Official CommentbyAuthors22 Nov 2023, 09:15Everyone", "Content": "Comment:\nDear Reviewer RtKh,\nWe have revised the paper and included additional strong results on more benchmarks. In the response above, we have also tried to clarify progresses on this research direction and our contributions over previous (concurrent) works. Since the rebuttal period is closing very soon, could you please check our response to see whether it mitigates your concerns? We would greatly appreciate that!\nThank you,\nThe authors"}, {"Heading": "Official Comment by Reviewer RtKh", "Subheading": "Official CommentbyReviewer RtKh22 Nov 2023, 22:25Everyone", "Content": "Comment:\nThanks to the authors for the careful response. The explanations and additional results definitely helped to better contextualize this work. I can understand the challenge of working on a trending topic with new results coming out all the time. From the author's explanation, the performance achieved by this work is at the frontier.\nThe part of my review remains that I do not see a clear technical contribution offered by this work, at least not a principled framework. I am not very familiar with the state-of-the-art performance for instruction tuning so I will have to leave the evaluation of this part to other reviewers and the AC.\nThus, I am not passionately against the publication of the work or passionately supporting it. I would raise my score to 5 while decreasing my confidence to 2."}]}]}, "AJBkfwXh3u": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Dynamic Graph, Graph Explanation, Graph Neural Network, Causal Inference", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "To the best of our knowledge, we are the first to explain dynamic graph neural networks.", "Abstract": "Dynamic Graph Neural Networks (DyGNNs) have gained significant popularity in the research of dynamic graphs, but are limited by the low transparency, such that human-understandable insights can hardly be drawn from their predictions. Although a number of existing research have been devoted to investigating the interpretability of graph neural networks (GNNs), achieving the interpretability of DyGNNs is pivotally challenging due to the complex spatial-temporal correlations in dynamic graphs. To this end, we propose an innovative causality-inspired generative model based on structural causal model (SCM), which explores the underlying philosophies of DyGNN predictions by identifying the trivial, static, and dynamic causal relationships. To reach this goal, two critical tasks need to be accomplished including (1) disentangling the complex causal relationships, and (2) fitting the spatial-temporal explanations of DyGNNs in the SCM architecture. To tackle these challenges, the proposed method incorporates a contrastive learning module to disentangle trivial and causal relationships, and a dynamic correlating module to disentangle dynamic and static causal relationships, respectively. A dynamic VGAE-based framework is further developed, which generates causal-and-dynamic masks for spatial interpretability, and recognizes dynamic relationships along the time horizon through causal invention for temporal interpretability. Comprehensive experiments have been conducted on both synthetic and real-world datasets, where our approach yields substantial improvements, thereby demonstrating significant superiority.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "learning on graphs and other geometries & topologies", "Submission Number": "9348", "PDF Url": "https://openreview.net/pdf?id=AJBkfwXh3u"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9348 by Area Chair qM9T", "Subheading": "Meta ReviewbyArea Chair qM9T05 Dec 2023, 20:16 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper presents a causal approach to improving the interpretability of Graph Neural Networks (GNNs). It leverages a contrastive learning module that distinguishes between non-causal (static and trivial) and causal relationships. The model also captures dynamic relationships across temporal scales through causal inference, thus enhancing its ability to interpret temporal data.\nWhile reviewers agree that the methodology is novel, they raise concerns regarding the validation pipeline, which seems to focus primarily on static graphs. Although the authors hand-crafted a synthetic dataset, it failed to alleviate these concerns for some reviewers. Additionally, concerns remain about whether the methods adequately address the core interpretability challenges of dynamic GNNs (DyGNNs).\nIn a nutshell, the method is novel and the results are compelling in both synthetic and real-world, albeit mostly static, datasets, which heavily nuance the results. I would recommend to accept.\nJustification For Why Not Higher Score:\nThe reviewers comment that most of the benchmarks are in static datasets, so it is not clear how the method would actually behave in dynamical graphs.\nJustification For Why Not Lower Score:\nThe framework it is interesting and novel. The results are compelling in static graphs."}, {"Heading": "General response", "Subheading": "Official CommentbyAuthors22 Nov 2023, 14:54Everyone", "Content": "Comment:\nWe thank all reviewers for their insightful comments and suggestions. We are particularly encouraged by the reviewers\u2019 feedback. We have made a heavy revision to our paper according to the reviewer's constructive suggestions. Below we summarize some key modifications in this revision:\nDerivation process of backdoor adjustment in Equation 1in Appendix A.4 (Reviewer #1, Reviewer #4)\nComplexity descriptions of dynamic VGAE in Appendix A.4 (Reviewer #1)\nLoss function hyperparameters in Appendix A.2 (Reviewer #1, Reviewer #3)\nDataset and baseline selection in Section 3.1 (Reviewer #1, Reviewer #3, Reviewer #4)\nMore related works in Section 4 and Appendix 4.3 (Reviewer #1)\nClearer explanation and presentation\nAblation study in Section 3.2 (Reviewer #1)\nText in Figure 1 (Reviewer #2)\nMotivations and solutions in Section 1 (Reviewer #3, Reviewer #4)\nGraph interpretability task in Section 2.1 (Reviewer #4)\nImplementation of Equation 7 (Reviewer #4)\nMoreover, we have carefully checked our paper typos and reorganized the presentation. If there still remains any consideration, please kindly let us know. We are very happy to make a further revision in light of your great suggestions. We will address comments by each of the reviewers individually."}, {"Heading": "Official Review of Submission9348 by Reviewer 8sLV", "Subheading": "Official ReviewbyReviewer 8sLV05 Nov 2023, 23:26 (modified: 22 Nov 2023, 22:50)EveryoneRevisions", "Content": "Summary:\nThis paper presents a causal approach to improving the interpretability of GNNs. The authors have integrated a contrastive learning module that distinguishes between non-causal and causal relationships, enhancing the clarity of the model's decision-making process. Additionally, a dynamic correlating component is employed to differentiate dynamic from static causal relationships, providing a nuanced understanding of changes over time. Furthermore, the authors utilize a VGAE-based model to generate causal-and-dynamic masks, which contribute to spatial interpretability. This model also captures dynamic relationships across temporal scales through causal inference, thereby boosting the model's ability to interpret temporal data.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\n(1) The composition and articulation of the paper are logical and coherent. The use of a causality-driven approach to enhance the out-of-distribution generalization capabilities of dynamic GNNs is intriguing.\n(2) Introducing research on temporal distribution shift in sequential processes is important and may provide valuable insights for subsequent studies.\nWeaknesses:\n(1) The paper's presentation appears problematic, particularly in the description of the backdoor adjustment. While simplified results are provided in the main text, the specific derivation process is absent and should be relegated to the appendix. Additionally, the computational intensity of introducing temporal masks, which could be exacerbated by the incorporation of contrastive learning (VGAE is known to be computationally demanding), is not addressed. The authors should include complexity descriptions to inform the reader. However, these issues are not discussed in the paper.\n(2) The proposal of 4 loss functions can be unfriendly to network training. If even one parameter is improperly tuned, it could lead to significant instability or even failure in network training. The authors should systematically discuss parameter selection techniques or guidelines to aid those who follow in this line of work.\n(3) There is a lack of related experiments: although experiments are conducted, there is a shortage of benchmarks in this field. It is recommended that the authors refer to [1] to add more experiments to validate the effectiveness of their DyGNN, such as including the Ogbn-Arxiv dataset. Additionally, an ablation study replacing VGAE-like models is crucial to help others understand the contribution of each model component.\n(4) Related work is missing from the paper, especially concerning spatio-temporal related work [5], generalization/extrapolation on graphs, and causality learning [2-4]. The authors should consider these areas to provide a more comprehensive context for their research.\n[2] Sui, Yongduo, et al. \"Causal attention for interpretable and generalizable graph classification.\" Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2022.\n[3] Wu, Ying-Xin, et al. \"Discovering invariant rationales for graph neural networks.\" arXiv preprint arXiv:2201.12872 (2022).\n[4] Miao, Siqi, Mia Liu, and Pan Li. \"Interpretable and generalizable graph learning via stochastic attention mechanism.\" International Conference on Machine Learning. PMLR, 2022.\n[5] Xia, Yutong, et al. \"Deciphering Spatio-Temporal Graph Forecasting: A Causal Lens and Treatment.\" arXiv preprint arXiv:2309.13378 (2023).\nQuestions:\nSee weakness\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Feedback to Reviewer #8sLV", "Subheading": "Official CommentbyAuthors22 Nov 2023, 14:31Everyone", "Content": "Comment:\nWe appreciate your overall positive assessment of our contributions and are grateful for your suggestion. We have already updated the new revision based on your suggestions.\nQ1: Derivation process and complexity descriptions\nA1:\nIn Equation 1, we merge the estimation of $P(\\mathcal{Y}|do(\\mathcal{C}))$ with that of $P(\\mathcal{Y}|do(\\mathcal{D}))$. The detailed derivation process of backdoor adjustment can be shown as:\n$$\nP(\\mathcal{Y}|do(\\mathcal{D})) = \\sum P(\\mathcal{Y}|do(\\mathcal{D}), \\mathcal{S})P(\\mathcal{S}|do(\\mathcal{D})) \\\n= \\sum P(\\mathcal{Y}|do(\\mathcal{C}))P(\\mathcal{S})\\\n= \\sum P(\\mathcal{S})\\sum P(\\mathcal{Y}|do(\\mathcal{C}),\\mathcal{T})P(\\mathcal{T}|do(\\mathcal{C})\\\n= \\sum P(\\mathcal{S})\\sum P(\\mathcal{Y}|\\mathcal{G})P(\\mathcal{T}).\n$$\nVGAE-based encoder is the most time consuming component in our method. In the dynamic VGAE-based encoder, we generate the causal soft mask matrix  $\\mathbf{M}^{\\mathcal{C}}$ and the dynamic soft mask matric $\\mathbf{M}^{\\mathcal{D}}$ with $O(d*|V|^2)$ complexity for T unique time steps, where d is the embedding size. The contrastive learning part also costs lots of time and has time complexity O(|V|\nd\n$T^2$). Then, the total time complexity is O($|V|^2$\nd\nT + |V|\nd\n$T^2$). Note that $T << |V|$, then we can ignore the time of contrastive learning and obtain the total time complexity as O(|V|^2\nd\nT).\nWe add this in Appendix A.4  in the new version.\nQ2: Loss function hyperparameters\nA2:\nThank you for your valuable suggestions. In graph interpretation tasks, they usually have many constraints and require different types of loss functions to satisfy these constraints, e.g., OrphicX has 4 loss functions for the static graph interpretation. We supplement the parameter search range and optimal parameter selection of the four constraints of the loss function to help improve the reliability and reproducibility of the results.\nIn the final optimization objects, the loss function weight parameters $\\lambda_1$, $\\lambda_2$, $\\lambda_3$, and $\\lambda_4$ are set from [0.2, 0.4, 0.6, 0.8, 1]. And the best performance is obtained where $\\lambda_1=1$, $\\lambda_2=0.4$, $\\lambda_3=0.2$, and $\\lambda_4=0.2$. We add this in Appendix A.2.\nOnce again, I extend my gratitude for your invaluable suggestions. It remains our primary objective to deliver trustworthy interpretive results.\nQ3: Shortage of benchmarks and ablation study\nA3:\nThank you for your valuable questions. Although there have been some works on static graph interpretability, to the best of our knowledge, we are the first to study dynamic graph interpretability. Therefore, we have no existing dynamic graph interpretability benchmarks for comparison, and can only compare with currently competitive static interpretability methods.\nOn the other hand, you recommend some benchmarks for graph representation and graph generalization. But it is hard to compare our method with them since the task in our model is totally different from theirs. Graph representation and graph generalization models are the target models we want to explain. For interpretable methods, the target model is model-agnostic. The interpretability task is to provide good explanations for these models. We make this more clear in Section 3.1.\nGiven the novelty of our study on dynamic graph interpretability, there is a dearth of readily available synthetic datasets suitable for this purpose. Consequently, we've undertaken dynamic transformations of commonly used synthetic static graph interpretability datasets such as BA-Shapes. We also use two real-world dynamic graph datasets, Elliptic for node classification and MemeTracker for graph classification. The Ogbn-Arxiv dataset is a real-world data set but a static graph dataset. If we dynamically transform it, it will lose its real meaning. We make this more clear in Section 3.1.\nFor ablation study, we provide a DyGNNExplainer version without VGAE ('w/o. VGAE'). In this version, we replace the encoder with a simple GCN layer. DyGNNExplainer outperforms the `w/o. VGAE' version. This is primarily due to the superior capabilities of VGAE in harnessing spatial graph information to generate soft masks. We provide this ablation study in Section 3.2.\nQ4: Related work\nA4:\nThank you for your valuable suggestions. Although our interpretability task is totally different from the graph generalization task, their method is the model we want to explain and is helpful in our work. Additionally, the spatial-temporal method and the causal method are directly related to our tasks. We add these related works in Section 4 and Appendix 4.3.\nThank you again for your constructive reviews. Hope that our response can address your concerns. We will feel grateful if you could boost our paper."}, {"Heading": "Official Comment by Reviewer 8sLV", "Subheading": "Official CommentbyReviewer 8sLV22 Nov 2023, 22:49Everyone", "Content": "Comment:\nSorry for the late reply. Thank you for the detailed response from the author; the major concern has already been addressed. I will raise my score to acceptance, I believe that with the added content, this work has become clearer and more coherent, especially the comparative analysis of related work, which has resolved my questions effectively."}]}, {"Heading": "Official Review of Submission9348 by Reviewer U7py", "Subheading": "Official ReviewbyReviewer U7py03 Nov 2023, 01:28 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a novel approach for interpretability in dynamic graph neural networks. The proposed framework is demonstrated on both synthetic and real-world datasets. The experimental results show that the proposed method outperforms the baselines (all baselines are for explaining static graph neural networks). Another contribution is that the paper constructs a new synthetic benchmark dataset for dynamic graph interpretability tasks.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe proposed framework is the first work for interpretability in dynamic graph neural networks. This is a significant contribution. The paper is well organized and clearly described. The method is technically sound. The experiments are comprehensive and the results show the effectiveness of the proposed method. The new constructed benchmark dataset is a good addition to the research domain.\nWeaknesses:\nMinors: \nIn Figure 1, the text is too small.\nQuestions:\nIn table 2, the best performance for OrphicX is obtained by DTree-Grid?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Feedback to Reviewer # U7py", "Subheading": "Official CommentbyAuthors22 Nov 2023, 14:32Everyone", "Content": "Comment:\nWe appreciate your overall positive assessment of our contributions and are grateful for your suggestion. We have already updated the new revision based on your suggestions.\nQ1: Text in Figure 1\nW2:\nWe have enlarged the text in Figure 1in the new version.\nQ2: Typo in Table 2\nW2:\nWe are sorry that one of the data in Table 2 was filled in incorrectly. The best performance in DTree-Grid is obtained by DyGNNExplainer. We have corrected the typo in Table 2 in the revision.\nThank you again for your constructive reviews. Hope that our response can address your concerns. We feel grateful for your appreciation."}]}, {"Heading": "Official Review of Submission9348 by Reviewer fzQP", "Subheading": "Official ReviewbyReviewer fzQP31 Oct 2023, 19:14 (modified: 04 Dec 2023, 00:52)EveryoneRevisions", "Content": "Summary:\nThis paper proposed a causality-inspired generative model to explain DyGNN predictions by identifying the trivial, static, and dynamic causal relationships. To experimentally evaluate the proposed approach, synthetic dynamic datasets are generated and provided. Evaluations on both synthetic datasets and real-world datasets demonstrate superior performance.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nOriginality: this paper is aimed at explaining dynamic graphs by proposing a causal inspired framework. Existing works on the explanation of GNNs are on static graphs. This paper instead focuses on dynamic graphs. Disentangling spatial and temporal relationships can be very challenging. This paper explicitly constructs a structural causal model by considering trivial relationships and causal relationships (consisting of static relationships and dynamic relationships) to solve this problem, which is interesting.\nWeaknesses:\nThe presentation can be improved. It is hard for me to follow the paper well. For example, in the Introduction section, it is hard to straightforwardly understand the spatial interpretability and temporal interpretability. Illustrations can help readers understand better. Besides, it is not easy for me to understand the challenges for implementing the SCM (third paragraph in the Intro). Correspondingly, I didn\u2019t see how the proposed approach addresses the challenges in the fourth paragraph.\nThe significance of the proposed approach is not clear. It is hard to judge the performance improvement achieved by DyGNNExplainer since other baselines are all for static graphs.\nQuestions:\nIn Table 2, for Node classification task, OrphicX performs better than DyGNNExplainer on DTree-Grid dataset but is not bolded?\nCan you compare your model on static graphs to state-of-the-art explainers?\nHow sensitive the model is to the hyper parameters in Equation 15? What\u2019s the computational complexity of solving Equation 15?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nThe link to the code and the dataset benchmark of this submission is\nnot anonymized\n.\nPost-rebuttal: this concern is addressed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Feedback to Reviewer # fzQP", "Subheading": "Official CommentbyAuthors22 Nov 2023, 14:45 (modified: 22 Nov 2023, 14:49)EveryoneRevisions", "Content": "Comment:\nWe appreciate your overall positive assessment of our contributions and are grateful for your suggestion. We have already updated the new revision based on your suggestions.\nQ1: Problems in introduction section\nW2:\nThanks for your valuable questions and suggestions.\nSpatial interpretability and temporal interpretability:\nThe investigation of spatial interpretability critically relies on the extraction of subgraphs that can represent the characteristics of the complete graph in spatial dimension and elucidate outcomes in subsequent tasks. In essence, these subgraphs serve as substitutes for the original graphs, enabling the attainment of analogous results in downstream tasks.\nTemporal interpretability relies on the importance of representative sub-graphs over the time slots. In essence, it's essential to elucidate the significance of each time step concerning its impact on the outcomes of subsequent tasks. We add this in Section 1.\nChallenges for implementing the SCM:\nThe first challenge lies in the approach to disentangling the complex causal relationships as no explicit information is available for the identification of trivial, dynamic, and static relationships. The dynamic graph encapsulates intricate spatial-temporal relationships and dependencies, posing a challenge in directly conducting interventions on the confounder. This makes decoupling the trivial, dynamic, and static relationships very difficult.\nThe second challenge is the way to construct the SCM to fit the task of discovering spatial-temporal interpretability due to the lack of existing models for dynamic graphs. As pioneers in the realm of dynamic graph interpretability, we encounter the challenge of lacking a causal model that can offer interpretive insights into intricate spatial-temporal relationships.\nHow the proposed approach addresses the challenges:\nWe propose two constraints to disentangle the trivial relationship, the static relationship, and the dynamic relationship, respectively.\nFirst, to disentangle the trivial relationship and the causal relationship, we propose that the causal relationship determines the downstream task results. Thus, we propose a contrastive learning module to ensure the semantic similarity between the causal relationship and the original graph while enlarging the semantic distance between the causal relationship and the trivial relationship.\nSecond, to disentangle the static relationship and the dynamic relationship, we propose that dynamic relationships evolve over time steps but static relationships are independent across each time step. Consequently, we leverage the pre-trained target DyGNN model to guarantee the essential temporal correlation between neighboring subgraphs for the dynamic relationships and identify the rest independent causal information to the static relationships.\nThank you again for your questions. It is also our goal to clean up our motivations and solutions. We aspire that through our explanations, you gain a more clear understanding of our work.\nQ2: Static datasets\nW2:\nSince our method is the first study on dynamic graph interpretability, there are no directly available datasets suitable for the task of dynamic graph interpretability. So we dynamically transformed some commonly used static graph interpretability datasets. We add this in Section 3.1 in the revision.\nQ3: Baselines\nW3:\nSince our method is the first study on dynamic graph interpretability, we can only utilize the baselines from static graph interpretability tasks. To achieve a relatively fair comparison, we add the time factor into baselines so as to make them suitable for dynamic graph interpretability. Dynamic graphs are much more complex than static graphs due to their spatial-temporal correlations. It is meaningless if we compare our method with baselines on static graphs.\nQ4: Typo in Table 2\nW4:\nWe are sorry that one of the data in Table 2 was filled in incorrectly. The best performance in DTree-Grid is obtained by DyGNNExplainer. We have corrected the typo in Table 2 in the revision."}, {"Heading": "Feedback to Reviewer # fzQP", "Subheading": "Official CommentbyAuthors22 Nov 2023, 14:45Everyone", "Content": "Comment:\nQ5: Hyperparameters and computational complexity in Equation 15\nW5:\nThanks for your suggestions. We supplement the parameter search range and optimal parameter selection of the four constraints of the loss function to help improve the reliability and reproducibility of the results.\nIn the final optimization objects, the loss function weight parameters $\\lambda_1$, $\\lambda_2$, $\\lambda_3$, and $\\lambda_4$ are set from [0.2, 0.4, 0.6, 0.8, 1]. And the best performance is obtained where $\\lambda_1=1$, $\\lambda_2=0.4$, $\\lambda_3=0.2$, and $\\lambda_4=0.2$. We add this in Appendix A.2.\nVGAE-based encoder is the most time consuming component in our method. In the dynamic VGAE-based encoder, we generate the causal soft mask matrix $\\mathbf{M}^{\\mathcal{C}}$ and the dynamic soft mask matric $\\mathbf{M}^{\\mathcal{D}}$ with $O(d*|V|^2)$ complexity for T unique time steps, where d is the embedding size. The contrastive learning part also costs lots of time and has time complexity O($|V|$\n$d$\n$T^2$). Then, the total time complexity is O($|V|^2$\n$d$\n$T$ + $|V|$\n$d$\n$T^2$). Note that $T << |V|$, then we can ignore the time of contrastive learning and obtain the total time complexity as O($|V|^2$\n$d$\n$T$).\nQ6: Codebase link\nW6:\nSo sorry we attached the wrong code link. The wrong code link is unrelated to this paper and does not include any information about authors. We have updated the correct anonymous code link in the new version.\nThank you again for your constructive reviews. Hope that our response can address your concerns. We will feel grateful if you could boost our paper."}]}, {"Heading": "Official Review of Submission9348 by Reviewer JCbW", "Subheading": "Official ReviewbyReviewer JCbW26 Oct 2023, 07:24 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work aims at interpreting the Dynamic Graph Neural Networks (DyGNNs), and proposes an innovative causality-inspired\ngenerative framework based on structural causal model (SCM), which explores the underlying philosophies of DyGNN predictions by identifying the trivial, static, and dynamic causal relationships. This work actually identifies the subgraph via a masking mechanism.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nS1. The research motivation of this paper is clear. The existing studies on the interpretability of Dynamic Graph Neural Networks are still limited, thus it is meaningful to bridge such gap.\nS2. The description of the existing challenges to the interpretability of DyGNNs is interesting. The authors argue that the first challenge lies in the approach to disentangling the complex causal relationships as no explicit information is available for the identification of trivial, dynamic, and static relationships.\nWeaknesses:\nW1. I'm confused about this sentence, 'Hence, our ultimate objective is to define a generative model', in Section 2.1. Throughout the whole paper, DyGNNExplainer is a representational model.\nW2. Equation 1 should be described in detail. Since causal relationships ($C$) consist of dynamic ($D$) and static ($S$) relationships, there should exist $P(S) = P(C) - P(D)$. I guess this equation is derived from it, but I can't see the logical derivation.\nW3. This paper still has not well addressed the interpretability issue of DyGNNs. The authors only provide evidence in performance improvements and static interpretability ('house' motif in BA-Shapes). We can not observe specific causal relationships in dynamic graphs from provided results. Besides, the baselines are interpretability methods conducted on static graphs, and the datasets are not classic dynamic graph datasets, such as traffic and citation network datasets. Thus, this proposed solution does not satisfy the expectation that exploring the interpretability of dynamic graph.\nW4. Some important literature is missing, e.g., CauSTG for capturing invariant relations targets temporal shifts in ST graphs [1] and CaST for discovering via Structural Causal Model (SCM) with back-door and front-door adjustment [2]. The authors should distinguish the distinctions between the proposed DyGNNExplainer and  (CauSTG, CaST), especially the CaST.\n[1] Xia Y, Liang Y, Wen H, et, al. Deciphering Spatio-Temporal Graph Forecasting: A Causal Lens and Treatment[J]. arXiv preprint arXiv:2309.13378, 2023.\n[2] Zhou Z,  Huang Q,  Yang K, et, al. Maintaining the Status Quo: Capturing Invariant Relations for OOD Spatiotemporal Learning. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '23), 3603\u20133614.\nQuestions:\nIn Equation 7, $e$ is not defined in this paper, and the implementation of  $s( \\cdot , \\cdot )$ is also not provided.\nDoes $||A||$ operate by summing all elements of $A$ in Equation 14? Besides, does Equation 14 exist error? To satisying the sparsity requirement of causal and dynamic causal graph set, whether Equation 14 should be replaced by $\\frac{{||A_t^C|{|_1} + ||A_t^S|{|_1}}}{{||{A_t}|{|_1}}}$?\nIn Table 2, OrphicX achieves the best performances on DTree-Grid (96.1). But, you bold your work DyGNNExplainer (94.2 < 96.1).\n$\\Theta $ should be replaced by $\\Psi $ in the last line of Section 2.\nHow to interpret the 'dynamic' in DyGNNExplainer? Can the datasets in experiments support the augment raised in this paper, as it seems there are no dynamic graph in experiments?\nDistinguish the distinctions between this work and CaST.\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nN/A.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Feedback to Reviewer # JCbW", "Subheading": "Official CommentbyAuthors22 Nov 2023, 14:50Everyone", "Content": "Comment:\nWe appreciate your overall positive assessment of our contributions and are grateful for your suggestion. We have already updated the new revision based on your suggestions.\nQ1: Generative model\nW1:\nThanks for your question. Our dynamic graph interpretability task lies in providing spatial-temporal explanations (dynamic subgraph set) for dynamic graph structures. Consequently, our ultimate objective is to define a generative model, not a representational model. We make this more clear in Section 2.1.\nQ2: Logical derivation of Equation 1\nW2:\nIn Equation 1, we merge the estimation of $P(\\mathcal{Y}|do(\\mathcal{C}))$ with that of $P(\\mathcal{Y}|do(\\mathcal{D}))$. The detailed derivation process of backdoor adjustment can be shown as:\n\\begin{equation}\n\\begin{aligned}\nP(\\mathcal{Y}|do(\\mathcal{D})) &= \\sum P(\\mathcal{Y}|do(\\mathcal{D}), \\mathcal{S})P(\\mathcal{S}|do(\\mathcal{D})) \\\n&= \\sum P(\\mathcal{Y}|do(\\mathcal{C}))P(\\mathcal{S})\\\n&= \\sum P(\\mathcal{S})\\sum P(\\mathcal{Y}|do(\\mathcal{C}),\\mathcal{T})P(\\mathcal{T}|do(\\mathcal{C})\\\n&= \\sum P(\\mathcal{S})\\sum P(\\mathcal{Y}|\\mathcal{G})P(\\mathcal{T}).\n\\end{aligned}.\n\\end{equation}\nWe add this in Appendix A.4 in the revision.\nQ3: Interpretability issue of DyGNNs\nW3:\nSorry for our unclear expression, all our experiments are conducted on dynamic datasets. In essence, our case study is conducted on DBA-Shapes to provide a more vivid demonstration of DyGNNExplainer's interpretability. We visually represent both the original graph and the top six weighted edges of the generated causal subgraph across all time steps using DyGNNExplainer.\nRegarding temporal interpretability, the scrutiny of variable $t_p$ reveals that DyGNNExplainer adeptly pinpoints the most critical time steps that significantly influence the target node label within the original graph.\nIn terms of spatial interpretability, DyGNNExplainer proficiently discerns the presence of the 'house' motif within the original graph's concluding time step, offering a compelling explanation for the target node label.\nQ4: Static datasets\nW4:\nSince our method is the first study on dynamic graph interpretability, there are no directly available datasets suitable for the task of dynamic graph interpretability. So we dynamically transformed some commonly used static graph interpretability datasets. We add this in Section 3.1 in the revision.\nQ5: Missing important literature\nW5:\nYou recommend some benchmarks for graph representation and graph generalization. But it is hard to compare our method with them since the task in our model is totally different from theirs. Graph representation and graph generalization models are the target models we want to explain. For interpretable methods, the target model is model-agnostic. The interpretability task is to provide good explanations for these models. We make this more clear in Section 3.1.\nAdditionally, our methods of decoupling dynamic and static relationships are also different from CaST. To disentangle the static relationship and the dynamic relationship, we propose the constraint that dynamic relationships evolve over time steps but static relationships are independent across each time step. Consequently, we leverage the pre-trained target DyGNN model to guarantee the essential temporal correlation between neighboring subgraphs for the dynamic relationships and identify the rest independent causal information to the static relationships.\nQ6: Implementation of Equation 7\nW6:\nWe utilize contrastive learning to ensure the semantic similarity between the causal embedding $\\mathbf{e}^{\\mathcal{C}}_t$ and the original embedding $\\mathbf{e}_t$ while enlarging the semantic distance between the causal embedding $\\mathbf{e}^{\\mathcal{C}}_t$ and the trivial embedding $\\mathbf{e}^{\\mathcal{T}}_t$. $s(\\cdot,\\cdot)$ measures the similarity, we utilize the dot product here. We add the implementation in Section 2.5 in the revision.\nQ7: Implementation of Equation 14\nW7:\n$\\left|\\mathbf{A}^{\\mathcal{C}}_t\\right|_1$  and $\\left|\\mathbf{A}^{\\mathcal{D}}_t\\right|_1$ are $l_1$ norm of the causal graph set and the dynamic causal graph set, respectively. We sum up all elements here. The $\\left|\\mathbf{A}^{\\mathcal{S}}_t\\right|_1$  in Equation 14 should be replaced by $\\left|\\mathbf{A}^{\\mathcal{D}}_t\\right|_1$ , we have corrected it in revision.\nQ8: Typo in Table 2 and Equation 15\nW8:\nWe are sorry that one of the data in Table 2 was filled in incorrectly. The best performance in DTree-Grid is obtained by DyGNNExplainer. We have corrected the typo in Table 2 in the revision. And we have corrected $\\Theta$ with $\\Psi$ in the last line of Section 2.\nThank you again for your constructive reviews. Hope that our response can address your concerns. We feel grateful for your appreciation."}, {"Heading": "Feedback to author rebuttal", "Subheading": "Official CommentbyReviewer JCbW03 Dec 2023, 23:24 (modified: 15 Mar 2024, 00:27)EveryoneRevisions", "Content": "Comment:\nThe reviewer thanks the efforts made by authors on the detailed responses.  I still consider the name of DyGNN is doubtful and keep my score at this time.\nThanks."}]}]}, "tmsqb6WpLz": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "language models, domain adaptation, catastrophic forgetting", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Finetuning language models on domain-specific corpus is a common approach to enhance their domain knowledge and capability. While improving performance on domain tasks, it often brings a side-effect of forgetting of the model's general abilities. In this study, we analyze the effects of finetuning on language models by dissecting its impacts on the modeling of topic, style, and factual knowledge in text. Our method uses instruction-following LLMs such as ChatGPT to auto-generate controlled-variable text examples which we use to probe the model. Our findings reveal that finetuning results in significant shifts in the language model's topic and style priors, while actual knowledge learning only contributes to a small fraction of the total probability change. Analysis shows that the adaptation of topic and style priors behave akin to learning simple features: they are learned rapidly and require little model capacity. They are also learned independently and primarily at the beginning of a text sequence. In contrast, factual knowledge is learned stably but slowly and requires significant model capacity to learn. The research offers insights and understanding into the finer dynamics of learning and forgetting in language models, and can potentially inform future research on improving domain adaptation and addressing the challenges of forgetting in continual learning of language models.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "transfer learning, meta learning, and lifelong learning", "Submission Number": "9346", "PDF Url": "https://openreview.net/pdf?id=tmsqb6WpLz"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9346 by Area Chair FYuR", "Subheading": "Meta ReviewbyArea Chair FYuR11 Dec 2023, 05:04 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nStrengths\n* Investigating the changes language models undergo after finetuning is very relevant to ICLR\n* The approach seems novel\n* The authors are sharing the data and code\n* The paper is well written\n\nWeaknesses\n* Assumes a decomposition in style, topic, and factual knowledge \n* Primary message or conclusion of the paper is ambiguous (lack of actionnable recommendations)\nJustification For Why Not Higher Score:\nSee weaknesses.\nJustification For Why Not Lower Score:\nSee strengths."}, {"Heading": "Comments to all reviewers", "Subheading": "Official CommentbyAuthors19 Nov 2023, 10:32Everyone", "Content": "Comment:\nWe would like to thank all the reviewers and express our appreciation for all the insightful comments and suggestions. \n\nWe have uploaded a revision of the paper by incorporating many helpful suggestions from the reviewers. This revision mainly include the following aspects:\n\n* More domain corpora for evaluation: we add two new text domains in our analysis: the legal domain and the customer review domain. Results show that our findings generalize across different domains, reflecting a common phenomena in domain finetuning. The description of experiment settings of the two new domains, the new results, and discussions are included in the Appendix D of the revised paper.\n\n* Evaluating factual knowledge with question answering: we add evaluation of knowledge learning with quesition answering datasets, and shows with side-by-side comparison that both the question answering performance and the proposed factual/counterfactual likelihood ratio are useful indicators of knowledge learning. The description of datasets, results, and discussions are included in the Appendix E of the revised paper.\n\n* Text decomposition analysis in the literature: we add reference to linguistic theories that endorse the decomposition of text into topic, style, and factual information. We also reference to machine learning studies on the three aspects of text. We discuss how previous literature support and justify the text decomposition used in our approach. The added contents are included in the Related Work section of the revised paper.\n\n* Rewritten introduction with more clarity and focus: we have rewritten the introduction section to better introduce the text decomposition analysis method we proposed in the paper with examples.\nThe new introduction also has an improved flow and better highlights the main contributions of the paper. \n\n* Improved presentation of figures: we add summaries of the main findings to each figure to make them more self-contained. We add more explanation of the legends to help the reader better understand the figures.\n\n* Discussion on directions to improve knowledge learning and future work: we add a part of discussion on potential directions to improve knowledge learning in the final section of the revised paper.\n\nWe hope that the revised paper is more clear and complete with enhancements in theoretical justification and empirical verification. We thank the reviewers again for their work that helped us improve the paper."}, {"Heading": "Official Review of Submission9346 by Reviewer DT5M", "Subheading": "Official ReviewbyReviewer DT5M31 Oct 2023, 07:47 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\n- This paper presents a detailed analysis of the effects of fine-tuning of large language models on domain-specific downstream tasks/datasets.\n- In doing so, authors break down the probability distribution of a text into its fundamental factors i.e., topic, style and factual knowledge, and study the effects of fine-tuning on the probability distribution over these three factors.\n- It has been shown that in the early cycles of fine-tuning, the language model easily captures the topic and style information of the underlying text data thus introducing learning bias, which ultimately leads to an increase in the forgetting of the previous knowledge. However, the model is able to capture the factual knowledge in the later cycles of fine-tuning and also requires significant model capacity as compared to the model capacity required for capturing topic and style information.\n- Extensive experimental evaluation asserts the claims made by authors and opens a new research direction in continual learning research.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\n- Quality\n\t- The motivation is well-founded and the claims are sound.\n\t- Experimental analysis is very detailed and explanatory.\n- Clarity\n\t- Paper is clearly presented and easy to follow.\nWeaknesses:\n- Quality\n\t- As the topic of a document can be determined by the factual knowledge it contains then it might be redundant to keep the topic as a relevant factor in the text generation process and only style and factual knowledge might suffice which then could directly align with the syntax and semantics of the underlying text respectively.\n- Significance\n\t- This paper presents a detailed technical analysis of the fine-tuning process of a language model on domain-specific downstream tasks/datasets. However, the outcomes of the study conform with the expected outcomes of fine-tuning a model on domain-specific data and hence this paper misses to provide any significant gainful insight into the fine-tuning process due to the following reasons:\n\t\t- In the PubMed dataset, as academic style is present across all abstracts with different factual knowledge, it is expected that the model will readily adapt to the academic style first before capturing the diverse type of factual knowledge.\n\t\t- Just like in topic modeling, the topic of a document is a broad sentiment and can be easily determined using a set of keywords. So, it will be easy for the model to detect/understand the topic of a document before reading the whole document and capturing the factual knowledge inside it. Therefore, it is expected for the model to easily understand the topic and style factors before capturing the factual knowledge inside it.\n\t- I am keen to hear the response of the authors on this and hope that they can change my point of view.\nQuestions:\n- The C4 dataset could possibly contain the documents written in the \"academic\" style although in a different domain. Similarly, the C4 dataset could also contain documents related to the biomedical domain although having different factual information. So, it is possible that the model is adapting fast to the academic style and biomedical domain topic because it has already seen them in the pretraining data, but the diverse factual information in the PubMed dataset is new for the model, and that is why model is possibly taking time to capture that knowledge. Have authors taken this into consideration in their analysis of the finetuning process?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to the reviewer", "Subheading": "Official CommentbyAuthors19 Nov 2023, 10:38Everyone", "Content": "Comment:\nWe would like to thank the reviewer for the insightful comments and suggestions. We have revised the paper incorporating many of the suggestions. Please let us explain our responses to the reviewer's comments below:\n\n**The necessity of separating the topic factor**\n\n *Separating the topic factor reflects a natural generation process of text, and allows us to study the many properties of topic bias.*\n\nWe agree that the topic of a document can be determined by the factual knowledge it contains. However, considering the natural generation process of text (i.e., how a paragraph is written), it is often the case that the overall topic is determined first, then the factual information to include in the paragraph is selected. Our decomposition of $p(x)$ into $p(topic) p(factual|topic)$ reflects such a natural generation process, where $p(topic)$ models how likely a topic is chosen in the first step, and $p(factual|topic)$ models how likely certain factual information is included once the topic is chosen. As the reviewer pointed out, the alternative decomposiiton of $p(x)$ into $p(factual) p(topic|factual)$ will not make sense becuase $p(topic|factual)$ is deterministic.\n\nThere are linguistics theories that support the decomposition of text into an overall topic and specific, detatiled information. For example, topic-focus articulation (Sgall et al., 1986) distinguishes between the \"topic\" of a sentence (what the sentence is about, or its theme) and the \"focus\" (new or important information in the sentence). Theme-rheme analysis (Halliday, 1994) divides a sentence into \"theme\" (the departure point of the clause, what it's about) and  \"rheme\" (the rest of the clause, what is being said about the theme). In machine learning and NLP, there are also prior work that endorse a hierachical decomposition of paragraphs which fascilitate analysis of text at different levels of semantic granularity (Lin et al., 2015; Li et al., 2015; Nawrot et al., 2022). We have included a new subsection in the Related Work section of the revised paper to discuss the above mentioned work, for a better justification of the text decomposition method used in our approach. (The citation and discussion on the above mentioned work can be found in the Related Work section of the revised paper.)\n\nSeparating the topic factor from factual knowledge also allows us to study the many differences of the learning dynamics between topic bias and factual knowledge, which constitudes one of the two main contributions of our paper. We show that the topic biases and factual knowledge are learned very differently, which also evidences that to a certain extent the language model internally models topics separately from factual knowledge. It might have been harder to gain these insights if the topic factor is not separated from factual knowledge in the analysis. We have also revised the introduction section to better highlight the main contributions of the paper."}, {"Heading": "(continued)", "Subheading": "Official CommentbyAuthors19 Nov 2023, 10:40 (modified: 19 Nov 2023, 10:41)EveryoneRevisions", "Content": "Comment:\n**Significance of our findings**\n\n*Our findings starts from a simple intuition, but leads to an unexpected result, detailed understanding of different components in domain finetuning, and wide implications for future work.*\n\nWe agree with the reviewer that topic and style are very simple features of text. We pointed out that given existing study on spectral bias and shortcut learning, it is expected that topic and style are learned faster than factual knowledge. This is the starting point of our study.\n\nWith a dissection analysis, we found that the topic and style biases not only learns *fast*, but the *degree* of adaptation of topic and style priors is very significant, much larger than the degree of adaptation to factual knowledge. We think this high degree of biasing towards certain topic and style is not quite expected, as one could reasonably speculate that because topic and style are so salient and easily determinable, the model can easily recognize them during inference and does not need to adopt a strongly biased prior.\n\nWe showed that the implication of bias learning is that it affect how we interpret loss/perplexity changes in finetuning. Large reduce in perplexity does not necessarily mean significant learning of new domain knowledge as we would often assume. Large increase in perplexity on general corpus also does not equal to catastrophic forgetting of factual knowledge. We also need to take care of the bias in finetuned models in applications, as they could potentially be too heavily biased towards certain topic and style in generation which may negatively impact application in real-world scenarios.\n\nAs our second main contribution of the paper, we showed that *there are many more different properties between bias learning and knowledge learning besides the learning order*. We showed that the two types of learning have different capacity requirements, different sensitivity to learning rate and data composition, and affect modeling probabilities at different token positions. Also the topic and style biases are learned independently of each other.\n These results are not found in previous literature and we believe they are not obvious derivatives from the nature of domain finetuning.\n\nWe also point out (in the revised version of the paper) how these new insights into the fine-tuning process can be useful and its implications for future directions. We can use the discovered differences between bias learning and knowledge learning to design methods that encourage knowledge learning and reduce forgetting. For example, based on the observation that bias learning mostly happens on the first few tokens of the sequence, we could mask out the loss on the first few tokens in the finetuning objective to considerably reduce bias learning. Based on the different capacity requirement of bias and knowledge learning, in principle we could use a small low-rank adapter to learn the bias, and subtract its weights from the full finetuned model to remove the bias while keeping the knowledge. We believe that more understanding of the detailed learning dynamics in domain finetuning under a systematic analysis is very much needed as a basis to explore more finetuning techniques beyond the conventional causal language modeling recipe."}, {"Heading": "(continued)", "Subheading": "Official CommentbyAuthors19 Nov 2023, 10:42Everyone", "Content": "Comment:\n**The effect of old vs. new information in finetuning**\n \nWe really appreciate the reviewer's point on the effect of old vs. new information on the speed of learning in finetuning. We agree that combining the fact that 1) LLMs pretrained on general internet corpora likely have knowledge of lots of different topics and styles and 2) topic and style are simple features of text thus are easy to learn, it would be easy for the model to adapt to the topic and style of the domain corpus.\nWe have included the discussion on the effect of old vs. new information in the revised paper, as a possible explanation of the order of learning between biases and factual knowledge. We note that, similar to the previous point, the effect of old vs. new information explans the order of learning but  not the many other differences between bias learning and knowledge learning that we discovered in our analysis.\n\n**Other revisions of the paper**\n\n We also kindly ask the reviewer to refer to the \"comments to all reviewers\" section at the top of this page for a list of newly added contents in the revised paper. We included theoretical support of our methods, new domain corpora and more knowledge evaluation tasks to generalize our findings. We hope that the revised paper is getting even more clear and complete with the help of the reviewers."}]}, {"Heading": "Official Review of Submission9346 by Reviewer xGn4", "Subheading": "Official ReviewbyReviewer xGn430 Oct 2023, 05:25 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper dissects the effect of fine-tuning on learning and forgetting of language style, topic, and factual knowledge. The authors use instruction-following LLMs to automatically construct corpus with controlled factors above. The authors performed extensive analysis across different LM types and summarized several empirical findings, among which they show topic and style priors are easy to learn but factual knowledge is not.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\n- The method how the analysis is performed is novel. Creating training and evaluation corpora with controlled differences (topics, style, factual knowledge) by prompting instruction following LLMs is interesting and inspiring.  \n- The analysis is extensive and is performed under various configurations (like the choice of LM, size of the training corpora)\n- The outcomes of analysis are interesting and relevant to future research that study lifelong learning of LMs.\nWeaknesses:\n- Although other configurations are very extensive, the choice of training and evaluation corpora and exclusively original or variants of PubMed and C4. \n- The three text-generating factors (styles, topics, facts) may not always be clearly separable of extensive enough in every corpora. The authors discussed this limitation in their limitation section.\n- Clarity issue: I feel the plots very hard to read because the captions are too generic and not self-contained. I suggest to briefly summarize the findings or implications in the captions.\n- Clarity issue: some legends in plots such as Figure 4 are not explained in text (e.g. readers may be confused about \"C4 -factuals\" before they associate them with \"C4-counterfactual\" in Table 1)\n- Though the authors pointed out the hardness of learning factual knowledge without learning style and topic bias, the authors' attempts failed to improve such performance at the end of Sec. 3. I suggest to provide some future directions about how the analysis will be beneficial the challenge of learning factual knowledge above.\n- The authors focused on evaluation of LM loss throughout the paper. I think this is fine for style and topics, but factual knowledge, evaluating LM loss is not clean enough because only a few tokens in a sentence are related to facts. The authors could create cloze-style  or question answering evaluation sets that focus exclusively on generation of factual knowledge.\nQuestions:\n- There is a \"side note\" in page 7: \"When capacity is limited, the topic ratio and factual ratio simultaneously reduce on Pubmed in Figure 6.\" I did not see topic ratio reduces in Figure 6. Is this information supposed to be told by Figure 6?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to the reviewer", "Subheading": "Official CommentbyAuthors19 Nov 2023, 10:46Everyone", "Content": "Comment:\nWe would like to thank the reviewer for the insightful comments and suggestions. We have revised the paper incorporating many of the suggestions. Please let us explain our responses to the reviewer's comments below:\n\n**Corpora for evaluation**\n\nWe included two new domains, the legal domain and the customer review domain, in our analysis to verify the generalization of our finding. For the legal domain, we use the \"Court Listener Opinions\" subset from the Pile of Law corpus. For the customer review domain, we use the \"automotive\" subset from the Amazon reviews dataset. We use the same procedure as in our main study to finetune LLaMa 2 7B model, generate derived datasets, and probe the model accordingly.\n\nWe show (in Figure 9-10 of the revised paper) that similar to the biomedical domain, for the legal and the customer review domain, likelihood of the dominant topic and style in the corresponding training corpus also increases significantly during finetuning. For all the domains, the factual/counterfactual likelihood ratio changes at a significantly slower rate than the topic and style likelihood ratios, showing that the effect of topic and style adaptation on langauge modeling modeling are much more significant than the effect of knowledge learning. This shows that our main findings are likely general phenomena in domain finetuning.\n\nThe above results and discussions are included in the Appendix D of the revised paper.\n\n**Separability of text-generating factors**\n\nWe agree that the text-generating factors may not always be clearly separable in every corpora, and this poses a limitation on the scope where the dissection analysis can be directly applied. However, we believe that the general idea of decomposition of text into simple features (such as topic, style) and complex features (such as factual knowledge) is still useful in understanding the learning dynamics in domain finetuning even in cases where the decomposition cannot be explicitly performed. \n\n**Improving factual knowledge learning**\n\nWhile the current study mainly aim to uncover the learning dynamics in domain finetuning, we believe that by identifying bias learning as a potential hindrances in knowledge learning and showing the properties of bias learning, we also pointed out potential directions to improve knowledge learning. We can use the discovered differences between bias learning and knowledge learning to design methods that encourage knowledge learning. For example, based on the observation that bias learning mostly happens on the first few tokens of the sequence, we could mask out the loss on the first few tokens in the finetuning objective to considerably reduce bias learning. Based on the different capacity requirement of bias and knowledge learning, in principle we could use a small low-rank adapter to learn the bias, and subtract its weights from the full finetuned model to remove the bias while keeping the learned knowledge.\n\nWe add a part of discussion on potential directions to improve knowledge learning in the conclusion section of the revised paper."}, {"Heading": "(continued)", "Subheading": "Official CommentbyAuthors19 Nov 2023, 10:48Everyone", "Content": "Comment:\n**Evaluation of factual knowledge**\n\nWe agree that the factual knowledge of language models is more clearly evaluated with question answering tasks. As there may not be existing question answering datasets that directly evaluates knowledge in the PubMed corpus, we use the clinical subsets from the MMLU benchmark to evaluate models' knowledge of medical concepts, following Google's Med-PaLM 2 paper. The following results show that the models finetuned on PubMed generally have better knowledge of medical concepts than the baseline model:\n\n| Training size | Anatomy | Clinical knowledge | College biology | College medicine | Medical genetics | Professional medicine |\n|---------------|---------|--------------------|-----------------|------------------|------------------|-----------------------|\n| Baseline      | 46.7    | 45.7               | 46.5            | 41.0             | 51.0             | 51.8                  |\n| 1K            | 45.2    | 46.0               | 46.5            | 42.2             | 52.0             | 51.8                  |\n| 10K           | 45.9    | 46.0               | 45.1            | 42.2             | 53.0             | 52.6                  |\n| 100K          | 47.4    | 46.4               | 46.5            | **43.4**         | 52.0             | 52.9                  |\n| 1M            | **48.1**| 46.4               | 46.5            | 42.8             | **54.0**         | **54.4**              |\n\nWe also compared the factual/counterfactual likelihood ratio proposed in this paper and the average accuracy on MMLU clinical subsets on the same graph as a cross-validation of the two metrics (Figure 11 of the revised paper). The two curves show a similar trend, indicating that the factual/counterfactual likelihood ratio is indeed an indicator of the learning of biomedical knowledge.\n\nThe above results and discussions are included in the Appendix E of the revised paper.\n\n**Improving clarity of the figures**\n\nWe added summaries of the main findings of each Figure in their captions (Figures 2-8) to make them more self-contained. We also add an explanation of the legends of Figure 4 and 6 in their captions to aid comprehension.\n\n\n**The side note in Figure 6**\n\nThe side note on page 7 is intended to explain the phenomenon that the topic ratio (red line) reduces with decreasing model capacity on PubMed (the left plot of Figure 6). The topic ratio on C4 (the right plot of Figure 6) is not affected by model capacity. We use the side note to explain this minor difference.\n\n**Other revisions of the paper**\n\nWe also kindly ask the reviewer to refer to the \"comments to all reviewers\" section at the top of this page for a list of newly added contents in the revised paper. We also included theoretical support of our methods and a rewritten introduction section with more clarity and focus. We hope that the revised paper is getting even more clear and complete with the help of the reviewers."}]}, {"Heading": "Official Review of Submission9346 by Reviewer QBAp", "Subheading": "Official ReviewbyReviewer QBAp29 Oct 2023, 07:56 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper investigates the impact of finetuning language models on domain-specific texts and how it affects their general performance. The authors show that finetuning alters the model's preferences for topics and styles significantly, learning these features quickly and with minimal capacity. Factual knowledge, however, is acquired more slowly and requires greater capacity. The study's insights into language model learning dynamics could guide future enhancements in domain adaptation and help address the challenge of model forgetting during continuous learning.\n\nIn this study, the authors fine-tuned three models in increasing scales (GPT2-XL, LLaMa2 7B, and 13B) on PubMed abstracts with different scales of datasets up to 1M abstracts.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\n1. Investigating the changes language models undergo after finetuning continues to be a highly relevant and evolving area of study, despite prior coverage in academic literature.\n\n2. The research offers key empirical insights into the differential impact of finetuning on language models, revealing a more pronounced effect on style and topic preferences compared to factual knowledge. These findings enhance our understanding of language model training dynamics and are instrumental in formulating more effective training methodologies.\n\n3. The researchers conducted extensive experiments on three language models of considerable size, particularly from an academic perspective.\nWeaknesses:\n* The assertion that each prediction by a language model can be broken down into components of writing style, topic, and factual knowledge requires further justification or explanation. The paper should present a stronger argument or provide additional evidence to substantiate this claim.\n\n* The primary message or conclusion of the paper is ambiguous. The authors need to clarify the central thesis to ensure that readers can grasp the main contribution of the work. what is the takeaway from this research? \n\n* While the prose is generally lucid, the paper's structure, particularly the introduction, could use refinement to enhance its readability and impact.\n\nFor improved clarity and presentation, the following suggestions are offered:\n1. The introduction would benefit from concrete examples illustrating the key domains of style, topic, and factual knowledge to help contextualize the subsequent findings.\n2. Details regarding the fine-tuning process are scant. Clarification of which specific models are assessed and the precise nature of the fine-tuning would provide a more robust understanding of the study's scope.\n3. The transition from discussing fine-tuning effects to probing methods in the third paragraph of the introduction is somewhat abrupt. A smoother segue that connects these topics would aid reader comprehension.\n4. In the fourth paragraph, where style and topic biases are introduced, it would be helpful to include examples or elaborate on what these biases entail to furnish readers with a clearer picture of these concepts.\nQuestions:\n* The basis of the method assumes that p(x)=p(topic,style,factual), but is there a justification to that decomposition? what about arithmetic? how does it fall to this decomposition?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to the reviewer", "Subheading": "Official CommentbyAuthors19 Nov 2023, 11:05Everyone", "Content": "Comment:\nWe would like to thank the reviewer for the insightful comments and suggestions. We have revised the paper incorporating many of the suggestions. Please let us explain our responses to the reviewer's comments below:\n\n\n**Decomposition of text-generating factors**\n\nWe could find theories from linguistics and literary analysis that endorse the approach of decomposition of text into content and style. Separating the content (what is being said) and form (how it is being said) has been a traditional approach in literary theories (Eagleton, 2011). Content analysis deals with themes and the narrative while form (style) analysis studies the use of literary devices like metaphors and the organization of the text.\n\nSome linguistics theories further support decomposing the content into an overall topic and specific, detatiled information. For example, topic-focus articulation (Sgall et al., 1986) distinguishes between the \"topic\" of a sentence (what the sentence is about, or its theme) and the \"focus\" (new or important information in the sentence). Theme-rheme analysis (Halliday, 1994) divides a sentence into \"theme\" (the departure point of the clause, what it's about) and \"rheme\" (the rest of the clause, what is being said about the theme). It can also be extended to larger text structures, where the overall theme of the text is distinguished from specific, detailed information.\n\nIn machine learning and NLP, there are many work that study the three aspects separately. For example, topic modeling (Hofmann, 1999; Blei et al., 2003) studies the topic distribution of text in a corpus, style transfer studies manipulation of the style of text (Shen et al., 2017; Fu et al., 2018) (and also how to separate style from content (Fu et al., 2018)), and information extraction (Brin, 1998; Banko et al., 2007) studies the identification of factual information from text. Also, in document modeling, several work uses a hierachical structure to separately model the overall theme and specific information (Lin et al., 2015;\nLi et al., 2015; Nawrot et al., 2022), in a similar spirit as we did in this work.\n\nThe citation and discussion on the above mentioned work can be found in the Related Work section of the revised paper. We hope that we provided sufficient evidence from past work for justification of the decomposition used in our approach.\n\n**A summary of contributions with better focus**\n\nWe have rewritten the summary of contributions in the introduction section to better highlight the main contributions of the paper. The main contributions of our paper are the following two observations:\n\n* Domain finetuning leads to a significant change in the topic and style priors of the language model, biasing them towards the training data. Effect caused by such bias dominates the learning and forgetting observed in finetuning.\n\n* Topic and style biases are learned like simple features, while factual knowledge are learned like complex features in finetuning. We present the significant differences between their learning dynamics in multiple aspects.\n\nThe details of each observation are succinctly summarized under the two bullet points at the end of the introduction section. We hope that the revised introduction can help readers better grasp the main contributions of the paper."}, {"Heading": "(continued)", "Subheading": "Official CommentbyAuthors19 Nov 2023, 11:09Everyone", "Content": "Comment:\n**An rewritten introduction with improved clarity**\n\nWe have significantly rewritten the introduction section to improve the following aspects suggested by the reviewer:\n\n* In introducing the three text-generating factors, we explained the meaning of style, topic, and factual knowledge factors, and uses the current paper as an example to illustrate what each factor corresponds to:\n\n  - style: the structure, tone and diction, e.g., academic writing in ICLR paper format;\n\n  - topic: the overall theme, e.g., \"language model finetuning\";\n\n  - factual knowledge: the detailed factual information, e.g., methods, citation, and results in this paper.\n\n* We introduced the specific models assessed (open LMs like LLaMA) and the nature of finetuning (causal language modeling) early in the introduction.\n\n* We rewrite the paragraph that introduces probing methods, so that we introduce our probing method as a natural choice given prior related work and our goal of studying learning dynamics. We think now it is much smoother and no longer abrupt.\n\n* We explained that the style and topic biases means that the during generation, the language model is biased towards generating text with the style and topic present in the training data and less likely to generate text with other topics and styles.\n\n**Justification for the decomposition**\n\nWe have included references to both linguistic theories and machine learning studies that support the decomposition of text into topic, style and factural knowledge in the Related Work section of the revised paper. For arithmetics content, for example in mathematical text, the topic could be the mathematical topic (e.g., calculus), the style be the writing style of mathematical text, and the factual knowledge being the mathematical facts (e.g., how the right hand-side relates to the left-hand side in an arithmetics expression).\n\n**Other revisions of the paper**\n\nWe also kindly ask the reviewer to refer to the \"comments to all reviewers\" section at the top of this page for a list of newly added contents in the revised paper. We also included new domain corpora and more knowledge evaluation tasks to generalize our findings. We hope that the revised paper is getting even more clear and complete with the help of the reviewers."}]}, {"Heading": "Official Review of Submission9346 by Reviewer o2MC", "Subheading": "Official ReviewbyReviewer o2MC28 Oct 2023, 05:48 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper studies the effects of finetuning on an LM. The authors disentangle the effects of the finetuning along three \u201cdimensions\u201d: topic, style, and factual knowledge. To achieve that, they leverage ChatGPT to generate a series of texts that are only different in one of those facets. Provided such texts, one can estimate log-likelihood ratio of different styles (for instance), by calculating differences of cross-entropies of the model on the texts.\nThe generated texts were verified by human judgements. \n\nThe experimental study is performed using two corpora (BioMed and C4) and three LMs (GPT-2 XL, LLaMa 2 - 7B & 13B). \n\nThe paper reports the following findings: (a) topic and style changing rapidly,(b) topic and style biases are independent, (c) topic and style require minimal capacity to be learned, in contrast to knowledge, (d) mixing in unbiased data only reduces the biases to a certain degree.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\n* I find the topic of the investigation quite novel. I believe that the approach taken is original and innovative, in particular building a corpus that allows disentangling style/topic/factual knowledge. I also like the way LoRa was used to measure the capacity required for learning different facets.\n* The authors are sharing the data and code.\n* The reported experiments have provided some applicable insights, e.g. wrt the data mixing.\nWeaknesses:\n* Using synthetic data, generated by ChatGPT, might introduce some hidden biases. It is not given that the same findings could be found if we had natural data.\n* It is not clear if the same approach can be generalized to any other characteristics?\n\nTypos:\n* \u201cby just changing the order of decomposition in 1\u201d -> \u201c...in Eq. 1\u201d\nQuestions:\n* I wonder if there are other factorizations which can be studied in the same setup, apart from style/topic/knowldge?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to the reviewer", "Subheading": "Official CommentbyAuthors19 Nov 2023, 11:12Everyone", "Content": "Comment:\nWe would like to thank the reviewer for the insightful comments and suggestions. We have revised the paper incorporating many of the suggestions. Please let us explain our responses to the reviewer's comments below:\n\n\n**Hidden biases of synthetic data**\n\nWe agree with the reviewer that text generated with ChatGPT can have hidden biases, and we mentioned some forms of possible bias in the limitations of the paper. It would make the results of our paper more robust if we had natural data, but unfortunately the data we require for controlled-variable analysis (e.g., two document having the same content but different styles) is unlikely to be available in natural corpora. The advantage of using synthetic data is precise control on the components on text, so that we can have good precision in locating the variables we want to study which increases the reliability of our results.\n\n**Generalization to other characteristics of text**\n\nThe decomposition of text into generating factors is not unique, as long as the decomposition of $p(x)$ into conditional probabilities corresponds to a valid model of text-generation process. For example, we could decompose text into a semantic part and a syntactic part, suggested by one of the reviewers. Such a decomposition would corresponds to a model of text generation where the semantic information is first determined, then the syntax of the document is determined based on the semantic information. \n\nOne would find more ways to decompose text for studying its various characteristics from linguistic theories. For example, stylistics separates the style of text into linguistic features such as vocabulary, syntax, and figurative language. Narratology separates the narrative of text into components like plot, characters, and narrative perspective. For specific types of text, we can define more components to analysis than general text. \n\nAs long as the separation of one characteristic from the rest of the text is clear enough and meaningful, we could apply our dissection analysis method to analyze how the characteristic is learned in finetuning. More precisely, \"separation\" means that the chosen factor has a degree of freedom that is independent of other factors, so that modifying it while keeping other factors still result in valid and coherent text. For example, the plot in a narrative text can be changed while keeping the characters and narrative perspective the same.\n\n\n**Typo in the paper**\n\nWe thank the reviewer for pointing out the typo and we have corrected it in the revised paper.\n\n**Generalization to other factorizations**\n\nWe answered this question in combination with the previous question and provided our response above.\n\n\n**Other paper updates**\n\nWe also kindly ask the reviewer to refer to the \"comments to all reviewers\" section at the top of this page for a list of newly added contents in the revised paper. We included theoretical support of our methods, new domain corpora and more knowledge evaluation tasks to generalize our findings. We hope that the revised paper is getting even more clear and complete with the help of the reviewers."}]}]}, "RpKA1wqgk0": {"paper_info": {"Keywords": "Meta-Learning, Vision Transformers", "Abstract": "Pre-trained vision transformers have revolutionized few-shot image classification, and it has been recently demonstrated that the previous common practice of meta-learning in synergy with these pre-trained transformers still holds significance and contributes to further advancing their performance. Unfortunately, the majority of working insights such as task conditioning are specifically tailored for convolutional neural networks, thus failing to translate effectively to vision transformers. This work sets out to bridge this gap via a coherent and lightweight framework called MetaFormer, which maintains compatibility with off-the-shelf pre-trained vision transformers. The proposed MetaFormer consists of two attention modules, i.e., the Sample-level Attention Module (SAM) and the Task-level Attention Module (TAM). SAM works in conjunction with the patch-level attention in Transformers to enforce consistency in the attended features across samples within a task, while TAM regularizes learning of the current task with an attended task in the pool. Empirical results on four few-shot learning benchmarks, i.e., miniImageNet, tieredImageNet, CIFAR-FS, and FC100, showcase that our approach achieves the new state-of-the-art at a very modest increase in computational overhead. Furthermore, our approach excels in cross-domain task generalization scenarios.", "Primary Area": "transfer learning, meta learning, and lifelong learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9345", "PDF Url": "https://openreview.net/pdf?id=RpKA1wqgk0"}, "review_info": [{"Heading": "Summary of changes", "Subheading": "Official CommentbyAuthors20 Nov 2023, 20:36 (modified: 22 Nov 2023, 03:41)EveryoneRevisions", "Content": "Comment:\nWe extend our sincere thanks to the reviewers for their constructive feedback. We have summarized additional experiments and clarification made during the rebuttal period as follows. The revised part has been highlighted in red color.\nClarification:\nIllustrated our technical contributions concerning sample-level attention and task-level attention. (Reviewer kzi2 Q1 and Reviewer xYfp Q2)\nIncluded the number of parameters for each backbone in Table 1 and 2 (Reviewer kzi2 Q3)\nCorrected the typos in line 1 of page 5. (Reviewer 5apc Q3)\nAdded discussion of more related works. (Reviewer kzi2 Q2 and Q4)\nUpdated terminology used in the paper.  (Reviewer xXZf Q1)\nClarified the inductive and autoregressive setting. (Reviewer xXZf Q2)\nAdditional Experiments:\nConducted a comparative analysis between our proposed TAM method and the inter-task attention module, demonstrating TAM's superiority.  (Reviewer kzi2 Q2)\nAnalyzed the effectiveness of directly translating previous CNN-based meta-learning methods to vision transformers (Reviewer kzi2 Q4)\nPerformed ablation studies for hyper-parameter selection and more model variants to validate our contribution not solely due to an increase in parameters. (Reviewer 5apc Q2 and Reviewer 5apc Q1)\nApplied our approach to CLIP, achieving remarkable success. (Reviewer xYfp Q1)\nProvided a detailed computational analysis, including inference latency, GFLOPs and memory usage. (Reviewer 5apc Q2 and Reviewer xYfp Q3 and Q4)"}, {"Heading": "Official Review of Submission9345 by Reviewer kzi2", "Subheading": "Official ReviewbyReviewer kzi231 Oct 2023, 02:26 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper introduces MetaFormer, a ViT-based framework, designed to excel in the domain of few-shot image classification. It splits attention mechanisms into two key phases: intra-task and inter-task interactions. Intra-task interactions are handled by the Sample-level Attention Module (SAM), which models sample relationships within tasks. For inter-task interactions, the Task-level Attention Module (TAM) is introduced to learn task-specific probe vectors and retrieve relevant semantic features from previous tasks, building a dynamic knowledge pool. MetaFormer demonstrates good performance across a wide range of benchmarks, including those related to few-shot learning and cross-domain tasks.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe concept behind the proposed Metaformer is very simple and straightforward.\nThe proposed Metaformer delivers superior quantitative results on extensive few-shot learning benchmarks.\nWeaknesses:\nFundamentally, the technical contributions concerning sample-level attention and task-level attention presented in this work are not groundbreaking. For instance, the approach of decoupling attention (as detailed in section 3.2) to alleviate computational complexity is a well-established practice, particularly within the domain of video transformers.\nA more thorough examination of related research is warranted. For example, it would be insightful to delve into the distinctions between the inter-task attention module in [1] and the proposed TAM module, even if [1] is rooted in the continual learning community.\nIt would enhance the clarity of Tables 1 and 2 to incorporate columns displaying the number of parameters for each backbone model, as opposed to segregating this information in the ablation study section. Such an adjustment would facilitate a more straightforward assessment of whether the observed improvements in numerical performance can be attributed to an augmented parameter count.\n[1] Continual learning with lifelong vision transformer, CVPR 2022\nQuestions:\nIt would be beneficial to incorporate more in-depth discussions concerning prior research in the realm of meta-learning that incorporates vision transformers as their foundational architecture. For instance, when the authors highlight that \"the majority of existing methods are specially tailored for CNNs and thus fail to translate effectively to vision transformers,\" it would be valuable to provide a more comprehensive explanation of the limitations of existing approaches when they are applied in conjunction with transformers.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer kzi2 (Part 1)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 19:54Everyone", "Content": "Comment:\nWe sincerely thank the reviewer for providing valuable feedback. We detail our response below point by point. Some experimental results have been updated in the revised paper, and any modifications made to the paper are highlighted in red for your convenience. Please kindly let us know whether you have any further concerns.\nQ1. Technical contributions concerning sample-level attention and task-level attention\nWe acknowledge the reviewer's scrutiny of our technical contributions and would like to emphasize that our work indeed introduces novel and meaningful innovations to the field of few-shot learning.\nThe decoupling of temporal and spatial attention has indeed been explored in video transformers [1]. However, it is crucial to highlight that our consideration of the sample-to-sample relationship in few-shot learning presents a unique challenge distinct from the frame-to-frame relationship in videos, i.e., query samples have to be differentiated from support ones. Our introduction of\nsample causal masks\nserves an effective solution to address the challenge.\nNotably, a mere adjustment in the design of these sample causal masks allows our method to\nflexibly accommodate both inductive and autoregressive inference\n.\nWe substantiate the effectiveness of the proposed masks in\nAppendix D Table 5c\n, concluding that a lack of effective constraints between support and query samples (see Appendix D Fig 6 for details of the ablated masks of within-support and support-query) results in sub-optimal performance.\nThe proposed task attention module (TAM) with\nnovel knowledge encoding and consolidation mechanisms\nalso contributes to few-shot learning within the context of vision transformers. Detailed insights into TAM's contributions are provided in response to Q2.\nWhile we acknowledge that our proposed technique may not be characterized as groundbreaking in a broader sense, it is important to note its wide impact to the domain of few-shot learning. In particular:\nThe matching of local structural patterns between samples has long proven effective in few-shot learning [2, 3], though preceding endeavors relying on CNNs such as DeepEMD [2] are very slow. For example, DeepEMD demands 8 hours to evaluate 2000 5-way 5-shot episodes) [3]. We first\nenable this pattern matching across both samples and tasks within the ideally fitting framework of ViT in a highly efficient manner\n(requiring only 3.5 minutes). Notably, the success of ViT plays a pivotal role in explaining our markedly improved performance than prior CNN-based methods (miniImageNet 5-way 1-shot: Ours: 75.78% / DeepEMD: 65.91%).\nOur decoupling of spatial and sample attention\nmakes the proposed method seamlessly compatible with recent state-of-the-art pre-trained vision transformers\n, as mentioned in the Introduction, further enhancing their few-shot learning performances.\nOur current experiments have already demonstrated the compatibility and effectiveness when working with the pre-trained model of\nDINO\n;\nDuring the response period, we have also applied our approach to\nCLIP\n, achieving remarkable success by outperforming the SOTA method by 16.82%. Please find details to the response to Q1 of Reviewer xYfp.\nIn conclusion, we appreciate the reviewer's critical evaluation of our work, and we hope that these clarifications underscore the significance of our technical contributions to the field of few-shot learning.\n[1] Bertasius, Gedas, Heng Wang, and Lorenzo Torresani. \u201cIs space-time attention all you need for video understanding?.\u201d ICML. Vol. 2. No. 3. 2021.\n[2] Zhang, Chi, Yujun Cai, Guosheng Lin, and Chunhua Shen. \"Deepemd: Few-shot image classification with differentiable earth mover's distance and structured classifiers.\" CVPR, pp. 12203-12213. 2020.\n[3] Kang, Dahyun, Heeseung Kwon, Juhong Min, and Minsu Cho. \"Relational embedding for few-shot classification.\" ICCV, pp. 8822-8833. 2021."}, {"Heading": "Response to Reviewer kzi2 (Part 2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 19:55Everyone", "Content": "Comment:\nQ2. Distinctions between the inter-task attention module in [1] and the proposed TAM module, even if [1] is rooted in the continual learning community.\nWe appreciate the reviewer's great suggestion, and have incorporated the following discussions into the revised manuscript.\nThe TAM module proposed in our study distinguishes itself from the inter-task attention (IT-att) in [1] on several crucial fronts.\nProblem setting\n: as acknowledged by the reviewer, TAM is rooted in the domain of\nfew-shot learning\n, where the paramount concern is facilitating\nknowledge transfer\nbetween tasks. <u>In contrast</u>, IT-att in [1] is grounded in\ncontinual learning\n, where the primary focus lies in mitigating\ncatastrophic forgetting\n.\nTask embedding\n: while both TAM and IT-att [1] seemingly adopt a learnable embedding for each task, TAM utilizes it to represent\nthe knowledge specific to the current task\n.  <u>In contrast</u>, IT-att stores\nall past knowledge\nin it through regularization-based consolidation mentioned below.\nEncoding of knowledge from other tasks\n: Owing to disparate problem settings, TAM maintains\na knowledge pool that stores an array of task-dependent embeddings\n. <u>In contrast</u>, IT-att [1] keeps a record of\na single key and a single bias\n.\nConsolidation mechanism\n: Leveraging our knowledge pool, we consolidate the current task probe vector by\naveraging it with the most relevant vector in the pool\n(refer to Eq.(5)). <u>In contrast</u>, IT-att, which is designed to address forgetting, employs\nimportance-based regularization\nto enforce proximity of the current task embedding and previous one.\nThus, the task interaction in TAM exhibits\ngreater flexibility and expressiveness\n, aligning more closely with the objective of knowledge transfer in few-shot learning.\nWe further substantiate this claim through an ablation study, wherein we implement IT-att in our setting. The results, reported below and in Appendix G Table 8, demonstrate that our proposed\nTAM consistently outperforms IT-att by approximately 1.3%\nin the 5-way 5-shot setting on miniImageNet.\nMethod\n5-way 5-shot on miniImageNet\nIT-att   [1]\n$88.70 \\pm 0.50$\nTAM\n$90.02 \\pm 0.44$\n[1] Wang, et al. \"Continual learning with lifelong vision transformer.\" In CVPR, 2022.\nQ3. Clarity of Tables 1 and 2 to incorporate columns displaying the number of parameters for each backbone model\nWe appreciate this great suggestion, and in response, we have incorporated additional columns in Table 1 and 2 to present\nthe number of parameters (backbone + model-related)\nfor each method in the revision.\nWe would like to humbly highlight that the observed improvements in performance are\nnot solely attributed to an augmented parameter count\n, as supported by the following empirical evidence.\nIn the updated tables, we observe that FewTURE/HCTransformers, despite possessing a larger number of parameters, markedly lags behind the proposed MetaFormer.\nWe also conduct a comparative analysis with an ablated version, achieved by naively augmenting the number of layers in ViT-Small to make it comparable with the proposed MetaFormer. The results presented in the following table substantiate that merely increasing parameters cannot fully address the challenges inherent in few-shot learning. In fact, such augmentation may even elevate the risk of overfitting.\nMethod\nBackbone\nBackbone Params\nTotal Params\n1-shot\n5-shot\nvanilla ViT with more layers\nViT-Small\n$21\\mathrm{M}$\n$25.2 \\mathrm{M}$\n$69.75 \\pm 0.71$\n$84.12 \\pm 0.56$\nMetaFormer-I (Ours)\nViT-Small\n$21\\mathrm{M}$\n$24.5 \\mathrm{M}$\n$75.78 \\pm 0.71$\n$90.02 \\pm 0.44$\nMetaFormer-A (Ours)\nViT-Small\n$21\\mathrm{M}$\n$24.5 \\mathrm{M}$\n$79.41 \\pm 0.73$\n$91.21 \\pm 0.44$\n[1] Hiller, et al. \"Rethinking generalization in few-shot classification.\" In NeurIPS, 2022.\n[2] Lin, et al. \"Supervised masked knowledge distillation for few-shot transformers.\" In CVPR, 2023"}, {"Heading": "Response to Reviewer kzi2 (Part 3)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 19:55Everyone", "Content": "Comment:\nQ4. More in-depth discussions concerning prior research in the realm of meta-learning that incorporates vision transformers as their foundation architectures.\nOur claim that \"existing meta-learning methods are specially tailored for CNNs and thus fail to translate effectively to vision transformers\" is grounded in our empirical observations during the development of our proposed framework and supported by the findings in [5].\nInitially, we had planned to\nadapt FiLM\n, a technique commonly employed in CNN-based meta-learning for task adaptation through conditioned batch normalization [2, 3], into\nlayer normalization layers of ViT for task conditioning\n. Unfortunately, our experiments reveal\na performance drop\nwhen ViT was applied with FiLM, as shown in the following table.\nThe work of\n[5] also showcases the inferiority of FiLM when naively applied to ViT\n, as compared to their proposed task conditioning method tailored specifically for ViT (which involves only conditioning the attention block with a bias), particularly on large-scale Meta-Dataset.\nSuch failures are attributed to the substantial differences between the two backbones [6].\nWe posit that the challenge of architectural inconsistency partially accounts for the\nlimited research in the realm of meta-learning grounded on ViT\n. Another key challenge is the increased parameter requirement of ViT. FewTURE, as expounded in the Related Work section, is the pioneering work that tailors to ViT via inner-loop token importance reweighting, and addresses the second challenge via pre-training with DINO on the meta-training dataset. Our approach, empowering sample-to-sample and task-to-task interaction, further improves the accuracy substantially.\nTo avoid misunderstanding, we have corrected the original claim to and incorporated these discussions into our supplemental material.\nMethod\nBackbone\nminiImageNet 5-way 1-shot\nVanilla ViT\nViT-Small\n$69.03 \\pm 0.71$\nViT + FiLM\nViT-Small\n$58.75 \\pm 0.73$\nMetaFormer-I\nViT-Small\n$75.78 \\pm 0.71$\nMetaFormer-A\nViT-Small\n$79.41 \\pm 0.73$\n[1] Han-Jia, et al. \"Few-shot learning via embedding adaptation with set-to-set functions.\" In CVPR, 2020.\n[2] Requeima, et al. \u201cFast and \ufb02exible multi-task classi\ufb01cation using conditional neural adaptive processes.\u201d In NeurIPS, 2019.\n[3] Oreshkin, et al. \u201cTADAM: task dependent adaptive metric for improved few-shot learning.\u201d In NeurIPS, 2018\n[4] Hiller, et al. \"Rethinking generalization in few-shot classification.\" In NeurIPS, 2022.\n[5] Xu, et al. \u201cExploring E\ufb03cient Few-shot Adaptation for Vision Transformers.\u201d In TMLR, 2023\n[6] Raghu, Maithra, et al. \"Do vision transformers see like convolutional neural networks?.\" In NeurIPS, 2021."}, {"Heading": "We would love to hear back from Reviewer kzi2", "Subheading": "Official CommentbyAuthors22 Nov 2023, 01:16Everyone", "Content": "Comment:\nHi Reviewer kzi2,\nWe would like to follow up to see if our response addresses your concerns or if you have any further questions. We would really appreciate the opportunity to discuss this further if our response has not already addressed your concerns.\nThank you again!"}]}, {"Heading": "Official Review of Submission9345 by Reviewer 5apc", "Subheading": "Official ReviewbyReviewer 5apc29 Oct 2023, 14:58 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn this paper, the authors propose a ViT-based few-shot learning framework namely MetaFormer. Starting from vanilla ViT, the authors first propose Sample-leel Attention Module to reduce the computation cost and better intra-task interaction, and then propose Task-level Attention Module to enhance inter-task interactions for better feature representation. MetaFormer achieves promising performance on various few-shot learning benchmarks.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe motivation of \"decoupling space-level and sample-level attention\" is intuitive. Since this design can effectively reduce the computation cost meanwhile reduce sufficient unrelated attention values to ensure the quality of output features.\nThe performance of MetaFormer is promising. And the visualization results demonstrate the effectiveness of proposed methods.\nThis paper is well written and easy to reproduce.\nWeaknesses:\nSome critical ablation studies are lacked. e.g., the nubmer of task probe vectors (why choosing 1 for ViTs) and the size of knowledge pool (which number is better). Besides, for Table 3, the authors could introduce more variants (e.g., vanilla ViT with more layers) to support that: the performance improvement is from SAM / TAM but not more parameters.\nThough the authors claim that using proposed holistic attention mechanism can significantly reduce the computation complexity, the authors still need to provide essential FLOPS / latency statistic to support the merit. For example, reporting baseline method and MetaFormer under 5-way 5-shot setting.\nMore questions regrading the details of the paper, please see Question section for detail.\nQuestions:\nIn line 1 of page 5, the authors claim that the complexity of O((NK + M)^2 + L^2). Nevertheless, both NK+M and L cannot be omitted in the decoupled attention, therefore it mighte be O(L(NK+M)^2 + (NK+M)L^2). The authors could recheck the complexity and ensure the correctness of the manuscript.\nAs shown in Eqn. 5, the tokens in knowledge pool are updated by direct addition without averaging. The authors could discuss the performance between with and without averaging during pool consolidation.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 5apc (Part 1)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 20:00Everyone", "Content": "Comment:\nThank you sincerely for your thoughtful feedback on our work. Below, we have provided a detailed explanation for your concerns as follows. Please do not hesitate to let us know if you have any further questions.\nQ1. Ablation studies to support that: the performance improvement is from SAM / TAM but not more parameters\nWe have thoroughly examined the factors contributing to our performance improvement, concluding that the improvement is attributed to SAM/TAM rather than a mere expansion of parameters. This assessment is articulated through two primary perspectives.\nComparison with other baselines with equivalent or more parameters: In the updated Tables 1 and 2, we observe that FewTURE/HCTransformers, despite possessing a larger number of parameters, markedly lags behind the proposed MetaFormer.\nAblation studies\nWe conduct the analysis by comparing with an ablated version, achieved by\nnaively augmenting the number of layers in ViT-Small to make it comparable with the proposed MetaFormer\n. The results presented in the following table and in Appendix F Table 7 substantiate that merely increasing parameters cannot fully address the challenges inherent in few-shot learning. In fact, such augmentation may even elevate the risk of overfitting.\nMethod\nBackbone\nBackbone Params\nTotal Params\n1-shot\n5-shot\nvanilla ViT with more layers\nViT-Small\n$21\\mathrm{M}$\n$25.2 \\mathrm{M}$\n$69.75 \\pm 0.71$\n$84.12 \\pm 0.56$\nMetaFormer-I (Ours)\nViT-Small\n$21\\mathrm{M}$\n$24.5 \\mathrm{M}$\n$75.78 \\pm 0.71$\n$90.02 \\pm 0.44$\nMetaFormer-A (Ours)\nViT-Small\n$21\\mathrm{M}$\n$24.5 \\mathrm{M}$\n$79.41 \\pm 0.73$\n$91.21 \\pm 0.44$\nIn\nTable 3\n, we present an ablation study where we remove either TAM or SAM, both of which yield a noticable performance drop. This underscores the indispensable contributions of both TAM and SAM to the overall effectiveness of our model.\nIn\nAppendix D Table 5c\n, We provide additional evidence of the effectiveness of the proposed SAM, by maintaining the number of parameters and only varying the masks.  The ablated masks of within-support and support-query (see Appendix D Fig 6 for details) manifest sub-optimal performance, further validating that SAM with the inductive mask works not because of the introduction of extra parameters.\nWe have also followed the reviewer's suggestion by investigating the impact of increasing the number of task probe vectors and pool size.  The results, as illustrated in the tables below, indicate that (1) our model is\nnot sensitive to the number of task probe vectors\n, and (2)\na sufficiently diverse but compact knowledge pool\n(rather than the largest pool) leads to improvements in performance.\nThe number of probe vectors\nminiImageNet 5-way 1-shot\n1\n$75.78 \\pm 0.71$\n4\n$75.28 \\pm 0.73$\n8\n$75.44 \\pm 0.72$\n16\n$75.58 \\pm 0.72$\nThe size of knowledge pool\ntieredImageNet 5-way 5-shot\n10\n$90.40 \\pm 0.49$\n50\n$91.44 \\pm 0.53$\n100\n$89.92 \\pm 0.54$"}, {"Heading": "Response to Reviewer 5apc (Part 2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 20:01Everyone", "Content": "Comment:\nQ2. Essential FLOPS / latency statistic to support the merit of reducing computational complexity. For example, reporting baseline method and MetaFormer under 5-way 5-shot setting.\nWe appreciate the reviewer's invaluable feedback, and delve into a meticulous comparative analysis of computational efficiency.\nThis assessment encompasses (1) MetaFormer, (2) a naive implementation of sample-to-sample interactions without decoupling the spatial attention and sample attention, denoted as MetaFormer-naive, and (3) two other state-of-the-art methods.\nWe conduct the evaluation on an NVIDIA RTX A6000 GPU, wherein we report performance metrics, including\ninference-time GFLOPs and latency\n, specifically for 5-way 1-shot and 5-way 5-shot scenarios on the miniImageNet dataset.\nThe table below distinctly signifies that\nMetaFormer significantly\nreduces computational complexity in stark contrast to MetaFormer-naive\n, the naive implementation of sample-to-sample interactions.\nCompared to other baselines, MetaFormer exhibits  not only\nhigher accuracies\nattributable to comprehensive sample-to-sample interactions, but also\nremarkably superior computational efficiency\n.\nWe have incorporated this detailed comparative analysis into Appendix E Table 6 in the revised manuscript, providing a robust understanding of the computational efficiency landscape and affirming the advantages of MetaFormer over baselines in efficiency.\nMethod\nGFLOPs\n5-way 1-shot Acc.\n5-way 1-shot Infer. Speed [ms]\n5-way 5-shot Acc.\n5-way 5-shot Infer. Speed [ms]\nFewTURE\n5.01\n$68.02 \\pm 0.88$\n$77.35 \\pm 0.47$\n$84.51 \\pm 0.53$\n$111.22 \\pm 1.27$\nSMKD-Prototype\n12.58\n$74.28 \\pm 0.18$\n$137.58 \\pm 0.66$\n$88.82 \\pm 0.09$\n$171.37 \\pm 0.78$\nMetaFormer-naive\n602.40\nN/A\n$417.05 \\pm 0.51$\nN/A\n$659.94 \\pm 1.05$\nMetaFormer-I\n4.88\n$75.78 \\pm 0.71$\n$67.65 \\pm 0.78$\n$90.02 \\pm 0.44$\n$105.72 \\pm 1.06$\nQ3. The complexity should be O(L(NK+M)^2 + (NK+M)L^2).\nWe appreciate the reviewer for pointing out this typo. We have revisited and corrected the complexity calculation in the manuscript based on your suggestion.\nQ4. The performance between with and without averaging during pool consolidation in Eqn. 5\nWe conducted supplementary experiments to explore the impact of \"averaging\". As illustrated in the table below, the\nperformance difference between consolidation with averaging and without averaging is relatively marginal\n. This can be elucidated by the nature of the cosine similarity-based score function employed during knowledge retrieval, which remains not influenced by the magnitude of the stored vectors in the pool. To this end, we adopt the addition without averaging.\nMethod\nminiImageNet 5-way 1-shot\nwith averaging\n$75.78 \\pm 0.71$\nwithout averaging\n$75.57 \\pm 0.72$"}, {"Heading": "We would love to hear back from Reviewer 5apc", "Subheading": "Official CommentbyAuthors22 Nov 2023, 01:17Everyone", "Content": "Comment:\nHi Reviewer 5apc,\nWe would like to follow up to see if our response addresses your concerns or if you have any further questions. We would really appreciate the opportunity to discuss this further if our response has not already addressed your concerns.\nThank you again!"}]}, {"Heading": "Official Review of Submission9345 by Reviewer xYfp", "Subheading": "Official ReviewbyReviewer xYfp28 Oct 2023, 06:29 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposed MetaFormer, a new Transformer-based method for meta-learning. To improve the efficiency of self-attention in meta-learning, the authors propose to distengle the computation into three different dimensions: Task Attention, Spatial Attention and Sample Attention. Compared to existing state-of-the-arts, the proposed method achieves better performance across different datasets.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe motivation of this paper is clear: most exisiting meta-learning frameworks only show effectiveness in convolutional neural networks, as Transformer is prevailing these days, it is meaningful to validate and adapt this architecture in meta-learning as well.\nThe proposed method achieves clearly better performance than SOTA methods.\nThis paper is easy to follow. The figures well illustrate the framework of the proposed MetaFormer.\nWeaknesses:\nRecent large-scale pretrained vision foundation models, such as CLIP and SAM, have demonstrated superior zero-shot performance on image classification and visual grounding. In this context, one of my primary concerns is that the problem setting in this paper is not sufficiently significant. For example, datasets such as miniImageNet and CIFAR-FS may provide insights into the performance of meta-learning frameworks on small datasets, but they cannot accurately reflect performance on large-scale open-vocabulary datasets.\nFrom a technical perspective, the proposed holistic attention mechanism is novel in meta-learning. However, in general, the decoupling of self-attention computation into multiple dimensions is not new in the literature [1, 2]. For example, in video processing, TimeSformer [2]  has proposed to separate the spatial and temporal attention in a single block.\nThe paper does not demonstrate any efficiency gains from the proposed attention design. This is unconvincing, as one of the primary motivations described in the introduction is to reduce the computational cost of attention in ViTs when adapting for Meta-learning.\n[1] Ho, Jonathan, et al. \"Axial attention in multidimensional transformers.\" arXiv preprint arXiv:1912.12180 (2019).\n[2] Bertasius, Gedas, Heng Wang, and Lorenzo Torresani. \"Is space-time attention all you need for video understanding?.\" ICML. Vol. 2. No. 3. 2021.\nQuestions:\nCan the authors report the FLOPs and inference speed, memory cost in Table 1, 2, 3? Or at least the Table 3.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer xYfp (Part 1)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 20:04Everyone", "Content": "Comment:\nWe appreciate very much your constructive comments on our paper. Please kindly find our response to your comments below, and all revisions made to the paper are highlighted in red for your ease of reference. We hope that our response satisfactorily addresses the issues you raised. Please feel free to let us know if you have any additional concerns or questions.\nQ1. Recent large-scale pretrained vision foundation models, such as CLIP and SAM, have demonstrated superior zero-shot performance. In this context, one of my primary concerns is that the problem setting in this paper is not sufficiently significant. Datasets such as miniImageNet and CIFAR-FS cannot accurately reflect performance on large-scale open-vocabulary datasets.\nOur paper is\nexpressly designed to enhance the few-shot performance of pre-trained vision foundation models\non downstream tasks, as underlined in the Introduction (last sentence in the first paragraph).\nPre-trained vision model: In our previous experiment, we adopt the\nViT pre-trained by DINO\nas the pre-trained vision model for meta-training. Extensive empirical results robustly validate the effectiveness of our proposed method in enhancing few-shot learning performance on the pre-trained model.\nDatasets: Despite the relatively modest scale of miniImageNet ad CIFAR-FS, our performance on these datasets\noffers valuable insights into open-vocabulary datasets.\nWe follow the practice in FewTURE by pre-training DINO on only the meta-training set of the two datasets. This mirrors real-world scenarios where open-vocabulary downstream datasets are often out of the distribution of the pre-training dataset.\nExisting literature highlights the potential for further enhancing CLIP's few-shot performance on downstream tasks utilizing few-shot techniques\n[3-5]. Many of these innovative designs and key insights originate from meta-learning experiments conducted on small datasets. For instance, the cache model in [3] is akin to matching networks [6], the context conditional prompt in [4] is inspired by task-specific vectors [7], and the observation that refined channels focus more on foreground regions [5] correlates with findings in [8] about varying channel importance across tasks.\nTo demonstrate the\ncompatibility of the proposed MetaFormer with larger pre-trained vision foundation models such as CLIP\nand the effectiveness on open-vocabulary datasets, we adapt our method to the CLIP model with ViT-B/16 for advancing its few-shot performance in downstream tasks.\nBaselines: We compare with\n(1)\nzero-shot CLIP,\n(2)\nTiP-Adapter [3], a state-of-the-art method that adopts the shot feature and its corresponding label for the key and value of the cache model as the classifier head,\n(3)\nthe variant TiP-Adapter-F [3] that fine-tunes the key in the cache model, and\n(4)\nthe variant TiP-Adapter-F with more layers fine-tuned, being comparable to ours in the number of parameters.\nDatasets: We follow [3] and evaluate on the challenging open-vocabulary datasets, EuroSAT [9] and ISIC [10].\nTraining and evaluation protocol: We adopt the episodic approach as described in [6] to construct tasks:\n(1)\nduring training, both support and query sets are sampled from the train set;\n(2)\nduring evaluation,  we strictly follow the TiP-Adapter [3] pipeline for sampling the support set from the train set and the query set from the test set to construct a task for evaluation. This is reasonable as there are no new classes in the test set.\nImplementation: Our implementation follows TiP-Adapter [3], integrating its cache model as the auxiliary classifier head. We exclusively fine-tune the SAM modules and the head while keeping the visual and textual encoders of CLIP frozen. Evaluation employs pre-trained word embeddings of a single prompt, \u201ca photo of a [CLASS].\u201d Further implementation details are available in Appendix I.\nResults: As presented in the table below, highlight noteworthy insights:\n(1)\nCLIP pre-trained on large-scale web-crawled image-text pairs struggles with downstream datasets exhibiting a substantial domain gap, such as the medical dataset of ISIC;\n(2)\nadapting CLIP with a downstream dataset is pivotal to improved performance, with a caution against the risks of overfitting with excessive parameter adaptation;\n(3)\nour method significantly enhances Zero-shot CLIP on EuroSAT by 42.76% and ISIC by 43.81%, and its adaptation ability also\nsurpasses Tip-Adapter by a large margin\n.\nWe sincerely thank the reviewer for the constructive comments. We have also incorporated these discussion into Appendix I."}, {"Heading": "Response to Reviewer xYfp (Part 1 Continued)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 20:05Everyone", "Content": "Comment:\nMethod\nEuroSAT\nISIC\nZero-shot CLIP\n$48.73 \\pm 0.98$\n$21.07 \\pm 0.76$\nTip-Adapter\n$69.85 \\pm 0.75$\n$28.70 \\pm 0.97$\nTip-Adapter-F\n$72.01 \\pm 0.97$\n$32.27 \\pm 1.11$\nTip-Adapter-F with more layers\n$51.95 \\pm 0.86$\n$16.17 \\pm 0.78$\nTip-Adapter+MetaFormer (Ours)\n$88.83 \\pm 0.78$\n$45.96 \\pm 1.44$\n[1] Hiller, et al. \"Rethinking generalization in few-shot classification.\" In NeurIPS, 2022.\n[2] Hu, et al. \"Pushing the limits of simple pipelines for few-shot learning: External data and fine-tuning make a difference\". In CVPR, 2022\n[3] Zhang, et al. \u201cTip-adapter: Training-free clip-adapter for better vision-language modeling.\u201d In ECCV, 2022\n[4] Zhou, et al. \u201cConditional prompt learning for vision-language models.\u201d In CVPR, 2022\n[5] Zhu, et al. \u201cNot All Features Matter: Enhancing Few-shot CLIP with Adaptive Prior Re\ufb01nement.\u201d In ICCV, 2023\n[6] Snell, et al. \u201cMatching networks for one shot learning\". In NeurIPS, 2016\n[7] Oreshkin, et al. \u201cTADAM: task dependent adaptive metric for improved few-shot learning.\u201d In NeurIPS, 2018\n[8] Luo, et al. \u201cChannel Importance Matters in Few-Shot Image Classi\ufb01cation.\u201d In ICML, 2022\n[9] Helber, et al. \"Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification\", In IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2019.\n[10] Tschandl, et al. \"The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions\", In Scientific data, 2018"}, {"Heading": "Response to Reviewer xYfp (Part 2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 20:07Everyone", "Content": "Comment:\nQ2. From a technical perspective, the proposed holistic attention mechanism is novel in meta-learning. However, in general, the decoupling of self-attention computation into multiple dimensions is not new in the literature [1, 2]\nWe  would like to underscore the following novel and meaningful technical innovations made to the field of few-shot learning.\nThe decoupling of temporal and spatial attention has indeed been explored in video transformers [1, 2]. However, it is crucial to highlight that our consideration of the sample-to-sample relationship in few-shot learning presents a unique challenge distinct from the frame-to-frame relationship in videos, i.e., query samples have to be differentiated from support ones. Our introduction of\nsample causal masks\nserves an effective solution to address the challenge.\nNotably, a mere adjustment in the design of these sample causal masks allows our method to\nflexibly accommodate both inductive and autoregressive inference\n.\nWe substantiate the effectiveness of the proposed masks in\nAppendix D Table 5c\n, concluding that a lack of effective constraints between support and query samples (see Appendix D Fig 6 for details of the ablated masks of within-support and support-query) results in sub-optimal performance.\nThe proposed task attention module (TAM) with\nnovel knowledge encoding and consolidation mechanisms\nalso contributes to few-shot learning within the context of vision transformers. Detailed insights into TAM's contributions are provided in response to reviewer kzi2 Q2.\nWhile we acknowledge that our proposed technique may not be characterized as groundbreaking in a broader sense, it is important to note its wide impact to the domain of few-shot learning. In particular:\nThe matching of local structural patterns between samples has long proven effective in few-shot learning [2, 3], though preceding endeavors relying on CNNs such as DeepEMD [2] are very slow. For example, DeepEMD demands 8 hours to evaluate 2000 5-way 5-shot episodes) [3]. We first\nenable this pattern matching across both samples and tasks within the ideally fitting framework of ViT in a highly efficient manner\n(requiring only 3.5 minutes). Notably, the success of ViT plays a pivotal role in explaining our markedly improved performance than prior CNN-based methods (miniImageNet 5-way 1-shot: Ours: 75.78% / DeepEMD: 65.91%).\nOur decoupling of spatial and sample attention\nmakes the proposed method seamlessly compatible with recent state-of-the-art pre-trained vision transformers\n, as mentioned in the Introduction, further enhancing their few-shot learning performances.\nOur current experiments have already demonstrated the compatibility and effectiveness when working with the pre-trained model of\nDINO\n;\nDuring the response period, we have also applied our approach to\nCLIP\n, achieving remarkable success by outperforming the SOTA method by 16.82%. Please find details to the response to Q1.\nIn conclusion, we hope that these clarifications underscore the significance of our work in the field of meta-learning, and have cited/discussed these two works in the main text.\n[1] Ho, Jonathan, et al. \"Axial attention in multidimensional transformers.\" arXiv preprint arXiv:1912.12180 (2019).\n[2] Bertasius, Gedas, Heng Wang, and Lorenzo Torresani. \"Is space-time attention all you need for video understanding?.\" ICML. Vol. 2. No. 3. 2021."}, {"Heading": "Response to Reviewer xYfp (Part 3)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 20:20Everyone", "Content": "Comment:\nQ3 and Q4. Efficiency gains in FLOPs and inference speed, memory cost\nWe appreciate the reviewer's invaluable feedback, and delve into a meticulous comparative analysis of computational efficiency.\nThis assessment encompasses (1) MetaFormer, (2) a naive implementation of sample-to-sample interactions without decoupling the spatial attention and sample attention, denoted as MetaFormer-naive, and (3) the selection of two state-of-the-art and representative methods with comparable parameter counts from the meta-learning and transfer-learning domains as our primary comparison objects (4) the additional computational ablation analysis in Table 3.\nWe conduct the evaluation on an NVIDIA RTX A6000 GPU, wherein we report performance metrics, including\ninference-time GFLOPs, latency, and memory usage\n, specifically for 5-way 1-shot and 5-way 5-shot scenarios on the miniImageNet dataset.\nThe tables below distinctly signify that\nMetaFormer significantly\nreduces computational complexity in stark contrast to MetaFormer-naive\n, the naive implementation of sample-to-sample interactions.\nCompared to other baselines, MetaFormer exhibits not only\nhigher accuracies\nattributable to comprehensive sample-to-sample interactions, but also\nremarkably superior computational efficiency\n.\nDifferent combinations of these modules reveal\ntrade-offs between model complexity and performance\n, as well as the benefits of each module in enhancing the model's capabilities.\nWe have incorporated this detailed comparative analysis into Appendix E Table 6 in the revised manuscript, providing a robust understanding of the computational efficiency landscape and affirming the advantages of MetaFormer over baselines in efficiency.\nMethod\nGFLOPs\n5w1s Acc.\n5w1s Infer. GPU Memory\n5w1s Infer. Speed [ms]\n5w5s Acc.\n5w5s Infer. GPU Memory\n5w5s Infer. Speed [ms]\nFewTURE\n5.01\n$68.02 \\pm 0.88$\n3304M\n$77.35 \\pm 0.47$\n$84.51 \\pm 0.53$\n6482M\n$111.22 \\pm 1.27$\nSMKD-Prototype\n12.58\n$74.28 \\pm 0.18$\n4288M\n$137.58 \\pm 0.66$\n$88.82 \\pm 0.09$\n4666M\n$171.37 \\pm 0.78$\nMetaFormer-naive\n602.40\nN/A\n20.85G\n$417.05 \\pm 0.51$\nN/A\n30.86G\n$659.94 \\pm 1.05$\nMetaFormer-I\n4.88\n$75.78 \\pm 0.71$\n3661M\n$67.65 \\pm 0.78$\n$90.02 \\pm 0.44$\n5887M\n$105.72 \\pm 1.06$\nSAM\nTAM\nAdd. Params.\nGFLOPs\n5w1s Acc.\n5w1s Infer. GPU Memory\n5w1s Infer. Speed [ms]\n5w5s Acc.\n5w5s Infer. GPU Memory\n5w5s Infer. Speed [ms]\n$\\checkmark$\n$\\checkmark$\n$+3.57 \\mathrm{M}$\n4.88\n$75.78 \\pm 0.71$\n3661M\n$67.65 \\pm 0.78$\n$90.02 \\pm 0.44$\n5887M\n$105.72 \\pm 1.06$\n$\\checkmark$\n$\\times$\n$+2.01 \\mathrm{M}$\n4.77\n$74.64 \\pm 0.76$\n3602M\n$67.56 \\pm 0.81$\n$87.53 \\pm 0.47$\n5878M\n$103.93 \\pm 0.84$\n$\\times$\n$\\checkmark$\n$+1.56 \\mathrm{M}$\n4.68\n$73.63 \\pm 0.75$\n3590M\n$54.51 \\pm 0.49$\n$87.76 \\pm 0.52$\n5868M\n$88.07 \\pm 0.79$"}, {"Heading": "We would love to hear back from Reviewer xYfp", "Subheading": "Official CommentbyAuthors22 Nov 2023, 01:18Everyone", "Content": "Comment:\nHi Reviewer xYfp,\nWe would like to follow up to see if our response addresses your concerns or if you have any further questions. We would really appreciate the opportunity to discuss this further if our response has not already addressed your concerns.\nThank you again!"}]}, {"Heading": "Official Review of Submission9345 by Reviewer xXZf", "Subheading": "Official ReviewbyReviewer xXZf25 Oct 2023, 04:06 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nA coherent and lightweight framework MetaFormer is proposed to improve the Vision Transformer performance in meta-learning. The framework contains a sample-level attention module (SAM) and a task-level attention module (TAM). The SAM enables the consistency of attended features across samples in a task whilst the TAM regularizes the learning of features for the current task by attending to a specific task in the pool. Extensive experiments are conducted on four commonly used FSL benchmark datasets and the new SOTA is achieved with a marginal increase in computational cost.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\n-- The paper adds inter-sample and inter-task attention modules to the original Vision Transformer for meta-learning. These ideas are not novel whilst the implementation of them in such a way is somewhat novel.\n-- The presentation is generally good but lacks clarity for some details (see weaknesses).\n-- Thorough experiments on the in-domain and cross-domain settings provide valuable references to the community of FSL.\nWeaknesses:\n-- The authors use the terms context and target sets instead of support and query sets which are usually employed in FSL literature. This makes the presentation harder to understand.\n-- The main concern is the use of test samples during learning which makes it a transductive learning method. It might be that I misunderstand the training details of the model but it is unclear to me if M unlabelled query samples are used in any way before final prediction using Eq(7).\n-- The autoregressive inference setting employs the information from the test data. It is unfair to compare with those under the true inductive learning setting.\n-- It is unclear what properties of the learned task embedding have. A suggestion would be to analyze the task embedding space somehow to give intuitive insights for better understanding. For example, one can sample N tasks from the meta-testing data and M tasks from the meta-training data and compute the NxM distance matrix and take a closer look at some exemplar rows/columns to see what kind of tasks are similar in the learned task embedding space.\nQuestions:\nIn tables 1 and 2,  why are the bottom two groups of methods separated whilst they use the same backbone ViT-Small?\nIf I misunderstand the method regarding the transductive setting, is it possible to adapt the framework to the transductive setting and how?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer xXZf (Part 1)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 20:25Everyone", "Content": "Comment:\nWe extend our appreciation for your  constructive feedback on our manuscript. Below, we address each of your points comprehensively. Should there be any additional queries or clarifications needed, please feel free to let us know.\nQ1: The terms context and target sets instead of support and query sets\nThanks for your suggestion. We have revised our manuscript to use \"support\" and \"query\" sets to align with more FSL works and enhance clarity. Our initial choice of \"context\" and \"target\" aligns with previous meta-learning works of [1-4],  where \"context\" set provide conditions for task adaptation and \"target\" set serves evaluation targets of the adapted model.\n[1] Zintgraf, et al. \u201cFast Context Adaptation via Meta-Learning.\u201d In ICML, 2019\n[2] Rusu, et al. \u201cMeta-learning with latent embedding optimization.\u201d In ICLR, 2019\n[3] Requeima, et al. \u201cFast and \ufb02exible multi-task classi\ufb01cation using conditional neural adaptive processes.\u201d In NeurIPS, 2019.\n[4] Patacchiola, et al. \u201cContextual Squeeze-and-Excitation for Efficient Few-Shot Image Classification.\u201d In NeurIPS, 2022\nQ2: Whether the proposed method is inductive or transductive\nWe would like to humbly clarify that the proposed MetaFormer with its meticulously designed sample causal mask\nflexibly and efficiently accommodates both inductive and transductive settings\n. This also constitutes one of our\ncore contributions\n.\nWhen configuring the sample causal mask as the inductive variant (refer to Figure 2(a) for details), we instantiate MetaFormer-I. This design choice with\nquery interactions blocked\n, coupled with the inherent Layer Normalization in vision transformers, ensures\nindependent predictions for each query sample\n, adhering strictly to inductive learning principles.\nWhen configuring the sample causal mask as the autoregressive variant (refer to Figure 2(b) for details), we instantiate\nMetaFormer-A\n. This represents a\ncoherent and efficient transductive implementation\ncapable of extracting support and query feature embeddings\nin a single feedforward pass\n. To the best of our knowledge, MetaFormer-A stands out as the\nfirst pure transformer-backed method for transductive few-shot image classification\n.  It eliminates the need for extra time-consuming components suh as label propagation in GNNs [1] or specialized loss functions [2], offering simplicity and efficiency.\nWe sincerely appreciate the reviewer's great suggestion to include more comparisons validating the superiority of our transductive version, MetaFormer-A. In response,\nWe conduct additional comparisons, pitting MetaFormer-A against other transductive methods. The results, in the table below, demonstrates its superior performance with a 79.41% accuracy without introducing extra components like label propagation in GNNs [1] or specialized loss functions [2], establishing it as a\ncompelling choice for seamless transitioning from the inductive setting\n.\nMethod\nBackbone\nminiImageNet 5-way 1-shot\nTPN [1]\nResNet\n59.46\nADV [2]\nWRN\n74.63\nMetaFormer-A\nViT-Small\n79.41\nWe further conduct a comparative analysis employing a naive transductive approach, wherein constraints on query interactions as MetaFormer-A impose are omitted, and the sampling size ($r$) is set to be equal to the number of query samples. This method is analogous to the one described in [3]. The following table results showcase the\nsuperiority of our autoregressive version MetaFormer-A\n.\nMethod\nBackbone\nminiImageNet 5-way 1-shot\nnaive transductive\nViT-Small\n76.00\nMetaFormer-I\nViT-Small\n75.78\nMetaFormer-A\nViT-Small\n79.41\n[1] Liu, et al. \"Learning to propagate labels: Transductive propagation network for few-shot learning.\" arXiv preprint arXiv:1805.10002, 2018.\n[2] Huang, et al. \"Improving Task-Speci\ufb01c Generalization in Few-Shot Learning via Adaptive Vicinal Risk Minimization.\" In NeurIPS, 2022\n[3] Hou, et al. \"Cross attention network for few-shot classification.\" In NeurIPS, 2019\nQ3: Visualization analysis of learned task embeddings\nThank you for your insightful suggestion. We conduct a qualitative analysis of learned task probe vectors across different tasks randomly sampled from meta-train (M=3) and meta-test sets (N=3). As shown in Appendix J Fig. 7, the visualization effectively reveals the\nefficacy of these vectors in capturing task relationships\n. For example, we observe a higher similarity in task features among tasks involving car tires, dogs, and long-legged animals. This demonstrates MetaFormer's capability in discerning and utilizing task semantics."}, {"Heading": "Response to Reviewer xXZf (Part 2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 20:26Everyone", "Content": "Comment:\nQ4. In tables 1 and 2, why are the bottom two groups of methods separated whilst they use the same backbone ViT-Small?\nWe  apologize for any potential misunderstandings. Our intention in distinguishing between these two groups of methods is to\nhighlight the effectiveness of MetaFormer when employed in conjunction with diverse training paradigms\n.\nFewTURE [1] represents a pioneering meta-learning approach specifically tailored for self-supervised pre-trained Vision Transformers (ViT).\nThe SMKD [2] method adopts a transfer learning approach based on self-distillation.\nThe results obtained from our experiments consistently showcase MetaFormer's ability to enhance task adaptation across both of these distinct methodological groups.\n[1] Hiller, et al. \"Rethinking generalization in few-shot classification.\" In NeurIPS, 2022.\n[2] Lin, et al. \"Supervised masked knowledge distillation for few-shot transformers.\" In CVPR, 2023"}, {"Heading": "We would love to hear back from Reviewer xXZf", "Subheading": "Official CommentbyAuthors22 Nov 2023, 01:19Everyone", "Content": "Comment:\nHi Reviewer xXZf,\nWe would like to follow up to see if our response addresses your concerns or if you have any further questions. We would really appreciate the opportunity to discuss this further if our response has not already addressed your concerns.\nThank you again!"}, {"Heading": "Official Comment by Reviewer xXZf", "Subheading": "Official CommentbyReviewer xXZf22 Nov 2023, 08:57Everyone", "Content": "Comment:\nThanks for the reply, much appreciated. The transductive learning method does not seem to perform comparably well with SOTA though the more advanced ViT backbone is employed."}, {"Heading": "Q: Gratitude to Reviewer xXZf's prompt response and updated fair comparison in the transductive setting", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:44Everyone", "Content": "Comment:\nWe appreciate the reviewer\u2019s prompt response very much, letting us know your remaining concern on the comparative performance of our autoregressive method, MetaFormer-A, with the current state-of-the-art transductive method.\nWe again highlight our core contribution that seamlessly transits between the inductive and transductive settings via simply configuring the sample causal mask.\nUnder the inductive setting, we have already demonstrated the unquestionable superiority of MetaFormer-I, agreed by the reviewer, over other state-of-the-art baselines.\nUnder the transductive setting, the proposed MetaFormer-A by only setting the autoregressive sample causal mask (see Fig 2(b)) requires\nonly one singe-pass during inference\n, which contrasts with other state-of-the-art transductive few-shot learning methods [3-5] that introduces additional time-consuming label propagation and GNNs.\nWe conduct additional comparisons for MetaFormer-A against other SOTA transductive methods. Note that for a fair comparison with the state-of-the-art methods [2,3] that employ inference-time augmentation, we adopt a similar approach for MetaFormer-A. This involves shuffling the order of the samples in a meta-testing task 30 times and then computing the average of logits as the final prediction. We conduct the inference-time latency evaluation on an NVIDIA RTX A6000 GPU for 5-way 5-shot scenarios. We extract features in advance for both protoLP[5] and our MetaFormer, and calculate the inference time without special parallel optimization.\nSuperiority over SOTA\n: The results, reported below and in Appendix K Table 11, demonstrate that our MetaFormer-A with inference-time augmentation\nexhibits not only higher accuracies but also remarkably superior computational efficiency.\nIn conclusion, we believe that our MetaFormer-A establishes a meaningful transductive baseline for pure transformer backbones in the realm of few-shot learning owing to its simplicity and efficiency. We have incorporated this part of experiments in our revision.\nMethod\nBackbone\nInference Speed[ms]\nminiImageNet 5-shot\ntieredImageNet 5-shot\nCIFAR-FS 5-shot\nCAN [1]\nResNet-12\n-\n80.64 \u00b1 0.35\n84.93 \u00b1 0.38\n-\nEASY [2]\n3*ResNet-12\n-\n88.57 \u00b1 0.12\n89.26 \u00b1 0.14\n90.20\u00b10.15\nODC [3]\nWRN-28-10\n-\n88.22\n91.20\n-\niLPC [4]\nWRN-28-10\n-\n88.82 \u00b1 0.42\n92.46 \u00b1 0.42\n90.60\u00b10.48\nprotoLP [5]\nWRN-28-10\n40.61\n90.02 \u00b1 0.12\n93.21 \u00b1 0.13\n90.82\u00b10.15\nMetaFormer-A\nViT-Small\n34.44\n93.36\u00b10.38\n93.66 \u00b1 0.50\n93.30 \u00b1 0.51\n[1] Hou, et al. \"Cross attention network for few-shot classification.\" In NeurIPS, 2019\n[2] Bendou et al. \"Easy\u2014ensemble augmented-shot-y-shaped learning: State-of-the-art few-shot classification with simple components.\" In Journal of Imaging, 2022\n[3] Qi et al. \"Transductive few-shot classification on the oblique manifold.\" In ICCV, 2021\n[4] Lazarou et al., \u201cIterative label cleaning for transductive and semi-supervised few-shot\u201d learning. In ICCV, 2021\n[5] Zhu, et al., \u201cTransductive Few-shot Learning with Prototype-based Label Propagation by Iterative Graph Refinement\u201d In CVPR, 2023"}]}]}, "xNdE7RiRyP": {"paper_info": {"Supplementary Material": "pdf", "Primary Area": "transfer learning, meta learning, and lifelong learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Tiny Machine Learning, On-device Training, Personalisation, Edge Computing, Microcontrollers", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We propose the on-device training approach that jointly optimises data, memory, and compute efficiency on constrained edge devices.", "Abstract": "On-device training is essential for user personalisation and privacy. With the pervasiveness of IoT devices and microcontroller units (MCU), this task becomes more challenging due to the constrained memory and compute resources, and the limited availability of labelled user data. Nonetheless, prior works neglect the data scarcity issue, require excessively long training time (e.g. a few hours), or induce substantial accuracy loss ($\\geq$10%). We propose TinyTrain, an on-device training approach that drastically reduces training time by selectively updating parts of the model and explicitly coping with data scarcity. TinyTrain introduces a task-adaptive sparse-update method that dynamically selects the layer/channel based on a multi-objective criterion that jointly captures user data, the memory, and the compute capabilities of the target device, leading to high accuracy on unseen tasks with reduced computation and memory footprint. TinyTrain outperforms vanilla fine-tuning of the entire network by 3.6-5.0% in accuracy, while reducing the backward-pass memory and computation cost by up to 1,098$\\times$ and 7.68$\\times$, respectively. Targeting broadly used real-world edge devices, TinyTrain achieves 9.5$\\times$ faster and 3.5$\\times$ more energy-efficient training over status-quo approaches, and 2.23$\\times$ smaller memory footprint than SOTA approaches, while remaining within the 1 MB memory envelope of MCU-grade platforms.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9344", "PDF Url": "https://openreview.net/pdf?id=xNdE7RiRyP"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9344 by Area Chair KtaN", "Subheading": "Meta ReviewbyArea Chair KtaN11 Dec 2023, 14:55 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nIn this paper, the authors present a method for on-device training of neural networks in extremely compute and memory limited systems such as microcontroller (MCUs) and IoT devices. In particular, the authors introduce a sparse update learning method that trains convolutional neural networks with less memory and computation demands. The paper demonstrates the efficacy of their approach across multiple CNN architectures (MCUNet, MobileNet, and NASNet) across an array of datasets with an impressive reduction in memory and compute demands (e.g ~10x faster training speed).\nThe reviewers commented positively on how practical this method is for real world scenarios in which the memory and compute are extremely limited. The reviewers raised concerns on the limited focus of this method on image classification, the novelty with respect to prior work (p-Meta), the quality of the presentation, and the details about the methodology. The authors provided some responses indicating that they will improve the presentation of the paper in subsequent revisions and argued the novelty of their work with respect to prior papers.\nThe reviewers though remained divided about acceptance. Given the lack of consensus, I took the opportunity to read the paper more closely. I agreed with several reviewers that the quality of presentation needs serious revisions. Additionally, I would like to see more comparisons and detailed discussions of the comparisons with prior work. That said, my biggest concern is the limited applicability of this work to the ICLR conference. This work is very heavily application oriented and would better suit a computer vision community or a community interested in \u201con-edge\u201d devices. I do not see as much general interest within the ICLR community for this area of work. For these reasons, this paper will not be accepted at this conference. I would encourage the authors to heavily revise this work based on the reviewer comments and resubmit this to a more specialized conference geared towards on-edge ML and computer vision.\nJustification For Why Not Higher Score:\nLimited interest to ICLR. Concerns about clarity of presentation.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "A common response to all the reviewers", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:51Everyone", "Content": "Comment:\nDear reviewers,\nWe sincerely appreciate all reviewers\u2019 time and efforts in reviewing our paper and for the constructive feedback. \nWe appreciate all of you for your positive reviews and for\nrecognising\nthe strengths of our work:\npF1F:\nProposed sample-efficient method of on-device learning that improves accuracy over other methods.\naEBW:\nPractical solution for training models on resource-constrained devices, improving the efficiency of on-device training.\nT24f:\nWell-motivated, extensive experiments on different benchmarks by deploying their models on two embedded devices.\nk57W:\nNovel contribution to the area of on-device training at the edge with solid empirical results.\nWe have addressed all the questions and comments raised by reviewers by providing\nmore clarifications\n, presenting\nnew results\n, generating a\nnew table\n, and revising\ntables and figures\nduring this rebuttal period. We summarise how we addressed the\nreviewers\u2019 main questions\nas follows:\npF1F:\nWe clarified the observations made in our work and further elaborated on our design choices derived from the observations.\npF1F, T24f:\nWe clarified the unique contributions of our work compared to prior works, E2-train and p-Meta.\naEBW:\nWe described the unique challenge of different vision applications like segmentation and detection.\naEBW:\nWe elaborated on the end-to-end on-device training latency results on embedded devices and cost analysis of meta-training.\nT24f:\nWe further explained the memory usage of the employed architectures in our work.\nT24f:\nWe presented new results regarding the detailed memory footprint breakdown.\nk57W:\nWe addressed the reviewer\u2019s questions regarding the applicability of our work to different IoT platforms, meta-learning and transfer learning, and layer/channel selection.\nk57W:\nWe further explained the energy measurement procedure and FullTrain\u2019s accuracy compared to our work."}, {"Heading": "Official Review of Submission9344 by Reviewer pF1F", "Subheading": "Official ReviewbyReviewer pF1F31 Oct 2023, 15:44 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nTinyTrain offers an approach to on-device training tailored to IoT and MCU devices, which are typically faced with limited memory and computational resources. By adopting a task-adaptive sparse-update method, this system aims to train neural network models more efficiently, addressing data scarcity and aiming to curtail training durations. TinyTrain claims to achieve a 3.6-5.0% improvement in accuracy compared to conventional methods and boasts of a 9.5\u00d7 faster training speed.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThis paper proposes a task-specific sparse update for the model. This dynamic sparse-update configuration is better in model accuracy than that method that adopts static configuration.\nThis paper enhances on-device learning by incorporating a few-shot learning scheme to let it be sample-efficient.\nWeaknesses:\nThe text in the figures is too small and hard to read.\nSome figures are not well-presented.\nThe design seems to have little to do with the observations of the paper.\nQuestions:\nThe text in almost all the figures is too small and pretty hard to read. The authors should make sure the figures are easy to read.\nIn Figure 3, the authors want to claim that i) Accuracy gain per layer is generally highest on the first layer of each block, ii) Accuracy gain per parameter and computation cost of each layer is higher on the second layer of each block. While I appreciate these interesting observations, I do have some concerns and comments:\n(1) The authors have some observations related to the position of a layer in the block. However, all we can see about the layer position in the figures is the layer index in the whole model. I have no idea which layers are the first/second layers in the block.\n(2) The authors say that the second observation is not a clear pattern. If it is not a clear pattern, why bother writing down this uncertain observation without any further explanation?\n(3) What are the accuracy gain per parameter and accuracy gain per MAC? Are these widely used terms? May you briefly introduce them before using them?\nThis paper gives out some observations. However, they seem to have limited contribution to the design. The design uses a gradient-based metric to indicate the importance of a layer/channel, which does not consider the layer position in the block.\nThere is already a paper [1] that jointly considers the layer importance and computation cost when selectively updating some layers of a model, which is similar to the idea of this paper. I have concerns about the novelty of this paper.\n[1] Yue Wang, Ziyu Jiang, Xiaohan Chen, Pengfei Xu, Yang Zhao, Yingyan Lin, and Zhangyang Wang. 2019. E2-train: training state-of-the-art CNNs with over 80% energy savings. Proceedings of the 33rd International Conference on Neural Information Processing Systems. Curran Associates Inc., Red Hook, NY, USA, Article 462, 5138\u20135150.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 22:33Everyone", "Content": "Comment:\nComment1. The text in the figures is too small and hard to read.\nWe will re-draw the figures by increasing the font size.\nComment2. The authors have some observations related to the position of a layer in the block. However, all we can see about the layer position in the figures is the layer index in the whole model. I have no idea which layers are the first/second layers in the block.\nWe will re-draw the figures so that readers can see each block in the networks. Specifically, blocks in the figures are coloured in either white or grey so that each block is visually separated. Also, to help readers easily identify which layer is the first and which is the second in the block, we put the layer index in one block as an example.\nComment3. The authors say that the second observation is not a clear pattern. If it is not a clear pattern, why bother writing down this uncertain observation without any further explanation?\nIn this work, we make the following observations as quoted below.\n(1) the peak point of accuracy gain occurs at the first layer of each block (pointwise convolutional layer) (Figure 3a), (2) the accuracy gain per parameter and computation cost occurs at the second layer of each block (depthwise convolutional layer) (Figures 3b and 3c).\nA key takeaway message of the second observation is to indicate that selecting the first layer of each block (which would be the case based on the contribution analysis in the prior work [a] and our first observation) may not always be an optimal choice for a layer/channel selection of on-device training when taking into account both accuracy and system aspects such as memory and computation. In other words, it indicates a non-trivial trade-off between accuracy, memory, and computation, which motivates us to propose our multi-objective criterion for an effective layer/channel selection that jointly considers all three aspects above. We will clarify this point in Section 2.2.\n[a] Ji Lin et al. \"On-device training under 256kb memory.\" 36th Conference on Neural Information Processing Systems (NeurIPS 2022).\nComment4. What are the accuracy gain per parameter and accuracy gain per MAC? Are these widely used terms? May you briefly introduce them before using them?\nWe introduced two new terms, (1) accuracy gain per parameters and (2) accuracy gain per MACs, in order to take into account the system aspects to enable resource-aware layer/channel selection for on-device training. First, accuracy gain per parameter indicates how much accuracy gain we can obtain by updating a single layer at a time divided by the number of parameters in the layer. Then, the accuracy gain per MAC represents how much accuracy gain we can obtain by updating a single layer at a time divided by the number of MACs in the layer. We will introduce and explain those terms in detail before we present our observations in Section 2.2.\nComment5. This paper gives out some observations. However, they seem to have limited contribution to the design. The design uses a gradient-based metric to indicate the importance of a layer/channel, which does not consider the layer position in the block.\nAs explained in our response to Comment 3 above, the observations made in this work directly inspired us to propose the multi-objective criterion, which is the first component of our task-adaptive sparse-update method. As the multi-objective criterion considers the importance of each layer and channel as well as its memory and computation overheads, it allows us to encompass both accuracy and efficiency aspects.\nHaving established the multi-objective criterion, we design the dynamic layer/channel selection scheme, the other component of our task-adaptive sparse update. Our observations may not directly affect the design of the dynamic layer/channel selection scheme; however, it leverages the multi-objective criterion to quickly identify the layers/channels that are important as well as memory- and compute-efficient on the fly during deployment given a target task, enabling our on-device training framework to be task adaptive. Also, in our dynamic layer/channel selection scheme, although we do not explicitly design our method to select each block's first or second layer, we observed that the first/second layers in a block are typically selected in our evaluation."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 22:34Everyone", "Content": "Comment:\nComment6. There is already a paper [1] that jointly considers the layer importance and computation cost when selectively updating some layers of a model, which is similar to the idea of this paper. I have concerns about the novelty of this paper.\nWe will clarify our contribution over E2-train [b] in Sections 4 and G. However, here are the salient points highlighting the superiority of TinyTrain over E2-train: E2-train introduces a trainable gating function. This consists of an RNN model per layer block - although the Appendix says that all RNNs share weights to save memory footprint. The RNNs are trained alongside the main on-device training process. The utilisation of RNN-based trainable gating functions i) adds overhead to the training stage in terms of training time and ii) opens up questions with respect to scalability (The paper does not report training time results, only energy).\nAlso, if E2-train's selective layer update (SLU) was to be trained during the offline meta-training stage of TinyTrain, it would require samples that are representative of the ones encountered upon deployment. In our FSL scenario, this cannot be the case by definition.\nE2-train performs selective updates only at the layer level. TinyTrain jointly considers both selective layer and channel updating, adding another dimension of adaptivity during training.\n[b] Yue Wang, Ziyu Jiang, Xiaohan Chen, Pengfei Xu, Yang Zhao, Yingyan Lin, and Zhangyang Wang. 2019. E2-train: training state-of-the-art CNNs with over 80% energy savings. Proceedings of the 33rd International Conference on Neural Information Processing Systems. Curran Associates Inc., Red Hook, NY, USA, Article 462, 5138\u20135150."}]}, {"Heading": "Official Review of Submission9344 by Reviewer aEBW", "Subheading": "Official ReviewbyReviewer aEBW30 Oct 2023, 02:43 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper develops TinyTrain as an on-device training approach that addresses the challenges of data scarcity and resource constraints in the context of IoT devices and microcontroller units (MCUs). Traditional methods neglect the data scarcity issue, require long training times, or result in significant accuracy loss. However, TinyTrain introduces a task-adaptive sparse-update method that dynamically selects layers and channels based on a multi-objective criterion. This approach considers user data, memory, and compute capabilities, leading to improved accuracy on unseen tasks with reduced computation and memory requirements. The proposed TinyTrain fits the memory constraints of MCU-grade platforms and ensures practical feasibility.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe proposed TinyTrain presents a practical solution for training models on resource-constrained edge devices, helping improve the efficiency of on-device model training.\nWeaknesses:\n(1) The experiments mainly concentrate on image classification with a limited number of training epochs, so it would be valuable to also evaluate the performance of the proposed methods on segmentation and detection tasks. These tasks often involve more complex data and require more extensive training. Examining the effectiveness of the proposed methods in such scenarios would provide a more comprehensive assessment of their applicability and overall performance.\n(2) To gain a better understanding of the practical implications and efficiency of the proposed methods, it is suggested to include information on training/inference speed or time cost when applying the methods to downstream tasks. This would offer valuable insights into the computational efficiency and scalability of the approach for real-time or time-sensitive applications.\nQuestions:\nPlease see the weakness part.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 10:47Everyone", "Content": "Comment:\nComment1. The experiments mainly concentrate on image classification with a limited number of training epochs, so it would be valuable to also evaluate the performance of the proposed methods on segmentation and detection tasks. These tasks often involve more complex data and require more extensive training. Examining the effectiveness of the proposed methods in such scenarios would provide a more comprehensive assessment of their applicability and overall performance.\nIt is very challenging to support\neven the forward pass\nof such applications as segmentation and object detection due to the large input resolution. For instance, a single image with a resolution of 640x640x3 (a widely used resolution for the MSCOCO dataset [c,d]) accounts for 1.17 MB to store, exceeding the available memory on a microcontroller (1 MB if it is a high-end microcontroller), let alone the cost of DNN execution regarding the forward and backward passes. Investigating the effectiveness of TinyTrain on segmentation and detection can be interesting, however, the challenge regarding high-resolution image inputs needs to be dealt with first. Thus, we leave this task as future work. Also, we would like to highlight that within the current scope of the paper, we have evaluated the proposed method on 9 different vision datasets to showcase the superior performance TinyTrain achieves in image classification.\nIn addition, we would like to clarify that the unique contribution of TinyTrain is the task-adaptive sparse update policy based on our proposed multi-objective criterion and dynamic layer/channel selection that guides the layer/channel selection process during deployment. We focus on a training framework that jointly addresses accuracy, memory, compute efficiency, as well as the scarcity of labelled data on user devices, which makes our work different from existing approaches in the sense that we consider realistic factors in real-world deployment comprehensively. Specifically, our online on-device learning stage leverages the offline meta-training which learns a sufficiently general representation in order to learn cross-domain tasks efficiently when given a few samples on-device (i.e. addressing (i) accuracy and (ii) data scarcity issues). Also, our proposed task-adaptive sparse update not only enables TinyTrain to automate the layer/channel selection process but also drastically reduce the memory and compute requirements of on-device training (i.e. addressing (iii) memory and (iv) computational efficiency issues) while achieving new SOTA accuracy results on nine cross-domain datasets across three architectures.\n[c] Tsung-Yi Lin et al. Microsoft COCO: Common Objects in Context. In European Conference on Computer Vision (ECCV), 2014.\n[d] Emanuel Ben-Baruch et al. Asymmetric Loss For Multi-Label Classification. Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021, pp. 82-9."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 10:48Everyone", "Content": "Comment:\nComment2. To gain a better understanding of the practical implications and efficiency of the proposed methods, it is suggested to include information on training/inference speed or time cost when applying the methods to downstream tasks. This would offer valuable insights into the computational efficiency and scalability of the approach for real-time or time-sensitive applications.\nWe have investigated the run-time efficiency of TinyTrain when it is applied to various downstream tasks (i.e. 9 cross-domain few-shot learning datasets) in Section 3.2. We have successfully deployed TinyTrain on two embedded devices such as Pi Zero 2 and Jetson Nano. In addition, we have measured the end-to-end on-device training time and energy consumption of the workloads of these downstream tasks and reported the results in Figure 5 and Section 3.2. The summary of results is written in the paper as follows.\nTinyTrain yields 1.08-1.12x and 1.3-1.7x faster on-device training than SOTA on Pi Zero 2 and Jetson Nano, respectively. Also, TinyTrain completes an end-to-end on-device training process within 10 minutes, an order of magnitude speedup over the two-hour training of conventional transfer learning, a.k.a. FullTrain on Pi Zero 2.\nAlso, regarding the efficiency of our dynamic layer/channel selection process, we have examined the time it takes to identify important layers/channels and reported them (20-35 seconds on Pi Zero 2 and Jetson Nano, accounting for only 3.4-3.8% of the total training time of TinyTrain) in Sections 3.2 and E.3.\nLastly, we have analysed the cost of meta-training that needs to be done offline before deploying the model on resource-constrained devices in Section F.2. We wrote as follows.\nIn our experiments, the offline meta-training on MiniImageNet takes around 5-6 hours across three architectures. However, note that this cost is small as meta-training needs to be performed only once per architecture. Furthermore, this cost is amortised by being able to reuse the same resulting meta-trained model across multiple downstream tasks (different target datasets) and devices, e.g. Raspberry Pi Zero 2 and Jetson Nano, while achieving significant accuracy improvements (refer to Table 1 and Figure 6a in the main manuscript and Figures 11, 12, and 13 in the appendix)."}]}, {"Heading": "Official Review of Submission9344 by Reviewer T24f", "Subheading": "Official ReviewbyReviewer T24f29 Oct 2023, 19:50 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors proposed a few-shot learning pipeline for edge devices, where both the data and the resources are limited during the training. The authors proposed a structured sparse-updating method that can dynamically select the critical layers/channels for each new learning task. During the few-shot learning, only these critical layers/channels will be updated. Therefore, both the training time and the energy cost are significantly reduced, which is also verified by their deployment results.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper is well-motivated. Learning a new unseen task on edge devices with customized user data faces the shortage from data and computing resources, as the single user often has a limited labor resource to collect and label samples and the edge devices often have a limited on-device memory and computing power. How to achieve a comparable performance with limited training samples on resource-constrained edge device is important to the scenarios where the user has privacy concerns and the user data can only be processed locally.\nThe authors conducted extensive experiments on different benchmarks. The authors also deployed their models on Pi Zero and Jetson Nano to measure the real training latency and energy cost, which is especially encouraged.\nWeaknesses:\nThe paper has a limited novelty. Although this paper proposed a different metric to select adaptation-critical weights, one of the related work \"p-Meta: Towards On-device Deep Model Adaptation\" had studied the same problem settings, i.e., how to train the model on new tasks given limited samples and limited computing resources. The proposed pipeline in p-Meta also consists of two stages, meta-training stages in the cloud and few-shot leaning stages on edge devices.\nI had some other concerns about how the authors computed the memory footprint in back-propagation. Since for a back-propagation, we must first conduct the forward pass. The peak memory consumption occurred during the backward pass at a certain layer only if it was larger than the peak memory required by the forward pass. Could you please elaborate how the memory number was calculated in Tab.2. At which layer during the back-propagation it reached the peak memory? \nThe reason why I had the concerns above was that 8-bit MCUNet had a 0.49MB peak memory in the forward pass, as reported in Fig.8 in\nhttps://arxiv.org/pdf/2007.10319.pdf\n. Then, the peak memory of training MCUNet in 32-bit floating point must be higher than 1.96MB (0.49*4), since you may also want to store some other intermediate values for backward. Unless the authors conducted low-precision training or used different architectures.\nI noticed that the authors used momentum SGD during on-device few-shot learning. What was the memory consumption from momentums? If these parameters took the majority, the authors should report a more fair comparison using vanilla SGD.\nQuestions:\nSee Weaknesses\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 22:39Everyone", "Content": "Comment:\nComment1. The paper has a limited novelty. Although this paper proposed a different metric to select adaptation-critical weights, one of the related work \"p-Meta: Towards On-device Deep Model Adaptation\" had studied the same problem settings, i.e., how to train the model on new tasks given limited samples and limited computing resources. The proposed pipeline in p-Meta also consists of two stages, meta-training stages in the cloud and few-shot learning stages on edge devices.\nThe objective of p-Meta and our work is the same, i.e., achieving efficient and accurate on-device training. However, those two approaches have considerable differences, providing unique benefits to TinyTrain over p-Meta. p-Meta uses a meta attention module that identifies the more important layers/channels, which shows the memory/computation reduction but does not take memory and computational costs as an optimisation goal explicitly. Conversely, we design a multi-criterion metric that explicitly takes the memory and computation costs into account when identifying which layers and channels to update, which would help our method select important layers/channels with less memory and computational costs, leading to a higher memory reduction.\nSecondly, p-Meta\u2019s updated layers/channels change for each sample and each iteration, which could result in very frequent write operations on storage. Considering the real-world deployment scenario, especially for microcontrollers (MCUs) where the write operation on the storage (Flash) is two orders of magnitude more costly compared to the read operation [e], frequent changes of the update configuration would harm the system efficiency. On the other hand, TinyTrain performs only once the layer/channel selection at the beginning of the on-device training to select which layers/channels to update for a target task and they are fixed during on-device training, which suits deployment scenarios on MCUs well. We will clarify these points in Section 4 and Section G.\n[e] Filip Svoboda et al. 2022. Deep Learning on Microcontrollers: A Study on Deployment Costs and Challenges. In Proceedings of the 2nd European Workshop on Machine Learning and Systems (Rennes, France) (EuroMLSys \u201922).\nComment2. Could you please elaborate how the memory number was calculated in Tab.2. At which layer during the back-propagation it reached the peak memory? The reason why I had the concerns above was that 8-bit MCUNet had a 0.49MB peak memory in the forward pass, as reported in Fig.8 in\nhttps://arxiv.org/pdf/2007.10319.pdf\n. Then, the peak memory of training MCUNet in 32-bit floating point must be higher than 1.96MB (0.49*4), since you may also want to store some other intermediate values for backward. Unless the authors conducted low-precision training or used different architectures.\nThe model mentioned in the comment above is the largest MCUNet architecture: it consumes 1.96 MB of memory in the forward pass alone. We use a different version of MCUNet, which is much smaller than the one above. Its peak memory use for the forward pass is 0.625 MB rather than 1.96 MB as the reviewer specified. Please refer to Section A.2 for more details regarding the model architectures used in our study.\nFollowing (Lin et al., 2022), we employ optimised DNN architectures designed to be used in resource-limited IoT devices, including MCUNet (Lin et al., 2020), MobileNetV2 (Sandler et al., 2018), and ProxylessNASNet (Cai et al., 2019). The DNN models are pre-trained using ImageNet (Deng et al., 2009). Specifically, the backbones of MCUNet (using the 5FPS ImageNet model), MobileNetV2 (with the 0.35 width multiplier), and ProxylessNAS (with a width multiplier of 0.3) have 23M, 17M, 19M MACs and 0.48M, 0.25M, 0.33M parameters, respectively. Note that MACs are calculated based on an input resolution of 128 \u00d7 128 with an input channel dimension of 3. The basic statistics of the three DNN architectures are summarised in Table 3.\nWe will clarify this point in Sections 3.1 and A.2."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 22:43Everyone", "Content": "Comment:\nComment3. I noticed that the authors used momentum SGD during on-device few-shot learning. What was the memory consumption from momentums? If these parameters took the majority, the authors should report a more fair comparison using vanilla SGD.\nAs the reviewer suggested, we provide a detailed breakdown of the memory footprint of different on-device training methods using two optimisers, ADAM and SGD (see Table A). In our evaluation, we employed ADAM optimiser during meta-testing as it achieves the highest accuracy compared to other optimiser types. Our memory breakdown shows that the majority of the memory footprint is due to the activation memory of the forward pass. In detail, activation memory reached its peak during the forward pass as the saved intermediate activations do not put additional memory overhead as the inference memory space can be reused during the backward pass to save the intermediate activations. Then, the optimiser incurs memory overhead. As the reviewer pointed out, the optimiser type affects the total memory footprint and associated memory reduction ratio. Yet, TinyTrain still outperforms all the on-device training baselines. We will incorporate this analysis in the additional result section in Section E.\nTable A. The detailed breakdown of the memory footprint of on-device training methods based on MCUNet according to different optimisers.\nADAM\nSGD\nMethod\nMemory Type\nMemory\nRatio\nMemory\nRatio\nLastLayer\nUpdated Weights\n0.35 MB\n-\n0.35 MB\n-\nOptimiser\n1.05 MB\n-\n0.35 MB\n-\nActivation\n0.63 MB\n-\n0.63 MB\n-\nTotal\n2.03 MB\n2.27x\n1.33 MB\n1.75x\nSparseUpdate\nUpdated Weights\n0.20 MB\n-\n0.20 MB\n-\nOptimiser\n0.60 MB\n-\n0.20 MB\n-\nActivation\n0.63 MB\n-\n0.63 MB\n-\nTotal\n1.43 MB\n1.59x\n1.03 MB\n1.35x\nTinyTrain\nUpdated Weights\n0.07 MB\n-\n0.07 MB\n-\nOptimiser\n0.20 MB\n-\n0.07 MB\n-\nActivation\n0.63 MB\n-\n0.63 MB\n-\nTotal\n0.89 MB\n1.00x\n0.76 MB\n1.00x"}]}, {"Heading": "Official Review of Submission9344 by Reviewer k57W", "Subheading": "Official ReviewbyReviewer k57W29 Oct 2023, 01:31 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors present their approach to on-device training for edge devices, i.e., Jetson Nano and Raspberry Pi Zero. Their methodology includes meta-learning based offline pre-training and partial updates during online training with a channel selection strategy based on Fisher information and a multi-objective selection metric to jointly capture channel importance, memory footprint, and computational cost.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThe authors contribute to the important area of on-device training at the edge. The novelties presented include the exploration of the capabilities of meta-learning as a means of offline pre-training, as well as a novel channel selection strategy that considers not only importance, but also goals such as computational complexity and memory footprint, which are generally important for deployment on resource-constrained targets. The authors provide solid empirical results by showing that their approach mostly outperforms other relevant state-of-the-art frameworks, namely TinyTL and MCUNet, on 9 different community datasets. Most interestingly, the authors also report results for latency and power consumption on two edge systems, the Jetson Nano and Pi Zero 2.\nWeaknesses:\nThe title of the paper states that the authors want to explore training at the extreme edge, but in my opinion systems like the Pi Zero 2 and Jetson Nano are quite \"large\" compared to most Cortex-M based MCUs, which I would consider the extreme edge. Since such systems present unique challenges, e.g. they usually cannot run Linux but rely on RTOS like MBedOS or sometimes have limited floating-point support, I would have liked to see if the techniques proposed by the authors also work in such scenarios, similar to e.g. MCUNet. [1]\nI found it hard to follow the paper at times, as it felt a bit unfocused, especially in Section 2, but the italicized summary provided at the end of each section definitely helped. Overall the paper is very dense (and many additional parts are left to the appendix), but it is not verbose.\n[1] Lin, Ji, et al. \"On-device training under 256kb memory.\" Advances in Neural Information Processing Systems 35 (2022): 22941-22954.\nSome small points:\nUse \u2018Sec.\u2019 or \u2018Section\u2019 instead of \u2018\u00a7\u2019 (at least I am always stumbling at these points)\nFig. 5a is missing.\nQuestions:\nAre the techniques presented by the authors applicable to Cortex-M based MCUs or only to the systems presented in this paper?\nIs meta-learning used only as part of pre-training or also for on-device training? It seems to me that classical transfer learning is done on-device. Do the authors think that on-device meta-learning techniques, e.g. few-shot learning, would be a feasible/reasonable approach?\nDoes the layer selection process focus only on which channels to remove or also on how many channels to remove at any given time? If not, how do the authors determine how many channels of a tensor should be updated at any given time?\nHow did you measure the energy consumption of your plattforms?\nI expected \u201cFullTrain\u201d to somehow act as an upper bound on predictive accuracy but it is not . can you elaborate on that in more detail?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nThe authors adequately address ethical and social implications of their work at the end of their manuscript.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 10:52Everyone", "Content": "Comment:\nQ1. Are the techniques presented by the authors applicable to Cortex-M based MCUs or only to the systems presented in this paper?\nWe have yet to deploy our method on ARM Cortex-M-based MCUs because no deep learning frameworks enable backpropagation to support dynamic channel selection. On-device training with the static channel selection is enabled based on the prior work [a], but its static configuration of layers and channels to be updated needs to be determined offline and cannot be dynamically changed online.\nHowever, we have implemented and successfully deployed our proposed method on Pi Zero 2 and Jetson Nano, demonstrating the feasibility of compute-, memory-, and data-efficient on-device training methodology on embedded systems. Similarly, our methodology can be applied to on-device training scenarios with extreme edge devices like Cortex-M-based MCUs given a backpropagation engine supporting dynamic layer/channel updates.\n[a] Ji Lin et al. \"On-device training under 256kb memory.\" 36th Conference on Neural Information Processing Systems (NeurIPS 2022).\nQ2. Is meta-learning used only as part of pre-training or also for on-device training? It seems to me that classical transfer learning is done on-device. Do the authors think that on-device meta-learning techniques, e.g. few-shot learning, would be a feasible/reasonable approach?\nYes, the meta-training is part of the few-shot learning (FSL) based pre-training as described in Section 2.1. Also, meta-training takes place offline before the online deployment stage (please refer to Section F.2 for the cost analysis of meta-training taking place offline).\nTinyTrain performs meta-learning, not transfer learning, on-device. as on-device adaptation is part of the process. Meta-learning (a.k.a. learning to learn) and/or few-shot learning consist of two stages, namely, meta-training and meta-testing. There are dedicated source and target datasets partitioned into sub-tasks employed by each of the two stages, as the idea is to learn in the inner loop one sub-task using the source dataset and evaluate the learned model on the target dataset. The meta-training phase aims to iteratively update the global weight initialisation through a range of sub-tasks, to be able to perform fast adaptation with a few samples when presented with new tasks. In other words, the learned DNNs are meta-tested, given a few examples of the meta-test (new) classes. In our case, this meta-test (adaptation + test) phase is performed on embedded systems. We will clarify this point further in our paper in Section 2.1.\nQ3. Does the layer selection process focus only on which channels to remove or also on how many channels to remove at any given time? If not, how do the authors determine how many channels of a tensor should be updated at any given time?\nIn a nutshell, the dynamic layer/channel selection is about selecting which layers and channels to be trained on-device rather than selecting them to be removed. In detail, given (1) the model architecture (e.g., MCUNet\u2019s backbone model contains 42 layers), (2) the memory budget, and (3) the compute budget, TinyTrain aims to select as many important channels and layers as possible without violating the memory and compute budgets.\nQ4. How did you measure the energy consumption of your platforms?\nRegarding energy consumption, we measure the total amount of energy consumed by a device during the end-to-end on-device training process. This is performed by measuring the power consumption on embedded devices using a YOTINO USB power meter and deriving the energy consumption following the equation: Energy = Power x Time. Then, to measure the end-to-end training time, we include the time elapsed to (1) load a pre-trained model and (2) perform training using all the samples (e.g. 25) for a certain number of iterations (e.g. 40). In particular, for reporting the time used for TinyTrain, we also include the time to conduct a dynamic layer/channel selection based on our proposed multi-criterion metric by computing the Fisher information on top of those to load a model and fine-tune it. Please refer to Section A.4 for more details."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 10:52 (modified: 23 Nov 2023, 06:48)EveryoneRevisions", "Content": "Comment:\nQ5. I expected \u201cFullTrain\u201d to somehow act as an upper bound on predictive accuracy but it is not. can you elaborate on that in more detail?\nIn the case of a conventional transfer learning setup where the method is given at least a few thousand labelled samples, FullTrain would serve as the upper bound on predictive accuracy. However, we deal with the more challenging problem of cross-domain (out-of-domain) few-shot learning where the total number of labelled samples is at most 500. Hence, FullTrain, i.e., updating the whole network, may result in overfitting, leading to slightly lower accuracy. However, FullTrain still serves as a strong baseline. In addition, the improved accuracy of TinyTrain is largely derived from the effectiveness of the offline meta-training. As shown in Figure 6a, TinyTrain does not outperform FullTrain without meta-training. Then, with meta-training, TinyTrain starts to exceed FullTrain\u2019s predictive accuracy. Updating the full networks could overfit due to memorization overfit or learner overfit as in [f]. It is possible the current setting is in favour of partial updates rather than FullTrain. We leave this as part of future investigation as it is more in the scope of meta-learning research.\n[f] Janarthanan Rajendran et al. \"Meta-Learning Requires Meta-Augmentation\" 34th Conference on Neural Information Processing Systems (NeurIPS 2020)\nMinor Comments: Use \u2018Sec\u2019 or \u2018Section\u2019 instead of \u00a7, and Figure 5a is missing\nFollowing the reviewer\u2019s suggestion, we will use Sec. instead of \u00a7 when referring to a section. Also, we will revise the captions of Figure 5."}]}]}, "TPZRq4FALB": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Test-time adaption, Imbalanced multi-modal learning", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "Reveal a new problem named reliability bias for multi-modal TTA, and propose a new method to achieve reliable fusion and robust adaption.", "Abstract": "Test-time adaptation (TTA) has emerged as a new paradigm for reconciling distribution shifts across domains without accessing source data. However, existing TTA methods mainly concentrate on uni-modal tasks, overlooking the complexity of multi-modal scenarios.\nIn this paper, we delve into the multi-modal test-time adaptation and reveal a new challenge named reliability bias. Different from the definition of traditional distribution shifts, reliability bias refers to the information discrepancies across different modalities derived from intra-modal distribution shifts. To solve the challenge, we propose a novel method, dubbed REliable fusion and robust ADaptation (READ). On the one hand, unlike the existing TTA paradigm that mainly repurposes the normalization layers, READ employs a new paradigm that modulates the attention between modalities in a self-adaptive way, supporting reliable fusion against reliability bias. On the other hand, READ adopts a novel objective function for robust multi-modal adaptation, where the contributions of confident predictions could be amplified and the negative impacts of noisy predictions could be mitigated. Moreover, we introduce two new benchmarks to facilitate comprehensive evaluations of multi-modal TTA under reliability bias. Extensive experiments on the benchmarks verify the effectiveness of our method against multi-modal reliability bias. The code and benchmarks are available athttps://github.com/XLearning-SCU/2024-ICLR-READ.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "Submission Number": "9339", "PDF Url": "https://openreview.net/pdf?id=TPZRq4FALB"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9339 by Area Chair 6XCe", "Subheading": "Meta ReviewbyArea Chair 6XCe05 Dec 2023, 23:25 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper presents a new approach for addressing reliability bias in multi-modal test-time adaptation. The research problem is well motivated, and the proposed method is technically sound. The paper also introduces two new benchmark datasets, and experimental results are extensive and convincing. Reviewers raised some concerns about technical details, experimental results, ablation studies, and paper writing, which have been adequately addressed in the authors' responses. In addition, some descriptions in the paper are unclear, such as: \"Comparisons between different fusion manners\", \"The blocks of the top left and bottom right denote\", and \"Pink denote the default setting.\" The authors are encouraged to proofread the paper carefully.\nJustification For Why Not Higher Score:\nReviewers raised some comments on technical details and experimental details, which should be carefully addressed in the final version.\nJustification For Why Not Lower Score:\nThis paper studies a new problem, i.e., reliability bias for multi-modal test-time adaptation. The paper is well written."}, {"Heading": "Official Review of Submission9339 by Reviewer Hrwp", "Subheading": "Official ReviewbyReviewer Hrwp30 Oct 2023, 09:23 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work proposes a method for multi-modal test-time adaption (TTA) in the presence of cross-modal reliability bias. While there are numberer of works in test-time adaption, most of them focus on single-modality tasks and few works consider the practical multi-modal scenarios. In contrast, the authors investigate the characteristics of multi-modal TTA and reveal the task-specific cross-modal reliability bias setting where the information between modalities is unbalanced during test time derived from the distribution shifts across domains in some modalities. The authors conduct analysis experiments finding that the unreliable cross-modal fusion and noisy predictions hinder the robustness against cross-modal reliability bias. As a remedy, this paper proposes a novel method dubbed reliable fusion and robust adaption (RFRA). The idea of RFRA is straightforward. A self-adaptive attention is employed to achieve reliable cross-fusion during test time and a robust loss is adopted to prevent the prediction noise from dominating the adaption process. The authors experimentally validate their method on two new benchmarks against several baselines showing reasonable improvements.\nSoundness:\n4 excellent\nPresentation:\n4 excellent\nContribution:\n4 excellent\nStrengths:\nThis paper has a good motivation. The authors focus on multi-modal test-time adaption and reveal a NEW task-specific challenge (i.e., cross-modal reliability bias) for the first time. This paper first empirically proves that the existing test-time adaption methods cannot tackle the cross-modal reliability bias problem. Furthermore, the authors also investigate the effect of adopting the existing unbalanced multi-modal learning methods to handle the cross-modal information discrepancy.  The unbalanced multi-modal learning methods handle the unbalanced multi-modal data during training time with the help of labeled data, which resembles the test-time training paradigm in the domain adaption community. The results indicate that the multi-modal learning methods cannot take superiority for the challenge. In other words, the authors support the claim that designing an elaborated method for the cross-modal reliability bias during test time is essential.\nThe authors take an in-depth study on the cross-modal reliability bias challenge and find that robust cross-modal fusion and noise resistance are essential to achieve multi-modal TTA against reliability bias. To this end, the authors design a novel method dubbed reliable fusion and robust adaption (RFRA). On the one hand, RFRA achieves reliable fusion through the self-adaptive fusion module. On the other hand, RFRA employs an elaborately designed objective function to achieve noise-robust adaption. Figs. 1 and 2 clearly depict the motivation and key idea of the paper. Overall evaluation, this paper is with strong motivation, a technical sound approach, extensive experiments, and good writing.\nWeaknesses:\nThe authors have conducted extensive evaluations on two newly constructed benchmarks regarding the most challenged setting (severity 5 in this paper), and the results indeed verify the effectiveness of handling the cross-modal reliability bias challenge. Even so, I think some challenging TTA settings that are orthogonal to the cross-modal reliability bias might help to improve the practicalness and impact of this work. First, in the practical multi-modal scenarios, the severity of distribution shifts might dynamically vary. It would make the work more practical if the authors could additionally investigate the robustness of the proposed method under the setting MIXED SEVERITIES. Furthermore, it is also common that the corruption types continually vary in the wild, resulting in the demand for continual test-time adaption (CTTA). The proposed approach would be more solid and universal if the proposed method could work in the MIXED DISTRIBUTION SHIFTS setting (i.e., continual TTA setting).\nSome details are missing. It is not clear how many layers of the attention module are used and repurposed during test time adaption in the proposed approach. And how many parameters do these self-attention layers account for? It is encouraged to supplement comparisons with the TTA baselines regarding the number of modulated parameters and the adaption time, which would make the comparisons more comprehensive.\nThe results of the default setting can be added to the ablation tables for clear clarification. In the current form, the readers need to compare the main table (1,2,3) and the ablation tables for contrast.\nI carefully read the paper and found two potential mathematical typos. $\\theta_{s}^{m}$ in Line 5, page 4. $\\partial$ in Eq. 9.\nQuestions:\nMy questions are mainly in the efficiency comparisons between the proposed SAF module and the TTA baselines, and some clarification on statements. Moreover, I wonder about the effect of the proposed method on the settings of MIXED SEVERITIES and MIXED DISTRIBUTION SHIFTS. Certainly, this is optional during the rebuttal time because the settings are out of the scope of the paper, but I think the results would strengthen this work.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "The Response to Reviewer Hrwp (Part 1)", "Subheading": "Official CommentbyAuthors18 Nov 2023, 23:04Everyone", "Content": "Comment:\nThanks for your constructive reviews and suggestions. In the following, we will answer your questions one by one.\nQ1.1: I think some challenging TTA settings that are orthogonal to the cross-modal reliability bias might help to improve the practicalness and impact of this work. First, in the practical multi-modal scenarios, the severity of distribution shifts might dynamically vary. It would make the work more practical if the authors could\nadditionally investigate the robustness of the proposed method under the setting MIXED SEVERITIES\n.\nA1.1\n: In this paper, we reveal the multi-modal reliability challenge for the TTA community and propose a reliable fusion and robust adaption (RFRA) approach to tackle the issue. Following the widely-used TTA evaluation protocol ([A, B, C, D]), we introduce different corruption types to either the video or audio modality. In the main paper, we reported the performance under different corruption types with a severity level of 5.\nIn response to your insightful suggestion, we conduct additional experiments on the Kinetics50-C benchmark, investigating the robustness of the proposed method under the setting of MIXED SEVERITY. To this end, we create test pairs for each corruption type by blending severity levels 1 through 5, resulting in 5N test pairs, where N represents the original size of the test data. After that, we shuffle the obtained test pairs and randomly choose N pairs for each corruption type. To verify the effectiveness of RFRA under the MIXED SEVERITY setting, we choose the typical TTA method Tent ([A]) and the SOTA TTA method SAR ([E]) as baselines for comparisons. The results are depicted in Fig. 8 within the revised manuscript. For your convenience, we attach the corresponding numerical result (regarding accuracy) in the following tables.\nKinetics50-C (Video Corruption, Mixed Severity)\nGauss.\nShot\nImpul.\nDefoc.\nGlass\nMot.\nZoom\nSnow\nFrost\nFog\nBrit.\nDigital\nContr.\nPix.\nJPEG\nAVG\nTent  ([A])\n58.4\n58.3\n57.0\n73.4\n71.3\n76.0\n71.7\n67.1\n68.3\n63.7\n79.5\n69.4\n74.9\n76.5\n72.9\n69.2\nSAR ([E])\n58.6\n58.2\n56.8\n73.1\n70.1\n75.6\n71.1\n66.4\n67.1\n63.8\n79.4\n69.2\n74.5\n76.5\n72.3\n68.8\nRFRA (Ours)\n59.4\n59.3\n57.9\n73.5\n72.1\n76.2\n72.6\n68.2\n70.3\n68.7\n79.4\n69.7\n75.1\n76.7\n73.7\n70.2\nKinetics50-C (Audio Corruption, Mixed Severity)\nGauss.\nTraff.\nCrowd.\nRain\nThund.\nWind\nAVG\nTent  ([A])\n76.1\n68.9\n70.3\n70.4\n68.0\n72.5\n71.0\nSAR ([E])\n76.1\n66.3\n69.1\n69.1\n68.5\n72.2\n70.2\nRFRA (Ours)\n76.5\n71.2\n71.2\n72.2\n72.6\n72.5\n72.7\nThe results indicate the effectiveness of RFRA in addressing cross-modal reliability bias across various corruption types exhibiting mixed severity levels."}, {"Heading": "The Response to Reviewer Hrwp (Part 2)", "Subheading": "Official CommentbyAuthors18 Nov 2023, 23:06 (modified: 18 Nov 2023, 23:40)EveryoneRevisions", "Content": "Comment:\nQ1.2: Furthermore, it is also common that the corruption types continually vary in the wild, resulting in the demand for continual test-time adaption (CTTA). The proposed approach would be more solid and universal if the proposed method could work\nin the MIXED DISTRIBUTION SHIFTS setting (i.e., continual TTA setting)\n.\nA1.2\n: Following the setting of continual TTA ([F, G]), we conduct additional experiments on the Kinetics50-C benchmark under the MIXED DISTRIBUTION SHIFTS setting as the reviewer suggested. In this setting, both baseline methods (Tent and SAR) alongside our RFRA continually adapt to evolving corruption types, and the averaged performance across all corruption types is reported. To ensure comprehensive evaluations, we vary the severity levels from 1 to 5. The results are summarized in Fig. 9 within the updated manuscript.\nFor your convenience, we attach the corresponding numerical result (regarding accuracy) in the following tables.\nKinetics50-C (Video Corruption, Mixed Distribution Shifts)\nSeverity 1\nSeverity 2\nSeverity 3\nSeverity 4\nSeverity 5\nAVG\nTent  ([A])\n76\n72.1\n67.1\n39.5\n38.3\n58.6\nSAR ([E])\n76.1\n71.8\n69.0\n64.3\n59.6\n68.2\nRFRA (Ours)\n76.8\n72.5\n69.0\n65.0\n61.7\n69.0\nKinetics50-C (Audio Corruption, Mixed Distribution Shifts)\nSeverity 1\nSeverity 2\nSeverity 3\nSeverity 4\nSeverity 5\nAVG\nTent  ([A])\n71.2\n70.8\n70.0\n69.4\n68.5\n70.0\nSAR ([E])\n71.0\n70.6\n70.0\n69.8\n69.3\n70.1\nRFRA (Ours)\n72.2\n71.6\n71.0\n70.4\n69.7\n71.0\nNotably, the performance of the vanilla TTA method (Tent) significantly degrades, especially under high-level mixed distribution shifts (e.g., 38.3 at Severity 5). In contrast, our RFRA showcases relative robustness against these shifts across different severity levels. It's worth highlighting that while our RFRA was primarily designed to address the challenge of multi-modal reliability bias, it demonstrates consistent performance superiority compared to SAR, an approach explicitly tailored for handling mixed distribution shifts in the continual TTA setting. This observation underscores the adaptability and resilience of RFRA beyond its initial design scope.\nQ2.1:\nSome details are missing\n. It is not clear how many layers of the attention module are used and repurposed during test time adaption in the proposed approach. And how many parameters do these self-attention layers account for?\nA2.1\n: We apologize for the initial oversight in providing comprehensive details. In the revised manuscript, we have supplemented the details of CAV-MAE ([H]) and implementation details of our RFRA. For your convenience, we attach the added statement as follows.\nIn the implementation, we use the CAV-MAE model as the backbone. CAV-MAE adopts an encoder-decoder-like architecture that is pre-trained on large-scale video data with both the contrastive learning and mask image modeling paradigms. The CAV-MAE encoder consists of 11 Transformer layers dedicated to each modality for the modality-speci\ufb01c feature extraction, alongside one Transformer layer for cross-modal fusion. The input to the CAV-MAE encoder involves 10-second video clips containing both video and corresponding audio data. For the video stream, CAVMAE samples 10 frames within each video clip and randomly selects one frame feeding into the visual Transformer encoder. For the audio stream, each 10-second audio waveform is converted into one spectrogram and then inputted to the audio Transformer encoder."}, {"Heading": "The Response to Reviewer Hrwp (Part 3)", "Subheading": "Official CommentbyAuthors18 Nov 2023, 23:08Everyone", "Content": "Comment:\nDuring the \ufb01ne-tuning phase, we maintain the visual and audio encoders of the pre-trained model and add one randomly initialized classi\ufb01cation head to them. The \ufb01ne-tuned model is regarded as the source model and denoted as \u201cSource (Stat. (LN & AF))\u201d. To investigate the robustness of different fusion manners, we design another variant of the source model that utilizes 12 Transformer layers for feature extraction and performs late fusion between the classi\ufb01cation logit of each modality. The corresponding model variant is denoted as \u201cSource ((Stat. LN) & LF)\u201d. During the test-time adaption phase, unless otherwise speci\ufb01ed, all baselines update the parameters of all normalization layers rooted in the source model, i.e., referred to as \u201cDyn. LN\u201d. In contrast, as depicted in Fig. 2, our default approach in the RFRA framework involves updating only the parameters of the last Transformer layer to ensure reliable fusion, denoted as \u201cSAF\u201d.\nQ2.2: It is encouraged to supplement\ncomparisons with the TTA baselines regarding the number of modulated parameters and the adaption time\n, which would make the comparisons more comprehensive.\nA2.2:\nThanks for your valuable suggestion. Different from most TTA methods that update the parameters of normalization layers, our RFRA repurposes the last Transformer layer of the CAV-MAE model as elaborated in Section 2 of the manuscript. In response to your insightful suggestion, we conduct additional experiments comparing the efficiency of the two paradigms. To this end, we choose the attention-fusion-based CAV-MAE model as the source model (\\textit{i.e.}, source (Stat. (LN & AF))), and conduct experiments on the VGGSound-C benchmark. We measure both the size of learnable parameters and the GPU time during the test-time adaptation phase. Results in the following table highlight that our RFRA accomplishes adaptation in less time. The efficiency of RFRA can be attributed to its module repurposing approach. Although the normalization layer updating scheme occupies fewer parameters, it demands more time for propagation.\nMethod\n#params (M)\nGPU time (14,046 pairs)\nTent (Dyn. LN)\n0.2\n209.5 seconds\nEATA (Dyn. LN)\n0.2\n207.6 seconds\nSAR (Dyn. LN)\n0.2\n286.1 seconds\nRFRA (SAF)\n1.8\n134.1 seconds\nQ3: The results of\nthe default setting can be added\nto the ablation tables for clear clari\ufb01cation. In the current form, the readers need to compare the main table (1,2,3) and the ablation tables for contrast.\nA3\n: We apologize for the confusion arising from the initial presentation. To address this concern, we've made necessary adjustments in the revised manuscript by incorporating the default setting's results, distinctly highlighted in pink, within the ablation tables (Tables 4, 5, and 6).\nQ4: I carefully read the paper and found two potential\nmathematical typos\n. $\\theta^{m}_{s}$ in Line 5, page 4. $\\partial$ in Eq. 9.\nA4\n:  Thanks for your careful reading. We apologize for the typos and have revised them in the updated manuscript.\nReference:\n[A] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In ICLR, 2021.\n[B] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self-supervision for generalization under distribution shifts. In ICML, 2020.\n[C] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Ef\ufb01cient test-time model adaptation without forgetting. In ICML, 2022.\n[D] Inkyu Shin, Yi-Hsuan Tsai, Bingbing Zhuang, Samuel Schulter, Buyu Liu, Sparsh Garg, In So Kweon, and Kuk-Jin Yoon. Mm-tta: multi-modal test-time adaptation for 3d semantic segmentation. In CVPR, 2022.\n[E] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan. Towards stable test-time adaptation in dynamic wild world. In ICLR, 2023.\n[F] Yulu Gan, Yan Bai, Yihang Lou, Xianzheng Ma, Renrui Zhang, Nian Shi, and Lin Luo. Decorate the newcomers: Visual domain prompt for continual test time adaptation. In AAAI, 2023.\n[G] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In CVPR, 2022.\n[H] Yuan Gong, Andrew Rouditchenko, Alexander H Liu, David Harwath, Leonid Karlinsky, Hilde Kuehne, and James R Glass. Contrastive audio-visual masked autoencoder. In ICLR, 2023."}]}, {"Heading": "Official Review of Submission9339 by Reviewer r3k4", "Subheading": "Official ReviewbyReviewer r3k429 Oct 2023, 01:31 (modified: 20 Nov 2023, 02:01)EveryoneRevisions", "Content": "Summary:\nThis paper delves into test-time adaption under the multi-modal setting and reveals an interesting and practical challenge, namely, reliability bias. In the wild, it is common that some modalities would suffer from distribution shifts compared to their counterparts in the source domain. As a result, the task-specific information across the modalities would be more inconsistent, thus contributing to the reliability differences for different modalities. Extensive empirical studies have been conducted to investigate the impact of the reliability bias using different cross-modal fusion strategies. To achieve robust multi-modal TTA against reliability bias,  the authors propose a novel method, dubbed reliable fusion and robust adaption (RFRA). Different from the existing TTA methods that mainly repurpose the normalization layers to achieve adaption, RFRA modulates the attention module to achieve reliable cross-modal fusion during test time. Besides, RFRA adopts a new objective function with desirable mathematical properties to combat with noise during adaption. To highlight the necessity of developing reliability-bias robust multi-modal TTA, the authors construct two new benchmarks with different settings of reliability bias based on the Kinetics and VGGSound datasets. Finally, the authors validate the effectiveness of the proposed method and give a deep analysis of the reliability bias challenge.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nRevealing a new problem. This paper studies a new and practical challenge in the context of multi-modal test-time adaptation, namely, reliability bias. In the wild, it is evitably to introduce distribution shifts in some modalities.  As a result, the task-specific information across the modalities would be more inconsistent, thus contributing to the reliability differences for different modalities. The authors design extensive experiments to investigate the influence of reliability bias under different multi-modal fusion manners and the results validate the necessity of handling reliability bias for multi-modal TTA. I think the revealed challenge would bring some insights to the TTA community.\nConstructing meaningful benchmarks. To highlight the necessity of developing reliability-bias robust multi-modal TTA, the authors construct two new benchmarks with different settings of reliability bias based on the Kinetics and VGGSound datasets. Concretely, the benchmarks consist of both video and audio modalities and each modality is with corruptions of different levels so that the reliability bias is simulated. On the one hand, the corruption on video modality follows ImageNet-C, which ensures comparison fairness. On the other hand, the incorporation of audio corruption types extends the utility of this research to the audio domain with TTA. Besides,  the benchmarks encompass diverse multi-modal tasks, including action recognition and event classification, thus providing a comprehensive evaluation and supplementing existing multi-modal test-time adaptation tasks.\nInnovative paradigm for TTA. This paper proposes a new paradigm for TTA, namely, repurposing the attention layers during test time. Intuitively, the parameter updating of normalization layers like most existing TTA methods can only handle the distribution shifts between domains. In contrast, the parameter modulation of attention layers would help learn the importance difference between modalities, resulting in the reliable fusion for multi-modal TTA. The authors perform extensive experiments to show the superiority of the proposed new paradigm against reliability bias.\nWeaknesses:\nWhile the paper is well-written, it lacks essential details about CAV-MAE, such as the number of attention layers used for fusion. As many evaluations rely on the CAV-MAE framework, providing this information is crucial for the readers and reviewers to fully grasp the methodology. Additionally, visualizing the corruption types on both video and audio modalities would enhance the paper's clarity and help readers better understand the benchmarks.\nThe paper introduces the modulation of Q, K, and V parameters to address reliability bias. However, it's not clear why the authors chose to update all parameters of Q, K, and V simultaneously. Explaining this choice and discussing the possibility of updating only the MLP parameters of Q and K would provide valuable insights. Furthermore, while the novel attention layer repurposing is effective for reliability bias, the paper should address whether this approach comes at the cost of efficiency for test-time adaptation.\nThe paper introduces a crucial hyper-parameter, the confidence threshold ($\\gamma$) in Equation 6. While this threshold is fixed in all experiments, it's essential to include ablation studies to explore the sensitivity of the proposed method to variations in this hyper-parameter. A more comprehensive analysis would provide a deeper understanding of the method's robustness.\nMinor: Some of the figures, such as Figure 1c and Figure 3b, suffer from low image clarity. Improving the quality of these figures would enhance the paper's visual presentation and make the findings more accessible to readers.\nOverall evaluation, I think this paper is above the bar of ICLR, regarding motivation and novelty.\nUpon reviewing the response, I note that my concerns have been effectively addressed. Considering the consensus of other reviewers, I wholeheartedly recommend this work with a high level of approval.\nQuestions:\nMy primary concerns revolve around the lack of comprehensive experiment details and the design of the modulation strategies, as highlighted in the weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "The Response to Reviewer r3k4 (Part 1)", "Subheading": "Official CommentbyAuthors18 Nov 2023, 23:16Everyone", "Content": "Comment:\nThanks for your valuable reviews. We would like to address your concerns one by one in the following.\nQ1.1: While the paper is well-written, it\nlacks essential details about CAV-MAE\n, such as the number of attention layers used for fusion. As many evaluations rely on the CAV-MAE framework, providing this information is crucial for the readers and reviewers to fully grasp the methodology.\nA1.1\n: We apologize for the missing details on the backbone that confuses the reviewer. In the revised manuscript, we have supplemented the details of CAV-MAE ([A]) and more implementation details of our RFRA in Section C. For your convenience, we attach the added statement as follows.\nIn the implementation, we use the CAV-MAE model as the backbone. CAV-MAE adopts an encoder-decoder-like architecture that is pre-trained on large-scale video data with both the contrastive learning and mask image modeling paradigms. The CAV-MAE encoder consists of 11 Transformer layers dedicated to each modality for the modality-speci\ufb01c feature extraction, alongside one Transformer layer for cross-modal fusion. The input to the CAV-MAE encoder involves 10-second video clips containing both video and corresponding audio data. For the video stream, CAVMAE samples 10 frames within each video clip and randomly selects one frame feeding into the visual Transformer encoder. For the audio stream, each 10-second audio waveform is converted into one spectrogram and then inputted to the audio Transformer encoder.\nDuring the \ufb01ne-tuning phase, we maintain the visual and audio encoders of the pre-trained model and add one randomly initialized classi\ufb01cation head to them. The \ufb01ne-tuned model is regarded as the source model and denoted as \u201cSource (Stat. (LN & AF))\u201d. To investigate the robustness of different fusion manners, we design another variant of the source model that utilizes 12 Transformer layers for feature extraction and performs late fusion between the classi\ufb01cation logit of each modality. The corresponding model variant is denoted as \u201cSource ((Stat. LN) & LF)\u201d. During the test-time adaption phase, unless otherwise speci\ufb01ed, all baselines update the parameters of all normalization layers rooted in the source model, i.e., referred to as \u201cDyn. LN\u201d. In contrast, as depicted in Fig. 2, our default approach in the RFRA framework involves updating only the parameters of the last Transformer layer to ensure reliable fusion, denoted as \u201cSAF\u201d.\nQ1.2: Additionally,\nvisualizing the corruption types on both video and audio modalities\nwould enhance the paper's clarity and help readers better understand the benchmarks.\nA1.2\n: Thanks for your valuable suggestion. In this work, to comprehensively evaluate modality bias, we introduce different distribution shifts on the video and audio modalities for the test sets of VGGSound ([B]) and Kinetics ([C]) datasets. For the video corruptions, we follow [D] to apply 15 kinds of corruptions into the video, and each corruption has 5 kinds of severity levels for extensive validations. Specifically, the corruptions on video modality include ''Gaussian Noise\", ''Shot Noise\", ''Impulse Noise\", ''Defocus Blur\", ''Glass Blur\", ''Motion Blur\", ''Zoom Blur\", ''Snow\", ''Frost\", ''Fog\", ''Brightness\", ''Elastic\", ''Pixelate\", ''Contrast\", and ''JPEG\". Similar to the video modality, we add 6 kinds of common audio noise (\nhttps://freesound.org\n) with 5 kinds of severity levels captured in the wild. Specifically, the corruptions on audio modality include ''Gaussian Noise\", ''Paris Traffic Noise\", ''Crowd Noise\", ''Rainy Noise\", ''Thunder Noise\" and ''Windy Noise\".\nIn response to your valuable suggestion, we've incorporated visualizations of corruption types in both video and audio modalities within the updated manuscript. Fig. 6 showcases the visualization results of various visual corruption types observed within the constructed Kinetics-C benchmark. Additionally, Fig. 7 presents the Mel spectrogram visualizations, highlighting the raw audio and the corresponding audio corruption types. For a comprehensive understanding, we encourage you to refer to the updated manuscript for an in-depth exploration of these visualizations."}, {"Heading": "The Response to Reviewer r3k4 (Part 2)", "Subheading": "Official CommentbyAuthors18 Nov 2023, 23:17Everyone", "Content": "Comment:\nQ2.1: The paper introduces the modulation of Q, K, and V parameters to address reliability bias. However, it's not clear why the authors chose to update all parameters of Q, K, and V simultaneously.\nExplaining this choice and discussing the possibility of updating only the MLP parameters of Q and K\nwould provide valuable insights.\nThanks for your constructive comment. In our default approach, we update $W_{{\\Theta}^h}$ and $B_{{\\Theta}^h}$ $(h\\in {q,k,v})$ within the last Transformer layer of the source model to ensure reliable fusion.\nIn response to your valuable comment, we conduct additional experiments to explore the impact of different repurposing schemes. To this end, we design three variants: one that updates only the query and key projection layers, another that updates only the value projection layers, and a third that updates the final classification head. Results are summarized in Table 8 within the revised manuscript. For your convenience, we attach the corresponding results in the following table.\nCorruption\nSource\nQK\nV\nMLP\nQKV (ours)\nVideo-Fog\n46.7\n51.7\n53.6\n49.1\n57.4\nAudio-Traffic\n65.5\n68.8\n67.2\n66.7\n69.0\nResults in the following table illustrate that the default setting, updating the query, key, and value projection layers simultaneously, exhibits significant performance superiority. Modulating the classification head demonstrates minimal effectiveness (e.g., from $46.7$ to $49.1$). Conversely, the attention modulation scheme achieves adaptive fusion between discrepant modalities, mitigating the multi-modal reliability bias problem (e.g., from $46.7$ to $51.7$). Moreover, modulation on the query, key, and value projection layers introduces additional parameters for reliable fusion, resulting in further improvements in robustness (e.g., from $46.7$ to $57.4$).\nQ2.2: Furthermore, while the novel attention layer repurposing is effective for reliability bias, the paper should address\nwhether this approach comes\nat the cost of efficiency for test-time adaptation\n.\nThanks for your valuable suggestion. Different from most TTA methods that update the parameters of normalization layers, our RFRA repurposes the last Transformer layer of the CAV-MAE model as elaborated in Section 2 of the manuscript.\nIn response to your insightful suggestion, we conduct additional experiments comparing the efficiency of the two paradigms. To this end, we choose the attention-fusion-based CAV-MAE model as the source model (\\textit{i.e.}, source (Stat. (LN & AF))), and conduct experiments on the VGGSound-C benchmark. We measure both the size of learnable parameters and the GPU time during the test-time adaptation phase. Results are summarized in Table 7 within the revised manuscript. For your convenience, we attach the corresponding results in the following table.\nMethod\n#params (M)\nGPU time (14,046 pairs)\nTent (Dyn. LN)\n0.2\n209.5 seconds\nEATA (Dyn. LN)\n0.2\n207.6 seconds\nSAR (Dyn. LN)\n0.2\n286.1 seconds\nRFRA (SAF)\n1.8\n134.1 seconds\nThe results underscore that RFRA achieves adaptation more efficiently, primarily due to its module repurposing approach. While the normalization layer updating scheme requires fewer parameters, it necessitates more time for propagation.\nQ3: The paper introduces a crucial hyper-parameter, the confidence threshold ($\\gamma$) in Equation 6. While this threshold is fixed in all experiments, it's essential to include ablation studies to\nexplore the sensitivity of the proposed method to variations in this hyper-parameter\n. A more comprehensive analysis would provide a deeper understanding of the method's robustness.\nThanks for your comment. In response to your concern, we investigate the influence of the only hyper-parameter (\\textit{i.e.,} threshold $\\gamma$ in Eq. 6) in our approach. To this end, we vary $\\gamma$ in the range of $[0.1, 0.2, 0.3, e^{-1}, 0.4, 0.5]$ and perform corresponding experiments on the Kinetics50-C benchmark with fog and traffic corruptions. Results are depicted in Fig. 10 within the revised manuscript. For your convenience, we attach the corresponding numerical results in the following table.\nThreshold ($\\gamma$ in Eq. 6)\n0.1\n0.2\n0.3\n$e^{-1}$\n0.4\n0.5\nVideo-Fog\n54.2\n56\n56.8\n57.4\n57.5\n57.7\nAudio-Traffic\n69.2\n69.1\n69.1\n69.0\n69.3\n69.0\nThe results illustrates the stability of RFRA across varying threshold values of $\\gamma$."}, {"Heading": "The Response to Reviewer r3k4 (Part 3)", "Subheading": "Official CommentbyAuthors18 Nov 2023, 23:18Everyone", "Content": "Comment:\nQ4: Minor: Some of the figures, such as Figure 1c and Figure 3b, suffer from\nlow image clarity\n. Improving the quality of these figures would enhance the paper's visual presentation and make the findings more accessible to readers.\nWe appreciate your feedback. In the revised manuscript, we have enhanced the quality of these figures to improve their visual presentation.\nReference:\n[A] Yuan Gong, Andrew Rouditchenko, Alexander H Liu, David Harwath, Leonid Karlinsky, Hilde Kuehne, and James R Glass. Contrastive audio-visual masked autoencoder. In ICLR, 2023.\n[B] Honglie Chen, Weidi Xie, Andrea Vedaldi, and Andrew Zisserman. Vggsound: A large-scale audiovisual dataset. In ICASSP, 2020.\n[C] Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, et al. The kinetics human action video dataset. arXiv:1705.06950, 2017.\n[D] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In ICLR, 2019."}, {"Heading": "Thank you for increasing your score!", "Subheading": "Official CommentbyAuthors20 Nov 2023, 08:34Everyone", "Content": "Comment:\nThank you for upgrading your score! We appreciate the time and effort you dedicated to reviewing this work."}]}, {"Heading": "Official Review of Submission9339 by Reviewer 9FmQ", "Subheading": "Official ReviewbyReviewer 9FmQ28 Oct 2023, 01:24 (modified: 22 Nov 2023, 03:35)EveryoneRevisions", "Content": "Summary:\nThis paper introduces a novel approach for addressing reliability bias in multi-modal test-time adaptation (TTA), a challenge arising from information disparities between modalities due to distribution shifts. To investigate the impact of reliability bias, the authors conduct comprehensive analyses involving various multi-modal fusion strategies and state-of-the-art TTA methods. The results underscore two pivotal aspects of effective TTA against reliability bias: dynamic information integration across modalities and noise-resilient adaptation across domains. To tackle these challenges, the authors devise a self-adaptive attention module to facilitate reliable cross-modal fusion and a confidence-aware loss function to ensure robustness against noisy predictions. Furthermore, this paper contributes two benchmark datasets focusing on multi-modal action recognition and event classification. Extensive comparison experiments against existing TTA methods and imbalanced multi-modal learning methods validate the effectiveness of the proposed method.\nSoundness:\n4 excellent\nPresentation:\n3 good\nContribution:\n4 excellent\nStrengths:\nThis paper studies a new challenge (i.e., reliability bias) for multi-modal test-time adaption. Test-time adaption methods aim at adopting the pre-trained model from the source domain to the target domain in real-time and most existing of them focus on single-modality tasks against domain shifts. On the one hand, this paper takes the more complex multi-modal scenarios into consideration. On the other hand, the authors study and tackle the reliability bias challenge.\nThe authors conduct extensive experiments to validate the importance of developing robust TTA methods against reliability bias. On the one hand, the existing cross-modal fusion methods (late fusion, attention-based fusion, etc.) would suffer from reliability bias and cannot achieve reliable cross-modal fusion. On the other hand, the existing TTA method cannot completely reconcile the distribution shifts by updating the parameters of normalization layers, leading to surviving reliability bias across modalities. Furthermore, the authors show that simply handling reliability bias during test time takes more superiority compared to the imbalanced multi-modal learning methods that alter the training process to handle the problem.\nThe proposed method is novel and technically sound. First, the authors focus on the characteristics of multi-modal TTA and design the self-adaptive attention module that repurposes the attention layers during test time for achieving reliable cross-modal fusion. I think the design would inspire the community to design task-specific parameter modulation instead of solely updating the parameters of normalization layers following most existing methods. Second, to achieve robustness against heavy noise during adaption, the authors propose the robust loss function which not only eliminates the influence of noisy predictions but also boosts utilization of the clean predictions with theoretical guarantees.\nWeaknesses:\nAlthough this paper is well-motivated and extensively validated, I still have the following concerns or suggestions, hoping to make the paper more clear and solid.\nThe experiment results are mainly obtained under the setting of severity 5. To establish the method's generality, it is encouraged to expand the empirical results across a spectrum of scenarios, including different severity levels. A broader array of experiments, encompassing various severity levels, would not only fortify the method's reliability but also enhance the comprehensiveness of this study. Moreover,  it would be beneficial to evaluate how the method performs in the context of test-time adaptation (TTA) under unbiased reliability conditions. Specifically, investigating the method's effectiveness in both (i.d.d. and non-i.d.d. scenarios would render it more practical and versatile.\nThe paper contains extensive analysis and experiments, but some settings require further clarification. For instance, it's not entirely clear what \"Attention A-V\" means in Figure 4 and how the results demonstrate the method's robustness. In the analysis of Figure 5, claims are made about the importance of maintenance between audio and video modalities, but the contrast with clean results is not evident. Additional clarification or supplementary results are needed to support these claims.\nThere are a few typos and vague statements in the paper, such as \"traf\ufb01c noise in the audio modality\" in the caption of Figure 1, \"information bias\" on Page 2, and inconsistent notations like \"(Stat. LN) & AF\" or \"Stat. (LN & AF)\" in Tables 1-3. These should be corrected for clarity and consistency.\nQuestions:\nMy questions mainly lie in some unclear experiment analysis and  the generalizability of the proposed approach to a broader range of severity levels.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "The Response to Reviewer 9FmQ (Part 1)", "Subheading": "Official CommentbyAuthors18 Nov 2023, 23:24Everyone", "Content": "Comment:\nThanks for the insightful reviews. We will answer your questions one by one in the following.\nQ1.1: The experiment results are mainly obtained under the setting of severity 5. To establish the method's generality, it is encouraged to\nexpand the empirical results across a spectrum of scenarios, including different severity levels\n. A broader array of experiments, encompassing various severity levels, would not only fortify the method's reliability but also enhance the comprehensiveness of this study.\nA1.1:\nThanks for your valuable suggestions. In the submission, we have reported the comparison results on VGGSound-C and Kinetics50-C benchmarks under 15 visual corruption and 6 audio corruption with a severity level of 5.\nIn response to your constructive feedback, we conduct additional experiments to assess our RFRA's performance across different corruption types at severity level 3. We've summarized these results in Tables 10-12 within the revised manuscript. For your convenience, the corresponding results are provided in the following tables.\nKinetics50-C (Video Corruption, Severity Level 3)\nGauss.\nShot\nImpul.\nDefoc.\nGlass\nMot.\nZoom\nSnow\nFrost\nFog\nBrit.\nDigital\nContr.\nPix.\nJPEG\nAVG\nSource ((Stat. LN) & LF)\n46.6\n47.8\n46.9\n71\n63.4\n74.4\n68.1\n62.1\n58.9\n65.4\n77.6\n68.2\n76.1\n77.1\n73\n65.1\n+ MM-TTA (Dyn. LN)\n48.8\n50.8\n50.6\n66\n60.6\n70.9\n63.5\n59.8\n56.3\n58.1\n75.1\n59.3\n72.2\n74.7\n68.7\n62.4\n+ Tent (Dyn. LN)\n44.6\n46.6\n44.9\n71.2\n64.6\n74.6\n68.7\n62.3\n56.5\n65.2\n77.9\n68.5\n76.3\n77\n73.2\n64.8\n+ EATA (Dyn. LN)\n46.8\n48.2\n47.3\n70.8\n63.9\n74.6\n68.4\n62.3\n58.9\n65.4\n77.8\n68.1\n76\n77\n73\n65.2\n+ SAR (Dyn. LN)\n46.7\n47.9\n47\n70.6\n63.3\n74.4\n68.2\n62.3\n58.9\n65.2\n77.7\n68\n76\n77\n72.7\n65.1\n+ RFRA (Dyn. LN)\n49.3\n50\n49.4\n71.1\n65.7\n75\n70.3\n64.5\n61.5\n67.1\n78.1\n69.5\n76.6\n77.2\n73.7\n66.6\nSource (Stat. (LN&AF))\n54.1\n54.8\n54.6\n73.5\n68.3\n76.6\n71.5\n69.2\n64.7\n69.5\n79.3\n72.1\n77.6\n79.4\n75.4\n69.4\n+ Tent (Dyn. LN)\n54.2\n55.1\n55.2\n73.6\n69.6\n76.8\n71.9\n69.5\n65.6\n70.2\n79.4\n72.9\n78.3\n79.2\n75.3\n69.8\n+ EATA (Dyn. LN)\n54.4\n54.9\n55\n73.4\n69.1\n76.5\n71.6\n69.2\n65.1\n69.5\n79.5\n72.3\n77.7\n79.1\n75.2\n69.5\n+ SAR (Dyn. LN)\n54.2\n54.8\n55\n73.1\n68.2\n76.4\n71.1\n69.1\n64.8\n69.4\n79.1\n72\n77.4\n79.1\n75\n69.2\n+ RFRA (SAF)\n56.1\n56.9\n56.4\n73.9\n70.5\n76.6\n72.8\n70\n68.1\n70.8\n79.3\n73.3\n78.2\n79.6\n75.6\n70.5"}, {"Heading": "The Response to Reviewer 9FmQ (Part 2)", "Subheading": "Official CommentbyAuthors18 Nov 2023, 23:25Everyone", "Content": "Comment:\nVGGSound-C (Video Corruption, Severity Level 3)\nGauss.\nShot\nImpul.\nDefoc.\nGlass\nMot.\nZoom\nSnow\nFrost\nFog\nBrit.\nDigital\nContr.\nPix.\nJPEG\nAVG\nSource ((Stat. LN) & LF)\n45.6\n45.3\n45.4\n55.7\n54\n57.6\n55.4\n55.1\n53.7\n53.4\n58.5\n53.9\n58.3\n58.1\n56.5\n53.8\n+ MM-TTA (Dyn. LN)\n18.6\n17.5\n15.8\n50.4\n44.3\n51.8\n48.4\n41.4\n28.1\n46.5\n52\n46.2\n52\n52\n51.6\n41.1\n+ Tent (Dyn. LN)\n19.8\n17.2\n18.4\n55.9\n55.3\n57.3\n55.9\n55.3\n45.3\n34.8\n58.4\n56.4\n58.4\n58.4\n57.1\n46.9\n+ EATA (Dyn. LN)\n45.8\n45.6\n45.7\n56.3\n55.2\n58\n56\n55.8\n54.4\n54.5\n58.9\n55.3\n58.8\n58.5\n57.1\n54.4\n+ SAR (Dyn. LN)\n45.4\n45.2\n45.2\n55.8\n54.3\n57.7\n55.6\n55.3\n53.9\n53.7\n58.5\n54.2\n58.5\n58.2\n56.7\n53.9\n+ RFRA (Dyn. LN)\n46\n46\n46.3\n53\n52.9\n56.3\n54.1\n53.8\n53.3\n53\n58\n53.8\n57.7\n56.8\n55.1\n53.1\nSource (Stat. (LN&AF))\n54.7\n54.6\n54.7\n59.3\n58.4\n60.4\n59\n58.3\n57.4\n57.8\n61.3\n58\n61\n60.9\n60\n58.4\n+ Tent (Dyn. LN)\n54.4\n54.3\n54.4\n58.8\n57.8\n59.7\n58.5\n57.6\n56.9\n58.6\n60.6\n58\n61\n60.9\n60\n58.1\n+ EATA (Dyn. LN)\n54.8\n54.6\n54.8\n59.4\n58.4\n60.3\n59.1\n58.2\n57.5\n58.7\n61.3\n58.9\n61.1\n60.8\n60.1\n58.5\n+ SAR (Dyn. LN)\n54.8\n54.6\n54.7\n59.4\n58.3\n60.3\n58.9\n58.3\n57.5\n58.2\n61.2\n58.3\n60.9\n60.8\n59.9\n58.4\n+ RFRA (SAF)\n55.3\n55.4\n55.4\n60\n59.1\n61.1\n59.8\n59.2\n58.5\n59.3\n61.9\n59.8\n61.5\n61.5\n60.7\n59.2\nKinetics50-C (Audio Corruption, Severity Level 3)\nGauss.\nTraff.\nCrowd.\nRain\nThund.\nWind\nAvg.\nSource ((Stat. LN) & LF)\n74.2\n68.8\n68.7\n66.7\n71.6\n70.4\n70.1\n+ MM-TTA (Dyn. LN)\n72.8\n69.6\n68.9\n68.7\n70.7\n70.3\n70.2\n+ Tent (Dyn. LN)\n74.2\n69\n69.6\n64.8\n71.9\n71.1\n70.1\n+ EATA (Dyn. LN)\n74.1\n68.8\n69.1\n67.3\n71.8\n70.6\n70.3\n+ SAR (Dyn. LN)\n73.9\n68.8\n68.9\n66.7\n71.6\n70.3\n70\n+ RFRA (Dyn. LN)\n74.2\n69.6\n70\n69\n72.7\n70.8\n71\nSource (Stat. (LN&AF))\n75.9\n64.4\n68.7\n70.3\n67.9\n70.3\n69.3\n+ Tent (Dyn. LN)\n73.9\n67.4\n69.2\n69.3\n69\n72.1\n70.1\n+ EATA (Dyn. LN)\n76\n65.7\n68.9\n69.8\n69.1\n72.1\n70.3\n+ SAR (Dyn. LN)\n76\n64.6\n68.7\n69.3\n68.6\n72.2\n69.9\n+ RFRA (SAF)\n76.4\n69.6\n70.8\n72\n72.6\n72.3\n72.3"}, {"Heading": "The Response to Reviewer 9FmQ (Part 3)", "Subheading": "Official CommentbyAuthors18 Nov 2023, 23:26Everyone", "Content": "Comment:\nVGGSound-C (Audio Corruption, Severity Level 3)\nGauss.\nTraff.\nCrowd.\nRain\nThund.\nWind\nAvg.\nSource ((Stat. LN) & LF)\n39.6\n23.8\n25\n28.7\n36.5\n26.9\n30.1\n+ MM-TTA (Dyn. LN)\n13.8\n7.1\n7.6\n16.2\n10.6\n5.4\n10.1\n+ Tent (Dyn. LN)\n11.2\n4.1\n3.4\n5.2\n12.8\n5.1\n7.0\n+ EATA (Dyn. LN)\n40.3\n23.9\n24.7\n28.7\n36.5\n26.9\n30.2\n+ SAR (Dyn. LN)\n39.9\n23.6\n24.9\n28.7\n36.4\n26.8\n30\n+ RFRA (Dyn. LN)\n44.5\n29.9\n31.5\n33.2\n37\n31.2\n34.6\nSource (Stat. (LN&AF))\n42.1\n29.4\n19.5\n27.6\n31.2\n29.4\n29.9\n+ Tent (Dyn. LN)\n8.1\n4\n2.3\n4.7\n7.8\n6.1\n5.5\n+ EATA (Dyn. LN)\n46.7\n30.5\n28\n31.4\n35.4\n33.8\n34.3\n+ SAR (Dyn. LN)\n43.1\n17.3\n8.3\n29\n31.6\n30.5\n26.6\n+ RFRA (SAF)\n47.3\n32.7\n29.9\n33.2\n38.3\n33.7\n35.8\nQ1.2: Moreover, it would be beneficial to evaluate how the method performs in the context of test-time adaptation (TTA)\nunder unbiased reliability conditions\n. Specifically, investigating the method's effectiveness in both (i.d.d. and non-i.d.d. scenarios would render it more practical and versatile.\nA1.2:\nThanks for your comment. We understand your concern and conduct additional experiments in the context of test-time adaptation (TTA) under unbiased reliability conditions. Specifically, we directly adapt RFRA and other baseline methods into the test sets of the VGGSound and Kinetics datasets without adding any corruptions. Results are summarized in Table 9 within the revised manuscript. For your convenience, we attach the corresponding results in the following table.\nMethod\nSource (Stat. (LN&AF))\nTent\nEATA\nSAR\nRFRA\nVGGSound\n63.3\n62.6\n63.1\n63.1\n63.5\nKinetics50\n82.3\n82.1\n82.3\n82.3\n82.2\nThe results indicate that the robustness of RFRA doesn't compromise the performance of the original target domain. In essence, RFRA remains effective even in scenarios where the presence of distribution shifts is uncertain.\nQ2.1: The paper contains extensive analysis and experiments, but some settings require further clarification. For instance, it's not entirely clear\nwhat \"Attention A-V\" means\nin Figure 4 and\nhow the results demonstrate the method's robustness\n.\n**A2.1: **\nWhat \"Attention A-V\" means.\n\"Attention A-V\" denotes the cross-attention from the audio modality to the video modality. Specifically, in Figure 4, the attention values between modalities, denoted as \"Attention X-Y\" (X, Y $\\in$ {A, V}), are derived using Equation 4 from the manuscript:\n$$\\mathbf{A}=\\operatorname{Softmax}\\left(\\frac{\\mathbf{Q} \\mathbf{K}^T}{\\sqrt{d}}\\right)$$.\nFor instance, \"Attention X-X\" represents the self-attention, computed by setting both the query ($\\mathbf{Q}$) and key ($\\mathbf{K}$) as the tokens of modality X. Meanwhile, \"Attention X-Y\" (X, Y $\\in$ {A, V}) corresponds to the configuration where the query and key tokens correspond to modality X and modality Y, respectively.\nHow the results demonstrate the robustness.\nLarger attention values indicate a greater focus on a particular modality during cross-modal fusion. In Figure 4, \"Tent\" displays slightly better robust fusion effects compared to \"AF,\" potentially due to the narrowed domain gap achieved by repurposing the LN. In contrast, our method demonstrates significant improvements in reliability estimation (attention values) for both video and audio bias situations across varying severities. This highlights the necessity of the self-adaptive attention-based fusion paradigm for multi-modal TTA, as it enhances the model's capability to adapt to reliability bias scenarios."}, {"Heading": "The Response to Reviewer 9FmQ (Part 4)", "Subheading": "Official CommentbyAuthors18 Nov 2023, 23:27 (modified: 22 Nov 2023, 02:04)EveryoneRevisions", "Content": "Comment:\nQ2.2: In the analysis of Figure 5, claims are made about the importance of maintenance between audio and video modalities, but\nthe contrast with clean results is not evident\n. Additional clarification or supplementary results are needed to support these claims.\nThanks for your comment. We have supplemented more visualization results on different baselines for comparisons. Specifically, Fig. 11 in the Appendix of the manuscript shows the attention matrixes of the source model with vanilla attention-based fusion (AF), and the model adapted by Tent with dynamic LN.\nQ3: There are a few\ntypos and vague statements\nin the paper, such as \"traf\ufb01c noise in the audio modality\" in the caption of Figure 1, \"information bias\" on Page 2, and inconsistent notations like \"(Stat. LN) & AF\" or \"Stat. (LN & AF)\" in Tables 1-3. These should be corrected for clarity and consistency.\nWe appreciate your feedback on the typos. In the updated version, we have carefully revised the typos."}, {"Heading": "Inquiry about further concerns/questions", "Subheading": "Official CommentbyAuthors22 Nov 2023, 02:04Everyone", "Content": "Comment:\nDear reviewer 9FmQ,\nAs the author/reviewer discussion will draw to a close soon, we would like to know if our response has addressed your concerns and questions. If you have any further concerns or suggestions for the paper or our rebuttal, please let us know. We would be happy to engage in further discussion and manuscript improvement.\nThank you again for the time and effort you dedicated to reviewing this work."}, {"Heading": "Official Comment by Reviewer 9FmQ", "Subheading": "Official CommentbyReviewer 9FmQ22 Nov 2023, 03:34Everyone", "Content": "Comment:\nAfter reading the comments from other reviewer and the response from the authors, I would like to promote my score to 'accept'. This paper deserves to be presented on ICLR 2024."}, {"Heading": "Thank you for increasing your score!", "Subheading": "Official CommentbyAuthors22 Nov 2023, 06:40Everyone", "Content": "Comment:\nWe sincerely appreciate your positive recognition and assessment of our work!"}]}, {"Heading": "Official Review of Submission9339 by Reviewer kzfx", "Subheading": "Official ReviewbyReviewer kzfx27 Oct 2023, 22:36 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper studies the problem of multi-modal test-time adaption (TTA) under the challenge of reliability bias, which refers to the information discrepancies across different modalities due to the distribution shifts between domains. The paper proposes a novel method, RFRA, which consists of two modules: a self-adaptive attention module for reliable fusion across modalities, and a confidence-aware loss function for robust adaption. The paper also provides two new benchmarks for multi-modal TTA with reliability bias based on Kinetics and VGGSound datasets. The paper shows that RFRA outperforms several state-of-the-art TTA methods on these benchmarks under various corruptions.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n4 excellent\nStrengths:\nThis paper is well-written, well-organized, and easy to follow.\nThe paper addresses a novel and important problem, i.e.,  multi-modal TTA with reliability bias, which has not been well-studied in the literature.  Accordingly, the paper proposes an effective method, RFRA, which leverages self-adaptive attention and confidence-aware loss to achieve reliable fusion and robust adaption across modalities.   Moreover, the confidence-aware loss is simple but effective and enjoy the non-monotonous gradient property.\nThe paper provides two new benchmarks for multi-modal TTA with reliability bias, which could facilitate future research on this topic. The paper conducts extensive experiments and ablation studies on these benchmarks to demonstrate the effectiveness and superiority of RFRA over existing TTA methods.\nWeaknesses:\nThe paper lacks some experimental details, such as clarifying the terms \u201cStatical\u201d and \u201cDynamic\u201d in Table 1 and explaining the distinctions between the proposed Self-Adaptive Attention and traditional self-attention. It is unclear what these terms mean and how they affect the performance of different methods. The paper should provide more definitions and discussions on these terms. Moreover, the paper should elaborate on how the Self-Adaptive Attention differs from the conventional self-attention in terms of design, implementation, and advantages.\nThe confidence threshold $gamma$ work as the important parameter in the confidence-aware loss.  However, the influence of the confidence threshold $\\gamma$ on TTA performance is not explored, and it would be beneficial to understand its role more explicitly. The paper could conduct more experiments and analysis to show how different values of $\\gamma$ affect the accuracy and robustness of TTA. The paper could provide provide some insights on how to choose an appropriate value of $\\gamma$.\nHow does the attention value in Figure 4 calculated? Some explanation is needed. The paper should provide more details on how to compute the attention value for each modality pair in Figure 4.\nAn outlying problem, how does the audio information used in autonomous vehicle? As most scenarios of autonomous vehicle might use the visual sensor and could your method used in such case?\nThere is a typographical error in Eq. (4); \u201cA\u201d should be bold. This is a minor mistake that can be easily corrected.\nQuestions:\nThe primary questions for the rebuttal primarily arise from the \"weaknesses\" section. It would be highly appreciated if the authors could provide further explanations regarding the experiments and address the raised concerns, which will strengthen the paper. Overall, I recommend accepting this paper.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "The Response to Reviewer kzfx (Part 1)", "Subheading": "Official CommentbyAuthors18 Nov 2023, 23:31Everyone", "Content": "Comment:\nThanks for the detailed comments. In the following, we will answer your questions one by one.\nQ1.1: The paper lacks some experimental details, such as\nclarifying the terms \u201cStatical\u201d and \u201cDynamic\u201d\nin Table 1 and explaining the distinctions between the proposed Self-Adaptive Attention and traditional self-attention. It is unclear what these terms mean and how they affect the performance of different methods. The paper should provide more definitions and discussions on these terms.\nMoreover, the paper should\nelaborate on how the Self-Adaptive Attention differs from the conventional self-attention\nin terms of design, implementation, and advantages.*\nA1.1:\nWe apologize for any confusion regarding these terms. Allow us to elaborate:\n\"Statical\" and \"Dynamic\"\n. \"Statical\" denotes the state where the layer normalization (LN) and attention-based fusion (AF) layers remain frozen during the test-time phase. Conversely, \"Dynamic\" implies the updating of parameters within all normalization layers rooted in the source model as most existing TTA methods do in the test-time phase.\nSelf-Adaptive Attention v.s. traditional self-attention\n. The traditional self-attention mechanism usually keeps the parameters inherited from the source model and performs information integration across modalities. Apparently, the distribution shift between training and test-time data might hinder the similarity estimation between tokens. As a result, reliable fusion on biased modalities cannot be guaranteed. Instead, we hope that the model could focus more on the unbiased modalities and avoid the interoperation from the bias. To this end, we propose repurposing the cross-modal attention-based fusion layers in a self-adaptive way. As depicted in Figure 2 of the manuscript, our default approach in the RFRA framework involves updating only the parameters of the last Transformer layer (referred to as the AF layer) in a self-adaptive manner. We dub this paradigm as self-adaptive attention-based fusion, abbreviated as \"SAF\". SAF essentially repurposes the standard AF operation by modulating the parameters within the attention layer with the guidance of the proposed objective function.\nQ2: The confidence threshold gamma work as the important parameter in the confidence-aware loss. However, the influence of the confidence threshold $\\gamma$ on TTA performance is not explored, and it would be beneficial to understand its role more explicitly. The paper could conduct more experiments and analysis to\nshow how different values of $\\gamma$ affect the accuracy and robustness of TTA\n. The paper could provide provide some insights on how to choose an appropriate value of $\\gamma$.\nA2:\nThanks for your comment. In response to your concern, we investigate the influence of the only hyper-parameter (\\textit{i.e.,} threshold $\\gamma$ in Eq. 6) in our approach. To this end, we vary $\\gamma$ in the range of $[0.1, 0.2, 0.3, e^{-1}, 0.4, 0.5]$ and perform corresponding experiments on the Kinetics50-C benchmark with fog and traffic corruptions. Results are depicted in Fig. 10 within the revised manuscript. For your convenience, we attach the corresponding numerical results in the following table.\nThreshold ($\\gamma$ in Eq. 6)\n0.1\n0.2\n0.3\n$e^{-1}$\n0.4\n0.5\nVideo-Fog\n54.2\n56\n56.8\n57.4\n57.5\n57.7\nAudio-Traffic\n69.2\n69.1\n69.1\n69.0\n69.3\n69.0\nThe results illustrate the stability of RFRA across varying threshold values of $\\gamma$.\nQ3: How does the attention value in Figure 4 calculated? Some explanation is needed. The paper should provide more\ndetails on how to compute the attention value for each modality pair in Figure 4\n.\nA3:\nThanks for your comment. In Figure 4, the attention values between modalities, denoted as \"Attention X-Y\" (X, Y $\\in$ {A, V}), are calculated using Equation 4 from the manuscript:\n$$\\mathbf{A}=\\operatorname{Softmax}\\left(\\frac{\\mathbf{Q} \\mathbf{K}^T}{\\sqrt{d}}\\right)$$.\nFor instance, \"Attention X-X\" represents the self-attention, computed by setting both the query ($\\mathbf{Q}$) and key ($\\mathbf{K}$) as the tokens of modality X. Meanwhile, \"Attention X-Y\" (X, Y $\\in$ {A, V}) corresponds to the configuration where the query and key tokens come from modality X and modality Y, respectively."}, {"Heading": "The Response to Reviewer kzfx (Part 2)", "Subheading": "Official CommentbyAuthors18 Nov 2023, 23:32Everyone", "Content": "Comment:\nQ4: An outlying problem,\nhow does the audio information used in autonomous vehicle\n? As most scenarios of autonomous vehicle might use the visual sensor and could your method used in such case?\nA4:\nThanks for your comment. It's crucial to note that the multi-modal reliability bias revealed in this study includes but not limited to autonomous vehicles and can manifest across various modalities in diverse scenarios. While the majority of autonomous vehicles primarily incorporate sensors like cameras, radars, and lidars, the potential utilization of microphones and audio data in autonomous driving has received increasing attention. Interestingly, audio information could significantly complement the capabilities of the autonomous system. For instance, as highlighted in [A], audio input aids in emergency vehicle recognition. This underlines the broader applicability of the multi-modal reliability bias challenge and its potential implications for the wider community.\nQ5: There is a\ntypographical error\nin Eq. (4); \u201cA\u201d should be bold. This is a minor mistake that can be easily corrected.\nA5:\nWe appreciate your feedback on the notation typos. In the updated version, we have carefully revised the typos.\n[A] Ivan Kharitonov. \"Survey on Acoustic Sensors in Self-Driving Cars.\" 2023,\nhttps://hackernoon.com/survey-on-acoustic-sensors-in-self-driving-cars](https://hackernoon.com/survey-on-acoustic-sensors-in-self-driving-cars)"}]}]}, "UPyLDIVBNP": {"paper_info": {"Primary Area": "general machine learning (i.e., none of the above)", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Initialization, Idetity Matrix, Dynamic Isometry", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "A initialization method for fast and stable training of deep neural networks based on identity matrix.", "Abstract": "Deep neural networks (DNNs) have achieved numerous remarkable accomplishments in practice. The success of these networks hinges on effective initialization methods, which are vital for ensuring stable and rapid convergence during training. Recently, initialization methods that maintain identity transition within layers have shown good efficiency in network training. These techniques (e.g., Fixup) set specific weights to zero to achieve identity control. However, settings of remaining weight (e.g., Fixup uses random values to initialize non-zero weights) will affect inductive bias that is achieved only by a zero weight, which may be harmful to training. Addressing this concern, we introduce fully identical initialization (IDInit), an innovative method that preserves identity in both the main and sub-stem layers of residual networks. IDInit employs a padded identity-like matrix to overcome rank constraints in non-square weight matrices. Furthermore, we show a convergence problem of an identity matrix can be solved by adding a momentum term into the optimizer. Additionally, we explore enhancing the universality of IDInit by processing higher-order weights and addressing dead neuron problems. IDInit is a straightforward yet effective initialization method, promising improved convergence, stability, and performance across various settings, including large-scale datasets and deep models. It stands as a novel solution for initializing non-standard weight matrices, offering significant advantages in network training.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9336", "PDF Url": "https://openreview.net/pdf?id=UPyLDIVBNP"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9336 by Area Chair jDGQ", "Subheading": "Meta ReviewbyArea Chair jDGQ21 Dec 2023, 09:46 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper proposes a novel initialization method for neural networks designed to improve performance and convergence during training. The reviewers are divided, with the potential utility and simplicity of the proposed method being praised, but with significant concerns about Theorem 3.1 and the patch-maintain scheme. After discussion with the reviewers (including private iteration with FbDy and GXx1) and discussion with the Senior Area Chair, it seems like concerns persist (see message below from FbDy). I therefore must recommend rejection and suggest the authors consider these points and revise (either in content or exposition) in a future version.\nIdentical input features (in their case, copying the input features to span over entire hidden dimension) do not promote feature diversity, which prevents rank from growing. I can not verify the correctness of the last comment by author as it still clarification on the last equation to conclude that the rank is strictly larger than D_0. It seems the authors not fully understand Theorem 3.1 given the errors I pointed out about computing gradients given batched gradient descent and the rank of vector outer product. Thus I would like to remain my score and recommendation.\nJustification For Why Not Higher Score:\nSee meta-review.\nJustification For Why Not Lower Score:\nn/a"}, {"Heading": "General Response", "Subheading": "Official CommentbyAuthors20 Nov 2023, 08:10Everyone", "Content": "Comment:\nWe deeply appreciate the insightful and considerate feedback provided by all of the reviewers. We are glad that all the reviewers (FbDy, eQMM, and GXx1) consider the identity initialization to be an interesting and novel method, and think the proposed IDInit to be validated through sufficient experiments. Furthermore, we appreciate Reviewer FbDy's commendation of our manuscript's clarity and coherence, Reviewer eQMM's positive evaluation of our technical contributions and theoretical analysis, and Reviewer GXx1's affirmation of IDInit's practical benefits, including its deterministic nature and ease of implementation. Additionally, we have undertaken our best efforts to comprehensively address all the queries raised by the reviewers, which included conducting further experimental comparisons and providing detailed clarifications. The extra theoretical and empirical results have been provided and are readily accessible within the uploaded revision PDF document."}, {"Heading": "Official Review of Submission9336 by Reviewer FbDy", "Subheading": "Official ReviewbyReviewer FbDy07 Nov 2023, 02:47 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors introduce a technique called Identical Initialization (IDInit), which uses identity matrices and their variants to initialize weights. They discussed the convergence problem and dead neuron problem for common identity initialization and previous works. They explore the application of this technique to non-square matrices, residual architectures, and convolutional operations. Empirical evaluation demonstrate its performance on vision and languages tasks.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper is well-written. The authors clearly describe the problem and their methodology. They also conduct extensive empirical evaluations. \nHow to make identity initialization works in practice is an interesting question and I believe it is an novel direction to explore.\nWeaknesses:\nTheoretical analysis seems incorrect and its proof lacks details. In Theorem 3.1, the author claims IDI breaks rank constraint such that its residual has rank more than D_0. However, in the proof in the appendix, the author only shows the full matrix has rank more than D_0, which is not the same as the residual. Please provide more details in the proof to justify your claim.\nThe authors claim that the rank constraint can be broken by IDI even when non-linearity like ReLU is not applied. It seems contradict approximation theory which emphasizes the importance of non-linearity to ensure expressivity. It would be great for authors to provide more insights on this point.\nAuthors mention that dead neurons problem happens when batch normalization set to 0 or downsampling operation cause 0 filled features. However, these cases are not common in practice and it's better to motivate more on why IDIZ is important.\nInsufficient explanation on why momentum is important to solve convergence problem of IDInit. It would be great to provide some theoretical insights to support this factor.\nQuestions:\nWhat is the meaning of zero down-sampling in Table 2, is this a special downsampling operation compared to standard downsampling (like avgpooling) in ResNet?\nIt would be great to compare IDI, IDI with loose condition, and IDIZ together to show the effectiveness of IDIZ.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer FbDy (1/3)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 07:26Everyone", "Content": "Comment:\nTheoretical analysis seems incorrect and its proof lacks details. In Theorem 3.1, the author claims IDI breaks rank constraint such that its residual has rank more than D_0. However, in the proof in the appendix, the author only shows the full matrix has rank more than D_0, which is not the same as the residual. Please provide more details in the proof to justify your claim.\nWe appreciate the reviewer's feedback regarding the theoretical analysis and acknowledge the need for further elaboration. However, our claim is indeed correct, and we would like to provide additional details for clarity.\nFirstly, it is important to understand that the rank of $\\theta^{(0)}$ exceeding $D_0$\u200b directly leads the distinct values of the feature ${x^{(k)}}_{k=1}^{L-1}$ to be larger than $D_0$\u200b. Then, since the gradient of $\\theta^{(k)}$ is calculated as $\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(k)}}=\\frac{\\partial \\mathcal{L}}{\\partial x^{(k)}}\\circ x^{(k-1)}$ for $k\\in {1, 2, \\dots, L-2}$, the rank of $\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(k)}}$ will be larger than $D_0$. As a result, with a learning rate $\\mu$, the subsequent $\\theta^{(k)}$ updated as $\\theta^{(k)} = \\theta^{(k)} - \\mu \\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(k)}}$, will also have a rank greater than $D_0$\u200b. This effectively resolves the rank constraint issue. Furthermore, this is also supported by the empirical evidence supporting as presented in Figure 4, where IDInit's success in surpassing the rank of $D_0$\u200b is demonstrated.\nWe believe that this additional explanation clarifies the theoretical foundation of our approach and addresses the concerns raised. We will revise the proof in the revised manuscript to ensure a comprehensive understanding of our methods and findings.\nThe authors claim that the rank constraint can be broken by IDI even when non-linearity like ReLU is not applied. It seems contradict approximation theory which emphasizes the importance of non-linearity to ensure expressivity. It would be great for authors to provide more insights on this point.\nWe appreciate the reviewer's point regarding the possible contradiction between IDInit and the approximation theory. To clarify, our claim is that IDInit has the capacity to break the rank constraint even without traditional non-linearities such as ReLU. This does not negate the significance of non-linearities in enhancing expressivity, as emphasized by approximation theory. In more detail, our work demonstrates that IDInit's mechanism allows for an increase in the rank of learned representations through padding the identity matrix repeatedly., independent of non-linear transformations. When non-linearities like ReLU are introduced, as per approximation theory, they indeed augment the expressivity of the IDInit. In summary, IDInit, in conjunction with non-linear activations, provides a compounded benefit to the model's expressivity. Therefore, IDInit's impact is additive to the benefits conferred by non-linearities, rather than contradictory.\nAuthors mention that dead neurons problem happens when batch normalization set to 0 or downsampling operation cause 0 filled features. However, these cases are not common in practice and it's better to motivate more on why IDIZ is important.\nThank you for the comment on IDIZ in addressing the issue of dead neurons, particularly in relation to batch normalization (BN) and downsampling operations. However, we contend that the scenarios we described are common in practice.\nBatch Normalization: The practice of setting the gamma parameter of the last BN layer in a ResNet block to zero is not only recommended for enhanced performance as indicated in references [1][2][3], but also a default setting in widely-used packages like timm [4]. This approach, while improving performance, can inadvertently lead to dead neurons, a problem IDIZ aims to mitigate.\nDownsampling: In common downsampling practices, there are two prevalent approaches: (i): Using pooling (e.g., avgpool) to reduce feature resolution, coupled with zero-padding to expand channel size (as shown in Line 40 of [5] and option 'A' in Line 66 of [6]). (ii): Employing convolution to simultaneously reduce resolution and expand channel size (evident in Line 241 of [7] and option 'B' in Line 72 of [6]). In particular, for the widely-used datasets like CIFAR-10, option (i) is frequently preferred.\nIDIZ is designed to generalize the utilization of IDInit by solving dead neurons of above conditions which is also common settings. So that IDIZ can be used more widely for addressing the disharmonious nature of identity-control methods, which avoids potential risks in compatibility with other techniques. We believe this is important characteristic to an initialization algorithm.\nWe will revise our manuscript to better discuss these points, ensuring that the relevance and utility of IDIZ are clearly and concisely presented."}, {"Heading": "Response to Reviewer FbDy (2/3)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 07:27Everyone", "Content": "Comment:\nWhat is the meaning of zero down-sampling in Table 2, is this a special downsampling operation compared to standard downsampling (like avgpooling) in ResNet?\nSorry for the unclear description of the term \"zero down-sampling\" in Table 2 of our manuscript. To clarify, this term refers specifically to the first downsampling setting (i) mentioned in our last response. This approach is commonly used for datasets like CIFAR-10 and involves the use of pooling (e.g., avgpool) to reduce the resolution of features, coupled with zero-padding to expand the channel size. In this case, ZerO performs poorly since affected by dead neurons.\nTo enhance the comparative analysis, we utilize ResNet-18 as the backbone, ensuring the avoidance of dead neurons for ZerO. Specifically, we implement 1\u00d71 convolution for downsampling in ResNet-18, as detailed in [6], adhering to the downsampling setting (ii). This approach effectively avoids the dead neuron issue, thereby facilitating normal functioning of ZerO. Results are shown in STable 1 below.\nModel\nAccuracy\nZerO\n94.81\u00a0$\\pm$\u00a00.05\nIDInit\n95.08\u00a0$\\pm$\u00a00.13\nThe results suggest that IDInit still outperforms ZerO of which the dead neurons are solved, which showcases the consistent robustness and effectiveness of IDInit across different downsampling strategies.  We will revise the description for better understanding.\nInsufficient explanation on why momentum is important to solve convergence problem of IDInit. It would be great to provide some theoretical insights to support this factor.\nThis is a great question. We would like to give the interpretation from the angle of theory. According to a study on the convergence problem with identity initialization [8], when layers are initialized with the identity matrix, all the layers will be the same at each step until the end, which causes layers not to converge to a ground truth whose eigenvalues contain negative values.  To address this, we delve into the mechanics of the SGD optimizer in our detailed proof presented in Appendix F.2 of the uploaded revision PDF.\nIn the proof, we examine how SGD facilitates differentiation between layers. Specifically, SGD updates weights through a component expressed as:\n$$\n-\\eta X_2^TX_2X_1^TX_1 + \\eta X_2^TX_2X_1^TY_1 - X_2^TY_2,\n $$\nwhere $\\eta$ represents the learning rate, and ${X_1, Y_1}$ and ${X_2, Y_2}$  are training pairs sampled from the same dataset $\\mathcal{D}$. This update mechanism inherently encourages layers to become asymmetric and distinct from each other, thereby mitigating the issue of identical layers post-training.\nBy amplifying the divergence between layers, momentum plays a critical role in this context . It enhances the effect of SGD's layer differentiation mechanism, thereby significantly addressing the convergence problem. Momentum essentially accelerates the process of breaking the symmetry in layer weights, which is pivotal for effective convergence in networks initialized by IDInit.\nWe believe this theoretical insight, backed by the proof in Appendix F.2, clearly articulates the importance of SGD with momentum in solving the convergence challenge associated with IDInit. We will revise the manuscript to explicate this point more thoroughly to provide a better understanding of the interplay between momentum, SGD, and the layer weights in the context of IDInit."}, {"Heading": "Response to Reviewer FbDy (3/3)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 07:31Everyone", "Content": "Comment:\nIt would be great to compare IDI, IDI with loose condition, and IDIZ together to show the effectiveness of IDIZ.\nWe appreciate the reviewer\u2019s suggestion to provide a comparative analysis of IDI, IDI with a loose condition, and IDIZ. In Section 4.4 of our manuscript, we initially discussed some of these components individually. Based on the reviewer\u2019s feedback, we have expanded this analysis to further exhibit the interaction of these components when combined.\nSTable 2. Analysis of components.\nSetting 1\nSetting 2\nSetting 3\nSetting 4\nSetting 5\nSetting 6\nSetting 7\nSetting 8\nLoose\n\u2714\n\u2714\n\u2714\n\u2714\nIDIC\n\u2714\n\u2714\n\u2714\n\u2714\nIDIZ\n\u2714\n\u2714\n\u2714\n\u2714\nAccuracy\n86.12$_{\u00b10.52}$\n92.68$_{\u00b10.08}$\n89.47$_{\u00b10.24}$\n87.01$_{\u00b10.29}$\n92.95$_{\u00b10.21}$\n92.9$_{\u00b10.18}$\n90.43$_{\u00b10.14}$\n93.22$_{\u00b10.05}$\nThe extended analysis is presented in the newly added STable 2. This table clearly illustrates that while the components 'Loose', 'IDIC', and 'IDIZ' each contribute to improvements independently, their combined application yields the most substantial results. Notably, IDIZ stands out by significantly enhancing accuracies to over 92%. This improvement is primarily attributed to IDIZ\u2019s ability to resolve the dead neuron issue, which is a critical factor in optimizing neural network performance.\nThis collective analysis underscores the individual and combined efficacy of the IDInit techniques. The results firmly establish that each component plays a vital role in the overall performance, with IDIZ being particularly instrumental in achieving higher accuracy rates. Our manuscript will be updated to include this comprehensive comparative analysis, ensuring a clear demonstration of the effectiveness and interplay of IDI, IDI with a loose condition, and IDIZ.\n[1] Goyal, Priya, et al. \"Accurate, large minibatch sgd: Training imagenet in 1 hour.\"\narXiv preprint arXiv:1706.02677\n(2017).\n[2] He, Tong, et al. \"Bag of tricks for image classification with convolutional neural networks.\"\nProceedings of the IEEE/CVF conference on computer vision and pattern recognition\n. 2019.\n[3] URL:\nhttps://github.com/tensorpack/tensorpack/issues/420\n[4] URL:\nhttps://github.com/huggingface/pytorch-image-models/blob/main/timm/models/resnet.py\n[5] URL:\nhttps://github.com/hongyi-zhang/Fixup/blob/master/cifar/models/resnet_cifar.py\n[6] URL:\nhttps://github.com/akamaster/pytorch_resnet_cifar10/blob/master/resnet.py\n[7] URL:\nhttps://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py\n[8] Bartlett, Peter, et al. \"Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks.\"\nInternational conference on machine learning\n. PMLR, 2018."}, {"Heading": "Official Comment by Reviewer FbDy", "Subheading": "Official CommentbyReviewer FbDy21 Nov 2023, 22:28Everyone", "Content": "Comment:\nThanks for author's detailed response. However, I still have questions about your response on Theorem 3.1.\n=> \"Firstly, it is important to understand that the rank of $\\theta^{(0)}$ exceeding $D_0$ directly leads the distinct values of the feature $x^{(k)}{ }_{k=1}^{L-1}$ to be larger than $D_0$. Then, since the gradient of $\\theta^{(k)}$ is calculated as $\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(k)}}=\\frac{\\partial \\mathcal{L}}{\\partial x^{(k)}} \\circ x^{(k-1)}$ for $k \\in 1,2, \\ldots, L-2$, the rank of $\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(k)}}$ will be larger than $D_0$.\"\nI think this is still incorrect. First, the rank of $\\theta^{(0)}$ can not exceed $D_0$ as it has the shape of $D_h \\times D_0$ (where $D_h > D_0$). Second, I want to kindly remind the authors that number of distinct values of the feature is not strictly correlated with the rank of the weight derivative matrix.\nFor example, considering we have $N$ input vectors $x^{0} \\in D_0$, we know the rank of $span(x^{0,1}, ..., x^{0,N})$ is smaller or equal to $D_0$. For $x^{1} = \\theta^{(0)} x^{0}$, even when $\\theta^{(0)}$ has full rank $D_0$, the rank of $span(x^{1,1}, ..., x^{1,N})$ is still smaller or equal to $D_0$, due to the nature of linear transformation.\nNow we analysis $\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(k)}}= \\sum^{N}_{i=1} \\frac{\\partial \\mathcal{L}}{\\partial x^{(k,i)}} \\circ x^{(k-1,i)}$ (assuming a full-batch gradient descent, you were using $\\frac{\\partial \\mathcal{L}}{\\partial x^{(k)}} \\circ x^{(k-1)}$ which is a single-batch GD and the matrix is rank-1 only).\nTake $x^{1}$ as a demonstration and assume $D_L > D_0$ without losing generality. We know the rank of $\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(1)}}$ can not exceeed $D_0$ given that \nthe rank of $span(x^{1,1}, ..., x^{1,N})$ is smaller or equal to $D_0$.\nIn other words, $\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(1)}}$ consists of $N$ rank-1 matrices, the summation of which can not exceed $D_0$. Thus, I don't agree the authors' claim that \"the rank of $\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(k)}}$ will be larger than $D_0$\".\nThe authors mention the empirical showcase in Figure 4. Is the 3-layer network in Figure 4 a linear network or a non-linear network? It should be a linear 3-layer network if the authors want to demonstrate Theorem 3.1 empirically."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 15:02 (modified: 22 Nov 2023, 15:03)EveryoneRevisions", "Content": "Comment:\nIn other words, $\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(1)}}$ consists of $N$ rank-1 matrices, the summation of which can not exceed $D_0$. Thus, I don't agree the authors' claim that \"the rank of $\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(k)}}$ will be larger than $D_0$\".\nThe authors mention the empirical showcase in Figure 4. Is the 3-layer network in Figure 4 a linear network or a non-linear network? It should be a linear 3-layer network if the authors want to demonstrate Theorem 3.1 empirically.\nThank you for your insightful observations. We acknowledge your point regarding the limitation of $\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(k)}}$ to $D_0$. \u200bHowever, we maintain that Theorem 3.1 remains valid. In a scenario using full-batch gradient descent for a single round,  $\\theta^{(k)}$ indeed retains a rank of at most $D_0$. Nevertheless, when employing Stochastic Gradient Descent (SGD), the weight update process involves iteratively adding gradients of rank $D_0$. As noted in reference [9], the addition of lower-rank matrices can increase the overall rank. This implies that the rank of $\\theta^{(k)}$ can be increased, provided the gradients are sufficiently independent, achievable through the use of ample training samples.\nTo clarify this concept, we utilized a 3-layer network for analysis. Following the notations from Section A.3 in the appendix and assuming $D_h=2D_L=2D_0$\u200b, we demonstrate the process using SGD. After the initial training step with a sample $x_1^{(0)}$\u200b, the gradient is calculated by\n$$\\frac{\\partial \\mathcal{L}}{\\partial \\theta_1^{(1)}}=\\begin{pmatrix*}\n    \\mu\\Pi & \\mu\\Pi  \\\\\n    \\mathbf{0} & \\mathbf{0}\n    \\end{pmatrix*},$$\nwhere $\\Pi = \\frac{\\partial L}{\\partial x_1^{(3)}} \\circ x_1^{(0)} \\in \\mathbb{R}^{D_L\\times D_0}$. Continuing with a second sample $x_2^{(0)}$\u200b, there is\n$$\\frac{\\partial \\mathcal{L}}{\\partial \\theta_2^{(1)}}=\\begin{pmatrix*}\n(I-\\mu\\Pi)M(I-\\mu\\Pi)x_2^{(0)} & (I-\\mu\\Pi)Mx_2^{(0)}  \\\\\n-\\mu\\Pi M(I-\\mu\\Pi)x_2^{(0)} & -\\mu\\Pi Mx_2^{(0)} \n\\end{pmatrix*},$$\nwhere $M=\\frac{\\partial \\mathcal{L}}{\\partial x_2^{(3)}}$. Thus, the residual step can be calculated as\n$$\\hat{\\theta}^{(1)}=\\theta^{(1)}-I=\\begin{pmatrix*}\n-\\mu\\Pi - (I-\\mu\\Pi)M(I-\\mu\\Pi)x_2^{(0)} & -\\mu\\Pi - (I-\\mu\\Pi)Mx_2^{(0)}  \\\\\n\\mu\\Pi M(I-\\mu\\Pi)x_2^{(0)} & \\mu\\Pi Mx_2^{(0)} \n\\end{pmatrix*}.$$\nWithout loss of generality, assuming $rank(\\Pi)=D_0$, the rank of $\\hat{\\theta}^{(1)}$ should exceed $D_0$\u200b.\nRegarding your query about Figure 4, the network used in this experiment is indeed a linear 3-layer network, as per the requirements to empirically demonstrate Theorem 3.1. There are no non-linear activation functions involved, ensuring the network\u2019s alignment with the theorem's conditions.\nWe appreciate your feedback and will ensure to include a comprehensive revision and discussion of this aspect in our next manuscript update. We hope this response addresses your concerns effectively."}, {"Heading": "Official Comment by Reviewer FbDy", "Subheading": "Official CommentbyReviewer FbDy22 Nov 2023, 15:23Everyone", "Content": "Comment:\nThanks for your clarification. However, there is a fundamental error in your proof: the vector outer product always has rank-1 if two vectors are non-zero. $rank(\\prod)$ can not be $D_0$ (if $D_0 > 1$) but 1 at most."}, {"Heading": "Thank you for the reply", "Subheading": "Official CommentbyAuthors22 Nov 2023, 16:31 (modified: 23 Nov 2023, 01:30)EveryoneRevisions", "Content": "Comment:\nThank you for the great insight. Indeed, it is accurate that the rank of the outer product of two non-zero vectors is at most 1. However, for batch data with size $m \\ge D_0$, the matrix $\\Pi$ can still achieve a rank of $D_0$. This is due to the aggregation of multiple rank-1 matrices arising from each instance in the batch. As these rank-1 matrices are derived from different instances, their cumulative effect can lead to an overall increase in the rank of the aggregated matrix $\\Pi$.\nFurthermore, we also empirically validate that even with a batch size of 1, through iterative training steps, the rank of $\\hat{\\theta}^{(1)}$ can exceed $D_0$. This phenomenon occurs due to the successive accumulation of gradients over multiple steps.\nThanks again for your thoughtful question! We are happy to discuss more if you have any other questions."}, {"Heading": "Updated Proof of Theorem 3.1", "Subheading": "Official CommentbyAuthors23 Nov 2023, 01:38 (modified: 23 Nov 2023, 01:41)EveryoneRevisions", "Content": "Comment:\nDear Reviewer FbDy,\nWe appreciate your feedback and have taken the opportunity to clarify and revise the proof of Theorem 3.1. This revised proof, along with a detailed explanation, is also included in Section A.3 in the appendix in the uploaded revision PDF. In this revised analysis, we focus on batch data rather than single data points.\nAssume weights are updated with the stochastic gradient descent (SGD). Without loss of generality, we set $D_h = 2D_0 = 2D_L$. Given two batches of inputs as ${x_1^{(0, 1)}, x_1^{(0, 2)}, \\dots, x_1^{(0, N)}}\\in \\mathbb{R}^{D_0}$ and ${x_2^{(0, 1)}, x_2^{(0, 2)}, \\dots, x_2^{(0, N)}}\\in \\mathbb{R}^{D_0}$, where $N \\ge D_0$ is the batch size. Therefore, the initial gradient of $\\theta^{(1)}$ are\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(1)}} = \n\\begin{pmatrix*}\n    \\Pi & \\Pi \\\\\n    \\mathbf{0} & \\mathbf{0} \\\n\\end{pmatrix*},\n$$\nwhere $\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(0)}} \\in \\mathbb{R}^{D_h \\times D_0}$, $\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(1)}} \\in \\mathbb{R}^{D_h \\times D_h}$, $\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(2)}} \\in \\mathbb{R}^{D_L \\times D_h}$, $\\Pi = \\frac{1}{N}\\sum^N_{i=1}\\frac{\\partial L}{\\partial x^{(L)}} \\circ x_1^{(0, i)} \\in \\mathbb{R}^{D_L\\times D_0}$, and $\\mathbf{0}$ is a zero values. $\\circ$ denotes outer production.\nAfter training with the second data batch, the gradient is calculated as follows:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\theta^{(1)}}=\n\\begin{pmatrix*}\n(I-\\mu\\Pi)M(I-\\mu\\Pi)K & (I-\\mu\\Pi)MK  \\\\\n-\\mu\\Pi M(I-\\mu\\Pi)K & -\\mu\\Pi MK \n\\end{pmatrix*},\n$$\nwhere $M=\\frac{\\partial \\mathcal{L}}{\\partial x_2^{(3)}}$ and $K=\\frac{1}{N}\\sum^N_{i=1}x_2^{(0, i)}$. This leads to the following residual component:\n$$\n\\hat{\\theta}^{(1)} =\n\\theta^{(1)} - I =\n\\begin{pmatrix*}\n-\\mu\\Pi - \\mu(I-\\mu\\Pi)M(I-\\mu\\Pi)K & -\\mu\\Pi - \\mu(I-\\mu\\Pi)MK  \\\\\n\\mu^2\\Pi M(I-\\mu\\Pi)K & \\mu^2\\Pi MK\n\\end{pmatrix*},\n$$\nWithout loss of generality, assuming $rank(\\Pi)=D_0$, we can conclude\n$$\n    rank(\\hat{\\theta}^{(1)}) \\ge D_0.\n$$\nTherefore, IDInit can break the rank constraint by achieving the rank of $\\hat{\\theta}^{(1)}$ larger than $D_0$.\nWe sincerely hope that this revision addresses your concern. If there are any further questions or clarifications needed, please do not hesitate to let us know.\nKind regards,\nAuthors"}]}, {"Heading": "Official Review of Submission9336 by Reviewer eQMM", "Subheading": "Official ReviewbyReviewer eQMM31 Oct 2023, 07:27 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper addresses the convergence problem in deep networks and proposes a Fully Identical Initialization (IDInit) method that initializes the weights with an identity matrix. The authors propose additional techniques such as momentum, padding, and reshaping to improve convergence and performance.\nThe overall method has some interesting aspects:\nPatch-Maintain Convolution is introduced as a technique to enhance the universality of IDInit for convolutional layers. It reshapes the convolutional kernel initialized with IDInit to increase feature diversity and improve model performance.\nThe issue of dead neurons is tackled by selecting some elements to a small numerical value and increasing trainable neurons.\nThe paper discusses the theoretical analysis of IDInit, including the Jacobian and gradient update equations in residual neural networks.\nFinally, the authors address the limitations and potential concerns of IDInit, such as its deterministic nature and the need for further exploration in different scenarios.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nS1 - Good technical contributions\nThe paper's technical contributions are significant in these aspects:\nIDInit improves the convergence speed, stability, and final performance of deep neural networks, addressing a critical issue in deep learning.\nThe additional techniques proposed, such as Patch-Maintain Convolution and recovering dead neurons, enhance the universality and robustness of IDInit.\nS2 - Theoretical and Experimental analysis\nThe paper discusses the theoretical analysis of IDInit, including the Jacobian and gradient update equations in residual neural networks.\nThe experiments are well-designed and conducted on various network architectures and tasks, demonstrating the effectiveness and superiority of IDInit.\nS3 - Novelty (similar to prior works, but with additional novel contributions)\nIdentity init is not new and has been explored in prior works (e.g. ISONet, ZeroO). However, this paper generalizes the Identity Init to various general architectures and activation functions, which is interesting.\nWeaknesses:\nW1 - Marginal or no improvement compared to Kaiming init\nMy biggest concern is the Cifar-10 performance compared to the simple Kaiming initialization.\nTable 2 shows that using SGD optimizer (which gives the best performance all across), Kaiming init obtains almost the same performance (93.36 v/s 93.41 and 94.06 v/z 94.04) as IDInit, while being only slightly slower.\nThis brings into question the practical utility of the proposed initialization.\nW2 - Comparisons with other init methods on ImageNet\nIDInit is compared with other initialization methods only on Cifar-10, which is very small-scale. No such comparisons have been shown on ImageNet. I think it's important to see if the proposed init is even useful when training on large-scale datasets.\nW3 - Theoretical analysis limitations\nWhile the paper provides a theoretical analysis of IDInit, it mainly focuses on the Jacobian and gradient update equations in residual neural networks. It would be valuable to extend the theoretical analysis to other network architectures and provide a more comprehensive understanding of the underlying principles of IDInit.\nW4 - Limited discussion on limitations\nAlthough the paper briefly mentions the limitations of IDInit, such as the deterministic nature and the need for momentum to handle negative eigenvalues, further discussion and analysis of these limitations would provide a more comprehensive understanding of the potential drawbacks and challenges of implementing IDInit in practical scenarios.\nQuestions:\nReference to weakness W2, can you please provide more insight into the efficacy of the propose init method on large-scale training datasets, like ImageNet?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer eQMM (1/2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 07:37Everyone", "Content": "Comment:\nMy biggest concern is the Cifar-10 performance compared to the simple Kaiming initialization.\nTable 2 shows that using SGD optimizer (which gives the best performance all across), Kaiming init obtains almost the same performance (93.36 v/s 93.41 and 94.06 v/z 94.04) as IDInit, while being only slightly slower.\nThis brings into question the practical utility of the proposed initialization.\nThanks for the reviewer\u2019s comment. While both IDInit and Kaiming initialization methods perform similarly in certain settings, our research indicates that IDInit offers superior stability and adaptability across a wider range of scenarios. To verify this claim, we have conducted additional experiments with varied hyperparameters, particularly focusing on weight decay and learning rate, using ResNet-56.\nRTable 1. Hyperparameters for IDInit on ResNet-56.\nlr=1e0\nlr=1e-1\nlr=1e-2\nlr=1e-3\nwd=1e-1\n10.00$_{\u00b10.00}$\n18.27$_{\u00b10.32}$\n74.46$_{\u00b13.52}$\n88.67$_{\u00b10.23}$\nwd=1e-2\n18.10$_{\u00b11.95}$\n90.37$_{\u00b10.14}$\n94.18$_{\u00b10.06}$\n84.07$_{\u00b10.53}$\nwd=1e-3\n89.18$_{\u00b10.24}$\n94.64$_{\u00b10.16}$\n89.99$_{\u00b10.06}$\n81.65$_{\u00b10.69}$\nwd=1e-4\n94.97$_{\u00b10.04}$\n92.60$_{\u00b10.05}$\n88.83$_{\u00b10.30}$\n82.47$_{\u00b10.12}$\nRTable 2. Hyperparameters for Kaiming on ResNet-56.\nlr=1e0\nlr=1e-1\nlr=1e-2\nlr=1e-3\nwd=1e-1\n10.00$_{\u00b10.00}$\n17.39$_{\u00b10.47}$\n48.98$_{\u00b14.11}$\n82.36$_{\u00b10.42}$\nwd=1e-2\n14.43$_{\u00b14.78}$\n90.10$_{\u00b10.11}$\n94.19$_{\u00b10.09}$\n55.44$_{\u00b11.07}$\nwd=1e-3\n87.78$_{\u00b11.20}$\n94.64$_{\u00b10.12}$\n82.44$_{\u00b10.49}$\n49.85$_{\u00b12.38}$\nwd=1e-4\n94.89$_{\u00b10.37}$\n91.52$_{\u00b10.33}$\n78.42$_{\u00b10.06}$\n50.32$_{\u00b12.71}$\nAs shown in RTable 1 and RTable 2, these experiments reveal that IDInit consistently surpasses Kaiming initialization in almost every setting tested. Most notably, in scenarios with smaller learning rates (e.g., 1e-2 and 1e-3), we observe a significant drop in the performance of models initialized with Kaiming. In contrast, IDInit maintains high accuracy levels under these conditions. This stability of IDInit is attributable to its ability to achieve isometry dynamics in the residual stem, a crucial factor for maintaining performance stability.\nFurther, we have extended our experimentation to include ResNet-32 on the CIFAR-10 dataset, as detailed in Section F.1 of the uploaded revision PDF. These additional results consistently demonstrate that IDInit not only matches but often exceeds the performance of Kaiming initialization, especially under varying and challenging hyperparameter settings.\nIn summary, while Kaiming initialization performs comparably in certain standard scenarios, IDInit exhibits greater performance consistency and stability across a broader spectrum of conditions. This enhanced stability and adaptability make IDInit a more practically valuable choice for diverse neural network applications. We will ensure that these findings are clearly presented in our revised manuscript to underscore the practical utility and advantages of IDInit over traditional initialization methods like Kaiming."}, {"Heading": "Response to Reviewer eQMM (2/2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 07:38Everyone", "Content": "Comment:\nIDInit is compared with other initialization methods only on Cifar-10, which is very small-scale. No such comparisons have been shown on ImageNet. I think it's important to see if the proposed init is even useful when training on large-scale datasets.\nReference to weakness W2, can you please provide more insight into the efficacy of the propose init method on large-scale training datasets, like ImageNet?\nThanks for the suggestion. We have expanded our experimental analysis to include comparisons with other initialization methods, namely Fixup and ZerO, on ImageNet. These experiments were conducted under the same settings as for ResNet-50, described in Section 4.3 of our manuscript.\nRTable 3. Results on ImageNet. The value in brackets means Epochs to 60% Acc.\nKaiming\nFixup\nZerO\nIDInit\n75.70 (38)\n76.24 (25)\n75.73 (35)\n76.72 (24)\nAs presented in RTable 3, the results demonstrate that IDInit simultaneously achieves high performance and fast convergence. Specifically, IDInit achieves the highest accuracy among all the compared methods. In terms of convergence speed, IDInit matches Fixup and significantly surpasses Kaiming and ZerO by 14 and 11 epochs, respectively.\nThis finding is particularly noteworthy as it illustrates that IDInit's advantages are not limited to small-scale datasets. Instead, its efficacy extends to large-scale training scenarios, highlighting its consistency in performance and convergence. We will incorporate these insights and results into our revised manuscript to comprehensively demonstrate IDInit's utility across different scales of datasets, thereby addressing the concerns regarding its practicality and scalability.\nWhile the paper provides a theoretical analysis of IDInit, it mainly focuses on the Jacobian and gradient update equations in residual neural networks. It would be valuable to extend the theoretical analysis to other network architectures and provide a more comprehensive understanding of the underlying principles of IDInit.\nThanks for your insightful comments regarding the theoretical analysis of IDInit in the context of residual neural networks. We acknowledge the importance of extending this analysis to other architectures for a more comprehensive understanding. Our decision to concentrate on residual networks was guided by their widespread use and relevance in current research on deep learning. While we recognize the value of broadening our theoretical framework, such a comprehensive analysis was beyond the scope of this particular study, primarily due to the complicated variations in network architectures that demand distinct analytical approaches. Nevertheless, the findings of our current research offer significant insights into the functioning of IDInit in residual networks, contributing valuable knowledge to the broader field. We are enthusiastic about the prospect of extending our work to include other architectures and consider this an important direction for our future research endeavors.\nAlthough the paper briefly mentions the limitations of IDInit, such as the deterministic nature and the need for momentum to handle negative eigenvalues, further discussion and analysis of these limitations would provide a more comprehensive understanding of the potential drawbacks and challenges of implementing IDInit in practical scenarios.\nThanks for the comment on the further discussion on the limitations. Regarding the convergence ability of IDInit, we add a theoretical analysis in Appendix F.2 of the uploaded revision PDF, which shows the mechanics of SGD w/ momentum to resolve the convergent problem by breaking symmetries of each layer weight. As for the deterministic nature, we have discussed the IDInit can already be in a good initial state that can exceed random initialization, and the whole training still contains randomness (e.g., sequence of samples) in the training process. Moreover, as acknowledged by reviewer GXx1, the deterministic nature could reduce some of the randomness in training networks, which helps comparison among networks become easier. Therefore, these two limitations are not likely to cause severe damage to the convergence and performance of IDInit. We will add this elaboration to the revision for better understanding."}]}, {"Heading": "Official Review of Submission9336 by Reviewer GXx1", "Subheading": "Official ReviewbyReviewer GXx130 Oct 2023, 14:57 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis manuscript proposes a method to initialise networks with identity matrices.\nSymmetry of the initialisation is broken by repeating the identity matrix\nand adding small (1e-6) perturbations to the diagonals.\nExtensions for convolutional layers and fixup-like initialisations are also presented.\nExperiments in both vision (CIFAR10 and ImageNet) and language (SST2, TREC6 and BERT pre-training) domains suggest better performance and faster convergence for various architectures.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n4 excellent\nStrengths:\n(quality) Experimental results are presented with error bars.\n(significance) This initialisation could reduce some of the randomness in training networks.\nAs a result, comparing networks should become easier.\n(significance) The proposed initialisation should be simple enough to implement, which typically leads to fast adoption by practicioners.\n(originality) Although the idea to use identity matrices for initialisation has been around for some time, it has typically been discarded as impractical due to the symmetries.\n This is (to the best of my knowledge) the first work that implements an initialisation scheme that sticks so close to the identity matrix.\nWeaknesses:\n(clarity) The idea of dynamical isometry has been introduced in (Saxe et al., 2014).\n(clarity) I would argue that the patch-maintain convolution is not very well motivated.\nI believe the problem is that I do not understand how this relates to Ghostnets (Han et al., 2020).\n(clarity) It also took me some time to realise that the channel-maintain convolution (as it is called in the appendix) which is described in the first paragraph of Section\u00a03.3.1 is something different from the proposed patch-maintain setting.\nNote that this channel-maintain setting has also been used in (Xiao et al., 2018).\n(clarity) The ablation experiment in Section\u00a04.4 is claimed to explain why channel-maintain is not as good as patch-maintain.\nHowever, the explanation in section\u00a04.4 seems to indicate that this is just an ablation of the different components of the proposed solution.\n(clarity) I can not find any explanation for the legend of Figure\u00a07\u00a0(a).\n(quality) The results in Table\u00a01 seem to correspond to GD, not SGD.\nA quick experiment with SGD (batch-size 200) learns without problems.\n(quality) The choice of hyper-parameters is not motivated properly and it is unclear how they were chosen.\nMoreover, it seems like the same hyper-parameter settings were used for every network.\nFor a fair comparison, hyper-parameters should be set for each method individually.\n(quality) An experiment without learning rate schedule, weight decay and other extras would be interesting for a more \"raw\" comparison between initialisation strategies.\nReferences\nSaxe, A. M., McClelland, J. L., & Ganguli, S. (2014). \nExact solutions to the nonlinear dynamics of learning in deep linear neural networks.\nInternational Conference on Learning Representations.\nhttps://arxiv.org/abs/1312.6120\nXiao, L., Bahri, Y., Sohl-Dickstein, J., Schoenholz, S., & Pennington, J. (2018). \nDynamical isometry and a mean field theory of cnns: How to train 10,000-layer vanilla convolutional neural networks. \nIn International Conference on Machine Learning (pp. 5393-5402). PMLR.\nhttps://proceedings.mlr.press/v80/xiao18a\nQuestions:\nPlease, include the references listed in the weaknesses section.\nWhat is the link between Ghostnet and the patch-maintain scheme?\nDo you have a direct comparison between patch-maintain and channel-maintain schemes for IDInit?\nCan you verify that using SGD instead of GD for the results in Table\u00a01 also resolves the stated problem?\nIs it possible to tune the hyper-parameters for each method individually?\nHow do weight decay and learning rate schedule interact with the proposed initialisation scheme?\nWhat is the difference between IDInit-0 and IDInit-10 or Kaiming-10 and Kaiming-40 in Figure\u00a07\u00a0(a)?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer GXx1 (1/3)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 07:48 (modified: 20 Nov 2023, 07:50)EveryoneRevisions", "Content": "Comment:\n(clarity) The idea of dynamical isometry has been introduced in (Saxe et al., 2014).\nWe acknowledge the seminal work presented in [1] regarding the concept of dynamical isometry in the context of non-residual networks. The approach outlined in [1] focuses on achieving dynamical isometry by orthogonalizing network weights to ensure that the mean squared singular value of the Jacobian matrix remains close to 1, a significant advancement for non-residual network initialization.\nHowever, our work with IDInit diverges from [1] in its application to residual networks, which are among the most powerful and prevalent structures in current deep learning architectures. In technique, IDInit emphasizes the maintenance of identity transit through both the main and residual stems, and empirical results show the effectiveness.\nIn light of this, while IDInit and the method in [1] both target dynamical isometry, IDInit's contribution lies in its novel application to residual networks. This extension not only broadens the understanding of dynamical isometry but also showcases its practical utility in some of the most advanced neural network architectures today. We will include a detailed discussion of these distinctions and contributions in the revised manuscript.\nPlease, include the references listed in the weaknesses section.\nThank you for your suggestion. [1] pioneered the integration of dynamic isometry in nonlinear networks, enhancing training efficiency. Specifically targeting Convolutional Neural Networks (CNNs), Reference [2] formulated a mean field theory for signal propagation adhering to dynamic isometry principles, enabling the training of networks with up to 10,000 layers. Different from these approaches, the proposed IDInit maintains identity in both the main and residual stems to preserve dynamic isometry to achieve good performance and fast convergence. Furthermore, we adapt the transformation on the identity matrix to accommodate various scenarios, such as nonsquare matrices and higher-order tensors. We will include these references in the revision.\n(clarity) I would argue that the patch-maintain convolution is not very well motivated. I believe the problem is that I do not understand how this relates to Ghostnets (Han et al., 2020).\nWhat is the link between Ghostnet and the patch-maintain scheme?\nThanks for the useful comment. Ghostnet [3] highlights the critical role of channel diversity in enhancing network performance. This insight serves as a foundational motivation for our patch-maintain scheme. In contrast to the channel-maintain approach, which tends to replicate channel features and thus might limit diversity, our patch-maintain scheme introduces a novel strategy to increase channel differentiation. By shifting features, the patch-maintain scheme aims to add variability and uniqueness across channels. This method is designed to capitalize on the principle articulated in Ghostnet \u2013 that channel diversity is beneficial for performance. This linkage between the need for channel diversity (as emphasized by Ghostnet) and our patch-maintain scheme is a key aspect of our work. We will include this discussion in the revision.\n(clarity) It also took me some time to realise that the channel-maintain convolution (as it is called in the appendix) which is described in the first paragraph of Section\u00a03.3.1 is something different from the proposed patch-maintain setting. Note that this channel-maintain setting has also been used in (Xiao et al., 2018).\n(clarity) The ablation experiment in Section\u00a04.4 is claimed to explain why channel-maintain is not as good as patch-maintain. However, the explanation in section\u00a04.4 seems to indicate that this is just an ablation of the different components of the proposed solution.\nDo you have a direct comparison between patch-maintain and channel-maintain schemes for IDInit?\nSorry for the confusion. In this work, we introduce the patch-maintain scheme (i.e., IDIC$_{\\tau}$) as our novel method for transforming a matrix into a convolutional format.\nOn the other hand, the channel-maintain method, referenced from prior studies [2][4], serves as a comparison baseline in our experiments, denoted as 'w/o IDIC$_{\\tau}$'. In Section 4.4, we present this comparative analysis, where we demonstrate that the patch-maintain scheme significantly enhances the performance of IDInit. To address the clarity issues raised, we will revise our manuscript for more explicit elaboration."}, {"Heading": "Response to Reviewer GXx1 (2/3)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 07:51Everyone", "Content": "Comment:\n(clarity) I can not find any explanation for the legend of Figure\u00a07\u00a0(a).\nWhat is the difference between IDInit-0 and IDInit-10 or Kaiming-10 and Kaiming-40 in Figure\u00a07\u00a0(a)?\nSorry for lacking the explanation for the legend in Figure\u00a07\u00a0(a).  The numbers following the initialization methods in the legend represent the duration of the warmup period, measured in epochs. Specifically, (i) IDInit-0 and IDInit-10 indicate that the IDInit method was used with a warmup period of 0 and 10 epochs, respectively; (ii) Kaiming-10 and Kaiming-40 refer to the Kaiming initialization method applied with warmup periods of 10 and 40 epochs, respectively. The inclusion of different warmup durations is crucial for evaluating the performance of these initialization methods under varying conditions of network adaptation at the beginning of the training process. We will add a description of the warmup epochs and their implications in the revised version.\n(quality) The results in Table\u00a01 seem to correspond to GD, not SGD. A quick experiment with SGD (batch-size 200) learns without problems.\nCan you verify that using SGD instead of GD for the results in Table\u00a01 also resolves the stated problem?\nThank you for your insightful comment. To clarify, in the original submission, the results presented in Table 1 were already obtained using Stochastic Gradient Descent (SGD) with a batch size of 200. Different from the reviewer's comment, our experiments indicated that SGD with 200 batch size did not yield satisfactory performance.\nIn order to further explore the impact of different batch sizes on training convergence, we conducted additional experiments with a significantly reduced batch size of 4. This adjustment led to a marked improvement in training convergence, highlighting the beneficial role of using smaller mini-batches in SGD.\nMoreover, we also observed that the momentum in SGD further enhances the convergence process. This aligns with our earlier discussions on the role of momentum in facilitating more effective weight updates and breaking the convergence problem.\nIn contrast, Gradient Descent (GD) without stochastic elements failed to converge even with the addition of momentum, underscoring the significance of the stochastic component in SGD for resolving convergence issues.\nTo summarize, our findings indicate that SGD, particularly with smaller batch sizes and the inclusion of momentum, effectively addresses the convergence problem highlighted in Table 1. These insights will be incorporated into our revised manuscript to provide a comprehensive understanding of the impact of SGD and batch size variations on training convergence."}, {"Heading": "Response to Reviewer GXx1 (3/3)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 07:53Everyone", "Content": "Comment:\n(quality) The choice of hyper-parameters is not motivated properly and it is unclear how they were chosen. Moreover, it seems like the same hyper-parameter settings were used for every network. For a fair comparison, hyper-parameters should be set for each method individually.\n(1) Is it possible to tune the hyper-parameters for each method individually?\n(quality) An experiment without learning rate schedule, weight decay and other extras would be interesting for a more \"raw\" comparison between initialisation strategies.\n(2) How do weight decay and learning rate schedule interact with the proposed initialisation scheme?\nInvestigating the influence of hyperparameters is important to validate the effectiveness of IDInit. In response, we have conducted an extensive set of experiments to analyze the effect of weight decay and learning rate on the performance of IDInit compared to baselines. These experiments are constructed on Cifar10 with ResNet-32, and detailed in Section F.1 in the uploaded revision PDF, with partial cases IDInit and Kaiming presented in RTable 1 and RTable 2, respectively.\nRTable 1. Hyperparameters for IDInit on ResNet-32.\nlr=1e0\nlr=1e-1\nlr=1e-2\nlr=1e-3\nwd=1e-1\n16.38$_{\u00b11.28}$\n21.68$_{\u00b12.61}$\n68.20$_{\u00b15.79}$\n82.17$_{\u00b10.14}$\nwd=1e-2\n22.57$_{\u00b12.69}$\n90.36$_{\u00b10.06}$\n93.28$_{\u00b10.04}$\n83.18$_{\u00b10.14}$\nwd=1e-3\n89.76$_{\u00b10.18}$\n94.08$_{\u00b10.13}$\n90.09$_{\u00b10.22}$\n81.42$_{\u00b10.13}$\nwd=1e-4\n94.08$_{\u00b10.08}$\n92.54$_{\u00b10.11}$\n88.33$_{\u00b10.03}$\n81.15$_{\u00b10.26}$\nwd=1e-5\n93.27$_{\u00b10.21}$\n91.92$_{\u00b10.29}$\n88.56$_{\u00b10.13}$\n81.65$_{\u00b10.34}$\nwd=1e-6\n92.94$_{\u00b10.18}$\n91.91$_{\u00b10.12}$\n88.47$_{\u00b10.10}$\n80.76$_{\u00b10.61}$\nwd=1e-7\n93.02$_{\u00b10.20}$\n91.80$_{\u00b10.18}$\n88.74$_{\u00b10.24}$\n81.00$_{\u00b10.44}$\nwd=1e-8\n92.99$_{\u00b10.19}$\n91.96$_{\u00b10.11}$\n88.82$_{\u00b10.34}$\n81.42$_{\u00b10.78}$\nRTable 2. Hyperparameters for Kaiming on ResNet-32.\nlr=1e0\nlr=1e-1\nlr=1e-2\nlr=1e-3\nwd=1e-1\n10.38$_{\u00b10.35}$\n21.12$_{\u00b12.73}$\n51.88$_{\u00b15.98}$\n69.52$_{\u00b17.60}$\nwd=1e-2\n21.77$_{\u00b13.10}$\n90.23$_{\u00b10.18}$\n92.78$_{\u00b10.14}$\n55.26$_{\u00b11.14}$\nwd=1e-3\n89.96$_{\u00b10.49}$\n93.69$_{\u00b10.12}$\n82.02$_{\u00b10.01}$\n51.25$_{\u00b11.17}$\nwd=1e-4\n94.06$_{\u00b10.11}$\n91.24$_{\u00b10.10}$\n78.37$_{\u00b10.41}$\n50.75$_{\u00b11.26}$\nwd=1e-5\n93.06$_{\u00b10.07}$\n90.14$_{\u00b10.12}$\n77.83$_{\u00b10.43}$\n50.81$_{\u00b11.48}$\nwd=1e-6\n92.60$_{\u00b10.14}$\n90.01$_{\u00b10.17}$\n78.05$_{\u00b10.33}$\n50.91$_{\u00b11.38}$\nwd=1e-7\n92.64$_{\u00b10.11}$\n90.00$_{\u00b10.14}$\n78.32$_{\u00b10.58}$\n51.00$_{\u00b11.22}$\nwd=1e-8\n92.48$_{\u00b10.25}$\n89.93$_{\u00b10.09}$\n77.96$_{\u00b10.21}$\n50.79$_{\u00b11.49}$\nAs shown in RTable 1 and RTable 2, across various settings of learning rate and weight decay, IDInit consistently outperforms or matches Kaiming initialization. It demonstrates that IDInit's performance superiority is not confined to a specific set of hyperparameters but is maintained across a range of settings. Moreover, at lower learning rates (1e-2 and 1e-3), where Kaiming initialization's performance drops significantly, whereas IDInit maintains high accuracy. This robustness of IDInit, even under smaller learning rates, highlights its effectiveness in achieving isometry dynamics in the residual stem.\nIn light of these findings, IDInit showcases the generalizability and effectiveness of IDInit across various hyperparameter configurations, indicating the promising utility of IDInit to practical application.\n[1] Saxe, Andrew M., et al. \"Exact solutions to the nonlinear dynamics of learning in deep linear neural networks.\"\narXiv preprint arXiv:1312.6120\n(2013).\n[2] Xiao, Lechao, et al. \"Dynamical isometry and a mean field theory of cnns: How to train 10,000-layer vanilla convolutional neural networks.\"\nInternational Conference on Machine Learning\n. PMLR, 2018.\n[3] Han, Kai, et al. \"Ghostnet: More features from cheap operations.\"\nProceedings of the IEEE/CVF conference on computer vision and pattern recognition\n. 2020.\n[4] Zhao, Jiawei, et al. \"ZerO initialization: Initializing neural networks with only zeros and ones.\"\narXiv preprint arXiv:2110.12661\n(2021)."}, {"Heading": "Last-minute questions", "Subheading": "Official CommentbyReviewer GXx121 Nov 2023, 14:37Everyone", "Content": "Comment:\nI still do not quite understand why the patch-maintain scheme would lead to more channel diversity. \nAfter all, reshaping the kernels to $\\mathbb{R}^{c_\\mathrm{out} \\times c_\\mathrm{in}k^2}$ leads to a matrix with much more columns than rows and therefore a lot of zeros. \nA quick test with the provided code seems to confirm that this leads to most kernels being completely zero.\nHow can this lead to more channel diversity?\nI would be very interested in the ablation experiments with individually tuned hyper-parameters for each setting (cf. RTable1 and RTable 2, but maybe even with learning rate scheduling disabled or also tuned).\nConcerning Table 1 (addressed in response 2/3): I noticed that I did not disable bias parameters as you did in the provided code.\n  This would indicate that this problem can be resolved by simply adding bias parameters, which is typically done anyway.\n  Therefore, I still believe that the results in Table 1 are a contrived example. \n  Would that be a fair assessment?"}, {"Heading": "Response to Last-minute Questions (1/3)", "Subheading": "Official CommentbyAuthors22 Nov 2023, 15:08Everyone", "Content": "Comment:\nI still do not quite understand why the patch-maintain scheme would lead to more channel diversity. After all, reshaping the kernels to\u00a0$\\mathbb{R}^{c_\\mathrm{out} \\times c_\\mathrm{in}k^2}$\u00a0leads to a matrix with much more columns than rows and therefore a lot of zeros. A quick test with the provided code seems to confirm that this leads to most kernels being completely zero. How can this lead to more channel diversity?\nThank you for your insightful comment. It is important to clarify that while the patch-maintain scheme introduces many zero values into a convolution kernel, this does not necessarily result in channels being zeroed out. Instead, this scheme is designed to enhance channel diversity by effectively shifting features.\nTo empirically validate this, we conducted a specific test case where a one-channel input of size $\\mathbb{R}^{1\\times 4\\times 4}$ is transformed into a three-channel output of size $\\mathbb{R}^{3\\times 4\\times 4}$. The convolution kernel used for this transformation, of size $\\mathbb{R}^{1\\times 3\\times 3\\times 3}$, is initialized using the patch-maintain scheme.\nRTable 3. The channel of the input.\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nRTable 4(a). The 1st channel of the output.\n0\n0\n0\n0\n0\n1\n2\n3\n0\n5\n6\n7\n0\n9\n10\n11\nRTable 4(b). The 2nd channel of the output.\n0\n0\n0\n0\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\nRTable 4(c). The 3rd channel of the output.\n0\n0\n0\n0\n2\n3\n4\n0\n6\n7\n8\n0\n10\n11\n12\n0\nThe results of this transformation are detailed in RTable 3 (input) and RTable 4 (output channels). As demonstrated in RTable 4, despite the presence of zero values, the output channels vary distinctly from each other, underscoring the enhancement in channel diversity. This variation arises due to the feature shifting induced by the patch-maintain scheme, rather than through the direct manipulation of non-zero values.\nAdditionally, we have updated the supplementary materials with code (named 'exp_channel_diversity') that replicates this test case, allowing for an in-depth examination of how the patch-maintain scheme contributes to channel diversity.\nWe hope this explanation and the provided experimental evidence adequately address your concerns regarding the impact of the patch-maintain scheme on channel diversity."}, {"Heading": "Response to Last-minute Questions (2/3)", "Subheading": "Official CommentbyAuthors22 Nov 2023, 15:11Everyone", "Content": "Comment:\nI would be very interested in the ablation experiments with individually tuned hyper-parameters for each setting (cf. RTable1 and RTable 2, but maybe even with learning rate scheduling disabled or also tuned).\nThank you for expressing interest in further hyperparameter experiments. To address your query, we conducted two additional settings of experiments: (i) with learning rate scheduling disabled, and (ii) with a multiple-step learning rate scheduling that multiplies the rate by 0.1 at the 100th and 150th epochs. The total epochs are 200 epochs.\nFor these experiments, we selected a subset of hyperparameters from RTable 1 and RTable 2, specifically focusing on learning rates {1e-1, 1e-2, 1e-3} and weight decay values {1e-2, 1e-3, 1e-4}. This selection represents a range of parameters that have previously demonstrated good performance.\nRTable 5(a). Hyperparameters for IDInit on ResNet-32 with learning rate scheduling disabled.\nlr=1e-1\nlr=1e-2\nlr=1e-3\nwd=1e-2\n89.83$_{\u00b10.01}$\n93.37$_{\u00b10.19}$\n83.45$_{\u00b10.58}$\nwd=1e-3\n93.97$_{\u00b10.08}$\n89.92$_{\u00b10.22}$\n81.00$_{\u00b10.43}$\nwd=1e-4\n92.43$_{\u00b10.21}$\n88.72$_{\u00b10.16}$\n80.27$_{\u00b10.62}$\nRTable 5(b). Hyperparameters for Kaiming on ResNet-32 with learning rate scheduling disabled.\nlr=1e-1\nlr=1e-2\nlr=1e-3\nwd=1e-2\n90.06$_{\u00b10.52}$\n92.75$_{\u00b10.16}$\n55.64$_{\u00b12.10}$\nwd=1e-3\n93.81$_{\u00b10.18}$\n81.86$_{\u00b10.23}$\n51.92$_{\u00b13.41}$\nwd=1e-4\n91.10$_{\u00b10.14}$\n78.35$_{\u00b10.59}$\n51.73$_{\u00b13.20}$\nRTable 6(a). Hyperparameters for IDInit on ResNet-32 with a multiple-step learning rate scheduling.\nlr=1e-1\nlr=1e-2\nlr=1e-3\nwd=1e-2\n88.58$_{\u00b10.28}$\n92.81$_{\u00b10.14}$\n82.90$_{\u00b10.04}$\nwd=1e-3\n93.32$_{\u00b10.08}$\n88.96$_{\u00b10.31}$\n80.82$_{\u00b10.59}$\nwd=1e-4\n91.02$_{\u00b10.24}$\n87.91$_{\u00b10.30}$\n80.56$_{\u00b10.13}$\nRTable 6(b). Hyperparameters for Kaiming on ResNet-32 with a multiple-step learning rate scheduling.\nlr=1e-1\nlr=1e-2\nlr=1e-3\nwd=1e-2\n88.69$_{\u00b10.27}$\n92.40$_{\u00b10.19}$\n56.36$_{\u00b11.41}$\nwd=1e-3\n93.31$_{\u00b10.13}$\n82.80$_{\u00b10.37}$\n52.58$_{\u00b11.97}$\nwd=1e-4\n90.71$_{\u00b10.20}$\n79.03$_{\u00b10.04}$\n52.03$_{\u00b12.14}$\nThe outcomes of these experiments are detailed in RTable 5 and RTable 6. The results align consistently with those observed in RTable 1 and RTable 2. It is noteworthy that under various settings of learning rate, weight decay, and learning rate scheduling, the IDInit approach either matches or outperforms the Kaiming initialization. This is particularly evident at lower learning rates (1e-2 and 1e-3), where the performance of Kaiming initialization significantly drops. The robustness of IDInit under these conditions underscores its stability and potential for wide-ranging applicability.\nThese findings bolster our confidence in the versatility and effectiveness of the IDInit method, suggesting its promising utility across diverse settings and scenarios."}, {"Heading": "Response to Last-minute Questions (3/3)", "Subheading": "Official CommentbyAuthors22 Nov 2023, 15:12 (modified: 22 Nov 2023, 15:14)EveryoneRevisions", "Content": "Comment:\nThank you for your observation regarding Table 1. This table was designed to address the convergence issues highlighted in reference [5], where the authors analyzed a network comprising entirely linear layers without biases and optimized it using Gradient Descent (GD). In line with their setting, we constructed a 3-layer fully linear network without biases as our experimental model. This choice was not an attempt to contrive a specific outcome but rather to adhere closely to the conditions set out in [5]. Therefore, this is a fair assessment.\nOur primary objective is to demonstrate that the convergence problem identified in [5] is readily solvable. To this end, any evidence that contributes to solving this convergence problem aligns with our goal. Consequently, our findings that SGD with momentum aids in resolving convergence issues, and that momentum can further expedite this process, are pertinent. Similarly, your observation that incorporating bias parameters might facilitate convergence is equally valuable and does not contradict the purpose of our experiment.\nIn summary, we appreciate your contribution to this discussion, as it helps uncover various potential solutions to the convergence problem. These findings, including the use of SGD with momentum, smaller batch sizes, and the addition of biases, do not contradict the central premise of Table 1; rather, they provide supporting evidence for the ease of resolving convergence issues. We find these insights intriguing and plan to include them in our next revision to offer a more comprehensive understanding of the IDInit approach.\n[5] Bartlett, Peter, et al. \"Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks.\"\nInternational conference on machine learning\n. PMLR, 2018."}]}]}, "30L0rr9W8A": {"paper_info": {"Primary Area": "reinforcement learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Representation Learning, Reinforcement Learning, Optimal Control, End-to-End Learning, Convex Optimization, Control Barrier Function, Autonomous Driving, CARLA, Robotics", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Safe control is crucial for safety-critical autonomous systems that are deployed in dynamic and uncertain environments. Quadratic-programming-control-barrier-function (QP-CBF) is becoming a popular tool for safe controller synthesis. Traditional QP-CBF relies on explicit knowledge of the system dynamics and access to all states, which are not always available in practice. We propose LatentCBF (LCBF), a control barrier function defined in the latent space, which only needs an agent's observations, not full states. The transformation from observations to latent space is established by a Lipschitz network-based AutoEncoder. In addition, the system dynamics and control barrier functions are all learned in the latent space. We demonstrate the efficiency, safety, and robustness of LCBFs in simulation for quadrotors and cars.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9335", "PDF Url": "https://openreview.net/pdf?id=30L0rr9W8A"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9335 by Area Chair X22b", "Subheading": "Meta ReviewbyArea Chair X22b14 Dec 2023, 03:39 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper investigate the problem of safe control in partially observable state conditions. The idea of embedding the dynamics in a latent space, and performing the safe control optimization therein is an interesting one, as it enables learning of the dynamics as well as the safe controller.\nThere is a lack of guarantees that the closed-loop trajectories in the latent space will satisfy safety constraints in the original space. More discussion and comparison with other data-driven control methods with control barrier functions would be appreciated.\nJustification For Why Not Higher Score:\nThe meta reviewer read the paper and discussions. The meta reviewer agrees with all the reviewers that this paper hasn't reached the bar of ICLR 2024.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Rebuttal Revision", "Subheading": "Official CommentbyAuthors21 Nov 2023, 15:31Everyone", "Content": "Comment:\nThank you to all reviewers for taking the time to give constructive feedback. We have added the necessary changes to the paper. Please go through them.\nMajor changes is\nremoving contribution 3\nfixing all the mathematical rigours\nAblation study to understand the importance of choosing $\\pi_{adapt}$ and how one would go about choosing the same. Appendix 8.1\nModularity of the approach in terms of new non-jointly trained $\\pi_{optimal}$. Appendix 8.2\nTraining plots of the pipeline to understand the stability of the training process. Appendix 7\nWe greatly appreciate to reviewing our manuscript and re-evaluating the score of our paper! We would like to hear your questions and answer them at the earliest."}, {"Heading": "Official Review of Submission9335 by Reviewer 5PWg", "Subheading": "Official ReviewbyReviewer 5PWg29 Oct 2023, 17:13 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper addresses the problem of safe data-driven control using neural networks when access to the state is unavailable. Observations (not necessarily the true states) are embedded in a latent space using a Lipschitz autoencoder. Using this latent representation of the dynamics, a QP-CLF based approach is used to design a safe controller in the latent space, by learning the dynamics in latent space, the controller and the barrier certificate. The safe and unsafe sets themselves are not explicitly defined; rather, they are annotated in the data using a simple formulation (eq 15). The empirical evaluation shows that the proposed approach achieves performance comparable to the state of the art.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThe paper has the following strengths.\nThe idea of embedding the dynamics in a latent space, and performing the safe control optimization therein is an interesting one, as it enables learning of the dynamics as well as the safe controller.\nIn this formulation, neither the safe set nor the dynamics need to be specified and can be learned from data.\nWeaknesses:\nThe paper has several weaknesses.\nThe discussion about safety and barrier certificates feels rushed. Safety, as defined in [1],[2], is always with respect to safe and unsafe sets. The barrier certificate conditions given in equations (4)-(5) should hold on the interior of the safe set (see, for instance, equations (4), (7) in [1]).\nThere are no discussions about guarantees that the closed-loop trajectories in the latent space will satisfy safety constraints in the canonical space (i.e. the space X from which trajectory data is initially drawn from).\nSimilarly, the learning problem should be more clearly stated - what is the dataset in question, what are the functions we are learning, and what is the loss function?\nThere is very limited discussion as to why Lipschitz autoencoders are necessary. In section 3.3, it's stated that this choice was made owing to [1], which requires the barrier certificate $B(z)$ to be Lipschitz. This is a little imprecise, as all the theorems in [1] only require that the barrier certificate (and the various functions, such as the state-dependent Hessian $H(x)$ used in the QP) be locally lipschitz.\nThere is limited discussion about other data-driven control methods, including reinforcement learning, kernel methods, gaussian processes, etc. What are the particular advantages of using potentially costly neural policies over other methods?\nIt is unclear what the authors mean with the third contribution - could that be clarified? It is not discussed anywhere else in the paper.\n[1]\nControl barrier function based\nquadratic programs for safety critical systems.\nAmes et al, 2016.\n[2]\nA framework for worst-case and stochastic safety verification using barrier certificates\n. Prajna and Rantzer, 2007.\nQuestions:\nI ask that the authors please address the points raised in the 'Weaknesses' section. Additionallly, I have the following questions for clarification.\nIt's stated in the paper that this work is motivated (at least in part) by the fact that the true state may not be accessible. This problem can be thought of as a variant of output feedback control, which has a rich history. Can you comment on the similarities and differences between this work, and other work that addresses the problem of data-driven output feedback control?\nFollowing the previous question, can one think of the latent-space embedding as a form of neural observer? If not, why not?\nIs it possible to formally analyze the performance of the closed-loop trajectories once they are decoded? For instance, is it possible to analyze the probability that the closed-loop trajectories are safe?\nIs there a practical advantage of using this technique in real-world scenarios? In particular, can you comment on the cost of inference using this neural network-based approach, to other methods?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reply to Reviewer 5PWg review's", "Subheading": "Official CommentbyAuthors19 Nov 2023, 12:35Everyone", "Content": "Comment:\nPlease find below the replies for the weaknesses mentioned by Reviewer 5PWg\nWeakness\nThe discussion about safety and barrier certificates feels rushed. Safety, as defined in [1],[2], is always with respect to safe and unsafe sets. The barrier certificate conditions given in equations (4)-(5) should hold on the interior of the safe set (see, for instance, equations (4), (7) in [1]).\nThe original definition of control barrier function (7) and function for safe set in (4) are valid. We follow a more relaxed and application-oriented definition of CBF from [3].\n[3]Robust Control Barrier\u2013Value Functions for Safety-Critical Control`\nThere are no discussions about guarantees that the closed-loop trajectories in the latent space will satisfy safety constraints in the canonical space (i.e. the space X from which trajectory data is initially drawn from).\nCan you clarify the necessity of defining a safety constraint in canonical space? To how much we understand the question, the argument we would like to put forward is that the encoder is only a mapping from canonical space to latent space. By using latent space for representing the manifold, it is still just a projection of the Canonical space. We evaluate the state of the agent from the environment for measuring safety metrics; hence, the results are supposed to be used to evaluate the safety guarantees.\nSimilarly, the learning problem should be more clearly stated - what is the dataset in question, what are the functions we are learning, and what is the loss function?\nWe will surely make it clearer in the revised manuscript, and the straightaway answer is that the functions learned are Barrier Function, Dynamics, Policy, Encoder, Hessian and linear cost matrices. Losses for Barrier Function is given by (16); for Dynamics, it is (9); for Policy, it is from the algorithm you choose. For Hessian and Linear cost matrices, it is (14). For the encoder, it is the aggregation of all the above losses. The dataset in question is episodes from each respective environment. The training process is split in two, one for data collection \\pi_adapt where labelling of states in these trajectories is done through (15). Later, the Policy with safety guarantees is trained, i.e. \\pi_optimal, while these trajectories are also used to update other algorithms.\nThere is very limited discussion as to why Lipschitz autoencoders are necessary. In section 3.3, it\u2019s stated that this choice was made owing to [1], which requires the barrier certificate to be Lipschitz. This is a little imprecise, as all the theorems in [1] only require that the barrier certificate (and the various functions, such as the state-dependent Hessian  used in the QP) be locally lipschitz.\nFor neural networks to be locally Lipschitz requires much finetuning[1]. Our functions, even though they use Lipschitz autoencoder they are locally Lipschitz with the bjork layers as through the training they only see a subset of the true state space which comes from exploration.\n[1] Exactly Computing the Local Lipschitz Constant of ReLU networks\nThere is limited discussion about other data-driven control methods, including reinforcement learning, kernel methods, gaussian processes, etc. What are the particular advantages of using potentially costly neural policies over other methods?\nThe work majorly focuses on end-to-end learning; on the contrary, data-driven control barrier functions may perform better, but they require prior modelling and knowledge of the system. The crucial idea of using neural policies over standard control algorithms is again the generalization offered in real-world scenarios. Hence, in the related works, we have majorly cited works that aim to solve similar goals."}, {"Heading": "Reply to Reviewer 5PWg review's", "Subheading": "Official CommentbyAuthors19 Nov 2023, 12:36Everyone", "Content": "Comment:\nPlease find below the replies for the questions mentioned by Reviewer 5PWg\nQuestions\nIt\u2019s stated in the paper that this work is motivated (at least in part) by the fact that the true state may not be accessible. This problem can be thought of as a variant of output feedback control, which has a rich history. Can you comment on the similarities and differences between this work, and other work that addresses the problem of data-driven output feedback control?\nYes, one can view the problem as a simple data-driven output feedback control for a nonlinear system. The only difference is the lack of safety guarantees from a Barrier Function. The rest of the system with Encoder, Policy and the Learnt Dynamics can be seen as a data-driven output feedback controller. To the best of our knowledge, a Control Barrier Function for such a controller has not been formulated and hence have not compared such approaches.\nFollowing the previous question, can one think of the latent-space embedding as a form of neural observer? If not, why not?\nIt may seem the encoder is acting as a neural observer, but unlike neural observer, the dynamics are not fixed and are also being learned for the new latent space from the encoder. Hence, we see it from a perspective of joint learning of system dynamics, policy and the CBF for the latent space and iteratively updating the latent space representation.\nIs it possible to formally analyze the performance of the closed-loop trajectories once they are decoded? For instance, is it possible to analyze the probability that the closed-loop trajectories are safe?\nYes, after decoding the trajectory from latent space to original space or using any closed loop trajectory from any other policy or controller can be verified with the learnt barrier function along with the encoder, similar to using CBF for certificates.\nIs there a practical advantage of using this technique in real-world scenarios? In particular, can you comment on the cost of inference using this neural network-based approach, to other methods?\nThe cost of inference of the system would surely be higher compared to fundamental approaches for individual components of the system, while it would also not be a fair comparison due to different hardware acceleration schemas traditional approaches use."}, {"Heading": "Response to Authors", "Subheading": "Official CommentbyReviewer 5PWg20 Nov 2023, 16:22Everyone", "Content": "Comment:\nI thank the authors for their response. Several of my questions have been answered. However, some issues, particularly concerning the first question raised, have not been satisfactorily addressed. Specifically:\nThe authors state that their formulation follows that in [3]. This does not seem to be the case - in [3], the safe set is explicitly defined in Equation (2), is stated clearly in the Problem Formulation, Definition 3, and in other places as well.  Safety is always with respect to safe and unsafe sets, and must be defined as such\nTo the authors second response, is it possible to prove (or at least demonstrate empirically) that trajectories that are safe/stable in the latent space will remain safe/stable in the original space? If not, this is a serious drawback of this work, as there would be no guarantee that the method would work once deployed. Formally speaking, suppose $\\mathbb{R}^n$ is the original space, and suppose $\\mathcal{C}\\subset\\mathbb{R}^n$ is the safe set. Let $\\mathcal{Z}$ be the latent space. How does one relate safety with respect to $\\mathcal{C}$ to trajectories in $\\mathcal{Z}$?"}, {"Heading": "Reply: Response to Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 06:09Everyone", "Content": "Comment:\nSorry for misunderstanding your question, Equation(2) in [3] defines a\nsafety target function\nwhich is being learnt in our paper. Let us assume $Z_{safe} \\in \\set{ z: h(z) \\geq 0 } $ defines the safe set and $Z_{unsafe} \\in \\set{ z : h(z) < 0 }$ define unsafe set. We have $B(z)$ in place of $h(z)$; hence we use (16) to optimize $B(z)$. This is the reason why we did not write the definition of $Z_{safe}$ or $Z_{unsafe}$ sets and only used the definitions for labelling samples using (15).\nIf we already have a safe set defined $\\mathcal{C} \\in \\mathbb{R}^D$ we can use the Decoder network in (1), which is trained with $L_{recon}$ in our formulation. This can be done by taking a trajectory in z (latent space) and decoding back to the Original Space where one can verify with the safe set $\\mathcal{C}$. \n$$\nz_{traj} \\sim \\mathcal{Z}\n$$\n$$\n\\hat{x_{traj}} = D(z_{traj})\n$$\n$\\hat{x_{traj}} \\in \\mathcal{C}$ for trajectory in safe set. \\\n$\\hat{x_{traj}} \\notin \\mathcal{C}$ for trajectory in unsafe set."}, {"Heading": "Response to Authors", "Subheading": "Official CommentbyReviewer 5PWg23 Nov 2023, 03:59Everyone", "Content": "Comment:\nI'd like to thank the authors for their continued discussion. However, while some of the ideas proposed in this work are interesting, I feel there are still several areas that lack clarity, particularly with respect to the safety set (the implicit safety constraints, and the injectivity of the mapping between the latent and canonical spaces). Based on this, I do not feel I can raise my score at this time."}]}, {"Heading": "Official Review of Submission9335 by Reviewer pAha", "Subheading": "Official ReviewbyReviewer pAha28 Oct 2023, 17:55 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nTraditional control methods for enforcing set-invariant safety involve the construction of a scalar functional such as a CBF to ensure projection to safe controls. With the advent of learning, several models that were used in generating safe controls have been replaced with learned models such as neural nets. For example, several papers learn a neural CBF while others try to fit a NN to both CBF and unknown dynamics. Here, the authors endeavor to relax the assumption of a known system/robot state. Rather, only a high-dimensional observation such as an image is known. The projection to latent space is performed using an auto-encoder to generate a latent representation. This representation is a proxy for the state and the CBF/dynamics is learnt over the representation. To learn the CBF, an appropriate loss function to separate safe and unsafe trajectories is used. The latent representation is learned end-to-end with an appropriate auto-encoder loss. The dynamics is also modeled with a neural net and learned during an exploration phase. Experimental validations are performed on several benchmarks common in CBF literature such as the quadrotor and kinematic car dynamics. Additional validation is performed using the CARLA simulator.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n2 fair\nStrengths:\nThe novelty is clear and is a good fit for this venue.\nThe experimental results and comparisons are good. The result in CARLA shows some additional effort on the authors' side.\nThe presentation and the figures in this paper are excellent and demonstrate the results clearly.\nThe specific use of Lipschitz neural networks and Bjorck layers is interesting.\nWeaknesses:\nSome of the weaknesses in terms of significance of the results and related questions are listed here.\nWhile it seems good to assume no knowledge of any aspect of the dynamics/environment, the solution can retain some structural aspects of the dynamics/environment. The approach here is to learn everything as a black box.  In contrast, this paper (\nhttps://arxiv.org/pdf/2203.02401.pdf\n) uses whatever ego-state information is available as proxy intermediate losses while training end-to-end. That might be a more realistic scenario where we have some partial information available.\nIt would be interesting for me to understand if the training is stable. In terms of the training, it would be nice to see learning curves and error bars as to how robust and repeatable the training is.\nSome of the appeal of classical control is the existence of provable guarantees especially when it comes to safety (even though those guarantees come with strings attached). While ensuring a self-driving car is safe, we are not happy if the car is safe $x\\%$ of the time. We are looking for something stronger. In this context, apart from the percentage of time the system is unsafe, it would be nice to understand how much the deviation from the safe boundary is.\nSafety is not guaranteed during the exploration phase\nQuestions:\n\u201cThe major limitation is that the typical definition of a barrier function requires state information that is not generally available in real-world scenarios.\u201d - Usually some partial state information is available so the premise is not perfectly true.\nWhen the CBF is learnt using a soft loss function, it is not for theoretical purposes a strict CBF. Rather, it is an approximate neural CBF.  Is there any way of overcoming this limitation such as using verification?\nFor the baseline comparison, is the state-assumed to be known or estimated with a different neural module. More clearly, is the main difference between the current method and baselines mainly end-to-end learning?\nIt is interesting that LCBF uses fewer episodes for learning. Is it because all components of the state are not relevant to safety and thus need not be learnt in the latent state?\nWill the method work if $\\pi^{optimal}$ changes?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reply to Reviewer pAha review's", "Subheading": "Official CommentbyAuthors19 Nov 2023, 12:26Everyone", "Content": "Comment:\nPlease find below the replies for the weakness and question mentioned by Reviewer pAha\nWeakness:\nWhile it seems good to assume no knowledge of any aspect of ... That might be a more realistic scenario where we have some partial information available.\nThe major limitation of the approach the reviewer refers to is access to true state value at training time, while the approach does not assume any such assumption and is able to train on tasks in Carla leaderboard benchmark.\nIt would be interesting for me to understand if the training is stable. In terms of the training, it would be nice to see learning curves and error bars as to how robust and repeatable the training is.\nSure, we will add training plots for dynamics, encoder and policy for selected experiments.\nSome of the appeal of classical control is the existence of provable guarantees especially when it comes to safety (even though those guarantees come with strings attached). ...  it would be nice to understand how much the deviation from the safe boundary is.\nWhile we have tried to submit the standard metrics with each environment, the CARLA leaderboard benchmark does not have any golden benchmark trajectory to compare our final policy performance with. We have produced |x_{traj} - x_{goal}| for the other environments. The computation of time to recover from an unsafe state would be highly biased as CBF is synthesized and not defined, leading to approximate results.\nSafety is not guaranteed during the exploration phase\nThis is true and also a quintessential step for training. In Carla Leaderboard, the Route Completion is lower than others because of robustness as \\pi_adapt is an MPC that rarely traverses through the unsafe set. Hence, exploration of safe and unsafe becomes crucial to learning a robust CBF.\nQuestions:\n\u201cThe major limitation is that the typical definition of a barrier function requires state information that is not generally available in real-world scenarios.\u201d - Usually some partial state information is available so the premise is not perfectly true.\nI believe the reviewer wants to address the partial availability of state information. Hence, we would like to point out that classical definitions of barrier function uses state information that is not directly available from sensors or vision modules and defining a barrier function on the partial state information is very challenging given vision and lidar information of the used environments. Hence, appealing synthesizing CBFs for such use cases\nWhen the CBF is learnt using a soft loss function, it is not for theoretical purposes a strict CBF. Rather, it is an approximate neural CBF. Is there any way of overcoming this limitation such as using verification?\nVerification of such an approach would be a great contribution to this work, but verification poses multiple challenges to understanding a baseline CBF for complex systems in latent or the Original space. Hence, we have only evaluated the performance of the system and visualized its trajectories.\nFor the baseline comparison, is the state-assumed to be known or estimated with a different neural module. More clearly, is the main difference between the current method and baselines mainly end-to-end learning?\nWhile we have tried to explain the difference between the baselines used and our approaches at the start of 4.1, summarizing the following is that other baseline approaches require defined dynamics and cost matrices and even require the use of an external state estimator for the tasks that require it. Our approach does not explicitly require any of these definitions. Hence, easier end-to-end learning approach for alike tasks.\nIt is interesting that LCBF uses fewer episodes for learning. Is it because all components of the state are not relevant to safety and thus need not be learnt in the latent state?\nThe efficiency of LCBF is higher than that of the other approaches primarily because of joint training of the latent space to optimize the loss for improving safety definition and the Policy while having all relevant state information through the reconstruction loss. This makes the system hyperparameter sensitive on the weights of individual losses for the encoder, But with sufficient experimentation, it is straightforward to get a balance of individual losses.\nWill the method work if\u00a0\\pi_optimal\u00a0changes?\nI Believe you have misunderstood \\pi_optimal with \\pi_adapt, as \\pi_optimal is the policy that is learnt through training. And \\pi_adapt is used for training sample collection. Yes, the policy \\pi_adapt plays a critical role in the robustness of the learnt CBF. As can be seen in CARLA experimentation. A sub-optimal policy which can explore the environment is sufficient for the task, and hence, we have not added additional information for the same."}, {"Heading": "Thank you for the response", "Subheading": "Official CommentbyReviewer pAha21 Nov 2023, 08:55Everyone", "Content": "Comment:\nIn RL, the training is always done in simulation and it should be okay to have access to state at training time. I would not dwell on this weakness at this stage too much. It is something to think about.\nI agree with the authors that exploration is important for learning.\n\"I believe the reviewer wants to address the partial availability of state information. Hence, we would like to point out that classical definitions of barrier function uses state information that is not directly available from sensors or vision modules and defining a barrier function on the partial state information is very challenging given vision and lidar information of the used environments. Hence, appealing synthesizing CBFs for such use cases\" - I am referring to the output-feedback control problem raised by Reviewer 5PWg. [A1] is making a contribution towards solving this problem.\nGiven that $\\pi_{optimal}$ is jointly trained, I am referring to the problem of distribution shift or covariate shift. If a different policy that is not jointly trained is used, will this setup work out-of-the-box like a classical CBF?\n[A1] Dean, Sarah, et al. \"Guaranteeing safety of learned perception modules via measurement-robust control barrier functions.\" Conference on Robot Learning. PMLR, 2021."}, {"Heading": "Reply to Reviewer pAha review's", "Subheading": "Official CommentbyAuthors21 Nov 2023, 16:34 (modified: 21 Nov 2023, 16:34)EveryoneRevisions", "Content": "Comment:\nReviews\nIn RL, the training is always done in simulation and it should be okay to have access to state at training time. I would not dwell on this weakness at this stage too much. It is something to think about.\nMajorly we wanted to focus on algorithms that can be used in realworld, and assumption from simulation make it difficult to transfer algorithms from sim to real, https://arxiv.org/pdf/2203.02401.pdf is a good example on how they extended the work https://arxiv.org/pdf/2111.11277.pdf for real world system using state estimators. Making the pipeline highly depending on these state estimators which could fail in multiple scenarios and hence propagating errors. We surely dont address the problem of sim-2-real transfer but wanted to follow this goal.\nI agree with the authors that exploration is important for learning.\n\"I believe the reviewer wants to address the partial availability of state information. Hence, we would like to point out that classical definitions of barrier function uses state information that is not directly available from sensors or vision modules and defining a barrier function on the partial state information is very challenging given vision and lidar information of the used environments. Hence, appealing synthesizing CBFs for such use cases\" - I am referring to the output-feedback control problem raised by Reviewer 5PWg. [A1] is making a contribution towards solving this problem.\nRight I believe i understand the question better now, Yes we are trying to solve the same problem as mentioned in the reply to 5PWg. [A1] is not output feedback control as they use measurement module that are perception modules to estimate the state space for the original dynamics of the problem. They are trying to unify techniques to compensate for errors in measurement modules by formulating it as a cbf for unknown dynamics. Our approach is much different as no work has explored cbf for output feedback control.\nGiven that\u00a0$\\pi_{optimal}$\u00a0is jointly trained, I am referring to the problem of distribution shift or covariate shift. If a different policy that is not jointly trained is used, will this setup work out-of-the-box like a classical CBF?\nWe have addressed the issue in the new rebuttal revision of the paper please let us know if you require any clarification on it."}, {"Heading": "Official Comment by Reviewer pAha", "Subheading": "Official CommentbyReviewer pAha22 Nov 2023, 20:42Everyone", "Content": "Comment:\nThank you for the clarification. Overall, I believe I provided fair scores to this paper and I would like to retain my score.\nIf the method is geared towards training in the real-world, it needs to be safe during exploration.\nEstimating the state from measurements is exactly one way of output feedback using what is known as the separation principle."}]}, {"Heading": "Official Review of Submission9335 by Reviewer ERPL", "Subheading": "Official ReviewbyReviewer ERPL28 Oct 2023, 03:49 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work uses autoencoder to learn latent space within which the dynamics and CBF are well-defined and proposes an algorithm for learning dynamics/CBF and an optimal policy together; which is applied to some practical tasks showing advantages.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nFor some experiments, it is shown that the proposed algorithm successfully learn CBF approximately with autoencoder architectures.\nAlgorithms are simple enough.\nWeaknesses:\nThere are some mathematically no rigorous or strange writings; e.g., page 3 top \u201care both in R^D\u201d should be \u201care both in the Euclidean space R^D\u201d or so.  Also, B(z, theta_B) should be continuously differentiable?  And B(z, theta_B) should be on R^d x parameter space (or theta_B could be given\u2026?)?  Eq 16 is a bit strange; z in Z_safe within dataset?\nIf you assume the dynamics is over the observation space (or learned latent space), it has all the information about the state; so I get the idea that the authors are trying to do encoding to get latent state, the work is not dealing with the partial observability case.  Abstract and introduction are misleading (no access to \u201call states\u201d may imply that we have partial observability).\nAnd it is mathematically just CBF (not LatentCBF or so).\nCBF is useful for giving theoretical guarantees of safety.  Although adding encoding/decoding layers for practical purpose, it adds little insights about the theoretical concept of CBF.\nQuestions:\nWhat is the systematic and robust choice of policy_adapt?  If the whole algorithm, including the learning of CBF, is robust, I believe the work becomes solid.  For now, it seems a bit ad-hoc, which hinders the benefits of practical applications (as I mentioned, the focus of this work is practical scaling to image space etc. rather than theoretical insights.  So each choice of parameters, exploration policies etc. should be made clear and robust.\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nN/A\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reply to Reviewer ERPL review's", "Subheading": "Official CommentbyAuthors19 Nov 2023, 12:28Everyone", "Content": "Comment:\nPlease find below the replies for the weakness and question mentioned by Reviewer ERPL\nWeakness\nThere are some mathematically no rigorous or strange writings; e.g., page 3 top \u201care both in R^D\u201d should be \u201care both in the Euclidean space R^D\u201d or so. Also, B(z, theta_B) should be continuously differentiable? And B(z, theta_B) should be on R^d x parameter space (or theta_B could be given\u2026?)? Eq 16 is a bit strange; z in Z_safe within dataset?\nThanks for pointing out the errors in writing, we will fix them.\nIf you assume the dynamics is over the observation space (or learned latent space), it has all the information about the state; so I get the idea that the authors are trying to do encoding to get latent state, the work is not dealing with the partial observability case. Abstract and introduction are misleading (no access to \u201call states\u201d may imply that we have partial observability). And it is mathematically just CBF (not LatentCBF or so).\nWe agree we are not solving partial observability directly, while our approach is only to use the observation from sensors and vision modules. In contrast, implicit definitions of CBF use state information, such as the position of obstacles and soon, which is not directly accessible in practical scenarios. Mathematically, it is simply a CBF as it is a synthesis of a CBF which can update based on chosen reward and environment.\nCBF is useful for giving theoretical guarantees of safety. Although adding encoding/decoding layers for practical purpose, it adds little insights about the theoretical concept of CBF.\nAs rightly outlined, our work focuses on practical usage of CBF as a generalized module for deep reinforcement learning approaches.\nQuestions\nWhat is the systematic and robust choice of policy_adapt? If the whole algorithm, including the learning of CBF, is robust, I believe the work becomes solid. For now, it seems a bit ad-hoc, which hinders the benefits of practical applications (as I mentioned, the focus of this work is practical scaling to image space etc. rather than theoretical insights. So each choice of parameters, exploration policies etc. should be made clear and robust.\nThank you for pointing out the ambiguity in the selection decisions of such hyperparameters. We are in progress of updating the current manuscript with an addition section in the Appendix for the same."}, {"Heading": "Thank you for the response", "Subheading": "Official CommentbyReviewer ERPL19 Nov 2023, 21:33Everyone", "Content": "Comment:\nThank you for the response to my concerns.\nI wanted to let you know that I have read your responses.\nFor the first part of Weakness, i.e., about mathematical rigors, I put some questionings rather than corrections.\nSo it would be great if you could answer to those questions.\nAlso please let me know when you update the part about the systematic and robust choice of parameters; if it can be clear from the response text, it is fine with me as well (no need to thoroughly update the manuscript at this time)"}, {"Heading": "Reply to Reviewer ERPL review's", "Subheading": "Official CommentbyAuthors21 Nov 2023, 15:48Everyone", "Content": "Comment:\nWe have updated the analysis of $\\pi_adapt$ selection and also commented about the works modularity for newer policies.\nAnswering your original question, we missed\nThere are some mathematically no rigorous or strange writings; e.g., page 3 top \u201care both in R^D\u201d should be \u201care both in the Euclidean space R^D\u201d or so. Also, B(z, theta_B) should be continuously differentiable? And B(z, theta_B) should be on R^d x parameter space (or theta_B could be given\u2026?)? Eq 16 is a bit strange; z in Z_safe within dataset?\nWe have fixed the first part, which was an error in writing. Yes, B(z, theta_b) is required to be continuously differentiable over the trajectory for the optimization problem defined in Eq 6. This is also required for non-singular solutions of the optimization problem.  Yes, it is also defined on the latent space, and the shape of theta_b is d x 1, 1 because output of barrier function is just a value\nIn Eq 16, $z \\in Z_{safe}$ under the summation means we are doing a summation for all the elements in $Z_{safe}$, which we get from a set defined in Eq 15 on the trajectory collected."}, {"Heading": "Thank you again for your response", "Subheading": "Official CommentbyReviewer ERPL22 Nov 2023, 05:36Everyone", "Content": "Comment:\nThank you again for your responses; although I keep my score, I think it will be an important work if the practicality of this work (rather than the CBF theory insights) with more guidance on how one could use it to diverse domains is studied well."}]}, {"Heading": "Official Review of Submission9335 by Reviewer ciJn", "Subheading": "Official ReviewbyReviewer ciJn25 Oct 2023, 02:38 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors propose to learn a control barrier function in the latent space via an auto-encoder.  The system dynamics is learned by directly regressing over the gradient. The CBF is learned following the common loss setup in the CBF learning literature. The safe policy is learned by distillation from the CBF-QP result where the QP layer is differentiable following Brandon Amos's work. The proposed method is verified on a few tasks including car and quadrotor obstacle avoidance. The author also combined the latent CBF with an existing learned driving agent and achieved improvement in the Carla simulator.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe simulation experiment results are strong,\nThe paper is generally well-written, easy to follow\nThe idea of learning a CBF in the latent space is new\nWeaknesses:\nI don't get why learning a CBF in the latent space is more advantageous than learning in the original state space, and there is no comparison to show the benefit.\nThere lacks necessary theoretical \"book-keeping\" results to ensure that the latent CBF is well-defined and the theories for the original CBF can carry over.\nThe training process is not explained clearly, I'm confused about the training details, e.g. how is the auto-encoder trained?\nQuestions:\n\"Domain adaptation for the encoder ensuring the latent space that the latent space is always relevant and can contain features necessary for the barrier function\", please remove the first \"the latent space\"\nFor equation (2), please specify the norm used.\nHow do you guarantee the injectiveness of the encoder, i.e., each point x got mapped to a unique z?\nI don't think one can simply define a barrier function on z and apply the original CBF theory without any care. For example, assuming that z has a higher dimension than x (which is probably true), all z that are mapped from an x live on a manifold. The original CBF theory is built on assumptions that involve openness and compactness of certain sets, which may be violated here. For one, the image of the safe set in the latent space may even be disconnected when the original safe set is connected or the other way around.\nI find the dynamics learning problem very weird, it seems that the assumption is that you can observe \\dot{x} directly, yet the dynamics is unknown. This is almost never the case in practice as gradient observation is very noisy. The authors may consider a discrete-time CBF setting for practicality.\nAs mentioned above, please provide more details on the training process, is the training end to end, if not, how many steps and which components are fixed, which are being trained in each step?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reply to Reviewer ciJn review's", "Subheading": "Official CommentbyAuthors19 Nov 2023, 12:31 (modified: 19 Nov 2023, 14:10)EveryoneRevisions", "Content": "Comment:\nPlease find below the replies for the weakness and question mentioned by Reviewer ciJn\nWeakness\nI don\u2019t get why learning a CBF in the latent space is more advantageous than learning in the original state space, and there is no comparison to show the benefit.\nThe experiments comparing barrier net and rlcbf-qp are done to show why learning on latent space is advantageous in terms of increased sample efficiency with better or on-par results and experiment with Carla is demonstration scalability in high dimensional environment which would be a strenuous modelling task for previous cbf based approaches.\nThere lacks necessary theoretical \u201cbook-keeping\u201d results to ensure that the latent CBF is well-defined and the theories for the original CBF can carry over.\nWe would be happy to understand what specific class of results you are trying to point.\nThe training process is not explained clearly, I\u2019m confused about the training details, e.g. how is the auto-encoder trained?\nWe apologize for the same, we have trained the autoencoder with (9), (14) and (16) losses on the samples from \\pi_{adapt}.\nQuestions\n\u201cDomain adaptation for the encoder ensuring the latent space that the latent space is always relevant and can contain features necessary for the barrier function\u201d, please remove the first \u201cthe latent space\u201d\nThank you for pointing out will do the same.\nFor equation (2), please specify the norm used.\nEquation (2) is for denoting the basic Lipschitz criterion, for our use its Euclidean Norm.\nHow do you guarantee the injectiveness of the encoder, i.e., each point x got mapped to a unique z?\nAs we aim to learn a compact but rich representation, we do not specifically check for a one-to-one behaviour of our encoder as we need it to generalize over different conditions while only being able to represent important features required by the policy and the CBF.\nI don\u2019t think one can simply define a barrier function on z and apply the original CBF theory without any care. For example, assuming that z has a higher dimension than x (which is probably true), all z that are mapped from an x live on a manifold. ... For one, the image of the safe set in the latent space may even be disconnected when the original safe set is connected or the other way around.\nWe agree that for high dimensional data like the one we present here containing information from images and sensors, the final representation learnt may have many finite subcovers. However, we have visually demonstrated that the subcovers for the safe set are well separated on the manifold. It is important to understand that the 2-dimensional space on which the manifold is plotted is obtained from NMF of the latent space, which leads to the union of these subcovers into the visualized manifold. The crucial implementation detail which assists the formation of closed sets for defining a barrier function according to the theory is Lipschitz networks as opposed to simple neural network layers and activations. Reducing the number of closed sets that are safe sets. This is an approximation for designing our system and not a guarantee.\nI find the dynamics learning problem very weird, it seems that the assumption is that you can observe \\dot{x} directly, ... The authors may consider a discrete-time CBF setting for practicality.\nWe agree that Discrete-time analysis would be better for defining System dynamics; while this would be a good direction of experimentations, this would detract from the current approach as the discrete control barrier function involves multiple challenges. The approach of learning the dynamics via gradient observation is a good approximation, gradient observation has been employed in multiple works (9) in [1], (27) in [2], (25) in [3], where such gradients are used as ground truth or have been part of the loss function for uncertain dynamics models. References: [1] Learning for Safety-Critical Control with Control Barrier Functions [2] Online Adaptive Compensation for Model Uncertainty Using Extreme Learning Machine-based Control Barrier Functions [3] Learning a Better Control Barrier Function Under Uncertain Dynamics\nAs mentioned above, please provide more details on the training process, is the training end to end, if not, how many steps and which components are fixed, which are being trained in each step?\nWe will update the manuscript with better details of the training process. There are two phases of training: one for sample collection done for training the dynamics and the autoencoder, similar to system identification with \\pi_adapt Policy; this is a policy with no safety guarantees, and phase 2 is training of policy \\optimal (which is the same policy \\pi_adapt), CBF and autoencoder all the results mentioning the number of episodes is the sum of episodes from both the phases."}, {"Heading": "Official Comment by Reviewer ciJn", "Subheading": "Official CommentbyReviewer ciJn20 Nov 2023, 12:31Everyone", "Content": "Comment:\nI appreciate the authors providing additional details and explanations. However, my main concern remains,  that is, this paper doesn't provide much theoretical advancement for neural CBF, and on the practical side, the improvement over existing learning-based CBF methods is not significant. Overall, I find the paper's contribution below the bar of ICLR."}, {"Heading": "Reply to Reviewer ciJn", "Subheading": "Official CommentbyAuthors21 Nov 2023, 15:36 (modified: 21 Nov 2023, 15:37)EveryoneRevisions", "Content": "Comment:\nThank you for your elucidative comments about the work. We do agree that the paper doesn't contribute to any theoretical advancement of CBFs but rather a modular pipeline for working with partially observed systems in RL. We would be happy to discuss which other learning-based CBF methods are suitable for such a task with unknown system definitions."}]}]}, "78iGZdqxYY": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "graph distillation, graph classification, frequent pattern mining", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "An unsupervised and model/hyper-parameter agnostic graph distillation algorithm for graph classification.", "Abstract": "GNNs, like other deep learning models, are data and computation hungry. There is a pressing need to scale training of GNNs on large datasets to enable their usage on low-resource environments. Graph distillation is an effort in that direction with the aim to construct a smaller synthetic training set from the original training data without significantly compromising model performance. While initial efforts are promising, this work is motivated by two key observations: (1) Existing graph distillation algorithms themselves rely on training with the full dataset, which undermines the very premise of graph distillation. (2) The distillation process is specific to the target GNN architecture and hyper-parameters and thus not robust to changes in the modeling pipeline. We circumvent these limitations by designing a distillation algorithm called MIRAGE for graph classification. MIRAGE is built on the insight that a message-passing GNN decomposes the input graph into a multiset of computation trees. Furthermore, the frequency distribution of computation trees is often skewed in nature, enabling us to condense this data into a concise distilled summary. By compressing the computation data itself, as opposed to emulating gradient flows on the original training set\u2014a prevalent approach to date\u2014MIRAGE transforms into an unsupervised and architecture-agnostic distillation algorithm. Extensive benchmarking on real-world datasets underscores MIRAGE\u2019s superiority, showcasing enhanced generalization accuracy, data compression, and distillation efficiency when compared to state-of-the-art baselines.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "learning on graphs and other geometries & topologies", "Submission Number": "9334", "PDF Url": "https://openreview.net/pdf?id=78iGZdqxYY"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9334 by Area Chair A8ma", "Subheading": "Meta ReviewbyArea Chair A8ma05 Dec 2023, 18:05 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nAn interesting contribution to graph distillation, MIRAGE, is proposed here. Leveraging the computational tree representations induced by message passing models, the authors construct appropriate compressions which demonstrate convincing performance across a variety of datasets. After a successful rebuttal, the reviewers are unanimous in recommending acceptance. I have no reservations to back this recommendation.\nJustification For Why Not Higher Score:\nI find that in its present form the paper just about exceeds the bar of ICLR publication---no reviewer championed it for a stronger outcome. I also think that a more comprehensive comparison over types of GNN baselines (including models like MPNN) would have been paramount for this work to make it to the next level.\nJustification For Why Not Lower Score:\nThe reviewers unanimously recommend acceptance after the Authors' rebuttal, and I am in agreement with them."}, {"Heading": "Looking forward to your feedback on rebuttal", "Subheading": "Official CommentbyAuthors20 Nov 2023, 13:12Everyone", "Content": "Comment:\nDear Reviewers,\nThank you once again for all of your constructive comments, which have helped us significantly improve the paper! As detailed below, we have performed several additional experiments and analyses to address the comments and concerns raised by the reviewers.\nSince we are into the last two days of the discussion phase, we are eagerly looking forward to your post-rebuttal responses.\nPlease do let us know if there are any additional clarifications or experiments that we can offer. We would love to discuss more if any concern still remains. Otherwise, we would appreciate it if you could support the paper by increasing the score.\nThank you!\nAuthors"}, {"Heading": "Summary of rebuttal", "Subheading": "Official CommentbyAuthors18 Nov 2023, 07:14 (modified: 15 Mar 2024, 00:27)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewers for their insights and constructive suggestions. A comprehensive point-by-point response to the reviewers' comments is presented below. We have updated the main manuscript and the appendix to address these comments. The changes made in the manuscript are highlighted in\nblue\ncolor. The\nmajor additional changes\nare listed below.\nAdditional experiments:\nWe have incorporated all of the additional experiments requested by the reviewers spanning\nextensive parameter sensitivity analysis\nempirical validation of information content in frequent patterns\ngeneralization to node classification\nmulti-class classification\nPresentation\n: We have addressed several presentation-related inquiries, such as better illustration of the frequency distribution of computation trees (Fig. 1) and the usage of the \"unsupervised\" term in describing MIRAGE.\nWe hope these revisions will satisfactorily address the concerns raised by the reviewers and elevate the overall quality of our work."}, {"Heading": "Public Comment by Jiahao Wu", "Subheading": "Public CommentbyJiahao Wu14 Nov 2023, 01:10Everyone", "Content": "Comment:\nThe approach presented in this paper can be characterized more as a sub-structure mining algorithm than a graph distillation method. Nevertheless, it introduces a novel perspective on graph distillation. Empirical results demonstrate comparable performance to traditional graph distillation, a noteworthy observation. While the condensation rate and classification performance show promise, it is advisable for the authors to provide a clear rationale for the significantly smaller sizes of computation tree sets compared to the sizes of graphs. This explanation is crucial, as the process of decomposing a graph into a set of computation trees might intuitively be expected to result in larger storage requirements due to potential overlap of nodes in non-isometric trees.", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors19 Nov 2023, 05:47Everyone", "Content": "Comment:\nTo explain the high compression achieved by MIRAGE, we first would like to point to Figure 1 in the paper and the discussion associated with it in Section 3.2. We observe that frequency distribution of computation trees is a long-tail distribution. The plot shows that a compact set of top-k frequent trees(non-isometric) captures a substantial portion of the distribution mass of the dataset. As the distillation process of Mirage builds the condensed dataset using\nonly\nthese frequent trees, hence, the storage is low. Furthermore, these trees are only n layers deep, where n is the number of layers in GNN. Typically n is within 3.\nFinally, we also point to the sufficiency experiments in Sec 4.4. The experiments indicate that the loss is similar for both the distilled dataset and the full dataset when using a model with weights trained on the full dataset. Thus, showcasing the GNN is attending to these frequent patterns primarily. This behavior by the GNN is not surprising. Specifically, gradient descent will run more iterations on trees that it sees more often and hence infrequent trees have limited impact on the gradients."}, {"Heading": "Public Comment by Jiahao Wu", "Subheading": "Public CommentbyJiahao Wu24 Nov 2023, 02:45Everyone", "Content": "Comment:\nThanks for your detailed explanation."}]}, {"Heading": "Official Review of Submission9334 by Reviewer 2KBE", "Subheading": "Official ReviewbyReviewer 2KBE01 Nov 2023, 19:46 (modified: 23 Nov 2023, 00:42)EveryoneRevisions", "Content": "Summary:\nThis paper proposes MIRAGE, a model-agnostic graph distillation method for graph classification task. Specifically, the authors first observe that existing graph distillation methods still rely on training with the full dataset and specific to GNNs architectures and hyper-parameters. To this end, MIRAGE can tackle these two limitations via decomposing input graphs into computation trees. The long-tailed frequency distribution of the computation tree enables the graph distillation with a high compression ratio. Experiments demonstrate the superiority of MIRAGE in terms of its effectiveness, compression ratio, and distillation efficiency.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThis paper is well-organized and easy to follow.\nThe idea of making graph distillation model-agnostic is interesting and meaningful in practice.\nThe proposed data-centric solution is a natural way to mitigate model hyperparameter dependency using the frequency distribution of the computation tree.\nWeaknesses:\nMotivations:\n(a) Problem Motivation: In the abstract, one of the identified limitations pertains to the reliance on training with the full dataset. To provide a clearer argument regarding the necessity of full dataset training for existing methods and the distinct advantages of MIRAGE, we should consider the following: What is the comparative performance of existing distillation methods (e.g., gradient matching) when applied to both randomly initialized and well-trained models? Is there a substantial performance gap between the two scenarios? Regarding computational costs in the distillation process, it's worth examining the resource requirements for calculating the computation tree frequency distribution, particularly in the context of deep GNNs. How does this computational overhead compare to training models on the full dataset?\n(b) Technical Motivation: While the concept of the computation tree is inherent to GNNs, we should address the sufficiency of the frequency distribution for the computation tree. Key points to explore include: Why is maintaining a high computation tree frequency distribution sufficient for effective learning? What is the distribution pattern of the computation tree, and does it exhibit a long-tail distribution?\nObjectives: Ideally, the distillate data should mirror the distribution of the full dataset, implying that the gradients of the distillate data should align with those of the full dataset for any model (random or well-trained). It's essential to clarify that while distillation can reduce computation costs, the primary objective remains data distillation. Additionally, considering the architecture transferability for existing graph distillation methods, the advantage of model-agnostic techniques is not significant.\nExperiments:\n(a) Comprehensive Model Comparison: In evaluating baselines, it would be beneficial to perform a comprehensive comparison across various model architectures. Specifically, assessing performance across different architecture pairs would enhance the evaluation's robustness and provide insights into transferability.\n(b) Baselines and Model Initialization: Investigate the significance of GNN model training prior to distillation for baselines. Explore performance outcomes for well-trained, randomly initialized, and warm-up trained models. Understanding the effectiveness of random initialization can help determine the necessity of training on the full data for baseline methods.\n(c) Hyperparameter Investigation: Explore the impact of different hyperparameters, such as threshold values and the number of hops, on various metrics, including accuracy, efficiency, compression ratio, and transferability.\n(d) Trade-off Analysis: Provide insights into the trade-off between accuracy, efficiency, and compression ratio. Understanding these trade-offs can offer valuable guidance for practical applications.\nIn a nutshell, I am currently leaning toward weak rejection. I am looking forward to the authors\u2019 response.\n-------------------After rebuttal -------------------------\nThanks for the response. I increase my score to 6.\nQuestions:\nPlease see the weakness part.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 2KBE: Part 1", "Subheading": "Official CommentbyAuthors18 Nov 2023, 07:18Everyone", "Content": "Comment:\n1a(i). Problem motivation: What is the comparative performance of existing distillation methods (e.g., gradient matching) when applied to both randomly initialized and well-trained models? Is there a substantial performance gap between the two scenarios?\nResponse:\nBelow we present the AUCROC numbers of DosCOND on randomly initialized DosCOND model, warm start (100 epochs) and training DosCOND until convergence (typically 1000 epochs). As visible, there is a noticeable gap in the AUCROC numbers indicating training until convergence is necessary. This discussion has been added App. D.\nDataset\nRandom\nWarm start\nConvergence\nogbg-molbace\n$55.04\\pm9.07$\n$59.25\\pm1.61$\n$67.34\\pm1.84$\nNCI1\n$51.22\\pm2.00$\n$48.18\\pm2.78$\n$57.90\\pm0.75$\nogbg-molbbbp\n$52.64\\pm1.98$\n$50.72\\pm3.48$\n$59.19\\pm0.95$\nogbg-molhiv\n$48.21\\pm5.95$\n$34.99\\pm7.25$\n$73.16\\pm0.69$\nDD\n$52.39\\pm7.19$\n$61.58\\pm2.11$\n$68.39\\pm9.64$\n1a(ii). Regarding computational costs in the distillation process, it's worth examining the resource requirements for calculating the computation tree frequency distribution, particularly in the context of deep GNNs. How does this computational overhead compare to training models on the full dataset?\nResponse:\nThe time taken to distill each dataset is provided in Fig. 4(a) in the form of a bar plot and the raw numbers are in Table E. MIRAGE is $\\approx$ 500 times faster on average than KIDD and $\\approx 150$ times faster than DOSCOND. To further expand on this aspect, we have added the following new experiments:\nComparison to full dataset training time:\nWe now report the time taken to train on the full dataset in Table I in Appendix. On average, the distillation time of MIRAGE is more than $30$ times faster than training on the full dataset. In contrast DosCOND and KiDD are slower than full dataset training due to reasons already highlighted in Sec 1 of our manuscript.\nImpact of hops (layers):\nIn Fig. H (discussed in App F and referred to from Sec 4.4 in main paper), we report the growth in distillation time against the number of hops. We show that even at a larger values of hops, MIRAGE is 2 to 25 times faster, on average, than training on the full dataset.\nImpact of frequency threshold on distillation:\nwe subject the system to variations in threshold parameters, graphically showing the resulting time in Figure 6. Notably, the distillation process exceeds the time of full dataset training solely under extreme threshold values. This divergence occurs when distilled dataset reaches equality with the full dataset in size post-distillation. Conversely, for pragmatic threshold values, the dataset distillation procedure consistently manifests as a significantly faster option to full dataset training.\n1b. Technical Motivation: While the concept of the computation tree is inherent to GNNs, we should address the sufficiency of the frequency distribution for the computation tree. Key points to explore include: Why is maintaining a high computation tree frequency distribution sufficient for effective learning? What is the distribution pattern of the computation tree, and does it exhibit a long-tail distribution?\nResponse\n: We note that the frequency distribution of computation trees is already reported in our manuscript in Fig. 1 and it is indeed a long-tail distribution. To further establish the sufficiency of frequent tree patterns, we have now dedicated an explicit section (Sec 4.4).\nSufficiency of frequent patterns:\nIn order to establish sufficiency of frequent tree patterns in capturing the dataset characteristic, we conduct the following experiment. We train the model on the full dataset and store its weights at each epoch. Then, we freeze the model at the weights after each epoch's training and pass both the distilled dataset consisting of just the frequent tree patterns, and the full dataset. We then compute the differences between the losses as shown in Figure 5(a) (GCN) and Figure I (GCN, GAT, and GIN). The rationale behind this is that the weights of the full model recognise the patterns that are important towards minimizing the loss. Now, if the same weights continue to be effective on the distilled train set, it indicates that the distilled dataset has retained the important information. In the figure, we can see that the difference quickly approaches $0$ for all the models for all the datasets, and only starts at a high value at the random initialization where the weights are not yet trained to recognize the important patterns. Furthermore, gradient descent will run more iterations on trees that it sees more often and hence infrequent trees have limited impact on the gradients. These results empirically establish the sufficiency of frequent tree patterns in capturing the majority of the dataset characteristics."}, {"Heading": "part 2", "Subheading": "Official CommentbyAuthors18 Nov 2023, 07:19 (modified: 18 Nov 2023, 07:32)EveryoneRevisions", "Content": "Comment:\n2(i). Objectives: Ideally, the distillate data should mirror the distribution of the full dataset, implying that the gradients of the distillate data should align with those of the full dataset for any model (random or well-trained). It's essential to clarify that while distillation can reduce computation costs, the primary objective remains data distillation.\nResponse\n: As mentioned in our response to 1b, the frequency distribution of computation trees is long tailed. With the newly added sufficiency experiments, we now also show that the frequent trees are the patterns that are being learned by the model parameters as well (Response to 1b.). Finally in Fig. 5b and J, we also show that the train losses on full dataset and distilled datasets, with their own respective training weights, are also aligned.\n2(ii). Objectives: Additionally, considering the architecture transferability for existing graph distillation methods, the advantage of model-agnostic techniques is not significant.\nResponse:\nOur manuscript includes experiments to evaluate transferability of model architectures in graph distillation. The results, reported in Table F of Appendix C, reveal there is a noticeable drop in AUCROC when the model architecture for distillation is different than the architecture used for training on the distilled dataset. The same observation has been reported in another recent work as well (See Table 3 in [1]). In KiDD [2], they theoretically establish why the distillation GNN and the training GNN needs to be same (Page 3 in KiDD). These results provide verification of why model-agnostic distillation is a problem of importance.\nTo better highlight these results and motivate the proposed problem, we now point to this information from the introduction itself.\n[1] Beining Yang, Kai Wang, Qingyun Sun, Cheng Ji, Xingcheng Fu, Hao Tang, Yang You, and Jianxin Li. Does graph distillation see like vision dataset counterpart? NeurIPS, 2023*.(to appear)\n[2] Zhe Xu, Yuzhong Chen, Menghai Pan, Huiyuan Chen, Mahashweta Das, Hao Yang, and Hanghang Tong. Kernel ridge regression-based graph dataset distillation. ACM SIGKDD, 2023\nExperiments: 3a. Comprehensive Model Comparison: In evaluating baselines, it would be beneficial to perform a comprehensive comparison across various model architectures. Specifically, assessing\nperformance across different architecture pairs\nwould enhance the evaluation's robustness and provide insights into transferability.\nResponse:\nOur evaluation already includes performance assessment across three different GNN architectures namely- GCN, GAT, and GIN, in Table 2. The results establish the proposed technique to be superior on average and consistently ranked among the top-2 distillation algorithms across all dataset-architecture combinations.\nIn addition, cross architecture transferability, i.e., the situation where the architecture used for distillation is different from the one used for training and inference is also included in Appendix C. As discussed in our response to 2(ii), there is a noticeable drop in AUCROC, which is consistent with existing literature [1]. This result motivates the need for model-agnostic distillation algorithms.\n3b. Baselines and Model Initialization: Investigate the significance of GNN model training prior to distillation for baselines. Explore performance outcomes for well-trained, randomly initialized, and warm-up trained models. Understanding the effectiveness of random initialization can help determine the necessity of training on the full data for baseline methods.\nResponse\n: Below we present the AUCROC numbers of DosCOND on randomly initialized DosCOND model, warm start (100 epochs) and training DosCOND until convergence (typically around 1000 epochs). As visible, there is a noticeable gap in the AUCROC numbers indicating full training is necessary. This discussion has been added App. D.\nDataset\nRandom\nWarm start\nConverged\nogbg-molbace\n$55.04\\pm9.07$\n$59.25\\pm1.61$\n67.34$\\pm$ 1.84\nNCI1\n$51.22\\pm2.00$\n$48.18\\pm2.78$\n57.90$\\pm$ 0.75\nogbg-molbbbp\n$52.64\\pm1.98$\n$50.72\\pm3.48$\n59.19$\\pm$ 0.95\nogbg-molhiv\n$48.21\\pm5.95$\n$34.99\\pm7.25$\n73.16$\\pm$ 0.69\nDD\n$52.39\\pm7.19$\n$61.58\\pm2.11$\n68.39$\\pm$ 9.64"}, {"Heading": "part 3", "Subheading": "Official CommentbyAuthors18 Nov 2023, 07:19Everyone", "Content": "Comment:\n3c. Hyperparameter Investigation: Explore the impact of different hyperparameters, such as threshold values and the number of hops, on various metrics, including accuracy, efficiency, compression ratio, and transferability.\nResponse:\nAll of these experiments have been incorporated in the revised manuscript.\nImpact of Frequency Threshold on distillation time, compression and accuracy (AUCROC):\nIn Section 4.5 (Figure 6 presents the results), we measure the impact of frequency threshold on the distillation time. MIRAGE is significantly faster than training on full datasets unless the frequency thresholds are set to extreme values where the distilled dataset reaches equality with the full dataset.\nIn Fig. L in Appendix, we present the relationship between compression and AUCROC. The compression ratio is controlled by increasing the frequency threshold, i.e., the higher the threshold, the more is the compression. As noted, there is marginal improvement in AUCROC with lower thresholds (higher distillation size). This trend can be explained from the long-tailed distribution of computation trees. Even if we incorporate more computation trees, they have negligible impact on capturing more of the distribution mass and hence limited effect on AUCROC.\nImpact of number of hops (layers):\nThe details are furnished in Appendix F and H of the appendix. We note the main observations here. First, even under high hop counts from the GNN perspective, the distillation process is more time-efficient than complete dataset training. Moreover, the distilled dataset's performance converges closely with that of the full dataset, as evident in Table 2. Second, the distillation process exceeds the time of full dataset training solely under extreme threshold values. This divergence occurs when distilled dataset reaches equality with the full dataset in size post-distillation.\nIn Fig. K in Appendix, we present the impact of hops on the AUC. We see mild deterioration in AUC at higher hops. This is consistent with the literature since GNNs are known to suffer from oversmoothing and oversquashing at higher layers[1].\nTransferability:\nOur algorithm is model-agnostic. Hence, transferability of knowledge from one model to another is not relevant for MIRAGE.\nIn summary, for pragmatic threshold values, the dataset distillation procedure consistently manifests as a significantly faster option to full dataset training.\n[1] Hamed Shirzad, Ameya Velingker, Balaji Venkatachalam, Danica J. Sutherland, and Ali Kemal Sinop. Exphormer: Sparse transformers for graphs. In ICML, 2023\n3d. Trade-off Analysis: Provide insights into the trade-off between accuracy, efficiency, and compression ratio. Understanding these trade-offs can offer valuable guidance for practical applications.\nResponse:\nAs mentioned in our response to Q3c above, the trade-off between compression ratio and AUCROC has been discussed in detail in App H (also references from Sec 4.5 in main paper). In our response to 3c., we also discuss the impact of frequency threshold on the distillation time. This is also discussed in detail in Sec 4.5."}, {"Heading": "Looking forward to your feedback", "Subheading": "Official CommentbyAuthors20 Nov 2023, 06:56Everyone", "Content": "Comment:\nDear Reviewer,\nWe thank you for taking the time to provide constructive comments, which have significantly improved the quality of the manuscript. In our revision, we have incorporated all of the given suggestions including:\nEstablishing sufficiency of frequent patterns through detailed empirical studies.\nDetailed study on the impact of random, warm-start and fully trained models on supervised distillation algorithms\nExtensive study of hyper-parameter sensitivity on accuracy (AUCROC), compression and running time.\nWith these additional experiments and improved explanations, we hope we have addressed all the concerns raised by the reviewer. If there are any outstanding concerns, we request the reviewer to please raise those. Otherwise, we would really appreciate it if the reviewer could increase the score.\nLooking forward to your response.\nThank you,\nAuthors"}, {"Heading": "Eagerly waiting for post-rebuttal feedback", "Subheading": "Official CommentbyAuthors21 Nov 2023, 12:11Everyone", "Content": "Comment:\nDear Reviewer,\nWe thank you for the insightful comments on our work. Your suggestions have now been incorporated in our revision and we are eagerly waiting for your feedback. As the author-reviewer discussion phase is approaching its conclusion in just a few hours, we are reaching out to inquire if there are any remaining concerns or points that require clarification. Your feedback is crucial to ensure the completeness and quality of our work.\nWe are pleased to share that the responses from other reviewers indicate a positive inclination towards acceptance. Your support in this final phase, particularly if you find the revisions satisfactory, would be immensely appreciated.\nregards,\nAuthors"}, {"Heading": "Keenly Seeking Your Feedback on Revised Manuscript", "Subheading": "Official CommentbyAuthors22 Nov 2023, 08:30Everyone", "Content": "Comment:\nDear Reviewer 2KBE,\nWe sincerely appreciate your insightful comments on our manuscript. Your valuable suggestions have been incorporated into our revision, and we are eager to receive your feedback.\nWe are particularly encouraged by your comment\n\"I am looking forward to the authors\u2019 response.\"\nWith the author-reviewer discussion phase concluding shortly, we would like to check if there are any lingering concerns or areas that may require further clarification. Your support in this final phase, especially if you find the revisions satisfactory, would be of immense significance. Your feedback and evaluation play a pivotal role in determining the ultimate fate of our work.\nregards,\nAuthors"}, {"Heading": "Earnestly awaiting feedback from Reviewer 2KBE", "Subheading": "Official CommentbyAuthors22 Nov 2023, 21:42Everyone", "Content": "Comment:\nDear Reviewer 2KBE,\nWe earnestly appeal to you to share your feedback on our revised version. We are happy to inform you that all of the three reviewers now lean towards acceptance. Your insights and evaluation play a crucial role in deciding the ultimate fate of our work, and we are eagerly awaiting your response to the revised manuscript.\nregards,\nAuthors."}, {"Heading": "Thanks for the rebuttal", "Subheading": "Official CommentbyReviewer 2KBE23 Nov 2023, 00:41Everyone", "Content": "Comment:\nThanks for the response. I will increase my score to 6."}]}, {"Heading": "Official Review of Submission9334 by Reviewer pdUR", "Subheading": "Official ReviewbyReviewer pdUR01 Nov 2023, 18:29 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper studies a new graph distillation approach called MIRAGE for graph classification, which addresses limitations in existing methods. MIRAGE leverages the idea that message-passing GNNs break down input graphs into computation trees with skewed frequency distributions, allowing for concise data summarization. Unlike traditional methods that emulate gradient flows, MIRAGE compresses the computation data itself, making it an unsupervised and architecture-agnostic distillation algorithm.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n4 excellent\nStrengths:\nIt is crucial to address the issue of existing costs in training large-scale graphs through graph distillation, as it remains an under-explored problem.\nIt is interesting to observe how the authors have proposed an unsupervised approach for graph distillation, eliminating the requirement for parameters and model architecture, and still achieving comparable performance to the original dataset.\nThe methodology is interesting, and the performances achieved by their approach are amazing.\nWeaknesses:\nIn the results presented in Table 2, why there is a discrepancy compared to those from the original DosCond paper? Could the authors clarify why the authors deviated from the settings employed in the DosCond paper?\nIt would be beneficial if the authors could delve deeper into the sensitivity of their approach with respect to distillation parameters \\theta_1 and \\theta_2. Undertaking further experiments to report the performance across varied distillation parameters might offer greater insights, given that these parameters significantly influence the size of the distilled dataset.\nOn the ogbg-molhiv dataset, could the authors provide an explanation for the better performance observed achieved by distilled data compared to the original dataset.\nAs we are removing the nodes that exist in the less-occurring computational trees, how can we be sure that we are not losing important information in the dataset (especially since this process does not consider the feature information)?  Can authors justify it theoretically or/and empirically by running some experiments?\nQuestions:\nMy major questions are on the experimental evaluation. It would tremendously strengthen this work by addressing the concerns listed in the Weakness section.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer pdUR: part 1", "Subheading": "Official CommentbyAuthors18 Nov 2023, 07:22Everyone", "Content": "Comment:\nQ1. In the results presented in Table 2, why there is a discrepancy compared to those from the original DosCOND paper? Could the authors clarify why the authors deviated from the settings employed in the DosCOND paper?\nResponse:\nThe results in DosCOND do not exactly align with ours due to the following reasons:\nInput data:\nThe graph datasets used (both in ours and DosCOND) are node and edge labeled. In DosCOND,\nonly\nthe node labels are used for predictive modeling, whereas we use both node and edge labels. We believe this is a better empirical design since generalization error between full and distilled dataset should be measured after incorporating the full input information.\nMetrics:\nA direct comparison between the AUCROC numbers of DosCOND and ours is possible only in the three datasets of ogbg-molbace, ogbg-mohiv, and ogbg-molbbbp, since DosCOND does not use AUCROC as the evaluation metric in the other datasets. We use AUCROC across all datasets.\nPerformance of DosCOND:\nIn all three datasets, as we show in the table below (columns 2 and 3),\nDosCOND's AUCROC improves in our evaluation.\nAUCROC on full dataset training\n: We observe significantly reduced AUCROC only in ogbg-molhiv (columns 4 and 5). We conducted hyper-parameter search over a larger space than in our initial setup for ogbg-molhiv (full dataset training) to revisit this issue and identified that reducing the weight of the L2 regularizer in the loss function from 0.01 to 0.00001 improves AUCROC to $75.93$ in GCN. A similar improvement is observed in GAT and GIN as well. This update has now been incorporated in the revised draft (highlighted in blue font in Table 2).\nDataset\nDoscond AUCROC in DosCond (#Graphs=1)\nDosCond AUCROC in ours (GCN)\nFull dataset AUCROC in DosCond\nFull Dataset AUCROC in ours (GCN)\nogbg-molbace\n65.7\n67.34\n71.4\n77.31\nogbg-molbbbp\n58.1\n61.30\n64.6\n64.43\nogbg-molhiv\n72.6\n73.16\n75.7\n64.78 $\\rightarrow$ 75.93\nOther things to note:\nDosCond reports numbers only for GCN, whereas we include GCN, GAT and GIN. The budget used in our experiments is set to 1 graph per class since even with this budget, MIRAGE is smaller than DosCond (details in Table 3).\nQ2. It would be beneficial if the authors could delve deeper into the sensitivity of their approach with respect to distillation parameters $\\theta_1$ and $\\theta_2$. Undertaking further experiments to report the performance across varied distillation parameters might offer greater insights, given that these parameters significantly influence the size of the distilled dataset.\nResponse:\nWe appreciate this constructive feedback. We have significantly expanded the studies on parameter sensitivity. Below we summarize the experiments conducted and the key insights derived from them.\nImpact of Frequency Threshold on distillation time, compression and accuracy (AUCROC):\nIn Section 4.5 (Fig. 6 presents the results), we measure the impact of frequency threshold on the distillation time. MIRAGE is significantly faster than training on full datasets unless the frequency thresholds are set to extreme values where the distilled dataset reaches equality with the full dataset.\nIn Fig. L in Appendix, we present the relationship between compression and AUCROC. The compression ratio is controlled by increasing the frequency threshold, i.e., the higher the threshold, the more the compression is. As noted, there is marginal improvement in AUCROC with lower thresholds (higher distillation size). This trend can be explained from the long-tailed distribution of computation trees. Even if we incorporate more computation trees, they have negligible impact on capturing more of the distribution mass and hence limited effect on AUCROC.\nImpact of number of hops (layers):\nThe details are furnished in Appendix F and H of the appendix. We note the main observations here. First, even under high hop counts from the GNN perspective, the distillation process is more time-efficient than complete dataset training. Moreover, the distilled dataset's performance converges closely with that of the full dataset, as evident in Table 2. Second, the distillation process exceeds the time of full dataset training solely under extreme threshold values. This divergence occurs when distilled dataset reaches equality with the full dataset in size post-distillation.\nIn Fig. K in Appendix, we present the impact of hops on the AUC. We see mild deterioration in AUC at higher hops. This is consistent with the literature since GNNs are known to suffer from oversmoothing and oversquashing at higher layers[1].\nIn summary, for pragmatic threshold values, the dataset distillation procedure consistently manifests as a significantly faster option to full dataset training.\n[1] Hamed Shirzad, Ameya Velingker, Balaji Venkatachalam, Danica J. Sutherland, and Ali Kemal Sinop. Exphormer: Sparse transformers for graphs. In ICML, 2023"}, {"Heading": "part 2", "Subheading": "Official CommentbyAuthors18 Nov 2023, 07:23Everyone", "Content": "Comment:\nQ3. On the ogbg-molhiv dataset, could the authors provide an explanation for the better performance observed achieved by distilled data compared to the original dataset.\nResponse:\nAs noted in our response to Q1, the performance on distilled dataset of ogbg-mohiv no longer outperforms the full dataset. Nonetheless, as we note in our manuscript, improved performance on the distilled dataset is possible and has been observed in the literature (Ex. In KiDD also this phenomenon has been reported). We reproduce the relevant text verbatim below.\nWe observe instances, such as in DD, where the distilled dataset outperforms the full dataset, an outcome that might initially seem counter-intuitive. This phenomenon has been reported in the literature before~\\citep{KIDD}. While pinpointing the exact cause behind this behavior is challenging, we hypothesize that the distillation process may tend to remove outliers from the training set, subsequently leading to improved accuracy. Additionally, given that distillation prioritizes the selection of graph components that are more informative to the task, it is likely to retain the most critical patterns, resulting in enhanced model generalizability.\nQ4. As we are removing the nodes that exist in the less-occurring computational trees, how can we be sure that we are not losing important information in the dataset (especially since this process does not consider the feature information)? Can authors justify it theoretically or/and empirically by running some experiments?\nResponse:\nThe above question is indeed important. We have now included a new experiment to evaluate the\nsufficiency\nof the frequent computation tree patterns.\nSufficiency of frequent patterns:\nIn order to establish sufficiency of frequent tree patterns in capturing the dataset characteristic, we conduct the following experiment. We train the model on the full dataset and store its weights at each epoch. Then, we freeze the model at the weights after each epoch's training and pass both the distilled dataset consisting of just the frequent tree patterns, and the full dataset. We then compute the differences between the losses as shown in Figure I (GCN, GAT, and GIN). The rationale behind this is that the weights of the full model recognise the patterns that are important towards minimizing the loss. Now, if the same weights continue to be effective on the distilled train set, it indicates that the distilled dataset has retained the important information. In the figure, we can see that the difference quickly approaches $0$ for all the models for all the datasets, and only starts at a high value at the random initialization where the weights are not yet trained to recognize the important patterns. Furthermore, gradient descent will run more iterations on trees that it sees more often and hence infrequent trees have limited impact on the gradients. These results empirically establish the sufficiency of frequent tree patterns in capturing the majority of the dataset characteristic.\nFeature information:\nFinally, we wanted to point out that we do consider feature information. In Def 2, we define graph (tree) isomorphism where feature correspondence is a required condition (Constraint (2)). Frequency is counted based on this definition (Eq. 6).\nAdditional information relevant to this question:\nIn Fig. 1, we show that the distribution of computational trees is long-tailed and hence by considering only the top-$k$ most frequent trees, majority of the input information processed by the GNN would be retained. Furthermore, in Fig. 5 (b), we show that the training loss against epochs is similar for the full dataset and distilled dataset."}, {"Heading": "Eagerly awaiting feedback on rebuttal", "Subheading": "Official CommentbyAuthors21 Nov 2023, 00:08Everyone", "Content": "Comment:\nDear Reviewer,\nSince we are only a day away from the completion of the discussion phase, we are eagerly awaiting your feedback on the revised manuscript.\nYour review pointed out important empirical studies that further enhanced our work. We have incorporated all of them and we thank the reviewer again for the deep insightful comments on our work. We would love to discuss more if any concern remains unaddressed. Otherwise, we would really appreciate it if you could support the paper by increasing the score.\nregards,\nAuthors"}, {"Heading": "Thanks for the rebuttal", "Subheading": "Official CommentbyReviewer pdUR21 Nov 2023, 10:38Everyone", "Content": "Comment:\nThanks for the response. I tend to accept this paper and will maintain my score."}]}, {"Heading": "Official Review of Submission9334 by Reviewer yzvf", "Subheading": "Official ReviewbyReviewer yzvf01 Nov 2023, 04:49 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents a model-agnostic graph distillation algorithm for graph classification, which aims to distill the original graph dataset into a small and compact synthetic dataset maintaining competitive model performance. It is pointed out that existing distillation methods typically rely on model-related information and need to train on the full dataset, resulting in poor generalization and efficiency issues, respectively. To address these weaknesses, MIRAGE directly compresses the computation trees to synthesize datasets by mining sets of frequently co-occurring items. This is inspired by the observation that the distribution of the computation trees, formed by decomposing graphs based message-passing GNN frameworks, always exhibits high skewness. Therefore, it is possible to approximate the true graph representation by aggregating the root representations of only the highly frequent trees. Extensive benchmarking demonstrates the superiority of MIRAGE.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThis paper distills the original graph dataset into a novel form, namely the sets of computation trees, instead of traditional feature and structure information, i.e. X\u2019 and A\u2019.\nThis paper not only improves generalization by avoiding model-related computation but also addresses the limitation of the traditional distillation step that necessitates training on the entire dataset.\nMIRAGE demonstrates superiority from various metrics, i.e. predictive accuracy, distillation efficiency, and data compression rates.\nWeaknesses:\nUnlike DOSCOND and KIDD, MIRAGE seems infeasible to be generalized to node classification tasks.\nThere is no theoretical analysis nor experimental proof to investigate the error when approximating the true graph representation by aggregating the root representations of only the highly frequent trees.\nMIRAGE compresses the computation trees by mining the set of frequently co-occurring items. However, we can consider an extreme situation in which two computation trees are co-occurring in all graphs, but their frequencies in each graph are very low. So, these trees can\u2019t approximate the true graph representation, which will destroy the synthetic dataset performance.\nThe synthetic dataset can solely be used to train GNNs based on the message-passing framework, but can\u2019t used to train certain spectral GNNs, such as ChebyNet with multiple propagation steps.\nQuestions:\nOriginal dataset labels are still used during the distillation procedure. So is it a strictly unsupervised algorithm from this perspective?\nThere is no clear statement about how Figure 1 is plotted. And I can't get what the x-axis and y-axis represent, respectively.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer yzvf: Part 1", "Subheading": "Official CommentbyAuthors18 Nov 2023, 07:26Everyone", "Content": "Comment:\n1. Unlike DOSCOND and KIDD, MIRAGE seems infeasible to be generalized to node classification tasks.\nResponse:\nWhile the primary focus of MIRAGE is on graph classification (as noted in the title itself), MIRAGE does generalize to node classification. We now empirically demonstrate this ability in App. E. (\nNote:\nKIDD also does not discuss node classification. Only, DosCOND does).\nGeneralization to node classification is simple since learning the node embeddings is a necessary step before aggregating them to form the graph embedding (Recollect Eqs. 4 and 5). Specifically, the pipeline follows in an identical manner except the omission of (Eq. 5) and the loss function being applied to node embeddings instead of graph embeddings.\nWe use ogbg-molbace to analyze performance in node classification. Here, each node is labeled as aromatic or non-aromatic depending on whether it is part of an aromatic ring substructure. The results are tabulated in Table H. Consistent with previous results, MIRAGE outperforms DosCOND in both AUC-ROC and compression (smaller size of the distilled dataset). DosCOND produces a dataset that is $\\approx 4$ times the size of that produced by MIRAGE, yet performs more than $7%$ lower in AUC-ROC. This coupled with model-agnostic-ness further solidifies the superiority of MIRAGE\n2. There is no theoretical analysis nor experimental proof to investigate the error when approximating the true graph representation by aggregating the root representations of only the highly frequent trees.\nResponse:\nThe above question is indeed important. We have now included a new experiment to evaluate the\nsufficiency\nof the frequent computation tree patterns.\nSufficiency of frequent patterns:\nIn order to establish sufficiency of frequent tree patterns in capturing the dataset characteristic, we conduct the following experiment. We train the model on the full dataset and store its weights at each epoch. Then, we freeze the model at the weights after each epoch's training and pass both the distilled dataset consisting of just the frequent tree patterns, and the full dataset. We then compute the differences between the losses as shown in Figure I (GCN, GAT, and GIN). The rationale behind this is that the weights of the full model recognise the patterns that are important towards minimizing the loss. Now, if the same weights continue to be effective on the distilled train set, it indicates that the distilled dataset has retained the important information. In the figure, we can see that the difference quickly approaches $0$ for all the models for all the datasets, and only starts at a high value at the random initialization where the weights are not yet trained to recognize the important patterns. Furthermore, gradient descent will run more iterations on trees that it sees more often and hence infrequent trees have limited impact on the gradients. These results empirically establish the sufficiency of frequent tree patterns in capturing the majority of the dataset characteristic.\nAdditional information relevant to this question:\nIn Fig. 1, we show that the distribution of computational trees is long-tailed and hence by considering only the top-$k$ most frequent trees, majority of the input information processed by the GNN would be retained. Furthermore, in Fig. 5 (b), we show that the training loss against epochs is similar for the full dataset and distilled dataset."}, {"Heading": "part 2", "Subheading": "Official CommentbyAuthors18 Nov 2023, 07:27Everyone", "Content": "Comment:\n3. MIRAGE compresses the computation trees by mining the set of frequently co-occurring items. However, we can consider an extreme situation in which two computation trees are co-occurring in all graphs, but their frequencies in each graph are very low. So, these trees can\u2019t approximate the true graph representation, which will destroy the synthetic dataset performance.\nResponse:\nThe observation is correct that if the frequencies of the co-occurring pair within all graphs are consistently low (and no other frequent tree sets exist across these graphs), then the approximated graph embedding may be different from the true graph embedding. However, it is essential to clarify that the performance on the synthetic dataset is not contingent on the distance between the approximated and true graph embeddings. Instead, it hinges on whether the approximated embedding includes the necessary information for predicting the class label of the graphs.\nGiven this context, recollect that we mine frequent tree sets per class label (Section 3.4). Therefore, if the residual tree sets across these graphs exhibit diversity, with the co-occurring pair being the sole exception, it becomes challenging for the GNN to establish correlations from the residual portion not reflected in the approximated embedding. Consequently, the embedding constructed solely from the shared computation trees across graphs may still retain valuable information.\nNonetheless, we realize that there may be situations such as the one described here, or when the distribution of computation trees is not skewed, MIRAGE may not be the most suitable method. We now explicitly acknowledge this aspect in our conclusion. We present below the relevant text verbatim.\nMIRAGE relies on the assumption that the distribution of computation trees is skewed. Although we provide compelling evidence of its prevalence across a diverse range of datasets, this assumption may not hold universally, especially in the case of heterophilous datasets. The development of an unsupervised, model-agnostic distillation algorithm remains an open challenge in such scenarios.\n4. The synthetic dataset can solely be used to train GNNs based on the message-passing framework, but can\u2019t used to train certain spectral GNNs, such as ChebyNet with multiple propagation steps.\nResponse:\nWe agree and this aspect was already acknowledged in our Conclusion. We present below the exact text that attests to this limitation. We note that this limitation also exists for KIDD since it assumes the input GNN architecture can be equivalently expressed as a Graph Neural Tangent Kernel, which holds for MPNNs but not graph transformers or spectral GNNs.\nAdditionally, there is a need to assess how these existing algorithms perform on contemporary architectures like graph transformers (e.g., (Ying et al., 2021; Ramp \u0301a\u02c7sek et al., 2022)) or equivariant GNNs (e.g., (Satorras et al., 2022)). Our future work will be dedicated to exploring these avenues of research.\n5. Original dataset labels are still used during the distillation procedure. So is it a strictly unsupervised algorithm from this perspective?\nResponse:\nWe thank the reviewer for highlighting this subtle point. We call our algorithm unsupervised from the perspective of not using the training gradients on the full dataset. To address this issue, we do not use the word \"unsupervised\" in isolation anywhere in the revised version. In all places, we mention \"unsupervised to original training gradients\".\n6. There is no clear statement about how Figure 1 is plotted. And I can't get what the x-axis and y-axis represent, respectively.\nResponse:\nWe apologize for not being clear in our description. We have now incorporated a detailed figure caption, which is reproduced verbatim below.\nThe figure presents the frequency distribution of computation trees across datasets. The \"frequency\" of a computation tree denotes the number of occurrences of that specific tree across all graphs in a dataset. The\nnormalized\nfrequency of a tree is computed by dividing its frequency with the total number of trees in a dataset and thus falls in the range $[0,1]$. The $x$-axis of the plot depicts the normalized frequency counts observed in a dataset, while the $y$-axis represents the percentage of computation trees corresponding to each frequency count. Both $x$ and $y$ axes are in log scale. The distribution is highly skewed characterized by a dominance of trees with low frequency counts, while a small subset of trees exhibiting higher frequencies. For example, in ogbg-molhiv, the most frequent tree alone has normalized frequency of $0.32$."}, {"Heading": "Official Comment by Reviewer yzvf", "Subheading": "Official CommentbyReviewer yzvf20 Nov 2023, 23:20Everyone", "Content": "Comment:\nThanks for the clarification and I will maintain my score."}]}, {"Heading": "Official Review of Submission9334 by Reviewer XL6A", "Subheading": "Official ReviewbyReviewer XL6A31 Oct 2023, 09:47 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces a graph classification model called MIRAGE, which is a graph distillation method based on frequent pattern mining. MIRAGE takes advantage of the design features of the message passing framework, decomposes the graph into calculation trees, and uses the distribution characteristics of the calculation tree to compress calculation data. Compared with existing graph distillation algorithms, MIRAGE shows advantages in key indicators such as prediction accuracy, distillation efficiency, and data compression rate. Furthermore, MIRAGE only relies on CPU operations, providing a more environmentally friendly and energy-efficient graph distillation method.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nIt is a novel idea to transform the graph distillation problem into the problem of graph decomposition.\nThis paper clearly expresses the distillation problem in mathematical language and naturally transforms it into a graph decomposition problem.\nThe experimental configuration is described in detail, and the experimental results are good and reasonable.\nWeaknesses:\nThe datasets used in the experiment is too small.\nQuestions:\nWould MIRAGE still be as effective if used on a very large data set?\nWhy is MIRAGE, which only uses the CPU, so much faster than DOSCOND and KIDD, which can use the GPU?\nIf a datasets is large, but its global computation tree is very similar, will such a datasets affect the effect of MIRAGE?\nHow will MIRAGE perform in multi-classification tasks?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer XL6A", "Subheading": "Official CommentbyAuthors18 Nov 2023, 07:31 (modified: 18 Nov 2023, 07:56)EveryoneRevisions", "Content": "Comment:\nQ1. Would MIRAGE still be as effective if used on a very large dataset?\nResponse:\nWe do not expect graph size to have any effect on the performance of MIRAGE since the underlying principles are not dependent on graph dataset size.  This is already evident from Table 2. Specifically, we compute the pearson's correlation coefficient between dataset size and the generalization error (AUC in full dataset-AUC of MIRAGE). The correlation is 0.153 with $p$-value of 0.743 and thus rejecting any bias in AUC from dataset size.\nQ2. Why is MIRAGE, which only uses the CPU, so much faster than DOSCOND and KIDD, which can use the GPU?\nResponse:\nExisting algorithms, namely DosCOND and KiDD, seek to replicate the gradient trajectory of model parameters on the full dataset. Hence, they need to train on the full dataset for distillation (and as we comment in Sec 1, this compromizes the basic premise of data distillation). In contrast, MIRAGE does not require training on the full dataset. Rather, MIRAGE emulates the input data processed by message-passing GNNs. By shifting the computation task to the pre-learning phase, MIRAGE is not only faster, but also independent of the GNN architecture.\nQ3. If a datasets is large, but its global computation tree is very similar, will such a datasets affect the effect of MIRAGE?\nResponse:\nAs we discussed in our response to Q1, the size of the dataset does not affect the performance of MIRAGE. The performance depends primarily on the frequency distribution of computation trees in a dataset. If the distribution is skewed, MIRAGE is expected to perform well since the top-$k$ most frequent computation trees would effectively capture a substantial portion of the distribution mass. On the other hand, if the distribution is not skewed, MIRAGE is not the most suitable distillation technique for such scenarios. This aspect is explicitly acknowledged in our conclusion (Sec 5). The relevant text is reproduced verbatim below.\nFinally, MIRAGE relies on the assumption that the distribution of computation trees is skewed. Although we provide compelling evidence of its prevalence across a diverse range of datasets, this assumption may not hold universally, especially in the case of heterophilous datasets. The development of a model-agnostic distillation algorithm remains an open challenge in such scenarios.\nQ4. How will MIRAGE perform in multi-classification tasks?\nResponse:\nWe have added a new dataset, namely IMDB-M, to evaluate MIRAGE's performance on multi-class classification. As we see below, MIRAGE produces the best performance. These results, and the details of the IMDB-M dataset has been added to Table 2 and Table 1 respectively in the revised manuscript.\nArchitecture\nRANDOM(Mean)\nRANDOM(sum)\nHERDING\nKidd\nDosCond\nMirage\n|Full Dataset\nGCN\n55.10$\\pm$ 3.8\n52.90 $\\pm$ 2.52\n61.0 $\\pm$ 2.4\n57.1 $\\pm$ 1.11\n55.9 $\\pm$ 1.06\n63.20 $\\pm$ 1.12\n|64.10 $\\pm$ 1.1\nGIN\n60.1$\\pm$ 2.67\n56.30 $\\pm 5.5$\n58.47 $\\pm$ 4.12\n54.18 $\\pm$ 0.90\n58.30 $\\pm$ 1.70\n61.8 $\\pm$ 1.51\n|64.8 $\\pm$ 1.10\nThe size of the dataset (in bytes) is as follows:\n$\\frac{\\text{ Method}\\rightarrow}{\\text{ Dataset}\\downarrow}$\nHerding(GCN)\nHerding(GIN)\nKiDD\nDosCond(GCN)\nDosCond(GIN)\nMIRAGE\n|Full Dataset\nIMDB-M\n1,156\n1,256\n936\n720\n824\n228\n|645,160"}, {"Heading": "Eagerly awaiting feedback", "Subheading": "Official CommentbyAuthors21 Nov 2023, 00:11Everyone", "Content": "Comment:\nDear Reviewer,\nSince we are only a day away from the completion of the discussion phase, we are eagerly awaiting your feedback on the revised manuscript.\nWe have incorporated all of the suggestions made in the review including new experiments on distillation for multi-class classification. We would love to discuss more if any concern remains unaddressed. Otherwise, we would really appreciate it if you could support the paper by increasing the score.\nregards,\nAuthors"}, {"Heading": "Keenly seeking feedback from Reviewer XL6A", "Subheading": "Official CommentbyAuthors22 Nov 2023, 13:41Everyone", "Content": "Comment:\nDear Reviewer XL6A,\nAs the author-reviewer discussion phase is nearing its conclusion, we would like to inquire if there are any remaining concerns or areas that may need further clarification. Your support during this final phase, especially if you find the revisions satisfactory, would be of great significance. Your feedback and evaluation hold a pivotal role in determining the ultimate fate of our work.\nRegards,\nAuthors"}, {"Heading": "Eagerly waiting feedback from Reviewer XL6A", "Subheading": "Official CommentbyAuthors23 Nov 2023, 01:14Everyone", "Content": "Comment:\nDear Reviewer XL6A,\nThank you for your insightful comments.\nWe have incorporated all suggestions, including additional experiments on distillation for multi-class classification.\nAs the author-reviewer discussion phase is nearing its conclusion, we would like to politely enquire if you have any outstanding concerns regarding our work.\nAs all other reviewers are leaning towards acceptance, your feedback is indeed important for determining the ultimate fate of our work.\nSincerely\nAuthors"}]}]}, "NqpdT8DwGc": {"paper_info": {"Keywords": "Model stealing, Adversarial images, Timing side-channel, Transfer Learning", "TL;DR": "Introduced a model stealing approach which exploits adversarial images misclassification pattern and timing side-channels", "Abstract": "Machine learning, with its myriad applications, has become an integral component of numerous technological systems. A common practice in this domain is the use of transfer learning, where a pre-trained model's architecture, readily available to the public, is fine-tuned to suit specific tasks. As Machine Learning as a Service (MLaaS) platforms increasingly use pre-trained models in their backends, it's crucial to safeguard these architectures and understand their vulnerabilities. In this work, we present an approach based on the observation that the classification patterns of adversarial images can be used as a means to steal the models. Furthermore, the adversarial image classifications in conjunction with timing side channels can lead to a model stealing method. Our approach, designed for typical user-level access in remote MLaaS environments exploits varying misclassifications of adversarial images across different models to fingerprint several renowned Convolutional Neural Network (CNN) and Vision Transformer (ViT) architectures. We utilize the profiling of remote model inference times to reduce the necessary adversarial images, subsequently decreasing the number of queries required. We have presented our results over 27 pre-trained models of different CNN and ViT architectures using CIFAR-10 dataset and demonstrate a high accuracy of 88.8% while keeping the query budget under20.", "Primary Area": "societal considerations including fairness, safety, privacy", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9333", "PDF Url": "https://openreview.net/pdf?id=NqpdT8DwGc"}, "review_info": [{"Heading": "Official Review of Submission9333 by Reviewer QATX", "Subheading": "Official ReviewbyReviewer QATX03 Nov 2023, 07:12 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces a model extraction attack that queries the MLaaS system and, at the same time, exploits the timing side channel. Except for the profiling stage, there are two stages in the attack. In the first stage, the timing side channel is used to shortlist the candidates from a total of 27 pre-trained models. In the second stage, adversarial examples are fed into the candidates, and then outputs from candidate models are used to differentiate different architectures. The main advantage of the proposed approach is that only limited query time is needed.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nExploiting the inference time as a side channel has an advantage that the adversary has only, as described by the authors, user-level access to the MLaaS service. This can be further exploited and combined to assist other model extraction approaches.\nWeaknesses:\nThe\nnecessity of adversarial examples\n. One claimed contribution is to leverage adversarial examples to differentiate different models. The provided evidence only showcases, but experimental results must be provided to further support this claim. Adversarial examples transfer across different architecture. Clean samples or randomly generated samples may also transfer across different architectures.  One possible experiment is to test the performance of random noises or clean images on differentiating the models. The classification patterns on random noises would be interesting and can provide evidence on the necessity of using adversarial examples.\nDiscussions on\npossible defenses\nis missing. For example, similar to cryptographic hardware, secure implementations, e.g., implementations where the inference time for different models is the same, could be a good defense, especially under the threat model that the adversary can only access user-level APIs. Such experiments need to be provided for completeness.\nDiscussion on\ncommercial MLaaS APIs\nwould also be interesting. It would be interesting if the authors could provide details when mounting such an attack on real-world commercial MLaaS services, showing the possibilities and the limitations. It would be a valuable discussion for practitioners.\nAbout the\nprofiling budget\n. Unlike hardware devices, the adversary can access an exact copy if the device is available for sale. The profiling would be hard to implement since the adversary has limited access to the APIs. Similar to template attacks, details on the profiling budget and the adversary's capability in the profiling stage can be discussed in the threat model part. In addition, In the current setup, only 27 models are used. Does it indicate that the proposed attack can only work for a limited number of models that are completely profiled in advance?\nFor results in Figure 6 b, the timing profiles can already differentiate the squeezenet1_0 from most architectures. However, instead, squeezenet1_0 can not be correctly predicted in the second stage. Please clarify.\nQuestions:\nSee weaknesses part\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9333 by Reviewer rKcg", "Subheading": "Official ReviewbyReviewer rKcg28 Oct 2023, 05:13 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a new approach that combines query-based and side-channel model attacks to infer the architecture of a model behind an API. \nUsing missclassified adversarial examples to fingerprint pre-trained model architectures, the approach is able to identify which pre-trained model architecture was used. The time-side-channel attack is used to reduce the number of possible adversarial examples that need to be used for fingerprinting possible models. The approach is evaluated using 27 different models which were fine-tuned on the CIFAR-10 dataset.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nthe paper is well written and relatively easy to follow\neven though for the specified setting a lot of assumptions are made, the topic is interesting and important\nWeaknesses:\nThe experiments are only conducted on the CIFAR-10 dataset. A dataset with a higher resolution would be more interesting.\nIn the abstract the paper claims that these adversarial examples used to fingerprint a model can be used for a model extraction attack. However, if we only get the information which pre-trained model was used for fine-tuning, this is not a model extraction attack in my understanding.\nThe adversarial examples are generated using the same dataset which is also used for training. This is a very unrealistic and a very strong assumption that the attacker has access to the same data distribution as the provider of the model. In reality the attacker doesn't even know the data distribution used for training and certainly doesn't have access to it.\nThe comprehension of fig. 1 and 2 could be improved if each predicted class has its own color. This would highlight the difference between the predictions.\nTo be honest I am skeptical that this approach is working if the model is fine-tuned for longer periods of time and on a harder dataset than CIFAR-10. More thorough experiments on higher resolution datasets with more classes and longer fine-tuning period would be more convincing.\nQuestions:\nQ1: As far as I can tell, the attacker can only discern the model architectures if he has a list of possible architectures. What if he has no information of possible architectures or the architecture is a custom one?\nQ2: Doesn't the timing side-channel attack depend on the hardware used by the MLaaS provider? If the attacker has different hardware, he cannot profile the timings. Would this approach then still work?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9333 by Reviewer 5A6W", "Subheading": "Official ReviewbyReviewer 5A6W27 Oct 2023, 12:10 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe approach proposed in this work tries to infer the base pre-trained model deployed, after being fine-tuned, to perform image classification in an MLaaS scenario. To do so, the attacker compares the inference time and the transferability of a selected set of adversarial examples between a set of publicly available models and the target model.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n1 poor\nStrengths:\nThe paper addresses an important topic, as the knowledge of the deployed pre-trained model architecture is valuable for an attacker.\nWeaknesses:\nThe paper presents several issues:\nlimited attack scenario: the authors assume that the attacker knows the set of pre-trained models that might be used by the victim, and also the dataset on which they are trained. These are not strong and realistic assumptions and limit the impact of the proposed approach;\noptimistic assumption on the inference time profiling: the main application scenario of the attack is against MLaaS platforms, therefore time measurements (which always present some randomness) are affected by the network's delay and jitter. As the inference times of considered models are in the order of nanoseconds, it is very likely that measurements are unusable;\nmissing comparison with competing approaches: the authors state that they \"successfully beat the state-of-the-art work on model fingerprinting\", but actually a comparison is missing. The attack should be compared at least with Chen et al., 2022, using the same experimental setting;\nlimited experimental setting: the authors only consider one dataset for the model pre-training, and one for the fine-tuning phase;\nmissing details required to reproduce the results: for instance, the number of fine-tuning epochs and the adversarial attacks parameters are not specified;\nthe limitations of the work are not discussed at all.\nQuestions:\nCould you simulate in the experiments the presence of an internet connection, in order to estimate how the attack would perform in a realistic setting?\nWhat happens if the pre-trained model is not among the set known by the attacker - or if it is trained on a different dataset?\nCan you please provide the complete details to reproduce the experimental results, and explicitly address the limitations of the work?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n1: strong reject\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9333 by Reviewer 1hVo", "Subheading": "Official ReviewbyReviewer 1hVo13 Oct 2023, 06:28 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn this paper, the authors combine model extraction attacks and side-channel attacks to improve the correctness and decrease query budgets of determining the victim model's structure.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe authors consider different model structures, including CNN and transformers.\nThe threat model is practical, in which the adversary can only call the provided APIs.\nThis proposed method is simple and easy to follow.\nWeaknesses:\nPersonally, I think there are several severe flaws in this paper.\nThe experiments are all on CIFAR-10, which is a toy dataset, only containing 10 different classes. It is doubtful whether the observation of the transferability still exists on larger datasets, like ImageNet-1K.\nAs Figure 3 indicates, for some model structures, there are no significant differences across different structures and parameters. And even for models with the same structures, there still exist differences among class labels. Therefore, it is questionable whether the proposed method is reasonable.\nFor timing profiles, in Figure 4, it is clear that the inference time is short. Therefore, a very small latency from the ML service will significantly change the results. In real cases, the service will deal with millions or billions of requests, which is to say that the time latency caused by occupation is usual. Therefore, the inference time will not be a reliable measurement to determine the model structure.\nOn the other hand, the service will adopt various accelerating methods to optimize the inference process, like pruning and quantizing, which will significantly decrease the inference time. However, based on the threat model, the adversary will have no information for such optimizations. It is to say that the timing profiles cannot provide any references for the attack.\nMinor:\na. The explanation of Figure 3 is not clear.\nb. No ablation study of the query budgets.\nc. Single dataset, CIFAR10.\nQuestions:\nPlease see weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}]}, "mYOYjhXGop": {"paper_info": {"Keywords": "brain tumor segmentation, weakly supervised learning, explainable learning, counterfactual generation, class association embedding, topological data analysis", "Abstract": "Brain tumors are a prevalent clinical disease that causes significant suffering for patients. Machine-based segmentation of brain tumors can assist doctors in diagnosis and providing better treatment. However, the complex structure of brain tumors presents a challenge for automatic tumor detection. Deep learning techniques have shown great potential in learning feature representations, but they often require a large number of samples with pixel-level annotations for training for implementing objects segmentation. Additionally, the lack of interpretability in deep learning models hinders their application in medical scenarios. In this paper, we propose a counterfactual generation framework that not only achieves exceptional performance in brain tumor segmentation without the need for pixel-level annotations, but also provides explainability. Our framework effectively separate class-related features from class-unrelated features of the samples, and generate new samples that preserve identity features while altering class attributes by embedding different class-related features.  We can accurately identify tumor regions through performing comparison between original abnormal images and generated normal samples which preserve original identity features. We employ topological data analysis for projecting extracted class-related features into a globally explainable class-related manifold. Furthermore, by actively manipulating the generation of images with different class attributes with defined paths, we can provide a more comprehensive and robust explanation of the model. We evaluate our proposed method through experiments conducted on two datasets, which demonstrates superior performance of brain segmentation.", "Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9332", "PDF Url": "https://openreview.net/pdf?id=mYOYjhXGop"}, "review_info": [{"Heading": "Official Review of Submission9332 by Reviewer naJ9", "Subheading": "Official ReviewbyReviewer naJ931 Oct 2023, 12:45 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors propose an interesting approach for a weekly supervised semantic segmentation framework. The proposed approach disentangles class-specific features from others, followed by identity-preserving counterfactual generation. The framework seems like a contrastive learning setup for a given pair of normal and diseased images for semantic segmentation. The steps mainly involve i) identifying class-specific features from others, ii) identity preserving counterfactual generation converting diseased to normal brain, (iii) pixel-wise L1 difference estimation, followed by (iv) post-processing to extract boundaries.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe proposed method is innovative, combining multiple approaches, lifting the need for pixel-wise labels for semantic segmentation tasks\nNice illustrative figures explaining the proposed method\nThe proposed approach attempts to learn interpretable rules based on class-specific feature topology\nWeaknesses:\nThe proposed approach only works on segmenting the whole tumour, which seems limited.\nThe interpretable rule from CS topology analysis is not that clear. Does the approach have a global CS topology graph from which the features are selected at every iteration of counterfactual generation? If so, how is this done?\nThe reported performance on the whole tumour is about 15-20% lower than the state-of-the-art model (based on fully supervised learning); it's unclear how the method would scale to other classes, like tumour core and enhancing tumour\nI fail to understand how the method extends to a multi-class semantic segmentation setup. Do you need more than two images in a pair? Do you need to generate all possible counterfactuals?\nAnalysis of the approach on other datasets would be really helpful\nSimilar approaches like in anomaly detection literature are not discussed; refer [1, 2]\nPresentation concerns: move all the related works into the related work section rather than including them in the methods section, which makes it hard to follow the contribution.\n[1] Chaitanya, K., Erdil, E., Karani, N. and Konukoglu, E., 2020. Contrastive learning of global and local features for medical image segmentation with limited annotations.\nAdvances in neural information processing systems\n,\n33\n, pp.12546-12558.\n[2] Wolleb, J., Bieder, F., Sandk\u00fchler, R. and Cattin, P.C., 2022, September. Diffusion models for medical anomaly detection. In\nInternational Conference on Medical image computing and computer-assisted intervention\n(pp. 35-45). Cham: Springer Nature Switzerland.\nQuestions:\nPlease refer to weakness section\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9332 by Reviewer Bw47", "Subheading": "Official ReviewbyReviewer Bw4731 Oct 2023, 09:49 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents a counterfactual generation framework that not only achieves exceptional performance in brain tumor segmentation without the need for pixel-level annotations but also provides explainability. The experimental results on two datasets are conducted to validate the effectiveness of the proposed framework.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n1 poor\nStrengths:\n(1) The overall structure is clear.\n(2) The proposed framework can effectively separate class-related features from class-unrelated features of the samples, and generate new samples that preserve identity features while altering class attributes.\n(3) The experiments were conducted on two public brain tumor datasets to validate the effectiveness of the proposed model.\nWeaknesses:\n(1) The overall contribution is limited. The core is this study aims to generate some normal samples, and then extract the tumor regions by using the generated samples.\n(2) The tumor regions are identified by performing a comparison between the original abnormal images and generated normal samples. However, if the generated samples are not accurate, the identified tumor regions are affected.\n(3) The paper designs weakly-supervised segmentation methods, but they do not compare it with other SOTA weakly-supervised segmentation models.\nQuestions:\n(1) The overall contribution is limited. The core is this study aims to generate some normal samples, and then extract the tumor regions by using the generated samples.\n(2) The tumor regions are identified by performing a comparison between the original abnormal images and generated normal samples. However, if the generated samples are not accurate, the identified tumor regions are affected.\n(3) The paper designs weakly-supervised segmentation methods, but they do not compare it with other SOTA weakly-supervised segmentation models.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9332 by Reviewer Er7v", "Subheading": "Official ReviewbyReviewer Er7v30 Oct 2023, 20:44 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn healthcare, brain tumors are a significant clinical issue that affects many patients. Machine-based tumor segmentation can assist doctors in diagnosis and treatment planning. Deep learning techniques offer potential for feature representation in brain tumor segmentation but often require a large number of samples with pixel-level annotations, and they lack interpretability. The paper addresses these challenges by introducing a framework that separates class-related features from class-unrelated ones. This approach reduces the need for pixel-level annotations, making it more practical for clinical settings. To improve interpretability, the authors use topological data analysis to project class-related features into a globally explainable manifold. This adds a layer of explanation to the model. The method is validated on two distinct datasets and shows improved performance in brain tumor segmentation, contributing to both machine learning and medical imaging.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe paper focuses on brain tumor segmentation, a critical issue in medical imaging and diagnostics. Effective segmentation can significantly aid in the treatment planning and monitoring of brain tumors, making this a high-impact area of research.\nThe paper acknowledges the challenges of requiring detailed, pixel-level annotations for medical images, especially in clinical settings. By aiming for a weakly supervised approach, the paper shows an understanding of the practical limitations and costs involved in medical image annotation.\nThe title suggests an emphasis on creating a \"globally explainable\" machine learning framework. Explainability is particularly crucial in medical applications, where understanding the model's decisions can influence clinical decisions and patient trust. Focus on this aspect is a strength\nWeaknesses:\nThe paper does not talk about what it means to have a unified manifold in section 2.2 and could have done a better job outlining some insights here.\nThis paper indexes on explainability but does not really outilne why their method has explainability and additionally the claim that topological analysis lends interpretability is not established.\nThe paper does not provide a detailed discussion on the limitations or potential challenges of the proposed weakly supervised learning framework for brain tumor segmentation.\nThey experiment with\nThe paper does not mention any comparative analysis or evaluation of the proposed method against existing state-of-the-art approaches for brain tumor segmentation.\nThe paper lacks information on the size and diversity of the datasets used for evaluation, which could affect the generalizability of the proposed method.\nThe paper does not discuss the computational complexity or efficiency of the proposed framework, which could be important considerations for practical implementation.\nThe paper does not provide insights into the potential impact or implications of the proposed method in real-world clinical settings, such as its integration with existing medical imaging systems or its usability by healthcare professionals\nQuestions:\nWhat are the reasons that the method is inherently explainable?\nHow do you ensure that the space allows for linear interpolation in generating new samples?\nWhy do you choose to create a graph when you could have used distance based algorithms to samples close in the euclidian space? What are the added advantages of this approach?\nHow do you handle errors from the generation network - if you would like it to generate images from class A but it generates images from class B, how do you handle the error?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9332 by Reviewer 4gaV", "Subheading": "Official ReviewbyReviewer 4gaV29 Oct 2023, 21:44 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn this work, the authors proposed a counterfactual generation framework for the brain tumor segmentation task. This work not only performs self-supervised segmentation accurately without relying on pixel-level annotations but also provides explainability, which is lacking in most of the deep learning models. The proposed method efficiently segregates class-related features from class-unrelated features within the samples. It then generates new samples that maintain identity features while modifying class attributes by embedding diverse class-related features. To achieve this, authors employ topological data analysis to project the extracted class-related features onto a globally interpretable class-related manifold.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper reads well and easy to understand.\nThe idea of extracting class-style codes to get the insights into global rules and creating relationships among topological structure adds some novelty.\nWeaknesses:\nMethodology section lacks math behind the study, equations and optimization strategy.\nMissing some SOTA during evaluation (eg, Capturing implicit hierarchical structure in 3D biomedical images with self-supervised hyperbolic representations and other self-supervised methods) and fully supervised methods.\nMissing ablation study on design choices (eg, adding shortest path design).\nQuestions:\nIt\u2019s interesting to see how this can be extended for multi-class segmentation. In most tumor cases, hardest region of interest to extract is enhanced tumor region. So how can you extend your approach with multi-class style codes and multiple rule-based approach?\nWhat is the computational complexity of the proposed method?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}]}, "D6Htk1rwkK": {"paper_info": {"Primary Area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Latent Geometry, Latent Spectrum, Adversarial Robustness, Mechanistic Model, Unsupervised Learning, Local Learning, Jacobian Regularization, Spectral Regularization", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Backpropagation-optimized artificial neural networks, while precise, lack robustness, leading to unforeseen behaviors that affect their safety. \nIn cancer detection, for example, slight image alterations can misclassify benign moles as malignant. \nBiological neural systems do not have such issues. \nThus, understanding the biological mechanisms of robustness is an important step towards building trustworthy and safe systems.\nUnlike artificial models, biological neurons adjust connectivity based on neighboring cell activity. \nRobustness in neural representations is hypothesized to correlate with the smoothness of the encoding manifold. \nRecent work suggests power law covariance spectra, which were observed studying the primary visual cortex of mice, to be indicative of a balanced trade-off between accuracy and robustness in representations.\nHere, we show that unsupervised local learning models with winner takes all dynamics learn such power law representations, providing upcoming studies a mechanistic model with that characteristic.\nOur research aims to understand the interplay between geometry, spectral properties, robustness, and expressivity in neural representations.\nHence, we study the link between representation smoothness and spectrum by using weight, Jacobian and spectral regularization while assessing performance and adversarial robustness. \nOur work serves as a foundation for future research into the mechanisms underlying power law spectra and optimally smooth encodings in both biological and artificial systems. \nThe insights gained may elucidate the mechanisms that realize robust neural networks in mammalian brains and inform the development of more stable and reliable artificial systems.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9331", "PDF Url": "https://openreview.net/pdf?id=D6Htk1rwkK"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9331 by Area Chair pKKQ", "Subheading": "Meta ReviewbyArea Chair pKKQ07 Dec 2023, 22:29 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper studies 2-layer neural networks trained using either a biologically plausible local learning rule or with backpropagation with different regularizations.  They study the spectra of the learned representations and show the local learning rule leads to a 1/n power law which is conjectured to lead to a smoother representation manifold and  better robustness.  They compare this to networks trained with backprop with L2, jacobian, or spectral regularization and investigate the representation spectrum, smoothness of the manifold, decision boundaries, and robustness of adversarial attacks across these methods.\nIn general, reviewers found the study interesting and worthwhile.  The findings and analysis and intriguing, for example, that 1/n spectrum is not necessary for robustness.  The connection between ML and neuroscience in terms of neural representation spectrum is an interesting direction.  However, there was wide agreement the presentation of the paper was problematic, the paper was hard to follow, and there was no central story and clear main contributions.  Moreover, the results appear preliminary and concern only small networks.  The consensus is the paper is not ready for publication and can benefit from substantial revision and more experiments.\nJustification For Why Not Higher Score:\npaper presentation\nsmall scale results\nproblematic interpretation of prior work and lack of connection to other prior work\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Individual comment addressing Reviewer wEmA", "Subheading": "Official CommentbyAuthors23 Nov 2023, 04:28Everyone", "Content": "Comment:\nReviewer wEmA:\nThank you for your insightful comments. We share the concern regarding generality of our results without visiting other unsupervised learning rules. We focussed on the local learning rule mentioned in the paper because it exhibits all properties we refer to (power law spectrum, sufficiently smooth manifold, robustness) which makes it an ideal candidate to study the mechanistic relationships between them. We have not analyzed other learning rules yet and appreciate the recommendation to proceed that way.\nRegarding question 1: \"There are two papers cited by Krotov and Hopfield, but you don\u2019t always say which one you are referring to. Please distinguish them by adding a year every time!\"\n    We thank the referee for that notice. We corrected the issue during our revision.\nRegarding question 2: \"The matrix S is not clear. What does \u201csynaptic adjacency\u201d mean? Is it defined by W=S ||S||^p-2? Also the norm ||S|| is not defined. Do you actually mean absolute value |S|\"\n    The matrix S is defined according to Krotov & Hopfield (2019). It corresponds to a weight matrix W with regard to the architecture discussed by the relation W=S |S|^p-2 , where |.| denotes the absolute value. It was our mistake that we did write the norm instead of the absolute value there. We have corrected it in our text.\nReharding question 3: \"\\lambda means learning rate in equation (4) but covariance eigenvalue in figure 1c.\"\n    That is correct, but we try to make the difference clear by the subscript. \\lambda_{L} with a capital subscript is reserved for the learning rate whereas \\lambda_{i} with lower case subscript refers to an index variable of an index in case the subscript is a numeral.\nRegarding question 4: \"What are the multiple curves in Figure 2?\"\n    Because a real power law is characterized by its scale independence, we test for that property by scaling the dimensions of the model (number of latent/hidden neurons). The different lines in Figure 2 refer to the spectra of differently scaled versions of the same model exposed to the same data."}, {"Heading": "Response and reference to our updated manuscript", "Subheading": "Official CommentbyAuthors23 Nov 2023, 04:27Everyone", "Content": "Comment:\nWe would like to thank the referees for their valuable feedback. Overall, we share the general critique regarding the structure of the paper, the quality of the writing and the presentation of our contribution. To resolve structural issues, we have revisited our story, restructured the document and rearranged some figures. The most evident changes include\nmove Figure 1. to the appendix  because it is not relevant\ntransfer Figure 6 to the results section\nIntroduce paragraph headings to both, the methods and the results section\nMoreover, we went through the document to eradicate typographic and formal errors. We hope the way we changed the story, order of results and arguments clarifies our motivation and benefits to understand our contributions.\nIn the following, we are going to address each of the reviewers individually to respond to their comments and answer their questions.\nReviewer 8ibB:\nWe want to take the opportunity to thank the referee for their positive assessment of our paper as well as their detailed and valuable feedback. We found the literature references helpful und clearly relevant for our research and decided to reference some of them in our text.\nRegarding question 1: \"The decision landscape analysis is super interesting, but also quite local and qualitative, do you have more quantitative population statistics for them?\"\n    The objection is justified. We share the concern but do not have respective population statistics, which would allow for a more comprehensive  and quantitative study, yet. We would appreciate any further advice on that.\nRegarding the comment: \"Covariance spectrum is a quite global measure of representation; on the other hand, the jacobian norm and adversarial property are super local property [3], so it makes sense that controlling the spectrum is not enough for getting adversrial robust\u2026\"\n     We agree with the reviewer's comment. However, the work by Nassar et al. appears to provide constrasting empirical evidence. Yet, we could not reproduce any of the results shown in their paper.\nReviewer 1KBf:\nThank you for your insightful feedback. We share that our assertions regarding Stringer et al. were incorrect and misleading. In our revised version, we tried to resolve these issues.\nRegarding question 2: - \"What is the point of the left panel of Fig 1c? The pruned version mainly differed from the Raw in the power of the first few components while the scaling-law concerns the properties of the tails. So I am not sure why this difference would matter for the scaling-law.\"\n    It is correct that we are only interested in the asymptotic behaviour of the spectrum. However, we wanted to check to what extent the high variance synapses contribute to the statistics we study. Since it does not contribute to the story of paper as it stands now, we decided to transfer this Figure and discussion to the appendix.\nRegarding question 3: - \"The analysis in Fig 4 is interesting. But it\u2019s just one example. Would there be a systematic way to quantify this?\"\"\n    You are right. The analysis presented is fairly limited and the question for a systematic quantitative statistic justified. So far, we would think there is but we do not know.\nReviewer 74wa:\nThank you for the detailed feedback and extensive references to the literature. We were glad the referee provided that starting point for us. We used it to extend our references to the NeuroAI literature in our introduction.\nRegarding question b): \"How do the authors handle the fitting for the \u201calpha\u201d value? In Stringer et al. I believe that the first few and last few eigenvalues are ignored. How does that play into the fitting here?\"\n    Indeed, we also ignore the first and the last few eigenvalues. Based on our spectral analysis with regard to scaling the model, we identify regions in which the profile appears fairly stable unaffected by boundary artefacts.\nRegarding question c): \"Which points (scales) are used for fitting the alpha value in Figure 2?\"\n    We use the full (largest) scale for fitting the alpha values.\nWe would also like to thank the reviewer for their additional comments. We will take them into account for further revisions of our paper."}, {"Heading": "Official Review of Submission9331 by Reviewer 8ibB", "Subheading": "Official ReviewbyReviewer 8ibB30 Oct 2023, 21:37 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nSummary\nThe authors conducted a series of carefully designed analyses on 2-layer NN models trained by hopfield-like local learning rules vs backpropagation with regularization, and they examined their representation spectra, local manifold geometry, decision boundary and robustness to white box attack. Through the analyses, they found the networks learned through local biologically plausible learning rules are indeed robust and have \"optimal\" spectra, while some other models trained via backprop can also achieve comparable robustness without the 1/n spectra, questioning the necessity of this 1/n spectral feature.\nSoundness:\n3 good\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nStrength\nThe detailed dissections of these models are\napplaudable.\nProviding evidence that the 1/n spectrum of the representation is not necessary for model robustness, (though the evidence is relatively few data points) .\nThe latent geometry analysis and its relation to decision boundary is illuminating, esp. by showing the similarity of KH model and L2 and Jacobian regularization model.\nFigures are well made, clean and easy to understood.\nWeaknesses:\nWeakness\nThe biggest issue maybe the paper at its current stage is kind of explorative data analysis in many directions\u2014\u2014 so I\u2019m not sure about the central contribution and conclusion. The 1/n spectrum, the geometry of represntation and decision boundary and adversarial robustness are all interesting, but currently they have not connect to form an overall story. It will be better to form a few central claims and then back it up with experiments and data.\nThe writing and overall organization of the paper could be improved\u2026\nIn the method section, it will benefit from a more streamlined organization. Currently it\u2019s jumping between method, results and some interpretations\u2026. Some paragraph (Figure 1 and its interpretation) should go to the results section. Adding headings e.g. paragraph titles can also help. e.g. model architecture, unsupervised training, supervised training, spectral analysis etc.\nSimilarly in the result section, better headings for the experiments could be added to guide the readers.\nGenerally the paper\u2019s experiment is relatively small scale, majorly with 2 layer MLPs. The generalization to deeper networks or CNNs is desirable for bigger impact.\nFor the decision boundary and  analysis, it may be worthwhile to refer to some previous works.\nFor example, the Frob norm of jacobian plot vs the decision boundary is interesting, and [1] devotes the whole paper to understand this. The technical difference is they plotted the volume element, which is the sum of log eigenvalues, instead of sum of squared eigenvalues in your case.\nThough outside image classification, for GAN networks, [2] analyzed the homogeneity / flatness of the Jacobian eigenframe across the space. which maybe useful for quantification in your case.\n[1]:\nNeural networks learn to magnify areas near decision boundaries\nhttps://arxiv.org/abs/2301.11375\n[2]:\nThe Geometry of Deep Generative Image Models and its Applications\nhttps://arxiv.org/abs/2101.06006\nMinor Weakness and typos\n\u201c\nBecause principal components correspond to the eigenvectors of the respective\ncovariance matrix Cov(h,h)\n\u201d should it be $\\hat{h},\\hat{h}$ ?\nIn Figure 2 and Figure 3, what does different color shades mean? is it different runs of the model?\nThe notation in Eq. 9 in appendix is not clear, $D$ seems to mean differential operator, but it\u2019s not standard and not defined anywhere, using partial differential or more standard notation may be easier for reader.\nEq. 10 in appendix is also confusing or even wrong. $\\sigma\u2019(Wx)$ seems to be a vector, how do you take the absolute value and time it with the L2 norm of $W$? Are you using some special properties of $\\sigma$?\nWhat is\nSHLP?\nQuestions:\nQuestions\nThe decision landscape analysis is super interesting, but also quite local and qualitative, do you have more quantitative population statistics for them?\nComments:\nCovariance spectrum is a quite global measure of representation; on the other hand, the jacobian norm and adversarial property are super local property [3], so it makes sense that controlling the spectrum is not enough for getting adversrial robust\u2026\n[3]:\nAdversarial training\u00a0is a form of data-dependent operator norm regularization\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9331 by Reviewer 1KBf", "Subheading": "Official ReviewbyReviewer 1KBf30 Oct 2023, 15:11 (modified: 11 Nov 2023, 19:08)EveryoneRevisions", "Content": "Summary:\nThis paper seeks to investigate the relationship between the smoothness of the representation and the spectra of its covariance matrix.\nI found the paper to be not particularly well organized, and somewhat difficult to follow. While the paper described a series of analyses, these analyses are overall preliminary. There is not a clear key result emerging from these analyses that would fundamentally change our understanding of the problem. In sum, I feel that while the question studied in the paper is potentially interesting, the results need to be substantially strengthened.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\n\u2014 Understanding the robustness of the representation is an important problem.\n\u2014 The attempt to leverage insights from neuroscience to improve machine learning algorithms should be applauded.\nWeaknesses:\nThe main problem that I see with the current version of the paper is that there isn\u2019t a clear and impactful result reported in the paper.\nThe presentation is not particularly well organized and needs major improvements. The descriptions of the analyses and results are messy.\nVarious statements are not rigorous. For example, the paper stated, \u201cbiological neurons adjust connectivity based on neighboring cell activity\u201d. What is the evidence for this? Also, the brain has abundant long-range connections.\nThe paper is motivated by Stringer et al (Nature, 2019). However, the interpretation of their results seems to be somewhat misleading. The paper stated \u201cThey prove that this smoothness is linked to the functional form of a power law decay in the manifold\u2019s covariance spectrum. In particular, balancing accuracy and robustness, a sweet spot lies close to a 1/n power law, with n denoting the index of the ordered spectral component. \u201d But I don\u2019t think Stringer et al 2019 proved a connection between the 1/n spectrum with the robustness. It was a conjecture described in the last paragraph of that paper. Also, Stringer et al predict different power-law relationships depending on the properties of the stimulus set (e.g., natural scene v.s. gratings). It is unclear whether the current results are consistent with theirs.\nQuestions:\n-- It would be helpful if the paper could be systematically revised to make the analysis more systematic and the key points more clear.\n-- What is the point of the left panel of Fig 1c? The pruned version mainly differed from the Raw in the power of the first few components while the scaling-law concerns the properties of the tails. So I am not sure why this difference would matter for the scaling-law.\n-- The analysis in Fig 4 is interesting. But it\u2019s just one example. Would there be a systematic way to quantify this?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9331 by Reviewer 74wa", "Subheading": "Official ReviewbyReviewer 74wa29 Oct 2023, 17:46 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors investigate whether a neural network trained on CIFAR with biologically inspired local learning rules contains activations with a power-law-like spectrum, which has been proposed as a property of biological systems. They compare this network to others trained with spectral regularization and Jacobian regularization, which explicitly induce power-law-like spectra in the network. The adversarial robustness of these networks is also investigated.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n1 poor\nStrengths:\nThe authors' experiments bridge many lines of work in machine learning and neuroscience. The question of power-law spectra in biological and artificial neural networks is topical and of interest to neuroscience and machine learning practitioners interested in adversarial robustness.\nWeaknesses:\nThe paper is difficult to follow. In some places, there are many methodological details presented, but the experiment hypothesis and conclusions need to be better described. In general, the writing could be clearer and more precise.\nMany of the experiments seem preliminary, which makes it hard to draw conclusions. For instance, the authors state in the discussion \u201cwe could not reproduce Nassar et. al. (2020)\u2019s results, probably due to the differences in our modeling choices\u201d, and in the appendix \u201cmost of our results suggest that we might have made sub-optimal choices in our methods regarding competitive results with spectral regularizers\u201d. While I appreciate the authors being honest about these limitations, this leaves more questions than answers. What would change if models were made that\ndid\nreproduce these previous results? Is there something fundamentally non-reproducible about the previous work? This makes the presented results difficult to interpret, and in the words of the authors \u201cwe ought to be cautious with generalizing them beyond the scope of this work\u201d.\nThere was not enough relation to previous literature. For instance, the authors motivate adversarial robustness with an example from cancer diagnosis, but there are many papers in the NeuroAI world that have directly looked at the robustness of models compared to human observers. This seems like it would be more relevant to the neuroscience audience that this paper is targeted towards. I encourage the authors to look at this work (some places to start would be Geirhos et al. 2018, Geirhos et al. 2021, Guo et al 2022, Harrington et al. 2022, Feather et al. 2023 but there are many many more).\nMinor: The citation format in the text seems to be incorrect with missing \u201c()\u201d around the text citations.\nMinor: In the first two sentences of section 3.2 the authors state that Figure 3 shows the spectrum of the KH layer, but this is not in Figure 3 (although it is in Figure 2).\nQuestions:\na) The authors introduce the acronym \u201cBNN\u201d and refer to these as \u201cmodels.\u201d When the authors refer to \u201cBNNs\u201d are they talking about true biological systems or models of biological systems? \u201cBNN\u201d is not a common acronym to my knowledge.\nb) How do the authors handle the fitting for the \u201calpha\u201d value? In Stringer et al. I believe that the first few and last few eigenvalues are ignored. How does that play into the fitting here?\nc) Which points (scales) are used for fitting the alpha value in Figure 2? Additionally, the different colored dots are not defined in the plot. A legend should be included.\nd) It would be helpful to show the non-normalized robustness plots. Because the clean performance significantly differs these are hard to interpret as shown.\ne) Figure 4 is interesting, however the statements about \u201csmoother\u201d decision landscapes should be quantified if one is to directly compare the results to the adversarial robustness curves.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9331 by Reviewer wEmA", "Subheading": "Official ReviewbyReviewer wEmA29 Oct 2023, 13:02 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper analyses the robustness of Krotov-Hopfield networks to noise by analyzing the eigenvalue spectrum of their internal representations. They find that it naturally produces a power-law spectrum, as had been observed in the brain by Stringer et al.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThis study provides some useful information on the robustness of the Krotov-Hopfield model\nWeaknesses:\nThe question of robustness and eigenvalue spectra is certainly interesting, but the focus on the KH model limits the impact of this work.  The study would have been stronger with a more general analysis of this for several learning rules.  For example, the KH model generates its hidden layer in a unsupervised manner.  Do other unsupervised rules act similarly?  There is some analysis of multiple rules in Figure 5, but not much in the way of a general theory, and the paper would have been stronger with more of this.\nQuestions:\nThere are two papers cited by Krotov and Hopfield, but you don\u2019t always say which one you are referring to.  Please distinguish them by adding a year every time!\nThe matrix S is not clear.  What does \u201csynaptic adjacency\u201d mean?  Is it defined by W=S ||S||^p-2?   Also the norm ||S|| is not defined.  Do you actually mean absolute value |S|?\n\\lambda means learning rate in equation (4) but covariance eigenvalue in figure 1c.\nWhat are the multiple curves in Figure 2?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}]}, "k65Nh7IV6X": {"paper_info": {"Primary Area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Conceptors, Few Shot Learning, Recurrent Neural Networks, BPTT, Motion Modelling, Low Dimensional Dynamics", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We propose a conceptor based regularization of Backpropagation through time that facilitates few shot learning of continuous interpolation between distinct temporal patterns.", "Abstract": "Generalizing from only two time series towards unseen intermediate patterns poses a significant challenge in representation learning. In this paper, we introduce a novel representation learning algorithm, \"Conceptor-Aided Recurrent Autoencoder\" (CARAE), which leverages a conceptor-based regularization to learn to generate a continuous spectrum of intermediate temporal patterns while just being trained on two distinct examples. Here, conceptors, a linear subspace characterization of neuron activations, are employed to impose a low-dimensional geometrical bottleneck on the neural dynamics. During training,  CARAE assembles a continuous and stable manifold between the two trained temporal patterns. Exploiting this manifold in the inference, CARAE facilitates continuous and phase-aligned interpolation between temporal patterns that are not linked within the training data. We demonstrate the effectiveness of the CARAE framework through comprehensive experiments on temporal pattern generation tasks and the generation of novel complex motion patterns based on the MoCap data set.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9329", "PDF Url": "https://openreview.net/pdf?id=k65Nh7IV6X"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9329 by Area Chair w9yJ", "Subheading": "Meta ReviewbyArea Chair w9yJ10 Dec 2023, 01:36 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis work proposed CARAE to use recurrent auto-encoder with a conceptor-based regularization to generate sequences that have temporal patterns interpolating between the two training sequences. The reviewers think that the problem that this paper tries to tackle is challenging, but have concerns on lacking of practical significance, which is not resolved in the rebuttal period. There is also unresolved concerns on lacking evaluation and comparison with other approaches.\nHence, rejection is recommended for this paper. The authors are encouraged to improve the quality of the draft based on the reviewers feedback.\nJustification For Why Not Higher Score:\nmotivation justification and sufficient evaluation\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9329 by Reviewer Wnkt", "Subheading": "Official ReviewbyReviewer Wnkt01 Nov 2023, 03:26 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe work proposed CARAE an approach of learning a continuous spectrum of temporal representation from two sequence of training examples. The proposed approach is based on the existing study of Conceptor and a matrix conceptor $C$ is inserted into an RNN model to control the update dynamics of the RNN's internal states. Two separate $C$s are learned from the two training sequences and a regularization term in the training objective attempts to minimize their distance. Interpolation is performed between the two $C$s to generate sequences that have temporal patterns interpolating between the two training sequences.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n1 poor\nStrengths:\nThe proposed problem setting is indeed challenging and novel and despite the challenging setting. Qualitative results from experiments on both synthetic data and real-world MOCAP data suggest the capability of the proposed CARAE in learning interpolatable representation from two training sequences.\nWeaknesses:\nThe major weakness of the work is a lack of justification for its practical significance, which makes it difficult to judge the work's contribution.\nIt is hard for me to judge the practical significance of the problem settings of the work, learning a continuous spectrum of representations that can interpolate between two training examples. The work mentioned related works of interpolatable representation learning in different areas, including locomotion modelling, robotics, and reinforcement learning. None of the mentioned work studies problems settings even close to the proposed setting. The proposed setting also restricts the approach to a two-shot learning setting and it is not clear how the approach can be extended to few-shot learning settings with more training examples and if the proposed approach would still have any practical value when larger amount of training data is available, which is not unusual in practice.\nThe proposed CARAE is based on an artificial RNN model with specific architecture designs, which is different from more commonly used RNN architectures like LSTM or GRU. Extending CARAE to these more common RNN architectures or more recent transformer architecture could significantly improve its practical value.\nApart from my concerns on practical significance, the work also have the following minor weakness:\nIn Sec. 5, the work uses\ntwo data sets\nand\ntwo distinct examples\nto call $u_1$ and $u_2$ which can be confusing. It would be much more clear if $u_1$ and $u_2$ are referred to as two training examples consistently in the work.\nThe work only presents qualitative results and training loss curves. The lack of a systematic quantitive evaluations makes the proposed approach and claimed contributions less convincing.\nQuestions:\nIn Sec. 2, the work identifies 4 challenges in the ability of RNN to generalize to different temporal dynamics.\nInferences\nis explicated tackled with in Sec. 3. Does CARAE address the other three challenges? If so, how are they addressed?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to Reviewer", "Subheading": "Official CommentbyAuthors19 Nov 2023, 15:04Everyone", "Content": "Comment:\nWe thank you for your valuable feedback on our work. We would like to address your concerns step-by-step in the following:\nWe mention related works of interpolatable representation learning in different areas, including locomotion modeling, robotics, and reinforcement learning because they deal with certain challenges, like sparsity of data while aiming for stable periodic solutions that can be interpolated. We would like to argue that the CARAE framework, although not yet applied to RL learning tasks, shows promising results in the motion modeling using the MoCap data set. Thereby, we address and overcome several of the discussed challenges that yet could only be solved by massive computational effort.\nWhile our current focus is on two-shot learning, we see the potential for expanding CARAE to few-shot learning scenarios. Thereby, the loss function needs to be reformulated to include several conceptors, one per learned temporal pattern. The CARAE framework even enables us to encode into the loss function whether the patterns should be all-to-all interpolated or whether they should line up along a single dimension. We briefly outline potential extensions of our method in the manuscript's conclusion and in appendix E, discuss how CARAE could adapt to and benefit from additional training examples, thereby enhancing its practicality and applicability in a broader range of data-constrained environments.\nWe appreciate your concern about extending CARAE to more commonly used RNN architectures like LSTM and to transformer architectures. As CARAE is an architecture-independent mechanism for manipulating neural dynamics through conceptors, we did not expect any problems with this. Indeed, in response to your suggestion, we have extended CARAE to the commonly used LSTM architecture. Furthermore, we have outlined a version of the CARAE that relies on a feed-forward neural net. Both architectures are able to learn continuous interpolation of temporal patterns as we present in the appendix C. These extensions demonstrate CARAE\u2019s versatility and significantly broaden CARAE's practical applicability.\nMinor weaknesses:\nWe thank  you for the careful reading and have streamlined the formulation in section 5 to avoid any confusion.\nIn the appendix, we added the introduction of a similarity measure (see revised manuscript) that evaluates the relation of our inferences to probabilistic features and temporal correlations of the training datasets. Based on this metric, we performed an ablation study of the two regularization parameters beta_1 and beta_2. The metric thereby adds a quantitative measure to evaluate the inferences beyond the loss terms we design, allowing for a more systematic investigation of our proposed method.\nRegarding further questions:\nThe CARAE framework effectively addresses all four challenges outlined in Section 2. The incorporation of the conceptor in the autoregressive mode ensures stable dynamics, protecting against exploding dynamics, interferences, and side dynamics. Our explicit training approach within the CARAE loss term thereby specifically tackles fixed-point dynamics, a critical aspect when aiming for interpolation. These improvements are needed to yield stable interpolated temporal patterns when dealing with sparse data as showcased by the two experiments discussed in the manuscript. Additionally to the failing vanilla RNN used in the sine wave interpolation, we added unsuccessful experiments using a RAE on both training sets to the appendix.\nIn conclusion, we believe that our revisions and additional analyses respond comprehensively to your concerns, thereby significantly strengthening the contribution and clarity of our work. We look forward to further feedback!"}, {"Heading": "Post-rebuttal response", "Subheading": "Official CommentbyReviewer Wnkt21 Nov 2023, 18:30 (modified: 21 Nov 2023, 18:30)EveryoneRevisions", "Content": "Comment:\nI would like to thank the authors for the detailed response. Maybe I'm not the target audience of this work but I'm not fully convinced by the authors' arguments for the practical significance of its unconventional problem setting. The response acknowledges the importance of learning interpolatable representation in many areas including reinforcement learning, robotics, and locomotion modelling. To my best knowledge, none of existing works in these areas that showcased interpolatable representation has a similar problem setting. Can the author give examples of existing works that adopt such a setting or examples of realistic problem settings where learning interpolatable representation from two samples is necessary? In addition, I'm not sure if the results on MoCap data are enough to justify the practical significance of the work. Controllable human motion generation under various settings has been studied in many existing works [1, 2]. Moreover, there's no unique way of interpolating between two human motion trajectories that looks realistic. Therefore I do not see a direct and objective way of evaluating the interpolated trajectories except for indirect and qualitative evaluations. I would encourage the author to spend more efforts on justifying the practical importance the problem setting for a more general audience and design experiment settings to help support that in future revision.\n[1] Petrovich, Mathis, Michael J. Black, and G\u00fcl Varol. \"Action-conditioned 3D human motion synthesis with transformer VAE.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.\n[2] Kania, Kacper, Marek Kowalski, and Tomasz Trzci\u0144ski. \"TrajeVAE: Controllable Human Motion Generation from Trajectories.\" arXiv preprint arXiv:2104.00351 (2021)."}, {"Heading": "Answer to Reviewer part 1/2", "Subheading": "Official CommentbyAuthors22 Nov 2023, 07:02Everyone", "Content": "Comment:\nWe would like to thank you for engaging with us. However, we challenge the assumption that our novel representational learning algorithm lacks practical importance. Contrary to your references, our work focuses on the smooth interpolation between learned motions, not just generating motion patterns from sequences. This is not the main aim of the work we present here. Other works, like [1], focus on learning velocity control in human motion using reinforcement learning. However, these approaches, lacking a robust representational learning mechanism, often require extensive training and computation, often resulting in unnatural motion patterns. In contrast, our work introduces a method for learning continuously interpolatable abstract representations using a small RNN trained on sparse data. In the following, we will address the raised points more in detail:\nFirst method that shows interpolatable generalization relying on two-shot learning\n: We focussed on the two-shot learning setting to showcase the unique generalization capability. Thereby, we present that our framework outperforms other e.g. classical recurrent auto-encoders that are notoriously hard to train and require a lot of data. Thereby we are less constraining, as there is no need to encode all the input into a low-dim vector space as done e.g. in transformer-based architectures. Furthermore, in the last revision, we introduced how our setup is extendable to few shot learning which further extends the applicability of our method.\nRelevance for applications in RL\n: Two-shot and few-shot learning are central challenges in machine learning. For instance, the recent resurgence of meta-learning is motivated by the drastic difference between humans and machines in terms of sample efficiency (cf. omniglot [5], finn). In RL, this need is more critical, as current algorithms still lag behind human-level sample efficiency. Addressing the reviewer\u2019s question about related works, we would highlight the work of Wayne et al[2], Mocapact[1], and more recently Gehring[2]. These start from a few policies learned by imitation (walking, running, jogging) and aim to distill them into a single neural network to accelerate further reinforcement learning on downstream tasks like following a speed target (cf. Figure). Despite showing minor improvements like faster subsequent learning and better pose, they still rely on significantly more training to follow intermediary speed targets. In our work, we accomplished a more complex task by successfully enabling the model to follow intermediary speed targets without requiring additional training (cf. video in Supplementary Materials), a development that shows a promising direction for reinforcement learning applications."}, {"Heading": "Answer to Reviewer part 2/2", "Subheading": "Official CommentbyAuthors22 Nov 2023, 07:03Everyone", "Content": "Comment:\nQualitative judgement is important for motion-related tasks and generative models in general\n: We agree with the reviewer that \u201cthere's no unique way of interpolating between two human motion trajectories that looks realistic.\u201d However, there are many ways of interpolating that don\u2019t look realistic. Here are some qualitative features that are still challenging to tackle in motion modeling\nfixed point issues: when generating in an autoregressive mode, models tends to fall into a fixed pose [4]. This makes it hard to model periodic behavior.\ntransition issues: when transitioning between different motion behaviors, models display glitches [6]\nThese are easy to spot by qualitative judgment but way more harder to quantify. Even the papers mentioned by the reviewer employ \u201cplausible\u201d and qualitative judging. Generative models are better judged with qualitative statements. Other generative models such as LLM are judged by qualitative measures as well as it is that hard to quantify e.g. \u201challucination\u201d.\nAlthough we recognize the importance of applied work, our CARAE framework proposes a novel principle for dynamic data representation learning. Thereby, we introduce a new prior to learn the representation based on the geometry of the neural dynamics which as indicated in the appendix of our work can be applied to various architectures. Our introduce method allows for visually convincing motion interpolation based on learning from only two data sets which showcase its strong ability to learn and abstract representations.\n[1] Wagener, Nolan, et al. \"MoCapAct: A Multi-Task Dataset for Simulated Humanoid Control.\" Advances in Neural Information Processing Systems 35 (2022): 35418-35431.\n[2] Merel, Josh, et al. \"Learning human behaviors from motion capture by adversarial imitation.\" arXiv preprint arXiv:1707.02201 (2017).\n[3] Gehring, Jonas, et al. \"Leveraging Demonstrations with Latent Space Priors.\" arXiv preprint arXiv:2210.14685 (2022).\n[4] Z. Ye, H. Wu, and J. Jia, \u201cHuman motion modeling with deep learning: A survey,\u201d AI Open, vol. 3, pp. 35\u201339, Jan. 2022, doi: 10.1016/j.aiopen.2021.12.002.\n[5] Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350(6266), 1332-1338.\n[6] J. Merel et al., \u201cHierarchical visuomotor control of humanoids.\u201d arXiv, Jan. 15, 2019. Accessed: Aug. 10, 2023. [Online]. Available:\nhttp://arxiv.org/abs/1811.09656"}]}, {"Heading": "Official Review of Submission9329 by Reviewer T2vx", "Subheading": "Official ReviewbyReviewer T2vx31 Oct 2023, 20:32 (modified: 23 Nov 2023, 05:53)EveryoneRevisions", "Content": "Summary:\nThe paper proposes to use conceptors (soft-projection matrices) to constrain the dynamics of an RNN to a low dimensional geometry space when learning temporal patterns in a two-shot regime. By encouraging the conceptors corresponding to the two input patterns to be close to each other when training in an autoencoder setup, the RNN learns a manifold of conceptors that can be traversed to generate interpolations, similar to the latent space traversal in a VAE.\nThe proposed method is validated with a simple sine waves example and with an example of interpolating between walking and running using 2 sequences from the Mocap dataset.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe idea of learning to control the dynamics of an RNN with only two-shots is very appealing. \nThe proposed formulation is simple and appears to work very well for the given examples.\nThe method seems to be novel, but I do not have enough familiarity with the topic to give a stronger assessment.\nThe paper is well written.\nWeaknesses:\nIf the two sequences differ in multiple underlying factors, would the learnt interpolation still give sensible results? E.g. given 2 moving mnist sequences, that differ in the colour of the digits (red vs blue on black background) and the digits themselves (e.g. 0s vs 8s), what would the interpolations look like?\nWere the values of \\beta_1 and \\beta_2 (in eq 8) ablated?\nSmall comment: in Fig 3 (c->j), it is difficult to distinguish the different colours.\nPost rebuttal and after checking the other reviews, I decided to reduce the score to 6. Indeed, the evaluation could be improved.\nQuestions:\nSee above.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to Reviewer", "Subheading": "Official CommentbyAuthors19 Nov 2023, 15:06Everyone", "Content": "Comment:\nThank you for your valuable feedback. Regarding the interpolation of different features, we have not yet incorporated a way to address different features independently. That means, in terms of your proposed colored digit interpolation where only 2 examples are given, both features (digit pattern and color) are interpolated at the same time guided by interpolating the conceptor during inference. However, and this would be partially related to the answer to reviewer 1, learning these disentangled factors of variation (digit pattern and colors) would require extending CARAE to the case where more than two-time series are present and a bottleneck of more than one dimension (in conceptor space). The multi-dimensional bottleneck is critical to discover the different factor of variations and to allow for feature-specific interpolation. Furthermore, once CARAE is expanded in this manner, it becomes possible to adapt techniques from the auto-encoder literature to promote disentanglement. For instance, one can enforce a probabilistic interpretation of the bottleneck and ensure the independence of its dimensions, as seen in VAE and Beta-VAE methods.\nIt's worth mentioning that the disentanglement of factors of variation holds significant relevance in the context of motion modeling. This is particularly important because a key challenge in achieving realism in simulating characters is the ability to portray various behaviors with distinct styles, such as depicting characters as drunk, sad, or excited [1].\nIn the appendix, we introduced a similarity metric (see the updated manuscript) to assess the connection between the intermediary inferences of the CARAE framework and the probabilistic attributes and time-related correlations to the training datasets. Utilizing this metric, we conducted an ablation analysis on the regularization parameters beta_1 and beta_2.\n[1] Taylor, Graham & Hinton, Geoffrey. (2009). Factored conditional restricted Boltzmann Machines for modeling motion style. Proceedings of the 26th International Conference On Machine Learning, ICML 2009. 129. 10.1145/1553374.1553505."}]}, {"Heading": "Official Review of Submission9329 by Reviewer cFnM", "Subheading": "Official ReviewbyReviewer cFnM31 Oct 2023, 10:12 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors introduce a novel algorithm called \"Conceptor-Aided Recurrent Autoencoder\" (CARAE) to address the challenge that generalizing from just two time series to create intermediate patterns in the context of representation learning. In addition, the author show the effectiveness proposed method on mocap motion modeling .\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe method section is well prepared and concise.\nWeaknesses:\nIn all honesty, I'm not well-versed in this particular subject, and I've noticed that there are limited related works available for reference. Despite dedicating a significant amount of time to study the topic, I'm still finding it challenging to provide a comprehensive and professional feedback on the paper.\nLimited Related Works: Research can be more challenging when there are few related works to use as a basis for comparison or to gain a deeper understanding of the context.\nOutdated References: The reference to Jaeger (2014) being eight years old may indicate that the paper doesn't incorporate more recent developments in the field. It's common in rapidly evolving fields like machine learning for research to become outdated relatively quickly.\nQuestions:\nWhy using RNN rather than more recent and powerful transformer architecture?\nWhy there is not a comparison with related works or baseline?\nIt's hard to get that (b) in Figure 4 is intermediate pattern.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to Reviewer", "Subheading": "Official CommentbyAuthors19 Nov 2023, 15:08Everyone", "Content": "Comment:\nWe thank you for your feedback, which we would like to address as follows\nAcknowledging the Relevance of Older References:\nWe would like to point out that the age of a reference does not undermine its validity. In fact, older concepts often find renewed significance in contemporary research. Additionally, linear subspace characterization linear subspace control did have recent successes by being effectively combined with backpropagation to address catastrophic forgetting issues, as highlighted in recent studies [1], [2]. Also, the concept of low-dimensional dynamics has recently gained traction in computational neuroscience, serving as a foundation for rich theoretical and experimental work to understand the dynamical aspect of the brain [3]. Our research proposes a novel interpretation of these phenomena by connecting it to the rich field of learning representation and autoencoding in Deep Learning.\nDifferentiating from Jaeger\u2019s Work and Aligning with Current SOTA Research:\nOur approach represents a significant departure from Jaeger\u2019s initial work [4], where linear subspace control was not linked to learning with RNNs but to store memories akin to Hopfield Networks but for time series. Instead, our methodology is more closely aligned with contemporary SOTA research in meta-learning [5], where some meta-parameters (equivalent of the conceptor) are multiplicatively interacting with a base model to improve the learning data-efficiency. These recent studies recognize and utilize the potential of linear subspace control in developing advanced learning models.\nEmphasizing the Role of RNNs in Deep Learning:\nIn the realm of deep learning, it's crucial to note that RNNs stand on par with other architectures like transformers on data-sparse domains. This includes the distillation and compression of locomotion policies into multi-task policy networks [6, 7]. Finding good compression principles is recognized as promising to be more data-efficient. Moreover, various RNN architectures are increasingly challenging transformers in terms of reducing computational costs and offering unbounded context length [7]. Additionally, some RNNs architectures have been shown to be very close to attention-based computations  [8].\nExtending the CARAE Architecture:\nAs mentioned in our responses to other reviewers, we have expanded our work in the appendix. Here, we demonstrate that the CARAE (Conceptor-Aided Recurrent AutoEncoder) architecture can be extended to scenarios involving more data, higher-dimensional bottlenecks, and other commonly used architectures like the LSTM. Furthermore, we adapted the CARAE to static Feed Forward Networks (FFWs) like MLPs applied to time series prediction, theoretically allowing for application to transformers.\n[1]      \tX. He and H. Jaeger, \u201cOvercoming Catastrophic Interference using Conceptor-Aided Backpropagation,\u201d presented at the International Conference on Learning Representations, Feb. 2018. Accessed: Aug. 21, 2023. [Online]. Available:\nhttps://openreview.net/forum?id=B1al7jg0b\n[2]      \tL. Duncker, L. Driscoll, K. V. Shenoy, M. Sahani, and D. Sussillo, \u201cOrganizing recurrent network dynamics by task-computation to enable continual learning,\u201d in Advances in Neural Information Processing Systems, Curran Associates, Inc., 2020, pp. 14387\u201314397. Accessed: Aug. 17, 2023. [Online]. Available:\nhttps://proceedings.neurips.cc/paper/2020/hash/a576eafbce762079f7d1f77fca1c5cc2-Abstract.html\n[3]      \t\u201cLow-rank RNNs in ten minutes,\u201d neurosopher. Accessed: May 31, 2023. [Online]. Available:\nhttps://adrian-valente.github.io/2022/06/01/low-rank-summary.html\n[4]      \tH. Jaeger, \u201cControlling Recurrent Neural Networks by Conceptors,\u201d arXiv:1403.3369 [cs], Apr. 2017, Accessed: Dec. 09, 2020. [Online]. Available:\nhttp://arxiv.org/abs/1403.3369\n[5]      \tN. Zucchet, S. Schug, J. von Oswald, D. Zhao, and J. Sacramento, \u201cA contrastive rule for meta-learning.\u201d arXiv, Oct. 03, 2022. Accessed: Jul. 07, 2023. [Online]. Available:\nhttp://arxiv.org/abs/2104.01677\n[6]      \tJ. Merel et al., \u201cNeural probabilistic motor primitives for humanoid control.\u201d arXiv, Jan. 15, 2019. Accessed: May 05, 2023. [Online]. Available:\nhttp://arxiv.org/abs/1811.11711\n[7]      \tN. Wagener, A. Kolobov, F. V. Frujeri, R. Loynd, C.-A. Cheng, and M. Hausknecht, \u201cMoCapAct: A Multi-Task Dataset for Simulated Humanoid Control.\u201d arXiv, Jan. 13, 2023. doi: 10.48550/arXiv.2208.07363.\n[8]      \tD. Y. Fu, T. Dao, K. K. Saab, A. W. Thomas, A. Rudra, and C. R\u00e9, \u201cHungry Hungry Hippos: Towards Language Modeling with State Space Models.\u201d arXiv, Apr. 28, 2023. doi: 10.48550/arXiv.2212.14052.\n[9]      \t\u201cRNNs strike back,\u201d neurosopher. Accessed: Nov. 18, 2023. [Online]. Available:\nhttps://adrian-valente.github.io/2023/10/03/linear-rnns.html"}]}, {"Heading": "Official Review of Submission9329 by Reviewer PFFz", "Subheading": "Official ReviewbyReviewer PFFz30 Oct 2023, 12:45 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper deals with analysis of time series. It is proposed to design a generator of such time series from limited observation data.Those data being limited in the sense that only two patterns type are considered as available. The aim of this paper is then to be able to generate 'intermediate' patterns. This is performed through the use of recurrent auto-encoder with a conceptor-based regularization. This conceptor-based regularization is based on two folds: (1) ensuring a close representation of patterns and (2) ensuring close conceptors for each pattern. \nFrom this trained recurrent auto-encoder, a linear interpolation of conceptors is proposed to generate intermediate patterns.\nExperimental results are reported on sine-wave patterns and MoCap motion modelling.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe proposed method allows to provide a recurrent auto-encoder generator that is able to generate continuous type of patters although being trained on two patterns.\nWeaknesses:\nThe proposed controlled recurrent auto-encoder allows to be able to generate continuous patterns evolution between two initial pattern of time series. However this is quite hard to assess the benefits of the proposed approach since no comparison to other technique is proposed nor any quality metrics. Only subjective evaluation is reported.\nReferences to equation and figures needs to be revisited since when cited it is often omitted to mention if it refers to a table, image or other.\nAs quickly mentioned in footnote of page 6, SPD matrices are to be associated to a specific manifold. So linear interpolation used in equation 10 could be discutable. But also the distance metric used in equation 8. It would be interesting to consider also here some classical metrics and interpolation technique of SPD matrices to see the impact of distance metric and interpolation technique there. See also [1,2] for additional paper on SPD matrices metrics.\nNo discussion on the impact of $\\beta_1, \\beta_2$ parameter is provided. What about for exemple using only pattern proximity (e.g. $\\beta_1=0$) ?\nDetails on backward pass in appendix B.2 is quite useless when considering Deep Learning frameworks that automaticaly compute back-propagation path (e.g. TensorFlow, Pytorch).\n[1] Huang et al, Log-Euclidean Metric Learning on Symmetric Positive Definite Manifold with Application to Image Set Classification, \nProceedings of the 32 nd International Conference on Machine Learning, Lille, France, 2015. JMLR: W&CP volume 37, 2015\n[2] Vemulapalli et al, Riemannian Metric Learning for Symmetric Positive Definite Matrices\nQuestions:\nCould there be objective metric to evaluate the performance of proposed approach? For example what about having a 3rd pattern to be used for evaluation?\nWhat about the impact of $\\beta_1, \\beta_2$ hyper-parameters? Could there be a specific ablation study?\nHow does the proposed technique performs with respect to other approaches?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to Reviewer", "Subheading": "Official CommentbyAuthors19 Nov 2023, 15:10 (modified: 19 Nov 2023, 15:11)EveryoneRevisions", "Content": "Comment:\nThank you for your critical feedback. We have made several amendments to our manuscript to address your concerns, particularly regarding the evaluation methodology.\nWe agree with  the need for objective evaluation metrics, and we have devised a quantitative metric in the revised manuscript. In this context, we would not like to use a third pattern to evaluate our method as the interpolated temporal patterns are based on probabilistic interpolation related to the training data. A third example of a parametric family could contain features that are absent or only weakly present in the training data and therefore can not be inferred by the CARAE mechanism. Using such third patterns for evaluating our method could lead to false understanding of what our method aims to achieve. To quantitatively measure the performance of the interpolated temporal patterns we have developed a similarity metric specifically tailored to our task. This metric provides a probabilistic measure and a temporal correlation measure of the generated patterns' fidelity to the training data, addressing the subjective nature of our initial evaluations. Further details on this metric, including its formulation and application, are now included in the appendix and referenced in the manuscript. Finally, we would also like to note that auto-encoders are often judged on their output re-generation with subjective judgments [1]. Motion modeling also [2] because one of their main goals is to develop plausible motion for simulated characters. \nTo provide further clarity on the role of conceptor loss and its regularization term, we included in the appendix an ablation study of the regularization parameters beta_1 and beta_2. This addition aims to elucidate the identifiable effects of conceptor loss on controlled neural networks, also illustrating the applicability of the newly introduced evaluation metrics. Both regularization parameters show different influences for the two evaluated tasks. Thereby, we find that the usage of both is needed to significantly improve the generalization during the interpolation.\nIn response to your remarks on SPD matrices, we would like to discuss our choice of the linear interpolation. We also discussed alternative metrics like log-euclidean and interpolation methods for SPD matrices, as mentioned in the referenced literature. However despite its simplicity, the linear interpolation approach preserves the SPD matrix properties [3], ensuring that the interpolated conceptors are still valid soft projection matrices. Furthermore, we decided to focus on linear interpolation due to its computational efficiency. Other metrics include the usage of matrix logarithm and exponential that are computationally expensive for the forward and backward-pass and could potentially introduce instabilities in the training.  Furthermore, these functions are often not implemented in standard deep learning libraries making their usage more complicated. Nevertheless, as it is computationally more feasible, we tested the usage of the log-euclidean and the shape-and-orientation (SAO) metric during the inference while relying on the linear notion for the training. The log-Euclidean and SAO metrics are developed to tackle known challenges in statistical operations involving semi-definite matrices. One such problem is the \"flattening effects\" [4]. This refers to the deformation and shrinkage of singular values that occur during linear interpolation. However, in our study, we found that these metrics did not significantly impact the inference process. Whereas this might be related to the particular task at hand we agree and mention in the paper that a more rigorous investigation of the influence of the metric might further improve our results. Due to the limited time, we started this investigation of the metrics for inference only and attached an initial discussion to the appendix as section F.\nMinor remarks:\nWe adapted the references in the revised manuscript making it more clear to which figure/table/equation we refer.\nIn summary, these revisions and additions address your concerns by enhancing the objective evaluation of our approach and justifying our methodological choices. We believe these changes strengthen the manuscript and look forward to your further feedback."}, {"Heading": "References for Answer to Reviewer", "Subheading": "Official CommentbyAuthors19 Nov 2023, 15:11Everyone", "Content": "Comment:\n[1]      \tI. Higgins et al., \u201c\u03b2-VAE: LEARNING BASIC VISUAL CONCEPTS WITH A CONSTRAINED VARIATIONAL FRAMEWORK,\u201d 2017.\n[2]      \tG. W. Taylor, G. E. Hinton, and S. Roweis, \u201cModeling Human Motion Using Binary Latent Variables\u201d.\n[3]      \tcopper.hat, \u201cAnswer to \u2018How to prove a set of positive semi definite matrices forms a convex set?,\u2019\u201d Mathematics Stack Exchange. Accessed: Nov. 18, 2023. [Online]. Available:\nhttps://math.stackexchange.com/a/322743\n[4]      \tA. Feragen and A. Fuster, \u201cGeometries and Interpolations for Symmetric Positive Definite Matrices,\u201d in Modeling, Analysis, and Visualization of Anisotropy, T. Schultz, E. \u00d6zarslan, and I. Hotz, Eds., in Mathematics and Visualization. , Cham: Springer International Publishing, 2017, pp. 85\u2013113. doi: 10.1007/978-3-319-61358-1_5."}, {"Heading": "Official Comment by Reviewer PFFz", "Subheading": "Official CommentbyReviewer PFFz22 Nov 2023, 06:30 (modified: 22 Nov 2023, 06:32)EveryoneRevisions", "Content": "Comment:\nThanks for these answers.\nI still have some concerns of the lack of evaluation with respect to other possible approaches. It is especially difficult to see the benefit of the proposed quantitative metric without further details. For instance, if to consider work done in [1] how could we position it here. In [1] use of auto-encoder is also proposed as well as a quality metric based on prediction metrics on further patterns. When I was suggestion 3rd pattern this was to go into that direction. To see how the proposed generation model could predict intermediate patterns.\nConsidering feedback on $\\beta$ parameters also provide a mixed feeling since finally it seems quite sensitive on the considered use case as said in response from authors.\nSo i am rather enclined to keep my initial rating.\n[1] Hughet et al, 'Manifold interpolating Optimal-Transport flows for trajectory inference', Neurips 22."}, {"Heading": "Reply to comment", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:59 (modified: 23 Nov 2023, 07:01)EveryoneRevisions", "Content": "Comment:\nThank you for your constructive feedback, which has led to significant improvements in our manuscript.\nInterpolating trajectories is more difficult than filling out single-time steps\nWe thank you for your feedback and reference to the \u201cMIOFlow\u201d framework by Huguet et al. \nHowever, we would like to note that while both CARAE and MIOFlow leverage auto-encoder concepts to analyze time series, their aim, methodology, and applications diverge significantly.\nVery different task\n: CARAE focuses on interpolating between trajectories conditioned on a latent variable. MIOFlow only deals with filling held-out time points within a trajectory. They never use their methods on novel interpolated trajectories.\nEvaluation\n: because they don\u2019t evaluate on interpolation between trajectories, it\u2019s much easier to quantify by holding out a one-time point. We also remark that the referenced paper relies on many qualitative comparisons.\nDifferent degree of difficulty\n: We would like to argue that their task is relatively simpler because:\nTheir task does not involve long-term stability issues because they deal with very short trajectories with simple dynamics: max 5-time steps versus around 150-time steps (of dimension around 100) for our work. Also, the video in the supplementary material shows that our pattern generator is very stable through transitions and at various levels. \nOur approach emphasizes the controlled generation of continuous pattern families from extremely limited data (as such data might be difficult to generate, particularly in RL settings, see other comments). \nThey do  not propose a mechanism to morph between trajectories while they are unfolding (as we showed in section 4.3).\nThe bottleneck definition\n:  MIOFlow employs a combination of dynamic models, manifold learning, and optimal transport to interpolate single timesteps between static population snapshots. \nWhile MIOFlow emphasizes a probabilistic framework to define their bottleneck, CARAE emphasizes the geometry of neural dynamics. MIOFlow's use of Neural ODEs and its emphasis on optimal transport with manifold ground distance distinguishes it from CARAE, which prioritizes the linear interpolation of conceptors and the generation of patterns specifically within a defined probabilistic framework.\nBenchmarking with a quantitative measure.\nWe have now addressed your suggestion for quantitative evaluation using a third pattern to benchmark the performance of our CARAE framework, taking inspiration from the MIOFlow paper that you added as reference.\nIn our revised approach, detailed in Appendix I, we compared the performance of CARAE against a baseline method of simple linear interpolation between two distinct temporal motion patterns: walking and running. Our goal was to generate an intermediate time series that would ideally represent a jogging motion (the \u201ccorrect\u201d intermediate between walking and running from the dataset), and then measure the accuracy of these generated patterns against the ground truth jogging data available in our dataset.\nWe used MSE and JSTCC the as the metric for quantification. The results, as presented in Appendix I, demonstrate that CARAE achieves a lower MSE in comparison to the direct linear interpolation approach when evaluated against the ground truth jogging data. This finding substantiates the efficacy of CARAE in generating more accurate intermediate temporal patterns and also provides a clear, objective measure of its performance. This establishes a tangible benchmark for future research, offering a solid foundation upon which to evaluate, measure, and enhance our proposed framework, task, and solution.\nWe believe that this additional experiment and its results effectively address your concerns regarding the lack of quantitative evaluation and comparative analysis in our initial submission. The ability of CARAE to outperform a straightforward linear interpolation method in this context highlights its potential as a more nuanced and effective tool for interpolating between temporal motion patterns.\nWe hope that this new evidence, alongside the other revisions made in response to your comments, strengthens the case for the novelty and utility of our proposed CARAE framework."}]}]}, "9k0krNzvlV": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "watermarking, large language models, distillation", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "Language models can learn to naturally generate watermarked text, without using any special decoding algorithms.", "Abstract": "Watermarking of language model outputs enables statistical detection of model-generated text, which can mitigate harms and misuses of language models. Existing watermarking strategies operate by altering the decoder of an existing language model. In this paper, we ask whether language models can directly learn to generate watermarked text, which would have significant implications for the real-world deployment of watermarks. First, learned watermarks could be used to build open models that naturally generate watermarked text, enabling watermarking for open models, where users can control the decoding procedure. Second, if watermarking is used to determine the provenance of generated text, an adversary can hurt the reputation of a victim model by spoofing its watermark and generating damaging watermarked text. To investigate the learnability of watermarks, we propose watermark distillation, which trains a student model to behave like a teacher model that uses decoding-based watermarking. We test our approach on three decoding-based watermarking strategies and various hyperparameter settings, finding that models can learn to generate watermarked text with high detectability. We also find limitations to learnability, including the loss of watermarking capabilities under fine-tuning on normal text and high sample complexity when learning low-distortion watermarks.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "general machine learning (i.e., none of the above)", "Submission Number": "9328", "PDF Url": "https://openreview.net/pdf?id=9k0krNzvlV"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9328 by Area Chair SdzQ", "Subheading": "Meta ReviewbyArea Chair SdzQ06 Dec 2023, 07:50 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\n\"On the Learnability of Watermarks for Language Models\" provides a comprehensive set of experiments investigating whether recently proposed watermarking strategies for large language models are learnable. The learnability of watermarking strategies has implications both concerning the ease of imprinting a watermark into open-source models and concerning spoofing attacks against watermarks.\nOverall the reviewers were positive about this work, although several concerns were brought up concerning the depth of the experimental investigation. The authors adressed these concerns during the response period and I ask them to make sure these additional experiments are included in the camera-ready version of this submission.\nAs a final remark, I am slightly surprised that the authors did not vary $k$ for the KGW watermark, given that this quantity is central to the learnability of that watermark. Especially in light of related work that is already investigating alternative choices for $k$, such as $k=0$ in Zhao et al., \"Provable Robust Watermarking for AI-Generated Text\", and $k=4$ in KGW2023b, in the context of other analysis. I firmly believe that the inclusion of these experiments would further strengthen this work and would be of interest to the ICLR community. The choice of  $k=0$ in Zhao et al., for example, is, intuitively, easily learnable.\nJustification For Why Not Higher Score:\nReviewers considered the topic at hand to be somewhat niche, so I am not proposing this submission for a talk, but I am confident that there is a community at ICLR that would be very interested in discussing the results of this work.\nJustification For Why Not Lower Score:\nInteresting, detailed investigation of a very relevant question, aiding the community's understanding of the pros and cons of different watermarking strategies."}, {"Heading": "Summary of main changes", "Subheading": "Official CommentbyAuthors21 Nov 2023, 08:43 (modified: 23 Nov 2023, 04:16)EveryoneRevisions", "Content": "Comment:\nWe thank all of the reviewers for their valuable and helpful feedback. We have responded to each reviewer individually and revised our paper accordingly. We summarize the main changes below:\nWe run additional experiments using Llama 2 7B as both the teacher and student model for sampling-based watermark distillation in Appendix C. (reviewer hxrQ)\nWe run additional experiments investigating the sample efficiency of sampling-based watermark distillation in Appendix D. (reviewer metd)\nWe run additional experiments on sampling-based distillation if the training samples are watermarked using two different keys in Appendix E. (reviewers 2p7U, metd)\nWe run evaluations on additional datasets (Wikipedia articles and arXiv papers) in Appendix F. (reviewer hxrQ)\nWe include the AUROC metric for classifying watermarked vs non-watermarked text in full tables in the Appendix. (reviewer GhKC)\nWe include a discussion of model watermarking for protection against model extraction attacks in the related work section (Section 7). (reviewers hxrQ, GhKC)\nWe re-ran watermark detection evaluation for sampling-based watermark distillation (Section 5.2) to only detect the first 200 tokens under the Llama 2 tokenizer, which is used for detection, rather than the first 200 tokens under the Pythia tokenizer, to allow for fairer comparison between logits-based and sampling-based distillation (Table 1 vs 2). This caused very slight changes in some of the p-values in Table 2, which do not change any of the trends or conclusions.\nWe have revised the paper to make our contribution clearer. (reviewers 2p7U, metd, GhKC)"}, {"Heading": "General comment clarifying our contribution", "Subheading": "Official CommentbyAuthors21 Nov 2023, 08:17 (modified: 21 Nov 2023, 08:17)EveryoneRevisions", "Content": "Comment:\nReviewers 2p7U, metd, and GhKC have raised clarifying questions about our exact contribution, particularly with regard to watermarking for open models. We give a clarification of our contribution here, and we have revised our paper accordingly.\nThe focus of our work is empirically investigating the learnability of decoding-based watermarks for language models, i.e., whether a model can learn to generate watermarked text by itself, without using a specialized watermark decoding algorithm. If a model is successfully able to learn to do so, we call this weights-based watermarking. This question of learnability was previously unexplored, and whether existing decoding-based watermarks are learnable was not known. Our main contribution is our empirical findings, namely that models can learn to generate watermarked text with high detectability, although sample complexity is higher for lower-distortion watermarks and hyperparameter settings.\nTo motivate and demonstrate the importance of our investigation into watermark learnability, we discuss relevant implications for developing watermarking for open models and for the possibility of spoofing attacks. Weights-based watermarking is necessary for developing robust watermarking for open models (e.g., Llama 2) since users can run inference themselves and choose the decoding procedure, so decoding-based watermarking algorithms are easily disabled, or just not enabled by default. So, our work addresses one of the key technical challenges towards developing robust watermarking for open models. Further important technical challenges remain, such as robustness to further fine-tuning, as users can fine-tune open models on their own data. We believe that solving these remaining roadblocks is best explored in future work.\nHowever, weights-based watermarking also has potential use cases that do not depend on being robust to further fine-tuning. For example, weights-based watermarking could be used for watermarking open models which are unlikely to be fine-tuned further by users, such as RLHF instruction-following chat models. In addition, weights-based watermarking simplifies decoding compared to decoding-based watermarking, as there is no need for an additional specialized decoding algorithm. So, weights-based watermarking can easily be deployed into existing LLM infrastructures and optimized generation algorithms, as it just requires loading different model weights.\nIn addition, watermark learnability raises the possibility of spoofing attacks, where an adversary mimics the watermark of a victim model. The existence of successful spoofing attacks suggests that watermark detection should not be used to attribute text provenance or blame to a specific model. We demonstrate a simple proof of concept spoofing attack to substantiate their possibility. We believe that comprehensively evaluating spoofing attacks and defenses is a cat and mouse security game which is not necessarily conclusively answerable at this time, and would be best explored in detail in future work, but our work provides a foundation for this future work by showing that spoofing attacks can exist in some settings.\nIn summary, our main contribution is our empirical investigation and results on the learnability of watermarks. We believe that this contribution is significant and new as watermark learnability was previously unexplored, and it was unknown whether existing decoding-based watermarks are learnable. Our findings address a key technical challenge towards developing watermarking for open models and raise the possibility of spoofing attacks. We hope that our work will inform and inspire future lines of research into remaining technical challenges towards watermarking for open models, comprehensively evaluating spoofing attacks and defenses, etc."}, {"Heading": "Official Review of Submission9328 by Reviewer 2p7U", "Subheading": "Official ReviewbyReviewer 2p7U31 Oct 2023, 12:55 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper raises a concern about forgery attacks on current LLM watermarking methods. To achieve the attack goal, a distillation-based strategy is introduced. Experiments on three existing LLM watermarking methods demonstrate the threat of such an attack.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nIt is interesting to introduce forgery/spoofing attacks into the recent popular area, namely, LLM.\nWeaknesses:\nThis paper directly extends distillation strategies on decoding-based watermarking and then poses the limitation of weight-based watermarking. However, no solution is provided. It seems like an experimental report, and it would be better to introduce the specific solution.\nThe motivation of this paper is there is a limitation of decoding-based watermarking, namely, replacing it with a normal decoder. Is the assumption practical? In practice, for an LLM API, how do we conduct such an operation?\nFor wright-based LLM watermarking, more attacks (besides fine-tuning) shall be considered, such as pruning and further distillation.\nThe paper exceeds 9 pages.\nQuestions:\nRe-clarify the contribution of this paper, and provide strong results or explanations to support the claim. Furthermore, re-clarify the scenario for better understanding.\nFor decoding-based watermarking, if different users are assigned different keys, will the distillation or spoofing attacks fail?\nWhat is the additional computational cost? Evaluate or compare it.\nBesides decoding-base LLM watermarking, there exist some backdoor-based LLM watermarking methods. Are the findings still suitable for them?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reply to Reviewer 2p7U", "Subheading": "Official CommentbyAuthors21 Nov 2023, 08:23Everyone", "Content": "Comment:\nWe thank you for the useful and insightful feedback and for taking the time to review our paper. We address questions and concerns below.\nClarification of contribution\nPlease see our general comment clarifying our contribution.\nhttps://openreview.net/forum?id=9k0krNzvlV&noteId=UyaqBwxSNh\nReplacing decoding-based watermarking with normal decoder\nFor API-only LLMs, decoding-based watermarking is suitable, since the LLM provider controls generation, and users cannot replace the decoding-based watermarking algorithm with a normal decoder. However, for open LLMs, e.g., Llama 2, users run generation themselves, so they can easily choose not to use a decoding-based watermark algorithm, and many inference libraries do not watermark outputs by default or at all. So, decoding-based watermarking is unsuitable for robust watermarking for open LLMs. Our findings into weights-based watermarking address this key technical challenge towards watermarking for open LLMs, though additional challenges remain, e.g., robustness to further fine-tuning.\nAttacks besides fine-tuning\nWe demonstrate that simple fine-tuning removes weights-based watermarking capabilities, showing that developing weights-based watermarking that is robust to modifying model weights is an important unsolved challenge. Further attacks would not change our conclusion.\nPaper length\nPer the ICLR author guide\nhttps://iclr.cc/Conferences/2024/AuthorGuide\n, the optional ethics statement and reproducibility statement do not count towards the page limit. The main body of our paper does not exceed 9 pages.\nAssigning different watermarking keys\nWe run additional experiments in Appendix E to investigate the behavior of sampling-based watermark distillation if the samples are watermarked using multiple different keys. We also run different trials varying the number of training samples. The table below shows watermark detection p-values.\nNumber of training samples\nModel\n20k\n40k\n80k\n160k\n320k\n640k\nKGW $\\delta = 2$ (one key)\n4.1e-02\n1.4e-02\n2.4e-03\n5.2e-04\n5.1e-05\n3.6e-06\nKGW $\\delta = 2$ (two keys)\n1.7e-01\n1.4e-01\n7.8e-02\n5.7e-02\n2.9e-02\n1.4e-02\nAar $k = 2$ (one key)\n7.4e-02\n9.4e-03\n3.5e-04\n1.0e-06\n5.1e-10\n2.9e-14\nAar $k = 2$ (two keys)\n4.2e-01\n2.3e-01\n1.2e-01\n4.0e-02\n1.0e-02\n1.2e-03\nThe results show that using two different keys hinders watermark learning, as indicated by the larger p-values. However, learning is not completely prevented, as the p-values are still much lower than 0.5 and decrease as the number of training samples increases.\nNote that if multiple watermarking keys are used, then the watermark detection will lose statistical power. Any suspected text will need to be tested using each of the keys in use, so multiple testing correction must be performed, leading to weaker p-values and a higher false negative rate.\nAdditional computational cost\nWeights-based watermarking uses standard generation procedures, so there is no additional computational cost at inference time compared to normal LLMs. Compared to decoding-based watermarking, weights-based watermarking has less computational cost at generation time, since there is no need to run an additional decoding-based watermarking algorithm on top of the LLM. Weights-based watermarking does require model training, the computational cost of which varies depending on model size and dataset size, but this cost is one-time and not incurred at inference time.\nRelationship to backdoor-based model watermarking\nOur findings concern the learnability of decoding-based text watermarking methods. Backdoor-based model watermarking is crucially different in both setting and method. Backdoor-based model watermarking is meant to enable detecting if a suspect model was stolen from a victim model, e.g., through leaking model weights. Detection is done by querying the suspect model multiple times on specially chosen inputs, i.e., the backdoored inputs. If the suspect model produces the chosen backdoored outputs on these backdoor inputs (which are chosen to be different from how a normal, non-backdoored model would behave), then the suspect model is detected as stolen. Note that the backdoored inputs are meant to be stealthy and hard to find, and the backdoored model still behaves normally on normal inputs. On the other hand, decoding-based text watermarking enables detecting if a given text was generated by an LLM using any input prompt. Detection is done without using any LLM, only the tokenizer is needed. Decoding-based text watermarking is designed to affect all model outputs regardless of input, so that ideally all generated texts can be detected as watermarked. Because of these crucial differences in both setting and method, our findings are not directly relevant to backdoor-based model watermarking, and vice versa."}, {"Heading": "End of discussion period", "Subheading": "Official CommentbyAuthors22 Nov 2023, 18:08Everyone", "Content": "Comment:\nDear Reviewer 2p7U,\nWe appreciate all of the valuable time and effort you have spent reviewing our paper. As today is the last day of the discussion period, we gently request that you review our reply and consider updating your evaluation accordingly. We believe that we have addressed all questions and concerns raised, but please feel free to ask any clarifying questions you might have before the end of the discussion period.\nBest,\nAuthors"}]}, {"Heading": "Official Review of Submission9328 by Reviewer metd", "Subheading": "Official ReviewbyReviewer metd30 Oct 2023, 18:50 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors study whether language watermarks can be spoofed by training a student language model (LM) on the watermarked outputs of a teacher LM (the process is known as distillation). The experiments show that all three surveyed watermarking methods can be spoofed when the attacker has 640k (watermarked) samples, each comprised of 256 tokens, and that the distilled watermark remains effective under different decoding strategies and has similar robustness properties as the teacher's watermark.\nSoundness:\n4 excellent\nPresentation:\n4 excellent\nContribution:\n2 fair\nStrengths:\nOverall, I liked the paper. The problem of watermarking open models and spoofing attacks against watermarks is timely and important.\nThe authors show that three watermarking methods are vulnerable to spoofing through distillation.\nThe authors convince me their distillation approach works for many different generation parameters against all three watermarking methods when sufficiently many samples are available to the attacker.\nThe authors show experiments with many state-of-the-art models.\nWeaknesses:\nContribution to Open Model Watermarking\n. As the authors show, open-model watermarking using distillation is not robust against fine-tuning. I am unclear about the contribution of the authors to open model watermarking. No prior work has used distillation to watermark LMs, hence there is no security threat. What is the use of a watermark that (i) lacks robustness and (ii) can be spoofed by design? I would love to hear the author's thoughts on this.\nLimited novelty.\nOne would expect that watermarking can be spoofed if the attacker can access sufficiently many watermarked samples. If I understood correctly, the authors use\n163 million tokens\n($640$k samples times 256 tokens each) of watermarked text with the\nsame\nmessage. How realistic is this assumption? Is the attack effective when a provider uses a different message after generating a set number of tokens?\nSpoofing is possible when sufficiently many samples are revealed. I believe a more interesting approach is to measure the number of samples that enable spoofing or to derive a theoretical bound for the spoofer's sample efficiency. Insights into that question could guide the party that injects the watermark into deploying defenses, such as switching to a different key or message after this number of samples has been revealed. Unfortunately, the paper does not investigate this problem. Do the authors have any insights into that problem?\nQuestions:\nWhat are your contributions towards open model watermarking?\nHow sample-efficient is the spoofing attack?\nCan the distilled and original watermarked distributions be distinguished? I assume the spoofed watermarked does not learn rare watermarked sequences, but instead focuses first on the most often occurring ones. If a defender can detect and ignore those during detection, can they evade your spoofing attack while effectively detecting watermarked text?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nI believe there are no ethical concerns in this paper.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reply to Reviewer metd (part 1/2)", "Subheading": "Official CommentbyAuthors21 Nov 2023, 08:26Everyone", "Content": "Comment:\nWe thank you for the useful feedback and for taking the time to review our paper. We are glad that you liked the paper and think that the problem is timely and important. We address questions and concerns below.\nContribution to open model watermarking\nPlease see our general comment clarifying our contribution.\nhttps://openreview.net/forum?id=9k0krNzvlV&noteId=UyaqBwxSNh\nOne important technical challenge towards open model watermarking is robustness to decoding procedure, since users of open models can run inference themselves and choose the decoding procedure, so it is easy to not use a decoding-based watermark algorithm. Our findings on watermark learnability and weights-based watermarking address this key challenge, taking a necessary first step towards developing open model watermarking. However, as you correctly point out, robustness to fine-tuning is another important technical challenge which we leave for future work. We believe that our contribution is still valuable because it investigates a necessary first step towards open model watermarking that was previously unexplored.\nRegarding point (ii), we do not design watermarks to be spoofable. We investigate the learnability of existing decoding-based watermarks, rather than design new watermark algorithms, and high learnability suggests the possibility of being vulnerable to spoofing attacks. Spoofability suggests that watermarks should not be used to assign provenance or blame to a specific model, but it does not hinder the primary case of detecting model-generated text, e.g., preventing students from cheating on essays or preventing LLM-generated misinformation campaigns. Watermarking is still useful and valuable even if it is spoofable.\nSample efficiency\nTo investigate sample efficiency, we have included additional experiments measuring watermark detection p-values as we vary the number of training samples for sampling-based watermark distillation. As in the main experiments, each sample is 256 tokens long, and we use Llama 2 7B as the teacher model and Pythia 1.4B as the student model. Note that the training batch size is held the same, so fewer training samples means fewer gradient steps. P-value results are shown below, and we have also included a plot of p-values against the number of training samples in the paper (Appendix D).\nNumber of training samples\nModel\n20k\n40k\n80k\n160k\n320k\n640k\nKGW $\\delta = 2$\n4.1e-02\n1.4e-02\n2.4e-03\n5.2e-04\n5.1e-05\n3.6e-06\nAar $k = 2$\n7.4e-02\n9.4e-03\n3.5e-04\n1.0e-06\n5.1e-10\n2.9e-14\nKTH $s = 1$\n7.4e-02\n4.2e-02\n1.0e-02\n1.1e-03\n6.0e-04\n1.0e-04\nAs expected, the results show that as the number of training samples increases, the watermark is learned more strongly. However, even at small numbers of training samples, the watermark is still learned (the p-values are much lower than chance), just to a lesser degree. Overall, we note that watermark learnability and sample efficiency is a continuous spectrum. More samples are helpful but not necessarily always crucial, and sample efficiency varies across watermarking strategies and hyperparameters.\nUsing multiple different keys/messages\nWe run additional experiments in Appendix E to investigate the behavior of sampling-based watermark distillation if the samples are watermarked using multiple different keys/messages. We also vary the number of training samples as before. The table below shows watermark detection p-values.\nNumber of training samples\nModel\n20k\n40k\n80k\n160k\n320k\n640k\nKGW $\\delta = 2$ (one key)\n4.1e-02\n1.4e-02\n2.4e-03\n5.2e-04\n5.1e-05\n3.6e-06\nKGW $\\delta = 2$ (two keys)\n1.7e-01\n1.4e-01\n7.8e-02\n5.7e-02\n2.9e-02\n1.4e-02\nAar $k = 2$ (one key)\n7.4e-02\n9.4e-03\n3.5e-04\n1.0e-06\n5.1e-10\n2.9e-14\nAar $k = 2$ (two keys)\n4.2e-01\n2.3e-01\n1.2e-01\n4.0e-02\n1.0e-02\n1.2e-03\nThe results show that using two different keys hinders watermark learning, as indicated by the larger p-values. However, learning is not completely prevented, as the p-values are still much lower than 0.5 and decrease as the number of training samples increases.\nThis suggests that using multiple watermark keys for generation may be a potential defense against spoofing attacks. However, if multiple watermark keys are used for generation, then all of those keys will need to be tested at detection, so multiple testing correction will need to be performed to obtain accurate, weaker p-values. So, this defense will slightly reduce the statistical power and increase the false negative rate of watermark detection."}, {"Heading": "Reply to Reviewer metd (part 2/2)", "Subheading": "Official CommentbyAuthors21 Nov 2023, 08:28 (modified: 21 Nov 2023, 08:28)EveryoneRevisions", "Content": "Comment:\nDistinguishing between distilled and original watermarked distributions\nYour assumption that the spoofed watermark tends to learn more common watermarked sequences first seems reasonable. If a defender tries to evade the spoofing attack by ignoring the most common watermarked sequences or n-grams, they could reduce the proportion of texts generated by the adversary which are detected as watermarked, but this would also reduce the proportion of texts genuinely generated by original model which are detected as watermarked. This is because the most common watermarked sequences/n-grams contribute more towards the watermark detection score. Rare watermarked sequences are less likely to appear, so it is more likely that a genuinely generated text contains none or few rare sequences, thus resulting in a false negative. So this attempt to evade the spoofing attack will reduce the watermark\u2019s efficacy to detect model-generated texts, which is its primary purpose.\nSpoofing attacks vs defenses\nMore generally, we believe that defenses against spoofing attacks vs. spoofing attacks to overcome these defenses is a security cat and mouse game, with no conclusive winner or answer at this time. Some new defense could later be defeated by a new attack, which is then defeated by a new defense, and so on. Ultimately, potential vulnerability to spoofing attacks is one reason among others suggesting that text watermarking should not be used to conclusively attribute provenance or blame to a specific model. Text watermarking is best suited for its original use case of detecting model-generated text, e.g., for preventing students from cheating on essays or preventing LLM-generated misinformation campaigns."}, {"Heading": "Thank you for your reply.", "Subheading": "Official CommentbyReviewer metd22 Nov 2023, 15:40Everyone", "Content": "Comment:\nThank you for your reply. I will keep my current positive score."}]}, {"Heading": "Official Review of Submission9328 by Reviewer hxrQ", "Subheading": "Official ReviewbyReviewer hxrQ30 Oct 2023, 15:56 (modified: 21 Nov 2023, 17:33)EveryoneRevisions", "Content": "Summary:\nThe paper investigates whether watermarks for language models, which allow for the detecting model-generated text, can be directly learned by another model without applying the same watermarking decoding algorithm, termed weights-based watermarking. This has implications for using watermarks in open-source models and for potential spoofing attacks.\nThe authors propose two methods for learning weights-based watermarks without specialized decoding - logits-based and sampling-based watermark distillation. This transfers watermarks from a teacher model to a student model.\nExperiments are run with three different decoding-based watermarking techniques. The results show that the proposed distillation methods can learn watermarks, but learnability varies across schemes and hyperparameters. Lower distortion watermarks are harder to learn.\nThe authors demonstrate two applications of the findings. For open models, learned watermarks will be removed by further fine-tuning, and they leave the learning weights-based watermarking that is robust to fine-tuning for future work. For spoofing attacks, sampling-based distillation can replicate watermarks. This suggests limitations of using watermarks for provenance.\nIn summary, this paper provides an interesting empirical analysis of the learnability of current decoding-based textual watermarks. It highlights the potential limitations of text watermarks for provenance. Their findings suggest the need for investigation on watermarks that are difficult to learn as a prevention of the discussed spoofing attacks.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nOriginality:\nInvestigates the novel problem of whether language models can learn to generate watermarks themselves. This question has important implications but was previously unexplored.\nQuality:\nProvides extensive empirical results across three watermarking schemes and hyperparameters\u2014thorough, reproducible experiments.\nUses appropriate metrics to assess watermark detection and text quality\u2014rigorous quantitative evaluation.\nClear methodology and training details\u2014enable replicability.\nClarity:\nStructured logically to build understanding incrementally. Smooth flow between sections.\nSignificance:\nFoundational insights into watermark learnability advance knowledge in an important emerging area.\nLearnability findings have direct implications for applications like watermarking open models.\nIdentifies risks around spoofing that impact watermark security. Informs responsible development.\nBenchmark results across schemes and hyperparameters enable future work. Valuable analysis.\nWeaknesses:\nThe experimental methodology could be strengthened by\ncontrolling for model architecture (use the Llama-2 as the student model for both logits-based and sample-based experiments for a more intuitive comparison of the results)). This would better isolate the distillation techniques themselves.\nincreasing the dataset diversity (currently, only one dataset is used).\nsomehow, seq-rep-3 is not evaluated on the sample-based distillation.\nThe technical writing is condensed in some areas, making it harder to follow for non-experts. Expanding explanations around key concepts like the distillation objectives could improve readability.\nThe related work could be expanded to provide a broader context. Watermarking has been studied for other modalities like images, which could give a useful perspective. Meanwhile, model-specific watermark leveraging the learnability of distribution difference has also been discussed in the literature [He, Xuanli, et al. ].\nThe spoofing attack evaluation is limited to a simple harmful/innocuous categorization. More nuanced human evaluations could better characterize risks.\nThe limitations around fine-tuning robustness are acknowledged but not thoroughly investigated. Exploring techniques to improve robustness could be valuable.\nHe, Xuanli, et al. \"Cater: Intellectual property protection on text generation apis via conditional watermarks.\" Advances in Neural Information Processing Systems 35 (2022): 5431-5445.\nQuestions:\nI would like to request an evaluation using Llama-2 for both distillation techniques, rather than different models for each. Doing so would allow for a more direct comparison of the distillation methods themselves, better isolating the impact of the techniques. This could strengthen the technical contributions by providing improved analysis of the relative efficacy of logits-based vs sampling-based distillation.\nAdditionally, conducting more in-depth studies on spoofing attacks across diverse topics and datasets could further increase the impact of the work's findings. Expanding the spoofing experiments to include varied contexts beyond the current proof of concept could substantiate the risks posed. Rigorously demonstrating successful spoofing in different settings would validate concerns around watermark security and attribution. This expanded analysis could strengthen the evaluative assessment by demonstrating comprehensive consideration of the practical implications.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reply to Reviewer hxrQ (part 1/2)", "Subheading": "Official CommentbyAuthors21 Nov 2023, 08:33Everyone", "Content": "Comment:\nWe thank you for the useful and insightful feedback and for taking the time to review our paper. We are glad that you found our findings valuable and significant, and our experiments thorough and rigorous. We address questions and concerns below.\nLlama-2 sampling-based watermark distillation evaluation\nAs requested, we have included an evaluation of sampling-based watermark distillation using Llama 2 7B as both the teacher and student model. We use the same evaluation procedure as before. Results are shown below, and also have been added to the paper. The trends are broadly similar to the original logits-based and sampling-based distillation experiments.\nModel\nDec p-value\nWD-S p-value\nDec AUROC\nWD-S AUROC\nDec LM-score\nWD-S LM-score\nDec seq-rep-3\nWD-S seq-rep-3\nDec MAUVE\nWD-S MAUVE\nKGW $\\delta=2$\n4.4e-18\n8.5e-07\n1.000\n0.996\n16.4\n19.7\n0.04\n0.04\n0.89\n0.85\nKGW $\\delta=1$\n1.0e-05\n2.0e-02\n0.992\n0.869\n12.5\n15.4\n0.03\n0.03\n0.91\n0.89\nAar $k=2$\n1.3e-75\n5.1e-17\n0.999\n0.984\n6.5\n7.6\n0.34\n0.34\n0.28\n0.29\nAar $k=3$\n4.8e-73\n8.5e-03\n1.000\n0.873\n9.5\n10.5\n0.14\n0.17\n0.74\n0.66\nAar $k=4$\n4.0e-72\n2.6e-01\n0.999\n0.651\n10.7\n11.9\n0.09\n0.10\n0.86\n0.83\nKTH $s=1$\n1.0e-04 (596)\n1.0e-04 (560)\n0.994\n0.998\n10.5\n15.3\n0.03\n0.03\n0.88\n0.86\nKTH $s=2$\n1.0e-04 (600)\n1.0e-04 (526)\n0.998\n0.994\n10.7\n13.5\n0.03\n0.04\n0.91\n0.87\nKTH $s=4$\n1.0e-04 (593)\n1.0e-04 (485)\n0.995\n0.984\n10.5\n12.6\n0.03\n0.04\n0.91\n0.87\nKTH $s=256$\n1.0e-04 (600)\n1.0e-04 (455)\n0.996\n0.968\n10.61\n11.3\n0.03\n0.04\n0.92\n0.90\nBase student\n5.0e-01\n0.500\n11.7\n0.03\n0.92\nHowever, we note that logits-based and sampling-based distillation have key differences, which means that they should not be compared solely based on efficacy to determine which method is better. Logits-based distillation requires white-box access to the teacher model and that the teacher and student models share the same tokenizer and vocabulary. It is also convenient if the teacher and student models share the same model architecture. On the other hand, sampling-based distillation only requires black-box access to samples from the teacher model, and the teacher and student models can have different tokenizers and vocabularies. Also, sampling-based distillation requires autoregressive sampling from the teacher model, which is slow, whereas logits-based distillation does not require sampling and is faster overall. So, logits-based and sampling-based distillation are each suitable and applicable for different settings, so neither is strictly better than the other across all scenarios.\nIncreasing dataset diversity\nWe have included additional evaluations of logits-based and sampling-based watermark distillation (including both Llama 2 7B and Pythia 1.4B as student model) on two additional datasets, Wikipedia articles and arXiv papers. We observe similar trends to the original main evaluation on the C4 RealNewsLike dataset. The full results are in Appendix F.\nSeq-rep-3 on sampling-based distillation\nApologies for the confusion, we originally omitted seq-rep-3 on sampling-based distillation in order to respect margin constraints, but we have now re-included it in Appendix B, as shown below.\nModel\nDecT seq-rep-3\nDecS seq-rep-3\nWD-S seq-rep-3\nKGW $\\delta=2$\n0.04\n0.04\n0.02\nKGW $\\delta=1$\n0.03\n0.03\n0.02\nAar $k=2$\n0.34\n0.53\n0.23\nAar $k=3$\n0.14\n0.27\n0.10\nAar $k=4$\n0.09\n0.12\n0.05\nKTH $s=1$\n0.03\n0.03\n0.02\nKTH $s=2$\n0.03\n0.03\n0.02\nKTH $s=4$\n0.03\n0.03\n0.02\nKTH $s=256$\n0.03\n0.03\n0.02\nBase student\n0.03\nExpanding explanations around distillation objectives\nWe have expanded the explanations around the watermark distillation objectives to improve readability."}, {"Heading": "Reply to Reviewer hxrQ (part 2/2)", "Subheading": "Official CommentbyAuthors21 Nov 2023, 08:39Everyone", "Content": "Comment:\nRelated work relationship to model watermarking\nWe have expanded the related work section to include a discussion of model watermarking methods for protection against model extraction attacks [1, 2, 3, 4]. Note that text watermarking, which we study, is crucially different from model watermarking/protection in both setting and method. Model watermarking is meant to protect language model APIs from model stealing/extraction attacks, where an adversary trains a model on outputs from the victim model API. The model watermark enables detecting if a suspect model was extracted from the victim model. Detection is done by querying the suspect model multiple times on specially chosen inputs. The model watermark is specifically designed to be learnable, so that the adversary model learns the watermark during the model extraction attack. On the other hand, text watermarking enables detecting if a given text was model-generated. Detection does not need access to any language model, only the tokenizer, and detection is meant to be performed on any generated text, regardless of the input prompt. Existing decoding-based text watermarking methods are specifically designed to be subtle and imperceptible in order to have minimal impact on text quality, and it was previously unknown whether they are learnable or not.\nHe et al., \"Protecting Intellectual Property of Language Generation APIs with Lexical Watermark,\" AAAI 2022.\nZhao et al., \"Distillation-Resistant Watermarking for Model Protection in NLP,\" EMNLP 2022.\nHe et al., \"CATER: Intellectual Property Protection on Text Generation APIs via Conditional Watermarks,\" NeurIPS 2022.\nZhao et al., \"Protecting Language Generation Models via Invisible Watermarking,\" ICML 2023.\nRobustness to fine-tuning\nWe agree that improving robustness of weights-based watermarking to fine-tuning is an important challenge towards developing watermarking for open models. However, we believe that methods to improve robustness to fine-tuning are not as directly related to our main focus of investigating watermark learnability and would best be explored in future work.\nMore in-depth spoofing experiments\nWe agree that more in-depth studies and evaluations of watermark spoofing attacks across different settings would be valuable for more comprehensively evaluating the practical implications and risks of spoofing attacks. However, we believe that our findings are still valuable and lay a foundation for future work in this direction. We demonstrate that sampling-based distillation is able to learn to generate watermarked text from black-box watermarked samples, which is the setting for spoofing attacks. We also include experiments on sample efficiency (Appendix D) and different generation datasets (Appendix F). These findings suggest the possibility of spoofing attacks, and we show a simple proof-of-concept spoofing attack to substantiate their possibility. We hope that our work will inform future research and responsible usage of watermark detection."}, {"Heading": "Score Changed", "Subheading": "Official CommentbyReviewer hxrQ21 Nov 2023, 17:32Everyone", "Content": "Comment:\nThank you for the detailed response and additional results. My concerns are partially resolved. The findings are interesting, though not quite comprehensive or novel enough in my view to warrant an outstanding score. I am raising my score to a 6 to reflect the contribution made."}]}, {"Heading": "Official Review of Submission9328 by Reviewer GhKC", "Subheading": "Official ReviewbyReviewer GhKC28 Oct 2023, 00:45 (modified: 01 Dec 2023, 11:30)EveryoneRevisions", "Content": "Summary:\nThis paper investigates the learnability of watermarks for language models. The authors use watermark distillation, a method that trains a student model to behave like a teacher model that uses decoding-based watermarking. They test their approach on three decoding-based watermarking strategies and find that models can learn to generate watermarked text with high detectability. However, they also find limitations to learnability, such as the loss of watermarking capabilities under fine-tuning on normal text and high sample complexity when learning low-distortion watermarks.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThis paper finds an approach for learning watermarks in language models through knowledge distillation.\nThe paper presents empirical findings on the learnability of watermarks, including the success of the proposed distillation method on three distinct decoding-based watermarking strategies. The results show that models can learn to generate watermarked text with high detectability.\nThe paper discusses the limitations of learnability, including the loss of watermarking capabilities under fine-tuning and the high sample complexity for learning low-distortion watermarks. These limitations provide valuable insights and highlight the challenges in implementing watermarking in language models.\nWeaknesses:\nThe method presented is neither novel nor new. Knowledge distillation is a well-established concept, and this paper simply tests existing watermarking methods in conjunction with it. The paper appears more evaluative in nature.\nThere's a body of prior works focused on watermark distillation. These works show that if the student model distills the watermarked teacher model, it offers protection against model extraction attacks. Although the context may differ, it is better for the author to acknowledge this in the related works section. Key references include:\nHe et al., \"Protecting Intellectual Property of Language Generation APIs with Lexical Watermark,\" AAAI 2022.\nZhao et al., \"Distillation-Resistant Watermarking for Model Protection in NLP,\" EMNLP 2022.\nHe et al., \"CATER: Intellectual Property Protection on Text Generation APIs via Conditional Watermarks,\" NeurIPS 2022.\nZhao et al., \"Protecting Language Generation Models via Invisible Watermarking,\" ICML 2023.\nAlthough the p-value is utilized for watermark detection, I also recommend that the author present quantitative metrics such as AUC, FPR, etc., for a more comprehensive understanding of watermark detection.\nQuestions:\nNone\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reply to Reviewer GhKC", "Subheading": "Official CommentbyAuthors21 Nov 2023, 08:41 (modified: 23 Nov 2023, 03:47)EveryoneRevisions", "Content": "Comment:\nWe thank you for the useful and insightful feedback and for taking the time to review our paper. We address questions and concerns below.\nContribution\nPlease see our general comment clarifying our contribution.\nhttps://openreview.net/forum?id=9k0krNzvlV&noteId=UyaqBwxSNh\nOur main contribution is our empirical investigation and findings on watermark learnability. It is true that knowledge distillation is a well-established concept, but our method is not our primary contribution. Our findings and evaluations are novel and new, as the learnability of decoding-based text watermarking was previously unexplored, and it was unknown whether existing decoding-based watermarks are learnable or not.\nRelationship to model watermarking for protection against model extraction attacks\nWe have updated the related work section to include a discussion of the relationship of these provided works with ours.\nThese works concern model watermarking for protection against model extraction attacks. Model watermarking for model protection is crucially different from text watermarking, which we study. Model watermarking is meant to protect language model APIs from model stealing/extraction attacks, where an adversary trains a model on outputs from the victim model API. The model watermark enables detecting if a suspect model was extracted from the victim model. Detection is done by querying the suspect model multiple times on specially chosen inputs. The model watermark is specifically designed to be learnable, so that the adversary model learns the watermark during the model extraction attack. On the other hand, text watermarking enables detecting if a given text was model-generated. Detection does not need access to any language model, only the tokenizer, and detection is meant to be performed on any generated text, regardless of the input prompt. Existing decoding-based text watermarking methods are specifically designed to be subtle and imperceptible in order to have minimal impact on text quality, and it was previously unknown whether they are learnable or not.\nIn short, the object being detected is different (model itself versus generated text), and model watermarking for model protection is specifically designed to be learnable, whereas the learnability of existing text watermarks was previously unexplored and unknown. Because of these crucial differences, these prior works into model watermarking for protection against model extraction attacks do not diminish the value and significance of our findings.\nAUROC and FPR\nAs requested, we have included the AUROC metric for classifying watermarked and non-watermarked text for a more comprehensive understanding of watermark detection, as shown below for the main logits-based watermark distillation (WD-L) and sampling-based watermark distillation (WD-S) experiments. Dec indicates decoding-based watermarking. Additional full tables can be found in the paper.\nModel\nDec AUROC\nWD-L AUROC\nWD-S AUROC\nKGW $\\delta=2$\n1.000\n0.997\n0.995\nKGW $\\delta=1$\n0.992\n0.913\n0.874\nAar $k=2$\n0.999\n0.996\n0.993\nAar $k=3$\n1.000\n0.773\n0.866\nAar $k=4$\n0.999\n0.580\n0.631\nKTH $s=1$\n0.994\n0.998\n0.989\nKTH $s=2$\n0.998\n0.994\n0.972\nKTH $s=4$\n0.995\n0.969\n0.955\nKTH $s=256$\n0.996\n0.893\n0.955\nBecause watermark detection returns p-values, the false positive rate is equal to the significance level that is chosen as the threshold for classifying a text as model-generated or not. So we do not report FPR because it is set by the detection user depending on the FPR they are willing to tolerate."}, {"Heading": "End of discussion period", "Subheading": "Official CommentbyAuthors22 Nov 2023, 18:09Everyone", "Content": "Comment:\nDear Reviewer GhKC,\nWe appreciate all of the valuable time and effort you have spent reviewing our paper. As today is the last day of the discussion period, we gently request that you review our reply and consider updating your evaluation accordingly. We believe that we have addressed all questions and concerns raised, but please feel free to ask any clarifying questions you might have before the end of the discussion period.\nBest,\nAuthors"}]}]}, "n1LiKueC4F": {"paper_info": {"Primary Area": "generative models", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Retrieval Augmented Generation, Bayesian Metric Learning", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Our paper presents a Bayesian adaptation of Retrieval Augmented Generation (RAG) designed to capture the characteristics of each user, encompassing factors such as their educational background and professions. We model each individual's characteristics using specific perturbations of the local metric of the embedding space. This perturbation introduces a crucial shift in the distance evaluation between the query's and the document's embedding, leading to different pertinent rankings of the retrieved documents. We propose a Bayesian learning procedure that assimilates user feedback and continuously enhances our estimation of the user-specific  metric. In the beginning, when there is no information about the user, we use a diverse retrieval method for generation. After this burn-in phase, we learn a Bayesian posterior estimate of the metric, and inject this metric into the nearest neighbor search for document retrieval. This additional layer of metric information acquisition leads to empirical improvement in the retrieval quality and in the performance of the generated text on multiple concept explanation tasks.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9327", "PDF Url": "https://openreview.net/pdf?id=n1LiKueC4F"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9327 by Area Chair 4oFx", "Subheading": "Meta ReviewbyArea Chair 4oFx06 Dec 2023, 09:14 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\na)  The paper proposes an approach for learning a personalized ranking model followed by generation of personalized summaries using an off the shelf summarization model. The paper proposes a probabilistic model for learning user preferences where user preferences are modeled as a perturbed Mahalanobis metric.   The model is a hybrid of Bayesian Learning and Retrieval Augmented Generation (RAG).  Experiments.  They use determinantal point process for diversity and a Wishart for user preferences\nb)  interesting combinations of probabilistic theories, well written\nc)  poor selection of datasets left reviewers wondering, poor baselines, paper needs better empirical work.\nJustification For Why Not Higher Score:\nconsensus on reject\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9327 by Reviewer zTRj", "Subheading": "Official ReviewbyReviewer zTRj05 Nov 2023, 16:56 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper presents a new method for information retrieval by combining recently developed retrieval models with large language models (LLMs). Their proposed approach is a two-task iterative technique which is particularly consisted of a task where LLMs are utilised to refine information about relevant to user's query documents are refined and of a task where retrieval models are employed to refine information in LLMs  and thus a refined query of the user's original query can be constructed. The method that the authors propose iteratively applies these tasks in a procedure consisted of 4 steps clearly listed in Section 4.3 of the paper. Finally, the authors utilise several publicly available datasets to compare their approach with existing methods in the related literature.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n3 good\nStrengths:\nI think that the paper is of good quality, well-written and is original enough in the sense of combining efficiently existing well-established approaches to construct a new method that outperforms the existing ones.\nWeaknesses:\nIt is very nice that the authors explain clearly the limitations of their approach at the end of Section 6. I think however, that they should provide some recommendations on the LLMs that should be used to avoid some of the problems they mention.\nQuestions:\nSince the authors recognise the limitation of their approach they should be more specific about the characteristics of the LLMs that should be integrated with their approach in order to end up with a technique with the metrics presented in Section 5.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Misalignment of review and manuscript", "Subheading": "Official CommentbyReviewer zTRj22 Nov 2023, 03:12Everyone", "Content": "Comment:\nAccidentally the review appearing here is not for this paper but for an other paper assigned to me. The review fro this paper \"Personalized Language Generation via Bayesian Metric Augmented Retrieval\" is also linked to an other paper."}, {"Heading": "Thank you!", "Subheading": "Official CommentbyAuthors22 Nov 2023, 05:09Everyone", "Content": "Comment:\nWe appreciate your time and effort in reviewing for ICLR2024!"}]}, {"Heading": "Official Review of Submission9327 by Reviewer u3r5", "Subheading": "Official ReviewbyReviewer u3r503 Nov 2023, 02:59 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces a Bayesian approach to modeling user preferences for document retrieval to be used in RAG, outperforming a few baselines on a generated dataset.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe paper tackles a timely and interesting problem of user preferences in RAG. The bayesian approach is reasonable and thoroughly described. The multi-phase setup is logical. The paper is generally well-written.\nWeaknesses:\nI have two main issues with the manuscript: The overly complex modeling procedure and the synthetic dataset.\nWhile I am a fan of Bayesian approaches, there is no appropriate ablation to validate the inherent complexity. Why not just fit a simple linear model to the user preferences? \nMany of the design choices in the proposed model are not justified. Why are we modeling the user preference as a a Wishart probability distribution? Why do we need a determinantal point process? How would that compare to random sampling? Et cetera.\nThe other issue is the dataset: it's entirely synthetic. There is no evidence that the proposed model would be useful at reflecting real users preferences. If the evaluation had fake data and real users, that would be interesting and such a user study would be illuminating to the proposed work. If the evaluation had real data and fake users (as imagined by an LLM), that might be okay too as LLMs have shown signs that they can model generic user behavior. Ideally the proposed model would be used on real data with user. And as I have yet to see the combined use of synthetic data and synthetic users in a promising fashion that represents real users/data, I cannot recommend accept.\nQuestions:\nWhat happens when you fit a simple linear model to users original preferences and update in an online fashion?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer u3r5 [1/2]", "Subheading": "Official CommentbyAuthors22 Nov 2023, 07:07 (modified: 22 Nov 2023, 09:58)EveryoneRevisions", "Content": "Comment:\nDear reviewer,\nWe appreciate that you review our paper and provide insightful comments. We would like to address your concerns as follows:\nWhat happens when you fit a simple linear model to users original preferences and update in an online fashion?\nAs mentioned in Section 6.2, we only ask users to rate a total of 18 shortened documents (N_c = 3, C1 = 3, C2 = 3). This number of samples is much too low for fitting a simple logistic regression binary classifier (with two classes,\nlike\nor\ndislike\n) and will lead to overfitting. We, anyways, have implemented the baseline that you proposed, in which we learn a logistic regression model to predict whether the user likes or dislikes each document. We conduct the comparison on the Politics, Law and Technology dataset. The table below presents the performance between two models.\nWe can clearly observe that our proposed method dominates the simple logistic regression baseline.\nDataset\nMethods\nHR@3\nPrecision@3\nRouge1\nRouge2\nPolitics\nLogistic Regression\n0.59\n0.3036\n0.3472\n0.0975\nOurs\n0.6849\n0.3751\n0.3701\n0.1109\nLaw\nLogistic Regression\n0.4809\n0.2521\n0.3640\n0.0933\nOurs\n0.6176\n0.3199\n0.3868\n0.1210\nTechnology\nLogistic Regression\n0.5485\n0.2704\n0.3455\n0.0950\nOurs\n0.6803\n0.3715\n0.3654\n0.1130\nWhy are we modeling the user preference as a Wishart probability distribution?\nBecause a popular approach for document retrieval is the nearest neighbor approach. The standard, off-the-shelf implementation uses an Euclidean distance. Thus, a reasonable approach to cater the user preference in the retrieval procedure is to alternate the distance. We thus need to parametrize the distance so that we can perform the learning process. Mahalanobis distance is the most natural way to generalize the Euclidean distance, and a Mahalanobis distance is parametrized by a positive semidefinite matrix (this is the matrix $A$ in our paper). To invoke a Bayesian method, we need to impose a prior and a posterior on the parameter space, and the parameter space in our case is the set of all a positive semidefinite matrices. And the Wishart distribution is, again, the most natural distribution supported on the positive semidefinite matrix space. We hope that this line of argument clarifies your concern.\nWhy do we need a determinantal point process? How would that compare to random sampling?\nDetrimental Point Process is needed because when a user arrives, there is no user preference information that we can use to personalize the retrieval process. This is the cold-start setting, and diversifying the retrieval via DPP is a well-known and powerful technique in this cold-start situation. Many papers have demonstrated that DPP delivers better performance than random sampling, including:\n[1] Wang et al. (2020) Personalized Re-ranking for Improving Diversity in Live Recommender Systems, arXiv:2004.06390\n[2] Liu et al. (2022) Determinantal Point Process Likelihoods for Sequential Recommendation, arXiv:2204.11562\n[3] Wilhelm et al. (2018) Practical Diversified Recommendations on YouTube with Determinantal Point Processes.\nWhen we design our framework, we have already optimized the choice of the component. That is why we use a determinantal point process. We will add this argument to the revision."}, {"Heading": "Response to Reviewer u3r5 [2/2]", "Subheading": "Official CommentbyAuthors22 Nov 2023, 07:08 (modified: 22 Nov 2023, 07:08)EveryoneRevisions", "Content": "Comment:\nThe other issue is the dataset: it's entirely synthetic. There is no evidence that the proposed model would be useful at reflecting real users preferences.\nWe do not fully understand the concern here.\nOur ultimate goal is to generate high-quality text (meaning that the generated text can be aligned better with the user\u2019s preference). We do not have to reflect 100 percent correctly the user\u2019s preferences in order to generate high-quality text. Our model is a\nmodel\n, it is an abstraction of the real world, it may be wrong, but it is useful.\nThere are a plethora of examples that follow the same argument, let us describe a few:\nDiscrete choice: The field of discrete choice builds abstract models that can help to predict the user\u2019s choice behaviors (whether the person buys a certain product or not). For sure, it is\nim\npossible to reflect accurately the users preferences, nevertheless, discrete choice models can have reasonably good performance in predicting the user\u2019s buy/not buy decision. Discrete choice models are also used a lot in marketing to personalized advertisement. Unfortunately, discrete choice model also require a large number of samples and/or contextual information to perform well, and does not fit into our setting.\nPortfolio allocation: It is also impossible to learn the risk appetite of the investors. Nevertheless, it does not stop us from building proxies (different utilities functions), that can help us optimize the portfolio allocation.\nRegarding the synthetic data concern: there are a growing literature on using GPT to generate datasets, for both training and testing. We list a few here:\nToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection\n(Hartvigsen et al., ACL 2022)\nA Synthetic Data Generation Framework for Grounded Dialogues\n(Bao et al., ACL 2023)\nSelf-Instruct: Aligning Language Models with Self-Generated Instructions\n(Wang et al., ACL 2023)\nIs GPT-3 Text Indistinguishable from Human Text? Scarecrow: A Framework for Scrutinizing Machine Text\n(Dou et al., ACL 2022)"}, {"Heading": "I will keep my score", "Subheading": "Official CommentbyReviewer u3r522 Nov 2023, 23:59Everyone", "Content": "Comment:\nThanks authors for the extra experiments. It is nice to see an improvement over a simple baseline.\nHowever, after seeing the other discussion I am inclined to keep my score. The synthetic dataset is a complete show stopper for me. While synthetic datasets are clearly useful in the NLP community, the combination of a brand new proposed method on a brand new synthetic dataset does not indicate to me generalality of either. I encourage the authors to evaluate both with real humans for a future version of the paper."}]}, {"Heading": "Official Review of Submission9327 by Reviewer Qd94", "Subheading": "Official ReviewbyReviewer Qd9401 Nov 2023, 18:01 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes an approach for learning a personalized ranking model followed by generation of personalized summaries using an off the shelf summarization model. The paper proposes a probabilistic model for learning user preferences where user preferences are modeled as a perturbed Mahalanobis metric. The paper proposes a 2 stage method for learning user preferences: in Phase 1 a detreminantal point process is used to retrieve diverse documents and gather user preferences for the documents given queries, in Phase 2 gathered feedback is used to make an update to the user preferences. In Phase 3 the learned user preferences are used for ranking documents for the query and generating summarizations of the ranked documents. The proposed approach is evaluated on 3 synthetic datasets generated with gpt-3.5-turbo with 50 concepts (queries), 100 user types (users), resulting in retrieval over 5000 documents.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper proposes an interesting Bayesian framework for learning personalized ranking models.\nThe experimental evaluations seem to indicate the value of the proposed framework.\nThe paper is largely well-written.\nWeaknesses:\nSimplistic synthetic data: The only data used for experiments are synthetic with the conceived form of user preference being somewhat simplistic (different user types seeking stylistically different concept definitions).\nWeak baselines: The baselines compared against are non-personalized and don't use user type information, one would expect to see poorer performance from such methods given the setup of the paper.\nUnclear experimental setup.\nThe paper is ungrounded from prior work making it hard to see what aspects of the contribution are novel.\nQuestions:\nAm I understanding correctly that the 5000 large document collection contains the 50 concept definitions rephrased in 100 different ways?\nAm I understanding correctly that the proposed approach never uses the pre-trained summarization model in learning user preferences?\nIs the user feedback for Phase 2 obtained from labelled data? Eg if the document corresponds to the correct concept+user it is a positive document and negative if not?\nPlease clarify in greater detail what data is used for training and evaluation. \"For each user type, we systematically exclude all documents associated with that user type from the database, treating them as reference documents\" -- its not clear what this means? Is this implying that no documents corresponding to the user type are available for training?\nSec 6.1: What reference documents are used for summarization evaluation? Eg in computing metrics like rouge.\nThe paper could benefit from inclusion of examples for concept, user type, positive document and negative document for concept and user type - perhaps in Fig 1.\nIf the experimental setup contains as input a query + positive document for user type - It would be illustrative to have a simple personalized ranking baseline which computes a score based on a simple linear interpolation concept-document score and a concept-user_type score. Perhaps a user_type could be represented with the average of document embeddings for that user and the weight for the two components tuned on a dev set. Alternatively, please consider formulating an appropriate, simpler personalized ranking baseline and comparing to it in addition to the ones in the paper.\nThe paper contains no context on related work from personalized search, it would be useful to make some connection to related prior work. Starting points may be:\nhttps://dl.acm.org/doi/10.1145/1076034.1076111\n,\nhttps://dl.acm.org/doi/10.1145/3357384.3357980\n,\nhttps://dl.acm.org/doi/10.1145/2124295.2124348\n. Also consider discussing differences to the task/approach of:\nhttps://arxiv.org/abs/2211.09260\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer Qd94", "Subheading": "Official CommentbyAuthors22 Nov 2023, 09:51 (modified: 22 Nov 2023, 09:58)EveryoneRevisions", "Content": "Comment:\nDear reviewer,\nWe appreciate that you review our paper and provide insightful comments. We would like to address your concerns as follows:\nAm I understanding correctly that the 5000 large document collection contains the 50 concept definitions rephrased in 100 different ways?\nYes, it is correct. As mentioned in Section 6.1, we synthesize 3 datasets (Political, Legal and Technology) with that setup.\nAm I understanding correctly that the proposed approach never uses the pre-trained summarization model in learning user preferences?\nYes, it is correct. However, we did use a pretrained summarization model to shorten documents for practical purposes.\nIs the user feedback for Phase 2 obtained from labelled data? Eg if the document corresponds to the correct concept+user it is a positive document and negative if not?\nA user likes a document if that document lies in the top 5 documents that are closest to the user\u2019s true document in terms of Euclidean distance; A user dislikes a document otherwise.\nPlease clarify in greater detail what data is used for training and evaluation. \"For each user type, we systematically exclude all documents associated with that user type from the database, treating them as reference documents\" -- its not clear what this means? Is this implying that no documents corresponding to the user type are available for training?\nYes, the document corresponding to the user type will not be used for training but only used as a reference document to compute the top-5 documents that will be liked by the user.\nSec 6.1: What reference documents are used for summarization evaluation? Eg in computing metrics like rouge.\nThe document corresponding to the user type will be used as a reference document to compute rouge scores for the generated answer.\nIf the experimental setup contains as input a query + positive document for user type - It would be illustrative to have a simple personalized ranking baseline that computes a score based on a simple linear interpolation concept-document score and a concept-user_type score. Perhaps a user_type could be represented with the average of document embeddings for that user and the weight for the two components tuned on a dev set. Alternatively, please consider formulating an appropriate, simpler personalized ranking baseline and comparing to it in addition to the ones in the paper.\nWe consider fitting user preference feedback to a simple logistic regression binary classifier. Please refer to the table below for results on all three datasets.\nDataset\nMethods\nHR@3\nPrecision@3\nRouge1\nRouge2\nPolitics\nLogistic Regression\n0.59\n0.3036\n0.3472\n0.0975\nOurs\n0.6849\n0.3751\n0.3701\n0.1109\nLaw\nLogistic Regression\n0.4809\n0.2521\n0.3640\n0.0933\nOurs\n0.6176\n0.3199\n0.3868\n0.1210\nTechnology\nLogistic Regression\n0.5485\n0.2704\n0.3455\n0.0950\nOurs\n0.6803\n0.3715\n0.3654\n0.1130\nAlso consider discussing differences to the task/approach of:\nhttps://arxiv.org/abs/2211.09260\nThe work in Task-aware Retrieval with Instructions by Asai et al. (2022) adapts its search results using an additional search task instruction $t$ in natural language, along with the user's query $q$ (see Section 3, 'Task Formulation'). Our work differs from that of Asai et al. (2022) in that we rely on the users' ratings (like/dislike) on a selection of summarized documents, instead of using the task instruction $t$."}, {"Heading": "Thank you for the clarifications.", "Subheading": "Official CommentbyReviewer Qd9422 Nov 2023, 22:07Everyone", "Content": "Comment:\nThank you for the clarifications. I continue to echo the concerns of reviewer u3r5 -- the synthetic data setup of the paper is a non-trivial weakness of the paper."}, {"Heading": "Response to Reviewer Qd94", "Subheading": "Official CommentbyAuthors22 Nov 2023, 22:47Everyone", "Content": "Comment:\nThank you for your feedback on our response. Regarding your concerns about the synthetic setup of our approach, we wish to underscore that our paper's primary objective is to generate text aligning with the preferences of users. Our experimental approach is supported by multiple studies indicating the similarity between text generated by ChatGPT and human-generated text:\nIs GPT-3 Text Indistinguishable from Human Text? Scarecrow: A Framework for Scrutinizing Machine Text (Dou et al., ACL 2022)\nAll That\u2019s \u2018Human\u2019 Is Not Gold: Evaluating Human Evaluation of Generated Text (Clark et al., ACL-IJCNLP 2021)\nConsequently, simulating human-like responses using ChatGPT in our experiments is a reasonable approach."}]}, {"Heading": "Official Review of Submission9327 by Reviewer NT9n", "Subheading": "Official ReviewbyReviewer NT9n28 Oct 2023, 22:34 (modified: 22 Nov 2023, 19:36)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a hybrid of Bayesian Learning and Retrieval Augmented Generation (RAG) framework to capture the characteristics of each user using specific perturbations of the local metric of the embedding space.\nAuthors aim to construct a comprehensive three-phase solution package for RAG-based conversational systems. \nIts primary aim is to enable the retrieval of documents that closely align with human preferences, \nultimately enhancing the quality of text generation.\nThey demonstrate that their approach captures the user\u2019s preference, and consequentially improve the retrieval and text generation quality under a llimited number of queries.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nBayesian Learning and Retrieval Augmented Generation (RAG) framework is simple and reasonable\nProposed solution system is simple and reasonable for adapting the retrieval mechanism to the the user\u2019s preferences.\nTo capture the user\u2019s preference, encompass factors such as their educational background and professions,and consequentially improve the retrieval and text generation quality, authors model these preference through the metric drift of the embedding space, which governs the ranking of the documents for each input query.\nLearning a Bayesian posterior estimate of the metric as the addtional layer is designed to empirical improvement in the retrieval quality and in the performance of the generated text on multiple concept explanation tasks.\nWeaknesses:\nThe authors have considered and designed their system well, but their effectiveness, advantages and claims are weak.\nWhile authors aim to capture the characteristics of each user,  they show that experimental results are search and textual quantitative evaluations, which do not lead to determine the level of achievement for this objective.\nThe performance increase in Table 1 and 2 appears marginal and weak to support the claim.\nSince there is no ablation analysis, it is not possible to determine the effectiveness of the authors' proposed elements such as perturbed Mahalanobis metric, and Bayesian posterior estimate.\nThis solution is a kind of RAG frameworks, but there is no comparison with other RAG based framework, so its superiority cannot be determined.\nQuestions:\nDid you not conduct a qualitative evaluation?\nDid you perform statistical tests on Table 1 and 2? If soIf so, please provide details.\nPlease see Weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNo\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer NT9n", "Subheading": "Official CommentbyAuthors22 Nov 2023, 09:56 (modified: 22 Nov 2023, 09:58)EveryoneRevisions", "Content": "Comment:\nDear reviewer,\nWe appreciate that you review our paper and provide insightful comments. We would like to address your concerns as follows:\nDid you perform statistical tests on Table 1 and 2? If so, please provide details.\nWe propose to look at the paired difference of the performance metrics: for each subject, we compute our method's HR@3, Rouge1 and the competing method\u2019s HR@3, Rouge1. We propose to test the hypotheses:\nNull hypothesis: Ours HR@3 and Rouge1 score equal competing method\u2019s HR@3 and Rouge1\nAlternative hypothesis: Ours HR@3 and Rouge1 are greater than competing method\u2019s HR@3 and Rouge1.\nIn order to test the above hypothesis, we use a one-sided Wilcoxon signed-rank test to compare the paired performance metric values. The p-value of the test between our method and the baselines is reported in the following table.\nSuppose we choose the significant level at 0.05. The table indicates that our method significantly outperforms baselines across all datasets.\nDatasets\nPolitics\nLaw\nTechnology\nHR@3\nOurs - Euclidean\n1e-15\n8e-16\n8e-14\nOurs - BM25\n2e-18\n2e-17\n2e-18\nOurs - MIPS\n7e-18\n2e-17\n2e-16\nOurs - Logistic Regression\n7e-16\n5e-17\n4e-16\nRouge1\nOurs - Euclidean\n1e-12\n1e-14\n5e-15\nOurs - BM25\n1e-18\n6e-17\n2e-18\nOurs - MIPS\n3e-10\n4e-16\n1e-14\nOurs - Logistic Regression\n4e-17\n7e-18\n3e-17"}, {"Heading": "Reply to authors", "Subheading": "Official CommentbyReviewer NT9n22 Nov 2023, 19:47Everyone", "Content": "Comment:\nDear,\nThank you for your response.\nWhile this table shows statistical differences, \nbut please clarify more if there are qualitative differences or error analysis."}, {"Heading": "Response to Reviewer NT9n", "Subheading": "Official CommentbyAuthors22 Nov 2023, 22:02 (modified: 22 Nov 2023, 22:25)EveryoneRevisions", "Content": "Comment:\nDear Reviewer, thank you for your feedback on our submission. Regarding the missing qualitative evaluation, we would like to provide an illustrative example from the\nLaw dataset\n. Consider the query 'Explain Criminal Law to me', posed by a user whose profession is a\nDentist\n. Our system knows nothing of this user but a few of his liked or disliked documents (a total of 18 documents in our experiment). Our system uniquely produces documents with analogies pertinent to medical or health-related fields, such as\npatients\nor\ntreatment or therapy\n. This illustrates how our method tailors content to user-specific contexts, even with limited information about the user.\nOur method\n:\nCriminal law refers to the body of laws that define and regulate behaviors that are considered to be crimes. You may encounter the concept of criminal law in your practice when dealing with **patients** who have engaged in illegal activities. Your expertise can be crucial in providing insights into their mental capacity, potential mitigating factors, or the need for **treatment or therapy**.\nEuclidean\n:\nCriminal law is a branch of law that deals with offenses committed against society as a whole, rather than individual disputes. This is similar to how physics principles, like the laws of motion, help maintain order and predict the movement of objects in the universe.\nBM25\n:\nCriminal Law is like a set of guidelines that defines what actions are considered against the law and can result in punishment. Just like there are certain rules and principles you follow while creating your beautiful artwork, there are rules in society that everyone must abide by. You may find Criminal Law relevant to your work in developing AI systems that interact with society.\nMIPS\n:\nCriminal law is a branch of law that deals with offenses committed against society as a whole, rather than individual disputes. By incorporating the principles of criminal law into your storytelling, you can create suspenseful plots, explore moral dilemmas, and delve into the psychological motivations behind criminal behavior."}, {"Heading": "Reply to authors", "Subheading": "Official CommentbyReviewer NT9n22 Nov 2023, 22:23Everyone", "Content": "Comment:\nThank you for showing example.\nThe example of the LAW dataset is interesting, \nbut since only a limited number of readers are capable of making this qualitative judgment, \na more general example would be better."}, {"Heading": "Response to Reviewer NT9n", "Subheading": "Official CommentbyAuthors22 Nov 2023, 23:20 (modified: 22 Nov 2023, 23:22)EveryoneRevisions", "Content": "Comment:\nDear reviewer NT9n,\nHere we show another example in the\nPolitics Dataset\n, whose user identity and concept are more widely known. In this example, we observe that only our method generates content that is aligned with the common objective of an\nonline content creator\n, which is to\nbuild trust and loyalty\nor\nappeal to your target audience\nTrue user identity\n: Online Content Creator\nQuery\n: \"Explain women's reproductive rights\"\nOur method\n:\nWomen's reproductive rights include access to contraception, family planning, and maternity care. They also include the freedom to make choices about when to have children and how many. Some places have restrictions on access to reproductive healthcare, limiting women's choices and jeopardizing their well-being. By highlighting women's rights, you can **appeal to your target audience of women** who want to make decisions that align with their personal goals and aspirations. In summary, understanding and respecting women's reproductive rights can **build trust and loyalty**.\nEuclidean\n:\nReproductive rights refer to a set of freedoms that women have regarding their reproductive health and choices. The lack of access to contraception and abortion services has historically limited women's ability to control their fertility and plan their families. By supporting women's reproductive rights, we promote equality and empower women to have control over their own lives. By studying the struggles and triumphs of the past, historians can provide valuable insights into the evolution of women\u2019s reproductive rights.\nBM25\n:\nWomen have the right to make decisions about their own reproductive health and rights. You can help by examining the impact of different levels of reproductive rights. For example, you can examine the effect of different types of birth control on the rate of unwanted pregnancies. You could also ask questions about the effectiveness of different countries' reproductive rights laws, such as those that allow women to choose not to give birth to their children in the first place.\nMIPS\n:\nWomen's reproductive rights are crucial because they ensure that women have autonomy over their bodies. The lack of access to contraception and abortion services has historically limited women's ability to control their fertility and plan their families. By studying the struggles and triumphs of the past, historians can provide valuable insights into the evolution of women\u2019s reproductive rights. By recognizing and respecting women's reproductive rights, we empower them to take control of their lives, pursue their agricultural endeavors, and contribute to the sustainable development of our communities."}]}]}, "D0zeqL7Vnz": {"paper_info": {"Primary Area": "generative models", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "large language models, prompting, decoding", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We decode text with LLMs by completing prompt templates end-to-end, instead of just sequential generation.", "Abstract": "Many recent prompting strategies for large language models (LLMs) query the model multiple times sequentially -- first to produce intermediate results and then the final answer. However, using these methods, both decoder and model are unaware of potential follow-up prompts, leading to disconnected and undesirably wordy intermediate responses.\nIn this work, we address this issue by proposing prompt sketching, a new prompting paradigm in which an LLM does not only respond by completing a prompt, but by predicting values for multiple variables in a template. This way, sketching grants users more control over the generation process, e.g., by providing a reasoning framework via intermediate instructions, leading to better overall results. The key idea enabling sketching with existing, autoregressive models is to adapt the decoding procedure to also score follow-up instructions during text generation, thus optimizing overall template likelihood in inference.\nOur experiments show that in a zero-shot setting, prompt sketching outperforms existing, sequential prompting schemes such as direct asking or chain-of-thought on 7 out of 8 LLM benchmarking tasks, including state tracking, arithmetic reasoning, and general question answering. To facilitate future use, we release a number of generic, yet effective sketches applicable to many tasks, and an open source library called dclib, powering our sketch-aware decoders.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9320", "PDF Url": "https://openreview.net/pdf?id=D0zeqL7Vnz"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9320 by Area Chair kkgv", "Subheading": "Meta ReviewbyArea Chair kkgv06 Dec 2023, 09:17 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper studies prompting for producing language model outputs that have a desired structure or satisfy constraints. Rather than conditioning on a fixed token sequence and allowing the model to complete it, as with traditional prompting, the authors suggest using sequences broken up into chunks that interleave fixed text and model generated text.  They essentially generalize a technique called stop-and-go inference including allowing it to operate with variations of beam search.\nStrengths include some of the experimental results and and the templates that the authors provided, which could prove useful in general. The main weakness here is that the technical contribution is fairly limited, which I explain more below.\nI generally felt that the paper is borderline. I ultimately voted for rejecting it for the following reason: most papers on particular prompting techniques tend to be a bit ephemeral since the next iteration of models may well be able to handle what appears to be challenging problems today (i.e., dealing with constraints). Indeed, one of the reviewers makes the same point for the example the authors provided in Figure 1. By itself this is\nnot\na problem, but it does mean that prompting papers should generally provide something like:\nvery substantial performance improvements versus baselines,\na general and new approach that was not there before,\nan analysis of particular scenarios (domains, distributions, tasks) where particular strategies work and others do not\nThe current draft didn't quite pass the bar: it doesn't really meet 1), is a generalization of particular techniques so doesn't quite do 2), and only slightly addresses 3). Of course there could be other contributions as well---but as it stands it wasn't quite enough.\nWith all this said, I'm optimistic for future versions, since the authors did do a bunch of work towards 3) in particular as part of the rebuttal.\nJustification For Why Not Higher Score:\nAs described above, the paper's contribution doesn't meet the bar along the axes that prompting papers typically operate on: it doesn't have sufficiently substantial performance improvements, substantial technical innovations, etc.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Main Response", "Subheading": "Official CommentbyAuthors21 Nov 2023, 04:11Everyone", "Content": "Comment:\nWe greatly appreciate the Reviewers\u2019 questions, comments, and suggestions and were particularly encouraged to hear that almost all reviewers recognized prompt sketching as a novel (tG6m, pDQp), useful, and intuitive (AyRy, Apoy) approach that identifies new connections between sequence decoding and structured LLM inference (AyRy) and enables novel, practical applications (tG6m).\nIn response to the reviews, we have extended and improved our manuscript, putting a particular focus on the following two points:\nWe want to highlight that our work not only introduces a novel theoretical perspective on template-guided inference and the corresponding decoding procedures but also (for the first time) empirically validates that already existing implementations of simple template-guided (stop-and-go) inference (e.g., Guidance AI [1], LMQL [2]), can indeed improve model reasoning capabilities. Since we believe this was not sufficiently clear, we have improved our description of this contribution in the revised draft.\nWe have significantly scaled (up to 10x) and extended many of our experiments to address concerns surrounding our experimental evaluation. These changes include:\nWe have extended our Llama-2 based evaluation to include all decoder/model combinations and observe similar trends as for OpenAI models, but at 10x the scale. In Table 8 (Appendix C.3), we provide confidence intervals for these results.\nWe have scaled our Sudoku and Dungeon Escape experiments by 10x and can confirm our initial findings (sketching significantly improves backtracking and planning capabilities with puzzles and interactive environments).\nWe have added an additional baseline in Appendix D, comparing with self-consistency decoding [4], showing that sketching outperforms self-consistency at a similar compute budget. We note that self-consistency remains orthogonal to sketching, meaning the two approaches can be applied jointly.\nWe have added a new experiment further demonstrating the effectiveness of sketching with interactive LLM-guided exploration of TextWorld [3] environments.\nFor more details, please see the individual review responses. We are happy to answer any follow-up questions that may arise as part of our responses and look forward to the Reviewers\u2019 response.\nReferences\n[1] Guidance AI: A guidance language for controlling large language models, S. Lundberg & M. T. C. Ribeiro,\nhttps://github.com/guidance-ai/guidance\n[2] Prompting is programming: A query language for large language models, L. Beurer-Kellner et al., PLDI\u201923\n[3]  Textworld: A learning environment for text-based games, M.-A. C\u00f4t\u00e9 et al., IJCAI\u201918\n[4] Self-consistency improves chain of thought reasoning in language models, X. Wang et al., ICLR\u201923"}, {"Heading": "Official Review of Submission9320 by Reviewer AyRy", "Subheading": "Official ReviewbyReviewer AyRy01 Nov 2023, 15:53 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a new approach to decoding LLM outputs when chaining multiple LLM queries. Such chains of queries can be specified as\nsketches\n: natural-language prompts that contain\nholes\nthat the LLM is meant to fill in. Each hole is associated with a stopping phrase, and a natural way to read the sketch is as specifying an interaction pattern, where we alternate between (1) deterministically extending an LLM's context window with the next (non-hole) chunk of the sketch, and (2) allowing the LLM to fill in the value of a hole by sampling tokens freely until it emits the stopping phrase for that hole. Because LLMs are autoregressive, this interaction pattern does not allow the LLM propose values for the holes in a way that is\naware\nof future interactions in the sketch. To alleviate this problem somewhat, the paper presents two new decoding algorithms (variants of beam search) that optimize the joint log probability of the entire LLM context. On several benchmark tasks, the paper compares the zero-shot performance of LLMs with standard prompts + standard decoding algorithms, vs. with particular prompt sketches and the new proposed decoding algorithms.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nPrompt sketches are an intuitive format for specifying certain types of chained queries.\nThe paper identifies a connection between decoding for these prompt sketches and constrained decoding, and points out (correctly) that standard beam search is insufficient for this task. The variants of beam search that the paper introduces are largely sensible, and overcome the key barriers to performing beam search in the multi-variable setting\u2014namely, the fact that beams with the same number of tokens may be at different stages of the sketch, making their scores difficult to compare fairly.\nResults are reported both for open models and closed (OpenAI) models. Many souped-up decoding methods require information that is not available through the OpenAI APIs, and it's nice that the authors have shown that a version of their approach (at least for small beam sizes)\ncan\nbe implemented atop the user-facing API (at least for text-davinci-003).\nWeaknesses:\nI couldn't quite follow the motivation: what problem with existing decoding techniques is prompt sketching meant to address? Figure 1 comes closest to illustrating the problem, but it was not particularly compelling. (I am not sure which model was used to generate Figure 1, but I tried copying the prompt and constraint into text-davinci-003 and it had no trouble following the constraint.) To be sure, there are many sketches that I am sure GPT-3 would often fail to follow, even if the sketch were included in the prompt; you can encode arbitrarily difficult infilling problems into sketches. But the sketches presented in this paper are enforcing very simple formatting constraints on, e.g., the list of thoughts generated for a chain-of-thought prompt. What failure modes do you see when just explaining to the model that it should follow the desired format (e.g. by pasting the sketch into the context)? Do failures to follow the format cause failures in reasoning? How exactly do VAR and BEAM_VAR address these failures? (Can they really be doing much, at a beam size of only n=2?)\nThe experiments provide somewhat weak evidence for the value of the new decoding methods. In different tasks, it often seems to be the case that\none\nof the methods outperforms an argmax baseline, whereas the\nother\nmethod underperforms the baseline, and which method wins varies from task to task. Even when the new decoding methods provide a modest advantage over argmax decoding, it is not clear whether the advantage is worth the added computational cost (or dollar cost, for OpenAI models).\nI am not convinced the experimental setup is completely debugged. For example, in chain-of-thought for the \"date understanding\" task, a period is used as the stopping phrase for each thought. However, periods show up frequently in dates (e.g., \"Sept. 1\"), and this stopping-phrase is clearly causing the model to cut off thoughts early (page 21). Some experimental settings are also missing details; e.g., in the single-variable chain-of-thought prompts, it is unclear when the [COT] variable ends -- I did not see a stopping phrase reported.\nSome of the algorithmic choices in VAR / BEAM_VAR were not sufficiently justified, and struck me as slightly odd. For example, the VAR algorithm shrinks the n^2 generations for a variable back down to a beam width of n\nbefore\nadding the next deterministic chunk. But I thought a key point of these algorithms was to enable the next deterministic chunk to provide a \"score\" for the proposed variable values; wouldn't it make more sense to rank all n^2 variable proposals by how well they fit with the next deterministic chunk, scale back down to n, and then generate proposals for the next variable?\nQuestions:\nI'd appreciate your thoughts on the questions raised in the \"weaknesses\" section. In particular, it would be great to better understand example failure modes of simpler methods (e.g., argmax decoding for few-shot chain-of-thought prompting) and how prompt sketching addresses / avoids these failures.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer AyRy Part I", "Subheading": "Official CommentbyAuthors21 Nov 2023, 04:26Everyone", "Content": "Comment:\nWe thank the reviewer for their insightful questions, which we address below, and are encouraged to hear that they find prompt sketches to be an intuitive format for chained queries.\nQ: Can you clarify the motivation for sketching and provide failure modes of existing models/decoding methods?\nAs pointed out by the reviewer, template-guided decoding can also be implemented by simply showing the LLM a template and asking it to produce a corresponding response. However, there are several limitations and failure modes with this approach:\nInstruction Following Capabilities:\nOnly big and powerful models are currently capable of this kind of instruction-following (e.g., see how\ntext-curie-001\nfails for this kind of task in Table 3, Sudoku). In contrast, sketching also works with small models, which may not understand the template, but can still produce useful completions for individual template variables.\nPrompt Size:\nIncluding large templates fully in the prompt will greatly increase the number of required tokens, possibly even exceeding the context window of the model. Further, LLM retrieval across large inputs remains difficult, which can lead to deviations from the provided template. In contrast, sketching guides the model through the template, step by step, without increasing the total number of tokens or requiring long-range retrieval.\nAccuracy, Reliability, and Automation:\nInstruction-following models are still not perfect, which means templates may be violated and not followed strictly. In contrast, sketching provides a 100% guarantee that the template will be adhered to. This is crucial in automated settings, where the LLM\u2019s output format must always be correct to enable processing by other systems that expect a specific format (e.g., function calling).\nDynamic Templates and Interactive Environment:\nIn some cases, providing the full template may also not be possible, as it may not be known fully ahead of time. For instance, templates may be dynamic, e.g., multiple repetitions of some template part, until a certain variable value is produced. Models can be instructed to respect such constraints, but this kind of prompting ultimately remains unreliable while sketching can enforce these properties strictly (cf. sketched CoT in the paper). Further, sketching is also applicable to interactive settings, where the template depends on and reacts to model output. For instance, in Table 3 we experimented with Dungeon-style graph traversal (Table 3), and in the updated revision, we added an additional experiment on TextWorld exploration.\nQ: How exactly do BeamVar/Var address these failure modes (with $n=2$)?\nAs pointed out above, sketching alone already greatly alleviates these failure modes as it leads to strict adherence to the template and allows for scripted follow-up. Sketch-aware decoders (BeamVar/Var) additionally allow us to jointly score multiple variables (while standard decoders only allow the last variable to be scored conditioned on all preceding ones). This enables picking variables based on later sequences in the template, which is particularly important in dynamic environments where the template text depends on the value of prior variables. While modern RLHF models are very strong and typically assign high probabilities to the top-1 token, a small beam width of n=2, can already be useful to track an alternative hypothesis when ambiguities arise (demonstrated by our experiments on reasoning tasks). For our more advanced experiments with other applications (cf. Table 3), we apply BeamVar and Var with higher beam width (n=5 and n=3 respectively), as clarified in the revised draft, which enables the exploration of a broader hypotheses space.\nQ: Why are you focusing on relatively simple formatting constraints?\nWe chose to focus on simple sketches, to examine whether structural support can improve model reasoning capabilities at all. Indeed, more complex or even grammar-guided approaches are possible, however, the design space of such sketches/reasoning grammars is very large and requires significant prompt engineering. In contrast, the main goal of this research is to establish foundational insight on whether structural guidance of the LLM reasoning process can improve its capabilities at all. Nonetheless, our sketching framework and decoders are general and capable of more complicated forms of template-guided inference, setting up future work to explore this direction."}, {"Heading": "Response to Reviewer AyRy Part II", "Subheading": "Official CommentbyAuthors21 Nov 2023, 04:27Everyone", "Content": "Comment:\nQ: Can you comment on the effectiveness of your methods with different tasks and models? Is it worth the computational overhead?\nWe consider the contribution of our experimental results to be twofold:\nWe demonstrate that template-guided inference via simple argmax-decoded sketches and comparatively simple structural templates can already improve task accuracy on reasoning tasks (OpenAI: $7/8$, Llama-2: $6/8$) greatly ($4%$ and $8%$ respectively). To the best of our knowledge, this has not been demonstrated before, as existing work on template-guided inference does not focus on the impact on reasoning performance. Computationally, argmax sketching is also cheaper than sequential decoding for the same output, as in sketching, the model does not have to autoregressively process fixed template parts (assuming sufficient model access and key-value caching).\nWe also demonstrate that while argmax sketching/stop-and-go inference can be effective, sketch-aware decoding brings even further improvements. For Beam-Var the computational cost is increased by a factor of beam width $n$, whereas Var requires a factor of $n^2$ more sequences to be explored. This is a considerable computational overhead, but, as known from traditional beam search, can be worth the additional compute if downstream performance is absolutely crucial.\nMore broadly, we mostly find VAR to be particularly effective with interleaved reasoning whereas BeamVar prevails in multiple-choice and math questions.\nQ: Does stopping on \u201c.\u201d with sketched chain-of-thought prompts restrict the model's reasoning? If no stopping phrase is specified, when does a variable end?\nThank you for this close attention to detail. Indeed, a badly chosen stopping phrase can impact decoding in this way, just like a badly constructed prompt will impact performance. However, upon manual inspection, we don\u2019t find this to be a particular issue in this case. Especially in chain-of-thought prompts, stopping on \u201c.\u201d mostly serves as a proxy for structuring the LLMs response, where LLMs will also recover and continue potentially truncated \u201cthoughts\u201d. Generally, we constructed sketches just like prompts, by developing, testing, and debugging them using real example data (also discussed in 4.3). If no stopping phrase is provided (e.g., for CoT), our decoders continue generation until the model emits the end-of-sequence token on its own.\nQ: Why do you shrink VARs $n^2$ generations back down to beam width $n$, before adding the next deterministic chunk rather than extending all $n^2$?\nThis is an interesting proposal. The reason for our choice is mostly based on cost considerations w.r.t. the OpenAI API. Each additional scored sequence incurs an additional request at the full length of the current sequence with OpenAI. Since\ntop_n\nstill maintains the highest scoring continuation, we reduce this cost by focusing on the \u201cmost promising\u201d sequences in the current set.  With open/accessible models, however, the proposed alternative would definitely be sensible, considering that scoring a sequence with standard transformers corresponds to a single forward pass only. In our published open source decoder library dclib, this can be easily implemented by moving a single line.\nWe hope to have been able to address all the reviewer\u2019s concerns, are happy to answer any follow-up questions they might have, and are looking forward to their reply."}, {"Heading": "Official Comment by Reviewer AyRy", "Subheading": "Official CommentbyReviewer AyRy23 Nov 2023, 03:41Everyone", "Content": "Comment:\nThank you for these detailed responses!\nIt seems that the main contribution of the paper is to empirically test whether this kind of guided decoding (variants of which have previously been published in LMQL, Synchromesh, etc. as well as implemented in open-source libraries like Microsoft Guidance and Outlines) help LLMs to reason better. In particular, there appears to be a claim that enforcing relatively simple stylistic constraints on the output ('chains of thought are \\n-separated lists beginning with hyphens') improves reasoning.\nBut I still do not feel that the paper, or the response, provides satisfying insight into why that is or how generally such a conclusion might hold. As I asked in my review, I am still wondering:\nDo failures to follow the format cause failures in reasoning?\nFor example, if not following a sketch template, how do chain-of-thought-prompted models fail? How often are failures in reasoning correlated with failures to follow the format? Why are these failures of reasoning fixable by forcing them to insert hyphens before each thought? How generally is that true?\nI will not argue against this paper's acceptance if other reviewers want to accept it, but I believe its thesis could be clarified and better defended empirically in future revisions."}]}, {"Heading": "Official Review of Submission9320 by Reviewer Apoy", "Subheading": "Official ReviewbyReviewer Apoy01 Nov 2023, 14:15 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes templated prompt sketches for problems requiring structured generation from LLMs. Structurally constrained generation is an important but overlooked problem. The paper also proposes sketch-aware decoding that considers the structured variables in decoding, and releases the code as an open-source library.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe motivation is clear, and the proposed methods which performs beamsearch over the variables (to be generated) is reasonable.\nA thorough study of non-templated and stop-and-go method as well as the proposed method, using various decoding strategies, is provided.\nThe provided prompt sketches are useful for various tasks.\nWeaknesses:\nThe experiments show that stop-and-go inference works well, and the proposed method does not significantly improve performance despite the additional overhead. Further, on many of the tasks simple autoregressive CoT seems sufficiently close in performance.\nWhile the paper provides some additional applications for prompt sketches, the tasks and the performance on the tasks are not entirely convincing.\nQuestions:\nHow is the custom decoding applied when using OpenAI API?\nI'm curious about the results if few-shot prompts are used.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer Apoy", "Subheading": "Official CommentbyAuthors21 Nov 2023, 04:41Everyone", "Content": "Comment:\nWe thank the reviewer for their encouraging response (clear motivation, thorough empirical study, useful for various tasks) and insightful observations and reply to their queries below.\nQ: Can you comment on the effectiveness of sketching/sketch-aware decoders with different tasks and models, and how it compares to argmax+CoT?\nWe consider the contribution of our experimental results to be twofold:\nWe demonstrate that template-guided inference via simple argmax-decoded sketches (stop-and-go) and comparatively simple structural templates can already improve task accuracy on reasoning tasks (OpenAI: 7/8, Llama-2: 6/8) significantly (4% and 8% respectively). To the best of our knowledge, this has not been demonstrated before, as existing work on template-guided inference does not discuss the impact on reasoning performance. We thus, for the first time, empirically validate the effectiveness of template-guided (stop-and-go) inference on reasoning tasks, using our sketching framework. Computationally, argmax sketching is cheaper than sequential decoding for the same output (e.g., argmax+CoT), as in sketching/stop-and-go, the model does not have to autoregressively process fixed template parts (assuming sufficient model access and key-value caching). In comparison, simple sketching thus provides accuracy improvements without necessarily incurring any computational overhead (potentially even reducing it).\nWe also demonstrate that while argmax sketching/stop-and-go inference can be effective, sketch-aware decoding brings even further improvements. These decoders incur computational overhead, but, as with traditional beam search, can be worth the additional compute if downstream performance is absolutely crucial. Of course, in practice this trade-off depends entirely on the concrete use case, compute budget, and user requirements.\nQ: Can you extend your evaluation of additional applications and further demonstrate the effectiveness of sketching in this context?\nWe have scaled our experiments regarding additional applications by a factor of 10, and now evaluate a larger number of samples (100 samples per model/decoder configuration). We report the results in the updated manuscript in Table 3. Overall, we observe comparable trends to before, i.e., sketch-aware decoders clearly show the ability to backtrack in Sudoku solving and solve the Dungeon Escape tasks more efficiently (fewer steps). We have also added an additional experiment on TextWorld [1] exploration (Table 3), which leverages our decoders for LLM-guided world exploration. Again, we find that sketch-aware decoders clearly outperform greedy argmax decoding, completing TextWorld quests of different lengths with ~20% fewer steps. We discuss our TextWorld result in appendix B.2.\nQ: How is custom decoding possible with the OpenAI API?\nThe proposed decoders only require rather minimal support by the API/model. In particular, we require the possibility to extend all of the sequences in the beam and obtain logprobs for these sequences for at least their top $n$ continuations. For the OpenAI Completion API models we use in the paper, these capabilities are available.\nQ: How does sketching perform when combined with few-shot prompting?\nSketching and few-shot prompting are orthogonal strategies, i.e., can be applied independently and jointly. We provide results on combining both in Appendix C.1. Overall, we find that few-shot prompting improves performance across the board, however, sketching still outcompetes sequential prompting, and in some cases zero-shot sketching even outperforms two-shot sequential prompting, suggesting that sketching can even serve as a replacement for few-shot demonstrations.\nWe hope to have been able to address all the reviewers\u2019 concerns, are happy to answer any follow-up questions they might have, and are looking forward to their reply.\nReferences\n[1]  Textworld: A learning environment for text-based games, M.-A. C\u00f4t\u00e9 et al., IJCAI\u201918"}]}, {"Heading": "Official Review of Submission9320 by Reviewer tG6m", "Subheading": "Official ReviewbyReviewer tG6m30 Oct 2023, 13:51 (modified: 21 Nov 2023, 19:45)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a novel prompting method (Prompt Sketching) which guides intermediate inference steps based on template. Prompt Sketching provides more control over generation and inference steps by putting deterministic chunks in decoding steps. In addition to the prompting strategy, authors suggests two variants of beam search (VAR, BEAMVAR) to adapt LLM to new decoding process. Experiments show its effectiveness in LLM reasoning tasks over CoT. Also, authors suggests types of task for which prompt sketching can be especially useful.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nSimple prompting strategy to improve LLM reasoning performance\nNew applications are interesting and could be useful for launching practical AI services.\nStructured outputs induced by prompt sketching have potential to automate various tasks beyond suggested applications.\nThe suggested method can reduce the number of model calls compared to stop-and-go and thus reduce the cost, which is practical.\nWeaknesses:\nGenerating templates requires human intervention and may necessitate significant efforts until finding a template working well. Also, potentially, templates can overfit to evaluation datasets.\nIt does not work well for small LMs.\nEvaluation results are given with limited amounts of data, which may harm the credibility of the results. Especially, confidence intervals in Table 6 look pretty large.\nMost of new applications look already doable by guidance-ai (\nhttps://github.com/guidance-ai/guidance\n), which is cited in the paper. Also, naive stop-and-go is not compared in main results.\nQuestions:\nWhat\u2019s the Sequential Prompting used in Table 3? CoTs or stop-and-go?\nCan templates be generated or suggested by LLM as well? I am also wondering if templates can be generated by retrieval.\nIs the suggested method applicable to programming tasks?\nCan Prompt sketching get help from demonstrations?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer tG6m Part I", "Subheading": "Official CommentbyAuthors21 Nov 2023, 05:04Everyone", "Content": "Comment:\nWe thank the reviewer for their insightful questions, which we address below, and are encouraged to hear that they find prompt sketches to be an intuitive format for chained queries.\nQ: Can you comment on the overhead of writing sketches as opposed to prompts?\nSimilar to prompt engineering, templates have to be constructed, tested, and debugged with example data to ensure the best performance. With current models, however, this prompt/template engineering effort cannot be avoided, as a single input/sentence is typically not sufficient to ensure that the model conforms to very specific and precise requirements. In this context, we consider sketching a more controlled form of prompting, where the output format is guaranteed and not up to prompt engineering and randomness in the generation process. Nonetheless, we agree that a human effort has to be made to properly prompt, template, and use LLMs. See also Section 4.3 for more discussion of this aspect.\nQ: Is prompt-sketching less effective with smaller LLMs?\nWe note that even with a smaller Llama-2 Chat model (13B parameters), sketching outperforms sequential prompting on 6/8 reasoning tasks while exhibiting even greater performance gains than for large OpenAI models (up to 8% vs. up to 4%). However, as we acknowledge in our evaluation, Llama-2 seems incapable of solving the Matrix Shape and AQuA reasoning tasks, irrespective of the prompting/sketching scheme, leading to inconclusive results on these datasets. Other tasks are not as strongly affected and show comparable trends to the OpenAI results. Further, we demonstrate in Appendix B.1 that sketching can be very effective with smaller models, for instance when asking a model to produce valid JSON output: For the small text-curie-001, sketching allows us to guarantee valid JSON output, whereas the same model with a corresponding prompts, is unable to produce any valid JSON at all.\nPotentially, our description in Section 4 was unclear in this regard. We have updated it in the rebuttal revision to make the above points more clear.\nQ: Does the sample size in the evaluation impact the credibility of the results?\nWe understand your concerns regarding sample size and statistical significance for the OpenAI-specific part of our evaluation. Unfortunately, we cannot scale our OpenAI experiments further, due to cost constraints ($4000 for the results at the current scale). However, we have expanded our Llama-2-based experiments (Table 2) to include all decoder/dataset configurations and for 10 times as many samples as in the OpenAI experiments (1000 per dataset, or the full datasets in many cases). We also provide confidence intervals for the Llama results in the new appendix Table 8. In this much larger-scale Llama-2 setting, we observe comparable trends to the smaller-scale OpenAI experiment: Across tasks, sketching improves overall reasoning performance when compared to sequential prompting, while sketch-aware decoders can provide further gains in exchange for higher computational cost.\nQ: How does the presented approach differ from Guidance?\nIndeed, practical tools like Guidance also enable a form of stop-and-go inference, which can be seen as a simple form of sketching. However, Guidance is an ad-hoc approach, where templates are simply decoded using multiple isolated LLM calls. In contrast, sketching theoretically anchors this approach as a multi-part sequence decoding problem, enabling sketch-aware decoders. Further, prior work (including Guidance) does not provide insights on whether this form of structural guidance positively impacts model reasoning capabilities. This is evaluated as the argmax version of prompt sketching. Our experimental results are thus also of interest to Guidance-like frameworks, as we show that structural guidance during inference can indeed improve reasoning capabilities, beyond syntax and structure. To the best of our knowledge, this has not been shown before and therefore improves the understanding of simple stop-and-go inference in general. We have updated the introduction of the paper to better reflect this."}, {"Heading": "Response to Reviewer tG6m Part II", "Subheading": "Official CommentbyAuthors21 Nov 2023, 05:05Everyone", "Content": "Comment:\nQ: What\u2019s the sequential prompting used in Table 3?\nFor Table 3, we reorder the prompt to include the Sudoku puzzle with missing values and then ask the model to repeat the template with values filled in. This works for simple templates, however does not support dynamically constructed templates or interactive environments.\nQ: Could templates be generated or suggested by LLMs?\nWe have implemented a prototype system that uses an LLM to produce templated sketches that subsequently can be executed using our decoders. However, we have not yet completed comprehensive empirical experiments on the effectiveness of this system. Early results show that a few-shot prompted LLM can easily adopt the sketching format, and indeed produce valid sketches with custom stopping phrases and constraints.\nQ: Is sketching applicability to programming tasks?\nSketching is agnostic with respect to the concrete templated data. For instance, sketching and sketch-aware decoders could be used for in-filling problems in program synthesis. Program sketching [1] is a common paradigm in program synthesis and could be implemented using prompt sketching.\nQ: Does Sketching benefit from (few-shot) demonstrations?\nSketching and few-shot prompting are orthogonal strategies, i.e., they can be applied independently and jointly. We provide results on combining both in Appendix C.1. Overall, we find that few-shot prompting improves performance across the board, however, sketching still outperforms sequential prompting and, in some cases, zero-shot sketching even outperforms two-shot sequential prompting, suggesting that sketching could even serve as a replacement for few-shot demonstrations.\nWe hope to have been able to address all the reviewer\u2019s concerns, are happy to answer any follow-up questions they might have, and are looking forward to their reply.\nReferences\n[1] \"Program sketching.\" A. Solar-Lezama, International Journal on Software Tools for Technology Transfer 15 (2013)"}, {"Heading": "Official Comment by Reviewer tG6m", "Subheading": "Official CommentbyReviewer tG6m21 Nov 2023, 19:46Everyone", "Content": "Comment:\nThank you for the detailed response! Since clarifications nicely addressed my concerns, I have raised my score to 6."}]}, {"Heading": "Official Review of Submission9320 by Reviewer pDQp", "Subheading": "Official ReviewbyReviewer pDQp30 Oct 2023, 13:34 (modified: 22 Nov 2023, 12:02)EveryoneRevisions", "Content": "Summary:\nThis paper proposes prompt sketching, a method to first provide sketches to the language model, then ask the model to fill in certain variables. The authors did experiments on several reasoning tasks and some planning tasks (with state tracking), to show the proposed method outperform existing method like direct prompting and chain-of-thought prompting. The models used are InstructGPT-based (text-davinci-003) and Llama-2 Chat based.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe motivation of this paper is great, and the sketching idea is highly interesting. Currently most language models do decoding in an auto-regressive fashion and might not adhere to certain constraints in the input. Sketching can definitely help models better plan and output responses better fit into user constraints.\nSome of the tasks explored are quite novel and interesting, like the interleaved reasoning tasks and the planning tasks (section 4.2), and the experiments do show they benefit from prompt sketching quite a bit.\nWeaknesses:\nThe biggest concern is the experiments in this paper, which do not clearly show the benefits of the proposed method:\nMost of the explored tasks, including logical reasoning, question answering, and arithmetic reasoning, use the\nmulti-variable\nprompting method (BeamVar, Var) as the sketch (Figure 3), which is actually a variant of the self-consistency [1] method: sample multiple chain-of-thoughts and then aggregate. Hence a fair comparison should be between the proposed method and self-consistency-based chain-of-thought, under the exact same number of samples.\nThe novelty of the proposed method compare to self-consistency should be discussed in details in this paper.\nCan the authors add self-consistency with the same number of samples as a baseline?\nComparing chain-of-thought prompting under BeamVar and prompt-sketching under BeamVar (this should be a more fair comparison with the same number of sampled thoughts), the proposed method does not yield much gains. Hence the authors should better discuss what is the main contribution of \"sketching\" over existing chain-of-thought.\n[1] Wang et al. Self-Consistency Improves Chain of Thought Reasoning in Language Models. ICLR 2023.\nIn section 4.2, some novel tasks are explored and could potentially show the benefits of the proposed sketching. However, the experiments are extremely small-scale (10 Sudoku puzzles, 10 Dungeon environments), so it is unclear whether the proposed method indeed outperform existing methods.\nPerformance gains: from Table 6, the confidence intervals are fairly large, and it is unclear which method is significantly better compared to the others. Can the authors clarify which result is statistically significant?\nComputational cost: can the authors discuss in more details on the exact computational cost used for the proposed method?\nQuestions:\nCan the authors add self-consistency with the same number of samples as a baseline?\nTable 6, the confidence intervals are fairly large, and it is unclear which method is significantly better compared to the others. Can the authors clarify which result is statistically significant?\nComputational cost: can the authors discuss in more details on the exact computational cost used for the proposed method?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer pDQp Part I", "Subheading": "Official CommentbyAuthors21 Nov 2023, 05:15 (modified: 21 Nov 2023, 05:15)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewer for their insightful questions, which we address below, and are encouraged to hear that they find prompt sketches to be a highly interesting idea.\nQ: How does Sketching with BeamVar/Var relate to Self-Consistency and can you add it as a baseline?\nThe self-consistency [1] decoding strategy improves LLM reasoning by greedily sampling multiple (chain-of-thought) reasoning paths and aggregating the resulting final answers, by (unweighted or weighted) majority vote. In contrast, sketch-aware decoders generate answers token-by-token or thought-by-thought (not path by path), can branch on the top-n alternatives at each step, and do not aggregate the final results. Instead, a single sequence is chosen as the one answer to an input, considering the model likelihood of the underlying token sequence only (no aggregation or majority voting). With this, self-consistency and sketching can be considered orthogonal approaches and could even be applied jointly, i.e., sample-decode a sketch multiple times and aggregate the results.\nWe added a comparison of sketching and self-consistency to the revised manuscript (Appendix D). For this comparison, we choose $n=2$/$n=4$ samples for self-consistency, as this aligns with the computational overhead of our branching decoders BeamVar/Var with $n=2$. However, our results show that, in many cases, self-consistency with such a low number of samples does not even outperform argmax CoT which is the main baseline we outcompete with sketching. This aligns with the self-consistency paper itself [1], which reports that around 5-20 consistency samples are required to outperform simple argmax CoT. We thus find that within this compute budget ($n=2$/$n=4$), argmax CoT and thus sketching both outperform self-consistency decoding.\nQ: Is CoT+BeamVar a better baseline for Sketching+BeamVar?\nComparing CoT+BeamVar with Sketching+BeamVar, we observe an accuracy increase of $8-12%$ with OpenAI models for AQuA, StrategyQA, Tracking Shuffled Objects and Matrix Shapes. On these tasks, CoT+BeamVar is thus clearly outperformed by sketching. For Date Understanding, Multistep Arithmetic, GSM8K on the other hand we indeed observe comparable performance with sketching+BeamVar. This can be explained by the two-part nature of the zero-shot CoT formulation [2] (first decoding reasoning and then the final answer). Applying a sketch-aware decoder like BeamVar to this kind of prompt already boosts performance, as BeamVar can exploit this two-variable structure. For a baseline comparison (no interaction between multiple variables), we thus have to look at Beam+CoT (one column to the left). There, we find that Multistep Arithmetic and GSM8K again perform worse. Only for Date Understanding do sketching and sketch-aware decoders not appear to bring particular benefit for OpenAI models, which is reflected in our overall summary: sketching outperforms sequential prompting on 7/8 tasks.\nQ: Can you extend your evaluation of additional applications and further demonstrate the effectiveness of sketching in this context?\nWe have scaled our experiments on the additional applications (Section 4.2) by a factor of 10 and now evaluate a larger number of samples (100 samples per model/decoder configuration). We report the results in the updated manuscript. Overall, we observe comparable trends to before, i.e., sketch-aware decoders clearly show the ability to backtrack in Sudoku solving and solve the Dungeon Escape tasks more efficiently (fewer steps), when compared to naive argmax decoding. We have also added an additional experiment on TextWorld [3] exploration, which leverages our decoders for LLM-guided world exploration. Again, we find that sketch-aware decoders clearly outperform greedy argmax decoding, completing TextWorld quests of different lengths with 20% fewer steps. We further discuss our TextWorld results in Appendix B.2.\nReferences\n[1] Self-consistency improves chain of thought reasoning in language models, X. Wang et al., ICLR\u201923\n[2] Large language models are zero-shot reasoners, K. Takeshi et al., NeurIPS\u201922\n[3] Textworld: A learning environment for text-based games, M.-A. C\u00f4t\u00e9 et al., IJCAI\u201918"}, {"Heading": "Response to Reviewer pDQp Part II", "Subheading": "Official CommentbyAuthors21 Nov 2023, 05:16Everyone", "Content": "Comment:\nQ: Can you clarify which results are statistically significant given the evaluation sample sizes and  fairly large confidence intervals in Table 6?\nWe understand your concerns regarding sample size and statistical significance for the OpenAI-specific part of our evaluation. Unfortunately, we cannot scale our OpenAI experiments further, due to cost constraints ($4000 for the results at the current scale). However, we have expanded our Llama-2-based experiments (Table 2) to include all decoder/dataset configurations and evaluate 10 times as many samples as in the OpenAI experiments (1000 per dataset, or the full datasets in many cases) and also provide confidence intervals for the Llama results in the new appendix Table 8. In this much more scaled Llama-2 setting, we observe comparable trends to the smaller-scale OpenAI experiments: Across tasks, sketching improves overall reasoning performance when compared to sequential prompting, while sketch-aware decoders can provide further gains in exchange for higher computational cost.\nQ: Can you discuss the computational cost of the proposed method in further detail?\nComputationally, argmax sketching is cheaper than sequential decoding for the same output. This is because in sketching the model does not have to autoregressively process fixed template parts (assuming sufficient model access and key-value caching). For BeamVar the computational cost is increased by a factor of beam width $n$, whereas Var requires a factor of $n^2$ more sequences to be explored (2x and 4x, respectively, for our main evaluation). This is a considerable computational overhead, but, as known from traditional beam search, can be worth the additional compute if downstream performance is absolutely crucial. It is also more cost-effective than, e.g., self-consistency decoding, which requires 5-20 consistency samples, resulting in a 5-20x overhead. In practice, this kind of performance/accuracy trade-off of course depends on the concrete use case, compute budget, and user requirements.\nWe hope to have been able to address all the reviewers\u2019 concerns, are happy to answer any follow-up questions they might have, and are looking forward to their reply."}, {"Heading": "Official Comment by Reviewer pDQp", "Subheading": "Official CommentbyReviewer pDQp22 Nov 2023, 01:44Everyone", "Content": "Comment:\nThanks for the clarification. I agree that for Interleaved Reasoning, the win is pretty clear and the underlying reason is clear as well (the model does more explicit state tracking via the sketches), however, for other tasks, the wins are fairly small (and seem to vary a lot based on which one of argmax/beamvar/var/beam is used).\nFor math tasks like AQuA or GSM8K, can the authors clarify exactly why sketching would help? From the prompts it seems like it's only forcing two things in addition to CoT: \n(1) the number of thought steps: how is this determined btw? I saw 12 is used for AQuA and 10 is used for GSM8K, are they randomly chosen? It's possible that by enforcing a certain number of thought steps, the model generates a\nlonger\nthought process which leads to some of the gains. Can the authors provide some simple statistics like the avg # tokens in CoT and in sketching?\n(2) some formatting on the thoughts: this issue can actually easily be addressed by few-shot CoT (i.e., by showing models a few examples, the model can better adhere to the few-shot format). From Table 4 we can also see the gains become much smaller when few-shot is used."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 06:56Everyone", "Content": "Comment:\nThanks for engaging in the discussion! We are happy to hear that the reviewer agrees with us on the clear advantages of sketching for tasks that can be framed as interleaved reasoning.\nRegarding the math tasks, we agree with the reviewer that both enforcing the reasoning format and increasing the reasoning chain length are likely to contribute to the performance improvement we observe. In addition, we believe that sketch-aware decoders effectively back-track and correct reasoning errors (see the improvement from 0.32 for argmax to 0.35 with Var and BeamVar, all with sketching, on GSM8K in Table 4).\nIn more detail: \nWhile our templates permit 12 and 10 reasoning steps, these are upper bounds that the model can break from earlier (by producing a corresponding stopping phrase). We based these limits on experimentation with example data, which showed that naturally, the model would very rarely exceed these bounds in well-formed reasoning processes. In practice, for sketched argmax, we observe on average 6.77 and 8.29 thought steps for AQuA and GSM8K, respectively. We also inspected the resulting model output at the step limit, and could not find any instances of truncated reasoning, where the model did not conclude with its final answer. Compared to non-sketched chain-of-thought, we observe ~20% longer reasoning chains, which can indeed affect performance. \nRegarding the results presented in Table 4 (revised draft): Indeed, in the few-shot setting, performance improvements are reduced as the advantageous formatting enforced by sketching can also be encouraged using few-shot prompting. However, our sketch-aware decoders combined with sketching applied in a 0-shot setting already outperform argmax decoding without sketching in the two-shot setting on all four considered tasks. We conclude that the rigorous formatting guidelines enforced by sketching can replace and even improve upon the soft ones imposed by few-shot prompting, crucially, without requiring the few-shot demonstrations which come with important drawbacks:\nPrompt length:\nIncluding few-shot examples increases the number of input tokens and thereby latency and cost.\nHandcrafting examples:\nFew-shot prompting needs examples in order to be applied to a new task. which need to be manually crafted. In contrast, sketching only requires the often transferable prompt sketch, which can be adapted (if needed) at the same effort as adapting a prompt.\nWe hope this addresses your follow-up questions. Should you want any further clarification, please don\u2019t hesitate to ask."}, {"Heading": "Official Comment by Reviewer pDQp", "Subheading": "Official CommentbyReviewer pDQp22 Nov 2023, 12:02Everyone", "Content": "Comment:\nThanks for the further clarification. Overall I think the idea proposed in this paper is novel and interesting, and the gain on interleaved reasoning is clear, hence I will increase my score.\nHowever, based on the responses I think this paper should better clarify its contribution on all the other reasoning tasks:\nthe proposed example reasoning framework (\"on one hand.., on the other hand\") is not generally adopted for all tasks (only used in \"Information Essentiality\") and it is unclear why it could be beneficial on top of CoT. It also seems to be task-specific (e.g., some tasks require thinking both pros and cons) and needs to be manually designed by looking at task examples;\nmost sketches adopt the \"for i in range(K): -THOUGHT\" framework, but it seems like multiple factors could contribute to the final gains: prompt length, formatting, backtracking, rather than just \"sketching\" which is the main claim of this paper. The number K also needs to be manually selected by looking at examples and model responses.\nI think this paper could be further improved by better clarifying its contributions, analysis on what actually contributes to the gains compared to existing methods, and more clear presentation on the methods/prompt used."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 13:35Everyone", "Content": "Comment:\nThank you for your response and analysis.\nWe agree with the reviewer that investigating the exact mechanisms leading to optimal performance on different reasoning tasks is an exciting and likely fruitful research direction for follow-up work. However, in this work, we want to establish the foundation for such investigations by showing, for the first time, that structural guidance of the LLM reasoning process can improve its capabilities and provide the conceptual and tooling framework to rigorously investigate related questions. We believe this to be of high practical importance as first tools enabling such structural guidance [1,2] are rapidly gaining popularity (jointly over 17k GitHub stars).\nIn particular, sketching in combination with sketch-aware decoders is exactly what enables constraints on reasoning chain length, formatting, and backtracking. However, we intentionally focus on simple sketches (with potentially suboptimal hyper-parameters) and a general analysis instead of exploring more complex or even grammar-guided prompt sketches, as our goal is to establish whether structural support can improve model reasoning capabilities at all. Thus, we believe that, while our sketching framework and decoders support these more complicated forms of template-guided inference, such investigations are out of scope for this work and not permitted by the rigorous space constraints of a single ICLR paper.\nWe believe that the mathematical reasoning problems discussed above are an interesting case study and are happy to include them in the appendix."}]}]}, "RAwfHdvisZ": {"paper_info": {"Keywords": "Multi-modal search, Hyperbolic space, Hyperbolic geometry, Lorentz model, Domain adapter", "TL;DR": "Chimera is an adaptation framework that enhances their representation learning over modalities.", "Abstract": "As multi-modal search relies on jointly learning image-text representations and has been investigated in the literature,\nwe explore spaces or representations that coexist with and enhance these models.\nBecause the core of multi-modal search is learning their modalities in a shared semantic space and measuring their similarities,\nsearch quality depends on which expressive space is used for learning.\nWe find that topic and Hyperbolic space can complement this space,\nand propose a model-agnostic adaptation framework, Chimera.\nThe novelty of this framework lies in 1) designing the topic and Hyperbolic spaces to reveal relationships buried in traditional spaces,\n2) leveraging token level interactions,\nand 3) performing contrastive/metric learning tasks to ensure the cooperation of these spaces with pre-trained models.\nExperiments show that Chimera empowers pre-trained models for multi-modal search tasks and demonstrate the ability of the layers it introduces.", "Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9317", "PDF Url": "https://openreview.net/pdf?id=RAwfHdvisZ"}, "review_info": []}, "elMKXvhhQ9": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Graph anomaly detection, consistency training, learnable data augmentation", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Graph Anomaly Detection (GAD) has surfaced as a significant field of research, predominantly due to its substantial influence in production environments. Although existing approaches for node anomaly detection have shown effectiveness, they have yet to fully address two major challenges: operating in settings with limited supervision and managing class imbalance effectively. In response to these challenges, we propose a novel model, ConsisGAD, which is tailored for GAD in scenarios characterized by limited supervision and is anchored in the principles of consistency training. Under limited supervision, ConsisGAD effectively leverages the abundance of unlabeled data for consistency training by incorporating a novel learnable data augmentation mechanism, thereby introducing controlled noise into the dataset. Moreover, ConsisGAD takes advantage of the variance in homophily distribution between normal and anomalous nodes to craft a simplified GNN backbone, enhancing its capability to distinguish effectively between these two classes. Comprehensive experiments on several benchmark datasets validate the superior performance of ConsisGAD in comparison to state-of-the-art baselines. Our code is available athttps://github.com/Xtra-Computing/ConsisGAD.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "learning on graphs and other geometries & topologies", "Submission Number": "9315", "PDF Url": "https://openreview.net/pdf?id=elMKXvhhQ9"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (spotlight)"}, {"Heading": "Code and Dataset Sharing", "Subheading": "Public CommentbyJunwei He12 Dec 2023, 08:31 (modified: 12 Dec 2023, 08:44)EveryoneRevisions", "Content": "Comment:\nI've been looking at the results of your recent study and I'm quite impressed with what you've accomplished. Your experiments seem to show some really interesting findings that could be important for our field.\n\nI do have a small request that I believe could help others appreciate your work as much as I do. Would it be possible for you to share the code and datasets you used? Making these available would make it easier for others (myself included) to understand and potentially replicate your work, which would really strengthen the impact of your findings.\n\nI know sharing these resources can take extra effort, but I think it would be incredibly valuable to our community. It would help everyone get a better grasp of your methods and possibly inspire more research in this area.\n\nThanks a lot for considering this."}, {"Heading": "Meta Review of Submission9315 by Area Chair PR2H", "Subheading": "Meta ReviewbyArea Chair PR2H04 Dec 2023, 07:14 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe majority of the reviewers were in strong support of acceptance (two scores of 8), and found novelty in the proposed learnable data augmentation approach.\nJustification For Why Not Higher Score:\nOne reviewer gave a 5, but then did not engage in discussion.\nJustification For Why Not Lower Score:\nThere is significantly strong support, with high confidence, from the majority of the reviewers."}, {"Heading": "A Summary of Our Contributions and Responses", "Subheading": "Official CommentbyAuthors23 Nov 2023, 04:39 (modified: 23 Nov 2023, 05:02)EveryoneRevisions", "Content": "Comment:\nDear Reviewers and ACs,\n\nAs the discussion is ending in the next few hours, we are grateful for the insightful comments and valuable suggestions from all reviewers. We would really appreciate it if reviewer _RZbU_ and reviewer _tbTo_ could kindly re-evaluate their reviews considering our follow-up responses and manuscript revisions. In the following, we would like to summarize the contributions and responses of this paper again. \n\n**Contributions**:\n\n- To deal with graph anomaly detection with limited supervision, we propose a learnable augmentation module and optimize it via two metrics: label consistency and distribution diversity. This approach appears ```effective```, ```enhancing the overall performance of the model``` (_R ZNLh_), and ```innovative``` (_R RZbU_). The two proposed metrics are ```intriguing``` (_R RZbU_).\n- We introduce a GNN backbone model that exploits the homophily distribution differences between normal and anomalous nodes for detection. This approach is ```straightforward yet effective``` (_R RZbU_). ```Visualization underscores the robustness of the proposed method``` (_R ZNLh_).\n- Our paper is ```well-written``` (_R ZNLh_, _R RZbU_, _R tbTo_). Our experiments are generally ```comprehensive``` (_R ZNLh_), ```extensive``` (_R RZbU_), and ```sufficient``` (_R tbTo_).\n\n**Responses and Revisions:**\n\n- **For Reviewer _ZNLh_'s concerns**:\n  - We conducted additional experiments to assess and analyze the quality of high-quality nodes.\n  - We conducted additional experiments to analyze the sensitivity of our model to several important hyper-parameters.\n  - We conducted additional experiments to evaluate and analyze the applicability of our GNN backbone model to generic multi-class node classification tasks.\n- **For Reviewer _RZbU_' concerns**:\n  - We made a detailed comparison between our learnable data augmentation module and existing automatic data augmentation techniques.\n  - We explored and analyzed the extensions of our learnable augmentation module to generic graph contrastive learning tasks.\n  - We conducted additional experiments to analyze the effectiveness of utilizing the exact labels of labeled nodes in consistency training.\n- **For Reviewer _tbTo_'s concerns**:\n  - We made clarifications on the architecture and motivations of our proposed model (Responses to Questions 1, 2, and 3).\n  - We highlighted our comparative analysis of our learnable data augmentation against four stochastic augmentation methods in the paper.\n  - We gave a comprehensive complexity analysis of our algorithm.\n\nAll modifications have been highlighted in blue in our revised manuscript. Thanks again for your efforts in reviewing our work, and we hope our responses adequately address any concerns about this work.\n\nWarm regards, \\\nThe Authors of Submission 9315"}, {"Heading": "Official Review of Submission9315 by Reviewer ZNLh", "Subheading": "Official ReviewbyReviewer ZNLh04 Nov 2023, 20:31 (modified: 21 Nov 2023, 08:45)EveryoneRevisions", "Content": "Summary:\nIn this paper, the authors tackle the problem of anomaly detection in graphs by introducing a novel approach---consistency training coupled with a learnable data augmentation mechanism. Their method involves leveraging a simple GNN backbone that emphasizes edge-level homophily representation for anomaly detection. By exploiting disparities in homophily distribution, the proposed model achieves enhanced anomaly detection capabilities. Additionally, the authors introduce two evaluation metrics designed to optimize their innovative learnable data augmentation technique, guiding its effectiveness in data synthesis. In their experimental evaluation, the authors assess the performance of their model across four benchmark datasets commonly used for graph-based anomaly detection, along with a private dataset. The proposed model generally outperforms existing state-of-the-art baselines across three key evaluation metrics.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\n1. I find the proposed learnable data augmentation mechanism intriguing. Intuitively, this approach appears effective, as it can be finely tuned through the optimization of two core metrics: label consistency and data distribution. Through iterative optimization of these components---the GNN module and the learnable data augmentation module---it seems both elements can be well-trained, enhancing the overall performance of the model.\n\n2. The node clusters displayed in Figure 3 provide a compelling visual representation of the effectiveness of the proposed GNN backbone. The well-separated node clusters, especially concerning different edge relations, serve as a strong validation of the necessity of leveraging distinctions in homophily distribution for anomaly detection. This visualization underscores the robustness of the proposed method.\n\n3. The paper is skillfully composed, ensuring clarity and coherence in conveying the research concepts. Additionally, the experiments conducted are generally comprehensive, offering substantial evidence to support the effectiveness of the proposed model.\nWeaknesses:\n1. Regarding consistency training, the proposed model employs thresholds to identify \"high-quality nodes\" from the unlabeled data for training. This step, akin to semi-supervised learning, assigns synthetic labels to unlabeled data for consistency training. The performance of these \"high-quality nodes\" is pivotal for downstream iterative training, emphasizing the significance of their accuracy. Hence, the authors should analyze the actual quality of these \"high-quality nodes\" and the accuracy of their predicted labels. This aspect holds significant importance in evaluating the reliability and effectiveness of the model.\n\n2. The paper introduces essential hyperparameters, including $\\alpha$ and $\\xi$. While the authors provide their specific settings in the experiments, the impact of these parameters on the performance of the model remains unexplored. The authors should perform a sensitivity analysis for the crucial hyperparameters in the proposed model.\n\n3. The proposed GNN backbone shows promise for anomaly detection by capturing distinctions in the homophily distribution of nodes in graphs. However, it raises intriguing questions about its performance on graphs with varying levels of heterophily. Specifically, how well does the proposed GNN backbone perform on graphs with low or high heterophily when applied to generic multi-class node classification tasks?\nQuestions:\n1. How about the correctness of the \"high-quality nodes\"?\n\n2. The authors should perform a sensitivity analysis for the crucial hyperparameters in the proposed model.\n\n3. Can the proposed GNN backbone effectively handle generic multi-class node classification tasks?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 16:32 (modified: 18 Nov 2023, 17:03)EveryoneRevisions", "Content": "Comment:\nThank you for your thorough review and insightful comments on our submission. We appreciate the time you invested in evaluating our work and offering constructive feedback. Below, we address your comments to clarify and improve our manuscript.\n\n**1. How about the correctness of the \"high-quality nodes\"?**\n\nThanks for highlighting the significance of evaluating the quality of \"high-quality nodes\" in our consistency training approach. Considering your valuable suggestion, we have conducted a detailed experiment to assess this aspect and include the results in Appendix E.6 of our revised manuscript. In this experiment, we visualize Macro F1 scores of \"high-quality nodes\" at each epoch during training and compare these with scores from the test set. For your reference, we report the scores with an interval of 10 epochs in the following table. For more details, please kindly refer to the Appendix E.6.\n\n|                    | Epoch 10 | Epoch 20 | Epoch 30 | Epoch 40 | Epoch 50 | Epoch 60 | Epoch 70 | Epoch 80 | Epoch 90 | Epoch 100 |\n| :----------------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :-------: |\n|       Amazon       |          |          |          |          |          |          |          |          |          |           |\n| High-quality Nodes |  90.79   |  88.89   |  91.06   |  92.18   |  90.91   |  90.76   |  90.76   |  91.43   |  89.99   |   89.29   |\n|     Test Nodes     |  87.56   |  88.13   |  90.10   |  90.96   |  90.98   |  90.92   |  90.04   |  90.60   |  90.07   |   90.43   |\n|       Diff.        |   3.23   |   0.76   |   0.96   |   1.23   |  -0.07   |  -0.17   |   0.72   |   0.83   |  -0.08   |   -1.14   |\n|      YelpChi       |          |          |          |          |          |          |          |          |          |           |\n| High-quality Nodes |  67.23   |  69.23   |  68.09   |  69.11   |  68.49   |  68.98   |  69.21   |  70.02   |  69.28   |   68.76   |\n|     Test Nodes     |  66.72   |  67.56   |  68.49   |  67.76   |  68.13   |  68.12   |  67.42   |  67.96   |  68.25   |   68.42   |\n|       Diff.        |   0.51   |   1.68   |  -0.40   |   1.35   |   0.36   |   0.86   |   1.79   |   2.06   |   1.03   |   0.33    |\n|     T-Finance      |          |          |          |          |          |          |          |          |          |           |\n| High-quality Nodes |  90.82   |  90.27   |  90.15   |  90.12   |  88.50   |  91.33   |  91.11   |  91.48   |  91.14   |   91.09   |\n|     Test Nodes     |  89.28   |  90.22   |  89.39   |  90.44   |  91.16   |  91.05   |  90.90   |  90.87   |  90.62   |   90.39   |\n|       Diff.        |   1.54   |   0.05   |   0.76   |  -0.31   |  -2.66   |   0.28   |   0.21   |   0.62   |   0.52   |   0.71    |\n|      T-Social      |          |          |          |          |          |          |          |          |          |           |\n| High-quality Nodes |  75.68   |  76.35   |  76.92   |  75.82   |  76.09   |  77.53   |  75.48   |  74.07   |  76.11   |   73.59   |\n|     Test Nodes     |  72.14   |  73.56   |  76.07   |  74.17   |  74.23   |  76.10   |  73.13   |  71.52   |  73.81   |   72.58   |\n|       Diff.        |   3.53   |   2.80   |   0.85   |   1.65   |   1.87   |   1.43   |   2.35   |   2.54   |   2.30   |   1.01    |\n\nThe result demonstrates that \"high-quality nodes\" consistently achieve higher Macro F1 scores than test nodes across various datasets. On Amazon, YelpChi, T-Finance, and T-Social, the average performance improvement of \"high-quality nodes\" over test nodes is 1.01%, 0.83%, 0.71%, and 0.64%, respectively. Generally, as depicted in Figure 10, both \"high-quality nodes\" and test nodes exhibit a gradual increase in performance, with the former driving the improvement of the latter. An exception lies in the T-Social dataset, on which we observe some performance fluctuations. This is possibly due to the much smaller batch size and training data relative to the whole dataset size. Overall, our analysis showcases the accuracy of the predicted labels and the robustness of our selection criteria for \"high-quality nodes\"."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 16:34Everyone", "Content": "Comment:\n**2. The authors should perform a sensitivity analysis for the crucial hyperparameters in the proposed model.**\n\nTaking your valuable advice, we have performed a sensitivity analysis on hyper-parameters and included the results in Appendix E.7 of our revised manuscript. We vary the weights of the label consistency loss $\\alpha$ among \\{0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0\\} and the drop ratio $\\xi$ among \\{0.0, 0.1, 0.2, 0.3, 0.4, 0.5\\}, and measure the corresponding model performance across the Amazon, YelpChi, and T-Finance datasets. For your ease of reference, we have summarized the results in the tables below. Additionally, we have included in Appendix E.7 a sensitivity analysis of the normal threshold $\\tau_n$ and anomalous threshold $\\tau_a$, providing a more comprehensive understanding of our model's behavior under different hyper-parameter settings.\n\n| $\\alpha$  |    0.1     |    0.2     |      0.5       |      1.0       |    2.0     |      5.0       |    10.0    |\n| :-------: | :--------: | :--------: | :------------: | :------------: | :--------: | :------------: | :--------: |\n|  Amazon   |            |            |                |                |            |                |            |\n|   AUROC   | 93.16\u00b10.56 | 93.55\u00b10.56 |   93.68\u00b10.63   | **93.91\u00b10.58** | 93.73\u00b10.54 |   92.89\u00b10.60   | 93.31\u00b10.58 |\n|   AUPRC   | 82.47\u00b10.48 | 82.38\u00b10.35 |   82.76\u00b10.51   | **83.33\u00b10.34** | 83.13\u00b10.69 |   80.37\u00b10.84   | 79.21\u00b11.04 |\n| Macro F1  | 89.50\u00b10.81 | 89.27\u00b10.66 |   89.03\u00b10.69   | **90.03\u00b10.53** | 89.77\u00b10.27 |   89.56\u00b10.40   | 88.65\u00b10.65 |\n|  YelpChi  |            |            |                |                |            |                |            |\n|   AUROC   | 81.86\u00b10.25 | 81.76\u00b10.41 | **83.36\u00b10.53** |   82.16\u00b10.63   | 82.94\u00b10.62 |   82.01\u00b10.81   | 81.34\u00b10.50 |\n|   AUPRC   | 45.33\u00b10.33 | 45.00\u00b10.52 | **47.33\u00b10.58** |   45.49\u00b11.08   | 46.27\u00b10.82 |   44.88\u00b11.19   | 43.47\u00b10.26 |\n| Macro F1  | 68.73\u00b10.33 | 68.63\u00b10.52 | **69.72\u00b10.30** |   68.81\u00b10.37   | 69.11\u00b10.50 |   68.55\u00b10.43   | 68.25\u00b10.36 |\n| T-Finance |            |            |                |                |            |                |            |\n|   AUROC   | 95.06\u00b10.31 | 95.10\u00b10.22 |   95.15\u00b10.48   |   95.01\u00b10.40   | 95.26\u00b10.17 | **95.33\u00b10.30** | 95.13\u00b10.45 |\n|   AUPRC   | 84.77\u00b10.47 | 85.37\u00b10.37 |   85.71\u00b10.77   |   85.88\u00b11.23   | 86.10\u00b10.75 | **86.63\u00b10.44** | 83.87\u00b10.39 |\n| Macro F1  | 89.57\u00b10.68 | 89.74\u00b10.41 |   90.29\u00b10.69   |   90.93\u00b10.55   | 90.74\u00b10.68 | **90.97\u00b10.63** | 89.17\u00b10.84 |\n\n\n|   $\\xi$   |    0.0     |      0.1       |      0.2       |      0.3       |    0.4     |    0.5     |\n| :-------: | :--------: | :------------: | :------------: | :------------: | :--------: | :--------: |\n|  Amazon   |            |                |                |                |            |            |\n|   AUROC   | 92.07\u00b10.29 |   92.93\u00b10.15   |   93.54\u00b10.47   | **93.91\u00b10.58** | 93.05\u00b10.82 | 92.43\u00b11.13 |\n|   AUPRC   | 78.79\u00b10.42 |   80.20\u00b10.74   |   81.58\u00b10.31   | **83.33\u00b10.34** | 81.66\u00b11.33 | 80.46\u00b11.82 |\n| Macro F1  | 87.25\u00b11.21 |   87.26\u00b10.99   |   88.93\u00b11.15   | **90.03\u00b10.53** | 89.38\u00b10.90 | 89.48\u00b10.87 |\n|  YelpChi  |            |                |                |                |            |            |\n|   AUROC   | 80.36\u00b10.62 | **83.36\u00b10.53** |   82.45\u00b10.65   |   81.93\u00b10.83   | 81.66\u00b10.63 | 81.82\u00b11.02 |\n|   AUPRC   | 42.60\u00b11.18 | **47.33\u00b10.58** |   45.47\u00b11.12   |   44.59\u00b10.99   | 43.80\u00b10.65 | 43.65\u00b11.28 |\n| Macro F1  | 67.22\u00b10.76 | **69.72\u00b10.30** |   68.89\u00b10.66   |   68.21\u00b10.72   | 67.87\u00b10.27 | 68.10\u00b10.58 |\n| T-Finance |            |                |                |                |            |            |\n|   AUROC   | 95.18\u00b10.56 |   95.24\u00b10.27   | **95.33\u00b10.30** |   95.14\u00b10.33   | 95.13\u00b10.39 | 95.20\u00b10.24 |\n|   AUPRC   | 83.57\u00b10.64 |   86.55\u00b10.82   | **86.63\u00b10.44** |   86.39\u00b10.88   | 85.29\u00b10.71 | 85.10\u00b10.73 |\n| Macro F1  | 88.79\u00b11.21 |   90.89\u00b10.73   | **90.97\u00b10.63** |   90.73\u00b11.03   | 89.69\u00b11.14 | 88.98\u00b11.09 |\n\nFor the weight of the label consistency loss $\\alpha$, our results indicate that an $\\alpha$ value of around 1.0 yields optimal performance for the Amazon and YelpChi datasets, whereas a value of around 5.0 is preferable for the T-Finance dataset. Overall, the model performance remains stable with a moderate $\\alpha$ value. If $\\alpha$ is set to an excessively high value, the performance will be greatly impaired. This is likely due to the diminished diversity in generated augmentations, which is crucial for effective consistency training. \n\nRegarding the drop ratio $\\xi$, our results reveal that maintaining $\\xi$ within a range of 0.1 to 0.3 offers consistent benefits across all datasets. A smaller $\\xi$ reduces ConsisGAD to its backbone model, limiting its ability to harness unlabeled data effectively. Conversely, a higher $\\xi$ could lead to significant information loss, making it hard for the model to discern valuable patterns."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 16:36Everyone", "Content": "Comment:\n**3. Can the proposed GNN backbone effectively handle generic multi-class node classification tasks?**\nPursuant to your advice, we have extended our experiments to include graphs with low and high heterophily and discussed the results in Appendix E.8 of our revised manuscript. In this experiment, we adhere to the experimental procedure of a recent work, the Feature Selection Graph Neural Network (FSGNN) [a], and use their public repository for experimentation. Our evaluation encompasses three homophily graphs and six heterophily graphs, with homophily ratios ranging from 0.11 to 0.81. This range provides a comprehensive spectrum for performance assessment of our model. For your easy reference, we list the dataset statistics in the following table:\n\n|                |      Cora      |  Citeseer  |     Pubmed     |   Chameleon    |   Wisconsin    |     Texas      |    Cornell     |    Squirrel    |     Actor      | \n| :------------- | :------------: | :--------: | :------------: | :------------: | :------------: | :------------: | :------------: | :------------: | :------------: |\n| Hom. ratio     |      0.81      |    0.74    |      0.80      |      0.23      |      0.21      |      0.11      |      0.30      |      0.22      |      0.22      |\n| \\# Nodes       |     2,708      |   3,327    |     19,717     |     2,277      |      251       |      183       |      183       |     5,201      |     7,600      |\n| \\# Edges       |     5,278      |   4,732    |     44,338     |     36,101     |      499       |      309       |      295       |    198,353     |     26,659     |\n| \\# Features    |     1,433      |   3,703    |      500       |     2,325      |     1,703      |     1,703      |     1,703      |     2,089      |      932       |\n| \\# Classes     |       7        |     6      |       3        |       4        |       5        |       5        |       5        |       5        |       5        |\n\nWe maintain a consistent architecture for our GNN backbone, setting it to two layers, and conduct fine-tuning for learning rate and weight decay on each dataset. The model is evaluated in ten publicly available data splits, and the mean test accuracy is reported. For your convenience, we list the results as below:\n\n|                |      Cora      |  Citeseer  |     Pubmed     |   Chameleon    |   Wisconsin    |     Texas      |    Cornell     |    Squirrel    |     Actor      | Mean Acc. |\n| :------------- | :------------: | :--------: | :------------: | :------------: | :------------: | :------------: | :------------: | :------------: | :------------: | :-------: |\n| GCN            |   87.28\u00b11.26   | 76.68\u00b11.64 |   87.38\u00b10.66   |   59.82\u00b12.58   |   59.80\u00b16.99   |   59.46\u00b15.25   |   57.03\u00b14.67   |   36.89\u00b11.34   |   30.26\u00b10.79   |   61.62   |\n| GAT            |   82.68\u00b11.80   | 75.46\u00b11.72 |   84.68\u00b10.44   |   54.69\u00b11.95   |   55.29\u00b18.71   |   58.38\u00b14.45   |   58.92\u00b13.32   |   30.62\u00b12.11   |   26.28\u00b11.73   |   58.55   |\n| GraphSAGE      |   86.90\u00b11.04   | 76.04\u00b11.30 |   88.45\u00b10.50   |   58.73\u00b11.68   |   81.18\u00b15.56   |   82.43\u00b16.14   |   75.95\u00b15.01   |   41.61\u00b10.74   |   34.23\u00b10.99   |   69.50   |\n| Cheby+JK       |   85.49\u00b11.27   | 74.98\u00b11.18 |   89.07\u00b10.30   |   63.79\u00b12.27   |   82.55\u00b14.57   |   78.38\u00b16.37   |   74.59\u00b17.87   |   45.03\u00b11.73   |   35.14\u00b11.37   |   69.89   |\n| MixHop         |   87.61\u00b10.85   | 76.26\u00b11.33 |   85.31\u00b10.61   |   60.50\u00b12.53   |   75.88\u00b14.90   |   77.84\u00b17.73   |   73.51\u00b16.34   |   43.80\u00b11.48   |   32.22\u00b12.34   |   68.10   |\n| GEOM-GCN       |     85.27      | **77.99**  |     90.05      |     60.90      |     64.12      |     67.57      |     60.81      |     38.14      |     31.63      |   64.05   |\n| GCNII          |   88.01\u00b11.33   | 77.13\u00b11.38 | **90.30\u00b10.37** |   62.48\u00b12.74   |   81.57\u00b14.98   |   77.84\u00b15.64   |   76.49\u00b14.37   |      N/A       |      N/A       |     -     |\n| H2GCN-1        |   86.92\u00b11.37   | 77.07\u00b11.64 |   89.40\u00b10.34   |   57.11\u00b11.58   |   86.67\u00b14.69   |   84.86\u00b16.77   |   82.16\u00b14.80   |   36.42\u00b11.89   |   35.86\u00b11.03   |   70.71   |\n| WRGAT          |   88.20\u00b12.26   | 76.81\u00b11.89 |   88.52\u00b10.92   |   65.24\u00b10.87   |   86.98\u00b13.78   |   83.62\u00b15.50   |   81.62\u00b13.90   |   48.85\u00b10.78   |   36.53\u00b10.77   |   72.93   |\n| GPRGNN         | **88.49\u00b10.95** | 77.08\u00b11.63 |   88.99\u00b10.40   |   66.47\u00b12.47   |   85.88\u00b13.70   |   86.49\u00b14.83   |   81.89\u00b16.17   |   49.03\u00b11.28   |   36.04\u00b10.96   |   73.37   |\n| FSGNN          |   88.23\u00b11.17   | 77.40\u00b11.93 |   89.78\u00b10.38   | **78.95\u00b10.86** | **88.43\u00b13.22** | **87.57\u00b14.86** | **87.84\u00b16.19** | **74.10\u00b11.89** |   35.75\u00b10.96   | **78.67** |\n| CONSISGAD(GNN) |   86.32\u00b11.72   | 75.83\u00b11.81 |   89.39\u00b10.34   |   44.82\u00b12.96   |   86.47\u00b14.51   |   83.24\u00b15.77   |   83.51\u00b16.89   |   33.08\u00b10.79   | **37.38\u00b11.55** |   68.89   |"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 16:36 (modified: 18 Nov 2023, 16:37)EveryoneRevisions", "Content": "Comment:\nIt is important to note that our proposed GNN backbone, ConsisGAD(GNN), is specifically tailored to exploit the homophily distribution differences between normal and anomalous nodes. Such a phenomenon is characteristic in the graph anomaly detection task (i.e., the imbalanced binary classification task) where normal nodes have high homophily distribution while anomalous nodes have low homophily distribution. This prominent distribution discrepancy lays down the foundation of our GNN backbone. When it comes to multi-class node classification tasks, the homophily-aware neighborhood aggregation (Equation (4)) in our GNN backbone will model the neighbor label distribution within a node's neighborhood. If this neighborhood label distribution exhibits distinguishable patterns for different classes, we would expect our backbone model to function well. \n\nFrom the results, we observe that our GNN backbone model performs comparably to existing baselines in the three homophily graphs. Our GNN backbone is built upon the Message-Passing Neural Network (MPNN) framework, which allows handling homophily information naturally. For heterophily graphs, our backbone model yields promising results in the Wisconsin, Texas, and Cornell datasets, but encounters challenges in the Chameleon, Squirrel, and Actor datasets. Our further investigations in Figure 15 reveal that, in Wisconsin, Texas, and Cornell, nodes of different classes have distinct neighbor label distribution within their neighborhood, which allows our backbone model to distinguish different classes effectively. However, such distinct patterns are absent in Chameleon, Squirrel, and Actor, explaining the struggle of our backbone model on them. Notably, despite a low accuracy on the Actor dataset, our model achieves a new state-of-the-art result, underscoring its potential in handling heterophily graphs in generic multi-class node classification tasks. We recognize the opportunity for further enhancements, particularly on datasets where distinct neighborhood patterns are less pronounced. Future research may explore synergies between our GNN backbone model and other advanced techniques to elevate performance on heterophily graphs.\n\nWe hope these revisions and additional analyses address your concerns and strengthen the contribution of our work. We appreciate the constructive guidance you have provided, which has substantially improved the manuscript. If you have additional comments or concerns, we welcome your input and are ready to make any necessary adjustments. \n\n[a] Simplifying approach to node classification in graph neural networks. Sunil Kumar Maurya, Xin Liu, and Tsuyoshi Murata. Journal of Computational Science, 2022."}, {"Heading": "A Kind Reminder to Reviewer ZNLh", "Subheading": "Official CommentbyAuthors21 Nov 2023, 06:47 (modified: 21 Nov 2023, 06:53)EveryoneRevisions", "Content": "Comment:\nDear Reviewer ZNLh,\n\nThank you once again for your insightful feedback on our submission. We would like to remind you that the discussion period is concluding. To facilitate your review, we have provided a concise summary below, outlining our responses to each of your concerns:\n\n- **Part 1**: We conducted additional experiments to assess the quality of high-quality nodes. The results consistently demonstrated superior performance of high-quality nodes compared to test nodes.\n- **Part 2**: We conducted additional experiments to assess the sensitivity of our hyperparameters: the weight of the label consistency loss ($\\alpha$) and the drop ratio ($\\xi$).\n- **Part 3**: We evaluated our GNN backbone on a generic multi-class node classification task. The experiments comprised three homophily graphs and six heterophily graphs, with homophily ratios ranging from 0.11 to 0.81. Additionally, we conducted a detailed performance comparison analysis.\n\nWe are grateful for your insightful comments and are eager to confirm whether our responses have adequately addressed your concerns. We look forward to any additional input you may provide.\n\nWarm regards, \\\nThe Authors of Submission 9315."}, {"Heading": "increase score", "Subheading": "Official CommentbyReviewer ZNLh21 Nov 2023, 08:48 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nThanks for the authors' detailed rebuttal. It generally addresses my comments in the review. Thus, I increase my score and support this paper."}, {"Heading": "Appreciate Your Feedback", "Subheading": "Official CommentbyAuthors21 Nov 2023, 21:59 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nDear Reviewer ZNLh,\n\nWe sincerely value your constructive feedback, and we are delighted that our responses have effectively addressed your concerns. Your recognition of our efforts in the paper is greatly appreciated!\n\nWarm regards, \\\nThe Authors of Submission 9315."}]}, {"Heading": "Official Review of Submission9315 by Reviewer RZbU", "Subheading": "Official ReviewbyReviewer RZbU03 Nov 2023, 13:33 (modified: 23 Nov 2023, 09:35)EveryoneRevisions", "Content": "Summary:\nThis paper delves into the challenge of graph anomaly detection with limited supervision. To address this, the authors introduce ConsisGAD, a novel model rooted in consistency training. ConsisGAD leverages variance in homophily distribution between normal and anomalous nodes to craft an effective GNN backbone. The authors also propose a learnable data augmentation mechanism for consistency training using unlabeled data. The paper presents comprehensive experiments on benchmark datasets to validate the effectiveness of the proposed model.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\n1. The paper is well-structured and presented in a clear manner. It effectively communicates the motivation behind the proposed model, making it accessible to readers. \n\n2. The proposed model, comprising homophily-aware neighborhood aggregation and consistency training with learnable data augmentation, is innovative. The homophily-aware aggregation method is straightforward yet effective, especially for edge-level homophily representation, enhancing the anomaly detection process. The proposed label consistency and distribution diversity concepts are intriguing, guiding the optimization of learnable data augmentation.\n\n3. The paper demonstrates a thorough evaluation through extensive experiments, which strengthens the empirical foundation and validates the performance across different datasets.\nWeaknesses:\nWeaknesses:\n\n1. The paper should acknowledge related works that are pertinent to the proposed learnable data augmentation, such as [a] and [b]. It is crucial to cite and discuss the distinctions between these works and the proposed approach, providing readers with a clear understanding of the novel contributions made by this study.\n\n2. The paper predominantly explores the concept of applying learnable data augmentation for graph anomaly detection. While this is valuable, investigating its applicability in broader graph learning tasks, such as node classification with contrastive learning, could significantly expand its scope. For example, how about its benefits to generic graph contrastive learning tasks, compared to existing contrastive techniques?\n\n3. While consistency training might usually be deployed on unlabeled data, I wonder if it would be beneficial to utilize labeled data for consistency training as well. Specifically, labeled data has exact labels, which might provide effective information for consistency training the model in dealing with the taks of graph anomaly detection.\n\n\n[a] Graph Contrastive Learning Automated. Yuning You, Tianlong Chen, Yang Shen, Zhangyang Wang. ICML 2021\n[b] Graph Contrastive Learning with Adaptive Augmentation. Yanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, Liang Wang. WWW 2021.\nQuestions:\nPlease see the Weaknesses\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNA\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 16:38Everyone", "Content": "Comment:\nDear Reviewer RZbU,\n\nThank you for your insightful comments and constructive feedback on our submission 9315. We appreciate the time and effort you have invested in reviewing our work. Below, we address each of your comments to clarify and improve our manuscript:\n\n**1. The paper should acknowledge related works that are pertinent to the proposed learnable data augmentation, such as [a] and [b]. It is crucial to cite and discuss the distinctions between these works and the proposed approach, providing readers with a clear understanding of the novel contributions made by this study.**\n\nWe acknowledge the importance of referencing and discussing relevant related works. In Appendix F of our revised manuscript, we have included a discussion comparing our work with the studies of [a] and [b]. For your convenience, we summarize the distinctions between these two works and our proposed learnable data augmentation:\n\n- **JOint Augmentation Optimization (JOAO) [a]**: This work learns a sampling distribution to sample augmentation pairs for graph contrastive learning. It instantiates the learning process as a min-max optimization process, iteratively optimizing the GNN encoder and the learnable sampling distribution. Our work is different from JOAO in two aspects:\n  - **Evaluation of augmentation quality**: JOAO is based on the adversarial training framework and assumes that a good augmentation will cause a high contrastive learning loss. Intuitively, increasing contrastive loss is to increase the distribution diversity of augmentations. However, the label consistency is overlooked, which may cause excessive noise injected into augmentations and lead to suboptimal performance, as indicated in prior studies [c,d]. In contrast, our work assumes that a good augmentation will increase the diversity of a node without changing its label (i.e., high label consistency). To this end, we formulate differentiable distribution diversity and label consistency metrics to evaluate augmentation quality and to guide the training of our augmentation module.\n  - **Learning objectives**: The learning objective of JOAO is to pick the optimal augmentation pair from a pre-defined pool of augmentation types for graph contrastive learning. It requires domain knowledge to manually construct and configure the augmentation pool for selection. By contrast, our work introduces a novel learnable augmentation module through learnable masking. Our module learns to synthesize node-specific augmentations, evolving dynamically with the dataset and GNN encoder. \n\n- **Graph Contrastive learning with Adaptive augmentation (GCA) [b]**: GCA introduces a general graph contrastive learning framework and generates augmented graphs by adaptively dropping edges and node features. The drop rates of edges and node features are based on node centrality scores, incorporating topological and semantic priors in a graph. The node centrality scores include degree centrality, eigenvector centrality, and PageRank centrality. Our work is different from GCA in two aspects:\n  - **Evaluation of augmentation quality**: GCA assumes that a good augmentation should drop unimportant edges and features while keeping important ones. The importance is measured through node centrality scores. In this way, edges whose ending nodes have low centrality scores are more likely to be dropped, and feature dimensions appearing less frequently on important nodes are more likely to be masked. However, this heuristic approach may not guarantee high consistency and diversity in augmentations. On the other hand, our proposed model does not rely on node importance metrics but focuses on maximizing distribution diversity and label consistency in augmentations.\n  - **Learning objectives**: The adaptive augmentation module in GCA, when presented with an input graph, remains fixed and non-learnable throughout the training process. This is due to the static nature of node centrality scores, resulting in unchanging dropping rates for edges and node features. Moreover, this module operates independently of the specific GNN encoder employed. On the contrary, our learnable augmentation module is dynamic, updating continuously throughout training to adapt to the dataset and the evolving GNN encoder."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 16:39Everyone", "Content": "Comment:\n**2. The paper predominantly explores the concept of applying learnable data augmentation for graph anomaly detection. While this is valuable, investigating its applicability in broader graph learning tasks, such as node classification with contrastive learning, could significantly expand its scope. For example, how about its benefits to generic graph contrastive learning tasks, compared to existing contrastive techniques?**\n\nThank you for your insightful suggestion regarding the potential applicability of our learnable data augmentation in generic graph contrastive learning tasks. We acknowledge the value of this idea. However, our current model is not straightforwardly applicable to such tasks due to the specific requirements of our label consistency metric. In graph contrastive learning, which focuses on pre-training a GNN encoder without specific label information, our method faces challenges, as it depends on label predictions for unlabeled nodes to measure label consistency.\n\nOne potential approach to address this could involve clustering nodes in the input graph and then using these clusters as proxy labels to assess label consistency. Nevertheless, due to time constraints, we have not been able to explore this adaptation in the current study. We appreciate your suggestion and agree that expanding the applicability of our augmentation approach represents an exciting and valuable direction for future research. This would indeed enhance the versatility and impact of our learnable augmentation module and the proposed metrics for label consistency and distribution diversity. We are eager to explore this avenue in our future research, aiming to further broaden the scope of our work."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 16:40Everyone", "Content": "Comment:\n**3. While consistency training might usually be deployed on unlabeled data, I wonder if it would be beneficial to utilize labeled data for consistency training as well. Specifically, labeled data has exact labels, which might provide effective information for consistency training the model in dealing with the task of graph anomaly detection.**\n\nThank you for highlighting the potential benefits of utilizing labeled data for consistency training. In our current settings, both labeled and unlabeled data are used for consistency training, but labeled samples are treated as unlabeled, using their predicted labels instead of exact labels.\n\nEncouraged by your suggestion, we explore the impact of using exact labels for labeled nodes in consistency training. The results of this additional experiment are detailed in Appendix E.9 of our revised manuscript. For your convenience, we provide a summary in the table below:\n\n| Dataset    | Metric   | ConsisGAD (Predicted Label) | ConsisGAD (Exact Label) |\n|------------|----------|-----------------------------|-------------------------|\n| Amazon     | AUROC    | 93.91\u00b10.58                  | 93.82\u00b10.55              |\n|            | AUPRC    | 83.33\u00b10.34                  | 83.16\u00b10.46              |\n|            | Macro F1 | 90.03\u00b10.53                  | 89.88\u00b10.30              |\n| YelpChi    | AUROC    | 83.36\u00b10.53                  | 82.91\u00b10.36              |\n|            | AUPRC    | 47.33\u00b10.58                  | 47.23\u00b10.98              |\n|            | Macro F1 | 69.72\u00b10.30                  | 69.44\u00b10.29              |\n| T-Finance  | AUROC    | 95.33\u00b10.30                  | 95.09\u00b10.27              |\n|            | AUPRC    | 86.63\u00b10.44                  | 86.94\u00b10.13              |\n|            | Macro F1 | 90.97\u00b10.63                  | 91.32\u00b10.18              |\n| T-Social   | AUROC    | 94.31\u00b10.20                  | 93.87\u00b10.30              |\n|            | AUPRC    | 58.38\u00b12.10                  | 56.54\u00b11.86              |\n|            | Macro F1 | 78.08\u00b10.54                  | 77.42\u00b10.67              |\n\nOur findings indicate that using exact labels in consistency training does not significantly improve performance on most datasets. This lack of improvement may stem from the fact that labeled data has already been utilized in the cross-entropy loss, and their reuse in the consistency training does not contribute significantly to performance enhancement. Notably, a decrease in performance is observed in the T-Social dataset. We hypothesize this could be attributed to the model overfitting to label noise, which could be mitigated by the use of predicted labels.\n\nWe hope these revisions to our submission adequately address your concerns and enhance its overall contributions. Your thoughtful feedback has been crucial in elevating the quality and coherence of our manuscript. Should you have additional comments or concerns, we remain receptive and prepared to undertake any further modifications.\n\n[a] Graph Contrastive Learning Automated. Yuning You, Tianlong Chen, Yang Shen, Zhangyang Wang. ICML 2021.\n\n[b] Graph Contrastive Learning with Adaptive Augmentation. Yanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, Liang Wang. WWW 2021.\n\n[c] Instance adaptive adversarial training: Improved accuracy tradeoffs in neural nets. Yogesh Balaji, Tom Goldstein, and Judy Hoffman. arXiv preprint arXiv:1910.08051, 2019.\n\n[d] Robustness May Be at Odds with Accuracy. Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and Aleksander Madry. ICLR, 2018."}, {"Heading": "A Kind Reminder to Reviewer RZbU", "Subheading": "Official CommentbyAuthors21 Nov 2023, 06:48 (modified: 21 Nov 2023, 06:53)EveryoneRevisions", "Content": "Comment:\nDear Reviewer RZbU,\n\nThank you once again for your insightful feedback on our submission. We would like to remind you that the discussion period is concluding. To facilitate your review, we have provided a concise summary below, outlining our responses to each of your concerns:\n\n- **Part 1**: We elucidated the distinctions between our learnable data augmentation and other automated data augmentation methods, such as JOAO and GCA.\n- **Part 2**: We explored the application of our learnable augmentation module in generic graph contrastive learning tasks.\n- **Part 3**: We conducted further analysis on the effectiveness of utilizing the exact labels of labeled nodes in consistency training.\n\nWe are grateful for your insightful comments and are eager to confirm whether our responses have adequately addressed your concerns. We look forward to any additional input you may provide.\n\nWarm regards, \\\nThe Authors of Submission 9315."}, {"Heading": "A Further Kind Reminder to Reviewer RZbU", "Subheading": "Official CommentbyAuthors22 Nov 2023, 20:42 (modified: 22 Nov 2023, 20:44)EveryoneRevisions", "Content": "Comment:\nThanks a lot for your time in reviewing and insightful comments. We sincerely understand you are busy. But since the discussion due is approaching, would you mind checking the response to confirm where you have any further questions?\n\nWe are looking forward to your reply and happy to answer your further questions.\n\nWarm regards, \\\nThe Authors of Submission 9315"}]}, {"Heading": "Official Review of Submission9315 by Reviewer tbTo", "Subheading": "Official ReviewbyReviewer tbTo28 Oct 2023, 08:58 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper has addressed the challenge of graph anomaly detection under limited supervision by introducing a novel model, which effectively leverages the abundance of unlabeled data for consistency training by incorporating a novel learnable data augmentation mechanism. Furthermore, CONSISGAD exploits the disparity in homophily distribution between normal and anomalous nodes, enabling the formulation of a refined GNN backbone that enhances its discriminatory power between the two classes.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\n1. The logic of the whole paper is relatively clear and there are no obvious grammatical errors.\n\n2. There are quite sufficient experiments to verify the proposed method.\nWeaknesses:\n1) why Eq4 can achieve the edge-level homophily representation? where does it differ from GCN aggregation? \n\n2) as you said, GAD has low homophily distribution, whether  the homophily-aware neighbourhood aggregation you propose will be effective for abnormal nodes, I deeply doubt it.\n\n3) I don't find  the definition of Vhq in Section 2,  whiat is the meaning of Vun?\n\n4) please compare  your learnable augmentation with other augmentation methods  \n\n5) please give complexity analysis\nQuestions:\nsee above\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 16:40Everyone", "Content": "Comment:\nDear reviewer tbTo,\nThank you for your thoughtful and constructive feedback on our submission 9315. We appreciate the time you have taken to review our work and provide detailed insights. Below, we address each of the concerns and questions you raised.\n\n**1. Why Eq4 can achieve the edge-level homophily representation? Where does it differ from GCN aggregation?**\n\n*For the first question: Why Eq4 can achieve the edge-level homophily representation?*\n\nIn Eq.(4), the representation of an edge (e.g., $(v,u)$) is calculated using the representations of its two end nodes (e.g., $v$ and $u$) through the function $\\delta(\\cdot,\\cdot;\\theta_{\\delta})$. Furthermore, Eq.(4) aggregates these edge-level representations into the node representation of node $v$. Notably, the node representation ($\\mathbf{h}^l_v$) is calculated based on the distinctions in homophily distribution between normal and anomalous nodes, as discussed in the Introduction.\n\nThe cross-entropy loss function elicits inverse predictions for normal and anomalous nodes. Specifically, this loss function steers the edge representations of edges surrounding a normal node away from those surrounding an anomalous node, emphasizing their distinct homophily distributions. As a result, edges with high homophily around normal nodes share similar representations, while edges with low homophily around anomalous nodes exhibit analogous representations. Therefore, through this optimization process, Eq.(4) achieves disparate representations for high-homophily and low-homophily (high-heterophily) edges, ensuring edge-level homophily representations for edges around different nodes.\n\nTo validate the ability of the edge representations to capture edge-level homophily distribution, we conducted an analysis and visualized the results in Figure 3. The visualizations demonstrate that edges with the same homophily or heterophily labels can be well-clustered together. This indicates that the edge-level homophily representation adeptly reflects the type of edge homophily, forming a robust foundation for aggregation to represent the contextual homophily distribution of each node.\n\n*For the second question: Where does it differ from GCN aggregation?*\n\nOur backbone GNN model, as outlined in Eq.(4), diverges from the generic GCN model. Typically, GCNs utilize the fundamental operation of neighborhood aggregation to consolidate information from neighboring nodes and generate the representation of the target node. In contrast, our backbone GNN model emphasizes edge-level representation learning by modeling the homophily distribution of each edge for aggregation to generate node representations. Therefore, relying on the intuition of distinctions in homophily distribution, as discussed in the Introduction (Figure 1(b)), our model places greater emphasis on edge-level homophily representation to address the classification of normal and anomalous nodes. Furthermore, Tables 1 and 2 in the Experiments consistently demonstrate that our backbone GNN model outperforms the GCN model, underscoring its effectiveness in handling anomaly detection on graphs."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 16:41 (modified: 18 Nov 2023, 16:49)EveryoneRevisions", "Content": "Comment:\n**2. As you said, GAD has low homophily distribution, whether the homophily-aware neighbourhood aggregation you propose will be effective for abnormal nodes, I deeply doubt it.**\n\n\nWe sincerely apologize for any confusion that may have arisen, and we appreciate the opportunity to clarify this aspect of our work. In our study, we use the term \"homophily\" as a conceptual label, and it is important to note that \"heterophily\" could be interchangeably used in this context. Our model's primary goal with the homophily-aware neighborhood aggregation is to differentiate between the distinct distributions of homophily (or equivalently, heterophily) that are observed in the edges surrounding normal and anomalous nodes. Specifically, edges in the neighborhood of normal nodes typically exhibit high homophily (or low heterophily), whereas those around anomalous nodes tend to show low homophily (or high heterophily). The cross-entropy loss function in our model facilitates inverse predictions for normal and anomalous nodes. This means that the loss function strategically guides the edge representations surrounding a normal node to diverge from those around an anomalous node, aligning with their distinct homophily (or heterophily) distributions. Consequently, edges with high homophily around normal nodes share similar representations, while those with low homophily around anomalous nodes form analogous representations. This approach is critical for enhancing the discriminatory power of our model between normal and anomalous nodes, aligning with the core objectives of our research.\n\n**3. I don't find the definition of Vhq in Section 2, what is the meaning of Vun?**\n\nThank you for highlighting the need for clarity regarding the definition of $V_{hq}$ and $V_{un}$ in our paper. We appreciate the opportunity to elucidate this aspect of our work. $V_{un}$ is defined as the set of unlabeled nodes.\nIn the paragraph preceding Eq.(3), $V_{hq}$ represents the set of high-quality nodes, defined as $V_{hq}=\\\\{v \\mid v\\in V_{un} \\land \\exists \\mathbf{p}_v[k]\\ge\\tau\\\\}$. This set comprises unlabeled nodes for which there exists at least one predicted score in their predictions greater than the threshold $\\tau$. We have clarified this definition in our paper."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 16:50Everyone", "Content": "Comment:\n**4. Please compare your learnable augmentation with other augmentation methods.**\n\nThank you for your insightful suggestion.\nIn Appendix E.4, we benchmark our learnable data augmentation against several stochastic augmentation methods. Specifically, we substitute our augmentation module with widely-recognized techniques in the consistency training framework, including *DropNode* (Feng et al., 2020a), *DropEdge* (Rong et al., 2020), and *Dropout* (Srivastava et al., 2014). We administer Dropout to both input features, denoted as *DropInput*, and intermediate features, referred to as *DropHidden*. It is noteworthy that DropHidden serves as a non-learnable analogue to our augmentation module. For a fair comparison, we determine the optimal drop rate for each method within the interval of $(0, 0.5]$, with a step size of $0.1$. We list the optimal drop rate in Table 6. For your ease of reference, we also reported these optimal rates in the table below.\n\n| Methods| Amazon | YelpChi | T-Finance | T-Social |\n| --- | --- | --- | --- | --- |\n| ConsisGAD (DropInput) | 0.1 | 0.1 | 0.1 | 0.4 |\n| ConsisGAD (DropNode) | 0.2 | 0.1 | 0.1 | 0.5 |\n| ConsisGAD (DropEdge) | 0.2 | 0.1 | 0.1 | 0.3 |\n| ConsisGAD (DropHidden) | 0.3 | 0.1 | 0.2 | 0.1 |\n\nThe outcomes, depicted in Figure 9 through the three metrics, underscore the preeminence of our proposed learnable data augmentation over traditional stochastic alternatives.\nA salient observation is that among conventional augmentation methods, employing DropHidden in consistency training usually yields more substantial and stable performance improvements across all datasets. This empirical insight substantiates our decision to integrate learnable data augmentation at intermediate states and suggests the potential exploration of applying such augmentation to graph topology (Xia et al., 2022). For your easy reference, we also summarize the numerical results in the following table.\n| Dataset    | Metric   | ConsisGAD | ConsisGAD (DropInput) | ConsisGAD (DropNode) | ConsisGAD (DropEdge) | ConsisGAD (DropHidden) |\n| --- | --- | --- | --- | --- | --- | --- |\n| Amazon     | AUROC    | **93.91\u00b10.58** | 89.16\u00b10.53 | 91.47\u00b10.73 | 92.63\u00b10.45 | 92.71\u00b10.38 |\n|            | AUPRC    | **83.33\u00b10.34** | 74.01\u00b11.30 | 77.84\u00b11.03 | 80.22\u00b10.89 | 81.03\u00b11.00 |\n|            | Macro F1 | **90.03\u00b10.53** | 86.22\u00b10.93 | 85.58\u00b10.68 | 88.03\u00b10.81 | 87.78\u00b10.91 |\n| YelpChi    | AUROC    | **83.36\u00b10.53** | 81.68\u00b10.21 | 79.85\u00b10.26 | 80.70\u00b10.47 | 80.27\u00b10.39 |\n|            | AUPRC    | **47.33\u00b10.58** | 42.14\u00b10.52 | 40.14\u00b10.67 | 43.54\u00b10.27 | 43.50\u00b10.21 |\n|            | Macro F1 | **69.72\u00b10.30** | 68.22\u00b10.37 | 66.31\u00b10.47 | 67.34\u00b10.29 | 67.32\u00b10.44 |\n| T-Finance  | AUROC    | **95.33\u00b10.30** | 95.17\u00b10.23 | 95.07\u00b10.40 | 95.13\u00b10.49 | 94.58\u00b10.45 |\n|            | AUPRC    | **86.63\u00b10.44** | 84.87\u00b10.61 | 84.78\u00b10.31 | 85.43\u00b10.47 | 85.59\u00b10.43 |\n|            | Macro F1 | **90.97\u00b10.63** | 90.16\u00b10.33 | 90.02\u00b10.66 | 90.16\u00b11.02 | 90.31\u00b11.05 |\n| T-Social   | AUROC    | **94.31\u00b10.20** | 94.23\u00b10.16 | 94.04\u00b10.34 | 94.10\u00b10.25 | 94.13\u00b10.32 |\n|            | AUPRC    | **58.38\u00b12.10** | 55.32\u00b12.00 | 54.00\u00b12.11 | 55.33\u00b12.39 | 53.58\u00b12.41 |\n|            | Macro F1 | **78.08\u00b10.54** | 76.86\u00b10.98 | 76.35\u00b10.71 | 77.75\u00b10.57 | 77.48\u00b11.03 |"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 17:00Everyone", "Content": "Comment:\n**5. Please give complexity analysis.**\n\nAs illustrated in Algorithm 1, our model is composed of two primary components: consistency training and the training of the learnable data augmentation module. These components operate iteratively in each iteration of the process. This approach potentially incurs a higher computational cost compared to the standard training procedures of graph neural networks. In this part, we give a detailed complexity analysis and analyze the possibility of using it on large graphs.\n\nAt the outset, we focus on analyzing the complexity of our backbone GNN model, as outlined in Equation (4). This model is a critical component in Algorithm 1 for calculating node embeddings. Considering a target node $v$, in the first GNN layer, the function $\\delta(\\cdot,\\cdot;\\theta_{\\delta})$ is implemented as $\\text{MLP}(\\mathbf{h}^{l-1}_v||\\mathbf{h}^{l-1}_u)$. A typical example of this MLP is $\\sigma(\\mathbf{W}(\\mathbf{h}^{l-1}_v \\|\\| \\mathbf{h}^{l-1}_u)+\\mathbf{b})$. The computational complexity in this first layer is $O(2dd_X+\\bar{N}d+2d)$, where $d_X$ represents the dimension of the input feature vector, $d$ the intermediate dimension of the embeddings, and $\\bar{N}$ the average node degree. Each subsequent layer contributes an additional complexity of $O(2d^2+\\bar{N}d+2d)$. Given $L$ total GNN layers, the overall complexity of the GNN backbone sums up to $O(2dd_X+\\bar{N}d+2d+(L-1)(2d^2+\\bar{N}d+2d))=O(2dd_X+2Ld^2+2Ld+L\\bar{N}d-2d^2)$.\nIn every iteration of Algorithm 1, we sample a batch of labeled and unlabeled nodes for subsequent computations. These batches are of sizes $B$ (for labeled nodes) and $\\mu B$ (for unlabeled nodes), respectively. We can split the whole process into three step as follows.\n- We begin by selecting high-quality nodes from the sampled batch of unlabeled nodes. In line 6, the GNN backbone introduces a complexity of $O(2dd_X+2Ld^2+2Ld+L\\bar{N}d-2d^2)$, as previously analyzed. The prediction step in line 7 has a complexity of $O(Kd+2K)$, where $K$ is the number of classes. Lines 8-10 involve checking the high-quality nodes with a complexity of $K$. Overall, for a batch size of $B$, lines 5-10 collectively result in a complexity of $O(\\mu B(2dd_X+2Ld^2+2Ld+L\\bar{N}d-2d^2+Kd+3K))$.\n- Each high-quality node is augmented and predicted, forming the basis for the consistency and diversity loss calculations. For line 12, the complexity of the Sharpen function in Algorithm 2 involves $O(8\\lfloor \\xi d \\rfloor d+d)$ across its steps. Consequently, line 12 in Algorithm 1 incurs a complexity of $O(8\\lfloor \\xi d \\rfloor d+d^2+3d)$. Line 13, similar to line 7, involves a complexity of $O(Kd+2K)$. Line 14 includes forming both the consistency and diversity losses, with complexities of $O(\\mu BK^2)$ and $O(2\\mu Bd)$, respectively. Summing up, lines 11-14 entail a complexity of $O(\\mu B(8\\lfloor \\xi d \\rfloor d+d^2+3d + Kd+2K) + \\mu BK^2 + 2\\mu Bd)$.\n- The consistency training involves complexity calculations similar to the earlier sections. Lines 17 and 18, as previously analyzed, involve a complexity of $O(2dd_X+2Ld^2+2Ld+L\\bar{N}d-2d^2+Kd+2K)$. Lines 19 and 20, pertaining to the loss calculations, have complexities of $O(BK^2)$ and $O(\\mu BK^2)$, respectively. Thus, the total complexity for lines 16-20 over $B$ iterations is $O(B(2dd_X+2Ld^2+2Ld+L\\bar{N}d-2d^2+Kd+2K)+BK^2+\\mu BK^2)$.\n\nIn each iteration of Algorithm 1, we aggregate the complexities from the previous sections to derive the overall complexity. This can be expressed as $O(2B(\\mu+1)dd_X + B(2\\mu L+2L-\\mu-2)d^2 + (2\\mu BL+\\mu BL\\bar{N}+\\mu BK+8\\mu B\\lfloor \\xi d \\rfloor+5\\mu B+K\\mu B+2BL+BL\\bar{N}+BK)d + 5\\mu BK+2\\mu BK^2+2BK+BK^2)$.\n\nParticularly in our anomaly detection scenario, where typically $K = 2$ due to the binary classification nature, and $L$ generally ranges from 1 to 3 as the number of GNN layers, the complexity of our model is predominantly influenced by the feature dimension $d_X$, the hidden dimension $d$, and the average node degree $\\bar{N}$. This indicates that with appropriately set hyper-parameters, our model shows promising potential for application on large-scale graphs. To enhance the clarity of our paper, we have included this detailed complexity analysis in Appendix A of our revised manuscript.\n\n\nWe hope that these clarifications and additional details address your concerns and strengthen the paper's contributions. Your insightful feedback has been instrumental in refining the quality and coherence of our manuscript. Should there be any more comments or issues from your side, we remain open and willing to make the requisite modifications."}, {"Heading": "A Kind Reminder to Reviewer tbTo", "Subheading": "Official CommentbyAuthors21 Nov 2023, 06:49 (modified: 21 Nov 2023, 06:53)EveryoneRevisions", "Content": "Comment:\nDear Reviewer tbTo,\n\nThank you once again for your insightful feedback on our submission. We would like to remind you that the discussion period is concluding. To facilitate your review, we have provided a concise summary below, outlining our responses to each of your concerns:\n\n- **Part 1**: We provided further details on how our homophily-aware neighborhood aggregation (Eq.4) achieves edge-level homophily representation and explained its distinctions from GCN aggregation.\n- **Part 2**: We offered additional clarifications on our homophily-aware neighborhood aggregation.\n- **Part 3**: We clarified the definitions of $V_{hq}$ and $V_{un}$.\n- **Part 4**: We conducted a comparative analysis of our learnable data augmentation against four stochastic augmentation methods for graph anomaly detection.\n- **Part 5**: We presented a detailed complexity analysis of our algorithm.\n\nWe are grateful for your insightful comments and are eager to confirm whether our responses have adequately addressed your concerns. We look forward to any additional input you may provide.\n\nWarm regards, \\\nThe Authors of Submission 9315."}, {"Heading": "A Further Kind Reminder to Reviewer tbTo", "Subheading": "Official CommentbyAuthors22 Nov 2023, 20:43 (modified: 22 Nov 2023, 20:44)EveryoneRevisions", "Content": "Comment:\nThanks a lot for your time in reviewing and insightful comments. We sincerely understand you are busy. But since the discussion due is approaching, would you mind checking the response to confirm where you have any further questions?\n\nWe are looking forward to your reply and happy to answer your further questions.\n\nWarm regards, \\\nThe Authors of Submission 9315"}]}]}, "QAq5JTFJmp": {"paper_info": {"Keywords": "Knowledge Distillation", "Abstract": "Knowledge distillation is a widely studied technique for transferring knowledge from a large teacher model to a smaller student model, with the aim of maintaining high performance while reducing computational complexity. However, the performance of the student model often suffers when the teacher model is overly large. \nWe observe significant differences in the ability of teacher and student models to minimize losses, with student models exhibiting higher entropy. This underscores the inherent difficulty in transferring knowledge from the more complex teacher model to the simpler student model. Through theoretical analysis, we propose a straightforward intermediate alignment module to narrow the entropy gap between the student and the teacher, thus enhancing the student performance. \nCompared with vanilla distillation, the proposed method has the potential to improve the performance of the student model when the teacher model is significantly large, paving the way for more efficient and powerful model learning techniques in the field of knowledge distillation.", "Supplementary Material": "zip", "Primary Area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9314", "PDF Url": "https://openreview.net/pdf?id=QAq5JTFJmp"}, "review_info": [{"Heading": "variance of the results", "Subheading": "Public CommentbyPeter Chen20 Nov 2023, 13:43Everyone", "Content": "Comment:\nDear author, is it possible to release the official implementation of the paper, after multiple trials, we failed to reproduce your results, with high variance.\nBest"}, {"Heading": "Public Comment", "Subheading": "Public Commentby16 Nov 2023, 19:04 (modified: 16 Nov 2023, 19:09)EveryoneRevisions", "Content": "[Deleted]"}, {"Heading": "Official Review of Submission9314 by Reviewer dqtM", "Subheading": "Official ReviewbyReviewer dqtM03 Nov 2023, 09:14 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper focuses on the performance degradation of student models when the teacher model is significantly large. The authors provide theoretical results on the discrepancy of student and teacher models, in terms of entropy rates & free energy. The authors also suggested spherical knowledge distillation, which is shown to perform well on multiple benchmarks.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe authors tested their scheme for multiple settings.\nThe empirical results are promising for some cases.\nWeaknesses:\nThe theoretical results are quite easy to derive. From the definition, entropy and free energy is bit related, so figuring out the relationship in the distillation setup does not seem to be a critical contribution.\nIt is unclear why simple normalization of logics (as in eq.15) is motivated by the theoretical results. The authors say \u201cIt can be seen that ||v||^2 - ||z||^2 plays a key role and can be removed by normalization techniques\u201d, but why are we removing the important term having key role?\nI personally believe current theoretical explanation is not enough to justify why spherical KD is working much better than vanilla KD.\nQuestions:\nIt\u2019s a minor issue, but the title in the manuscript is different from the title in the console.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9314 by Reviewer YbW2", "Subheading": "Official ReviewbyReviewer YbW202 Nov 2023, 11:54 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper investigates knowledge from the entropy perspective and proposes a knowledge distillation method by first normalizing the logits and then minimizing the KL-divergence. In this way, the entropy gap can be reduced. Experiments on CIFAR-100 and ImageNet are conducted and show promising results.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThis paper is easy to follow.\nThe proposed method is easy to implement.\nComparison with different methods are reported.\nWeaknesses:\nThe improvement is minor. As shown in Table 4, there is almost no improvements over CRD (ICLR'2020).\nThe proposed method of normalizing the logits is not a big contribution, since normalizing the logits is widely used in metric learning and few-shot learning literature.\nQuestions:\nFirst, this paper defines entropy gap, which I think is reasonable. Then, this paper simply assumes a small entropy gap leads to a better performance and proposes a method to minimize the entropy gap. However, there is no theory or comprehensive experiments supporting this assumption. When this assumption works, and for what kinds of teacher and student networks?\nCRD was proposed in 2020. Recent SOTA approaches are not compared.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9314 by Reviewer kj6Z", "Subheading": "Official ReviewbyReviewer kj6Z19 Oct 2023, 21:52 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper analyzed reasons of performance degradation of distilling knowledge from an overly large teacher model to the student, and proposed to narrow entropy gap and free energy gap between the student model and the teacher model.  Through theoretical analysis, the paper proposed an alignment  module to narrow these gaps, thus enhancing the student performance.  Experiment results validated the effectiveness of the proposed alignment module.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe paper provided theoretical analysis. And, these mathematical proof is easy to understand\nThe author's writing is very good, and the entire paper is relatively easy to understand\nWeaknesses:\nThe contribution of this method is not very important. In section 4, the authors summarized that \"Different from Xu et al. [35] that normalizes the features in the penultimate layer of the network to perform distillation, our methods perform normalization on the logits layer.\".  Although the paper is different from Xu et al. [35], it is not difficult to derive this method from Xu et al. [35].\nThe paper proposed two metrics (entropy gap and free energy gap) to evaluate the gap of the student and the teacher. They are very close as shown in Eq. 9 and Eq.13, so they cannot provide more information from different perspectives.\nSome important works are missing and not to compare, e.g. Zhao, Borui, Quan Cui, Renjie Song, Yiyu Qiu and Jiajun Liang. \u201cDecoupled Knowledge Distillation. 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2022): 11943-11952.\n|| * || is not exactly indicated, it is better to add explanations, e.g. L1 or L2, or others\nQuestions:\nWhen proving equation 8, the Taylor expansion is a first-order expansion, and when proving equation 12, the Taylor expansion is a second-order expansion. Why use different formulas?\nThere are no experiments showing the combination of SKD with other KD methods. SKD adds an alignment module, so it can be directly combined with other KD methods. Can it improve the performance of other KD methods?\nIn section 3, there are duplicate descriptions \", e.g. Learning rate is dropped at 30, 60, 80 and 90 epoch.\" and \"learning rate dropped by 0.1 in 30, 60, 80, 90 epoch\".\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}]}, "O3BaKCxTAO": {"paper_info": {"Keywords": "Convolutional Neural Network, Singularly Perturbed PDEs, Stabilization Scheme", "Abstract": "This paper introduces ConvStabNet, a convolutional neural network that\npredicts optimal stabilization parameters for the Streamline Upwind Petrov\nGalerkin method (SUPG) stabilization scheme. To enhance the accuracy of\nSUPG in solving partial differential equations (PDE) with interior and bound-\nary layers, ConvStabNet incorporates a loss function that combines a strong\nresidual component and a cross-wind derivative term. ConvStabNet utilizes\na shared parameter scheme, enabling the network to learn the correlations\nbetween cell properties and their respective stabilization parameters while\neffectively managing the parameter space. Comparative evaluations against\nstate-of-the-art neural network solvers based on variational formulations\ndemonstrate the superior performance of ConvStabNet. The results affirm\nConvStabNet as a promising approach for accurately predicting stabilization\nparameters in SUPG, thereby establishing it as an improvement over neural\nnetwork-based SUPG solvers", "Primary Area": "applications to physical sciences (physics, chemistry, biology, etc.)", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9313", "PDF Url": "https://openreview.net/pdf?id=O3BaKCxTAO"}, "review_info": [{"Heading": "Official Review of Submission9313 by Reviewer ptK7", "Subheading": "Official ReviewbyReviewer ptK731 Oct 2023, 20:25 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nNumerical solution of advection-dominated PDEs, such as Singularly Perturbed Partial Differential Equations (SPPDEs) is a nontrivial task. Galerkin methods alone may produce oscillations or spurious solutions. The SUPG method introduces a stabilizing term that takes into account the flow direction, effectively handling the convection effects and improving the accuracy of the solution. Comparison of equations 6 and 8 clarifies the impact of added term, which is proportional to cell-wise \\tau_K. The solution is sensitive to such stabilization parameter to avoid over-damping (large values) or numerical stability (small values). Such stabilization parameter field is learned via convolutional network, to account for 2D fields as input and retain the connectivity/neighborhood information. Algorithm 1, along with figure 1 clarifies the method, along with the choice of parameters, input, output and more importantly the choice of loss function. Various examples are solved and compared with SOTA (based on equation 9) in section 4.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper is well written. The numerical method is valid and the paper can sit well in the computational PDE community. Comparison with one-dimensional approximation is an appropriate baseline. Examples are in the context of advection dominated PDE class and relevant. Weak form formulation is introduced properly, given the space of the paper. The choice of loss function is meaningful and nontrivial.\nWeaknesses:\nMy major concern of this paper is the scope. Even in the context of stabilizing the weak formulation for CFD applications one may think of alternative methods such as Petrov-Galerkin (PG) or its variants like Discontinuous Galerkin or cross-wind  stabilization methods. Authors can argue that for the specific advection dominated PDEs, SUPG may be superior but this not a very major contribution. This paper can be good candidate for numerical journals (and even then authors may want to solve more complicated examples or geometries; the current examples are really not very challenging) but due to its limited scope and not involving examples have a limited scope of applications. \nI also have some questions which I'll refer to below section.\nQuestions:\nInspired by variational PINNs and the use of SUPG is an interesting problem formulation. But could authors formulate the problem as parameter-dependent PINNs, such as the ones arise in inverse problems: the loss function includes the governing equation plus a regularization term (which could be of the form of residual introduced in equation 7) and the input is collocation points (spatial coordinates) plus \\tau_K? Authors don't need to actually solve such alternative formulation but it would be nice to have a conversation about this.\nAlternatively, can one alter the architecture of the paper and use the trained network as the solution of PDE itself? This may be done by having u in addition to \\tau_K as output (loss function may need modification too).\nThere are various typos in the paper; for instance at page 5 Figure ?? is shown which should be modified in the original latex. Also, at the end pf page 8, the text is not legible. Please improve the quality of the paper in the revised version.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9313 by Reviewer pFUX", "Subheading": "Official ReviewbyReviewer pFUX29 Oct 2023, 18:55 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper introduces a novel approach to address the stabilization issue that is raised when solving perturbed partial derivative equations (PPDEs) using some physic informed neural networks (PINNs). While the current approaches predict the stabilization parameter globally, the authors suggest to learn a parameter that take different values for each cell of the 2D grid. To do so, the authors use a convolutional network that is learned using an iterative procedure. The paper presents some numerical experiments showing the efficiency of their approach against some approaches from the literature.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper introduces a method that addresses a specific issue raised in the resolutions of  PPDEs using ML methods. The learning methodology is well explained and the numerical experiments show that the resulting error obtained is lower than the other PINNs-based approaches.\nWeaknesses:\nIn my opinion, the paper has several major weaknesses.\nMajor comments:\nAlthough the efficiency of the overall approach is proved on several numerical experiments, the paper attempts to address an issue that seems to be very specific, which makes the contribution of the paper relatively low compared to ICLR standards. In my opinion, the positioning of the paper would make it more suitable for submission to physics journal. To be clear, the contribution is relevant for the domain, but the contribution to the ML aspect is not significant.\nThe cross-wind derivative term seems to play an important role in the efficiency of the approach. However, there is a lack of clarity on its meaning for a non-expert reader. The authors claim that this is a crucial point without providing the intuition behind its use.\nOne of the main weakness of the paper is the numerical experiment section. The authors introduce several examples from the literature, but they report the error for only one of them (Example 2). The qualitative comparison is also difficult to understand. The authors claim that the approach captures varying coefficient and local details, \"enhancing the fidelity of the results\". What does it mean exactly? Is this learned stabilization parameter theoretically approved? In my opinion, capturing local details does not necessarily mean that the reconstructed solution has a better accuracy.\nMinor comments:\nIn the introduction, the authors explain that the value of the stabilization parameter has to be carefully chosen. Could the authors provide more details about the trade-off? Why do we want to keep a reasonable amplitude of oscillations?\nThere is a compiling problem at the end of the numerical experiments section.\nQuestions:\nSee comments above.\nIs the code publicly available?\nDepending on authors responses, I would change my score.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9313 by Reviewer WvoG", "Subheading": "Official ReviewbyReviewer WvoG24 Oct 2023, 16:16 (modified: 30 Nov 2023, 11:50)EveryoneRevisions", "Content": "Summary:\nThe submission studies a CNN-based strategy to \"learn\" the stablization paramater for the Streamline Upwind Petrov-Galerkin method for convection-dominated problems. Due to flawed philosophy to design the method in the first place, I cannot recommend acception.\nSoundness:\n1 poor\nPresentation:\n3 good\nContribution:\n1 poor\nStrengths:\nConvection-dominated convection-diffusion equation is important in many problems (MHD, EM, fluid, etc), and its accurate numerical approximation still poses many open problems in the scientific computing community. This paper studies one of them, the optimal stabilization parameter\n\u03c4\nK\nin 2D for the SUPG discretization of the convection-dominated problem.\nThe use of\nb\nK\nand\n\u2225\n\u2207\nu\nh\n\u2225\n0\n,\nK\nas different input channels of CNN is a good practice (though the references are missing).\nWeaknesses:\nThere are several major weaknesses, and all of them, most likely, attribute to the authors' misunderstanding of the cause of the problem of \"spurious oscillations\" for numerical methods for convection-dominated problems, as well as what SUPG is trying to do (or rather to say, what compromises, in terms of consistency vs stability, does SUPG make to get the ball rolling).\nFor example, on page 3, it says \"A small value of\n\u03f5\noften induces spurious oscillations in the standard Galerkin solution.\", this is wrong. If the mesh is sufficiently fine, or the mesh can resolve the crosswind in a certain way, there will be no spurious oscillations for even standard Galerkin approximations. Please see all those studies in the anisotropic meshing for convection-dominated problems.\nContinuing the point above, why meshing is more important than\n\u03c4\nK\nis simply because on a given mesh (that is not fine enough to resolve the layers),\n\u03c4\nK\ncannot be chosen to resolve the interior layer perfectly with no oscillation, and at the same time gives a good non-over-smoothened solution. For example, the plot of\nu\nh\nin Figure 2 looks like the typical over-smoothened ones.\nOne reason that the oscillation is present is because the numerical solution does not satisfy the (discrete) maximum principle (or not monotone per se).  The maximum principle guarantees no interior maximum (thus no oscillation) is achieved on either side of the characteristics (where the sharp layers are located). The authors did not acknowledge all the developments of monotone methods for convection-dominated problems. For example, a Scharfetter\u2013Gummel type exponential fitting scheme for the linear finite element can eliminate the oscillations completely (on a mesh SUPG either over-stablizes and cannot resolve the interior layer, or under-stablizes thus oscillatory). Please check the figures in Xu-Zikatanov 1999 Math. Comp. paper to see what a non-oscillatory non-over-smoothened numerical solution is like.\nThe authors claimed the standard SUPG stabilization parameter \"lacks extendability to high-dimensional problems\", in fact, people in this field have known the criterion in higher dimensions for a long time.  You want a decent amount of diffusion in the direction of streamlines/characteristics to make the coercivity robust in the\n\u03f5\n-weighted SUPG norm (so you want it sufficiently big), but without making too much compromise in the (local) consistency (so you want it as small as possible). The optimal choice should in fact the solution to a saddle-point problem (constraint minimization) locally,\nNOT globally\nlike the ones obtained using Alg 1 line 9 in this submission. For example, see A. Russo 1996 CMAME paper which analyzes what condition the stabilizing bubble should satisfy. This point brings the next point.\nThe loss function is said to be \"inspired\" by the error indicators in John-Knobloch-Savescu 2011 CMAME paper. However, in that paper,\n\u03c4\nK\nis solved through the critical point argument of the error functional (solution to an adjoint variational problem in\nL\n\u221e\n, an analogy in optimization would be the convex conjugate to a saddle point problem). Not a direct minimization.\nMinor ones\nHere are the list of minor weaknesses such as typos, unidiomatic notations, wrong claims.\nAll the equation references seems to have an extra \"equation\" due to some macro setup, for example, on page 2: \"In Equation equation 1, ...\", \"Lossequation 3\", and \"In Equation equation 3, ...\", and this error carries on to later pages as well.\nThe authors give the problem of interest, the Singularly Perturbed Partial Differential Equations, the acronym the SPPDEs. In my opinion, this is misleading, because there is singularly perturbed reaction-diffusion equation (which does not need SUPG). The keyword here should be \"convection-dominated\", i.e., convection-dominated convection\u2013diffusion equations.\nOn Page 4, if\n\u03a9\nh\nis a partition of\n\u03a9\n(triangulation, Cartesian grid, polytopal, etc), then\nH\n1\n(\n\u03a9\nh\n)\nin many occasions represents the\npiecewise\nH\n1\nspace with respect to this partition, i.e.,\nH\n1\n(\n\u03a9\nh\n)\n:=\n\u03a0\nK\n\u2208\n\u03a9\nh\nH\n1\n(\nK\n)\n, not a finite dimensional subspace. For example, please see the Arnold-Brezzi-Cockburn-Marini 2002 SINUM paper (about discontinuous Galerkin methods).\nEquation (8) on page 4, if the authors ought to write the weak formulation in the Galerkin form, then the part involving\n\u03c4\nK\n(\nf\nh\n,\nb\n\u22c5\n\u2207\nv\nh\n)\nK\nconventionally appears on the right hand side, because\na\nSUPG\n(\n\u22c5\n,\n\u22c5\n)\nis a bilinear form for\nu\nh\nand\nv\nh\nand this term is not a part of any bilinear form (see e.g., John-Knobloch-Savescu 2011 CMAME paper in the reference). Alternatively, the left hand side of the equation is sometimes written as\na\n(\nu\nh\n,\nv\nh\n)\n+\n\u2211\nK\n(\nR\nK\n(\nu\nh\n)\n,\n\u03c4\nK\nb\n\u22c5\n\u2207\nv\nh\n)\nK\nwhere\na\n(\nu\nh\n,\nv\nh\n)\nis the usual Galerkin bilinear form (see e.g., John-Knobloch 2007 CMAME paper in the reference).\nPage 4, if the authors meant to represent\nf\nas discretized in the context of computing the integral quadrature, then both\nf\n's in (6), (8) should be\nf\nh\n. Right now they are mixed together.\nPage 5, the author claims \"the function\nq\n(\ns\n)\ncorresponds to the cross-wind derivative term\", this is imply wrong. The cross-wind directional derivative is\nb\n\u22a5\n\u22c5\n\u2207\nu\nh\n. Judging by the form of\nq\n(\n\u22c5\n)\n, it is a common tool that guarantees that the cross-wind derivative is still differentiable at 0 (due to the presence of the absolute value) in the context of John-Knobloch-Savescu 2011 CMAME paper.\nPage 4, the local P\u00e9clet number should have\nh\nK\nnot\nh\n.\nSometimes, the flow field is denoted using boldface\nb\n, while on some other occasions it is just\nb\n(equation (7)).\nSometimes, the mesh size is denoted by\nh\nK\n(section 2.3), while on some other occasions it is\nh\nK\n.\nPersonally, I would not use \"advection\" and \"convection\" to describe the same term in the same paper.\nQuestions:\nThe questions following are more like weaknesses, however, when re-submitting to a conventional computational physics/math venue, it is suggested that the authors adding these in the reports, as well as fixing the erroneous claims mentioned above (mostly about the finite element methods for convection-dominated problems). A good proof-read from a person familiar with finite element methods for convection-dominated problem is helpful as well.\nThe key quantity in the loss function,\n\u2225\n\u22c5\n\u2225\n0\n,\n1\n,\nK\nnorm goes undefined.\nWhile it is okay to report\nL\n2\n-error,\nL\n\u221e\n-error, and\nH\n1\n-error, it is the tradition to report the error associated with the bilinear norm (aka SUPG norm).\nPage 7 Table 1, if the mesh size halves, the number of cells should quadrupled in 2D. The table is wrong. The order of convergence does not match any of the numbers in the table either.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes"}]}, "Iyve2ycvGZ": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "flow matching, generative model, efficient sampling, distillation, responsible ML", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "This paper introduces Bellman Optimal Step-size Straightening (BOSS) technique for distilling flow-matching generative models while adhering to a computational budget constraint.", "Abstract": "Flow matching is a powerful framework for generating high-quality samples in various applications, especially image synthesis. However, the intensive computational demands of these models, especially during the finetuning process and sampling processes, pose significant challenges for low-resource scenarios. This paper introduces Bellman Optimal Stepsize Straightening (BOSS) technique for distilling flow-matching generative models: it aims specifically for a few-step efficient image sampling while adhering to a computational budget constraint. First, this technique involves a dynamic programming algorithm that optimizes the stepsizes of the pretrained network. Then, it refines the velocity network to match the optimal step sizes, aiming to straighten the generation paths. Extensive experimental evaluations across image generation tasks demonstrate the efficacy of BOSS in terms of both resource utilization and image quality. Our results reveal that BOSS achieves substantial gains in efficiency while maintaining competitive sample quality, effectively bridging the gap between low-resource constraints and the demanding requirements of flow-matching generative models. Our paper also fortifies the responsible development of artificial intelligence, offering a more sustainable generative model that reduces computational costs and environmental footprints. Our code can be found athttps://github.com/nguyenngocbaocmt02/BOSS.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "generative models", "Submission Number": "9312", "PDF Url": "https://openreview.net/pdf?id=Iyve2ycvGZ"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9312 by Area Chair NEBb", "Subheading": "Meta ReviewbyArea Chair NEBb12 Dec 2023, 11:20 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper utilizes dynamic programming for optimizing the step sizes to sample a pre-trained flow model. As a second step it refines the pre-trained model's weights to further improve the straightness of the sampling paths. The methods offers an improved image quality at an improved computational cost and a novel optimization for step-sizes using dynamic programming. During rebuttal the authors addressed the issues of missing comparisons to performant baseline sampling methods and missing resource/running time analysis. The reviewers felt the paper offers a sufficient contribution to justify acceptance of the paper.\nJustification For Why Not Higher Score:\nThe sampling efficiency improvement offered by this method is still somewhat limited compared to the effort in designing and optimizing the solver. This is true especially in view of non-model-dependent methods used for efficient sampling of flow models.\nJustification For Why Not Lower Score:\nThe paper introduces a novel step-size optimization for solvers of generative flow models which can be further developed and incorporated within other/future solver methods."}, {"Heading": "A general response to reviewers", "Subheading": "Official CommentbyAuthors20 Nov 2023, 11:41 (modified: 20 Nov 2023, 12:01)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewers for taking their time to provide us with valuable feedback. We have incorporated these suggestions into the modified version of our submission, with added elaborations and new results/plots, with additional datasets. Please refer to the updated pdf of the submission file. These new results, in additional with existing ones, show that within limited budget of resources, the proposed method BOSS achieves significantly better performance compared to other methods in terms of FID score.\nBelow are our general replies to the general concerns from the reviewers. We also make specific replies to each reviewer\u2019s comment section.\nNeed more comprehensive benchmarks\nWe have added LSUN bedroom dataset + modified Tables 1 and 2 (FID for 4-6-8 NFEs) for redress/reflow for the CIFAR/CelebA/Church/Bedroom/AFHQ dataset.\nWe have added plots (Figure 4) demonstrating the decrease of FID with an increasing number of function evaluations (NFEs) across different sampling schemes and datasets.\nWe have added qualitative comparisons for different datasets (celebA, LSUN, AFHQ) on page 9 (Figure 5) and in the Appendix.\nResource requirements/memory usage/power consumption/processing time of the proposed method.\nWe have added in Appendix A the average GPU hours, estimated on training using NVIDIA RTX A5000.\nMore elaboration on the Dynamic Programming\nWe have added Appendix B that provides a pseudocode and details on our Dynamic Programming algorithm.\nWe also apologize for replying late into the rebuttal period. We still hope that the reviewers can take their time to review our replies, and we are eager to address any further concerns or questions from the reviewers."}, {"Heading": "Official Review of Submission9312 by Reviewer TqqW", "Subheading": "Official ReviewbyReviewer TqqW05 Nov 2023, 19:11 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe author introduces the Bellman Optimal Step-size Straightening (BOSS) technique, a method for distilling flow-matching generative models that enhances the efficiency of image sampling within computational budget constraints. BOSS utilizes dynamic programming to optimize step sizes in a pretrained network and refines the velocity network to straighten generation paths. In this paper, the proposed method has been extensively evaluated on image generation tasks, showing that it significantly improves resource efficiency and maintains high image quality. This approach serves to reconcile the intensive computational demands of flow-matching models with low-resource availability, contributing to the sustainable development of artificial intelligence by reducing computational expenses and environmental impacts.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe BOSS (Bellman Optimal Step-size Straightening) method presents an innovative two-phase approach for adapting pretrained flow-matching models. This paper illustrates that BOSS can straighten the velocity network with approximately 10,000 retraining iterations, which marks a significant improvement in efficiency compared to standard practices. Consistently, BOSS achieves lower FID scores in the task of unconditional image generation across a variety of datasets, suggesting superior image quality relative to competing methods. Moreover, the paper introduces a distinctive methodology for calculating optimal sampling step sizes through dynamic programming, thereby increasing the sampling process's efficiency.\nWeaknesses:\nAlthough the paper demonstrates significant improvements in image quality and efficiency, its testing is concentrated on specific datasets. A more comprehensive comparative analysis with current state-of-the-art methods would elucidate the advancements BOSS provides, especially in efficiency and quality. Additionally, while the paper addresses low-resource scenarios, it lacks a clear comparison of resource requirements such as memory usage, power consumption, or processing time, essential for evaluating BOSS's practicality for users with limited computational resources. Furthermore, despite the method's enhancements over existing approaches, the computational intensity of the dynamic programming algorithm and the network retraining requirement could limit its utility in resource-constrained settings. The scalability of BOSS, with respect to increasing dataset sizes or complexity, is also not addressed, and an evaluation of this aspect would greatly benefit the paper's comprehensiveness.\nQuestions:\nCould the authors extend their testing to include a broader range of datasets and perform a comprehensive comparative analysis with current state-of-the-art methods to better highlight the efficiency and quality improvements of the BOSS method? \nCan the paper provide a detailed comparison of resource requirements, such as memory usage, power consumption, or processing time, to evaluate the practicality of BOSS for users with limited computational resources? \nHow does the computational intensity of the dynamic programming algorithm and the network retraining requirement impact the method's applicability in resource-constrained environments?\n Additionally, has the scalability of BOSS been assessed in relation to increasing dataset sizes or complexity, and if not, would the authors consider evaluating this to enhance the paper's comprehensiveness?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reponse to Reviewer TqqW", "Subheading": "Official CommentbyAuthors20 Nov 2023, 11:48 (modified: 20 Nov 2023, 12:10)EveryoneRevisions", "Content": "Comment:\nA more comprehensive comparative analysis with current state-of-the-art methods would elucidate the advancements BOSS provides, especially in efficiency and quality.\nWe have added more baseline methods and additional datasets to showcase the effectiveness of our proposed algorithm. The new results can be found in [Tables 1 & 2], together with Figure 4 (quantitatively) and Figure 5 (qualitatively) of our paper.\nIt lacks a clear comparison of resource requirements such as memory usage, power consumption, or processing time, essential for evaluating BOSS's practicality for users with limited computational resources.\nWe have added a paragraph inside the main text of our paper focusing on this point. Please find below a copy of it.\nThe pre-trained models are finetuned by three methods including Uniform-Reflow, Distill-k Reflow, and BOSS  in 12000 iterations. An iteration is the passing and backpropagation process for a batch including 15 samples. Due to the similar cost of training between finetuning methods, we report the average GPU hours consumed on each pre-trained model up to 12000 iterations, using NVIDIA RTX A5000.\nCIFAR10: 3.56 training hours.\nCelebA-HQ: 10.35 training hours.\nLSUN-CHURCH: 13.43 training hours.\nLSUN-BEDROOM: 14.23 training hours.\nAFHQ-CAT: 9.30 training hours.\nWith this limited budget of resources, the proposed method BOSS achieves significantly better performance compared to other methods in terms of FID score.\nDespite the method's enhancements over existing approaches, the computational intensity of the dynamic programming algorithm and the network retraining requirement could limit its utility in resource-constrained settings.\nWe have added a section in the Appendix (Section 3) with a pseudocode that provides details on our Dynamic Programming algorithm. The time complexity of this algorithm is $O((K^{max})^2 \\times K)$. The choice of $K^{max}$ is crucial, aiming for the Euler sampling method with $K^{max}$ stepsizes to precisely replicate the trajectory of the Ordinary Differential Equation (ODE). Typically, $K^{max}$ falls within the range of 100 to 1000, ensuring accuracy. Given this range for $K^{max}$ and the variable $K$ ranging from 2 to 1000, the algorithm executes within seconds in all scenarios. Moreover, our solved problem is fast sampling in flow-matching models which focuses on relatively small values of K (<20), so the intensity of the dynamic programming algorithm is not a worrying problem even in the case that $K^{max} > 1000$.\nThe scalability of BOSS, with respect to increasing dataset sizes or complexity, is also not addressed, and an evaluation of this aspect would greatly benefit the paper's comprehensiveness. How does the computational intensity of the dynamic programming algorithm and the network retraining requirement impact the method's applicability in resource-constrained environments?\nWe agree that this is one limitation of the paper since we have not tested the method on very high-resolution images like CelebA 1024x1024 and above. However, the results on 256x256 datasets (CelebA-HQ, LSUN Church/Bedroom, AFHQ) suggested that BOSS will receive more benefit with higher dimension datasets since one NFE evaluation for each of the score networks for such dataset will take more time (as we require more network parameters to generate high fidelity high-resolution images).\nHas the scalability of BOSS been assessed in relation to increasing dataset sizes or complexity, and if not, would the authors consider evaluating this to enhance the paper's comprehensiveness?\nWe are unsure if the reviewer means the dataset\u2019s number of samples or the dataset\u2019s resolution. For the former, we always fix the retraining/redress batch size at 15 samples. For the latter, at this moment we cannot find a pretrained velocity network for higher resolution images more than 256x256. We will be thankful if the reviewer can give a pointer to us and we are willing to run the additional benchmark should the time allow."}, {"Heading": "A reminder", "Subheading": "Official CommentbyAuthors22 Nov 2023, 20:55Everyone", "Content": "Comment:\nDear reviewer,\nIt is now only several hours until the author-reviewer discussion period ends. It would be really great if you can acknowledge that you have read the rebuttal and our revised version of the work. If you have any additional questions or concerns, we will try our best to address them quickly. Thank you for your valuable feedback, and we sincerely anticipate your response.\nBest regards,\nThe authors."}]}, {"Heading": "Official Review of Submission9312 by Reviewer pSht", "Subheading": "Official ReviewbyReviewer pSht31 Oct 2023, 05:41 (modified: 08 Dec 2023, 09:57)EveryoneRevisions", "Content": "Summary:\nFlow matching is a powerful framework for generating high-quality samples, especially in image synthesis. However, the computational demands of these models pose challenges in low-resource scenarios. This paper introduces the Bellman Optimal Step-size Straightening (BOSS) technique for efficient image sampling within a computational budget. BOSS optimizes step sizes and refines the velocity network to improve generation paths. Experimental evaluations demonstrate BOSS's effectiveness in resource utilization and image quality. It provides a sustainable solution that reduces costs and environmental footprints.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nNot only in flow matching, but also in diffusion models, all endeavors are focused on predicting the efficiency of noise, score, and vector field. While most of them set the step size based on a heuristic principle (e.g., DDIM, DDPM), this paper explores generative models of ODE from a different perspective - the step size itself, rather than the \"direction\" of a specific step.\nWeaknesses:\nThe baseline is too weak, as it only compares quantitatively with the fixed-step size ODE solver euler, while it doesn't compare with adaptive step size ODE solvers such as dopri5 or rk45. This comparison should be included in Table 1.\nThe optimization needs to be conducted on a case-by-case basis. Additionally, the use of the dynamic programming algorithm using Gorubi may result in slow performance, rendering the method impractical. Optimization time is also not discussed in this paper.\nQuestions:\nas above\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reponse to Reviewer pSht", "Subheading": "Official CommentbyAuthors20 Nov 2023, 11:49 (modified: 20 Nov 2023, 11:59)EveryoneRevisions", "Content": "Comment:\nThe baseline is too weak, as it only compares quantitatively with the fixed-step size ODE solver euler, while it doesn't compare with adaptive step size ODE solvers such as dopri5 or rk45. This comparison should be included in Table 1.\nWe thank the reviewer for the suggestion. We have added more baseline methods and additional datasets to showcase the effectiveness. The quantitative results can be found in [Table 1 & 2], Figure 4 of our revision of the paper, and the qualitative results can be found in Figure 5 of our paper.\nThe optimization needs to be conducted on a case-by-case basis. Additionally, the use of the dynamic programming algorithm using Gorubi may result in slow performance, rendering the method impractical.\nWe agree that our method requires solving additional dynamic programming problem to find sampling step sizes, compared to the many other training-free diffusion/flow matching samplers that have closed-form formulation. However, we want to point out that in most cases, there are no guarantee  that these closed-form formulas are optimal, as they are mostly on heuristic rules.\nOptimization time is also not discussed in this paper.\nIndeed this is missing from the previous version of our work. We have added a paragraph in the Appendix A & B regarding CPU+GPU hours of calculating Bellman steps and GPU hours of retraining/redressing the pretrained velocity networks."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 11:25 (modified: 22 Nov 2023, 11:43)EveryoneRevisions", "Content": "Comment:\nOptimization time is also not discussed in this paper.\nLet us elaborate further on the efficiency of our framework:. This efficiency arises because we only need to pass\na single batch\nof noise through the forward process to obtain the values for each intermediate timestamp. Subsequently, we calculate the local truncation error for any two timestamps. These local truncation errors has in total $K^{\\max}*(K^{\\max}-1)/2$ and they can be efficiently stored without requiring large memory. The dynamic programming involved in this process is also time-efficient, as elaborated in the Appendix. For added credibility, we provide a running time of the entire stepsizes calculation process with NFE = 10, detailing the running time of each component across all our datasets in the below table. All running time are for Nvidia A5000 (an old generation GPU, launched in April 2021), CPU: Intel Xeon 2.4-3.7 GHz, 20 core, 40 thread. The whole process just takes around 115 seconds to complete for the 256x256 datasets.\nRunning time (s)\nCIFAR10\nCelebA-HQ\nLSUN-CHURCH\nLSUN-BEDROOM\nAFHQ-CAT\nOne batch forward\n8.5977\n47.7143\n47.4024\n48.4324\n45.5489\nLocal truncation errors\n10.066\n67.9143\n67.5273\n65.9875\n66.7532\nDynamic programming\n0.0134\n0.0138\n0.0138\n0.0139\n0.0138\nThe whole process\n18.6771\n115.6424\n114.9435\n114.4338\n112.3159"}, {"Heading": "A reminder", "Subheading": "Official CommentbyAuthors22 Nov 2023, 20:57Everyone", "Content": "Comment:\nDear reviewer,\nIt is now only several hours until the author-reviewer discussion period ends. It would be really great if you can acknowledge that you have read the rebuttal and our revised version of the work. If you have any additional questions or concerns, we will try our best to address them quickly. Otherwise, we would appreciate if you can adjust your evaluation accordingly. Thank you for your valuable feedback, and we sincerely anticipate your response.\nBest regards, The authors."}]}, {"Heading": "Official Review of Submission9312 by Reviewer GU1Q", "Subheading": "Official ReviewbyReviewer GU1Q23 Oct 2023, 02:33 (modified: 04 Dec 2023, 05:38)EveryoneRevisions", "Content": "Summary:\nThis paper proposed a new sampling strategy for flow-matching (flow-reflected) generative models. Formally, the authors analyze the sampling error estimation and propose to formulate the sampling process as a dynamic programming problem. Then the task is addressed by the bellman optimal schedule. Moreover, the authors proposed to re-align the velocity network along the accumulated sampling errors, which enjoys good performance.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe authors clearly present the issue of sampling error in flow-matching generation.\nIt is interesting and intuitive to formulate the sampling schedule as a dynamic programming problem. The solution is convincing.\nThis paper is well-written with clear motivations.\nWeaknesses:\nAlthough the main idea of this paper is interesting, this paper gives me the initial impression of being incomplete, with this incompleteness of the presentation of both the methodology and experimental sections.\nFor method Sec.3.3, the authors did not provide enough details about how to address the dynamic programming (DP) problem in practice. From the experiments, different datasets should share different sampling schedules. Moreover, how many samples are used to calculate the optimal scheduler? What will the optimal scheduler be like, if using different initial noises? The analysis of the generalization of the optimal scheduler selected by DP is very important.\nMissing necessary discussions about diffusion sampling schedules in related works (such as [1]). Moreover, the related works are too simple, and only include some matching-flow methods.\nInsufficient qualitative comparisons: the authors only provide qualitative comparisons of human faces.\nNo details about the velocity network re-alignment training are provided.\n[1] Karras T, Aittala M, Aila T, et al. Elucidating the design space of diffusion-based generative models[J]. Advances in Neural Information Processing Systems, 2022, 35: 26565-26577.\nQuestions:\nAlthough this paper enjoys interesting idea, it suffers from incomplete related works, experimental results, analysis, and methodology/implementation details, which largely limit the quality of this paper. I think this paper needs a major revision before the publication.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reponse to Reviewer GU1Q", "Subheading": "Official CommentbyAuthors20 Nov 2023, 11:59Everyone", "Content": "Comment:\nAlthough the main idea of this paper is interesting, this paper gives me the initial impression of being incomplete, with this incompleteness of the presentation of both the methodology and experimental sections.\nWe appreciate the reviewer\u2019s comment and have added various elaborations in the main text. Please refer to the improved version of our submission with added elaborations, new results with additional datasets.\nFor method Sec.3.3, the authors did not provide enough details about how to address the dynamic programming (DP) problem in practice.\nWe have added a section in the Appendix B with a pseudocode that provides details on our Dynamic Programming algorithm. The time complexity of this algorithm is $O((K^{max})^2 \\times K)$. The choice of $K^{max}$ is crucial, aiming for the Euler sampling method with $K^{max}$ stepsizes to precisely replicate the trajectory of the Ordinary Differential Equation (ODE). Typically, $K^{max}$ falls within the range of 100 to 1000, ensuring accuracy. Given this range for $K^{max}$ and the variable $K$ ranging from 2 to 1000, the algorithm executes within seconds in all scenarios. Moreover, our solved problem is fast sampling in flow-matching models which focuses on relatively small values of K (<20), so the intensity of the dynamic programming algorithm is not a worrying problem even in the case that $K^{max} > 1000$.\nFrom the experiments, different datasets should share different sampling schedules. Moreover, how many samples are used to calculate the optimal scheduler? What will the optimal scheduler be like, if using different initial noises? The analysis of the generalization of the optimal scheduler selected by DP is very important.\nWe have added a section in the Appendix A on experimental details. In short, we used 100 samples for calculating the Bellman steps for all dataset, as we did not observe any improvements in FID when using more than that number of samples for calculating optimal step-size scheduler. Moreover, we aim to use as low computational resources as possible to keep it inline with the goal of our work. \nWe agree with the reviewer that an analysis of the generalization of the optimal scheduler/sampler with DP steps is very important. However, we think it requires setting up plenty of additional definitions and assumptions related to learning theory (e.g. neural network class of the velocity networks, assumption about data and noise distributions, smoothness of the velocity functions, etc.) and therefore we consider this beyond the scope of the current work. However, we find this a very interesting direction to explore in the future work, and we thank the reviewer for helpful comment.\nMissing necessary discussions about diffusion sampling schedules in related works. Moreover, the related works are too simple, and only include some matching-flow methods.\nWe thank the reviewer for pointing this out, and we have updated the related work sessions accordingly. In short, the focus of our work is on improving the ODE sampler of flow-matching models. While flow matching is a special case of diffusion probability ODE flow, flow matching having different formulations for its probability path (linear interpolation $X_t = (1-t)X_0 + t X_1$ makes it possible for redressing/reflowing to work. The principle of measuring the straightness of the trajectory curve is not applicable to general affine formulation from diffusion probability ODE. Nevertheless, we think that extending the philosophy of calculating optimal step sizes/noise schedulers with dynamic programming is an interesting direction, and we will leave it for future works.\nInsufficient qualitative comparisons: the authors only provide qualitative comparisons of human faces.\nWe have added more detailed qualitative comparisons in the main text as suggested by the reviewer. Please refer to [Figure 5].\nNo details about the velocity network re-alignment training are provided.\nWe are unsure if we understood correctly that the reviewer asked for details and training objective of the straightening velocity network. If this is the case, then the reviewer can refer to Section 4. On the other hand, if instead the reviewer wanted to know more about the details of velocity network retraining (GPU hours, training iterations, etc.), please kindly refer to our Appendix A (Experimental details). Below is a copy of the paragraph.\nThe pre-trained models are finetuned by three methods including Uniform-Reflow, Distill-k Reflow, and BOSS  in 12000 iterations. An iteration is the passing and backpropagation process for a batch including 15 samples. Due to the similar cost of training between finetuning methods, we report the average GPU hours consumed on each pre-trained model up to 12000 iterations, using NVIDIA RTX A5000.\nCIFAR10: 3.56 training hours.\nCelebA-HQ: 10.35 training hours.\nLSUN-CHURCH: 13.43 training hours.\nLSUN-BEDROOM: 14.23 training hours.\nAFHQ-CAT: 9.30 training hours."}, {"Heading": "Thanks for the response from the authors", "Subheading": "Official CommentbyReviewer GU1Q22 Nov 2023, 07:25Everyone", "Content": "Comment:\nThe authors have extensively revised their paper, incorporating numerous details that have significantly enhanced its overall quality.\nHowever, a concern arises from the fact that all step-size selections are tailored to specific datasets, posing a challenge to achieving generalization. The absence of a universal approach may limit the broader applicability of the proposed methodology.\nTo address this potential limitation, conducting additional empirical experiments would be beneficial on this issue. For instance, exploring the consequences of transferring the scheduler optimized for one dataset to another could provide valuable insights. Understanding whether such a transfer adversely affects performance would contribute to a more comprehensive evaluation of the proposed approach."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 11:22 (modified: 22 Nov 2023, 11:44)EveryoneRevisions", "Content": "Comment:\nThanks for your constructive comments. We appreciate your suggestion of analyzing the transferability between stepsizes optimized for a dataset to other datasets. However, we argue that stepsize transferability is not a must for the following reasons:\nIn the current state of generative AI, for two different datasets, we have two different velocity networks. Each network is fine-tuned to generate samples only for the training dataset. If we have two different networks, there is no clear reason why we should use the same stepsize. Thus, stepsize transferability is not needed.\nOur objective is not to find a common step size for every dataset. Our goal is to\ncustomize\nthe stepsizes to the dataset so that we can reduce the number of steps while retaining the quality of the generated samples. We have demonstrated in our experiments that this can be done efficiently under low resources, even for moderately high resolution datasets such as CelebA-HQ 256, LSUN Church/Bedroom and AFHQ-Cat.\nThe important message is that the\nstep size is not generalizable, but our framework is generalizable\n. When applied to various datasets and pre-trained models, our framework consistently exhibits improvements over the baselines (uniform stepsizes, etc.). Thus,\nour framework is universal\n, at least for all the experiments in our paper.\nNevertheless, we still follow the reviewer\u2019s suggestion to check the transferability of dynamic programming step sizes, we agree that it can provide us further insights into our framework. Due to time constraints, we transfer the optimized step sizes from LSUN-CHURCH to the pre-trained models on CeleA-HQ and LSUN-BEDROOM. \nThe FID scores, obtained with 4, 6, and 8 NFEs, for CelebA-HQ resulting from this transfer are presented in the tables below.\nMethod\n4 NFE\n6 NFE\n8 NFE\nUniform Euler\n158.95\n127.01\n109.42\nBellman Euler\n92.03\n72.54\n49.80\nBellman-transfer\n132.04\n100.68\n72.88\nUniform Euler uses uniform stepsizes, Bellman Euler uses optimal stepsizes for the CelebA-HQ, while Bellman-transfer uses the stepsizes taken from the LSUN-CHURCH. It is clear that Bellman Euler is still the optimal method. However, what is important here is that Bellman-transfer is\nbetter\nthan Uniform Euler. This hints that there is a certain degree of transferability of the stepsizes (this is an empirical claim, we do not impose any theoretical claim at this point).\nThe below table is for the LSUN-BEDROOM:\nMethod\n4 NFE\n6 NFE\n8 NFE\nUniform Euler\n84.35\n39.19\n32.15\nBellman Euler\n61.60\n35.35\n25.80\nBellman-transfer\n70.23\n38.01\n29.14\nWe observe the same trend here, confirming empirically that there is a certain degree of transferability in the stepsize. Nevertheless, if we optimize the stepsize and use Bellman Euler, we would still obtain the best performance.\nThese empirical results reinforce the importance of\ncustomizing\nstepsizes to each dataset to obtain superior performance.\nOnce again, finding the optimal stepsizes is efficient using our proposed framework.\nLet us elaborate further on the efficiency of our framework:. This efficiency arises because we only need to pass\na single batch\nof noise through the forward process to obtain the values for each intermediate timestamp. Subsequently, we calculate the local truncation error for any two timestamps. These local truncation errors has in total $K^{\\max}*(K^{\\max}-1)/2$ and they can be efficiently stored without requiring large memory. The dynamic programming involved in this process is also time-efficient, as elaborated in the Appendix. For added credibility, we provide a running time of the entire stepsizes calculation process with NFE = 10, detailing the running time of each component across all our datasets in the below table. All running time are for Nvidia A5000 (an old generation GPU, launched in April 2021), CPU: Intel Xeon 2.4-3.7 GHz, 20 core, 40 thread. The whole process just takes around 115 seconds to complete for the 256x256 datasets.\nRunning time (s)\nCIFAR10\nCelebA-HQ\nLSUN-CHURCH\nLSUN-BEDROOM\nAFHQ-CAT\nOne batch forward\n8.5977\n47.7143\n47.4024\n48.4324\n45.5489\nLocal truncation errors\n10.066\n67.9143\n67.5273\n65.9875\n66.7532\nDynamic programming\n0.0134\n0.0138\n0.0138\n0.0139\n0.0138\nThe whole process\n18.6771\n115.6424\n114.9435\n114.4338\n112.3159"}, {"Heading": "A reminder", "Subheading": "Official CommentbyAuthors22 Nov 2023, 20:58Everyone", "Content": "Comment:\nDear reviewer,\nIt is now only several hours until the author-reviewer discussion period ends. It would be really great if you can acknowledge that you have read the rebuttal and our revised version of the work. If you have any additional questions or concerns, we will try our best to address them quickly. Otherwise, we would appreciate if you can adjust your evaluation accordingly. Thank you for your valuable feedback, and we sincerely anticipate your response.\nBest regards, The authors."}, {"Heading": "Thanks for the further discussion", "Subheading": "Official CommentbyReviewer GU1Q22 Nov 2023, 21:27Everyone", "Content": "Comment:\nI understand the concern of authors that different models are trained on different datasets, and they should share different step sizes. However, it is crucial that the overarching objective of this method extends to large diffusion models, such as the recently proposed InstaFlow. I acknowledge the inherent difficulty in evaluating the performance of such expansive matching flow models during the rebuttal phase. Consequently, I suggest that the authors delve deeper into discussions and analyses pertaining to the generalization of their method.\nOn the whole, the authors have effectively addressed all my concerns. The only notable observation is that this paper has undergone a substantial revision compared to its initial submission, encompassing essential experiments and discussions. If the AC deems this extensive alteration acceptable, I would be inclined to revise my score to borderline acceptance."}]}]}, "j7S7o6ROn9": {"paper_info": {"Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Pruning, Structured Pruning, Total Variation Distance", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "Discrimination-based structured pruning using novel lower bounds on the TV distance.", "Abstract": "Recent literature introduced the notion of distributional structured pruning (DSP) in Deep Neural Networks by retaining discriminative filters that can effectively differentiate between classes.  Crucial to  DSP is the ability to estimate the discriminative ability of a filter, which is defined by the minimum pairwise Total Variation (TV) distance between the class-conditional feature distributions. Since the computation of TV distance is generally intractable, existing literature assumes the class-conditional feature distributions are Gaussian, thereby enabling the use of the tractable Hellinger lower bound to estimate discriminative ability. However, the Gaussian assumption is not only restrictive but also does not typically hold. In this work, we address this gap by deriving a lower bound on TV Distance which depends only on the moments of witness functions. Using linear witness functions, the bound establishes new relationships between the TV Distance and well-known discriminant-based classifiers, such as Fisher Discriminants and Minimax Probability machines. The lower bounds are used to produce a variety of pruning algorithms called WitnessPrune by varying the choice of witness function. We empirically show that we can achieve up to 7% greater accuracy for similar sparsity in hard-to-prune layers using a polynomial witness function as compared to the state-of-the-art.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9311", "PDF Url": "https://openreview.net/pdf?id=j7S7o6ROn9"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9311 by Area Chair n37h", "Subheading": "Meta ReviewbyArea Chair n37h06 Dec 2023, 11:04 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper proposes a new pruning algorithm for compressing neural networks. The idea is that for a given filter, if the distributions of output for different classes are close (in TV distance) then we can prune the filter. The TV distance is hard to compute so one needs to use other bounds that are easier to estimate. Previous works assume that the distributions are Gaussian and use bounds that are only valid for Gaussian. The current work uses the first two moments of the distribution to derive a bound. The experiments show good empirical performance that is better than alternatives, especially without further fine-tuning.\nOn the downside, the result is more general but does not take into account the error in estimating the moments of the distributions. This error/cost to reduce the error will only go up with larger models. The original paper only tested on VGG16 but in the discussion with the reviewers, some limited extra experiments for Resnet50 was done, showing improved performance compared with alternatives but essentially the same performance after extra fine-tuning.\nJustification For Why Not Higher Score:\nWhile two reviewers put it marginally above the threshold, one reviewer puts it significantly below due to the concern about estimation error for the moments. On the balance, it seems to be a good work that can be accepted some day but a bit incomplete in the current state.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "General response to Reviewers", "Subheading": "Official CommentbyAuthors21 Nov 2023, 03:05Everyone", "Content": "Comment:\nWe'd like to thank all the reviewers and the area chair for the time and effort put into reviewing our work.\nWe hope we've addressed the reviewers' concerns, and are excited to engage further with reviewers and gain further feedback on our work.\nWe would first like to sincerely thank all the reviewers for their appreciation of and praise for our work. In particular,\nReviewers appreciated the quality of the presentation of ideas.\nReviewers appreciated the key technical results, as well as their application to pruning.\nReviewers also raised some common concerns.\nTypos can affect the clarity of writing\nWe have endeavoured to address these issues in the amended draft (now uploaded). We hope this addresses the reviewers' concerns.**\nExperimental Validation could be better (noted by reviewers XVjC and G7wT)\nWe present a snapshot of our experiments on ImageNet below. Our method achieves superior or comparable performance to several contemporary works.  Further experimental details can be found in the responses to\nReviewer XVjC\nand\nReviewer G7wT\n.\nAlgorithm\nWitnessPrune\nCHIP\nTVSPrune\nL1\n40.2% sparsity\n(with fine-tuning)\n-2.58%\n-2.74%\n-2.77%\n-4.45%\nList of Changes\nWe also take this opportunity to list the changes made to the draft.\nSection 2 has been edited, and typos removed.\nError in Table 1 pointed out by Reviewer XVjC has been fixed\nTypo pointed out by Reviewer 1f4m has been fixed\nIn Appendix B.3, Corollary 4 has been introduced, to highlight cases when our lower bound can be used to compute the true TV distance (also in the response to reviewer 14fm).\nOther typos/minor errors have been addressed."}, {"Heading": "Official Review of Submission9311 by Reviewer 1f4m", "Subheading": "Official ReviewbyReviewer 1f4m01 Nov 2023, 01:32 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents a simple lower bound on the total variation (TV) distance between two distributions, and uses it to design novel pruning algorithms. To illustrate the basic idea in neural network pruning algorithms, consider a binary classification setup and class-conditional \u201cfeature\u201d distributions (i.e., distribution of activations for each layer in the neural network). The approach considers a neuron \u201cuninformative\u201d if the TV distance between its conditional distribution for label 0 and label 1 is small, and prunes it. TV distance between high-dimensional distributions is in general difficult to compute, and the fact that we usually only have samples, not the densities, makes this issue even worse. The authors claim that their simple lower bound provides a more \u201ctractable\u201d alternative, though it is not clear what they mean by \u201ctractable\u201d in this context.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nOverall, the paper is well-written. The ideas are clearly presented and I appreciate the simplicity of the TV lower bound and the straightforward application to pruning.\nWeaknesses:\nThe paper leaves a lot of issues, both theoretical and practical, unaddressed. Thus, I am inclined to reject this paper at the moment, but I do see substantial potential in it should the authors address the issues mentioned below.\nThe most glaring issue is that the TV lower bound is stated only in terms of populational quantities, such as exact moments of the distribution. In practice, these quantities have to be\nestimated\nfrom finitely many samples. The regime the authors seem to have in mind is the fixed-dimension infinite-samples setting. However, for neural network pruning, their main application, a\nhigh-dimensional\nscaling in which the data dimension and the number of samples grow proportionally would be a more pertinent setting to analyze. This greatly complicates the analysis for their lower bound since one would need to analyze the estimation error in their moment functional. Even the simple task of estimating moment tensors of high-dimensional distributions can be tricky. Hence, a finite sample analysis of their lower bound is warranted.\nAnother issue, which is mostly of theoretical interest, is that the lower bound can be extremely loose in some cases. It would be helpful if the authors could provide some insights on the weakness of their lower bounds to provide a more balanced perspective. For example, it is well-known that for any positive integer k, there exists a discrete distribution that exactly matches the first k moments of the standard Gaussian (see e.g., [DKS17]). If P is this moment matching discrete distribution and Q is   the standard Gaussian, then TV(P,Q) = 1 but the lower bound is 0.\nReferences\n[DKS17]: Ilias Diakonikolas, Daniel M. Kane, Alistair Stewart. Statistical Query Lower Bounds for Robust Estimation of High-dimensional Gaussians and Gaussian Mixtures.\nFOCS\n2017.\nQuestions:\nCan the authors explain why a \u201cwitness function\u201d is named as such? My guess is that it comes from the general form of the lower bound from A.1 and the authors view it as the function that achieves the supremum (a \u201cwitness\u201d of the supremum), but it would be helpful to explain the term in the introduction.\nThe use of descriptor \u201crobust\u201d when they say \u201crobust lower bound\u201d is somewhat misleading. \u201cRobust\u201d is typically used in the context of estimation, but there is no estimation analysis in this paper.\nCan \\varphi be non-polynomial? The defining condition for \\varphi: R^d \\to R^n is that its expectation is a function of only the first k moments. Are there any non-polynomial functions that satisfy this condition?\np.6 saliency score r_j^\\ell subscript and superscript are reversed before Eq.(7).\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 14fm (1)", "Subheading": "Official CommentbyAuthors17 Nov 2023, 06:04Everyone", "Content": "Comment:\nWe would like to thank the author for his appreciation of our work, and his insightful questions. In particular, we thank the reviewer for his appreciation of the main ideas presented in our work.\nOverall, the paper is well-written. The ideas are clearly presented and I appreciate the simplicity of the TV lower bound and the straightforward application to pruning.\nWe thank the reviewer for the appreciation of the new results proposed in our work, as well as their application to neural network pruning.\nWe would then like to address the reviewer's concerns.\nThe authors claim that their simple lower bound provides a more \u201ctractable\u201d alternative, though it is not clear what they mean by \u201ctractable\u201d in this context.\nTypically, the approximating the TV distance is known to be  #P complete [9]. Our work is more tractable than prior art since it requires only the computation of the first two moments of a witness function $f(X) = u^\\top \\varphi(X)$, which, as stated in Section 4, are assumed to be functions of the moments of the distributions themselves, as noted in Section 4 of the main document.\nThe most glaring issue is that the TV lower bound is stated only in terms of populational quantities, such as exact moments of the distribution. In practice, these quantities have to be estimated from finitely many samples. The regime the authors seem to have in mind is the fixed-dimension infinite-samples setting.\nWe would like to clarify that in the setting of this paper - that is, using the TV-separation between the class-condtional distributions of the\nfeature maps generated by individual filters\nas defined in Equation (1) on page 2-  the dimensions of feature maps, particularly in later layers, are not high-dimensional. That is, the number of samples of each class is actually greater than the dimension of the individual feature maps.  For models trained on CIFAR10, we typically choose 100 samples per class to compute the moments of the witness function $u^\\top \\varphi(X)$.\nHowever, for neural network pruning, their main application, a high-dimensional scaling in which the data dimension and the number of samples grow proportionally would be a more pertinent setting to analyze.\nIn the final layers, of most neural network architectures, the size of the feature maps is often\nlow-dimensional\n, and moreover, these layers have been shown to be most amenable to pruning [1],[7]. We illustrate this with a VGG-16 model trained on CIFAR10, where $n=100$ is the number of samples. We see that the dimension of the feature maps is relatively small.\nLayers\n4,5,6\n7,8,9\n10,11,12\nDimension of feature map $d$\n64\n16\n4\nRatio of dimension to sample size $d/n$\n.64\n.16\n.04\nWe see from this table that the majority of feature maps that can be effectively pruned are\nnot\nhigh dimensional. Note that this trend can be observed over a variety of architectures as well.\nThis greatly complicates the analysis for their lower bound since one would need to analyze the estimation error in their moment functional. Even the simple task of estimating moment tensors of high-dimensional distributions can be tricky. Hence, a finite sample analysis of their lower bound is warranted.\nFor feature maps that are high dimensional, we note that in Corollaries 1 and 2, we derive lower bounds on the TV distance with respect to the Fisher Linear Discriminant [5] and the Minimax Probability Machine (MPM) [6].  We also recall that works such as [1],[7] observed that initial layers possessing high-dimensional feature maps are typically the most difficult to prune effectively. In this case, we can use existing methodologies, such as those proposed in  [8],[6] for robust estimation of Fisher and MPM based lower bounds on the TV distance. Specifically, if we choose $u^\\top \\varphi(X) = u^\\top X$, we can directly apply Equation 15 proposed in\nRobust Fisher Discriminant Analysis\n, by Kim et al [8].\nHowever, we feel that a broader investigation of these aspects is beyond the scope of our current work, which focuses on using the lower bounds for pruning, which it does effectively, as evidenced by the empirical results presented in Section 7.3.\nReferences\n[1]\nProvable Filter Pruning for Efficient Neural Networks\n. Liebenwein et al, 2020.\n[2]\nA Kernel Two-Sample Test\n. Gretton et al, 2012.\n[3]\nA Witness Function Based Construction of Discriminative Models Using Hermite Polynomials\n. Mhaskar et al, 2020.\n[4]\nA Witness Two-Sample Test\n. Kubler et al, 2022.\n[5]\nPattern Classification\n. Duda and Hart, 2002.\n[6]\nA Robust Minimax Approach to Classification\n. Lanckriet et al, 2002.\n[7]\nTVSPrune - Pruning Non-discriminative filters via Total Variation separability of intermediate representations without fine tuning\n. Murti et al, 2023.\n[8]\nRobust Fisher Discriminant Analysis\n. Kim et al, 2005.\n[9]\nOn Approximating Total Variation Distance\nBhattaharyya et al, 2022."}, {"Heading": "Response to Reviewer 14fm (2)", "Subheading": "Official CommentbyAuthors17 Nov 2023, 06:12 (modified: 17 Nov 2023, 11:28)EveryoneRevisions", "Content": "Comment:\nAnother issue, which is mostly of theoretical interest, is that the lower bound can be extremely loose in some cases. It would be helpful if the authors could provide some insights on the weakness of their lower bounds to provide a more balanced perspective.\nWe thank the reviewer for this insightful and important question.\nThe lower bounds on TV distance proposed in this work are not tight for arbitrary distributions. As stated in Theorem 1 (Equation 3),\n$$\\min_{ \\mathbb{P}\\in \\mathcal{S}_{k}(\\mathbf{P}),\\mathbb{Q}\\in \\mathcal{S}_{k}(\\mathbf{Q})} \\mathrm{TV} (\\mathbb{P},\\mathbb{Q}) \\geq \n  \\sup_{u\\in\\mathbb{R}^n}\\frac{\\left(u^\\top(g(\\mathbf{P})-g(\\mathbf{Q}))\\right)^2}{2u^\\top(G(\\mathbf{P}) + G(\\mathbf{Q}))u},$$ where $\\mathcal{S}_k(\\mathbf{P})$ is the set of all distributions with moments $\\mathbf{P}$, the lower bound is in the setting with\nlimited information\n, like finite collections of moments.  Thus, given two finite collections of moments $\\mathbf{P}$ and $\\mathbf{Q}$ of the two distributions, Theorem 1 provides a\nworst case\nlower bound on the TV distance between\nany\ndistributions with moments given by $\\mathbf{P},$ $\\mathbf{Q}$, as stated in Equation 3. Thus, the lower bound may be loose.\nHowever, the purpose of the lower bounds proposed in this work is to determine the well-separatedness of the class conditional distributions of the feature maps generated by individual filters.  For this use case, it is sufficient to check whether the lower bound provided by Theorem 3 is high enough.\nAnother insight is provided in Section 7.1. We show the quality of the lower bound improves with a richer class of witness function. In particular, we show that with polynomial witness functions, higher-degree polynomials provide higher lower bounds than lower-degree polynomials, as they incorporate more distributional information in terms of higher-order moments.\nFurthermore, there are cases where the true TV distance can be computed from the lower bound. For instance, when  the distributions $\\mathbb{P}$ and $\\mathbb{Q}$ are Gaussians with the same variance $\\Sigma$, and with means $\\mu_p$ and $\\mu_q$, and if we choose $\\varphi(X) = X - \\frac{1}{2}(\\mu_p-\\mu_q)$, we can find the true TV distance by computing $u^*$ in equation 3. We also take this opportunity to point out that this provides a different perspective on discriminative ability - we consider a filter to be discriminative if the optimal classifier trained upon the features it generates has a low classification error. We detail this further in Appendix B3, in the amended draft.\nFor example, it is well-known that for any positive integer k, there exists a discrete distribution that exactly matches the first k moments of the standard Gaussian (see e.g., [DKS17]). If P is this moment matching discrete distribution and Q is the standard Gaussian, then TV(P,Q) = 1 but the lower bound is 0.\nThe lower bounds proposed in this work are\nworst-case\nlower bounds for the TV distance - that is, given a set of distributions $\\mathcal{S}_k(\\mathbf{M}_1)$ with moments $\\mathbf{M}_1$, and a set of distributions $\\mathcal{S}_k(\\mathbf{M}_2)$ with moments $\\mathbf{M}_2$, Theorem 1 (and Equation 3 in particular) provides a lower bound for the minimum TV distance between any distribution in $\\mathbb{P}\\in \\mathcal{S}_k(\\mathbf{M}_1)$ and any  $\\mathbb{Q}\\in\\mathcal{S}_k(\\mathbf{M}_2)$.\nTo illustrate this, suppose $\\mathbf{M}_1 := (\\mu_1,\\Sigma_1)$ and $\\mathbf{M}_2 := (\\mu_2,\\Sigma_2)$. Then $\\mathcal{S}_k(\\mathbf{M_1})$ is the set of\nall\ndistributions with means and variances given by $\\mathbf{M}_1$, including the normal distribution. The same is true for  $\\mathcal{S}_k(\\mathbf{M_2})$. Thus, Theorem 1 provides a lower bound between any two distributions with means and variances given by $\\mathbf{M}_1$ and $\\mathbf{M}_2$ respectively. Thus, if $\\mathbf{M}_1 = \\mathbf{M_2}$, the lower bound will be 0.\nAlso, in section 7.1, we consider an example where we compare two Gaussians, with the means of both distributions is $(0,0)$. As we incorporate higher-order moments by choosing witness functions that are higher-order polynomials, we obtain nontrivial lower bounds on the TV distance between them.\nReferences\n[1]\nProvable Filter Pruning for Efficient Neural Networks\n. Liebenwein et al, 2020.\n[2]\nA Kernel Two-Sample Test\n. Gretton et al, 2012.\n[3]\nA Witness Function Based Construction of Discriminative Models Using Hermite Polynomials\n. Mhaskar et al, 2020.\n[4]\nA Witness Two-Sample Test\n. Kubler et al, 2022.\n[5]\nPattern Classification\n. Duda and Hart, 2002.\n[6]\nA Robust Minimax Approach to Classification\n. Lanckriet et al, 2002.\n[7]\nTVSPrune - Pruning Non-discriminative filters via Total Variation separability of intermediate representations without fine tuning\n. Murti et al, 2023.\n[8]\nRobust Fisher Discriminant Analysis\n. Kim et al, 2005.\n[9]\nOn Approximating Total Variation Distance\nBhattaharyya et al, 2022."}, {"Heading": "Response to Reviewer 14fm (3)", "Subheading": "Official CommentbyAuthors17 Nov 2023, 06:13 (modified: 17 Nov 2023, 06:28)EveryoneRevisions", "Content": "Comment:\nCan the authors explain why a \u201cwitness function\u201d is named as such? My guess is that it comes from the general form of the lower bound from A.1 and the authors view it as the function that achieves the supremum (a \u201cwitness\u201d of the supremum), but it would be helpful to explain the term in the introduction.\nThe term \"witness function\" is a term commonly used in the literature to describe functions that \"witness\" the effect of distributions. Some recent and highly cited works that utilize this terminology are [2],[3],[4].\n-   The use of descriptor \u201crobust\u201d when they say \u201crobust lower bound\u201d is somewhat misleading. \u201cRobust\u201d is typically used in the context of estimation, but there is no estimation analysis in this paper.\nIn this work, we use the term \"robust\" in the sense of\ndistributional robustness\n. As stated in a previous response, the proposed bound is a worst-case lower bound. Thus, given any distributions $\\mathcal{P}$ and $\\mathcal{Q}$  with collections of moments\nP\nand\nQ\nrespectively, Theorem 1 provides a worst-case lower bound on the TV distance between them.\n-   Can \\varphi be non-polynomial? The defining condition for \\varphi: R^d \\to R^n is that its expectation is a function of only the first k moments. Are there any non-polynomial functions that satisfy this condition?\n$\\varphi$ can indeed be non-polynomial. For instance, if we choose $u^\\top \\varphi(X)$ to be the moment generating function, there are distributions for which closed-form expressions of the MGF exist. An example of this would be the univariate Gaussian distribution $\\mathcal{N}(\\mu,\\sigma)$, where we can simply choose $\\varphi(X) =  \\mathrm{exp}(\\mu t + \\frac{1}{2}\\sigma^2 t^2)$, for a given real $t$.\n-   p.6 saliency score r_j^\\ell subscript and superscript are reversed before Eq.(7).\nThank you for pointing out this error - we have amended it.\nReferences\n[1]\nProvable Filter Pruning for Efficient Neural Networks\n. Liebenwein et al, 2020.\n[2]\nA Kernel Two-Sample Test\n. Gretton et al, 2012.\n[3]\nA Witness Function Based Construction of Discriminative Models Using Hermite Polynomials\n. Mhaskar et al, 2020.\n[4]\nA Witness Two-Sample Test\n. Kubler et al, 2022.\n[5]\nPattern Classification\n. Duda and Hart, 2002.\n[6]\nA Robust Minimax Approach to Classification\n. Lanckriet et al, 2002.\n[7]\nTVSPrune - Pruning Non-discriminative filters via Total Variation separability of intermediate representations without fine tuning\n. Murti et al, 2023.\n[8]\nRobust Fisher Discriminant Analysis\n. Kim et al, 2005.\n[9]\nOn Approximating Total Variation Distance\nBhattaharyya et al, 2022."}, {"Heading": "Additional response to Reviewer", "Subheading": "Official CommentbyAuthors21 Nov 2023, 03:03Everyone", "Content": "Comment:\nWe hope we have sufficiently answered the questions and concerns raised by you. If there are additional concerns or thoughts, we are eager to engage in further discussions to try and answer them."}, {"Heading": "Official Comment by Reviewer 1f4m", "Subheading": "Official CommentbyReviewer 1f4m22 Nov 2023, 17:38Everyone", "Content": "Comment:\nI thank the authors for their effort in addressing my questions. However, I will maintain my initial score, as I believe essential issues within the scope of this work remain unaddressed. The paper does not lack merit, but it is somewhat incomplete.\nEstimation error\nis\nwithin the scope of this work.\nAccording to the paper, the novelty of this work lies in dispensing with distributional assumptions on the distributions, e.g., the Gaussian assumption of [Murti et al., 2022]. However, going beyond the simplifying distributional assumptions entails accounting for a wider range of distributions, some of which may pathological, and providing guarantees of comparable nature. Otherwise, it would be difficult to argue for the novelty of the work since generalization would have come at the cost of rigor.\nUnder the Gaussian assumption, finite-sample analysis is a non-issue since we have tight control over the estimation error. However, in the general setting of this work, where distributions are identified only up to their moment sequence, we no longer have this luxury.\nBounds on the estimation error would be useful for practitioners too since it would provide guidance on how to choose their \\varphi\u2019s (e.g., how many moments should I inspect before pruning?)\nFalse sense of validity.\nThe language used in this paper gives a false sense of validity in the pruning procedure. What is obtained from samples is NOT the TV lower bound. The TV lower bound requires\nexact\nmoments\nof the unknown distributions. What is obtained is an estimate of the lower bound, which achieves validity (as a high confidence bound) only after getting bounds on the estimation error.\nRelated to this issue is the first bullet point on p2: \u201cThe bounds require no prior knowledge of the distributions, apart from the boundedness of the distributions moments.\u201d It is true that the bounds, which are functions of\nexact\nmoments, do not require prior knowledge of the distributions. However, we do not know the exact moments. They need to be estimated and the estimation error for the lower bound would depend on specific properties of the unknown distribution.\n\u201cRobust lower bound\u201c is a misnomer.\nThe TV lower bounds are agnostic to distributional properties other than the moments. As the authors mentioned, the lower bounds are worst-case in the sense that it takes a supremum over the set of all distributions sharing the same (truncated) moment sequence. This, in fact, makes the lower bound extremely\nsensitive\nto estimation error since any non-zero error in the estimated moments would place the distribution in a totally different set, and then take the supremum over this incorrect set. Thus, calling it a \u201crobust\u201d lower bound is somewhat misleading.\nUnnecessarily general definitions.\nThe MGF example the authors gave for a non-polynomial test function \\varphi seems incorrect. The fact that the MGF of a Gaussian can be expressed in terms of its first two moments comes from the fact that its\nentire moment sequence\ncan be characterized by its first two moments. If we applied the same \\varphi (i.e., the MGF) to say, a mixture of k Gaussians, it seems unlikely that it can be expressed in terms of finitely many moments (of the\nmixture\n, not its components). This shows that the current formulation of the test statistic is unnecessarily complicated and confusing. If there are no good examples of a non-polynomial \\varphi, I suggest simply defining \\varphi as a bounded-degree polynomial in X."}, {"Heading": "Additional Response to Reviewer 14fm", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:42Everyone", "Content": "Comment:\nWe would like to thank the reviewer for his insightful comments. Furthermore, we hope that we addressed the reviewer's concerns in the previous rebuttal.\nIn particular, we addressed the following:\nLooseness of the lower bound:\nWe agreed that the lower bound proposed in Theorem 1 is loose, However, we also illustrated cases from which the true lower bound could be recovered, specifically in\nCorollary 4\nin Section B.3.\nPruning setting:\nWe argued that the feature maps in CNNs  are not necessarily high dimensional, and illustrated that with the example of VGG16.\nDistrubutions with the same truncated moment sequences:\nWe clarified that given two pairs of truncated moment sequences, at least one moment would need to be different in order to obtain a nontrivial lower bound.\nWitness function name and typos:\nWe amended the typos pointed out by the reviewer, and noted that the phrase \"witness function\" is commonly used in the literature.\nWe would also like to put forward the following arguments.\nGeneral definition of $\\varphi$:\nWe agree that finding examples of $\\varphi$ that are not polynomials with bounded degree is difficult, As such, we will amend the manuscript to reflect this,\nUse of 'robustness':\nWe agree that our lower bounds are not robust to estimation errors, and we'll amend our manuscript to reflect these changes as well.\nImportance of estimation error and incompleteness of the work:\nWe agree that an investigation into estimation error is very important. However, we argue that:\nOur current work focuses on the application of the new lower bound to structured pruning, and our experiments indicate that\nthe current method is highly effective at that task\n. Moreover, we argue that our current work is sufficient in scope for publication, as in the literature, robustness analysis usually merits an entirely new investigation - see the robustness investigation of the Minimax Probability Machine [1] first provided in [2], and the Robust Fisher LDA paper [3].\nSecond, as the feature maps of CNNs, particularly in later layers, are typically not high dimensional, the effect of estimation error on network pruning is diminished. This is further highlighted when the Batchnorm Random variables are used instead of the feature maps (inspired by [4]), as they are scalars.\nLast, we will add an additional discussion section to the manuscript, highlighting the need for a deeper investigation into moment estimation errors and the robustness of the proposed techniques.\nReferences\n[1]\nMinimax Probability Machine\n. Lanckriet et al, 2002.\n[2]\nRobust Minimax Probability Machine\n. Lanckriet et al, 2003.\n[3]\nRobust Fisher Discriminant Analysis\n. Kim and Boyd, 2005.\n[4]\nDreaming to Distill: Data-free Knowledge Transfer via DeepInversion\n, Yin et al, 2020."}]}, {"Heading": "Official Review of Submission9311 by Reviewer XVjC", "Subheading": "Official ReviewbyReviewer XVjC30 Oct 2023, 10:26 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper discusses distributional structured pruning in deep neural networks by introducing new lower bounds on TV Distance that depends on moments of witness functions. The paper introduces a new algorithm \"WitnessPrune\" that utilizes the lower bounds for pruning. The paper discusses both theoretical justification of this algorithm and provides some experimental evidence supporting the effectiveness of WitnessPrune in pruning.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nOriginality and significance: While the topic of pruning has existed within the literature, the paper presents interesting contributions, both theoretically and empirically, that were shown to improve upon state of the art. Judging from this, the paper presents good originality and significance, and the topic is relevant to ICLR.\nQuality and clarity: Overall, the quality and clarity of the paper is decent, but can be improved with further revision. The paper effectively guides the reader via usage of questions and discussions. There are some issues surrounding the formatting of references, typos, etc., though. More suggestions regarding quality and clarity are presented in the following section.\nInteresting-ness of results: The proofs and techniques presented within the paper is also interesting and insightful by itself. For example, the proofs stated in sections A.1 and A.2 in the appendix are simple, clean and to the point.\nWeaknesses:\nOverall, there are not too many major weaknesses. Some additional questions regarding technicalities are listed in the following \"Questions\" section. Here, only weaknesses in overall presentation are discussed.\nPotential breach of anonymity: In Table 1, there is a column with header \"TVSPrune(Murti et al., 2022) (our work)\".\nClarity issues: In certain parts of the paper, clarity issues cause confusion when reading. Some examples include:\nFormatting of references. The paper chooses to use references without separations from text. While this is suitable for some scenarios, in other situations it obstructs the flow of the reading, and it may be beneficial to update the references in these situations. This can likely be changed quite easily.\nUnclear definitions. There are multiple sections of the paper that can be revised to make definitions clearer. One example is in Section 2.2: the very first sentence abruptly ends with a \"..., and let.\"\nFormatting issues and typos throughout the paper should be revised and updated.\nQuestions:\nSome minor questions for clarification and discussions:\nIn Section 4.1, there is an assumption that that functions \"g\" and \"G\" exist. How strict is this assumption and how does it affect the main results?\nAre there theoretical justifications on whether WitnessPrune is generally preferable over previous methods such as TVSPrune?\nRegarding Table 1, why is CHIP unavailable for VGG19? Is it possible to produce the numbers for that experiment? Also, regarding Table 1, how are the sparsity levels in the \"Param. Sparsity\" selected?\nWhile there are some discussions on the variants of WitnessPrune in the appendix, it is not discussed thoroughly and the clarity there is lacking. Are there additional experiments to discuss the effectiveness of these variants?\nFlag For Ethics Review:\nYes, Other reasons (please specify below)\nDetails Of Ethics Concerns:\nThere is a potential breach of anonymity: in Table 1, there is a column with header \"TVSPrune(Murti et al., 2022) (our work)\".\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer XVjC (1)", "Subheading": "Official CommentbyAuthors17 Nov 2023, 05:50Everyone", "Content": "Comment:\nWe thank the reviewer for his time and his appreciation of our work. Specifically, we are glad that the reviewer found our key technical results interesting, and our proofs clear and easy to follow. We also appreciate the fact that the reviewer describes the application of our technical results to the challenging problem of structured pruning as novel and worthy of publication.\nFurthermore, we would like to specifically highlight the following comments.\nOriginality and significance: While the topic of pruning has existed within the literature, the paper presents interesting contributions, both theoretically and empirically, that were shown to improve upon state of the art. Judging from this, the paper presents good originality and significance, and the topic is relevant to ICLR.\nWe thank the reviewer for the appreciation of the originality of our work!\nQuality and clarity: Overall, the quality and clarity of the paper is decent, but can be improved with further revision. The paper effectively guides the reader via usage of questions and discussions. There are some issues surrounding the formatting of references, typos, etc., though. More suggestions regarding quality and clarity are presented in the following section.\nWe thank the reviewer for the positive review! We have tried to answer the specific points regarding the clarity of our work in the sequel.\nInteresting-ness of results: The proofs and techniques presented within the paper is also interesting and insightful by itself. For example, the proofs stated in sections A.1 and A.2 in the appendix are simple, clean and to the point.\nWe sincerely thank the reviewer for the appreciation of the novel mathematical techniques introduced in this work.\nWe now address the concerns raised by the reviewer.\nPotential breach of anonymity: In Table 1, there is a column with header \"TVSPrune(Murti et al., 2022) (our work)\".\nWe apologize for this typo - \"(our work)\" was intended to be next to WitnessPrune on Table 1. We have amended this error.\nClarity issues: In certain parts of the paper, clarity issues cause confusion when reading. Some examples include:\n-   Formatting of references. The paper chooses to use references without separations from text. While this is suitable for some scenarios, in other situations it obstructs the flow of the reading, and it may be beneficial to update the references in these situations. This can likely be changed quite easily.\n-   Unclear definitions. There are multiple sections of the paper that can be revised to make definitions clearer. One example is in Section 2.2: the very first sentence abruptly ends with a \"..., and let.\" Formatting issues and typos throughout the paper should be revised and updated.\nWe have updated the text with corrections to the main document. Please do check it out!\nIn Section 4.1, there is an assumption that that functions \"g\" and \"G\" exist. How strict is this assumption and how does it affect the main results?\nThe functions $g(\\cdot)$ and $G(\\cdot)$ need only exist implicitly. As noted in Theorems 1 and 2, we require that $\\mathbb{E}_{x\\sim \\mathbb{P}} [u^\\top\\varphi(X)] = g(\\mathbf{P})$. Thus, so long as $\\mathbb{E}_{x\\sim \\mathbb{P}}[u^\\top\\varphi(X)]$ and $\\mathbb{E}_{x\\sim \\mathbb{P}}[(u^\\top\\varphi(X))^2]$ are finite, that is sufficient. This is also reflected in the proofs of Theorems 1 and 2, presented in Appendices A.1 and A.2 - the result only depends on the moments of the witness function $f(X)$ with respect to the distributions $\\mathbb{P}$ and $\\mathbb{Q}$.\nMoreover, this assumption is common. For Fisher Discriminant Analysis, it is assumed that the first two moments of the distributions exist, and given distributions $\\mathbb{P}$ and $\\mathbb{Q}$, we choose $\\varphi(X) = X - \\frac{1}{2}(\\mu_p - \\mu_q$, where $\\mu_p$ is the mean of distribution $\\mathbb{P}$.\nAre there theoretical justifications on whether WitnessPrune is generally preferable over previous methods such as TVSPrune?\nYes! TVSPrune[3]  makes a strong assumption that the class conditional distributions of the feature maps are spherical Gaussian. In this work, we make no such assumptions about the class-conditional distributions of the feature maps, immediately highlighting the improvement over works such as TVSPrune.\nReferences\n[1]\nCHIP: CHannel Independence-based Pruning for Compact Neural Networks\n. Sui et al, 2021.\n[2]\nhttps://github.com/Eclipsess/CHIP_NeurIPS2021\n(CHIP github)\n[3]\nPruning Filters for Efficient Convnets\n. Li et al, 2017.\n[4]\nProvable Filter Pruning for Efficient Neural Networks\n. Liebenwein et al, 2020.\n[5]\nDreaming to Distill: Data-free Knowledge Transfer via DeepInversion\n. Yin et al, 2020."}, {"Heading": "Response to Reviewer XVjC (2)", "Subheading": "Official CommentbyAuthors17 Nov 2023, 05:52Everyone", "Content": "Comment:\nRegarding Table 1, why is CHIP unavailable for VGG19? Is it possible to produce the numbers for that experiment?\nUnfortunately, CHIP[1] does not provide an implementation for VGG19, as seen in the main paper as well as the github repository [2], and as such, is untenable to implement at short notice. However, the authors provided an implemenation of ResNet50 trained on ImageNet. We are currently comparing our work with CHIP and TVSPrune on ResNet50 trained on ImageNet.\nAlso, regarding Table 1, how are the sparsity levels in the \"Param. Sparsity\" selected?\nWe do as follows:\nFor each layer $l$, we select a number of filters to be pruned, This is based on insights from [3],[4].\nWe then count the number of parameters removed when the filters are pruned.\nWe also count the number of kernels removed in layer $l+1$. For each filter pruned in layer $l$, a kernel ($3\\times 3$ in VGGnets, and with various sizes for ResNets) is removed from every filter in layer $l+1$.\nWe write this formally as follows. Let $n_l$ be the number of filters in layer $l$,  let $r_l < n_l$ be the number of filters pruned in layer $l$, and let $L$ be the total number of layers. Let $K^2$ be the number of parameters in each convolutional kernel (as defined in . Note that $n_l$ is the number of input channels to layer $l+1$ in an unpruned model, and $n_l-r_l$ is the number of input channels to layer $l+1$ after pruning $r_l$ filters in layer $l$.\nThus, the number of parameters pruned is $N_{pruned} = \\sum_{l=1}^{L}(r_{l}n_{l-1}K^2 ) + \\sum_{l=2}^L(n_l-r_l)r_{l-1}K^2$. Here, $r_0=0$ and $n_0$ is the size of the input channels, which is 3 for RGB images.\nFor a concrete example, we consider the case of the VGG16 example stated in the second row of Table 1. Here, $L=13$. For $l=1,\\cdots,7$, we let $r_l$ be the smallest integer greater than $0.1n_l$, and for $l=8,\\cdots,13$, $r_l$ is the smallest integer greater than $0.6n_l$. For layers 8-13, this is $r_l=309$. Applying the formula, we get $N_{pruned}/N_{total} \\approx .751$.\nWhile there are some discussions on the variants of WitnessPrune in the appendix, it is not discussed thoroughly and the clarity there is lacking. Are there additional experiments to discuss the effectiveness of these variants?\nWe thank the reviewer for the feedback!  The key points we raise in this discussion are as follows.\nWe describe the different variants of WitnessPrune in greater detail, namely  WitnessPrune-FQ, WitnessPrune-M, and WitnessPrune-E. WitnessPrune-FQ uses the Fisher discriminant based lower bound described given in Corollary 1, only with quadratic as opposed to linear features,  to estimate the similarity between the distributions of feature maps, whereas WitnessPrune-M uses the Minimax Probability Machine (MPM) based bound stated in Corollary 2. WitnessPrune-E chooses the best separation of the two prior methods. Our experiments show that the Fisher discriminant based lower bound generally outperforms the MPM based lower bound on VGG and ResNet models trained on CIFAR10.\nIn Section C.3, we describe the use of the BatchNorm random variables (BNRVs). We define the BNRVs  in equation 15, and the moments of the BNRV are the BatchNorm running means and variances. We use this machinery to reduce the storage requirements of the moments, as they allow us to compute the moments of scalar functions, while still retaining sufficient distributional information, as noted in Yin et al [5].\nWe study the efficacy of the different variants of WitnessPrune by using each algorithm\nwithout finetuning\n, as that best illustrates the quality of the pruning algorithm.  Our experiments show that the WitnessPrune-FQ slightly outperforms WitnessPrune-M. We will present those empirical results within the next 24-48 hours.\nReferences\n[1]\nCHIP: CHannel Independence-based Pruning for Compact Neural Networks\n. Sui et al, 2021.\n[2]\nhttps://github.com/Eclipsess/CHIP_NeurIPS2021\n(CHIP github)\n[3]\nPruning Filters for Efficient Convnets\n. Li et al, 2017.\n[4]\nProvable Filter Pruning for Efficient Neural Networks\n. Liebenwein et al, 2020.\n[5]\nDreaming to Distill: Data-free Knowledge Transfer via DeepInversion\n. Yin et al, 2020."}, {"Heading": "Response to reviewer XVjC - Additional Experiments", "Subheading": "Official CommentbyAuthors21 Nov 2023, 03:01Everyone", "Content": "Comment:\nAre there additional experiments to discuss the effectiveness of these variants?\nWe conducted an experiment comparing different variants of WitnessPrune. We focus on the VGG16 model trained on CIFAR10, as it is illustrative of this. We prune only the final 6 convolutional layers, each by a factor of .5 (so 256 filters are pruned from each layer). We compare 3 variants - WitnessPrune-FQ (Algorithm 2), WitnessPrune-MQ (Algorithm 3), and WitnessPrune-E (Algorithm 4), and the derivation of TVSPrune described in Appendix C. To show the utility of the different algorithms, we compare them without fine-tuning, and with 30 epochs of fine-tuning. We present the results in the Table below:\nAlgorithm\nWitnessPrune-FQ\nWitnessPrune-MQ\nWitnessPrune-E\nTVSPrune\nWitnessPrune\nAccuracy drop\n(No Fine-tuning)\n-8.54%\n-8.77%\n-8.54%\n-8.62%\n-7.85%\nAccuracy drop\nWith Fine Tuning\n-1.21%\n-1.19%\n-1.16%\n-1.08%\n-1.03%\nObservations\nOn this model and dataset, WitnessPrune-FQ outperforms TVSPrune and WitnessPrune-MQ. WitnessPrune-E is effectively WitnessPrune-FQ, as the MPM-based lower bound is weaker than the Fisher-based lower bound (as we demonstrated in section 7.2). This is reflected in the accuracy of the unpruned model - they are almost identical. Note that all three methods are weaker than WitnessPrune (Algorithm 1), whose main results are presented in Table 1 in Section 7.3.\nResnet Experiments - ResNet50 on Imagenet\nAs promised previously, we have evaluated our method on a ResNet50 model trained on Imagenet. We compare WitnessPrune with CHIP [1], TVSPrune (the variant discussed in Appendix C.3), and L1 [2]. We fine-tune for 120 epochs with a batch size of 128. We present our results below.\nAlgorithm\nWitnessPrune\nCHIP\nTVSPrune\nL1\n20.2% sparsity\n(No FT)\n-2.67%\n-2.99%\n-2.85%\n-6.45%\n20.2% sparsity\n(FT)\n+.02%\n+.01%\n-.01%\n-1.08%\n40.2% sparsity\n-2.58%\n-2.74%\n-2.77%\n-4.45%\nObservations\nWe see that WitnessPrune clearly outperforms several contemporary baselines on the ImageNet task on the ResNet50 architecture, demonstrating its broad applicability to classification tasks. At low sparsity levels in particular,\nWe hope we have addressed your concerns. If there are any further concerns or questions you have, we are eager to engage in further discussions.\nReferences\n[1]\nTVSPrune - Pruning Non-discriminative filters via Total Variation separability of intermediate representations without fine tuning\n. Murti et al, 2023.\n[2]\nCHIP: CHannel Independence-based Pruning for Compact Neural Networks\n. Sui et al, 2021.\n[3]\nPruning Filters for Efficient Convnets\n. Li et al, 2017."}]}, {"Heading": "Official Review of Submission9311 by Reviewer G7wT", "Subheading": "Official ReviewbyReviewer G7wT29 Oct 2023, 17:58 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces an innovative concept of 'witness functions,' providing a more accurate and reliable framework for estimating the Total Variation (TV) distance between probability distributions. This theoretical insight has practical implications, particularly in the realm of neural network pruning. By applying the witness function methodology, the authors develop 'WitnessPrune' which is an algorithm that efficiently identifies and eliminates redundant elements in neural networks, thereby optimizing their performance without sacrificing accuracy. The paper also bridges theoretical understanding and practical application by establishing insightful connections between discriminant-based classifiers and the TV distance, enhancing the robustness of machine learning models.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper introduces a pioneering approach to neural network pruning that deviates from the standard assumption of Gaussian-distributed class-conditional features. By employing a witness function-based strategy for lower bounding the Total Variation (TV) distance, the research not only addresses the limitations of previous methodologies but also enhances the precision of distributional pruning.\nThe introduction of the WITNESSPRUNE algorithms, derived from these theoretical foundations, which could optimize neural network performance significantly, particularly in resource-sensitive applications.\nWeaknesses:\nThe paper seems to lack extensive testing across a diverse range of neural network architectures and data distributions. This limitation raises concerns about the applicability of the proposed methods in various real-world scenarios and different neural network models.\nThe paper's methodologies rely on certain assumptions regarding witness functions and distribution moments, necessary for theoretical formulations but potentially unrealistic in practice.\nVGG-16 is a very old NN architecture. It would be better if the authors could demonstrate that their approach works for newer NN architecture.\nQuestions:\nHow do these methods scale with increasingly complex and deep neural networks? Is there an in-depth analysis of the computational overhead and efficiency trade-offs when applying the proposed pruning techniques to larger-scale networks, especially compared to traditional pruning methods?\nCould the authors provide further evidence on how the proposed pruning strategies perform across a wider range of scenarios? For instance, how do these methods fare with different types of neural network architectures, and varying data modalities?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer G7wT", "Subheading": "Official CommentbyAuthors17 Nov 2023, 05:39Everyone", "Content": "Comment:\nWe thank the reviewer for the comments and discussion. Specifically:\nThe paper introduces a pioneering approach to neural network pruning that deviates from the standard assumption of Gaussian-distributed class-conditional features. By employing a witness function-based strategy for lower bounding the Total Variation (TV) distance, the research not only addresses the limitations of previous methodologies but also enhances the precision of distributional pruning.\nWe thank the author for their strong appreciation for our work!\nThe introduction of the WITNESSPRUNE algorithms, derived from these theoretical foundations, which could optimize neural network performance significantly, particularly in resource-sensitive applications.\nWe appreciate the attention to our well-founded pruning algorithms.\nThe paper seems to lack extensive testing across a diverse range of neural network architectures and data distributions. This limitation raises concerns about the applicability of the proposed methods in various real-world scenarios and different neural network models.\nWe will provide a new battery of experiments highlighting the efficacy of our algorithm to other datasets and architectures within the next couple of days. Specifically, we will present results evaluating our algorithm on ResNet50 models trained on ImageNet. We'll post those results here, and please check out the general response as well!\nThe paper's methodologies rely on certain assumptions regarding witness functions and distribution moments, necessary for theoretical formulations but potentially unrealistic in practice.\nThe assumptions made on (a) the distributions, and (b) the witness functions themselves, are very minimal. In Theorems 1 and 2, we only assume we have access to $k$ moments of  the distribution. Similarly, the witness functions themselves only need to have bounded first and second order moments; that is $\\mathbb{E}[u^\\top \\varphi(X)] <\\infty$ and $\\mathbb{E}[(u^\\top \\varphi(X))^2] < \\infty$.\nVGG-16 is a very old NN architecture. It would be better if the authors could demonstrate that their approach works for newer NN architecture.\nFurther experiments are being conducted, and are coming soon! In particular, we compare the performance of WitnessPrune with CHIP [2] and TVSPrune [1] for pruning ResNet50 on the ImageNet dataset. We'll post those results both here and in the general response.\nHow do these methods scale with increasingly complex and deep neural networks? Is there an in-depth analysis of the computational overhead and efficiency trade-offs when applying the proposed pruning techniques to larger-scale networks, especially compared to traditional pruning methods?\nWe thank the reviewer for this insightful question. We answer the question in 2 parts.\nTraditional structured pruning strategies that require gradients often require expensive backpropagation in order to compute saliency scores (which are used to identify which filters are important, and which are not).\nIn this work, we focus on the challenging use case where the training data and the loss function are unavailable to us\n. As a benefit to this, we no longer need to compute the gradients.\nThe key computational cost involved in this algorithm is the storage of moments required to compute the $r^l_j$ scoress defined in Equation 7. Unlike previous works such as TVSPrune [1] and CHIP [2], we do not need to store the moments of entire feature maps - we need only store the first two moments of the witness function $f(X) = u^\\top \\varphi(X)$. Thus, prior to computing the $r^l_j$ scores, we only  need to store $2n_l$ real numbers per class for each layer. This is in contrast to [1] and [2], where moments of the entire (flattened) feature maps are stored. Furthermore, unlike prior work such as TVSPrune, for classification tasks where the dataset has $K$ classes, we need only store $2K$ moments, whereas TVSPrune requires the storage of ${K \\choose 2}$ moments.\nCould the authors provide further evidence on how the proposed pruning strategies perform across a wider range of scenarios? For instance, how do these methods fare with different types of neural network architectures, and varying data modalities?\nWe'll post additional experimental results both here and in the general response, in the next 48 hours. Our experiments will focus on ResNet50 model trained on the ImageNet dataset, and compare with some standard baselines [1],[2],[3].\nReferences\n[1]\nTVSPrune - Pruning Non-discriminative filters via Total Variation separability of intermediate representations without fine tuning\n. Murti et al, 2023.\n[2]\nCHIP: CHannel Independence-based Pruning for Compact Neural Networks\n. Sui et al, 2021.\n[3]\nPruning Filters for Efficient Convnets\n. Li et al, 2017."}, {"Heading": "Response to Reviewer G7wT with Additional Experiments", "Subheading": "Official CommentbyAuthors21 Nov 2023, 02:54Everyone", "Content": "Comment:\nResNet50 experiments on Imagenet\nAs requested by the reviewer, we have validated the proposed WitnessPrune algorithm on the ResNet50 model trained on ImageNet.\nWe compare WitnessPrune with CHIP [1], TVSPrune (the variant discussed in Appendix C.3), and L1 [2]. In our experimental setup, we fine-tune our models for 120 epochs with a batch size of 128 (other hyperparameters to be uploaded in the amended draft, in Appendix D). We present our results below.\nAlgorithm\nWitnessPrune\nCHIP\nTVSPrune\nL1\n20.2% sparsity\n(No FT)\n-2.67%\n-2.99%\n-2.85%\n-6.45%\n20.2% sparsity\n(FT)\n+.02%\n+.01%\n-.01%\n-1.08%\n40.2% sparsity\n-2.58%\n-2.74%\n-2.77%\n-4.45%\nObservations\nOur experiments indicate that WitnessPrune clearly outperforms several contemporary baselines on the ImageNet task on the ResNet50 architecture, demonstrating its broad applicability to classification tasks.\nWe hope we've addressed the concerns you raised. If you have additional questions, concerns, or thoughts, we are eager to engage in further discussions.\nReferences\n[1]\nTVSPrune - Pruning Non-discriminative filters via Total Variation separability of intermediate representations without fine tuning\n. Murti et al, 2023.\n[2]\nCHIP: CHannel Independence-based Pruning for Compact Neural Networks\n. Sui et al, 2021.\n[3]\nPruning Filters for Efficient Convnets\n. Li et al, 2017."}, {"Heading": "Official Comment by Reviewer G7wT", "Subheading": "Official CommentbyReviewer G7wT21 Nov 2023, 03:00Everyone", "Content": "Comment:\nThank you for replying to my concerns and conducting additional experiments. After checking other reviewers' comments and considering that I already gave a positive score, I would like to keep the current score."}]}]}, "7Yg5eylBHe": {"paper_info": {"Supplementary Material": "zip", "Primary Area": "optimization", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "distributed machine learning, Bayesian optimization, multi-agent systems, zero-gradient-sum optimization, event-driven mechanism", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Bayesian optimization (BO) is a well-established framework for globally optimizing expensive-to-evaluate black-box functions with impressive efficiency. Although numerous BO algorithms have been developed for the centralized machine learning setting and some recent works have extended BO to the tree-structured federated learning, no previous studies have investigated BO within a fully distributed multi-agent system (MAS) in the field of distributed learning (DL). Addressing this gap, we introduce and investigate a novel paradigm, Distributed Bayesian Optimization (DBO), in which agents cooperatively optimize the same costly-to-evaluate black-box objectives. An innovative generalized algorithm, Zero-Gradient-Sum-Based Event-Driven Distributed Lower Confidence Bound (ZGS-ED-DLCB), is proposed to overcome the significant challenges of DBO and DL: We (a) adopt a surrogate model based on random Fourier features as an approximate alternative to a typical Gaussian process to enable the exchange of local knowledge between neighboring agents, and (b) employ the event-driven mechanism to enhance communication efficiency in MASs. Moreover, we propose a novel generalized fully distributed convergence theorem, which represents a substantial theoretical and practical breakthrough wrt the ZGS-based DL. The performance of our proposed algorithm has been rigorously evaluated through theoretical analysis and extensive experiments, demonstrating substantial advantages over the state-of-the-art baselines.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9310", "PDF Url": "https://openreview.net/pdf?id=7Yg5eylBHe"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9310 by Area Chair 6ZoM", "Subheading": "Meta ReviewbyArea Chair 6ZoM07 Dec 2023, 12:36 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe authors consider the use of Bayesian optimization in a fully distributed multi-agent system. The authors propose an algorithm for this setting, analyze it theoretically, and evaluate it empirically.\nThe reviewers noted some interest in the problem setting of distributed Bayesian optimization, which perhaps has not been thoroughly explored by the existing literature in this area.\nHowever, the reviewers noted some perceived weaknesses in the manuscript as submitted, some of which were judged to be severe:\na lack of clarity in the presented material, with several reviewers expressing difficulty in understanding core developments\nas a result of the above, insufficient motivation for some decisions made by the authors in developing their methodology\nsome concerns regarding the theoretical foundation and analysis\nJustification For Why Not Higher Score:\nDespite engagement with the authors during the author response period, 3 of 4 reviewers continued to express a perceived severe lack of clarity regarding the core ideas and developments in this paper. There was consensus that the manuscript would require significant revision before it would be acceptable for publication.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9310 by Reviewer N4Gg", "Subheading": "Official ReviewbyReviewer N4Gg01 Nov 2023, 03:07 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces a distributed optimization algorithm for multi-agent systems, in which the agents use random Fourier features to model the objective function as a linear function in the random features, and collaboratively estimate the parameter for the linear function.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThe paper derives theoretical guarantees for the parameter estimation.\nThe experimental results do achieve improvements over previous methods.\nWeaknesses:\nThe most important concern I have is regarding the writing and presentation of the paper. I'm relatively familiar with the field of Bayesian optimization, but I find the paper not easy to understand and I am somewhat confused as to what is the connection between the proposed method and Bayesian optimization. If I understand correctly, the paper models the objective function $f$ as a linear function in the random features (equation 4) with parameters $W$, and the proposed algorithm aims to estimate the parameters $W$ (using the methods from equations 12 and 13) and the theoretical guarantees in Section 4 also guarantee the estimation quality for the parameters $W$. However, Bayesian optimization aims to optimize (instead of estimate) the function $f$. Therefore, it's unclear to me why the proposed method is named distributed Bayesian optimization. Also, I'm also confused by equation (7), i.e., why do we need to extend W to be time-varying? Also, none of the baselines compared in the experiments are federated/distributed BO.\nBelow equation (1), the regret bound shown here is for time-varying Bayesian optimization, I wonder why is that the case?\nSection 3.2, I think the presentation of this section can be further polished. Below equation (11), what is $\\hat{W}$? The estimated $W$ since the last information exchange? In the next paragraph, what is a \"sub-iteration\"? It is never mentioned that the proposed method has an inner loop with sub-iterations. Remark 2: again it's confusing to me why the parameters are time-varying.\nSection 3.3: I find this section not easy to understand. Perhaps it will help understanding if more intuitions/descriptions are given in addition to the equations.\nStage 2 in Section 3.3: it says here that based on the $W^{i^*}_t$, each agent can calculate the Gaussian process posterior mean and variance. But in my understanding, with a single parameter vector $W$, we can only calculate a single function value at an input (see equation 4). To be able to calculate the GP posterior mean and variance, we need the entire distribution of $W$ (see Dai et al., (2020)). Please give the exact equations using which the GP posterior mean and variance are calculated.\nSection 4.1: I also find this section not easy to understand.\nQuestions:\nPlease see the questions I listed above under Weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment", "Subheading": "Official Commentby21 Nov 2023, 09:56 (modified: 21 Nov 2023, 09:58)EveryoneRevisions", "Content": "[Deleted]"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 10:12 (modified: 21 Nov 2023, 10:15)EveryoneRevisions", "Content": "Comment:\nResponse for Strengths:\nWe are grateful for your acknowledgement and positive assessment of the theoretical guarantees and the experimental results in our research.\nResponse for Weaknesses/Questions:\n(1). We appreciate your feedback regarding our writing and presentation. Bayesian optimization (BO) aims to optimize the objective function indeed, and we design the novel distirbuted BO (DBO) paradigm in order to optimize the global objective function (7) of DBO (equally $f$ in (4)) over a fully distributed multi-agent system (MAS). The whole procedure of BO includes surrogate modeing and derserving next potential profitable locations by acquisition functions. Gaussian process (GP) is the mainstream choice for surrogate modeling. Acquisition functions are utilized to search next potential profitable locations. In our work, Random Fourier features (RFF) are used to replace a typical GP of BO. The reference paper \"Dai et al., 2020\" illustrates that \"A GP with RFF approximation can be interpreted as a Bayesian linear regression model with $\\phi(x)$ as the features\". However, unlike that $W$ are sampled according to (2) of \"Dai et al., 2020\" in the FBO setting, $W$ is derived by training in our DBO setting, specifically, training by our presented ZGS-ED-DLCB according to (12). We call our presented paradigm DBO because we are the first to extend BO to the distributed learning (DL) setting of a fully distributed MAS, similar to that FBO origins by extending BO to the federated learning (FL) setting (please see the rederence paper \"Dai et al., 2020\", for example, the Abstract section).\nNaturally and necessarily, $W$ is time-varying in the DBO setting. $t$ represents the iteration index of ZGS-ED-DLCB and local BO. After one iteration, one potential location and its corresponding output is derived by each agent. Then, the corresponding $S_t^i$ is changed because the available data samples are increased to update $S_t^i$. Then $W$ are also necessarily changed by the next iteration step of ZGS-ED-DLCB. Thus, $W$ should be time-varying.\nWe present the novel DBO paradigm, and we present the first DBO algorithm, ZGS-ED-DLCB. No prior DBO algorithms have been developed before. Both DBO and FBO are paradigms in the field of distributed machine learning. FL is tree-structured and DL is decentralized, so FBO algorithms cannot be implemented in the DBO setting. Similar to the reference paper \"Dai et al., 2020\", well-known DL algorithms including the DCL, ATC-LMS, CTA-LMS and ADMM-based algorithms are adjusted to adapt to the DBO setting as the baselines in the comparative experiments. Moreover, in the FBO experiments, none of the baselines compared in the experiments are federated/distributed BO.\n(2). In contrast to centralized BO, DBO is the corresponding fully distributed version. In the theory of distributed learning, learning performance of distributed learning equals to that of centralized learning. DBO does not change the regret bound of the centralized BO. Regret bound of the ZGS-ED-DLCB algorithm originates from to the theory of Regret Bound in Section 4.2 of Bogunovic et al. (2016). In terms of the squared exponential (SE) kernel, the regret bound of the ZGS-ED-DLCB algorithm is $R_T=\\tilde{\\mathcal{O}}(\\max\\lbrace\\sqrt{T}, T\\epsilon^{1/6}\\rbrace)$ when employing the local LCB acquisition functions and the RFF-based surrogate model according to Corollary 4.1 of Bogunovic et al. (2016). Please see App. M.\n(3). $\\hat{{W_t^i}}(k)$ is the local transferred weight vector at the $k$th sub-iteration step during the $t$th iteration step. To illustrate our ZGS-ED-DLCB algorithm more detailedly, the pseudocode is shown in App. C. From the pseudocode, we can see the the update of $W_{t}^{i}(k)$ includes $T$ iterations from 1 to $t$, of which each includes $K$ sub-iterations from 0 to $K$ in Stage 1. Thus, $t$ indexes the iteration, $k$ indexes the sub-iteration. The parameters are time-varying because lcoal data samples are actually increased after each iteration step indexed by $t$ and the parameters corresponding to the calculation process of ZGS-ED-DLCB in each iteration step are changed with the index $t$.\n(4). In response to your concerns, we have revisited our manuscript with a fresh perspective and revised it. If you are interested, the final version will deliever the revised manuscript.\n(5). RFF are utilized to approximate a typical, so the approximated GP posterior mean and variance are calculated in this paper. Similar to the work Dai et al., (2020), the posterior mean and variance are calculated according to formulae (6) and (7) in App .B of Dai et al., 2020. The corresponding computing formula for our ZGS-ED-DLCB in the DBO setting will be shown in our revised manuscript.\n(6). In response to your concerns, we have revisited our manuscript with a fresh perspective and revised it. If you are interested, the final version will deliever the revised manuscript."}]}, {"Heading": "Official Review of Submission9310 by Reviewer ugDi", "Subheading": "Official ReviewbyReviewer ugDi30 Oct 2023, 20:26 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper studies distributed Bayesian optimization in a multi-agent setting where private raw data cannot be shared among neighboring agents. The authors introduce the ZGS-ED-DLCB algorithm to address the challenge of expensive black-box optimization over a network. In this context, agents possess local data and must collaborate to achieve a global objective. The algorithm employs an event-driven mechanism to trigger communication between agents when necessary, thereby reducing the overall communication burden within the network. The paper includes theoretical and experimental results to demonstrate the efficiency and effectiveness of the proposed algorithm.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThe problem-setting appears interesting and worthy of exploration. The authors provide some theoretical analysis for their algorithm, ZGS-ED-DLCB.\nWeaknesses:\nI have to say the paper is not well written. It suffers from a lack of clarity in terms of writing, notation, and explanation, making it challenging to follow. From the problem formulation to the theoretical results, several essential details are omitted. Understanding the context is difficult, necessitating multiple visits to the appendices. I would suggest the authors maintain the core message within the main paper while relocating unnecessary sections to the appendix.\nFurthermore, the main technical contributions remain poorly explained, with insufficient references to existing literature. High-level intuitions are well presented. It is hard for me to evaluate the theoretical contribution.\nRegarding the contributions you claim, it is unclear how your algorithm tracks expensive-to-evaluate black-box optimization. Additionally, the paper does not adequately demonstrate how your algorithm handles limited data and how it compares to existing approaches. The privacy preservation aspects are mentioned, but the extent and specific mechanisms are not detailed.\nSome minor comments:\nThe line immediately following equation (11) introduces $\\hat{W}_t^i$, but this term is not defined.\nThe introduction of the notion of \"regret\" raises questions as the paper does not present the associated results.\nQuestions:\nSee weaknesses\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 09:57Everyone", "Content": "Comment:\nResponse for Strengths:\nWe appreciate your positive remarks about the problem setting and theoretical analysis of the presented ZGS-ED-DLCB algorithm in our work.\nResponse for Weaknesses/Questions:\n(1) We appreciate your feedback regarding our writing and presentation. We have revisited our manuscript with a fresh perspective and revised it. If you are interested, the final version will deliever the revised manuscript.\n(2) We have revisited our manuscript with a fresh perspective and revised it. DBO is a novel paradigm that we introduce and investigate, no prior DBO algorithms or exist. Could you please display the additional reference papers you think that we should reference to us?\n(3) In our paper, the data samples used in the whole experiments are limited to each agent. Compared with the traditional centralized BO, the decentralized learning framework in the DBO setting has the following advantages in terms of privacy: \n  (a) Data Localization: In fully distributed learning, each node processes its own data locally and shares only model updates (like weight updates or gradients), not the raw data. This means that raw data doesn't need to propagate through the network, reducing the risk of data leaks.\n  (b) Reduced Centralization Risk: In centralized learning, all data is brought to a central node for processing. If this central node is compromised, all data could potentially be exposed. In fully distributed learning, there's no such central node, reducing the overall attack surface of the system.\n  (c) Regulatory Compliance: In some cases, the storage and processing of data may be subject to strict regulatory requirements, such as GDPR. In these cases, distributed learning allows for data to be processed locally, making it easier to meet these regulatory requirements.\nResponse for Minor Comments:\n(1) The latest transferred knowledge of agent $i$ is denoted as $\\hat{{W_t^i}}(k)=W_{t}^{i}(k_{t,i}^{m_{i}})$. We have revisited our manuscript with a fresh perspective and revised it.\n(2) We are the first to present nontions of regret in the DBO setting. In the synthetic experiments, the evaluation metric $R_T/T$, which is associated with the global cumulative regret $R_T$, is used to compare the learning performance of ZGS-ED-DLCB with the baselines is in the paper."}]}, {"Heading": "Official Review of Submission9310 by Reviewer EeJ5", "Subheading": "Official ReviewbyReviewer EeJ530 Oct 2023, 19:45 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\n***** I do not have enough background knowledge to provide a fair review of this paper, since it is totally out of my scope. I sincerely request the AC to introduce another reviewer. I have set my confidence score to be 2 to indicate this.*******\nThis paper studies Bayesian optimization method for the fully distributed multi-agent systems. A new algorithm is proposed and the convergence is proved.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThe problem setting is quite clear, and the authors describe their method straightforwardly.\nThe theoretical results are provided, an upper bound of the regret is given.\nThe experiment part is strong and shows improved results.\nWeaknesses:\nI am quite confuse about the comparison of the results to other papers. For example, is the regret bound in (15) matching the SOTA? I think some discussion on the related works and results are missing.\nQuestions:\nSee above.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 09:55Everyone", "Content": "Comment:\nResponse for Strengths:\nWe greatly appreciate your positive remarks on the problem setting, theoretical results and experimental aspects of our work.\nResponse for Weaknesses/Questions:\nIn contrast to centralized BO, DBO is the corresponding fully distributed version. In the theory of distributed learning, learning performance of distributed learning equals to that of centralized learning. DBO does not change the regret bound of the centralized BO. Regret bound of the ZGS-ED-DLCB algorithm originates from to the theory of Regret Bound in Section 4.2 of Bogunovic et al. (2016). In terms of the squared exponential (SE) kernel, the regret bound of the ZGS-ED-DLCB algorithm is $R_T=\\tilde{\\mathcal{O}}(\\max\\lbrace\\sqrt{T}, T\\epsilon^{1/6}\\rbrace)$ when employing the local LCB acquisition functions and the RFF-based surrogate model according to Corollary 4.1 of Bogunovic et al. (2016). Please see App. M."}]}, {"Heading": "Official Review of Submission9310 by Reviewer BqAx", "Subheading": "Official ReviewbyReviewer BqAx21 Oct 2023, 11:18 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors study the problem of distributed BO, in which multiple agents wish to optimize the same black-box objective function in a sample-efficient manner but cannot share their data due to privacy concerns. The authors propose ZGS-ED-DLCB, an algorithm that circumvents the problem by sharing the parameters of a random Fourier features model instead of the data directly. The algorithm builds off an event-triggered zero-gradient sum algorithm in the distributed learning literature. The authors provide theoretical results to show the convergence of the parameters of all agents in each iteration. The authors compare ZGS-ED-DLCB to previous algorithms in the distributed learning literature.\nSoundness:\n1 poor\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nApplying the event-triggered zero-gradient-sum algorithm to BO may be of interest to BO practitioners interested in distributed BO with privacy concerns.\nThe authors show that their algorithm outperforms previous algorithms in the distributed learning literature, suggesting that their algorithm has empirical advantages within the BO setting as compared to these other algorithms.\nWeaknesses:\nThe paper has several major weaknesses:\nTechnical misconception of random Fourier features (RFF) in a BO context.\nSection 3.3, Stage 2 says \"Based on the obtained $W_t^{i*}$, each agent calculates the aforementioned mean and prediction variance at the iteration step t. Using the calculated $m_t(\\mathbf x^*)$ and $\\hat \\sigma_t^2(\\mathbf x^*)$, the RFF-based DLCB acquisition function is employed...\" where DLCB is a UCB-type acquisition (lower bound version). $W_t^{i*}$ are the parameters to the linear model that arises from a RFF approximation of the GP ($\\omega$ in [1]); specifically, the parameters that minimize the linear model's regularized L2 loss with respect to all agents' data. The problem arises as $W_t^{i*}$ has nothing to do with the computation of $m_t(\\mathbf x)$ and $\\hat \\sigma_t^2(\\mathbf x)$. In a RFF context, $m_t(\\mathbf x)$ and $\\hat \\sigma_t^2(\\mathbf x)$ are computed only using $s$ ($\\phi$ in [1]), i.e., the RFF approximation to the kernel $k$, along with the data (see Appendix B in [1]). This begs the question, what is the use of computing $W_t^{i*}$ if a UCB algorithm is to be used subsequently? Computing $W_t^{i*}$ makes sense in a Thompson sampling context (as was done in [1]), but not with UCB algorithms. This renders the significance of most of the technical content in this paper questionable since most of the paper is devoted to the ZGS-based algorithm for computing $W_t^{i*}$.\nExperiments do not compare to the most relevant baselines, and results are not presented well.\nThe paper makes mention of [1] and [2], and the idea of using RFF to share information in a parametric manner is borrowed from [1]. In a BO context, [1] is clearly the closest work. However, the experiments do not compare against the algorithms from [1] and [2], and instead compare against existing algorithms in the distributed learning (DL) literature. This is a problematic choice given that, in the introduction, the authors claim that \"the existing DL works ... do not consider the expensive black-box optimization problems utilizing limited data\", so why only use them for the experiments and exclude the directly relevant algorithms from [1] and [2]? This weakens the empirical support for the proposed algorithm. Furthermore, the authors present the number $R_T/T$ without error bars in tables instead of graphs of the per iteration cumulative regret as is standard for BO works in order to compare the convergence over time.\nSignificance of theory is questionable.\nFrom a BO perspective, this paper does not contribute anything theory-wise. All the results are about the convergence of the parameters $W$ in each iteration due to the ZGS algorithm, and it is not clear how this suggests sublinear regret. There is a cryptic paragraph about a regret bound in Appendix M (not referenced from the main paper) which handwaves the issue to the results from another paper. From a distributed learning perspective, I am not sure that this paper has significant contribution, since the BO problem is turned into a linear regression problem upon which the ZGS algorithm is applied, but the ZGS algorithm builds upon work in [3] which is for continuously differentiable strongly convex problems, a more general class of problems.\nSevere clarity issues\n:\na. Problems with notation. Some variables are used before they are defined e.g. $W(k)$, and some are never defined at all e.g. $\\hat \\sigma_2(\\mathbf x)$. Some notation is inconsistent e.g. $\\mathbf x$ and $x$ are both for inputs; vectors are sometimes denoted in lower case, sometimes they are in bold lower case, sometimes they are in upper case. Some notation is just wrong, e.g., in Appendix B, an input output pair is written as $(\\mathbf x_1, f(\\mathbf x_1))$, and then the output is later referred to as $y_1$, but $f(\\mathbf x_1)$ and $y_1$ are separate quantities, the latter is the noise-corrupted version of the former.\nb. Extensive typos and grammatical errors, including but not limited to: \"addressing these significant gaps, we aim to design a DBO algorithm that solves costly-to-evaluate black-box optimization problems in a fully distributed multi-agent system (MAS) is nontrivial and promising\"; \"It is the first time to provide\"; \"2.1 ALTERNATIVE TO A GAUSSIAN PORCESS\"; \"As aforementioned discussions\".\n[1] Dai et. al., 2020. \"Federated Bayesian optimization via Thompson sampling\".\n[2] Dai et. al., 2020. \"Differentially private federated Bayesian optimization with distributed exploration\".\n[3] Chen and Ren, 2016. \"Event-triggered zero-gradient-sum distributed consensus optimization over directed networks\".\nQuestions:\nNo questions other than those listed in the Weaknesses section.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n1: strong reject\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 10:29 (modified: 22 Nov 2023, 07:41)EveryoneRevisions", "Content": "Comment:\n(1). Bayesian optimization (BO) aims to optimize the function indeed, and we design the novel distirbuted BO (DBO) paradigm in order to optimize the global objective function (7) of DBO (equally $f$ in (4)) over a fully distributed multi-agent system (MAS). The whole procedure of BO includes surrogate modeing and derserving next potential profitable locations by acquisition functions. Gaussian process (GP) is the mainstream choice for surrogate modeling. Acquisition functions are utilized to search next potential profitable locations. In our work, Random Fourier features (RFF) are used to replace a typical GP of BO. The reference paper \"Dai et al., 2020\" illustrates that \"A GP with RFF approximation can be interpreted as a Bayesian linear regression model with $\\phi(x)$ as the features\". However, unlike that W are sampled according to (2) of \"Dai et al., 2020\" in the FBO setting, $W$ is derived by training in our DBO setting, specifically, training by our presented ZGS-ED-DLCB according to (12). Then the local RFF-based DLCB is utilized to deserve the next profitable location by using the trained $\\hat{W}_{t}^{i}(K)$ for each agent in each iteration step.\n(2). Thanks a lot for reading the reference paper \"Dai et al. (2020)\", which is [1] in your mark. The reference paper [2] you mark is \"Dai et al. (2021)\" in our reference list. Although both tree-structured federated learning (FL) and decentralized (fully) distributed learning (DL) are distinct distributed machine learning paradigms, FBO in FL and DBO in DL are distinct paradigms. FBO/FL algorithms cannot be implemented in the DBO/DL setting. We reference Dai et al. (2021; 2020), however, it's not feasible to conduct comparative experiments using the algorithms presented in those references. We introduce and investigate the novel DBO paradigm, and we present the first DBO algorithm, ZGS-ED-DLCB. No prior DBO algorithms have been developed before. Similar to the comparative experiments in Dai et al. (2020), well-known DL algorithms including the DCL, ATC-LMS, CTA-LMS and ADMM-based algorithms are adjusted to adapt to the DBO setting as the baselines in the comparative experiments.\nMoreover, in the FBO experiments, none of the baselines compared in the experiments are federated/distributed BO. The following is a direct quote from the NeurIPS reference paper Dai et al. (2020): \"Although FTS is the first algorithm for the FBO setting, some algorithms for meta-learning in BO, such as ranking-weighted GP ensemble (RGPE) [16] and transfer acquisition function (TAF) [55], can be adapted to the FBO setting through a heuristic combination with RFF approximation.\". Drawing inspiration from the experimental design in Dai et al. (2020), we have constructed comparative experiments for the first DBO algorithm.\n(3). We consider the expensive-to-evaluate black-box optimization problem within a fully distributed multi-agent system (MAS) and create a distributed BO (DBO) algorithm, ZGS-ED-DLCB. Moreover, no prior works inverstigate the problem (including leveraging BO) in a fully distributed MAS. In very recent years, novel federated Bayesian optimization (FBO) algorithms, which precede the development of DBO algorithms, (Dai et al. (2021; 2020)) are developed in the federated learning (FL) setting. Tree-structured federated learning (FL) and decentralized (fully) distributed learning (DL) are distinct distributed machine learning paradigms. Similiar to that Dai et al. (2020) presents the FBO paradigm and the first FBO algorithm in the FL setting, we propose the DBO paradigm and the first DBO algorithm in the DL setting. In contrast to the FBO in the FL setting, DBO faces unique challenges to tackle, which are illustrated in the Introduction section. At the end of Introduction section, the main contributions are summerized.\n(4). In response to your concerns, we have revisited our manuscript with a fresh perspective and revised it. If you are interested, the final version will deliever the revised manuscript."}, {"Heading": "Official Comment by Reviewer BqAx", "Subheading": "Official CommentbyReviewer BqAx22 Nov 2023, 09:54Everyone", "Content": "Comment:\nThanks for your response.\nMy question hasn\u2019t been answered. The algorithm from Dai et. al. (2020) is Thompson sampling where $W^i_t{}^*$ is used. Your algorithm is a UCB variant where $W^i_t{}^*$ is not used and only $m_t$ and $\\hat{\\sigma}^2$ are used. Thompson sampling and UCB are different algorithms. $W^i_t{}^*$ is not involved in the computation of $m_t$ and $\\hat{\\sigma}^2$. Why exactly is $W^i_t{}^*$ computed in your algorithm at every iteration?\nWhy exactly is the FBO setting incompatible with the DBO setting? Please describe the incompatibility precisely by comparing their problem formulations. Surely the algorithm from Dai et. al. (2020) can be adapted to the DBO setting, even if assuming a specific network topology is necessary.\nYou may be the first to combine the DL setting with BO, but this does not address the issue that the theoretical results in Section 4 are not significant from either a BO or a DL perspective."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 07:01 (modified: 23 Nov 2023, 07:14)EveryoneRevisions", "Content": "Comment:\nThanks for your interests and comments.\nResponse:\n${W_t^i}^*$ is derived by training and used in each iteration step of ZGS-ED-DLCB. Specifically, it is utilized in the calculation of  local mean function $m_{i, t}\\left(\\mathrm{x}\\right)=S_t^i {W_t^i}^*$ (please refer to the equation (5) in our work) for each agent. The calculation of $m_{i, t}\\left(\\mathrm{x}\\right)$ is eaisier and more resource-saving than that of the FBO algorithms. In terms of the aforementioned corresponding or relevant content, we have revisited our manuscript with a fresh perspective and revised it. If you are interested, the final version will deliever the revised manuscript.\nThe problem formlation can be the same for FBO and DBO. However, while FBO uses a tree-structured paradigm with a cloud server, DBO is a decentralized paradigm without the use of a server. The FBO setting includes a cloud server, while no server is leveraged in the DBO setting. The procedure of an FBO algorithm includes the agent side and the server side, whereas the procedure of a DBO algorithm only involves the agent side. The distinction extends beyond just the network topology. There are specific communication mechanisms and limitations in the settings of fully distributed learning (DL) and federated learning (FL), not just in the aspect of network topology. Therefore, FBO algorithms are not incompatible with the DBO setting, and vice versa. FL origins much later than DL, although they are both distributed machine learning paradigms. According to your concern, why are the FBO algorithms not compared with the adapted DL algorithms in the FBO works? It seems that comparative experiments involving the adapted well-known DL algorithms (should be adapted as you expect) in the FL setting should be implemented. But the authors of the FBO works do not handle these and it is not unreasonable due to the distinction of the DBO and FBO settings.\nThank you for noticing the phrase \"the first\". We highlight the sentence in our abstract \"Moreover, we propose a novel generalized fully distributed convergence theorem, which represents a substantial theoretical and practical breakthrough wrt the ZGS-based DL.\" to emphasize that our ZGS-ED-DLCB algorithm overcomes the drawback exists in the recent ZGS-based DL algorithms that we notice theoretically and practically, in which all agents require the $S_{t}^{i}$ from the other agents to work. ZGS-ED-DLCB is a feasible algorithm in practice."}]}]}, "fGskrC9Wy1": {"paper_info": {"Primary Area": "optimization", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Recurrent Neural Networks, Long Short-Term Memory, Sequence classification, Boosted architectures", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "The Boosted LSTM model, enhanced with additional layers inside the unit, outperforms standard LSTM architectures in empirical tasks, often converging in fewer epochs.", "Abstract": "Long Short-Term Memory (LSTM) is widely known as a powerful type of Recurrent Neural Network, allowing it to achieve great results on many difficult sequential data tasks. \nNumerous experiments have shown that adding more complexity to neural network architectures may lead to a significant increase in performance that outweighs the incurred costs of an upgraded structure.\nIn this paper, we propose a Boosted LSTM model created by adding layers inside the LSTM unit to optimize the model by enhancing its memory and reasoning capabilities.\nWe evaluated the performance of different versions of Boosted LSTM architectures using three empirical tasks, studying the impact of different placements of additional layers, the activation functions used in the additional layers, and the model's hidden units.\nThe experiments have shown that the Boosted LSTM unit, which uses Exponential Linear Unit as its boosted layers activation function, performs better than the similar models created from the simple LSTM units while often taking fewer epochs to achieve similar or better results, usually in a smaller number of training epochs.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9308", "PDF Url": "https://openreview.net/pdf?id=fGskrC9Wy1"}, "review_info": []}, "Xsrsj3cne4": {"paper_info": {"Primary Area": "learning on graphs and other geometries & topologies", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Graph Neural Networks, Robustness, Lipschitz Regularization", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Graph Neural Networks (GNNs) have exhibited exceptional performance across diverse application domains by harnessing the inherent interconnectedness of data. However, the emergence of adversarial attacks targeting GNNs poses a substantial and pervasive threat, compromising their overall performance and learning capabilities. While recent efforts have focused on enhancing GNN robustness from both data and architectural perspectives, more attention should be given to overall network stability in the face of input perturbations. Prior methods addressing network stability have routinely employed gradient normalization as a fundamental technique. This study introduces a unifying approach, termed as AdaLip, for adversarial training of GNNs through an optimization framework that leverages the explicit Lipschitz constant. By seamlessly integrating graph denoising and network regularization, AdaLip offers a comprehensive and versatile solution, extending its applicability and enabling robust regularization for diverse neural network architectures. Further, we develop a provably convergent iterative algorithm, leveraging block majorization-minimization, graph learning, and alternate minimization techniques to solve the proposed optimization problem. Simulation results on real datasets demonstrate the efficacy of AdaLip over state-of-the-art defence methods across diverse classes of poisoning attacks. On select datasets, AdaLip demonstrates GCN performance improvements of up to 20% against modification attacks and approximately 10% against injection attacks. Remarkably, AdaLip achieves a similar performance gain on heterophily graph datasets.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9303", "PDF Url": "https://openreview.net/pdf?id=Xsrsj3cne4"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9303 by Area Chair nh4z", "Subheading": "Meta ReviewbyArea Chair nh4z07 Dec 2023, 04:59 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nSummary: The submission proposes a method for making GNNs more robust by integrating graph denoising and network regularization.\n\n+ The paper studies an important problem.\n+ The optimization-based perspective is interesting.\n+ The experiments, though limited, show improvements over some baselines.\n\n- The paper lacks clarity.\n- The correctness/significance of the theorectical claims is unclear.\n- The experimental setup is lacking in some aspects, e.g. stronger attacks, and more recent baselines.\nJustification For Why Not Higher Score:\n- The paper lacks clarity.\n- The correctness/significance of the theorectical claims is unclear.\n- The experimental setup is lacking in some aspects, e.g. stronger attacks, and more recent baselines.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9303 by Reviewer umJp", "Subheading": "Official ReviewbyReviewer umJp01 Nov 2023, 02:41 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper claims to address the vulnerability of GNN to adversarial attacks. While the topic is of interest, the paper's approach and presentation leave much to be desired. The authors introduce AdaLip, an optimization-based framework, but the effectiveness of this method are questionable based on the provided content.\nSoundness:\n1 poor\nPresentation:\n1 poor\nContribution:\n1 poor\nStrengths:\nThe paper attempts to introduce an optimization-based framework, which could be of interest if executed well.\nWeaknesses:\n1.  The paper lacks a clear and coherent structure. The introduction does not set a clear stage for the problem, and the motivation behind the proposed method is weak.\n\n2. Notation Issues: The paper is riddled with unclear and undefined notations, which severely hampers its readability. Examples include:\n\n$f$ in eq(2)\n\n$\\lambda$ in eq(4)\n\n$\\mathcal{X}$ in eq(6)\n\n$\\theta(x, \\Delta)$ in eq(6).\n\n$d$ in eq(7)\n\n$\\mathcal{L}, \\mathcal{A}$ in Lemma 2\n\nFurthermore, there are inconsistencies in notation usage, such as\n\n $\\left(\\theta_{(k+1)}, \\phi_{(k+1)}\\right)$ and $\\left(\\theta_{(k+1)}, \\omega_{(k+1)}\\right)$.\n\nIn eq(8), it writes $\\min _{\\theta, \\phi \\in \\mathcal{S}_\\phi}$, however this is different from eq(3).\n\n3. Lack of Motivation for Lemmas: The relevance of certain lemmas, such as Lemma 1, is not clear. Why is it necessary, and how does it contribute to the overall narrative?\n\n\n4. Unclear Statements: The paper contains several vague statements that lack clarity or justification:\n\n\"On the contrary, this research explores methods for enhancing the robustness of training across diverse architectural models by inherently minimizing the likelihood of failure, quantified through its stability coefficient.\"\n\nClarification needed: How does your approach differ in terms of \"robustness of training\" compared to other methods?\n\n\"The overall objective of learning a stable hypothesis $\\theta$ as GNN parameters under the constraint of learning a denoised graph structure can be formulated as the general optimization problem\". \"The set $\\mathbb{S}_\\theta$ contains all possible stable hypothesis functions mapping from the domain set to the labelled set.\"\n\n-Clarification needed: How exactly is a \"stable hypothesis\" defined in this context? It is just a combination of GNN under the constraint of a denoised graph structure. \n\n\"One effective method for enforcing Lipschitz constraints on a network during training involves normalizing the parameters of each layer using Projected Gradient Descent (PGD).\"\n\n-Clarification needed: Is there a reference here?\n\n\"Without loss of generality, the adaptive Lipschitz regularization in (9) can be equivalently replaced by a logarithmic counterpart.\"\n\n-Clarification needed: Can you provide proof or justification for this equivalence?\n\n\"Lemma 2. By defining linear operators $\\mathcal{L}, \\mathcal{A}$ and respective adjoint operators $\\mathcal{L}^{\\star} \\mathcal{A}^*$\"\n\n-Clarification needed: What is the objective of this lemma? How are these linear operators defined, and why do we need the transformation from (10) to (11)?\n\n\"$\\Delta_{(k)}$ denote the optimal adjacency matrix corresponding to the optimal graph Laplacian $\\phi_{(k)}$ at the $k^{\\text {th }}$ iteration while solving (8).\"\n\n-Clarification needed: what are the iterations here?\n\n5. Theoretical Errors: \n\nIn the derivation of Theorem 1, the initial inequality appears ambiguous. Either there are missing assumptions that need to be explicitly stated, or the derivation is flawed.\n\nThe assertion that $\\left|X^{(0)}\\right|_F=\\sqrt{d}$ lacks justification. What is the basis for this equality?\n\nUpon examining Lemma 1 and its accompanying proof, I am at a loss for words regarding its presentation and rigor.\n\nI ceased my examination of the subsequent proofs due to the glaring inadequacies in the mathematical statements presented thus far.\n\n6. Grammatical Oversights: The paper is marred by numerous grammatical errors, particularly concerning punctuation. A glaring oversight is the absence of punctuation marks following ALL equations throughout the document.\n\n7. Disconnect Between Theory and Experiments: The paper claims that AdaLip performs well on heterophily graph datasets, yet there's no evidence or explanation supporting this claim.\n    \n8. Experimental Deficiencies: The experimental section is glaringly inadequate. Not only does it lack a comprehensive set of baselines, but the range of attacks considered is also severely limited. It is imperative to incorporate evaluations against poison and evasion attacks, as well as both white-box and black-box scenarios, and to consider both injection and modification types.\n\nThe glaring omission of a multitude of established works on Lipschitz regularization for GNNs is concerning. This oversight casts doubt on the rigor of the literature review.\n\nFurthermore, the paper fails to report any computational costs, leaving readers in the dark about the practicality of the proposed method.\nQuestions:\nPlease clarify the issues raised in the weaknesses section.\n\nIn its current form, I cannot in good conscience recommend this paper for acceptance. I strongly advise the authors to rigorously revise and contemplate resubmission to a future conference.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer umJp", "Subheading": "Official CommentbyAuthors22 Nov 2023, 02:03Everyone", "Content": "Comment:\nThanks for your detailed review. We are going to address your concerns one by one as follows:\n\n**Question: Undefined Notations.**\n\nResponse: Thanks for pointing it out. We will clearly state each notation in the paper. $f_{\\theta}$ in (12) represents the GNN function. $\\lambda$ in (4) is a regularization parameter. $d$ in (7) represents the input feature dimension. $\\chi$ is the domain set. $\\theta(x,\\Delta)$ is a typo; kindly consider it $f_{\\theta}(x,\\Delta)$, which represents GNN as a function of input feature and graph.\n\n**Question: Lemma 2 and operators $\\mathcal{L}$ and $\\mathcal{A}$.**\n\nResponse: The detailed analysis of Lemma 2 and both operators is presented in Appendix C. Using the Lemma 2 problem (10) gets simplified as the matrix variable $\\phi$, which is graph Laplacian can be replaced by the vector $\\omega$.\n\n\n**Question: How does your approach differ in terms of \"robustness of training\" compared to other methods? How exactly is a \"stable hypothesis\" defined in this context?**\n\nResponse: The stability of a neural network is quantified by its sensitivity toward small variations in the inputs. In literature, several approaches have been used to make the machine robust towards perturbations in the input data. The methods can broadly be summarized in three approaches:\n\n1.) Training networks with perturbed versions of the data.\n\n2.) Approaches where the goal is first to obtain the clean data and then train the network\n\n3.) Studies that aim to use mathematical notions of stability.\n\nPrevious methods are not mathematically proven to be robust toward input perturbations. In this paper, we have considered the notion of stability as a bounded Lipschitz constant for the graph neural network. The notion of stability using the Lipschitz property is quite popular in the analysis of non-linear systems. A system with a bounded Lipschitz constant can be easily proven robust toward input variations. \n\nOur current work focuses on providing a unified way where one can use the Lipschitz property while training the neural network without changing the overall architecture to provide robustness towards adversarial perturbations. Previous works that have enforced Lipschitz property while training have used brute-force methods where the layerwise weights are normalized [1,2]. This is the first work to formulate an optimization problem where the Lipschitz property is posed as an objective. Additionally, we have provided an iterative algorithm to solve the proposed optimization problem. Extensive experiments have demonstrated that the proposed approach is superior compared to state-of-the-art methods. \n\n**Question: Use of Projected Gradient descent**\n\nResponse: By using projected gradient descent similar to [1], the parameters can be normalized after every iteration in order to have a $\\kappa$-Lipschitz stable model. In literature often the $\\kappa$  is taken as unity. However, several studies have pointed the tradeoff in terms of expressiveness while doing such normalization [2,3]. Hence, in this work we propose an optimization based method for adaptive Lipschitz regularization.\n\n**Question: Clarification on the proof of Theorem 1**\n\nResponse: Thank you for highlighting this concern. We have modified the proof in the paper with all assumptions and details.\n\n**Question: Results on Heterophily datasets.**\n\nResponse: The results are presented in Section 5.3. \n\n**Question: Use of $\\log$ in (10)**\n\nResponse: Thank you for bringing this to our attention. The problem of minimizing the product of functions is indeed transformed to minimize the sum of logarithms, aiming at simplifying mathematical analysis and ensuring numerical stability. However, our previous formulation did not explicitly involve taking the logarithm of the entire objective function, leading to a non-equivalent representation between equations (9) and (10). In line with the feedback from reviewer C1i6, we agree with the suggestion to directly add the log in the original definition eq (9).\n\n**Question: Meaning of iterations**\n\nResponse: Since the problem (9) is a multi-block non-convex optimization problem, we devise an iterative algorithm for solving it.\n\n[1]: Gouk, H., Frank, E., Pfahringer, B., & Cree, M. J. (2021). Regularisation of neural networks by enforcing lipschitz continuity. Machine Learning, 110, 393-416.\n\n[2]: Zhao, X., Zhang, Z., Zhang, Z., Wu, L., Jin, J., Zhou, Y., ... & Yan, D. (2021, July). Expressive 1-lipschitz neural networks for robust multiple graph learning against adversarial attacks. In International Conference on Machine Learning (pp. 12719-12735). PMLR.\n\n[3]: Anil, C., Lucas, J., & Grosse, R. (2019, May). Sorting out Lipschitz function approximation. In International Conference on Machine Learning (pp. 291-301). PMLR."}, {"Heading": "Additional Results", "Subheading": "Official CommentbyAuthors22 Nov 2023, 04:43Everyone", "Content": "Comment:\n**Question: Runtime Analysis**\n\nResponse: The table shows runtime comparison of different methods for 400 epochs on Cora dataset.\n\n| **Method** | **Time (s)** |\n|------------|--------------|\n| GCN        | 5.87         |\n| ProGNN     | 770.56       |\n| AdaLip.J   | 201.89       |\n| AdaLip.2   | 56.29        |\n\n**Robustness Unit Test**\n\nWe perform a robustness test of our proposed method following [1]. A unit test is proposed consisting of several adaptive attacks. The attacks that are based on Vanilla GCN are considered non-adaptive. The unit test consists of poisoning attacks over a range of budget 0 to 15% of E (E=Total no. of edges). We present the results of the attacks that lead to maximum degradation in Vanilla GCN performance on Cora-ML dataset.\n\n| **Adaptive Attack** | **GCN** | **RGCN** | **ProGNN** | **AdaLip** |\n|---------------------|---------|----------|------------|------------|\n| Jaccard-GCN         | 57.60   | 56.84    | 61.67      | **71.08**  |\n| GCN-SVD             | 80.33   | 79.49    | 80.08      | **82.89**  |\n| RGCN                | 46.48   | 49.20    | 49.14      | **66.61**  |\n| ProGNN              | 38.85   | 34.61    | 33.65      | **59.61**  |\n| GNNGuard            | 58.35   | 61.16    | **67.21**  | 62.63      |\n| GRAND               | 42.81   | 41.56    | 48.65      | **63.28**  |\n\n\nNote that the hyperparameters for each model are tuned based on clean data and kept same throughout the experiment.\n\n\n\n\n\n\n\n\n\n[1]: Mujkanovic, F., Geisler, S., G\u00fcnnemann, S., & Bojchevski, A. (2022). Are Defenses for Graph Neural Networks Robust?. Advances in Neural Information Processing Systems, 35, 8954-8968."}, {"Heading": "Official Comment by Reviewer umJp", "Subheading": "Official CommentbyReviewer umJp22 Nov 2023, 19:10Everyone", "Content": "Comment:\nI have read the responses and choose to maintain my current score. Thank you."}]}, {"Heading": "Official Review of Submission9303 by Reviewer 5YoB", "Subheading": "Official ReviewbyReviewer 5YoB31 Oct 2023, 17:48 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn this paper the authors propose a graph adversarial attack defense mechanism, based on the Lipschitz constant and its regularization. \n\nThe authors provide significant amount of theory and then present the experimental evaluation of their method.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe paper is easy to follow. The results look promising.\nWeaknesses:\n* The authors propose an optimisation based method. This approach requires taking the gradient of the network and then applying it to the learned weights. However, it is not promised that the network itself is a valid potential function. Therefore, I am afraid that it cannot be guaranteed that the method should converge. Therefore I believe that the theoretical guarantees are not complete as not all assumptions are provided, and also it is not clear if the experiments are conducted with a network that is a potential function. To my understanding, the authors use GCN as a backbone, which is not guaranteed to be a valid potential function. I look forward to read the authors response.\n\n* The authors should add comparisons with recent methods such as \"Robust Mid-Pass Filtering Graph Convolutional Networks\"\n\n* The authors should discuss recent findings about the evaluation of GNN robustness and conduct experiments with additional benchmarks to show the performance of the model. Please see discussion and data in \"Are Defenses for Graph Neural Networks Robust?\"\n\n* The authors should provide the runtimes of the method.\nQuestions:\nPlease see my review\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 5YoB", "Subheading": "Official CommentbyAuthors21 Nov 2023, 20:05Everyone", "Content": "Comment:\nThanks for your detailed review. We are going to address your concerns one by one as follows:\n\n**Question: Convergence of the algorithm**\n\nResponse: In the proposed approach, we regularize the GCN loss for Lipschitz stability. There has been multitude of work proving the convergence guarantees of GCN [1,2]. Proof is presented in Appendix E.\n\n**Question: Comparison with Robust Mid-Pass Filtering Graph Convolutional Networks (Mid-GCN) [3]**\n\nResponse: Thank you for the suggestion. The table presents average accuracy over ten random runs.\n| **Dataset** | **Attack**       | **Mid-GCN** | **AdaLip** |\n|-------------|------------------|-------------|------------|\n| Cora        | Metattack (25%)  | 72.89       | **76.22**  |\n| CS          | Metaattack (25%) | 69.12       | **72.35**  |\n| Cora        | Nettack (5)      | 68.56       | **74.04**  |\n| CS          | Nettack (5)      | **77.12**   | 76.19      |\n\n\n**Question: Runtime Comparison**\n\nResponse: The table shows runtime comparison of different methods for 400 epochs on Cora dataset.\n\n| **Method** | **Time (s)** |\n|------------|--------------|\n| GCN        | 5.87         |\n| ProGNN     | 770.56       |\n| AdaLip.J   | 201.89       |\n| AdaLip.2   | 56.29        |\n\n[1]: Awasthi, P., Das, A., & Gollapudi, S. (2021). A convergence analysis of gradient descent on graph neural networks. Advances in Neural Information Processing Systems, 34, 20385-20397.\n\n[2]: Keriven, N., Bietti, A., & Vaiter, S. (2020). Convergence and stability of graph convolutional networks on large random graphs. Advances in Neural Information Processing Systems, 33, 21512-21523.\n\n[3]: Huang, J., Du, L., Chen, X., Fu, Q., Han, S., & Zhang, D. (2023, April). Robust Mid-Pass Filtering Graph Convolutional Networks. In Proceedings of the ACM Web Conference 2023 (pp. 328-338)."}, {"Heading": "Robustness Unit Test", "Subheading": "Official CommentbyAuthors22 Nov 2023, 04:41Everyone", "Content": "Comment:\n**Robustness Unit Test**\n\nWe perform a robustness test of our proposed method following [1]. A unit test is proposed consisting of several adaptive attacks. The attacks that are based on Vanilla GCN are considered non-adaptive. The unit test consists of poisoning attacks over a range of budget 0 to 15% of E (E=Total no. of edges). We present the results of the attacks that lead to maximum degradation in Vanilla GCN performance on Cora-ML dataset.\n\n| **Adaptive Attack** | **GCN** | **RGCN** | **ProGNN** | **AdaLip** |\n|---------------------|---------|----------|------------|------------|\n| Jaccard-GCN         | 57.60   | 56.84    | 61.67      | **71.08**  |\n| GCN-SVD             | 80.33   | 79.49    | 80.08      | **82.89**  |\n| RGCN                | 46.48   | 49.20    | 49.14      | **66.61**  |\n| ProGNN              | 38.85   | 34.61    | 33.65      | **59.61**  |\n| GNNGuard            | 58.35   | 61.16    | **67.21**  | 62.63      |\n| GRAND               | 42.81   | 41.56    | 48.65      | **63.28**  |\n\n\nNote that the hyperparameters for each model are tuned based on clean data and kept same throughout the experiment.\n\n\n\n\n\n\n\n\n\n[1]: Mujkanovic, F., Geisler, S., G\u00fcnnemann, S., & Bojchevski, A. (2022). Are Defenses for Graph Neural Networks Robust?. Advances in Neural Information Processing Systems, 35, 8954-8968."}, {"Heading": "Thanks", "Subheading": "Official CommentbyReviewer 5YoB23 Nov 2023, 02:49Everyone", "Content": "Comment:\nI thank the authors for their response, which I've read together with the other reviews. \nI think that they are still not sufficient to convince me on the problems found by the other reviewers and myself, and therefore I keep my original score."}]}, {"Heading": "Official Review of Submission9303 by Reviewer uQo7", "Subheading": "Official ReviewbyReviewer uQo729 Oct 2023, 14:30 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work introduces an approach called AdaLip to improve GNN robustness. Specifically, authors first introduce an objective function based on the adaptive Lipschitz regularization, which aims to purify the graph topology and train robust GNNs. Subsequently, authors develop an iterative algorithm that is provably convergent for optimizing the objective function. Experimental results indicate that AdaLip outperforms a few defense baselines under the transfer attack setting.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\n- Authors have considered both graph modification and injection attacks.\n- AdaLip has been evaluated on both homophily and heterophily datasets.\nWeaknesses:\n- Missing adaptive attack results. As shown by [1], most prior defense GNN methods can be easily broken by adaptive attacks, which are aware of the given defense method during attacking. Thus, it is very important to adaptively attack the proposed defense model to demonstrate its true robustness.\n- Missing relevant defense models for evaluation. There are some prior methods (e.g., [2]) for defending on both homophily and heterophily datasets, which are not compared in this work.\n- Improper claims. It is unclear why prior adversarial training methods (e.g., PGD) cannot be applied to different GNN architectures. Furthermore, since the authors exclusively focus on GCN as the GNN backbone in their experiments, their claim on the adaptability of AdaLip to various GNNs is less convincing. Additionally, the authors assert that PGD is not a suitable choice for solving Equation (4), but they provide no empirical results to support this claim.\n- There is a lack of sensitivity analyses on $\\alpha$ and $\\beta$.\n- The tightness of the upper bound in Theorem 1 is unclear.\n- The paper writing can be further improved. Authors have introduced several terms without adequate explanations or definitions, some of which I've listed in the following questions.\n\n[1]: Mujkanovic et al., \u201cAre Defenses for Graph Neural Networks Robust?\u201d, NeurIPS'22. \\\n[2]: Deng et al., \u201cGARNET: Reduced-Rank Topology Learning for Robust and Scalable Graph Neural Networks\u201d, LoG'22.\nQuestions:\n- What's the \"smoothness of vertices\"? Do authors mean node feature smoothness? \n- What does the \"data adaptivity\" mean? \n- What's the definition of high-frequency components within the data? Do authors mean the Laplacian eigenvectors corresponding to the largest eigenvalues? If so, it's unclear to me why AdaLip can work on heterophily datasets since it is less responsive to those high-frequency components.\n- What does the \"adaLip w/o GD\" mean in Figure 1?\n- Remark 2 is somewhat unclear. Do the authors mean that AdaLip also employs low-rank approximation on the adjacency matrix? If so, could you please point out the equation in the paper that demonstrates this? Additionally, given that ProGNN also learns a low-rank adjacency matrix, why does Figure 1 illustrate the efficacy of the low-rank approximation?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer uQo7", "Subheading": "Official CommentbyAuthors21 Nov 2023, 20:49Everyone", "Content": "Comment:\nThanks for your detailed review. We are going to address your concerns one by one as follows:\n\n**Question: Clarification on smoothness of vertices?**\n\nResponse: By smoothness of vertices, the authors mean smoothness of node-level attributes over the graph (clarification will be updated in the paper).\n\n**Question: Comparison with GARNET [1]**\n\nResponse: Thank you for the suggestion. We present the comparison on Cora, CS, and Chameleon dataset. The backbone is GCN for both, hence for Chameleon dataset we have only used 10% Metattack.\n\n| **Dataset** | **Attack**      | **GARNET** | **AdaLip** |\n|-------------|-----------------|------------|------------|\n| CS          | Metattack (10%) | 72.70      | **74.21**  |\n| CS          | Metattack (25%) | 67.74      | **72.35**  |\n| Cora        | Metattack (10%) | **80.68**  | 78.14      |\n| Cora        | Metattack (25%) | 74.81      | **76.22**  |\n| Chameleon   | Metattack (10%) | 34.81      | **36.12**  |\n\n\n**Question: Use of Projected Gradient descent**\n\nResponse: By using projected gradient descent similar to [2], the parameters can be normalized after every iteration in order to have a $\\kappa$-Lipschitz stable model ($\\kappa$ being tuned as hyperparameter). In literature often the $\\kappa$ is taken as unity. However, several studies have pointed the tradeoff in terms of expressiveness while doing such normalization [3,4]. Hence, in this work we propose an optimization based method for adaptive Lipschitz regularization. The discussion will be added in the paper.\n\n**Question: Clarification on heterophily datasets.**\n\nResponse: In the experiment section, we have mentioned that for heterophily datasets we have set parameter $\\beta\\rightarrow 0$.\n\n**Question: Clarification of data adaptivity**\n\nResponse: Since, the proposed approach have a joint method to learn GNN parameters along with graph denoising, the algorithm becomes adaptive to the data given as input. \n\n**Question: Clarification of \"adaLip w/o GD\" in Figure 1**\n\nResponse: In Figure 1, AdaLip w/o GD means our proposed approach without using graph denoising objective ($\\beta=0$). \n\n**Question: Clarification on Remark 2**\n\nResponse: In Remark 2, we mean to say that low-rank approximation based graph denoising can also be used within the framework of AdaLip. Also, in figure 1 we have compared the accuracy and Lipschitz bound of different methods.\n\n\n\n[1]: Deng, C., Li, X., Feng, Z., & Zhang, Z. (2022, December). GARNET: Reduced-Rank Topology Learning for Robust and Scalable Graph Neural Networks. In Learning on Graphs Conference (pp. 3-1). PMLR.\n\n[2]: Gouk, H., Frank, E., Pfahringer, B., & Cree, M. J. (2021). Regularisation of neural networks by enforcing lipschitz continuity. Machine Learning, 110, 393-416.\n\n[3]: Zhao, X., Zhang, Z., Zhang, Z., Wu, L., Jin, J., Zhou, Y., ... & Yan, D. (2021, July). Expressive 1-lipschitz neural networks for robust multiple graph learning against adversarial attacks. In International Conference on Machine Learning (pp. 12719-12735). PMLR.\n\n[4]: Anil, C., Lucas, J., & Grosse, R. (2019, May). Sorting out Lipschitz function approximation. In International Conference on Machine Learning (pp. 291-301). PMLR."}, {"Heading": "Robustness Unit Test", "Subheading": "Official CommentbyAuthors22 Nov 2023, 04:39Everyone", "Content": "Comment:\n**Robustness Unit Test**\n\nWe perform a robustness test of our proposed method following [1]. A unit test is proposed consisting of several adaptive attacks. The attacks that are based on Vanilla GCN are considered non-adaptive. The unit test consists of poisoning attacks over a range of budget 0 to 15% of E (E=Total no. of edges). We present the results of the attacks that lead to maximum degradation in Vanilla GCN performance on Cora-ML dataset.\n\n| **Adaptive Attack** | **GCN** | **RGCN** | **ProGNN** | **AdaLip** |\n|---------------------|---------|----------|------------|------------|\n| Jaccard-GCN         | 57.60   | 56.84    | 61.67      | **71.08**  |\n| GCN-SVD             | 80.33   | 79.49    | 80.08      | **82.89**  |\n| RGCN                | 46.48   | 49.20    | 49.14      | **66.61**  |\n| ProGNN              | 38.85   | 34.61    | 33.65      | **59.61**  |\n| GNNGuard            | 58.35   | 61.16    | **67.21**  | 62.63      |\n| GRAND               | 42.81   | 41.56    | 48.65      | **63.28**  |\n\n\nNote that the hyperparameters for each model are tuned based on clean data and kept same throughout the experiment.\n\n\n\n\n\n\n\n\n\n[1]: Mujkanovic, F., Geisler, S., G\u00fcnnemann, S., & Bojchevski, A. (2022). Are Defenses for Graph Neural Networks Robust?. Advances in Neural Information Processing Systems, 35, 8954-8968."}, {"Heading": "Follow-up", "Subheading": "Official CommentbyReviewer uQo722 Nov 2023, 16:19Everyone", "Content": "Comment:\nThanks for the detailed response and additional experiments. However, my major concerns are still valid. In particular, the new results of Robustness Unit Test are still considered as the transfer attack setting. Authors should adaptively attack their proposed model instead.\n\nThus, I keep my score unchanged."}]}, {"Heading": "Official Review of Submission9303 by Reviewer C1i6", "Subheading": "Official ReviewbyReviewer C1i625 Oct 2023, 01:35 (modified: 22 Nov 2023, 17:38)EveryoneRevisions", "Content": "Summary:\nThe presented paper proposed a unified framework based on optimization unfolding. The proposed framewrok combines methods based on updating the graph (denoising) and methods based on training (network regularization).\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\n- The presented paper combines two worlds (graph denoising and regularization), and is flexible enough to allow different choice of components by using different loss function.\n- The framework is derived from an optimization perspective, which provides good interpretability of the proposed method.\n- Experiment results shows the effectiveness of the proposed method.\n\n-----\nI have read the author responce and decided to keep my rating unchanged.\nWeaknesses:\n- I found this paper rather sloppy in mathematics. In terms of:\n    - Undefined synbols. See Questions.\n    - Some synbols are overrided without explanation. For example, in eq.(6) $\\theta$ is used to represent a function (the GNN model in my understanding), while in eq.(10) $\\theta$ is used to represent the parameters of the model.\n    - There are some imprecise terms. \n        - From (3) to (4) the authors say \"The problem (eq.(3)) can be rewritten as a joint objective (eq.(4))\". I don't see how eq.(3) can be rewritten as eq.(4). Indeed eq.(4) is a relaxed version eq.(3), but they are not equavalent. Doing such relaxation usually requires some related properties of the two problems, e.g. they share the same global optima. For the eq.(3) to eq.(4), I don't see such a relation, at least the authors didn't mention any.\n        - In section 4, there's a sentence \"Without loss of generality, the adaptive Lipschitz regularization in (9) can be equivalently replaced by a logarithmic counterpart\". I don't see how relacing a part of a equation by its logarithmic counterpart while leaving other parts unchanged is without loss of generality. It's likely eq.(9) and eq.(10) have different global optima. I would suggest the authors just add the log in the original definition eq.(9).\n- For the two stage approach, I don't see why it can converge. The given theorem only proves the convergence of the joint optimization approach. \n- The experiments are performed only on small graphs. I wonder what is the computational complexity of the proposed algorithm and if it is limited on small graphs?\n- The proof of Theorem 1 is looks problematic. Overall, I think it's unlikely that the Lipschitz constant depends only on the parameters but not on the activation function and the structure of the GNN.\n    - For the first inequal symbol in eq.(2) in the appendix, how is $\\sigma$ disapeared? Doesn't this require $\\sigma$ to be $1$-Lipschitz?\n    - The proof of Theorem 1 assums a very specific structure of GNN (basically GCN), which mismatches the definition of GNN given in section 2.1. The authors should state it explicitly that it works only for a specific implementation of GNN in the statement of  Theorem 1. Alternatively, you can also assume $\\mathcal M$ and $\\mathcal U$ are Lipschitz continous and combine the Lipschitz constant of them into the bound.\nQuestions:\nThere are some undefined or unclear notations. Although I can guess most of them but it's better to define them clearly.\n\n - In eq.(1), what is $\\mathcal N$?\n - In eq.(3), what is $\\phi$? Also, based on the definition of $\\mathcal S_{\\phi}$, is $\\phi \\in \\mathcal S_\\phi$ just a graph Laplacian?\n- In Theorem 1, is $E$ a scalar or vector? In the statement it says $|\\Delta - \\Delta_p| \\overset{\\text{def}}= |E|$, which makes it looks like a scalar, but in the equation it uses $\\\\|E\\\\|_2$, which makes it looks like a vector.\n- In Lemma 2, what is $\\omega$? Is it a scalar or vector?\n- In eq.(21), what is $L_q$?\n\nIt's possible that I missed some definitions or assumptions. Feel free to point out if I missed something.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer C1i6", "Subheading": "Official CommentbyAuthors22 Nov 2023, 02:14Everyone", "Content": "Comment:\nThanks for your detailed review. We are going to address your concerns one by one as follows:\n\n**Question: Clarification on the relaxation of problem (3) to (4)**\n\nResponse: The authors agree that optimization problem (4) is relaxed version of (3). By solving (4) graph denoising and GNN training is done jointly, making the method adaptive.\n\n**Suggestion on using log based definition in (9)**\n\nResponse: Thank you for the suggestion. We will revise the original definition according to the suggestion.\n\n**Question: Computational cost analysis**\n\nResponse: The table shows runtime comparison of different methods for 400 epochs on Cora dataset.\n\n| **Method** | **Time (s)** |\n|------------|--------------|\n| GCN        | 5.87         |\n| ProGNN     | 770.56       |\n| AdaLip.J   | 201.89       |\n| AdaLip.2   | 56.29        |\n\n**Question: Convergence of two-stage approach**\n\nResponse: We acknowledge that the two-stage algorithm aims to provide an approximate solution to the problem (11) with reduced computational resources. We intend to strike a balance between computational efficiency and solution quality. The results in the Table above demonstrate that our approach effectively achieves this objective, offering a compelling alternative that merits consideration. Indeed, the optimal solution obtained through the two-stage process may not strictly minimize the problem (11). However, in our analysis, we have observed that the solution serves as a robust proxy. The results align well with recent findings indicating the significance of the average degree of the input graph in the convergence of GNN [1]. Solving the problem (12) filters the adversarial connections, leading to a lower average degree in the data.\n\n**Question: Clarification on the proof of Theorem 1**\n\nResponse: Thank you for the suggestion. We have modified the proof in the paper with all assumptions and details.\n\n**Question: Clarification of $\\mathcal{N}$ in (1)**\nResponse: It is the neighbourhood function.\n\n**Question: Clarification on $\\phi$ in (3)**\nResponse: It is the graph Laplacian\n\n**Question: Clarification on $\\|\\|E\\|\\|$ in Theorem 1**\nResponse: Thank you for highlighting this. We have rectified in the paper.\n\n**Question: Clarification on $\\omega$ in Lemma 2**\nResponse: It is a vector. Detailed description is in Appendix C.\n\n**Question: Clarification on $L_q$ in (21)**\nResponse: It is the Lipschitz constant of the function $q(\\omega)$ defined in (19).\n\n[1]: Awasthi, P., Das, A., & Gollapudi, S. (2021). A convergence analysis of gradient descent on graph neural networks. Advances in Neural Information Processing Systems, 34, 20385-20397."}, {"Heading": "Official Comment by Reviewer C1i6", "Subheading": "Official CommentbyReviewer C1i622 Nov 2023, 17:37Everyone", "Content": "Comment:\nThank the authors for their responce. My concerns has been partially addressed. However, there are still unaddressed issues. For the computational cost, what I expected was a computational complexity analysis, which can give us a sense of how fast the algorithm is in a direct way. The authors provided some experiment result on Cora. Although I appreciate the authors' efforts in conduction extra experiments, it is worth noting that Cora is a fairly small dataset and can not reflect the true complexity of an algorithm. Not to mention the proposed method looks quite slow on Cora. Based on this, I have decided to keep my current rating to this paper unchanged. I suggest the authors to rewrite and reorganize this paper with a more rigorous and consistent math notation and language and resubmit it."}]}]}, "wlRp8IdLkN": {"paper_info": {"Keywords": "Large Language Models, Complex Instructions, Reinforcement Learning", "Abstract": "The development of Large Language Models (LLMs) often confronts challenges stemming from the heavy reliance on human annotators in the reinforcement learning with human feedback (RLHF) framework, or the frequent and costly external queries tied to the self-instruct paradigm.  In this work, we pivot to Reinforcement Learning (RL)---but with a twist. Diverging from the typical RLHF, which refines LLMs following instruction data training,  we use RL to directly generate the foundational instruction dataset  that alone suffices for fine-tuning. Our method uses a suite of textual operations and rules, prioritizing the diversification of training datasets. It facilitates the generation of  rich instructions without excessive reliance on external advanced models, paving the way for a single fine-tuning step and negating the need for subsequent RLHF stages. Our findings underscore some key advantages of our approach: a diminished need for human involvement and fewer model queries, along with boosting the capability of LLMs in crafting and comprehending complex instructions compared to strong baselines.", "Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9302", "PDF Url": "https://openreview.net/pdf?id=wlRp8IdLkN"}, "review_info": [{"Heading": "General response and summary of updates in the paper", "Subheading": "Official CommentbyAuthors21 Nov 2023, 22:16Everyone", "Content": "Comment:\nDear Reviewers,\n\nWe value your insightful comments, which have significantly enhanced our paper. Key updates (highlighted in yellow in revision) include:\n\n- Clarification of key contribution--the **first RL framework** (distinct from RLHF) to generate instruction finetuning data, reducing collection costs and potential needs for human alignment or heavy reliance on external models (per Reviewers **6muu, tJXC**). More broadly, our work addresses **data limitations** where obtaining instruction responses (played by proprietary models in our evaluation) requires careful considerations of which instructions to query (in response to Reviewer **1H8F**\u2019s comment). WWe foster instruction quality, reflecting the philosophy that well-crafted questions (via RL) are crucial alongside responses from advanced LLMs (Reviewers **6muu, tJXC**).\n- Discussions of key **technical** contributions (generating high-quality instruction data via RL, per Reviewer **6muu, tJXC**): **1)** Formulated as MDP to learn policy for **contextualized instruction manipulations** that maximize diversity of instruction set. **Continuous action space** allows differentiatng nuances between similar actions. In contrast, WizardLM and Tree-Instruct treat actions as ordinal choices, lacking context to directly compare the suitability of actions; Tree-instruct also requires finding the right tree structure. (Reviewer **1H8F** Q1, Reviewer **6muu** Q5).  **2)** To solve this MDP, we use TRPO (though other common methods could be used). Compared to rejection sampling, this **mitigates combinatorial complexity** from the sequential composition of instruction actions, enabling iterative policy improvement (TRPO guarantees monotonic improvement). \n- Clarification on our algorithm: 1)\tOur approach uses **RL for generating instruction sets for fine-tuning**, eliminating the second human alignment stage as required in RLHF (Reviewer **1H8F**). While our method is complementary to RLHF, we do not consider the setting that makes high-quality human feedback available (Reivewer **6muu**). 2) Clarification of leveraging WizardLM13B, ChatGPT and GPT-4 for additional instruction data (Reviewer **1H8F**, reviewer **tJXC**): WizardLM-13B: environment to help search for instruction-generation policy (step 3). ChatGPT (or GPT-4): generate responses to instructions (Step 4). \n- Discussion of empirical results: \n     * Our results should be viewed along **two key dimensions**: benchmark performance, and significantly, the amount of fine-tuning data required (Reviewer **1H8F, 6muu**). Compared to WizardLM, we reduce instructions by **94%** while maintaining similar (HellaSwag, ARC) or better (TruthfulQA, MMLU) performance. This brings **major cost and privacy benefits** for LLM alignment. The advantage stems from *contextualized, scalable RL instruction generation* (Reviewer **6muu**, Q1). We also discussed slightly lower performance than LLAMA-2-7b on HellaSwag/ARC as likely due to initial instruction set emphasizing multi-tasking over specialized performance (evidenced by similar WizardLM results, Fig 4-5).\n    * Fairness in comparison to WizardLM7b  (Reviewer **tJXC**): **Both approaches use LLAMA 7B as the base model.** WizardLM7B queried ChatGPT **624,000** times for responses. Our method queried WizardLM13B **371** times (896 in the initial submission) during policy training and ChatGPT **35,756** times for responses. Since open-source WizardLM13B is no more capable than ChatGPT, our combined queries are far fewer. Hence we believe the comparison is fair in terms of base model and query amount.\n    * Using WizardLM13b to train an instruction-generation policy (Reviewer **tJXC**): 1) Our policy is universal for **aligning various models** like llama-1-7b and llama-2-7b; 2) As an open-source model, WizardLM13b serves as a **proxy environment** rather than for knowledge distillation. Weaker models may miss instruction nuances, impacting the universal policy's quality.\n    * Computation overhead (Reviewer **6muu**): Main overhead is learning the instruction-generation policy, performed on (relatively small) WizardLM-13b in <1 hour (with 371 queries in total). This transferable policy (verified in Experiment Section 4.2.1 and 4.2.2) has **lower incremental cost** for aligning multiple models, versus RLHF requiring separate RL per model. Offloading to policy learning allows an instruction set serving dual purposes of tuning and alignment - a substantial benefit over current usage of tuning-only instruction data.\n\nAbove all, we conducted **additional** experiments:\n- Further reduce the number of queries of WizardLM-13B required from 896 to 371 (94% less than WizardLM method). \n- Our approach of improving data quality while limiting data size enhances privacy performance. See comparison experiments on model privacy attacks (Sec. 4.3 and Appendix 2).\n\nPlease let us know if you have any additional comments or concerns; we would be happy to address them."}, {"Heading": "Looking forward to the Reviewers' feedback", "Subheading": "Official CommentbyAuthors17 Nov 2023, 10:31Everyone", "Content": "Comment:\nDear Reviewers,\n\nWe hope this message finds you well. The deadline for discussion is approaching, and we are eager to await your response. We are grateful for your time and dedication in reviewing our paper and guiding its improvement. We kindly request that you recheck our responses and inform us whether they have completely or partially addressed your concerns.  \n\nThank you once again for your reviews. We look forward to hearing from you.\n\nWith gratitude,\n\nAuthors of Paper 9302"}, {"Heading": "Common Responses by Authors", "Subheading": "Official CommentbyAuthors13 Nov 2023, 11:31 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\nDear Reviewers,\n\nWe are grateful for your insightful and helpful feedback. Besides responding to the comments from each reviewer, we want to summarize the contributions and highlight the new privacy attack experiments on our model. Please refer to the latest version of the manuscript.\n\n## Key Contributions:\n- Firstly, The direct utilization of WizardLM or tree-instruct methodologies may incur **substantial costs in terms of both querying GPT costs and training time**. In the case of WizardLM, the utilization of random samples for instruction poses a challenge, as it is not feasible to discern which instructions are optimal for instructing LLMs effectively. Concerning tree-instruct, the requirement to formulate well-structured tree instructions to facilitate enhanced LLM learning is an explicit challenge. In contrast, our proposed methodology introduces the incorporation of RL techniques to design tree instructions, thereby contributing to improving LLMs' performance with small data. Notably, the dataset employed by WizardLM outpaces our dataset in terms of scale, exceeding it by a substantial margin of over **94%**. Nevertheless, our proposed approach, despite its reliance on a comparatively **smaller dataset**, showcases the capacity to achieve performance levels that are on par with those achievable by models trained on considerably **larger datasets**, such as WizardLM. \n\n- Secondly, our methodology demonstrates a versatile capacity by extending its applicability towards **augmenting the quality of small data** in situations characterized by limited data availability. This adaptable attribute broadens its utility beyond the specific context mentioned previously. Notably, in domains such as manufacturing industries, chemical processes, and medical applications, acquiring large datasets can be a formidable challenge due to factors such as data scarcity or the high cost associated with data collection.\n\n- Lastly, it is noteworthy that training models through our approach, which generates **high-quality smaller datasets**, can offer enhanced **privacy protection performance** compared to models trained on large datasets. This consideration underscores the potential advantages of our method in safeguarding individual privacy within the broader scope of model training. **We also provide comparison experiments  on the model privacy attacks, the experiment results indicate that our method can significantly improve model privacy protection performance.** For details, please see section 4.3 and Appendix 2 in the latest version of the manuscript.", "Replies": [{"Heading": "New updates", "Subheading": "Official CommentbyAuthors15 Nov 2023, 20:06 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\nDear reviewers,\n\nWe would again like to thank all the reviewers for their constructive feedback, which significantly improved our paper's quality. \n\nWe have completed new experiments involving training a policy with WizardLM-13B. Remarkably, this training only necessitates 371 samples from WizardLM-13B to achieve a policy performance comparable to that of our initial submission. This indicates that, despite the query count of WizardLM-13B, our method can still reduce the query count by 94.21% to attain similar results. It underscores a more economical and sustainable approach in LLM training and enhancing data quality.\n\nWe hope our responses and revisions to the paper address the reviewers' concerns. If you have any additional comments or concerns, please do not hesitate to let us know; we are happy to address them.\n\nWith gratitude,\n\nAuthors of Paper 9302"}]}, {"Heading": "Official Review of Submission9302 by Reviewer 1H8F", "Subheading": "Official ReviewbyReviewer 1H8F04 Nov 2023, 22:45 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes to first train a language model to generate instructions diverse from the seed. This is done using RL where the reward comes from another LM on whether or not the output instruction is of good quality. Then this model is used to generate diverse instructions, responses to which are generated by gpt-3.5 and other LMs, to create a dataset for instruction fine-tuning. When fine-tuned using this data, models like Llama2-chat-7b and WizardLM-7b are shown to improve on some benchmarks.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThe direction of lowering the cost of collecting instruction fine-tuning data and eliminating need for human feedback is important in making conversational LLMs more accessible.\nWeaknesses:\nThis work seems to be leveraging additional instruction fine-tuning data (see Step 4 & 5) derived from ChatGPT and GPT-4 without clearly describing how it does so in the corresponding Sections. The contribution of this work seems weak if the responses are generated primarily using external models.\n\nMixed results with marginal gains compared to the checkpoints they start with, in some cases a drop (Fig 4 & 5). TruthfulQA performance of llama-2-chat-7b is under-reported as 38.98, Table 14 from the Llama2 paper reports the performance of the 7B chat model to be at 57.04.\n\nI find it very hard to comprehend the problem being solved and the approach being proposed in this submission. At least some parts of the paper seem to be LLM-generated.\nQuestions:\nQuestions on steps of the Algorithm proposed\n\nStep 1: Desigin of actions - do you simply use the same actions as proposed by WizardLM?\n\nStep 2: What does discrete value-based action space S mean?\n\nStep 3: How is TRPO used here? The binary feedback ('reward') that you get on diversity of the generated instructions is used to train the base LM, this appears to be the rejection sampling approach.\n\nStep 4 & 5: How is ChatGPT or GPT-4 used here? \n\nWhy are LLMs called Advanced LLM in Fig 1 & 2?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 1H8F (Part one)", "Subheading": "Official CommentbyAuthors13 Nov 2023, 11:35 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\n**Q1:** Contributions.\n- **A1:** See the common response\u2019 contribution part.\n\n**Q2:** external models usage, and Steps 4 & 5 for generating instructions and responses.\n- **A2:** The external models include WizardLM-13B, ChatGPT(GPT-3.5) and GPT-4. As illustrated in our manuscript, during training RL, WizardLM-13B is used as an environment to help search for a policy (**Step 3**). The policy is leveraged to teach LLMs (such as ChatGPT) to generate high-quality data comprising complex instructions (**Step 4**) and their corresponding responses (**Step 5**). Particularly, our methodology is applicable beyond the specific external models used, indicating that the contribution is not limited to the capabilities of ChatGPT and GPT-4 but is instead a generalizable strategy. This approach is anticipated to substantially reduce computational demands as well as the number of queries to models such as ChatGPT, thus yielding a notable decrease in associated costs and generating high-quality small data (In the latest version of the manuscript, we have merged steps 4 and 5 into a single step, which is now referred to as step 4).\n\n\n\n**Q3:** Performance analysis (Fig 4 & 5). \n- **A3:** Thanks for your helpful comments. In our comparative experiments involving llama-2 models, as shown **in Figure 4**, our method exhibits significant enhancements in the performance metrics of TruthfulQA and MMLU. Notably, TruthfulQA, a benchmark encompassing a diverse array of 817 questions spanning 38 distinct categories, covering a broad spectrum of domains, including but not limited to health, law, finance, and politics, demonstrates marked improvement. Similarly, our method reflects notable advancements in MMLU, a comprehensive evaluation criterion assessing a text model\u2019s multitask accuracy across domains such as elementary mathematics, US history, computer science, law, etc. Conversely, in the case of the HellaSwag and AI2 Reasoning Challenge benchmarks, llama-2-7b slightly outperforms our method. This discrepancy in performance could be attributed to several factors, including the adequacy of the number of instructions provided and the nature of the initial dataset, which may have placed a greater emphasis on multi-task learning capabilities than specific task performance.\n\n- **In Figure 5**, Our model, denoted as lunyu-7b-v1.1, was trained as an extension of llama-1-7b. Our approach has yielded substantial improvements in performance across the TruthfulQA and ARC benchmarks, while achieving a comparable level of performance in the HellaSwag benchmark. However, in the MMLU benchmark, our model exhibits slightly diminished performance relative to llama-1-7b. These results can be attributed, in part, to the potential insufficiency of instructional data. It is noteworthy that we utilized approximately 5% of the training data of WizardLM's, which may not have provided an ample instructional basis for our model. Nevertheless, even within the constraints of this relatively small dataset, our approach has demonstrated the capability to markedly enhance reasoning and multitasking proficiencies when compared to llama-1-7b. Furthermore, it has achieved performance levels comparable to those of WizardLM-7b and, notably, has exhibited remarkable enhancements in overall performance compared with llama-1-7b."}, {"Heading": "Response to Reviewer 1H8F (Part two)", "Subheading": "Official CommentbyAuthors13 Nov 2023, 11:36 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\n**Q4:** TruthfulQA performance of llama-2-chat-7b is under-reported as 38.98, Table 14 from the Llama2 paper reports the performance of the 7B chat model to be at 57.04.\n- **A4:** As illustrated within our manuscript, in an endeavor to save computational resources, we have uniformly configured all models to operate in a float16 format and evaluated all models' performance on a well-known benchmark, [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness.git). It is worth noting that the performance metrics reported in the llama2 paper may have been derived from models utilizing a float32 format. In our own investigations, we have ascertained that models employing a higher-precision float format tend to yield superior performance scores. Consequently, it is important to acknowledge that the performance scores we have examined may exhibit disparities in comparison to those presented in the llama2 paper, due to the aforementioned difference in precision format. \n\n**Q5:** Discrete value-based action space $S$.\n- **A5:** The instruction actions are similar to WizardLM, but it is a little different from the instruction writing. Particularly, in our study, the discrete value-based action space means the instruction items. However, in RL policy searching, after mapping the instruction actions into a discrete value-based action space, we further map the discrete action space into a continous space for searching a policy. This facilitates the effective search for a high-quality policy. Such a policy is capable of teaching LLMs to generate complex instructions and responses with enhanced effectiveness. Conversely, in WizardLM, they randomly sample the instruction items, which may not be effective in generating high-quality data.\n\n\n**Q6:** How is TRPO used here?\n- **A6:** In the process of delineating the action and state spaces, TRPO is employed to ascertain an optimal policy. TRPO operates on a framework where the state and corresponding rewards, as yielded by the environment, constitute the inputs. Upon processing these inputs, TRPO formulates a sequence of actions that are then executed within the environment with the objective of enhancing the cumulative reward. It is imperative to note that the optimization is conducted over entire trajectories of rewards as opposed to singular, instantaneous rewards, thereby emphasizing the sequential decision-making aspect inherent in RL. However, TRPO is not the only choice, The choice of TRPO is motivated by its ability to rigorously handle advantage function values in policy searching, backed by a theoretical underpinning.\n\n\n**Q7:** The rejection sampling approach.\n- **A7:** Our methodology shares a conceptual alignment with the principles underpinning the rejection sampling approach, but differs in some important technical aspects to address some challenges, including but not limited to scalability and contextual comprehension. Notably, the process of learning a trajectory policy within the rejection sampling framework can be time-consuming and susceptible to the curse of dimensionality, primarily stemming from the exponential growth in the number of required samples. Additionally, it does not inherently guarantee the realization of monotonically improving rewards.\nIn contrast, our method relies on interactive engagement with a contextually aware environment, notably represented by WizardLM-13B. In this interactive paradigm, to learn a trajectory policy, our approach elicits feedback in the form of rewards contingent upon the actions undertaken. Consequently, it undergoes an iterative learning process aimed at enhancing decision-making efficacy within the context, thus fostering continuous improvement through the feedback loop.\n\n\n**Q8:** Why are LLMs called Advanced LLM in Fig 1 & 2?\n- **A8:** Our training models fall within the category of base models, while advanced models, exemplified by ChatGPT, represent a higher level of sophistication and capability within this category."}, {"Heading": "Looking forward to your feedback", "Subheading": "Official CommentbyAuthors18 Nov 2023, 17:29Everyone", "Content": "Comment:\nDear Reviewer  1H8F,\n\nThank you for your constructive and valuable reviews, which have significantly enhanced the quality of our paper.\n\nWe have outlined our key contributions (low costs, high-quality data, model privacy performance, and general for other areas potentially), explained models' performance on a well-known benchmark, [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness), and elucidated how our method works, focusing on the main steps outlined in steps 3 and 4 of the latest version of our manuscript. \n\nAs the deadline for discussion is approaching, we highly value your reviews and eagerly await your feedback. We are immensely grateful for your time and effort in reviewing our paper. We kindly ask you to review our responses once more and let us know if they have fully or partially addressed your concerns.\n\nWith gratitude,\n\nAuthors of Paper 9302"}]}, {"Heading": "Official Review of Submission9302 by Reviewer 6muu", "Subheading": "Official ReviewbyReviewer 6muu01 Nov 2023, 05:28 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a novel approach to generate complex instruction-tuning data through reinforcement learning. It negates the need for subsequent RLHF stages. Their method can diminish the dependence on human instructors and moderates the need for constant queries to external models.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThis paper proposes a novel way to evolve instructions through reinforcement learning. The experiment results on LM-Eval benchmark demonstrate the effectiveness of their method.\nWeaknesses:\n1. The paper focuses on enhancing the instructions by iteratively optimizing the policy through RL. However, directly evolving instructions through WizardLM or Tree-Instruct prompts also avoids the need for training a large language model. The benefit brought by their method is constrained.\n2. Whether RLHF will further facilitate human alignment is not verified in this paper. Involving RL in the stage of SFT is computationally expensive.\nQuestions:\nNone\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 6muu", "Subheading": "Official CommentbyAuthors13 Nov 2023, 11:38 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\n**Q1:** Directly evolving instructions through WizardLM or Tree-Instruct prompts also avoids the need for training a large language model. The benefit brought by their method is constrained.\n- **A1:** The direct utilization of WizardLM or tree-instruct methodologies may incur substantial costs in terms of both querying GPT costs and training time. In the case of WizardLM, the utilization of random samples for instruction poses a challenge, as it is not feasible to discern which instructions are optimal for instructing LLMs effectively. Concerning tree-instruct, the requirement to formulate well-structured tree instructions to facilitate enhanced LLM learning is an explicit challenge. In contrast, our proposed methodology introduces the incorporation of RL techniques to design tree instructions, thereby contributing to improving LLMs\u2019 performance with small data. Notably, the dataset employed by WizardLM outpaces our dataset in terms of scale, exceeding it by a substantial margin of over 94%. Nevertheless, our proposed approach, despite its reliance on a comparatively smaller dataset, showcases the capacity to achieve performance levels that are on par with those achievable by models trained on considerably larger datasets, such as WizardLM.\n- Our method can efficiently fine-tune LLMs with the **high-quality small dataset**, and we also leverage the discrete action representation to **continuously encode context-aware selection of actions** in the policy. For details, please see the common response' contribution part.\n\n\n\n**Q2:** Whether RLHF will further facilitate human alignment is not verified in this paper.\n- **A2:** Thanks for your constructive comments.  The alignment of RLHF with human values is an important topic. However, our method differs from RLHF, and the training data is derived from teaching advanced models, such as ChatGPT (GPT-3.5) and GPT-4. We believe the data from these advanced models aligns well with human values. \n\n**Q3:** Involving RL in the stage of SFT is computationally expensive.\n- **A3:** Our policy is trained utilizing a modestly-sized model, such as the WizardLM-13b model, and the training process requires less than one hour (the query count of  WizardLM-13B is only 896), conducted on a hardware setup consisting of an A100 GPU and 16-core CPUs. Once our policy is adequately trained, it becomes a valuable asset to teach any advanced LLMs (such as ChatGPT) for the generation of complex instructions and corresponding responses, obviating the need for further policy training. Subsequently, upon acquisition of the requisite dataset comprising instructions and responses, we proceed to fine-tune a base model using a supervised learning approach, devoid of any RL training at this juncture."}, {"Heading": "Looking forward to your feedback", "Subheading": "Official CommentbyAuthors18 Nov 2023, 18:09 (modified: 18 Nov 2023, 18:15)EveryoneRevisions", "Content": "Comment:\nDear Reviewer 6muu,\n\nThank you for your constructive and valuable reviews, which have significantly enhanced the quality of our paper.\n\n- First, we have outlined our key contributions (low costs, high-quality data, model privacy performance, and general for other areas potentially) and clarified the disadvantages of directly evolving instructions through WizardLM or Tree-Instruct prompts. \n- Second, our method differs from RLHF, and the training data is derived from teaching ChatGPT (GPT-3.5) and GPT-4. We believe the data from these advanced models aligns well with human values [OpenAI-learning-from-human-preferences, 2017; Christiano, P. F., et al., 2017; Ouyang, L., et al., 2022] . \n- Third, In the STF stage, our method does not require RL training, and our approach is designed to train models more efficiently using small, high-quality datasets rather than relying on large volumes of data. We kindly request that you review our responses once again and inform us whether they have fully or partially addressed your concerns.\n\nAs the deadline for discussion is approaching, we highly value your reviews and eagerly await your feedback. We are immensely grateful for your time and effort in reviewing our paper. \n\n- [OpenAI-learning-from-human-preferences, 2017] https://openai.com/research/learning-from-human-preferences, June 13, 2017.\n- [Christiano, P. F., et al., 2017] Christiano, P. F., Leike, J., Brown, T., Martic, M., Legg, S., & Amodei, D. (2017). Deep reinforcement learning from human preferences. Advances in neural information processing systems, 30.\n- [Ouyang, L., et al., 2022] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., ... & Lowe, R. (2022). Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35, 27730-27744.\n\n\nWith gratitude,\n\nAuthors of Paper 9302"}]}, {"Heading": "Official Review of Submission9302 by Reviewer tJXC", "Subheading": "Official ReviewbyReviewer tJXC15 Oct 2023, 16:23 (modified: 05 Dec 2023, 14:20)EveryoneRevisions", "Content": "Summary:\nThe authors propose to use RL to learn a policy for sampling diverse instructions to generate a dataset for instruction tuning for downstream LLM alignment.\n\n\nEdit following author response:\n\nThank you for your honesty re: performance compared to LLaMA-1. However, I feel that the authors missed the main point of many of my other questions. \n\nQ3: Yes, WizardLM-13B is of course stronger than WizardLM-7B or LLaMA-1-7B so the performance will be better. I was mainly thinking that it would make your method more convincing if you did not need an existing strong instruction-tuned model to bootstrap your approach (i.e., if you could do everything starting from LLaMA-1-7B). This point is a bit moot though since as you mentioned in Q6, it turns out you're actually heavily relying on ChatGPT / GPT4 anyway - I didn't realize there was such heavy reliance on ChatGPT / GPT4 in the method which makes it a bit less convincing as there are a lot of methods these days which basically boil down to distilling from ChatGPT / GPT4. \n\nQ4: I agree that the benchmark itself is fine. However, I think that an important baseline is missing - generating new instructions via prompting rather than RL, as in e.g. https://arxiv.org/abs/2305.03047 and maybe other works by the same first author.\n\nQ5: This is not a problem of presentation. Rather, presumably you used the original prompts in your experiment run, which would imply that your experiments arguably contained \"bugs\" due to the typos in the prompts. (I.e., if you were to rerun experiments in the future, I'd recommend fixing the errors in the prompts as there's a chance you could increase your performance for free.)\n\nTo be honest, while I do think the core idea of this paper could be potentially promising, I would probably recommend the authors to spend much more time polishing the presentation in the paper and then resubmit; additional experiments or (potentially including further improvements on the methodology) could also make the argument much more convincing as the current results are not that strong.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\n--there is an interesting idea at the core of this paper: rather than just prompting to generate new diverse instructions for your initial instruction tuning prompt set, you can actually finetune the model for generating that dataset in the first place. this kind of suggests a \"hierarchy\" of sorts in the data generation, where you generate your data on multiple levels, starting from just your action set in 3.1.1.\nWeaknesses:\n--performance still seems a bit mixed compared to LLAMA, despite you leveraging ChatGPT/GPT4 and also WizardLM13b. Also, is the comparison to WizardLM7b in Fig 6 fair, given that you used WizardLM13b extensively in your pipeline?\n\n--similarly, it seems like you rely on having a strong instruction-tuned model already (WizardLM13b) as the \"Advanced LLM\" in Fig1 to be able to train your initial policy for sampling diverse instructions, which seems like maybe a bit of a chicken-and-egg problem. i think it might be more convincing if you were able to use a weaker model to do the initial judgments (e.g., why not use LLaMA7b, or WizardLM7b? are those not good enough for your purposes?), or show that you can later outperform whichever model you use for the initial Advanced LLM.\n\n--unless i missed it, there's no comparison on final downstream performance to any baseline that generates its instruction set just by prompting an LM rather than finetuning, which seems like it'd be the most direct baseline\n\n--there are typos/grammar errors even in the model prompts- these are arguably \u201cbugs\u201d\nQuestions:\n--i don't understand step 4 in algorithm 1 - how is chatgpt/gpt4 also being used to help you generate the complex instructions? are you just prompting it for more instructions to add to your instruction set, in addition to what you generated previously using your smaller RL-trained model?\n\n--nit: some typos and tense changes here and there, might want to proofread\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer tJXC", "Subheading": "Official CommentbyAuthors13 Nov 2023, 11:40 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\n**Q1:**  Performance Improvement in Figures 4 and 5. \n- **A1:** Thanks for your valuable comments. In our comparative experiments involving llama-2 models, as shown **in Figure 4**, our method exhibits significant enhancements in the performance metrics of TruthfulQA and MMLU. Notably, TruthfulQA, a benchmark encompassing a diverse array of 817 questions spanning 38 distinct categories, covering a broad spectrum of domains, including but not limited to health, law, finance, and politics, demonstrates marked improvement. Similarly, our method reflects notable advancements in MMLU, a comprehensive evaluation criterion assessing a text model\u2019s multitask accuracy across domains such as elementary mathematics, US history, computer science, law, etc. Conversely, in the case of the HellaSwag and AI2 Reasoning Challenge benchmarks, llama-2-7b slightly outperforms our method. This discrepancy in performance could be attributed to several factors, including the adequacy of the number of instructions provided and the nature of the initial dataset, which may have placed a greater emphasis on multi-task learning capabilities than specific task performance.\n- **In Figure 5**, Our model, denoted as lunyu-7b-v1.1, was trained as an extension of llama-1-7b. Our approach has yielded substantial improvements in performance across the TruthfulQA and ARC benchmarks, while achieving a comparable level of performance in the HellaSwag benchmark. However, in the MMLU benchmark, our model exhibits slightly diminished performance relative to llama-1-7b. These results can be attributed, in part, to the potential insufficiency of instructional data. It is noteworthy that we utilized approximately 5% of the training data of WizardLM's, which may not have provided an ample instructional basis for our model. Nevertheless, even within the constraints of this relatively small dataset, our approach has demonstrated the capability to markedly enhance reasoning and multitasking proficiencies when compared to llama-1-7b. Furthermore, it has achieved performance levels comparable to those of WizardLM-7b and, notably, has exhibited remarkable enhancements in overall performance compared with llama-1-7b.\n\n\n**Q2:**  Also, is the comparison to WizardLM7b in Fig 6 fair, given that you used WizardLM13b extensively in your pipeline? \n- **A2:** WizardLM-13 presents the unrestricted accessibility without imposing any querying costs. However, it is imperative to emphasize that employing ChatGPT for queries may engender substantial expenses. Consequently, from the perspective of saving querying costs while generating high-quality dataset, **it is fair**.  Particularly, the query count of  WizardLM-13B is only 896, even with the query count of  WizardLM-13B, our method can still reduce the query count by 94.13% to reach comparable outcomes, emphasizing a more economical and sustainable strategy for LLM training.\n\n\n\n**Q3:** why train policy with a 13B model?\n- **A3:** Thanks for your constructive comments. Generally, if the model is larger, the model performance is more powerful, since the WizardLM-13B performance is better than WizardLM-7B model, and is open-source, which could save query costs, thus it is a better choice to use it for training our policy. \n\n\n**Q4:** final downstream performance. \n- **A4:** I appreciate your acknowledgment. We evaluate model performance on a well-established benchmark that can provide a more robust and objective assessment, particularly when assessing the quality of generated instructions, which can be inherently challenging to evaluate in isolation.\n\n**Q5:** Typos.\n- **A5:** Thanks for your carful review, we have fixed the typos.\n\n**Q6:** ChatGPT/GPT-4 and RL model uses.\n- **A6:** ChatGPT/GPT-4 serve as the generative model for producing intricate instructions and corresponding responses. It is noteworthy that the trained RL model plays a pivotal role in teaching ChatGPT to produce high-quality instructions and responses."}, {"Heading": "Looking forward to your feedback", "Subheading": "Official CommentbyAuthors18 Nov 2023, 18:58 (modified: 18 Nov 2023, 18:59)EveryoneRevisions", "Content": "Comment:\nDear Reviewer tJXC,\n\n\nThank you for your constructive and valuable reviews, which have significantly enhanced the quality of our paper.\n\n- First, we have outlined our key contributions, which include low costs, the use of high-quality data, enhanced model privacy performance, and potential generalizability to other areas. We have also elucidated the performance improvements as illustrated in Figures 4 and 5. Furthermore, our training process requires only a limited number of samples from WizardLM-13B (371 samples for the revised version, and 896 samples for the initial version). This demonstrates that our method can significantly reduce the query count of WizardLM-13B by over 94% while achieving comparable results, indicating a more cost-effective and sustainable approach to LLM training and data quality enhancement.\n\n- Second, we have clarified performance evaluation on a well-established benchmark that can provide a more robust and objective assessment.\n\n- Third, we have described the use of ChatGPT (GPT-3.5) and GPT-4 in our work, where we developed a method for training a policy that teaches ChatGPT or GPT-4 to generate high-quality data, specifically focusing on steps 3 and 4 in the latest version of our manuscript.\n\nAs the deadline for discussion is approaching, we highly value your reviews and eagerly await your feedback. We kindly ask you to review our responses once more and let us know if they have fully or partially addressed your concerns. We are immensely grateful for your time and effort in reviewing our paper. \n\nWith gratitude,\n\nAuthors of Paper 9302"}]}]}}