{"M11LONBkx1": {"paper_info": {"Primary Area": "learning on graphs and other geometries & topologies", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Graph neural networks, Missing features", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "For graphs with missing features, we propose a new diffusion-based imputation scheme using synthetic features.", "Abstract": "In this paper, we tackle learning tasks on graphs with missing features, improving the applicability of graph neural networks to real-world graph-structured data. Previous diffusion-based imputation methods overlook the presence of channels with low-variance features, and these channels contribute very little to the performance in graph learning tasks. To overcome this issue, we propose a new diffusion-based imputation scheme using synthetic features in addition to observed features. The proposed scheme first identifies channels with low-variance features via pre-diffusion and generates a synthetic feature for a randomly chosen node in each low-variance channel. Then, our diffusion process spreads the synthetic features widely while considering observed features simultaneously. Extensive experiments on graphs with various rates of missing features demonstrate the effectiveness of our scheme, achieving state-of-the-art performance in both semi-supervised node classification and link prediction.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9301", "PDF Url": "https://openreview.net/pdf?id=M11LONBkx1"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9301 by Area Chair LFds", "Subheading": "Meta ReviewbyArea Chair LFds15 Dec 2023, 00:17 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper introduces a new method called Feature Imputation with Synthetic Features (FISF) to improve graph neural networks' performance on graphs with missing features. FISF addresses the issue of low-variance channels in previous diffusion-based methods by generating and diffusing synthetic features alongside observed ones. This approach demonstrates enhanced performance in semi-supervised node classification and link prediction tasks, especially in high-missing feature scenarios. Despite its promising results, the paper fails to thoroughly explain the impact of low-variance channels on overall performance, the rationale behind synthetic features, and its computational efficiency, leaving questions about its scalability and applicability to various graph-structured data types.\nJustification For Why Not Higher Score:\nThe drawbacks in thoroughly explain the impact of low-variance channels on overall performance.\nJustification For Why Not Lower Score:\nNA"}, {"Heading": "Gentle Reminder", "Subheading": "Official CommentbyAuthors22 Nov 2023, 22:32Everyone", "Content": "Comment:\nDear all reviewers,\n\nIn response to your reviews, we have conducted additional experiments and revised our manuscript based on the reviews. We have also responded in detail to all of the raised questions.\n\nWith the discussion period concluding in 8 hours, we would like to ensure that our responses have adequately clarified and addressed the reviewers' concerns. We are open to providing further clarification and engaging in additional discussions if needed.\n\nThank you!"}, {"Heading": "General Response to Reviewers", "Subheading": "Official CommentbyAuthors21 Nov 2023, 15:07Everyone", "Content": "Comment:\nDear Reviewers,\n\nWe appreciate all reviewers for their constructive feedback and hope that our response convinces the reviewers. Please inform us if the raised issues have been addressed. If the reviewers have additional concerns, we would appreciate the opportunity to further address them. Since we have addressed each review individually, we summarize the most important changes as follows:\n\n1. We included original feature variances of the datasets and distributions of feature variances when the datasets contain $90$% missing features (in Figure 1 and Figure 9 in the revised manuscript).\n2. We experimentally confirmed little contribution of low-variance channels in downstream tasks (in Appendix C.3 of the revised manuscript).\n3. We analyzed the time complexity of our scheme (in Appendix C.6 of the revised manuscript).\n\nWe uploaded the revised manuscript, marking the changes in blue."}, {"Heading": "Official Review of Submission9301 by Reviewer mYHT", "Subheading": "Official ReviewbyReviewer mYHT01 Nov 2023, 02:48 (modified: 23 Nov 2023, 07:03)EveryoneRevisions", "Content": "Summary:\nThis paper tackles the missing feature problem in graphs through the lens of low-variance channels. To address this, FISF first pre-diffuses the known features to unknown features and generates a synthetic feature on a specific low-variance channel. Finally, it diffuses the synthetic feature widely, treating it as a known feature throughout the graph. Performance across various missing rates demonstrates the efficacy of FISF.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\n1. The problem of the low-variance channel is interesting and provides a new perspective on the missing feature issue in the graph community.\n  \n2. The use of generating synthetic features seems to be a straightforward remedy for the low-variance channel.\n  \n3. The paper is well-written and easy to follow.\nWeaknesses:\n1. Although the authors demonstrated the existence of a low-variance channel after current diffusion-based methods, FP and PCFI, the link explaining how these low-variance channels act as a bottleneck for overall performance is not comprehensively provided. For example, the performance of node classification could be provided after excluding some portions of low-variance channels. Additionally, I am curious whether the original variance of the dataset, without any missing features, shows low variance as depicted in Figure 1. In this context, the authors should explain why a low-variance channel is especially burdensome in scenarios with missing features.\n  \n2. I wonder if the low-variance problem is due to zero-initialization. In cases of severe missing data and zero-initialization is equipped, the majority of the feature matrix would consist of zeros, so the output matrix would naturally contain many zeros (i.e., biases, if adding biases is enabled), especially considering that most graph datasets use one-hot encoding via bag-of-words for feature matrices. If the initialization for the missing feature were from random sampling, such as a uniform or normal distribution, the low variance problem might be easily addressed.\n  \n3. Although diffusion via synthetic features can enhance the distinctiveness across features, it might undermine the GNN's key inductive bias, which is the smoothness across connected nodes. A more in-depth discussion of the trade-off between feature distinctiveness and the smoothness of connected features should be provided.\n  \n4. While the authors proposed the use of synthetic features, excluding this module, the pre-diffusion and diffusion with synthetic features are exactly aligned with the existing work, PCFI. This raises concerns about the overall novelty of this paper.\n  \n5. The complexity of FISF compared to existing works is not comprehensively addressed. Given that the adjacency matrix is created for each feature dimension, the complexity would be exceedingly high, potentially limiting the practical application of FISF.\n  \n6. The proposed missing rates of 0.995 and 0.999 seem unrealistic. Furthermore, edge information can also be missing in real-world scenarios, a factor that should be considered.\nQuestions:\nSee the Weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer mYHT [Part 1/3]", "Subheading": "Official CommentbyAuthors21 Nov 2023, 13:06 (modified: 21 Nov 2023, 13:09)EveryoneRevisions", "Content": "Comment:\nThank you for the time and valuable feedback. We provide the answers below.\n\n> $\\textbf{Q1.}$ The link explaining how these low-variance channels act as a bottleneck for overall performance is not comprehensively provided. Additionally, I am curious whether the original variance of the dataset, without any missing features, shows low variance as depicted in Figure 1.\n\n$\\textbf{A1.}$ We conduct additional experiments to demonstrate little contribution of low-variance channels in downstream tasks. We compare performance by excluding partial channels from an original feature matrix using two different ways. The first way is excluding channels in descending order of variance, starting from the highest, based on a fixed proportion. The second way is excluding channels in ascending order of variance. As shown in Figure 5 and Figure 6 in Appendix C.3, the performance persists despite an increasing removal proportion of low-variance channels. However, cases of channel removal from the highest variance suffer significant performance degradation even with a low proportion of channel removal.\n\nWe added the original variance of the datasets before missing, to Figure 1 in the revised manuscript and Figure 9 in Appendix E. Through the original variance of the dataset, we can confirm that the original dataset also contains a few low-variance channels like output features from FISF. \n\n> $\\textbf{Q2.}$ I wonder if the low-variance problem is due to zero-initialization. In cases of severe missing data and zero-initialization is equipped, the majority of the feature matrix would consist of zeros, so the output matrix would naturally contain many zeros (i.e., biases, if adding biases is enabled), especially considering that most graph datasets use one-hot encoding via bag-of-words for feature matrices.  If the initialization for the missing feature were from random sampling, such as a uniform or normal distribution, the low variance problem might be easily addressed.\n\n$\\textbf{A2.}$ The low-variance channels in an output matrix are not caused by zero initialization for unknown features. According to the proof in Appendix A, initial values for unknown features do not affect the steady state of diffusion. During the diffusion, observed features are preserved by resetting to their original values at every iteration while missing features are updated by aggregating features from neighboring nodes. Eventually, the missing features converge to a steady state depending on only the observed features regardless of the initial values of missing features. That is, the influence of the initial values of the missing features converge to zero.\n\nIn the case of Cora, CiteSeer, and PubMed, which are sparse datasets containing many zeros in their original feature matrices, many low (almost zero)-variance channels can occur due to nearly identical observed values within a channel, resulting in a low-variance channel. This phenomenon due to sparsity is entirely different from the zero initialization of missing features. In the case of Photo, Computers, and OGBN-Arxiv, the ratio of zeros within the feature matrix is not high. For example, in OGBN-Arxiv, only 0.0002% of features are zeros since features are obtained by 128-dimensional deep embeddings of words. For all the aforementioned datasets, FISF improves the performance in downstream tasks by addressing low-variance channels regardless of their frequent values."}, {"Heading": "Response to Reviewer mYHT [Part 2/3]", "Subheading": "Official CommentbyAuthors21 Nov 2023, 13:08 (modified: 23 Nov 2023, 03:05)EveryoneRevisions", "Content": "Comment:\n> $\\textbf{Q3.}$ A more in-depth discussion of the trade-off between feature distinctiveness and the smoothness of connected features should be provided.\n\n$\\textbf{A3.}$ As the reviewer mentioned, there exists a trade-off between feature distinctiveness and smoothness on a graph. We discussed feature distinctiveness and smoothness in depth through various experiments. Initially, to explore the graph-level smoothness, we measure Dirichlet energy on imputed features and original features. As shown in the table below, FP designed to minimize Dirichlet energy via diffusion demonstrates the lowest Dirichlet energy. In contrast, FISF makes Dirichlet energy of the imputed features similar to that of the original features without considering the trade-off. Note that our FISF shows the highest Dirichlet energy (distinctiveness) among the methods.\n\n<Table A: log($E_D$) of imputed features under a structural-missing setting with $r_m=0.995$, where $E_D$ is the Dirichlet energy. Original denotes original given features.>\n\n|     Missing way     |        | Structural |         |        |  Uniform |         |\n|:-------------------:|:------:|:----------:|:-------:|:------:|:--------:|:-------:|\n| Method $\\downarrow$ |  Cora  |  CiteSeer  |  PubMed |  Cora  | CiteSeer |  PubMed |\n| Original            | $4.36$ |   $4.49$   |  $3.11$ | $4.36$ |  $4.49$  |  $3.11$ |\n| FP                  | $1.90$ |   $1.94$   | $0.798$ | $1.89$ |  $1.91$  | $0.805$ |\n| PCFI                | $3.14$ |   $2.59$   |  $1.49$ | $2.52$ |  $2.64$  |  $1.43$ |\n| FISF (Ours)         | $3.25$ |   $2.92$   |  $4.15$ | $2.69$ |  $2.70$  |  $4.34$ |\n\nWe conduct further qualitative analysis on imputed and deep features to examine feature distinctiveness. Figures 7 and 8 in Appendix C.4 depict t-SNE plots visualizing imputed and deep features. These plots indicate that FISF provides clearer cluster structures for both imputed and deep features compared to other imputation methods. While smoothness is an important inductive bias for GNNs, our experimental results confirm that features displaying excessive smoothness lead to poor performance in downstream tasks.\n\n> $\\textbf{Q4.}$  The pre-diffusion and diffusion with synthetic features are exactly aligned with the existing work, PCFI.\n\n$\\textbf{A4.}$ As the pre-diffusion stage in FISF, we adopt channel-wise inter-node diffusion in PCFI. However, the second diffusion stage involving synthetic features is a new scheme, distinct from PCFI.  Beyond addressing the problem of low-variance channels by generating synthetic features, we introduce a new diffusion stage that employs two distinct types of distance encoding. By combining these two distances, synthetic features exert a stronger influence than observed features during the diffusion process. As a result, FISF outperforms PCFI by a large margin at high rates of missing features.\n\n> $\\textbf{Q5.}$  The complexity of FISF compared to existing works.\n\n$\\textbf{A5.}$ FISF operates in structural-missing settings with a time complexity of $O(|\\mathcal{E}|+(1+\\gamma F)N^2)$ and in uniform-missing settings with a complexity of $O(|\\mathcal{E}|+(1+\\gamma) F N^2)$. During the rebuttal period, to address the increasing time complexity in uniform-missing settings, we have sought a way to replace channel-wise inter-node diffusion with FP in pre-diffusion as a light version of FISF, called FastFISF. Consequently, the time complexity of FastFISF decreases to $O(|\\mathcal{E}|+\\gamma FN^2)$ regardless of the missing way.\n\nThe table below displays the training time of methods. FP exhibits the shortest training time among the methods. However, FISF notably enhances performance in downstream tasks compared to FP. For instance, in structural-missing setups with $r_m=0.995$, FISF achieves significant gains in node classification accuracy over FP, showing improvements of $7.43$% and $4.94$% on Cora and PubMed, respectively. Additionally, FastFISF demonstrates substantial reductions in training time under uniform-missing settings. A detailed explanation of FastFISF including performance in downstream tasks is in Appendix C.5.\n\n<Table B: Training time of methods. OOM denotes an out-of-memory error.>\n\n| Missing way | Structural | missing | Uniform | missing |\n|-------------|:----------:|:---------:|:-------:|:-------:|\n| Method      |    Cora    |   PubMed  |   Cora  |  PubMed |\n| GCNMF       |   $10.3$s  |  $19.4$s  | $9.87$s | $28.3$s |\n| GRAFENNE    |   $47.9$s  |  $74.7$s  | $51.1$s | $74.0$s |\n| MEGAE       |   $1753$s  |    OOM    | $1801$s |   OOM   |\n| FP          |   $2.36$s  |  $3.12$s  | $2.25$s | $2.90$s |\n| PCFI        |   $2.45$s  |  $3.23$s  | $11.1$s | $34.1$s |\n| FastFISF    |   $13.4$s  |  $34.6$s  | $11.8$s | $42.5$s |\n| FISF        |   $13.4$s  |  $34.8$s  | $17.6$s | $78.2$s |"}, {"Heading": "Response to Reviewer mYHT [Part 3/3]", "Subheading": "Official CommentbyAuthors21 Nov 2023, 13:10 (modified: 23 Nov 2023, 01:49)EveryoneRevisions", "Content": "Comment:\n> $\\textbf{Q6.}$ The proposed missing rates of 0.995 and 0.999 seem unrealistic. Furthermore, edge information can also be missing in real-world scenarios, a factor that should be considered.\n\n$\\textbf{A6.}$ Research aimed at handling extremely high rates of missing data is actively progressing across various fields (e.g., 99.99% missing in electronic health records [1], 97.5% missing in semiconductor manufacturing data, and 95% missing in an image [3]). In line with this trend, diffusion-based imputation methods have been addressing challenging missing scenarios with a missing rate of 99%/99.5% [4, 5]. To demonstrate that our scheme endures even in more extreme missing scenarios, we include experimental results under 99.9% missing settings.\t\t \t \t \t\t\n\nAs an extreme scenario, during the early stages when few people (e.g., 0.1%) purchase a new product, most people (e.g., 99.9%) linked in a social network, having similar purchase tendencies, do not have any features related to this product. In this case, from product-specific features of the very few early adaptors, the proposed diffusion scheme can impute the features. Then, the fully filled matrix can be used as an input by GNNs for a learning task of product recommendation. \n\nWe concur with the reviewer\u2019s point that connectivity between entities is not provided in many real-world scenarios. To use graph-based methods in such scenarios, several efforts have been made to form graphs by using the k-NN algorithm [6, 7]. \n\n[1] Kim, Yeo-Jin, and Min Chi. \"Temporal Belief Memory: Imputing Missing Data during RNN Training.\" In Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI-2018). 2018\\\n[2] Park, Sewon, et al. \"Bayesian nonparametric classification for incomplete data with a high missing rate: an application to semiconductor manufacturing data.\" IEEE Transactions on Semiconductor Manufacturing (2023).\\\n[3] Yoon, Seongwook, and Sanghoon Sull. \"GAMIN: Generative adversarial multiple imputation network for highly missing data.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.\\\n[4] Rossi, Emanuele, et al. \"On the unreasonable effectiveness of feature propagation in learning on graphs with missing node features.\" Learning on Graphs Conference. PMLR, 2022.\\\n[5] Um, Daeho, et al. \"Confidence-Based Feature Imputation for Graphs with Partially Known Features.\" The Eleventh International Conference on Learning Representations. 2022.\\\n[6] Telyatnikov, Lev, and Simone Scardapane. \"EGG-GAE: scalable graph neural networks for tabular data imputation.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2023.\\\n[7] Yun, Sukwon, Junseok Lee, and Chanyoung Park. \"Single-cell RNA-seq data imputation using Feature Propagation.\" ICML workshop. 2023."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 19:32 (modified: 22 Nov 2023, 19:32)EveryoneRevisions", "Content": "Comment:\nDear Reviewer mYHT,\n\nWe're grateful for your feedback on our work. As the discussion period nears its end, we would like to confirm if our responses have sufficiently clarified and addressed your concerns. We are happy to provide any additional clarification and discussion.\n\nThank you."}, {"Heading": "Response from Reviewer mYHT", "Subheading": "Official CommentbyReviewer mYHT23 Nov 2023, 04:55Everyone", "Content": "Comment:\nI appreciate the author's detailed rebuttal. The majority of my concerns have been addressed, and I am particularly pleased with the addition of Figure C.3 and the updates made to Figure 1. However, I still have a concern regarding the impact of high missing rates on your model. Specifically, in cases like 99% and 99.9% missing, some columns might consist entirely of zeros, and thus the propagated values would remain zeros.\n\nIn this regard, could you provide results similar to those in Figure 1 but with random initialization? This would help address my concern. If my concern is satisfactorily resolved, I will directly raise my current score. However, considering the limited remaining time for the rebuttal process, I am prepared to raise my score before the deadline."}, {"Heading": "Second Response to Reviewer mYHT", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:53 (modified: 23 Nov 2023, 07:03)EveryoneRevisions", "Content": "Comment:\nThank you for the positive comments and constructive advice. \n\nTo address your remaing concern, we have included Figure 11 in Appendix E.3 of the revised manuscript. Figure 11 compares variance distributions when zero initialization and random initialization are used. Figure 11 shows that many low-varince channels persist despite random initialization, but there is a slight difference between the distributions despite using the same setting. This is because all the diffusion-based methods approximate the steady state with a sufficiently large hyperparameter $K$, indicating the number of diffusion iteration (e.g. $K=40$ is used in FP and $K=100$ is used in PCFI and FISF). However, we have further confirmed that variance distributions becomes identical with very large $K$ values (e.g., $K=1000$) regardless of initialization. Although the final approximated results are not affected by initialization for missing features with a large $K$, careful consideration is needed when determining $K$, depending on the initialization."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:59Everyone", "Content": "Comment:\nWe fixed an issue in Figure 11 and uploaded the revised manuscript."}, {"Heading": "Official Comment by Reviewer mYHT", "Subheading": "Official CommentbyReviewer mYHT23 Nov 2023, 07:05Everyone", "Content": "Comment:\nThank you for the last-minute discussion and all the authors' efforts.\n\nI have raised my score to 6."}]}, {"Heading": "Official Review of Submission9301 by Reviewer VMHb", "Subheading": "Official ReviewbyReviewer VMHb30 Oct 2023, 23:20 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a method for missing value imputation on top of pseudo-confidence-based feature imputation (PCFI) by manipulating the features with low variance, whose were left behind by PCFI. The idea is to insert another random feature for each low variance.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nI think the original idea is fair that the paper try to amplify low variance features.\nWeaknesses:\nThe direction of amplifying low variance features can be a good idea and if it is done right, there might be an optimal point that maximize performance on top of its baseline. \nHowever, the paper shows the algorithm, how to manipulate the synthetically generated random features without a clue why it has to be done that way, for what purpose. Overall, the paper really proposes a \"new method\" without actually showing what is the problem it is solving and how the method help achieving the goal.\nQuestions:\nWhat is the idea of a synthetic random feature and how it help improving performance?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer VMHb", "Subheading": "Official CommentbyAuthors21 Nov 2023, 13:17Everyone", "Content": "Comment:\nThank you for the time and valuable feedback. We provide the answer below.\n\n> $\\textbf{Q1.}$ What is the idea of a synthetic random feature and how it help improving performance? A clue why it has to be done that way, for what purpose.\n\n$\\textbf{A1.}$ The synthetic random feature is used as a virtual observed feature instead of a randomly chosen  missing feature. This synthetic feature is introduced to change a low variance channel into a high variance channel to increase distinctiveness. The distinctiveness leads to high performance of the downstream tasks.\n\nIn Figure 1 in the revised manuscript, we demonstrate that existing diffusion-based imputation methods generate low-variance channels that contribute very little to distinguishing nodes. A low-variance channel occurs when observed features within the channel have nearly identical values. Furthermore, to provide a clue on how synthetic random features improve performance, we conduct additional experiments on real-world datasets (Appendix C.3). We empirically verify that low-variance channels (not distinctive channels) contribute very little to performance in downstream tasks. To make features in low-variance channels help GNNs perform downstream tasks well, we inject synthetic features with randomly sampled values. When a synthetic feature is provided to a low-variance channel, there exists a feature value different from the observed features within the channel. Hence, treating the synthetic feature as a virtual observed feature can make the channel deviate from low variance. We observe that only a few low-variance channels remain in imputed features by our scheme. Across various missing settings, our scheme achieves state-of-the-art performance in both semi-supervised node classification and link prediction."}, {"Heading": "Official Comment by Reviewer VMHb", "Subheading": "Official CommentbyReviewer VMHb21 Nov 2023, 23:54Everyone", "Content": "Comment:\nThank you for your clarification. \n\nI think I am clear in the fact that the paper add random features to low variance channel that help to distinguish nodes, which is a way of adding more variance to low variance channels. What I still find missing is the justification of how more variance in any channel help to have better performance. One can add any amount of variance to any channel by random features, which increases distinctiveness, there is no clues why it should help any downstream task. \nI does not see this is a valid argument to explain performances. I keep my evaluation."}, {"Heading": "Second Response to Reviewer VMHb [Part 1/2]", "Subheading": "Official CommentbyAuthors22 Nov 2023, 06:57 (modified: 22 Nov 2023, 10:52)EveryoneRevisions", "Content": "Comment:\nWe agree with the reviewer\u2019s opinion that injecting many synthetic features into a low-variance channel disrupts the influence of the observed features due to the generation of many artificial spikes. As shown in Table 3 of our ablation study (Appendix C.1), injecting one synthetic feature per channel yields better performance in downstream tasks compared to injecting two synthetic features. We included this discussion on the reason for improving performance in downstream tasks in Appendix C.7. To explain the reason succinctly, we injected one synthetic feature into each low variance channel, but placed it at a different location for each channel. Then the diffused node feature vector containing every low-variance channel feature after diffusion becomes distinctive from others by reflecting the graph structure. We will illustrate a visualization on the distinctiveness of the diffused feature vector by our scheme in Appendix C.7."}, {"Heading": "Second Response to Reviewer VMHb [Part 2/2]", "Subheading": "Official CommentbyAuthors22 Nov 2023, 10:51 (modified: 22 Nov 2023, 10:52)EveryoneRevisions", "Content": "Comment:\nWe have added Figure 9 (in Appendix C.7), which visualizes the distinctiveness of a node feature vector obtained by our method, to the revised manuscript. \n\nWe appreciate your constructive feedback. Please let us know if our responses address your concerns."}, {"Heading": "Official Comment", "Subheading": "Official Commentby23 Nov 2023, 07:04 (modified: 23 Nov 2023, 07:04)EveryoneRevisions", "Content": "[Deleted]"}]}, {"Heading": "Official Review of Submission9301 by Reviewer VoZJ", "Subheading": "Official ReviewbyReviewer VoZJ30 Oct 2023, 07:25 (modified: 22 Nov 2023, 09:10)EveryoneRevisions", "Content": "Summary:\nThis paper claims that existing methods output low variance channels within imputed features and then presents a method called FISF, which performs diffusion with randomly injected synthetic features on low variance channels discovered from pre-diffusion process.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\n- This paper empirically shows that existing diffusion-based methods causes many low variance channels within imputed features, while proposed method FISF can solve those problem (Figure 1).\n- The paper is well-written and easy to follow.\nWeaknesses:\n-\tThis paper does not clearly justify why alleviating the low variance channel problem of the existing diffusion methods is significant for graph learning tasks, even though it is a key motivation of this paper. Without additional evidences, it is hard to agree with this paper\u2019s argument that low variance channels contribute very little to performance.\n-\tThis paper lacks justification of using na\u00efve random synthetic features. Authors claim that more distinctive representations are crucial for classification tasks, but I have concern that randomly injected synthetic features can lead to lower intra-class node representation similarity thus can be harmful on downstream tasks. In my opinion, discussion on aforementioned concern is required.\n-\tIt is required to include the time complexity of presented method. Since V_{k}^{(a)} differs by channel \u2018a\u2019 as synthetic feature-injected node differs by channels, diffusion process should be done by channels. Moreover, as presented method further requires pre-diffusion process, presented FISF seems to have much higher time complexity compared to existing methods, especially FP.\n-\tAs presented in the Table 5 in the Appendix, hyperparameters have been tuned with respect to each feature missing rate r_m. Regarding complexity of setting optimal hyperparameters, there is some concern about practical usage of FISF. \n-\tLastly, considering the similarity of Label Propagation (LP) and FP, and the argument about low variance channels (in respect of very high missing feature rates), I think this paper shares similar motivation with Poisson Learning [1], which mitigates very low label rate problem in LP. Poisson Learning points out that LP outputs almost constant pseudo-labels for most of unlabeled samples, while this paper points out existing diffusion-based methods including FP causes \u201clow variance channels\u201d, i.e. almost constant features (or an exact constant when there is only one observed feature value, as presented in this paper). Regarding aforementioned similarity, further discussion with Poisson Learning might be beneficial.\nQuestions:\n-\tCan you provide the feature variance distribution (Figure 1) in more realistic missing feature settings (I.e. r_m <= 0.9)? In my opinion, authors have to show that existing diffusion-based methods still suffer from the problem of making low variance channels in various missing feature settings, especially in more realistic scenarios.\n-\tCan you provide further theoretical or empirical evidences that can explain why random synthetic feature works well? (to resolve concern in W2)\n-\tWhat happens if pre-diffusion method is replaced to FP from PCFI? (Why this paper have chosen PCFI as a pre-diffusion method?)\n\n[1] Jeff Calder, Brendan Cook, Matthew Thorpe and Dejan Slepcev. Poisson Learning: Graph Based Semi-Supervised Learning At Very Low Label Rates. In International Conference on Machine Learning, pp. 1306-1316. PMLR, 2020.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer VoZJ [Part 1/5]", "Subheading": "Official CommentbyAuthors21 Nov 2023, 14:07 (modified: 21 Nov 2023, 14:08)EveryoneRevisions", "Content": "Comment:\nThank you for the time and valuable feedback. We provide the answers below.\n\n> $\\textbf{Q1.}$ This paper does not clearly justify why alleviating the low variance channel problem of the existing diffusion methods is significant for graph learning tasks, even though it is a key motivation of this paper. Without additional evidences, it is hard to agree with this paper\u2019s argument that low variance channels contribute very little to performance.\n\n$\\textbf{A1.}$ Since low-variance channels do not have any distinctive features, they contribute very little to performance in downstream tasks. To justify addressing the low-variance channel problem, we carry out extra experiments that provide evidence that low-variance channels have little contribution to downstream tasks. We compare performance by removing partial channels from an initial feature matrix using two distinct ways. One method involves excluding channels in descending order of variance, beginning with the highest and based on a fixed percentage. The second way is excluding channels in ascending order of variance. As demonstrated in Figure 5 and Figure 6 in Appendix C.3, performance remains relatively steady even as we remove an increasing proportion of low-variance channels. However, removing channels starting from the highest variance results in notable performance drops, even with a small proportion of channel removal.\n\n> $\\textbf{Q2.}$ This paper lacks justification of using na\u00efve random synthetic features. Authors claim that more distinctive representations are crucial for classification tasks, but I have concern that randomly injected synthetic features can lead to lower intra-class node representation similarity thus can be harmful on downstream tasks. In my opinion, discussion on the aforementioned concern is required. Can you provide further theoretical or empirical evidences that can explain why random synthetic feature works well?\n\n$\\textbf{A2.}$ To provide evidence regarding smoothness and intra-class node feature similarity, we conduct additional experiments. First, we measure Dirichlet energy of imputed features to compare graph-level smoothness. The table below shows that FISF gives the highest Dirichlet energy (distinctiveness) among the imputation methods.\n\n<Table A: log($E_D$) of imputed features under a structural-missing setting with $r_m=0.995$, where $E_D$ is the Dirichlet energy. Original denotes original given features.>\n\n|     Missing way     |        | Structural |         |        |  Uniform |         |\n|:-------------------:|:------:|:----------:|:-------:|:------:|:--------:|:-------:|\n| Method $\\downarrow$ |  Cora  |  CiteSeer  |  PubMed |  Cora  | CiteSeer |  PubMed |\n| Original            | $4.36$ |   $4.49$   |  $3.11$ | $4.36$ |  $4.49$  |  $3.11$ |\n| FP                  | $1.90$ |   $1.94$   | $0.798$ | $1.89$ |  $1.91$  | $0.805$ |\n| PCFI                | $3.14$ |   $2.59$   |  $1.49$ | $2.52$ |  $2.64$  |  $1.43$ |\n| FISF (Ours)         | $3.25$ |   $2.92$   |  $4.15$ | $2.69$ |  $2.70$  |  $4.34$ |\n\nIn addition, we conduct further experiments to investigate smoothness within classes. The table below demonstrates the intra-class cosine similarity calculated from imputed features by FISF. Ratio denotes average intra-class similarity/inter-class similarity. If Ratio is greater than 1, inter-class similarity becomes less than the average intra-class similarity, which means the feature is distinctive enough for classification of node features.  We include t-SNE plots that visualize imputed features and deep features in Appendix C.4. We verify that FISF provides clearer cluster structures for both imputed features and deep features than the other imputation methods. Since the imputed features still give distinctiveness and improve the classification performance, we can say that the randomly injected synthetic features are not  harmful on downstream tasks. \n\n<Table B: Average cosine similarity of imputed features by FISF, under a structural-missing setting with $r_m=0.995$.>\n\n| Dataset  | Inter-class | class 1 | class 2 | class 3 | class 4 | class 5 | class 6 | class 7 | Average intra-class |  Ratio |\n|----------|:-----------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------------------:|:------:|\n| Cora     |   $0.760$   | $0.858$ | $0.902$ | $0.902$ | $0.844$ | $0.691$ | $0.826$ | $0.870$ |       $0.842$       | $1.11$ |\n| CiteSeer |   $0.279$   | $0.267$ | $0.341$ | $0.636$ | $0.282$ | $0.513$ | $0.380$ |    -    |       $0.403$       | $1.45$ |\n| PubMed   |   $0.871$   | $0.893$ | $0.936$ | $0.880$ |    -    |    -    |    -    |    -    |       $0.903$       | $1.04$ |"}, {"Heading": "Response to Reviewer VoZJ [Part 2/5]", "Subheading": "Official CommentbyAuthors21 Nov 2023, 14:11 (modified: 21 Nov 2023, 14:17)EveryoneRevisions", "Content": "Comment:\n> $\\textbf{Q3.}$ It is required to include the time complexity of presented method. Since V_{k}^{(a)} differs by channel \u2018a\u2019 as synthetic feature-injected node differs by channels, diffusion process should be done by channels. Moreover, as presented method further requires pre-diffusion process, presented FISF seems to have much higher time complexity compared to existing methods, especially FP.\n\n$\\textbf{A3.}$ FISF operates in structural-missing settings with a time complexity of $O(|\\mathcal{E}|+(1+\\gamma F)N^2)$ and in uniform-missing settings with a complexity of $O(|\\mathcal{E}|+(1+\\gamma) F N^2)$. During the rebuttal period, to address the increasing time complexity in uniform-missing settings, we have sought a way to replace channel-wise inter-node diffusion with FP in pre-diffusion as a light version of FISF, called FastFISF. Consequently, the time complexity of FastFISF decreases to $O(|\\mathcal{E}|+\\gamma FN^2)$ regardless of the missing way.\n\nThe table below displays the training time of methods. FP exhibits the shortest training time among the methods. However, FISF notably enhances performance in downstream tasks compared to FP. For instance, in structural-missing setups with $r_m=0.995$, FISF achieves significant gains in node classification accuracy over FP, showing improvements of $7.43$% and $4.94$% on Cora and PubMed, respectively. Additionally, FastFISF demonstrates substantial reductions in training time under uniform-missing settings. A detailed explanation of FastFISF including performance in downstream tasks is in Appendix C.5.\n\n<Table C: Training time of methods. OOM denotes an out-of-memory error.>\n\n| Missing way | Structural | missing   | Uniform | missing |\n|-------------|:----------:|:---------:|:-------:|:-------:|\n| Method      |    Cora    |   PubMed  |   Cora  |  PubMed |\n| GCNMF       |   $10.3$s  |  $19.4$s  | $9.87$s | $28.3$s |\n| GRAFENNE    |   $47.9$s  |  $74.7$s  | $51.1$s | $74.0$s |\n| MEGAE       |   $1753$s  |    OOM    | $1801$s |   OOM   |\n| FP          |   $2.36$s  |  $3.12$s  | $2.25$s | $2.90$s |\n| PCFI        |   $2.45$s  |  $3.23$s  | $11.1$s | $34.1$s |\n| FastFISF    |   $13.4$s  |  $34.6$s  | $11.8$s | $42.5$s |\n| FISF        |   $13.4$s  |  $34.8$s  | $17.6$s | $78.2$s |"}, {"Heading": "Response to Reviewer VoZJ [Part 3/5]", "Subheading": "Official CommentbyAuthors21 Nov 2023, 14:17 (modified: 23 Nov 2023, 03:06)EveryoneRevisions", "Content": "Comment:\n> $\\textbf{Q4.}$ As presented in the Table 5 in the Appendix, hyperparameters have been tuned with respect to each feature missing rate r_m. Regarding complexity of setting optimal hyperparameters, there is some concern about practical usage of FISF.\n\n$\\textbf{A4.}$ Despite outperforming performance of FISF, conducting a hyperparameter search for FISF with three hyperparameters ($\\alpha$, $\\beta$, and $\\gamma$) can be burdensome in certain situations. However, both $\\alpha$ and $\\beta$ ($0<\\alpha,\\beta<1$) play a similar role in a base of distance during calculating PC (\\textit{i.e.} $\\xi^*_{i,b}=\\alpha^{\\mathbf{S}^*_{i,b}}$ and $\\xi^s_{i,a}=\\beta^{\\mathbf{S}^s_{i,a}}$). Thus we can combine them into one, i.e., $\\alpha = \\beta$. By doing this, the search complexity can be reduced from $5^3$ to $5^2$ without the performance degradation by setting five search points for each hyperparameter. The tables below show that the FISF* with the light search does not degrade performance on semi-supervised node classification and link prediction. The version with the light search requires from 20 minutes to 10 hours depending on the datasets, therefore this burden is manageable for practical usage of FISF.\n\n<Table D: Performance on semi-supervised node classification tasks under structural-missing settings with $r_m=0.995$, measured in accuracy (%)>\n\n| Method |      Cora      | CiteSeer | PubMed | Photo | Computers | OGBN-Arxiv | Average |\n|--------|:--------------:|:--------:|:------:|:-----:|:---------:|:----------:|:-------:|\n| FISF   | $79.29\\pm1.72$ |     $69.68\\pm2.47$     |    $76.90\\pm1.50$    |    $88.22\\pm0.79$   |      $79.40\\pm1.11$     |       $69.92\\pm0.17$     |    $77.24$     |\n| FISF*  |         $78.68\\pm1.72$        |     $69.68\\pm2.47$     | $76.74\\pm1.84$       |   $88.22\\pm0.79$   |      $79.40\\pm1.11$     |    $69.92\\pm0.17$        |    $77.11$     |\n\n<Table E: Performance on semi-supervised node classification tasks under uniform-missing settings with $r_m=0.995$, measured in accuracy (%)>\n\n| Method |      Cora      | CiteSeer | PubMed | Photo | Computers | OGBN-Arxiv | Average |\n|--------|:--------------:|:--------:|:------:|:-----:|:---------:|:----------:|:-------:|\n| FISF   | $79.09\\pm1.73$ |     $69.52\\pm1.81$      |     $77.53\\pm1.28$   |    $88.32\\pm1.37$    |     $82.12\\pm0.51$                  |     $69.81\\pm0.16$    | $77.73$  |\n| FISF*  |       $79.09\\pm1.73$         |      $69.52\\pm1.81$    |            $76.89\\pm2.01$   |      $88.32\\pm1.37$     |     $81.56\\pm0.47$       |      $69.81\\pm0.16$   | $77.53$ | \n\n<Table F: Performance on link prediction tasks under structural-missing settings with $r_m=0.995$, measured in ROC AUC score (%)>\n\n| Method |      Cora      | CiteSeer | PubMed | Photo | Computers| Average |\n|--------|:--------------:|:--------:|:------:|:-----:|:---------:|:----------:|\n| FISF   | $87.26\\pm1.44$   | $84.12\\pm1.17$       | $83.19\\pm0.78$     | $95.86\\pm0.21$    | $94.70\\pm0.30$  | $89.03$      |\n| FISF*  |         $86.80\\pm1.27$   | $84.12\\pm1.17$       | $82.46\\pm0.94$     | $95.76\\pm0.33$    | $94.39\\pm0.82$ | $88.70$     |\n\n<Table G: Performance on link prediction tasks under uniform-missing settings with $r_m=0.995$, measured in ROC AUC score (%)>\n\n| Method |      Cora      | CiteSeer | PubMed | Photo | Computers| Average |\n|--------|:--------------:|:--------:|:------:|:-----:|:---------:|:----------:|\n| FISF   | $87.44\\pm0.80$   | $83.45\\pm2.53$       | $85.33\\pm0.47$     | $96.64\\pm0.18$    | $95.13\\pm0.35$ | $89.60$      |\n| FISF*  |         $87.56\\pm1.29$   | $81.15\\pm1.17$       | $82.46\\pm0.69$     | $95.68\\pm0.42$    | $94.94\\pm0.27$ | $88.36$     |"}, {"Heading": "Response to Reviewer VoZJ [Part 4/5]", "Subheading": "Official CommentbyAuthors21 Nov 2023, 14:25Everyone", "Content": "Comment:\n> $\\textbf{Q5.}$ Lastly, considering the similarity of Label Propagation (LP) and FP, and the argument about low variance channels (in respect of very high missing feature rates), I think this paper shares similar motivation with Poisson Learning [1], which mitigates very low label rate problem in LP. Poisson Learning points out that LP outputs almost constant pseudo-labels for most of unlabeled samples, while this paper points out existing diffusion-based methods including FP causes \u201clow variance channels\u201d, i.e. almost constant features (or an exact constant when there is only one observed feature value, as presented in this paper). Regarding aforementioned similarity, further discussion with Poisson Learning might be beneficial.\n\n$\\textbf{A5.}$ We thank the reviewer for pointing out a relevant reference [1]. As the reviewer mentioned, our paper and [1] commonly address problems in Laplacian learning adopted by both LP and FP. As you recommended, we added further discussion with Poisson learning [1] to the related work in the revised manuscript as follows. ``The problems being addressed are different, and the causes of each problem are completely different. In [1], proposed Poisson learning is a feature-agnostic method that only propagates given labels like LP, tackling semi-supervised classification. Furthermore, the problem addressed in [1] arises from the very narrow area of a localized spike, generated by the propagation of a given label. The problem assumes having a wide variety of labels evenly distributed despite very low label rates. However, we discover and address the problem of low-variance channels caused by nearly identical observed values with a feature channel. We provide theoretical proof about the cause of the problem of low-variance channels.\u201d \n\n[1] Calder, Jeff, et al. \"Poisson learning: Graph based semi-supervised learning at very low label rates.\" International Conference on Machine Learning. PMLR, 2020.\n\n> $\\textbf{Q6.}$ Can you provide the feature variance distribution (Figure 1) in more realistic missing feature settings (I.e. r_m <= 0.9)? In my opinion, authors have to show that existing diffusion-based methods still suffer from the problem of making low variance channels in various missing feature settings, especially in more realistic scenarios.\n\n$\\textbf{A6.}$ In the revised version, we provided distributions of feature variances for each channel on CiteSeer containing 90\\% missing features in Figure 1. We also added distributions of feature variances on Cora in Appendix E.2. We can observe that the problem of low-variance channels is not limited to high $r_m$ and also occurs in more realistic missing feature settings. We further demonstrate variance distributions of original features without any missing. We confirm that the original features only contain a few low-variance channels like output features from FISF."}, {"Heading": "Response to Reviewer VoZJ [Part 5/5]", "Subheading": "Official CommentbyAuthors21 Nov 2023, 14:31 (modified: 21 Nov 2023, 23:01)EveryoneRevisions", "Content": "Comment:\n> $\\textbf{Q7.}$ What happens if pre-diffusion method is replaced to FP from PCFI? (Why this paper have chosen PCFI as a pre-diffusion method?)\n\n$\\textbf{A7.}$ We select channel-wise inter-node diffusion in PCFI as pre-diffusion to maximize performance in downstream tasks. For not low-variance channels, features obtained via pre-diffusion are preserved until diffusion with synthetic features ends. Therefore, since PCFI outperforms FP in terms of performance in downstream tasks, FISF shows slightly better performance than FastFISF in most cases. We define FISF using FP for pre-diffusion as FastFiSF and the table below shows the comparison results in terms of semi-supervised node classification accuracy. While the original FISF outperforms FastFISF, the performance of FastFISF is comparable to FISF.\n\n<Table H: Performance on semi-supervised node classification tasks under structural-missing settings with $r_m=0.995$, measured in accuracy (%)>\n\n| Method |      Cora      | CiteSeer | PubMed | Photo | Computers | OGBN-Arxiv | Average |\n|--------|:--------------:|:--------:|:------:|:-----:|:---------:|:----------:|:-------:|\n| FISF   | $79.29\\pm1.72$ |     $69.68\\pm2.47$     |    $76.90\\pm1.50$    |    $88.22\\pm0.79$   |      $79.40\\pm1.11$     |       $69.92\\pm0.17$     |    $77.24$     |\n| FastFISF  |         $78.94\\pm1.92$   | $69.42\\pm1.44$       | $77.14\\pm0.94$     | $88.10\\pm1.38$    | $79.09\\pm1.42$        | $69.53\\pm0.21$ | $77.04$     |\n\n<Table I: Performance on semi-supervised node classification tasks under uniform-missing settings with $r_m=0.995$, measured in accuracy (%)>\n\n| Method |      Cora      | CiteSeer | PubMed | Photo | Computers | OGBN-Arxiv | Average |\n|--------|:--------------:|:--------:|:------:|:-----:|:---------:|:----------:|:-------:|\n| FISF   | $79.09\\pm1.73$ |     $69.52\\pm1.81$      |     $77.53\\pm1.28$   |    $88.32\\pm1.37$    |     $82.12\\pm0.51$                  |     $69.81\\pm0.16$    | $77.73$  |\n| FastFISF  |       $79.29\\pm1.84$   | $69.39\\pm1.57$       | $77.41\\pm1.77$     | $88.03\\pm1.46$    | $81.70\\pm0.54$        | $69.45\\pm0.18$  | $77.55$ | \n\n\nThe advantage of using FastFISF is a reduction in time complexity. Since channel-wise inter-node diffusion requires more time compared to FP in uniform-missing settings, FastFISF decreases the training time in uniform-missing settings. Table C in $\\textbf{A3}$ shows the training time of methods.  While FP has the lowest training time among the methods, FISF brings great performance improvement compared to FP. For instance, on Cora and PubMed, FISF demonstrates improvements in node classification accuracy by $7.43$\\%p and $4.94$\\%p respectively, compared to FP."}, {"Heading": "Official Comment by Reviewer VoZJ", "Subheading": "Official CommentbyReviewer VoZJ22 Nov 2023, 09:09 (modified: 22 Nov 2023, 09:09)EveryoneRevisions", "Content": "Comment:\nThank you for the authors' earnest response. Overall, most of the doubtful points were addressed. Thus, I have raised my ratings.  \nThe following are the remaining minor issues in your responses.\n- A2: Can you provide the average (inter/intra-class) cosine similarity of original features like the results presented in Table B (Table 7 in the manuscript) for imputed features? In my opinion, comparing the results shown in Table B with those results might be beneficial and help understand the significance of the results of Table B.\n- A5. I appreciate the authors' responses in general. However, the discussion with Poisson learning added to the manuscript seems insufficient because it is abbreviated compared to the authors' responses. Therefore, we request that the authors' responses be reflected in the manuscript as they are."}, {"Heading": "Second Response to Reviewer VoZJ", "Subheading": "Official CommentbyAuthors22 Nov 2023, 19:22 (modified: 23 Nov 2023, 03:02)EveryoneRevisions", "Content": "Comment:\nWe appreciate the reviewer's decision. Your insightful feedback has further improved our paper.\n\n> $\\textbf{Q8.}$ Can you provide the average (inter/intra-class) cosine similarity of original features like the results presented in Table B (Table 7 in the manuscript) for imputed features? In my opinion, comparing the results shown in Table B with those results might be beneficial and help understand the significance of the results of Table B.\n\n$\\textbf{A8.}$ Table J shows the intra-class cosine similarity calculated from original features. The results indicate that original features also have values of Ratio greater than 1 across the datasets. This means that the datasets also originally have higher intra-class feature similarity compared to inter-class feature similarity. Despite the introduction of synthetic features during diffusion, as shown in Table B, we can observe that imputed features by our scheme consistently maintains higher intra-class feature similarity than inter-class feature similarity. We included this discussion and Table J in Appendix C.4 of the revised manuscript.\n\n<Table J: Average cosine similarity of original features.>\n\n| Dataset  | Inter-class | class 1 | class 2 | class 3 | class 4 | class 5 | class 6 | class 7 | Intra-class Average |  Ratio |\n|----------|:-----------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------------------:|:------:|\n| Cora     |   $0.0578$           | $0.841$       | $0.113$       | $0.0896$       | $0.683$       | $0.0690$       | $0.0853$       | $0.109$       | $0.0883$           | $1.53$ |\n| CiteSeer |   $0.0470$          | $0.655$      | $0.0601$      | $0.0617$      | $0.0650$      | $0.762$  | $0.0581$  | -   | $0.0644$ | $1.37$ |\n| PubMed   |   $0.0719$         | $0.112$    | $0.937$     | $0.0779$    | -    | -    | -    | -    | $0.0946$         | $1.32$ |\n\n> $\\textbf{Q9.}$  The discussion with Poisson learning added to the manuscript seems insufficient because it is abbreviated compared to the authors' responses. Therefore, we request that the authors' responses be reflected in the manuscript as they are.\n\n$\\textbf{A9.}$ We thank you for the suggestion. We added our full discussion with Poisson learning to the related work in the revised manuscript.\n\nPlease let us know if the remaining issues are addressed. If you have any further concerns, we would like to have an opportunity to address them."}]}, {"Heading": "Official Review of Submission9301 by Reviewer 8JVT", "Subheading": "Official ReviewbyReviewer 8JVT28 Oct 2023, 13:55 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper addresses the task of learning on graphs with missing features, specifically focusing on improving the application of graph neural networks (GNNs) to real-world graph-structured data. The paper introduces a novel diffusion-based imputation scheme called Feature Imputation with Synthetic Features (FISF).\n\n(1) It generates synthetic features via pre-diffusion for randomly chosen nodes in these channels.\n\n(2) The diffusion process spreads these synthetic features while also considering observed features simultaneously.\n\n(3) The proposed scheme has been empirically tested, showing promising results, especially in scenarios with a high rate of missing \nfeatures. It shows robust performance in both semi-supervised node classification and link prediction tasks.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\n1. The paper addresses a significant and practical problem in the domain of graph learning.\n\n2. The proposed FISF method is novel, focusing on low-variance channels that were overlooked by previous approaches.\n\n3. The paper seems to provide extensive experiments on graphs with varying rates of missing features, demonstrating the robustness of the proposed method.\nWeaknesses:\n1. From the provided content, it's unclear how the proposed method scales with large real-world graphs or its computational efficiency.\n\n2. The abstract and introduction don't mention how generalizable the method is across diverse types of graph-structured data or different\nQuestions:\nSee weakness\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 8JVT", "Subheading": "Official CommentbyAuthors21 Nov 2023, 14:39Everyone", "Content": "Comment:\nWe appreciate your encouragement and hope that the following answers can make you more confident.\n\n> $\\textbf{Q1.}$ From the provided content, it's unclear how the proposed method scales with large real-world graphs or its computational efficiency.\n\nFISF operates in structural-missing settings with a time complexity of $O(|\\mathcal{E}|+(1+\\gamma F)N^2)$ and in uniform-missing settings with a complexity of $O(|\\mathcal{E}|+(1+\\gamma) F N^2)$. During the rebuttal period, to address the increasing time complexity in uniform-missing settings, we have sought a way to replace channel-wise inter-node diffusion with FP in pre-diffusion as a light version of FISF, called FastFISF. Consequently, the time complexity of FastFISF decreases to $O(|\\mathcal{E}|+\\gamma FN^2)$ regardless of the missing way.\n\nThe table below displays the training time of methods. FP exhibits the shortest training time among the methods. However, FISF notably enhances performance in downstream tasks compared to FP. For instance, in structural-missing setups with $r_m=0.995$, FISF achieves significant gains in node classification accuracy over FP, showing improvements of $7.43$% and $4.94$% on Cora and PubMed, respectively. Additionally, FastFISF demonstrates substantial reductions in training time under uniform-missing settings. A detailed explanation of FastFISF including performance in downstream tasks is in Appendix C.5.\n\nOGBN-Arxiv with ~0.2M nodes is the largest real-world graph dataset in this paper. On OGBN-Arxiv, we show the effectiveness of FISF on semi-supervised node classification tasks and FISF requires only 16.1 seconds for imputation. We agree with the reviewer that the computational efficiency of FISF was unclear. Hence, we added complexity analysis in Appendix C.6.\n\n<Table A: Training time of methods. OOM denotes an out-of-memory error.>\n\n| Missing way | Structural | missing   | Uniform | missing |\n|-------------|:----------:|:---------:|:-------:|:-------:|\n| Method      |    Cora    |   PubMed  |   Cora  |  PubMed |\n| GCNMF       |   $10.3$s  |  $19.4$s  | $9.87$s | $28.3$s |\n| GRAFENNE    |   $47.9$s  |  $74.7$s  | $51.1$s | $74.0$s |\n| MEGAE       |   $1753$s  |    OOM    | $1801$s |   OOM   |\n| FP          |   $2.36$s  |  $3.12$s  | $2.25$s | $2.90$s |\n| PCFI        |   $2.45$s  |  $3.23$s  | $11.1$s | $34.1$s |\n| FastFISF    |   $13.4$s  |  $34.6$s  | $11.8$s | $42.5$s |\n| FISF        |   $13.4$s  |  $34.8$s  | $17.6$s | $78.2$s |\n\n\n> $\\textbf{Q2.}$ The abstract and introduction don't mention how generalizable the method is across diverse types of graph-structured data or different.\n\nFISF has good generalizability across diverse types of graph-structured data, extending its applicability to both  hypergraphs and heterogeneous graphs. In case of hypergraphs, a hypergraph can be transformed into a homogeneous graph via clique expansion. Therefore, missing features of nodes in a hypergraph can be also imputed by FISF. In case of heterogeneous graphs, our FISF can be applied to heterogeneous graphs throughout  meta-paths. However, since this application is not straightforward, we mention these extensions as future work in Conclusion."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 19:35Everyone", "Content": "Comment:\nDear Reviewer 8JVT,\n\nWe're grateful for your feedback on our work. As the discussion period nears its end, we would like to confirm if our responses have sufficiently clarified and addressed your concerns. We are happy to provide any additional clarification and discussion.\n\nThank you."}]}]}, "2wwPG1wpsu": {"paper_info": {"Primary Area": "datasets and benchmarks", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Time Series, Deep Learning, Neural Networks, Data Mining", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "This paper introduces LST-Bench, a comprehensive benchmark designed for evaluating long sequence time-series forecasting(LSTF) models. This benchmark has been developed in response to recent advancements in deep learning methods in the field of LSTF tasks. LST-Bench includes Transformer-based, MLP-based, CNN-based, and RNN-based models, evaluating the performance of 11 major forecasting models on a set of commonly used 7 datasets and 7 new datasets that we have introduced. We conduct a thorough analysis of the experimental results, including the overall prediction performance of models and their generalization across different prediction lengths and datasets. Notably, we found that regardless of the model architecture, the phenomenon referred to as \"Degeneracy\" occurs when the model's predictions consistently maintain a low Mean Squared Error value but are characterized by repetitive and simplistic pattern generation, thus losing the meaningfulness of the predictions. Also, the model's optimal performance is very close to its performance after training for just one epoch. These two phenomenons emphasize the need for further investigation. Our LST-Bench will serve as a valuable resource for advancing research in the field of time series forecasting.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9299", "PDF Url": "https://openreview.net/pdf?id=2wwPG1wpsu"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9299 by Area Chair D5qA", "Subheading": "Meta ReviewbyArea Chair D5qA05 Dec 2023, 03:09 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper introduces a benchmark for long-term time-series forecasting, comparing 11 major models on 14 datasets. While such a benchmark would be useful if it is designed well, there are concerns about the novelty and contribution of the paper. The phenomena observed from the experiments could potentially bring about insights that can lead to further research. Unfortunately, those phenomena were not discussed and analyzed in detail in the paper. The authors are encouraged to consider the comments and suggestions of the reviewers to improve the paper.\nJustification For Why Not Higher Score:\nIt is well below the acceptance standard.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9299 by Reviewer 1Wsy", "Subheading": "Official ReviewbyReviewer 1Wsy31 Oct 2023, 09:22 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents LST-Bench to evaluate long-sequence time-series forecasting models. The benchmark includes four types of models and evaluates them on a variety of datasets, including a new dataset called NEW. The experimental results show that all models exhibit significantly faster convergence compared to models in other domains, but also exhibit a phenomenon called Degeneracy, which signifies that the model's predictions exhibit lower MSE/MAE values, yet in fact, the forecasted outcomes tend to manifest as periodic repetitions, failing to genuinely predict the future data. The paper emphasizes the need for further investigation to address this issue and to reevaluate or redefine evaluation metrics applicable to time series forecasting to more accurately measure model performance, model design, and improvement on that. The paper also discusses the limitations of the benchmark, such as the input being limited to a single time series and not allowing for the inclusion of external features.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nThe authors conduct a series of experiments on existing models and datasets and spot the phenomenon called Degeneracy.\nThe authors collect a dataset from the electricity industry.\nWeaknesses:\nThe contribution and novelty of this paper are low. The authors have applied existing time series models to commonly used datasets, which does not provide additional insights into either the model or its results.\nThe only new thing in this work seems to be the introduction of a NEW dataset from the electricity industry. Unfortunately, the authors have not provided any additional information about this dataset beyond its source and sampling rate.\nQuestions:\nNA\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n1: strong reject\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9299 by Reviewer t1kK", "Subheading": "Official ReviewbyReviewer t1kK29 Oct 2023, 04:08 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper provides a benchmark for long sequence time series forecasting (LSTF) task. The benchmark consists of 4 ETT datasets, weather, traffic, electricity and 7 NEW datasets of 15-minute-level data from the power industry. By conducting experiments of 11 major forecasting models on these datasets, the paper reveals the phenomenon of Degeneracy, that is the model's predictions consistently maintain a low MSE loss but are characterized by repetitive and simplistic pattern generation. Meanwhile, these model achieve near convergence after just one epoch. These two features need further investigation.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThis paper can be considered as the first benchmark for LSTF problem after the widespread application of deep learning in time series forecasting, and serve as a valuable resource for future research.\nThis paper reveals two important phenomenon: Degeneracy and quick-convergence in LSTF problem, which inspires future investigation.\nWeaknesses:\nThe paper summarizes the experiment results, but lacks further discussion about those phenomenon. For example, will Degeneracy affect generalization ability of the model? Any showcase illustrates the differences between one-epoch model and fully-trained model? I think by diving into those questions will make the paper more inspiring.\nQuestions:\nsee weakness\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9299 by Reviewer PPjW", "Subheading": "Official ReviewbyReviewer PPjW28 Oct 2023, 23:41 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents a long sequence timeseries benchmark framework that involves 11 benchmark models and 14 datasets, including 7 new and 7 old. Specifically, the authors conducted a thorough analysis on the experimental results, including the overall prediction performance of models and their generalization across different prediction lengths and datasets. The authors found a phenomenon referred to as \"degeneracy\", which means the low MSE value but with predictions having repetitive and simplistic pattern generations. Additionally, the authors found that the optimal performance is very close to its performance after training just one epoch. The authors claimed their benchmark work serves as valuable resource for advancing research in the field of timeseries forecasting.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nI think this paper is easy to follow and presents many detailed results on the long sequence timeseries benchmark model performance, covering different domains. Also the new datasets may be used in other works for model evaluation. The experimental setup and configuration detail is very clear.\nWeaknesses:\nThe novelty in this paper is very marginal. Though the authors have presented many results, the originality of the paper is very low. Nothing is new in terms of technical frameworks. All models are existing and some datasets have been public. Though the new datasets are provided for evaluating the models, it is unclear to me how much value it would bring for the community.\nThe technical detail for each model is missing. The authors should present each model architecture in the paper for completeness at least.\nThe authors have found some interesting phenomena, while they failed to investigate them to dig out the underlying cause. They have been quite generically existing in different scenarios. If the authors could study them in a theoretical perspective, this would add great value to the paper.\nMore accuracy metrics should be introduced in the paper to extend the generality of the benchmark framework, such as MAPE, CVRMSE, NMBE.\nQuestions:\nHow to improve the paper's novelty?\nWhat is the underlying theoretical cause of the \"degeneracy\" in the work?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9299 by Reviewer inoa", "Subheading": "Official ReviewbyReviewer inoa27 Oct 2023, 06:15 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn spite of the widespread use of time series forecasting models, there are limited benchmarks for assessing the quality of different models in specific settings. In this work, the authors focus on model performance when applied to long-horizon forecasting, and demonstrate that all models perform poorly for datapoints further into the future - the authors refer to this problem as \u201cdegeneracy\u201d. Although some existing models perform better than others, the analysis reveals a wider problem, and the authors call for further research into why performance degrades in such settings.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n1 poor\nStrengths:\nIdentifying limitations in existing models is helpful for informing future research directions, and addressing potential misconceptions on expected performance.\nThe authors present a clear comparison of how different models compare against a suite of datasets for long-horizon predictions. The obtained rankings could be helpful for practitioners assessing which model to apply to their problem setting.\nWeaknesses:\nTo my understanding, the 9 new datasets all originate from the same problem domain (equipment monitoring). The authors did not share the time series yet; however, I would not expect there to be much diversity among these new time series. A well-developed benchmark should cover additional time series from different domains, and hence I don\u2019t see this addition as being particularly noteworthy.\nThe insights gleaned from the paper are very limited, as the authors primarily present empirical evidence of the degraded performance over longer horizons without much novel perceptions. Although I appreciate the evaluation presented by the authors in this work, I don\u2019t think the paper feels complete without a clearer vision of how the issues identified here can be effectively resolved or at least partially mitigated in a tangible manner.\nIn the evaluation, the authors comment on how the default hyper-parameters were selected for the models under review. I can see how this simplifies the experimental set-up, but I\u2019m also left wondering about the extent to which adequate hyper-parameter optimisation could improve the reported results.\nUnfortunately, the paper\u2019s writing isn\u2019t very compelling, and the overall structuring seems more akin to a technical report than a conference paper.\nQuestions:\nI list out my concerns around the paper in the\nWeaknesses\nsection. I would be looking for responses to those comments in the forthcoming author rebuttal.\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nN/A\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}]}, "6ARlSgun7J": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Extreme Classification, Extreme Multi-Label Learning", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Extreme Classification (XC) architectures, which utilize a massive One-vs-All (OvA) classifier layer at the output, have demonstrated remarkable performance on problems with large label sets. Nonetheless, these architectures falter on tail labels with few representative samples. This phenomenon has been attributed to factors such as classifier over-fitting and missing label bias, and solutions involving regularization and loss re-calibration have been developed. This paper explores the impact of label variance - a previously unexamined factor - on the tail performance in extreme classifiers. It also develops a method to systematically reduce label variance in XC by transferring the knowledge from a specialized tail-robust teacher model to the OvA classifiers. For this purpose, it proposes a principled knowledge distillation framework, LEVER, which enhances the tail performance in extreme classifiers with formal guarantees on generalization. Comprehensive experiments are conducted on a diverse set of XC datasets, demonstrating that LEVER can enhance tail performance by around 5% and 6% points in PSP and coverage metrics, respectively, when integrated with leading extreme classifiers. Moreover, it establishes a new state-of-the-art when added to the top-performing Renee classifier. Extensive ablations and analyses substantiate the efficacy of our design choices. Another significant contribution is the release of two new XC datasets that are different from and more challenging than the available benchmark datasets, thereby encouraging more rigorous algorithmic evaluation in the future. Code for LEVER is available at: aka.ms/lever.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "Submission Number": "9297", "PDF Url": "https://openreview.net/pdf?id=6ARlSgun7J"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9297 by Area Chair Cace", "Subheading": "Meta ReviewbyArea Chair Cace15 Dec 2023, 12:39 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper concerns the problem of tail-label performance in extreme multi-label classification. As variance on tail-labels can be high, the authors introduce an architecture with an additional Siamese teacher model. The introduced solution is justified by a theoretical analysis and very promising empirical results.\nThe weak point of the paper raised by the reviewers is that the the introduced algorithm is based rather on a simple idea with limited novelty. Additionally, the theoretical analysis is flawed as it heavily relies on previous results without a clear extension or elaboration on them. Nevertheless, the new algorithm achieves state-of-the-art results for extreme multi-label classification tasks, motivating new research in this domain.\nThe authors are encouraged to improve the theoretical part in their final version of the paper.\nJustification For Why Not Higher Score:\nThe paper has several flaws raised by the reviewers such as limited novelty of the algorithmic solution or limited theoretical analysis heavily relying on previous results.\nJustification For Why Not Lower Score:\nThe new algorithm achieves state-of-the-art results."}, {"Heading": "Rebuttal Summary", "Subheading": "Official CommentbyAuthors23 Nov 2023, 04:26Everyone", "Content": "Comment:\nWe thank the reviewers for their efforts in reviewing our work. Below, we summarize the rebuttal.\nAs suggested by\nReviewer Kx6v\n, we have added a detailed breakdown of the training time overhead by adding LEVER (Table 24,25, 26 in the suppl.), clarified the model size and examined the effect of using different $\\tau$ (\nthis response\n) in Table 22 in the suppl. We are glad that all of their concerns have been resolved.\nAs suggested by\nReviewer Cq1J\n, we have discussed the effect of varying the $\\lambda$ parameter in our loss function in\nthis response\n. We will discuss the effect of varying $\\tau$, currently discussed in Section 5,  in Section 3 in the revised draft. We appreciate the reviewer's positive outlook on our experimental rigor.\nLastly, as suggested by\nReviewer Uo9h\n, we have clarified the differences between our work and [1] in\nthis response\n. We will include this in our final draft and further polish our presentation of theoretical results in the final version, as this will require re-writing to adhere to the page limits at the moment.\n[1]: \"Data scarcity, robustness, and extreme multi-label classification\" (Babbar and Scholkopf 2019)"}, {"Heading": "Author-Reviewer Discussion ends soon", "Subheading": "Official CommentbyArea Chair Cace21 Nov 2023, 21:46 (modified: 15 Mar 2024, 00:27)EveryoneRevisions", "Content": "Comment:\nDear Reviewers and Authors,\nThe discussion phase ends soon. Please check all the comments, questions, and responses and react appropriately.\nThank you!\nBest, AC for Paper #9297"}, {"Heading": "Official Review of Submission9297 by Reviewer Uo9h", "Subheading": "Official ReviewbyReviewer Uo9h09 Nov 2023, 08:59 (modified: 23 Nov 2023, 05:19)EveryoneRevisions", "Content": "Summary:\nThe paper presents a methodology for improving performance on tail-labels. The main observation behind the proposed approach is that there is a significant variance in the label distribution due to the finite and even scarce number of data points for tail-labels in the extreme classification. The paper builds a connection with an existing work (Menon et al. 2021), on which it heavily relies, for most of the motivation, to propose a variance reduction strategy (Theorem 1 in the paper & discussion thereafter) and hence improvement in the generalization error.\nThe focus of the approach (generalization analysis) is on the last/classification layer of the network. The above generalization analysis leads to an augmented objective which, in addition to standard hard labels, also consists of a loss term consisting of soft labels from a teacher model, for which recent frameworks based on Siamese training are exploited. The proposed approach is tested on a range of datasets from the extreme classification repository, and it is shown that the proposed approach leads to significant improvements in the prediction performance in terms of P@k and PSP@k metrics. The augmentation strategy is also compared to existing methods for data augmentation in extreme classification to further demonstrate its general applicability.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe paper attempts to address a key shortcoming of existing methods in extreme classification i.e. performance of sota methods on tail-labels, which despite its importance, doesn\u2019t get much focus of research.\nThe experimental results of the paper are quite impressive, and significant gains on a range of datasets, and methods are shown, thereby demonstrating its general applicability. Overall, the experimental setup is quite detailed.\nThe paper also contributes two additional datasets (LF-AOL-270K, and LF-WikiHierarchy-1M), which may be helpful for the community.\nWeaknesses:\nThe main shortcoming of the paper is the lack of novelty in the main idea and the approach :\n1a) In terms of the content i.e. the main theoretical results such as Theorem 1, its proof, the idea to reduce variance for improving generalization, using soft-labels in teacher-student setup has already been explored in the existing work of Menon et al 2021. It seems that the paper attempts to build a loose bridge between this earlier theoretical work to build a weighting scheme and soft-labels (equation 9).\n1b) The paper claims that the variance issue for tail-labels has not been explored so far. However, this seems not quite true, as a similar concern has been raised in the earlier work Babbar and Scholkopf 2019, where there was a similar argument that due to the lack of data in tail-labels, for a given class label, there is high variance between the input features between two samples.\nThere also seems to be a lack of consistency in terms of using the symbols and notation in many places. For instance, X is used in Section 3.1 to denote a (random?) instance in the input space $\\mathcal{X}$. However, the same is used to limit the norm of x in the same section. For equation (1), should the LHS also not be conditioned on x i.e. V[y|x]. It is not clear why there are two different symbols for the sub-script (small-case) x. Why the equation (6) is defined in terms of a trained classifier w*, while the standard generalization results are stated in terms of all possible classifiers in the hypothesis class. The theorem statement needs to be on a better formal footing as done in the original paper Menon et al. 2021, the current version is incomplete and unclear.\nIn terms of properly citing related work, the paper falls somewhat short. For instance, the paper introduces the need to use calibrated losses without a proper justification to use calibrated losses or a reference thereof. It does not seem to be in the sense of the word used in the last sentence of page 1. Another concern is the lack of setting the right context for the cited papers.  As mentioned above, the high variance problem for tail-labels has also been explored. As another instance, the work of Schultheis et al. 2022 is cited but the correct context is in the related work section when discussing Missing and Tail-labels in Section 2.2, and not only later down in discussing coverage as a metric. Even though the paper has been cited, it is not in the right context. In terms of the main classifier, the focus of the paper is on one-vs-rest approaches, while DiSMEC which initiated this approach in extreme settings isn\u2019t referred.\nQuestions:\nAs mentioned above in the weaknesses section\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors19 Nov 2023, 11:04Everyone", "Content": "Comment:\nWe thank the reviewer for their valuable feedback. Below, we provide clarifications:\nConcerns around novelty: The paper claims that the variance issue for tail labels has not been explored so far. However, this seems not quite true, as a similar concern has been raised in the earlier work by Babbar and Scholkopf 2019\n[1] discusses the issue of variance from the point of view of a lack of commonality between features of training instances and those between training and test instances. However, the definition of variance we use is different, and we highlight it with an example below:\nConsider a dataset where data points are user queries and labels are advertisements shown in response to user queries. \nNow, if we consider a label with the text \u201cinsurance,\u201d there could be a wide variety of user queries (or documents), such as \u201chospital bills\u201d and \u201ccar repair,\u201d that are relevant to this label. This lack of commonality between documents associated with a single label has been discussed in [1].\nIn recommendation tasks, dataset rely on click signals to build the ground truth, i.e., if the user clicks on an advertisement for a particular query, then the query-advertisement pair is considered relevant (1 in ground truth). However, feedback in the form of user clicks is subject to variability as a user\u2019s interests can fluctuate over time; for example, for the query \u201chospital bills,\u201d there may or may not be a click on the \u201cinsurance\u201d ad. Approximating the relevance using click signals that are binary leads to inaccuracies in the dataset, which we quantify using the term label variance.\nIn regards to the novelty of our work, we would like to highlight a few points:\nWe propose the concept of label variance, which, to the best of our knowledge, has not been explored in the domain of extreme classification.\nWhile Menon et al. discuss the teacher-student setup, their teacher is better than the student overall (as indicated by superior Precision values in Table 1). While such a strong teacher might not always be available, we demonstrate the potential of improving the performance of OvA classifiers by proposing a Siamese teacher that excels only  on tail labels. Note that the Siamese teacher is inferior in precision compared to the OvA student model. To the best of our knowledge, we are the first to propose distilling from a teacher that excels only on a subset of the dataset population (tail labels) for XMC tasks.\nWhile the idea is simple, we believe the method's simplicity is a strength as it allows for an easy and effective combination with state-of-the-art one-versus-all methods, as highlighted in our results.\n[1]: \u201cData scarcity, robustness, and extreme multi-label classification\u201d (Babbar and Scholkopf 2019)\nInconsistent notation in Section 3.1, and better presentation of improving presentation of Theorem 1.\nThanks for highlighting this. We will work on addressing the issues in our final draft.\nCiting related works\nJustification for the use of calibrated losses\nIn Section 3.3, we discuss the need to use calibrated losses. In summary, Siamese networks trained using triplet loss have shown to do well on tail labels. However, the scores output by these models are not well calibrated, i.e., they do not have a probabilistic interpretation). For training OvA classifiers with soft targets, we need calibrated scores, and Theorem 2 in our paper shows how we can obtain calibrated scores from the Siamese teacher.  Note that this is in line with the posthoc calibration strategy mentioned in [3], where a model is learned. Then a parametrized Sigmoid function is fit to learn the relevance probabilities, i.e., given an uncalibrated score $s_x$ we get $p_x$ by fitting the sigmoid function $p_x = 1/(1 + e^{-(ms_x +c)})$ where $m, c$ are model hyper-parameters.\nWe will clarify the definition of calibration used in the current context and add a citation to [2].\nMeaning of calibration used at the end of Pg1?\nAt the end of Pg 1. We discuss the strategies that rebalance the loss functions to tackle the problem of extreme class imbalance in XMC datasets. We will clarify this in the final version of the paper.\nCiting work of Schultheis et al. 2022 in the correct context and missing citation of DiSMEC\nIn our revised draft, we have cited the work of Schultheis et al. 2022 in Section 2.2 while discussing \u201cBias due to Missing Lables,\u201d and  DiSMEC has now been cited in the introduction while discussing about OvA classifiers in the revised draft.\nWe hope this rebuttal clarifies the concerns you had about the paper. We would be happy to discuss any further questions about the work. We would really appreciate an increase in the score if the reviewer\u2019s concerns are adequately addressed to facilitate the acceptance of the paper.\n[2]: Scale Calibration of Deep Ranking Models, Le Yan et al, KDD 2022\n[3] Probabilistic Outputs for SVMs and Comparisons to Regularized Likelihood Methods, Platt 2000"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 06:25 (modified: 15 Mar 2024, 00:27)EveryoneRevisions", "Content": "Comment:\nSince the author-reviewer discussion period ends soon, we request the reviewer check our responses. We would appreciate an appropriate increase in the score if the reviewer\u2019s concerns are adequately addressed to facilitate the acceptance of the paper."}, {"Heading": "post author rebuttal", "Subheading": "Official CommentbyReviewer Uo9h23 Nov 2023, 05:19Everyone", "Content": "Comment:\nThanks to the authors for the response. While this does help somewhat in improving my score, there are still some concerns/clarifications required :\nVariance issues : In my opinion, both the earlier work [1] and this one focus on different aspects of the same issue i.e. data scarcity leading to shift in the observed empirical distribution between different sub-samples. In [1] the change in the empirical distribution (between train and test) of the inputs x_i for a given label, and in this case, possible change in the observed label y_i for an instance x_i over time or different annotators. In the second scenario, however, it seems like a missing label problem, even though the authors mention that this does not include any systematic bias, and hence they claim that it is not a missing labels problem, to which I am not sure if I entirely agree. Despite that PSP metrics are used for evaluation, which were designed for missing label problem in the first place, and the usage for measuring the tail-label performance as a metric is rather secondary (as per Schultheis et al 2022). Apparently, we seem to be going in circles, and this requires some clarification/discussion in the paper.\nThe overlap with Menon et al. 2021 remains a concern, and the paper in its current form lacks theoretical soundness in comparison to that paper. On the positive side, it has strong empirical performance and addresses a key problem in XMLC literature."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:47Everyone", "Content": "Comment:\nWe thank the reviewer for appreciating the strong empirical performance of our method.\nWe will revise our draft to (i) clarify the difference between missing labels and label variance and (ii) Polish our presentation of theoretical results."}]}, {"Heading": "Official Review of Submission9297 by Reviewer Cq1J", "Subheading": "Official ReviewbyReviewer Cq1J06 Nov 2023, 10:54 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper introduces a new extreme multi-label classification algorithm called LEVER, that aims to improve the existing methods by proposing training with a loss function that combines loss calculated on observed hard labels and soft labels coming from the teacher model, which is assumed to have superior performance on the tail labels. The teacher model used by the authors in the empirical part of the paper is a Siamese-style neural network that leverages label features and is trained with a logistic-loss-based objective, which was found to yield calibrated estimates of the marginal probabilities of labels. The authors demonstrate the attractiveness of the proposed approach in the exhaustive empirical comparison when they used 4 popular XMLC benchmarks, introduced 2 new benchmarks, and combined the proposed approach with 3 SOTA methods. The proposed approach, in many cases, significantly improves the performance on standard precision@k, propensity-scored precision@k, and coverage@k.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe paper is well-written and easy to follow.\nThe proposed method is simple to apply to a wide range of XML classifiers.\nThe exhausting empirical comparison proved the attractiveness of the proposed method.\nIn addition to the main results, the authors provide a wide array of additional experiments in the appendix.\nTwo new datasets additionally strengthen the contribution of this work.\nWeaknesses:\nThe proposed method is just a combination of loss with hard and soft labels, which is a simple idea.\nI find the theoretical results rather simplistic, expected, and being there to serve as just justification for the applied method rather than its original motivation.\nThis part of the paper especially confirms that for me:\nNotably, if we have precise estimates of marginal relevance, denoted by $p_x = E[y|x]$, we can replace $y$ with $p_x$, effectively reducing the variance term to 0 and thereby improving classifier generalization. This principle forms the foundation for the LEVER framework, which employs an additional teacher network to provide accurate estimates of $p_x$.\nIf we have a model that provides good estimates $p_x$ then we don't need to train another one, the XMLC task is already solved! The strength of the method seems to lay in the properly selected trade-off between loss calculated on hard observed labels and soft labels coming from the teacher network that seems to be much better on tail-labels thanks to leveraging labels-side information.\nFrom the appendix, I understand that $\\lambda = 0.05$ (the variable that weights the hard and soft part of the loss) was used for all the experiments. Since the choice of $\\lambda$ seems to be crucial for the method. I find the lack of further comments on it and experiments demonstrating its impact the biggest weakness of this paper.\nMy score is 6, but I believe the paper is even a bit above that.\nQuestions:\nAs I mentioned in the weakness section, I would like to see how different values of $\\lambda$ impact the final performance and what the trade-off curve between head-labels and tail-labels performance looks like. Could the authors comment on that?\nOn the LF-AOL-270K dataset, LEVER combined with ELIAS yields extremely high improvement on standard precision@k, especially at @5. These seem almost unrealistic when compared with scores of other methods. Are these numbers for sure correct? If yes, do the authors have any explanation for this result?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nN/A\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors19 Nov 2023, 02:16Everyone", "Content": "Comment:\nWe thank the reviewer for their valuable feedback. Below, we provide clarifications.\nThe proposed method is just a combination of loss with hard and soft labels, which is a simple idea.\nYes, while the idea is a combination of hard and soft labels, we would like to highlight that this simplicity allows the easy and effective combination of LEVER with any OvA-based XMC approach. However, unlike standard distillation where logits for all classes from teacher are used, in our case, for each label l, only the \u03c4 nearest points from the pool are selected and added as ground truth for distillation. This is how we have adapted distillation for our multi-label scenario. Table 22 and Figure 7 in supplementary show that increasing \u03c4 improves performance on tail, while it hurts head or torso label\nIf we have a model that provides good estimates then we don't need to train another one; the XMLC task is already solved!\nOur intention for writing \u201cif we have precise estimates of marginal relevance.. Reducing the variance to 0\u201d was to convey that as the teacher gets more accurate, the variance term reduces to zero, and thus the upper bound on the true risk reduces, thereby improving generalization error of the classifier. However, a perfect teacher model is not available in practice. The NGAME model we use is a proxy for the perfect teacher and note that it is more accurate than the OvA classifier only on tail labels. Leveraging the strength of this Siamese model on the tail to reduce the label variance of OvA classifiers on the tail is what LEVER aims to achieve.\nFrom the appendix, I understand that $\\lambda$ (the variable that weights the hard and soft part of the loss) was used for all the experiments..\nWe think the reviewer has confused the $\\lambda$ for ELIAS mentioned in Section D.2 of supplementary with the $\\lambda$ for LEVER. We have renamed the $\\lambda$ used in Section D.2 to $\\lambda_{elias}$. The $\\lambda$ used in LEVER is 0.5 (equal weight to both hard & soft labels).\nI would like to see how different values of $\\lambda$ impact the final performance and what the trade-off curve between head-labels and tail-labels performance looks like\nIn table below, we show the effect of varying $\\lambda$ when LEVER is combined with Renee on 3 datasets: LF-AmazonTitles-131K, LF-Wikipedia-500K, & LF-AOL-270K. Note that $\\lambda$=0.33 weighs the soft labels with double the weight as compared to hard labels. \nOur observations are:\nThe equal weightage (0.5) gives the best performance.\nIncreasing $\\lambda$ weighs the hard labels more and this results in performance that gets closer to the base classifier, i.e., PSP worsens, and Precision remains flat or drops slightly.\nAdditionally, decreasing $\\lambda$ helps only up to a certain point, i.e., $\\lambda$=0.5; this is because our teacher is not perfect we need to strike a balance between hard and soft labels.\nLF-AmazonTitles-131K\n$\\lambda$\nP@1\nP@3\nP@5\nPSP@1\nPSP@3\nPSP@5\nC@1\nC@3\nC@5\n0.33\n46.15\n30.76\n21.87\n39.70\n45.33\n50.13\n32.56\n54.48\n61.24\n0.50\n46.44\n30.83\n21.92\n39.70\n45.44\n50.31\n32.82\n55.11\n61.94\n0.66\n46.57\n30.87\n21.93\n39.59\n45.46\n50.36\n32.31\n54.49\n61.48\n0.80\n46.58\n30.88\n21.92\n39.37\n45.39\n50.33\n32.06\n54.38\n61.42\nLF-Wikipedia-500K\n$\\lambda$\nP@1\nP@3\nP@5\nPSP@1\nPSP@3\nPSP@5\nC@1\nC@3\nC@5\n0.33\n84.66\n65.94\n51.54\n40.51\n53.40\n58.75\n26.88\n56.01\n67.94\n0.50\n85.02\n66.42\n52.05\n42.50\n54.86\n60.20\n29.46\n58.53\n70.29\n0.66\n84.96\n66.51\n52.18\n39.34\n53.53\n59.46\n25.66\n55.78\n68.33\n0.80\n84.84\n66.42\n52.14\n38.66\n53.09\n59.16\n24.96\n55.08\n67.79\nAOL-270K\n$\\lambda$\nP@1\nP@3\nP@5\nPSP@1\nPSP@3\nPSP@5\nC@1\nC@3\nC@5\n0.33\n41.14\n24.00\n16.50\n17.24\n32.31\n40.02\n14.14\n36.67\n45.84\n0.50\n41.70\n24.78\n17.07\n20.38\n37.07\n45.13\n17.43\n42.54\n52.01\n0.66\n41.44\n24.41\n16.76\n16.76\n32.69\n40.47\n14.16\n37.38\n46.54\n0.80\n41.17\n24.04\n16.49\n15.59\n30.30\n37.64\n13.16\n34.62\n43.25\nThis table has been added as Table 16 in the supplementary material. For decile-wise plots showing head-tail variation, please refer to Fig. 4, 5, 6 in the supplementary material\nOn the LF-AOL-270K dataset, LEVER combined with ELIAS yields extremely high improvement on standard precision@k..\nThanks for pointing this out. This is a typo; the number from the LF-AmazonTitles-1.3M ELIAS+LEVER row was mistakenly copied to the ELIAS+LEVER row in LF-AOL-270K. The supplement however has the correct values for LF-AOL-270K without this typo. We fixed this in the main table of updated draft.\nHere are the values for your reference\nLF-AOL-270K\nP@1\nP@3\nP@5\nPSP@1\nPSP@3\nPSP@5\nELIAS\n40.83\n22.33\n14.91\n13.29\n21.46\n25.22\nELIAS + LEVER\n40.85\n22.83\n15.57\n13.68\n24.30\n30.43\nWe hope this rebuttal clarifies your concerns. We would be happy to discuss any further questions, and would appreciate an appropriate increase in the score if the reviewer\u2019s concerns are addressed to facilitate the acceptance of the paper."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 06:27 (modified: 15 Mar 2024, 00:27)EveryoneRevisions", "Content": "Comment:\nSince the author-reviewer discussion period ends soon, we request the reviewer check our responses. We would appreciate an appropriate increase in the score if the reviewer\u2019s concerns are adequately addressed to facilitate the acceptance of the paper."}, {"Heading": "Re: Official Comment by Authors", "Subheading": "Official CommentbyReviewer Cq1J22 Nov 2023, 22:15 (modified: 15 Mar 2024, 00:27)EveryoneRevisions", "Content": "Comment:\nI thank the authors for additional clarifications. I also checked the other reviews and responses. I'm generally satisfied with the additional experiments conducted by the authors. The experimental setup and a large number of experiments are big strengths of the paper and the authors' rebuttal only improves in this area. However, the discussion does not change my opinion on the limited novelty of this work and the weak and unoriginal theoretical justification for the idea. If that it would be possible, at this point, I would give this paper a 7, but right now, I'm keeping my score as it is.\nAdditional comments:\nThe $\\tau$ parameters seem to have a significant impact on model performance. I believe it should be already discussed and motivated in Section 3 of the paper.\nNIT:\nI found a broken reference in the appendix in the added section about the impact of $\\lambda$:\nEffect of varying \u03bb: The hyperparameter \u03bb controls the importance between the two loss terms. Table 16 shows the effect of varying \u03bb, and Figures ?? show their corresponding decile-wise plots"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 03:35 (modified: 15 Mar 2024, 00:27)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewer for their valuable feedback! About novelty, we would like to highlight our contribution in terms of putting forward the concept of label variance. To the best of our knowledge, this concept has not been explored in prior XML literature. We would also like to clarify that Menon et al. work [1] develops a relation between variance in loss and the model's generalization performance (Proposition 2). Our work builds upon this to create a link between label variance and generalization performance (Theorem 1). As pointed out by reviewer Uo9h, we will work on polishing our presentation of the theoretical results in our updated draft.\nWe will also discuss the effect of $\\tau$, currently discussed in Section 5, Pg 9 in Section 3, and address the broken reference issue you have highlighted in our updated draft\n[1]: A Statistical Perspective on Distillation. Menon et al. 2021"}]}, {"Heading": "Official Review of Submission9297 by Reviewer Kx6v", "Subheading": "Official ReviewbyReviewer Kx6v31 Oct 2023, 18:12 (modified: 22 Nov 2023, 02:33)EveryoneRevisions", "Content": "Summary:\nThis paper aims to improve the tail labels performance of the extreme multi-label classification (XMC) problems. The paper propose LEVER, a knowledge distillation framework, that learns student OVA classifiers with binary relevance true labels and soft-labels generated by teacher bi-encoders. The author claims that bi-encoders have better performance on tail labels, and hence using their soft labels as additional signals to learn the student OVA classifiers can help reduce the variance for tail labels. Empirically, LEVER demonstrated consistent improvement upon competitive OVA classifiers on a wide-range of XMC datasets.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe paper writing is easy to follow\nEmpirical results are strong\nWeaknesses:\nIts questionable that using \"pairwise\" logistic loss (Eq.10) lead to calibrated scores\nSome experiment settings are not clear from the main text. See detailed questions below.\nMissing proper evaluation metrics (i.e., Macro-average Precision/Recall/F1) for tail-labels performance\nQuestions:\n1. Calibrated Scores\nIts well known that pairwise ranking losses (e.g., Equation (10) of this submission) is shift-invariant hence may not produce calibrated scores, as pointed out by [1]. Why not considering point-wise loss functions or hybrid objectives [1] (listwise Softmax + pointwise BCE) to produce more calibrated scores?\n2. Experiment Settings and Results\n(1) What's the model size for each method in Table 1 and Table 2? The model size should include every component needed to do inference. For example, does ELIAS and ELIAS+LEVER have the same model size, as LEVER is just in-place modifying the OVA classifiers of LEVER? If not, I am concern about the performance gain of LEVER is due to additional model capacity.\n(2) In Table 1, ELIAS+LEVER achieved >20% absolute gain on LF-AOL-270K in P@3 and P@5. If not a typo, any insight why such significant gain? Similar questions to ELIAS+LEVER on LF-Wiki-1M, PSP metrics.\n(3) On page 9, the author claims the training time of LEVER only increased by at most 2x. Does that include (a) training time of teacher bi-encoders (b) prediction time of teacher bi-encoder to generate soft-labels (c) training time of student OVA classifiers which are trained by not only sparse ground truth labels but also dense soft-labels? If so, what's the detailed breakdown in terms of those three components?\n(4) Suppose the ground truth label matrix is a sparse $N \\times L$ matrix. How dense are the soft-labels generated by LEVER? Does the performance of LEVER vary when using different top-$k$ soft-labels per input?\n3. Macro-averaged Evaluation Metrics\nTo properly measure the performance of long-tailed labels, text classification community often consider Macro-average Precision/Recall/F1 metrics [2,3,4]. The author should also report Macro-averaged metrics to further validate the major claim of LEVER, which is the the performance gain on tailed-labels.\nReference\n[1] Yan et al. Scale Calibration of Deep Ranking Models. KDD 2022.\n[2] Zhang et al. Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions. EACL 2023.\n[3] Yang et al. A re-examination of text categorization methods. SIGR 1999.\n[4] Lewis et al. RCV1: A New Benchmark Collection for Text Categorization Research. JMLR 2004.\nFlag For Ethics Review:\nYes, Unprofessional behaviors (e.g., unprofessional exchange between authors and reviewers)\nRating:\n8: accept, good paper\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Part-1 of Response", "Subheading": "Official CommentbyAuthors19 Nov 2023, 02:39Everyone", "Content": "Comment:\nWe thank the reviewer for their valuable feedback. We request the reviewer to clarify the ethical concerns with our submission as we see our paper has been flagged for ethics review.\nBelow we clarify some of the concerns.\nCalibration concerns\nThank you for bringing this paper [1] to our notice. Since our loss is shift-invariant, the scores produced by the model are not calibrated, as pointed out in [1]. If $s_x =z_l^{T}z_x$  is the score output by the Siamese model for a label $l$ (with embedding $z_l$) and document $x$ with embedding $z_x$ this would mean that $s_x$ is not calibrated, we agree. However as indicated in theorem 2, we make use of probabilities $p_x = 1/(1 + e^{-(ms_x + c)})$ where $m,c$ are hyper-parameters for training OvA classifiers. Note that this  is in line with the post-hoc calibration strategies explored in [2], where a model is learned and then a parametrized Sigmoid function is fit to learn the relevance probabilities, i.e., given an uncalibrated score $s_x$ we learn $p_x$ by fitting the sigmoid function $p_x = 1/(1 + e^{-(ms_x +c)})$ where $m, c$ are model hyper-parameters.\nWhy not use BCE Loss or methods proposed in [1] to achieve calibration?\nWe acknowledge that exploring the techniques in [1] could certainly be an interesting direction for future investigation to understand the effect of teacher models trained with different loss functions on student model performance, and we will add this as a future direction in our updated draft.\nAdditionally, from our experience using BCELoss while training Bi-encoders leads to training instability. Hence we resorted to using pair-wise losses and posthoc calibration techniques\n[1]: Scale Calibration of Deep Ranking Models, Le Yan et al, KDD 2022\n[2]: Probabilistic Outputs for SVMs and Comparisons to Regularized Likelihood Methods, Platt 2000\nExperimental settings and results\nModel Size\nPlease note that the inference pipeline is unchanged with the addition of LEVER (both in terms of model capacity and inference time). LEVER only affects the training strategy by the addition of soft labels. So, the model size is the same for the base classifier and its LEVER counterpart.\nThe below table shows the model size (in Millions of parameters) for the different models and datasets. Note the smaller model size in ELIAS for LF-AmazonTitles-1.3M is due to using 512 dimension classifiers, (as 768D led to OOM issues).\nRenee\nELIAS\nCascadeXML\nLFAT-13K\n167.03M\n168.73M\n268.94M\nLFA-131K\n167.03M\n168.73M\n268.94M\nLF-AOL-270K\n275.26M\n277.14M\n377.95M\nLF-WikiSeeAlso-320K\n312.12M\n315.59M\n408.33M\nLF-Wikipedia-500K\n451.90M\n457.93M\n553.47M\nLF-WikiHierarchy-970K\n815.93M\n829.51M\n918.86M\nLF-AmazonTItles-1.3M\n1064.76M\n746.25M\n1171.11M\nSignificant gain in  P@3/5 AOL in ELIAS\nWe apologize for the typo here, we accidentally entered values for ELIAS + LEVER on LFAT-1.3M here. The correct values were present in the appendix (Table 7), and now they have been added to the main paper in Table 1. as well. Here are the values for your reference\nLF-AOL-270K\nP@1\nP@3\nP@5\nPSP@1\nPSP@3\nPSP@5\nELIAS\n40.83\n22.33\n14.91\n13.29\n21.46\n25.22\nELIAS + LEVER\n40.85\n22.83\n15.57\n13.68\n24.30\n30.43\nSignificant gain in PSP metrics in WikiHierarchy in ELIAS\nIn ELIAS there is a bigger drop in head performance as compared to Renee when LEVER is applied.  This therefore translates to a much larger increase in ELIAS+LEVER\u2019s tail performance for this dataset, note that for ELIAS the performance improvement starts from the torso labels itself. This is illustrated in Figure 8 in the supplementary which compares decile wise plot ELIAS, ELIAS + LEVER and Renee, Renne+LEVER."}, {"Heading": "Part-2 of Response", "Subheading": "Official CommentbyAuthors19 Nov 2023, 03:14Everyone", "Content": "Comment:\nTraining time\nOn page 9, the author claims the training time of LEVER only increased by at most 2x. Does that include (a) the training time of teacher bi-encoders (b) the prediction time of teacher bi-encoders to generate soft labels (c) the training time of student OVA classifiers which are trained by not only sparse ground truth labels but also dense soft labels? If so, what's the detailed breakdown in terms of those three components?\nThe train times reported in the paper only included component (c), i.e., the training time of the student OvA classifiers. Following are the observations\nIncluding all the components (a), (b), & (c) results in an average increase of 3.1x in training time and a maximum increase of 8.9x. Note that this level of increase happens only in two cases: while training CascadeXML on LF-Amazon-131K & LF-WikiSeeAlso-320K.\nIn the case of the state-of-the-art method Ren'ee, the increase in training time is at max 1.27x times the original model training time as Ren\\\u2019ee depends on the Siamese teacher for initialization.\nCascadeXML & ELIAS do not depend on the Siamese Teacher for initialization. The below table shows the total training (a) + (b) + (c) [This table has been added to main paper - Table-3). For a breakdown of these values, please refer to Table 24,25,26 in appendix.\nDataset\nRen\u00e9e\nRen\u00e9e+LEVER\nELIAS\nELIAS+LEVER\nCascade\nCascade+LEVER\nLF-AmazonTitles-131K\n17.59\n20.11\n4.33\n18.82\n3.63\n17.14\nLF-Amazon-131K\n42.77\n46.51\n19.44\n65.62\n4.60\n41.31\nLF-AOL-270K\n136.22\n138.20\n60.67\n171.20\n42.12\n152.00\nLF-WikiSeeAlso-320K\n86.42\n95.19\n25.33\n111.46\n12.40\n88.52\nLF-Wikipedia-500K\n154.93\n184.05\n138.67\n226.72\n29.58\n89.72\nLF-WikiHierarchy-1M\n31.44\n40.15\n24.00\n61.17\n9.85\n35.91\nLF-AmazonTitles-1.3M\n154.39\n186.45\n40.00\n158.23\n70.00\n202.93\nAverageTimeInc.\n1.14x\n3.29x\n4.86x\nEffect of density on performance\nHow dense are the soft labels generated by LEVER? Does the performance of LEVER vary when using different top-k soft-labels per input?\nAs we increase $k$, LEVER adds more samples (documents or labels). Adding more samples results in an improved tail performance, but impacts precision due to losses on head deciles. The table below (added as Table 22 in suppl.) shows the density in terms of points per label (PPL) and $k$. Figure 7 in the suppl. Shows the decile-wise plots for these configs. Kindly note that $k$ is referred to as $\\tau$ in the tables and figures.\n$k$\nPPL\nP@1\nP@3\nP@5\nPSP@1\nPSP@3\nPSP@5\nC@1\nC@3\nC@5\nLF-Wikipedia-500K\n1\n18.1\n84.96\n66.26\n51.68\n37.10\n50.27\n55.68\n22.90\n50.08\n61.59\n20\n39.5\n85.14\n66.90\n52.35\n38.39\n52.33\n58.04\n24.72\n53.45\n65.43\n45\n64.5\n85.02\n66.43\n52.05\n42.51\n54.86\n60.20\n29.08\n58.28\n70.09\nLF-WikiHierarchy-1M\n1\n43.3\n95.01\n93.99\n92.24\n19.69\n27.36\n33.20\n6.62\n11.39\n14.56\n4\n44.8\n95.19\n93.90\n92.07\n24.79\n32.74\n38.29\n9.08\n16.12\n20.02\n8\n47.7\n94.97\n93.18\n90.98\n26.37\n34.99\n40.51\n10.08\n18.34\n22.74\nMacro Metrics\nAs recommended in [3] we report MacroF1, MarcoPrecision, & MacroRecall at $k$ where $k$ values for datasets were chosen based on average labels per point for the dataset. We use $k$=3 for LF-AmazonTitles-131K, LF-Amazon-131K, LF-WikiSeeAlso-320K, LF-AOL-270K, $k$=5 for LF-Wikipedia-500K, $k$=25 for LF-AmazonTitles-1.3M and LF-WikiHierarchy-1M. We see an average gain of $4.3%$ in MacroF1, $4.1%$ in MacroPrecision, & $5.6%$ in MacroRecall. The below table summarizes the results [Added as Table 8 in suppl.]\nModel\nLF-AmazonTitles-131K\nLF-Amazon-131K\nLF-Wikipedia-500K\nF1@k\nP@k\nR@k\nF1@k\nP@k\nR@k\nF1@k\nP@k\nR@k\nELIAS\n24.23\n22.82\n31.70\n28.48\n26.46\n37.93\n27.98\n27.97\n35.17\nELIAS+LEVER\n29.53\n27.70\n38.21\n33.36\n31.16\n43.35\n34.12\n33.88\n44.68\nCascadeXML\n22.23\n20.80\n30.36\n28.89\n26.74\n38.83\n20.04\n20.13\n26.75\nCascadeXML+LEVER\n29.12\n26.91\n39.04\n33.29\n30.76\n44.13\n31.40\n31.61\n41.70\nRenee\n32.19\n30.36\n41.55\n32.55\n29.95\n43.88\n35.94\n36.78\n43.76\nRenee+LEVER\n33.35\n31.78\n42.45\n35.69\n34.05\n45.04\n40.54\n40.71\n51.36\nLF-AmazonTitles-1.3M\nLF-AOL-270K\nLF-WikiHierarchy-1M\nF1@k\nP@k\nR@k\nF1@k\nP@k\nR@k\nF1@k\nP@k\nR@k\nELIAS\n16.43\n15.73\n24.68\n10.69\n9.45\n16.18\n20.71\n23.26\n22.43\nELIAS+LEVER\n18.85\n17.92\n28.58\n13.97\n12.87\n19.41\n26.99\n28.75\n30.53\nCascadeXML\n13.58\n13.23\n22.06\n9.00\n8.25\n13.46\n17.73\n20.91\n19.22\nCascadeXML+LEVER\n16.02\n15.07\n27.02\n11.59\n11.03\n15.74\n21.17\n24.36\n21.85\nRenee\n24.79\n24.16\n35.42\n17.7\n16.88\n22.53\n24.48\n27.59\n26.04\nRenee+LEVER\n26.72\n25.73\n37.04\n22.38\n20.4\n30.18\n27.89\n30.67\n30.23\n[3]:Zhang et al. Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions. EACL 2023.\nWe hope this rebuttal clarifies the concerns you had. We would be happy to discuss any further questions about the work, and would appreciate an appropriate increase in the score if the reviewer\u2019s concerns are addressed to facilitate the acceptance of the paper."}, {"Heading": "Official Comment by Reviewer Kx6v", "Subheading": "Official CommentbyReviewer Kx6v22 Nov 2023, 02:33Everyone", "Content": "Comment:\nI am satisfied with the authors response and appreciate the additional experiment results. I am happy to increase the rating."}, {"Heading": "Thank you!", "Subheading": "Official CommentbyAuthors22 Nov 2023, 02:43Everyone", "Content": "Comment:\nWe're happy to know that our response helped in addressing your concerns. Thanks again for the helpful feedback and for upgrading the score!"}]}, {"Heading": "Official Review of Submission9297 by Reviewer UBHy", "Subheading": "Official ReviewbyReviewer UBHy18 Oct 2023, 05:12 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper investigates a novel factor, label variance, in the context of tail performance in extreme classifiers. To address this issue, the authors propose LEVER, a knowledge distillation framework that leverages a robust teacher model to reduce label variance. Experimental results demonstrate that LEVER significantly improves tail performance, achieving approximately 5% and 6% increases in PSP and Coverage metrics, respectively, when integrated with state-of-the-art extreme classifiers.\nSoundness:\n3 good\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThe paper give a proof of the correlation between the generalization performance of a classifier and the variance in labels.\nUse a Siamese- style model as a teacher to help reduce the label variance effects.\nThe extensive experiment results are promising.\nThe paper contribute two new datasets to the field.\nWeaknesses:\nThe readability of the paper is not strong, and the formatting is uncomfortable. For example, the abstract should generally be a single paragraph, there are too many blank spaces before and after Section 2 Related Work, and the spacing of equations is large. With ample space in the appendix, the full text does not fill up the nine pages. Improvements are needed in basic writing formatting and readability.\nThe paper has limited novelty. From a personal perspective, the innovation lies in using a teacher model to predict probabilities. The rest of the paper mainly demonstrates the significant impact of tail classes. From the perspective of innovative design, it is not convincing. It is also unclear why the teacher model can provide accurate estimates of $p_x$.\nThere is limited description regarding fair comparisons. After introducing the teacher model, the training process and time will be affected. The main part should devote more space to introducing the teacher model, analyzing its performance, and comparing the training time with other models.\nQuestions:\nCan the teacher model be adapted to the current task? How does its performance compare? What are the differences between directly using a better model for distillation and utilizing the results of other models as auxiliary information in this paper?\nRefer to the weaknesses mentioned.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors19 Nov 2023, 02:23Everyone", "Content": "Comment:\nWe thank the reviewer for their valuable feedback.\nCan the teacher model be adapted to the current task?  How does its performance compare?\nThe teacher model is adapted to the current task, the Siamese model is trained on the same dataset on which the classifier-based methods were trained. The teacher model (Siamese network) is much better than the student model (classifier) on the tail (indicated by superior PSP Coverage), while it lags behind significantly in Precision. Using the superior performance of the teacher on the tail, LEVER improves the OvA classifier\u2019s tail performance. We have updated the draft to include a comparison between teacher and student in Table 4 in the main paper.\nWhat are the differences between directly using a better model for distillation and utilizing the results of other models as auxiliary information in this paper?\nWe request the reviewer to clarify the question. From what we understand, the reviewer is asking the effect of using a better model for distillation.\nIf so, it is the case that a better teacher model results in better performance of classifiers when combined with LEVER. Table 13 in the supplementary shows the effect of using different teachers. We experiment with 3 teachers: Astec, MiniLM 3-layer, and 6-layer DistilBERT.However, it is important to note that even our best teacher, NGAME 6-layer DistilBert, performs much inferior to classifier-based methods on precision.\nReadability of paper not strong and uncomfortable formatting. Full text not filling 9 pages. More discussion around train time and teacher model performance.\nWe apologize for the concerns around formatting. We have made the following changes:\n(i): Abstract has been made concise, \n(ii): Empty space around Section 2 related work and  equations has been cut down,\n(iii): We have devoted the additional space obtained to discuss the train time overhead of using LEVER (Table 3) and Comparison with the teacher model (Table 4)\nLimited novelty: the innovation lies in using a teacher model to predict probabilities. From a personal perspective, the innovation lies in using a teacher model to predict probabilities From the perspective of innovative design, it is not convincing.\nWhile the approach might be simple, we believe the concept of label variance we propose is novel. Additionally, we would like to highlight the difference between our setup and conventional distillation, which usually relies on a teacher model that is uniformly better than the student. In our work, we show that a teacher model that excels on a subpopulation (tail-labels) can also be leveraged to improve the performance of OvA classifiers for XMC tasks. Further, the simplicity of the approach should rather be viewed as a strength as it allows for easy and effective combinations with multiple SOTA classifier-based methods.\nWhy does the Siamese model provide accurate estimates of $p_x$?\nRecent studies have shown that Siamese Networks, when used as input encoders, exhibit impressive performance on tail labels (Dahiya et al., 2021a; 2022; Jain et al., 2023). This success can be attributed to the ability of Siamese encoders to learn correlations by utilizing label-side features. Further, we consume only high confidence estimates of $p_x$ from Siamese teacher models: \u201cFor each label l, the \u03c4 nearest points from the pool are selected and added as ground truth.\u201d\nWe hope this rebuttal clarifies the concerns you had about the paper. We would be happy to discuss any further questions about the work, and would really appreciate an appropriate increase in the score if the reviewer\u2019s concerns are adequately addressed to facilitate the acceptance of the paper."}, {"Heading": "Official Comment by Reviewer UBHy", "Subheading": "Official CommentbyReviewer UBHy20 Nov 2023, 07:05Everyone", "Content": "Comment:\nThank you for your response, but I still choose to keep my score."}]}]}, "OpWg0ldkcB": {"paper_info": {"Primary Area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "neural encoding, receptive fields, multi-unit activity, visual cortex", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "We introduce affine feature response transforms (AFRT, \\\u2019e-fert ), - a new family of neural encoding models based on spatial transformer networks (STNs). AFRT factorises receptive fields into a sequential affine component with 3 interpretable parameters (\u0398 for shifting and scaling) and response components with a small number of feature weights per response, which drastically simplifies the state-of-the-art neural encoding models and significantly improves performance of the encoding model. Additionally, our investigation delves into the sizes of the AFRT-generated receptive fields at various depth levels within the neural network. Our findings reveal a correspondence between these sizes and the information complexity present in corresponding brain regions, offering valuable insights into the behavior of the model, which demonstrate the benefits of incorporating spatial specificity into neural encoding models and potentially offers a new avenue for retinotopic mapping.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9295", "PDF Url": "https://openreview.net/pdf?id=OpWg0ldkcB"}, "review_info": []}, "LegZeFYugN": {"paper_info": {"Primary Area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Time series classification; Time series image representation; Adaptive time series gaussian mapping; Vision Transformer", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Time Series Classification (TSC) is a crucial and challenging task that holds significant importance across various domains, of which one of the kernel ingredients is to construct a suitable time series representation for better feature capture. However, extracting informative and robust time series representation with good generalization potential is still a challenging problem. To address this issue, we propose Time2Image, a novel image-based representation framework for TSC. At the heart of our framework is a proposed Adaptive Time Series Gaussian Mapping (ATSGM) module for robust time series encoding in 2D image structure, based on which we employ Vision Transformer (ViT) for subsequent classification tasks considering its prominent long-dependency modeling capability. Experiments were conducted on all 158 public time series datasets from UCR/UEA covering diverse domains, among which our method achieves top 1 performance in 86 datasets compared with existing State-Of-The-Art (SOTA) methods. In addition, our framework flexibly allows handling both univariate and multivariate time series with unequal length across different domains and takes inherent advantage of generalization ability due to our proposed ATSGM representation method. The source code will be publicly available soon.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9293", "PDF Url": "https://openreview.net/pdf?id=LegZeFYugN"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9293 by Area Chair Xs9S", "Subheading": "Meta ReviewbyArea Chair Xs9S09 Dec 2023, 20:16 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper presents an image-based representation learning framework called Time2Image for time series classification. In particular, the proposed Adaptive Time Series Gaussian Mapping (ATSGM) module works well for the time-series to image conversion. Overall, I would think this paper has certain merits but it falls below the ICLR standard. I agree on the concerns raised by the reviewers, particularly the concerns on literature review and experimental evaluation. For example, there are several language-based (OneFitsAll) and other image-based (TimesNet and PIP) frameworks for time series analysis, while TimesNet outperforms Time2Image as reported in the rebuttal. The effectiveness of the proposed method currently lacks sufficient support. Therefore, my recommendation is to reject this paper.\nJustification For Why Not Higher Score:\nThe effectiveness of the proposed method currently lacks sufficient support, due to inadequate literature review and unconvincing evaluation. Therefore, we are not able to accept this paper.\nJustification For Why Not Lower Score:\nN/A."}, {"Heading": "General Response", "Subheading": "Official CommentbyAuthors22 Nov 2023, 23:36Everyone", "Content": "Comment:\nWe would like to express our sincere gratitude to all reviewers for dedicating their valuable time to reviewing our manuscript and providing constructive feedback. We are delighted to see the positive recognition from several reviewers, with three of them acknowledging the novelty of our method. Moreover, we extend our thanks to Reviewer mdnq for noting that our method \"provides a reasonable way to represent time series.\" We also appreciate the commendation from Reviewer HAQG, who found our method \"well motivated as a powerful method for computer vision utilization\" and recognized its contribution to \"advancing the general family of methods\". We take every suggestion and comment each reviewer brings up seriously and try to answer it as comprehensively and clearly as possible, followed by some additional experiments if needed. Please find the answers to each comment.\nWe also noticed that more than one reviewer showed great interest in our motivation and intuition for the work. In this response, we would like to address this by providing detailed explanations of the motivation, advantages, and contributions of our work to ensure a better understanding and positioning within the field. Please find them in the following:\nWe are working on time series classification through image representation, which is a small but challenging field. There are 2\nresearch gaps\nin this field: (1) Before this work, there was no research on multivariate time series (MTS) image representations since it was a challenging task. (2) Even though there are some image representation approaches for univariate time series, there are significant performance gaps to make a comparison of current state-of-the-art (SOTA) models in classification tasks. Therefore, our\ngoal\nis to propose a novel time series image representation framework that not only has better comprehensive performance compared with existing deep learning SOTA algorithms but also has the inherent generalization ability to both UTS and MTS with inconsistent length.Inspired by\nthe 2D keypoint detection\ntask in computer vision, we noticed that Gaussian distributions are often used to model uncertainty or confidence in locations. In addition, a Gaussian distribution is a smooth distribution; that is to say, since time series data usually have noise and fluctuations, we think modeling it through a Gaussian distribution can smooth the data to a certain extent and make the model more robust. Therefore, introducing this idea into the representation of time series data by modeling the uncertainty of each channel time point and forming a sub-patch through the Adaptive Time Series Gaussian Mapping (ATSGM) we proposed can help the model better understand the importance of each time point in the time series data. At the same time, the relationship and local information between different channels in MTS data can also be obtained in order to improve the model's robustness and generalization ability. Therefore, in our framework, we hope the time series image representation can better capture local temporal and channel information, while the transformer structure ViT adopts can effectively capture long-term information. This is our original idea for \u200b\u200bdesigning this method.\nThis work is the\nfirst work\nto propose a time series image representation suitable for both UTS and MTS with unequal length, and the ViT-B/16 we adopted is also the\nfirst attempt\non time series classification. In addition to that, experiments were conducted on all 158 public time series datasets from UCR/UEA covering all UTS and MTS, and shows superiority of the algorithm by comparing deep learning SOTA algorithms. We hope the above description will give you more information about the motivation and intuition of this framework.\nIn addition, we have addressed questions and comments in our responses to each reviewer and revised our paper. Key updates in the revised paper included: (1) Additional experiment results were added to better position our work, which can be seen in the Appendix. (2) Additional information is added to Figures 1 and 2 for a better understanding of the framework. (3) A detailed analysis of the performance based on datasets of different lengths, domains, etc to find the bounds of the work.\nThank you again for your time and engagement. If you have any more questions, we are happy to continue the discussion even after the discussion process. We are also willing to address the problems with the public if possible."}, {"Heading": "Official Review of Submission9293 by Reviewer mdnq", "Subheading": "Official ReviewbyReviewer mdnq01 Nov 2023, 01:19 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work presents a method for time series feature representation that enables the use of transformers on multivariate time series classification problems in a new, performant way. This representation, Adaptive Time Series Gaussian Mapping frames the representation as a packing problem for Gaussian distributions, where all channels in a multivariate time series are represented by an individual Gaussian distribution projected onto a 16x16 patch. A single patch represents each time step in the sequence and a matrix of all the patches represents the entire sequence. Classification is then completed on the final representation with evaluation on standard benchmarks showing improvement over current methods on univariate classification and matching performance on multivariate classification.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThanks to the authors for their submission: it contains useful research that shows good research practices while explaining an interesting and novel idea within multivariate time series classification. The results of this work will be informative to other researchers and are significant in improving our understanding of applying deep learning methods within time series work - a field where such applications have proved difficult.\nThis paper adds to a small but growing literature around the use of Transformer-based models on multivariate time series classification. While previous large-scale benchmarks have shown that the best deep neural network-based methods use convolutional methods (ResNet, InceptionTime), this approach shows how to combine time series with Vision Transformers, which have shown improvements over ResNet in computer vision. The ATSGM framework which packs each time stamp into a patch representation that can then be fed into ViT, provides a reasonable way to represent the time series.\nEvaluation of the method against other leading approaches is thorough, using the standard UCI univariate and multivariate benchmarks. Conducting full benchmarking across all the tasks is an accomplishment which few papers in time series choose to complete and the authors should be lauded for this! The evidence provided shows that ATSGM+ViT outperforms existing methods in the univariate setting and has matching performance with the best methods in the multivariate setting.\nFinally the construction of this paper was strong. The writing was well put-together with helpful diagrams elucidating the more difficult parts of the provided methods. It was easy to read and to the point.\nWeaknesses:\nThere are two key weakness that I see in this paper:\nOne is the lack of comparison with other encoding and representation methods combined with transformers. There is previous work [1, 2] that uses normalized and learnable linearly projected representations of the multivariate time series with learnable positional encodings. Additional ablation studies that separate out the normalization and projection methods and compare against additional encoding types could help shine a light on the specific benefits of the ATSGM framework. One concern I have is that the improvement may be primarily due to ViT using positional embeddings and a linear projection of the flattened patches rather than due to the Gaussian projection itself and the Gaussian method may be adding more unnecessary complexity.\nSecond is the lack of motivation for the main method. While it is a novel method which performs well in the standardized benchmarks, it is not clear what the bounds or weaknesses of method might be. I have suggested a number in the questions below. In short: how does the Gaussian representation restrict the information available as time series scale up in size? How might the method be flexible enough to accommodate different data needs?\n[1] \u201cTST\u201d\nhttps://arxiv.org/pdf/2010.02803.pdf\n[2] \u201cCropTransformer\u201d\nhttps://arxiv.org/pdf/1905.11893.pdf\nAdditional Nits:\nPage 5: the link to the best packings of equal circles in a square returns 404. The correct link should include a \u2018#\u2019 before \u2018Results\u2019.\nAlgorithm 1 does not define L anywhere in the paper though I believe it is simply equal to 196.\nTable 1: Incorrect based on the results of Table 6. In Table 6 ResNet shows 4 wins instead of 3, Time2Image shows 11 wins instead of 13, and Time2Image+ResNet shows 2 wins which should not be conflated with Time2Image+ViT in this table.\nFigure 4 should include InceptionTime\nQuestions:\nThese questions will help clarify my understanding of the paper. Some of these could benefit from additional analysis in the paper itself:\n1/ What are the author\u2019s intuitions for why Time2Image underperforms the regular ResNet? Is there something about the Gaussian representation that is particularly suited to Transformers over Convulational approaches?\n2/ The results of InceptionTime seem to worse in this evaluation compared with the results of the Time Series Benchmark and Redux. Is this because T2I is better at the same categories as inception time? While the paper explains the generalization ability of T2I across domains it does not shine any light on where (if any) the gains may come from.\n3/ Are the authors concerned that the method  for selecting the standard deviation parameter could allow overfitting on the benchmark datasets? Were there any held-out datasets for parameter selection that could be used for evaluation?\n4/ Given the restrictions of the algorithm, in that finding a packing for the gaussian distributions in the patches will reduce the resolution of the final sample as the number of channels increases, would it make sense to evaluate the performance of the model as the number of channels increases? From quick observation on the datasets with high number of channels (Crop-7200, phalangesOutlinesCorrect-1800, Ford*-3600, ElectricDevices-8926, NonInvasive*-1800, DuckDuckGeese-1345) it seems that in this collection the T2I win-rate is lower (~50%). A similar analysis would be on sequence length. EigenWorms contains the longest sequences by an order of magnitude in the MTS set and Time2Image performance is much worse than ResNet or InceptionTime. Helping understand these performance bounds would be very useful for practical applications and understanding the generalization from the test benchmark to other evaluations. This could also help inform how the additional parameters for series normalization and patch size can be set.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Response to Reviewer mdnq on weakness 1/2", "Subheading": "Official CommentbyAuthors23 Nov 2023, 00:13 (modified: 23 Nov 2023, 04:36)EveryoneRevisions", "Content": "Comment:\nThank you your thoughtful and constructive feedback on our manuscript. We appreciate the time and effort you have dedicated to reviewing our work. Below, we address your concerns and provide additional insights into our methodology.\nW1: lack of comparison with other encoding and representation methods, i.e. w/o normalization, and position embeddings.\nAnswer\n: \nThank you for your detailed review and valuable suggestions. In order to fully respond to your above requests, we have conducted some experiments.\nFirst\n, we conducted a normalized ablation experiment on 10 selected MTS datasets and 10 selected UTS datasets according to different length, class and domains during preprocessing for our proposed method to study the impact of normalization on the classification performance. The\naccuracy\nof each dataset and the\nepochs\nrequired to achieve the best performance can be seen as follows:\nUCR UTS Datasets\nTime2Image\nTime2Image w.o. Normalization\nECGFiveDays\n91.87% (89)\n92.57% (122)\nPickupGestureWiimoteZ\n72.40% (102)\n72.00% (130)\nShakeGestureWiimoteZ\n93.20% (96)\n95.99% (139)\nItalyPowerDemand\n96.85% (75)\n96.79% (96)\nECG200\n93.40% (90)\n93.00%(95)\nGestureMidAirD1\n72.77% (102)\n64.62% (127)\nEOGHorizontalSignal\n60.61% (33)\n59.94% (38)\nEOGVerticalSignal\n55.36% (40)\n54.41% (47)\nECG5000\n94.82% (62)\n94.79% (75)\nFordA\n93.98% (42)\n94.02%(34)\nUEA MTS Datasets\nTime2Image\nTime2Image w.o. Normalization\nEthanolConcentration\n28.67% (64)\n35.36% (99)\nFaceDetection\n67.79% (12)\n66.91% (12)\nHandwriting\n44.80% (123)\n42.59% (184)\nHeartbeat\n75.61% (44)\n73.66% (77)\nJapaneseVowels\n89.51% (33)\n87.84% (51)\nPEMS-SF\n84.62% (92)\n86.71% (181)\nSelfRegulationSCP1\n85.94% (38)\n90.44% (32)\nSelfRegulationSCP2\n60.22% (68)\n56.67%(132)\nSpokenArabicDigits\n99.41% (30)\n99.41% (36)\nUWaveGestureLibrary\n89.31% (55)\n90.94% (78)\nAccording to the data presented in the table, we observe that the impact of normalization on classification accuracy is marginal, regardless of its use or non-use. This limited effect may be attributed to the varying characteristics of each dataset, which influence the need for standardization differently. However, in terms of model convergence speed, it's evident that models with normalized preprocessing converge more rapidly. Hence, we recommend the adoption of normalization in the preprocessing stage.\nRegarding the suggestion to perform comparative experiments with other time series representation methods in conjunction with the transformer model, we have implemented typical image encoding techniques using both Transformer and CNN architectures for image classification of UTS. The outcomes of these experiments are presented in Figure 3. It's important to highlight that our study is pioneering in applying image representation to Multivariate Time Series (MTS). This approach has demonstrated superiority over other image representation methods and shows competitive performance relative to current state-of-the-art deep learning methods in Time Series Classification (TSC).\nFinally, we concur with the assessment of ViT's strengths, particularly its positional embedding and linear projection of flattened image patches. These features were a key factor in selecting ViT for our framework. However, it's crucial to note that ViT alone does not account for our method's effectiveness. As seen in Figure 3, merely utilizing existing image encoding methods followed by ViT yields inferior results compared to baseline models. Regarding Gaussian mapping, we consider it a versatile tool in handling time series data, which often includes noise and fluctuations. This approach can smooth the data, enhancing the robustness of the model.\nWe hope the above answers can address your questions and concerns."}, {"Heading": "Official Response to Reviewer mdnq on weakness 2/2", "Subheading": "Official CommentbyAuthors23 Nov 2023, 00:32 (modified: 23 Nov 2023, 04:38)EveryoneRevisions", "Content": "Comment:\nW2: lack of motivation for the main method\nAnswer\n: We thank the reviewer for these insightful comments of our work. The goal of this paper is to propose a novel time series image representation framework that not only has better comprehensive performance compared with existing deep learning SOTA algorithms but also has the inherent generalization ability of both UTS and MTS with inconsistent length.\nInspired by 2D keypoint detection task\nin computer vision, we noticed that Gaussian distributions are often used to model uncertainty or confidence in locations. In addition, Gaussian distribution is a smooth distribution; that is to say, since time series data usually have noise and fluctuations, we think modeling it through Gaussian distribution can smooth the data to a certain extent and make the model more robust, which is our motivation for Gaussian mapping. At the same time, the sub-patch constructed from the data of each channel time point can also better integrate the information of each channel, which is helpful for the model to better understand the overall characteristics of multivariable time series.\nWe also appreciate the reviewer for bringing about the analysis from a data perspective. We did an in-depth analysis based on all the datasets we use. Here are some findings we want to share. First, since the experiment with Time2Image was conducted on an all time series public dataset, the superior performance indicates that this method is suitable for most time series data. Here are some findings we want to share from our perspective:\n(1)\nThe number of channels in MTS will have an important impact on the performance\n; that is to say, our method might have limited performance when the number of MTS is large. Since the size of the sub-patch is fixed and we regard data on each dataset from different channels as \"equal circle in the square\" problem, that means the larger the channel, the smaller the place for representation of each channel (see DuckDuckGeese with 1345 channels, PEMS_SF with 963 channels,etc.).\n(2)\nThe length of the time series will have an impact on the performance\n; that is to say, the smaller the difference between predefined sizes L, the better the performance.The reason is mainly because of the resize we use in preprocessing. In this work, we set size L to 196. Even though resizing can deal with unequal length on MTS, it is recommended to find the suitable size based on the original length of the dataset in the future. For instance, when the length of the time series is too long, there will be a large information loss, which might have a negative impact on the performance (see EigenWorms with 17984, CinCECGTorso with 1639, and HandOutlines with 2709).\nI hope these findings will address your concern. Any further suggestions and comments are still welcome."}, {"Heading": "Official Response to Reviewer mdnq on Questions 1/2", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:35Everyone", "Content": "Comment:\nAbout Questions\nWhat are the author\u2019s intuitions for why Time2Image underperforms the regular ResNet? Is there something about the Gaussian representation that is particularly suited to Transformers over Convulational approaches?\nAnswer\n: We appreciate your insightful question regarding the performance comparison between Time2Image and the regular ResNet. As far as we are concerned, the observed difference in performance can be attributed to the unique characteristics of the proposed Gaussian representation ATSGM and its compatibility with Transformers. To illustrate this, let's delve into the Time2Image image representation process using multivariate time series (MTS) as an example. Following the Gaussian representation by ATSGM, each patch encapsulates the image representation of all channels at a specific time stamp from the MTS. This implies that each patch contains local information, particularly channel information, at a certain time stamp. Subsequently, these patches are arranged in chronological order to create input sequences for the Vision Transformer (ViT). This arrangement allows ViT to effectively capture temporal information and learn patterns in a sequential manner. Therefore, our use of Gaussian mapping in ATSGM aligns well with Vision Transformer (ViT) because ViT is excellent at understanding long-term patterns in sequences. The smooth and continuous nature of the Gaussian representation enhances ViT's ability to capture important features in a seamless way, making our approach effective for analyzing complex patterns in time series data.\nThe results of InceptionTime seem to worse in this evaluation compared with the results of the Time Series Benchmark and Redux. Is this because T2I is better at the same categories as inception time? While the paper explains the generalization ability of T2I across domains it does not shine any light on where (if any) the gains may come from.\nAnswer\n: We appreciate your insightful comments and suggestions. From our understanding, the generalization ability of Time2Image might depend on the flexibility of Gaussian representation. The idea of ATSGM is to integrate information from different channels at the same time point, which helps enhance the model's ability to capture diverse features in multivariate time series data. This integration facilitates a more comprehensive understanding of the interdependencies and interactions among different channels. The design choice of combining information from various channels at each time point demonstrates the flexibility of Gaussian representation, allowing it to adapt well to the intricate patterns present in multivariate time series data. This integration aligns with real-world scenarios where inter-channel relationships are crucial, enhancing the model's capacity to accurately represent complex, correlated structures in diverse time series datasets. This can also be proved from our result in Table 6, which we can see that the better performance mainly belongs to the physiological dataset, which has typical characteristics of the correlation and dependence between different channels. We hope it can address your question, and any further comments or thoughts are also welcome to have a better understanding of the framework.\nAre the authors concerned that the method for selecting the standard deviation parameter could allow overfitting on the benchmark datasets? Were there any held-out datasets for parameter selection that could be used for evaluation?\nAnswer\n:\nThank you for your questions. In our work, we used pre-defined training and testing splits for fairness comparison to other baselines without having a held-out dataset specifically for parameter selection. However, we would like to note that for the standard deviation parameter selection process, we employed the \"3 sigma rule\" of the Gaussian distribution. By deriving a relationship between the standard deviation, sub-patch size, and the fixed number of channels in multivariate time series, we can figure out the value of the standard deviation. We really appreciate your insightful question, and we will further elaborate on this aspect in the revised version. Please find the clarification in detail on page 5, which we believe provides additional clarity on the rationale behind the selection of standard deviation parameters, as demonstrated in Table 7."}, {"Heading": "Official Response to Reviewer mdnq on Questions 2/2", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:40Everyone", "Content": "Comment:\nGiven the restrictions of the algorithm, in that finding a packing for the gaussian distributions in the patches will reduce the resolution of the final sample as the number of channels increases, would it make sense to evaluate the performance of the model as the number of channels increases? From quick observation on the datasets with high number of channels (Crop-7200, phalangesOutlinesCorrect-1800, Ford*-3600, ElectricDevices-8926, NonInvasive*-1800, DuckDuckGeese-1345) it seems that in this collection the T2I win-rate is lower (~50%). A similar analysis would be on sequence length. EigenWorms contains the longest sequences by an order of magnitude in the MTS set and Time2Image performance is much worse than ResNet or InceptionTime. Helping understand these performance bounds would be very useful for practical applications and understanding the generalization from the test benchmark to other evaluations. This could also help inform how the additional parameters for series normalization and patch size can be set.\nAnswer\n: Thank you for your insightful suggestions and observations. We think this question is similar to the Weakness #2, so please find the answers from weakness #2 to see if those findings can address you questions. We fully agree with your suggestion on understanding the performance bounds under different conditions and how this knowledge can inform the setting of additional parameters. We will elaborate on these aspects in the revised manuscript to provide a more comprehensive understanding of our approach.\nAdditional Nits:\nPage 5: the link to the best packings of equal circles in a square returns 404. The correct link should include a \u2018#\u2019 before \u2018Results\u2019.\nAlgorithm 1 does not define L anywhere in the paper though I believe it is simply equal to 196.\nTable 1: Incorrect based on the results of Table 6. In Table 6 ResNet shows 4 wins instead of 3, Time2Image shows 11 wins instead of 13, and Time2Image+ResNet shows 2 wins which should not be conflated with Time2Image+ViT in this table.\nFigure 4 should include InceptionTime\nAnswer\n: Thank you so much for your careful reading. Based on your suggestions, we made the following revisions to our paper:\nWe revised the link on page 5, and you're right about the correct link\nWe added the definition of L to our revised manuscript on page 4.\nThe Figure 4 is also updated to include the performance of InceptionTime.\nWhat we want to note is that after a careful check on Table 1, we think there might be a misunderstanding from the analysis. What we want to show in Table 1 is the performance of our proposed Time2Image compared to other baseline models (ROCKET, CIF, HIVE-COTE, ResNet, and InceptionTime). However, in the last column of Table 6 is the performance of the proposed image representation method for different frameworks of image classification that we want to explore from comparative experiment for further analysis. Therefore, in Table 1, we do not need to consider the performance of the last column from Table 6. Hope this explanation solves your problem.\nWe're grateful for your thoughtful questions and helpful advice. Please feel free to reach out if you have any additional queries. If you feel that our response adequately addresses your concerns, would you like to consider raising your rating score for our paper? Thank you for your consideration!"}]}, {"Heading": "Official Review of Submission9293 by Reviewer soQ5", "Subheading": "Official ReviewbyReviewer soQ529 Oct 2023, 22:45 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper introduces a method to transform time series data into images, subsequently employing an image classifier to classify the time series data. This image representation derives from calculating the Gaussian distribution for each subsequence. The primary objective of the proposed method is to enhance time series classification.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nPaper is very well written and structured.\nWeaknesses:\nMissing some related works:\nA recent survey, as seen in [\nhttps://arxiv.org/pdf/2304.13029.pdf]\n, found that InceptionTime, detailed at [\nhttps://link.springer.com/article/10.1007/s10618-020-00710-y]\n, achieves higher accuracy than ResNet. A comparison of the proposed method with the InceptionTime model could provide further insights into the proposed method performance.\nFurthermore, the paper omits some pertinent related work, such as methods based on the Fast Fourier Transform (FFT) and the Continuous Wavelet Transform (CWT).\n1-Meintjes, A., Lowe, A., & Legget, M. (2018, July). Fundamental heart sound classification using the continuous wavelet transform and convolutional neural networks. In 2018 40th annual international conference of the IEEE engineering in medicine and biology society (EMBC) (pp. 409-412). IEEE.\n2- Hatami, N., Gavet, Y., & Debayle, J. (2018, April). Classification of time-series images using deep convolutional neural networks. In Tenth international conference on machine vision (ICMV 2017) (Vol. 10696, pp. 242-249). SPIE.\nQuestions:\nThe core goal of transforming time series data into images is to boost accuracy. Although the authors demonstrate that their method outperforms other networks that utilize raw time series data, such as the Fully Connected Network (FCN) and ResNet, this superiority isn't primarily due to the image transformation. Instead, it's attributed to the disparity in network size. For instance, the FCN comprises 396,550 parameters, and ResNet contains 580,486 parameters. In contrast, the network featured in this paper, VIT-16, encompasses a staggering 86,859,496 parameters. Despite its immense size, VIT-16 significantly surpasses the other networks. However, given the smaller size of the other networks, they still yield commendable results. One must question the computational feasibility of transforming time series data into images and then training a model on it. Wouldn't a larger ResNet or FCN model potentially produce comparable results?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Response to Reviewer soQ5 on Weakness", "Subheading": "Official CommentbyAuthors23 Nov 2023, 01:17 (modified: 23 Nov 2023, 06:42)EveryoneRevisions", "Content": "Comment:\nThank you for the insightful comments on our work. Please find our answers below.\nAbout weakness\nMissing some related works: A recent survey, as seen in [\nhttps://arxiv.org/pdf/2304.13029.pdf]\n, found that InceptionTime, detailed at [\nhttps://link.springer.com/article/10.1007/s10618-020-00710-y]\n, achieves higher accuracy than ResNet. A comparison of the proposed method with the InceptionTime model could provide further insights into the proposed method's performance.\nAnswer\n: Thank you for highlighting InceptionTime as a competitive baseline. In our initial manuscript, our primary focus was to demonstrate the effectiveness of time series image representation through deep learning-based classification. We chose FCN and ResNet as baselines based on a comprehensive review of deep learning models for classification [1], considering them as SOTA models for our specific task. We were concerned that including InceptionTime, designed as a neural network ensemble model for UTS, might introduce bias and result in an unfair comparison. However, we appreciate your valuable suggestion and found that in a recent paper you mentioned, the author also mentioned InceptionTime as one of the deep learning-based methods, and in response, we have included the performance comparison with InceptionTime on UTS in our Appendix Table 5 and update Figure 3 in revised manuscript, please find the CD diagram including InceptionTime. It is worth noting that through CD diagram, it can be found that even with this additional comparison, our proposed Time2Image method continues to exhibit superiority on both UTS and MTS datasets. \n[1] Ismail et al. Deep learning for time series classification:a review\nFurthermore, the paper omits some pertinent related work, such as methods based on the Fast Fourier Transform (FFT) and the Continuous Wavelet Transform (CWT). 1-Meintjes, A., Lowe, A., & Legget, M. (2018, July). Fundamental heart sound classification using the continuous wavelet transform and convolutional neural networks. In 2018 40th annual international conference of the IEEE engineering in medicine and biology society (EMBC) (pp. 409-412). IEEE. 2- Hatami, N., Gavet, Y., & Debayle, J. (2018, April). Classification of time-series images using deep convolutional neural networks. In Tenth international conference on machine vision (ICMV 2017) (Vol. 10696, pp. 242-249). SPIE.\nAnswer: Thank you for bringing to our attention the two relevant papers on time series classification. After reviewing these works, we have made the following adjustments to the Related Work section:\nThe first paper introduces another time series encoding method, which we believe falls under the category of decomposition methods within the broader transformation methods. We have incorporated this information into the first paragraph of Section 2.1.\nThe second paper presents RP+CNN for univariate time series classification, representing one of the time series image representations followed by classification algorithms. This content has been included in the second paragraph when introducing time series image encoding methods.\nWe appreciate your valuable suggestions, and please find these two papers in the related work section of our revised manuscript."}, {"Heading": "Official Response to Reviewer soQ5 on Questions", "Subheading": "Official CommentbyAuthors23 Nov 2023, 01:25 (modified: 23 Nov 2023, 06:02)EveryoneRevisions", "Content": "Comment:\nAbout questions\nThe core goal of transforming time series data into images is to boost accuracy. Although the authors demonstrate that their method outperforms other networks that utilize raw time series data, such as the Fully Connected Network (FCN) and ResNet, this superiority isn't primarily due to the image transformation. Instead, it's attributed to the disparity in network size. For instance, the FCN comprises 396,550 parameters, and ResNet contains 580,486 parameters. In contrast, the network featured in this paper, VIT-16, encompasses a staggering 86,859,496 parameters. Despite its immense size, VIT-16 significantly surpasses the other networks. However, given the smaller size of the other networks, they still yield commendable results. One must question the computational feasibility of transforming time series data into images and then training a model on it. Wouldn't a larger ResNet or FCN model potentially produce comparable results?\nAnswer\n: Thank you for bringing this to our attention, and we find your suggestion intriguing for further exploration. Over the past few days, we conducted additional experiments to test the performance on larger ResNet, and now we would like to share the results with you. The experiment was conducted through all UEA Multivariate time series dataset. Specifically, we utilized ResNeXt101-32x8d, which encompasses\n88,791,336\nparameters, sharing a similar scale parameter with ViT-B/16.\nThe accuracy of ResNet-50, ResNeXt101-32x8d, and our proposed Time2Image on all UEA MTS datasets is presented below.\nDataset\nTime2Image\nResNeXt101-32x8d\nResNet\nArticularyWordRecognition\n97.80%\n96.67%\n98.26%\nAtrialFibrillation\n45.33%\n60.00%\n36.22%\nBasicMotions\n99.00%\n80.00%\n100.00%\nCharacterTrajectories\n99.50%\n99.30%\n-\nCricket\n100.00%\n91.67%\n99.40%\nDuckDuckGeese\n47.20%\n44.00%\n63.20%\nERing\n89.93%\n80.74%\n45.45%\nEigenWorms\n79.24%\n42.75%\n99.18%\nEpilepsy\n96.09%\n84.06%\n28.66%\nEthanolConcentration\n28.67%\n25.10%\n87.19%\nFaceDetection\n67.79%\n50.88%\n62.97%\nFingerMovements\n58.00%\n53.00%\n54.70%\nHandMovementDirection\n61.89%\n40.54%\n35.32%\nHandwriting\n44.80%\n24.35%\n59.78%\nHeartbeat\n75.61%\n72.20%\n63.89%\nInsectWingbeat\n47.60%\n41.64%\n-\nJapaneseVowels\n89.51%\n82.70%\n-\nLSST\n65.24%\n62.49%\n94.11%\nLibras\n86.44%\n82.22%\n42.94%\nMotorImagery\n63.60%\n53.00%\n49.77%\nNATOPS\n86.33%\n77.22%\n97.11%\nPEMS-SF\n84.62%\n79.77%\n99.64%\nPenDigits\n99.11%\n99.00%\n81.95%\nPhonemeSpectra\n24.94%\n23.11%\n30.86%\nRacketSports\n89.87%\n79.61%\n94.23%\nSelfRegulationSCP1\n85.94%\n86.69%\n76.11%\nSelfRegulationSCP2\n60.22%\n54.44%\n50.24%\nSpokenArabicDigits\n99.41%\n99.77%\n-\nStandWalkJump\n66.67%\n53.33%\n30.89%\nUWaveGestureLibrary\n89.31%\n89.38%\n88.35%\nFrom the result, we can see that despite the increased parameterization in ResNeXt101-32x8d, which has\n88,791,336 parameters\ncompared to the\n86,859,496 parameters\nin ViT-B, our Time2Image method consistently outperforms on 15 out of 32 datasets. This superior performance, even with the significantly larger parameter count of ResNeXt101-32x8d relative to the standard ResNet-50, suggests that increased model size does not linearly correlate with improved results. Importantly, our findings highlight the practical viability of Time2Image, especially in contexts where accuracy is paramount, despite potential increases in computational time. Thank you for inspiring us to conduct this insightful investigation.\nWe're grateful for your thoughtful questions and helpful advice. Please feel free to reach out if you have any additional questions. If you feel that our response adequately addresses your concerns, would you like to consider raising your rating score for our paper? Thank you for your consideration!"}]}, {"Heading": "Official Review of Submission9293 by Reviewer HAQG", "Subheading": "Official ReviewbyReviewer HAQG23 Oct 2023, 12:27 (modified: 23 Nov 2023, 06:31)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a new approach to time series classification (TSC). The method, Time2Image, involves producing image-based representations of time series, and then classifying the image representations using a vision transformer (ViT). The encoding process uses a  novel technique called Adaptive Time Series Gaussian Mapping (TSGM). Time2Image is able to process both univariate and multivariate time series, and can handle time series of unequal lengths. The approach is evaluated against SOTA methods on 158 datasets from the UCR/UEA collection.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nOriginality\nO1. The novelty of the methods lies in the time series to image encoding process (ATSGM), which is a novel way of encoding time series.\nQuality\nQ1. Compared to existing time series image representation methods (GAF, MTF, and RP) using the same classifier (ViT), Time2Image is shown to have improved performance on UTS datasets (Figure 3).\nQ2. Compared to two baseline methods (FCN and ResNet), Time2Image is shown to have the best performance on UTS (Table 1 and Figure 3).\nQ3. For the MTS datasets, Time2Image wins on the most datasets when compared to five baselines (ResNet, ROCKET, CIF, HIVE-COTE, and InceptionTime).\nQ4. The results are shown to generalise across different univariate TSC domains (Table 2).\nClarity\nC1. I appreciate the inclusion of Algorithm 1 to aid understanding and clarity of the method.\nSignificance\nS1. Time series image representation methods are well motivated, as powerful methods for computer vision can then be utilised. As existing approaches are behind SOTA, improving on them helps move the general family of methods forward.\nWeaknesses:\nOriginality\nO1. Further comparison to existing time series to image encoding methods is required, demonstrating the benefits of ATSGM. e.g. evaluation on MTS.\nO2. The classification method (ViT) is unchanged from its existing design, so originality only appears in the image encoding process.\nQuality\nQ1.\nMy biggest criticism of the work is the selection of SOTA baselines to compare to.\nA recent study [1] identified HIVE-COTEv2 and Hydra+MultiROCKET as the new SOTA for univariate time series. These methods would be better comparisons for UTS than FCN and ResNet, and help better position the work.\nQ2. I am unsure why only FCN and ResNet were used for the UTS evaluation. The other SOTA baselines that are used for MTS can be applied to UTS as well, but are not used.\nClarity\nC1.  It needs to be made more clear that all time series are resized to fixed length L (which is set to 196 for the experiments). I could not see L explicitly defined.\nC2. The link in footnote 1 does not work (404 not found). Visual examples of \"circle packing in a square\" would aid understanding.\nC3. Figures 1 and 2 need improvement. Additional information in the caption and further explanation of the patch -> matrix reshaping (step 11 in Algorithm 1) would be helpful.\nC4. I believe the ECG results are incorrect in Table 2. ResNet has an accuracy of 94.98%, while Time2Image has an accuracy of 94.67%. However, Time2Image is highlighted as the best score.\nSignifiance\nS1. Due to the choice of baselines, it is difficult to determine how significant the development of Time2Image is.\nS2. Many of these datasets are imbalanced, so only evaluating with accuracy can be misleading. A further evaluation using balanced accuracy, AUROC, etc. would be beneficial.\nS3. While grouping by domain does show generalisation, it would be more insightful to analyse by dataset properties, e.g. time series length, number of classes etc. This would help identify where the method is strong and where it is weak.\nS4. In addition to providing the critical difference diagram and number of wins, it would be helpful to see the average accuracy over all datasets.\n[1] Middlehurst, Matthew, Patrick Sch\u00e4fer, and Anthony Bagnall. \"Bake off redux: a review and experimental evaluation of recent time series classification algorithms.\" arXiv preprint arXiv:2304.13029 (2023).\nQuestions:\nQ1. Why were ROCKET, CIF, HIVE-COTE, and InceptionTime not evaluated for UTS?\nQ2. Other than improved performance, what are the benefits of ATSGM over existing image encoding methods? E.g. are the other methods able to deal with multivariate time series?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Response to Reviewer HAQG on Weaknesses 1/3", "Subheading": "Official CommentbyAuthors23 Nov 2023, 01:48Everyone", "Content": "Comment:\nWe greatly appreciate your thoughtful questions and valuable suggestions, which have significantly enriched the discussion around our work. Please find the answers below.\nAbout weakness\nO1. Further comparison to existing time series to image encoding methods is required, demonstrating the benefits of ATSGM. e.g. evaluation on MTS.\nAnswer\n: We sincerely appreciate your thorough review of our work. We would like to clarify that the reason we did not compare our method with existing time series image encoding methods on Multivariate Time Series (MTS) is due to the inherent challenge of extending current time series modeling methods to handle multivariate cases. As for now, there is a lack of methods specifically designed for multivariate time series image representation, and our proposed ATSGM is the first method to address this by providing a novel approach for modeling multivariate time series as images. We hope it could become the first baseline for comparison in the future.\nO2. The classification method (ViT) is unchanged from its existing design, so originality only appears in the image encoding process.\nAnswer\n:Thanks for your insightful observation. Indeed, the core classification method (ViT) remains unchanged in its original design, and the primary innovation in our work lies in the novel image encoding process\u2014ATSGM. From the overall response, we mentioned 2 research gap on time series image representation for classification, which we will quote here: (1) Before this work, there are no research working on multivariate time series (MTS) image representations since it is a challenging task. (2) Even though there are some image representation approaches for univariate time series, there are significant performance gaps to make a comparison of current state-of-the-art (SOTA) models in classification tasks. By introducing the Gaussian projection and utilizing sub-patches constructed from each channel's time points, we aim to provide a unique and effective representation for both univariate and multivariate time series data. The use of Gaussian projection allows for flexible modeling of the non-linear structures present in time series, contributing to improved feature retention and robustness. We believe that the novelty and contributions of our work primarily stem from this encoding process, enabling a distinctive approach to time series representation. Hope this answer can address your concern.\nQ1. My biggest criticism of the work is the selection of SOTA baselines to compare to. A recent study [1] identified HIVE-COTEv2 and Hydra+MultiROCKET as the new SOTA for univariate time series. These methods would be better comparisons for UTS than FCN and ResNet, and help better position the work.\nAnswer\n: We appreciate your attention to the field of Time Series Classification (TSC) and thank you for highlighting the recent work published in April [1]. However, what we want to say is that the initial goal of our study was to demonstrate the immense potential of time series image representation, showcasing the substantial performance gap between existing image representation methods and state-of-the-art (SOTA) methods in the context of image classification. Additionally, we aimed to explore the effectiveness of combining image representation with deep learning methods, bridging the gap between time series and computer vision. Therefore, in baseline model selection process, we only consider the deep learning-based time series classification algorithm. While other SOTA baselines (e.g.HIVE-COTEv2 and Hydra+MultiROCKET) all belong to the hybrid (ensemble) model according to the literature you just mentioned, and we think our selection in the comparative experiments should be driven by the desire for a fair comparison between models and a focus on showcasing the performance of our proposed method within deep learning frameworks.\nQ2. I am unsure why only FCN and ResNet were used for the UTS evaluation. The other SOTA baselines that are used for MTS can be applied to UTS as well, but are not used.\nAnswer\n: Thanks for your question. This concern is similar to Q1. Please find our answers to Q1 and our overall response. Any suggestions and comments are welcome if there's any question."}, {"Heading": "Official Response to Reviewer HAQG on Weaknesses 2/3", "Subheading": "Official CommentbyAuthors23 Nov 2023, 02:02Everyone", "Content": "Comment:\nC1. It needs to be made more clear that all time series are resized to fixed length L (which is set to 196 for the experiments). I could not see L explicitly defined.\nAnswer\n: Thanks once again for your valuable suggestions. We also apologize for any lack of clarity in defining this aspect. As you correctly pointed out, for our experiments, we chose L to be 196. The primary reason for this choice is the subsequent use of the ViT-B/16 classification model. In response to your feedback, we have further elaborated on this aspect in our revised version, which will be uploaded later. We appreciate your diligence in reviewing our work and believe that these revisions will contribute to a more comprehensive understanding of our experimental setup.\nC2. The link in footnote 1 does not work (404 not found). Visual examples of \"circle packing in a square\" would aid understanding.\nAnswer\n: We appreciate your attention to detail and thank you for bringing this to our attention. We apologize for the broken link in footnote 1, which has now been rectified in the revised version of the manuscript. The correct link is now:\nhttp://hydra.nat.uni-magdeburg.de/packing/csq/csq.html\n. We hope this website can help. Further questions or suggestions would also be appreciated.\nC3. Figures 1 and 2 need improvement. Additional information in the caption and further explanation of the patch -> matrix reshaping (step 11 in Algorithm 1) would be helpful.\nAnswer\n: We appreciate your feedback and will certainly work on improving the clarity of Figures 1 and 2. In the revised manuscript, we will provide more detailed information in the captions to offer better context for the figures. Additionally, we recognize the importance of explaining the patch -> matrix reshaping process (step 11 in Algorithm 1). Please find them in the captions of Figure 1 and 2 in our revised manuscript. And thanks for your suggestions for a better understanding of our framework.\nC4. I believe the ECG results are incorrect in Table 2. ResNet has an accuracy of 94.98%, while Time2Image has an accuracy of 94.67%. However, Time2Image is highlighted as the best score.\nAnswer\n: Thank you for bringing this to our attention, and we apologize for any confusion. We will rectify this in the revised version and ensure that the correct information is presented. Please find the revised version later. Thanks for making our work better. However, it's crucial to note that despite this oversight, the correct ranking and result from the analysis remain the same, which shows the inherent generalization ability of Time2Image.\nS1. Due to the choice of baselines, it is difficult to determine how significant the development of Time2Image is.\nAnswer\n: We appreciate your concern regarding the choice of baselines in our study. The primary objective of our work was to explore the effectiveness of the proposed Time2Image representation for time series classification, emphasizing its adaptability to both univariate and multivariate scenarios. Therefore, in our opinion, the focus should be more on the comparison between different time series image representations and the current deep learning image classification architecture. More answers can be found in Q1 and the overall response. But please note that we are open to further discussions and recommendations on baseline model selection."}, {"Heading": "Official Response to Reviewer HAQG on Weaknesses 3/3", "Subheading": "Official CommentbyAuthors23 Nov 2023, 02:26Everyone", "Content": "Comment:\nS2. Many of these datasets are imbalanced, so only evaluating with accuracy can be misleading. A further evaluation using balanced accuracy, AUROC, etc. would be beneficial.\nAnswer\n: Thank you very much for your suggestion. For this reason, we conducted experiments on the performance of our model, obtained a balanced accuracy value, and compared it with the accuracy we disclosed before. We selected 14 UTS data and 10 MTS data with various lengths, classes, domains, etc. due to time constraints. The results can be seen below. From the results, we can see that by calculating the balanced accuracy, we can find that in some datasets, balanced accuracy performs better than accuracy on most datasets, which also shows that our method can solve the problem of imbalanced dataset well.\nDataset\nBalanced Accuracy\nAccuracy\nECGFiveDays\n93.17%\n91.87%\nItalyPowerDemand\n96.79%\n96.85%\nECG200\n92.64%\n93.40%\nGestureMidAirD1\n71.72%\n72.77%\nEOGHorizontalSignal\n63.74%\n60.61%\nEOGVerticalSignal\n57.87%\n55.36%\nECG5000\n92.23%\n94.82%\nFordA\n94.05%\n93.98%\nFordB\n81.13%\n80.86%\nPickupGestureWiimoteZ\n78.47%\n72.40%\nShakeGestureWiimoteZ\n96.67%\n93.20%\nItalyPowerDemand\n96.79%\n96.85%\nNonInvasiveFetalECGThorax1\n94.59%\n94.14%\nNonInvasiveFetalECGThorax2\n94.05%\n94.05%\nDataset\nBalanced Accuracy\nAccuracy\nEthanolConcentration\n62.64%\n28.67%\nFaceDetection\n67.40%\n67.79%\nHandwriting\n49.85%\n44.80%\nHeartbeat\n74.56%\n75.61%\nJapaneseVowels\n91.38%\n89.51%\nPEMS-SF\n87.79%\n84.62%\nSelfRegulationSCP1\n87.03%\n85.94%\nSelfRegulationSCP2\n62.59%\n60.22%\nSpokenArabicDigits\n99.45%\n99.41%\nUWaveGestureLibrary\n90.59%\n89.31%\nS3. While grouping by domain does show generalisation, it would be more insightful to analyse by dataset properties, e.g. time series length, number of classes etc. This would help identify where the method is strong and where it is weak.\nAnswer\n: Thank you for your suggestions. Actually, reviewer mdnq also asked a similar question, which requires an in-depth analysis from a data perspective to help understand the bounds and weaknesses of the model. Here we paste the answers and share our findings with you from previous answers:\n(1) The number of channels in MTS will have an important impact on the performance\n; that is to say, our method might have limited performance when the number of MTS is large. Since the size of the sub-patch is fixed and we regard data on each dataset from different channels as \"equal circle in the square\" problem, that means the larger the channel, the smaller the place for representation of each channel (see DuckDuckGeese with 1345 channels, PEMS_SF with 963 channels,etc.).\n(2) The length of the time series will have an impact on the performance\n; that is to say, the smaller the difference between predefined sizes L, the better the performance.The reason is mainly because of the resize we use in preprocessing. In this work, we set size L to 196. Even though resizing can deal with unequal length on MTS, it is recommended to find the suitable size based on the original length of the dataset in the future. For instance, when the length of the time series is too long, there will be a large information loss, which might have a negative impact on the performance (see EigenWorms with 17984, CinCECGTorso with 1639, and HandOutlines with 2709).I hope these findings will address your concern. Any further suggestions and comments are still welcome.\nS4. In addition to providing the critical difference diagram and number of wins, it would be helpful to see the average accuracy over all datasets.\nAnswer\n: Thank you for your suggestions. We have added the average accuracy of each method to the Table 5 and 6 in the appendix. Through analysis, it can be found that our method still has the best performance in average accuracy in MTS an has a slightly gap with InceptionTime."}, {"Heading": "Official Response to Reviewer HAQG on Questions", "Subheading": "Official CommentbyAuthors23 Nov 2023, 02:43 (modified: 23 Nov 2023, 03:47)EveryoneRevisions", "Content": "Comment:\nQ1. Why were ROCKET, CIF, HIVE-COTE, and InceptionTime not evaluated for UTS?\nAnswer\n: Thank you for this question. We added InceptionTime as one of our baseline for UTS since recent paper categorized this method as a deep learning-based classification algorithm, and the performance can be found in our revised manuscript. However, since ROCKET, CIF, and HIVE-COTE all belong to ensemble algorithms, which is not what we are focused on. Further explanation can be found in the answers to Weakness Q1 and the overall response. Thank you for understanding.\nQ2. Other than improved performance, what are the benefits of ATSGM over existing image encoding methods? E.g. are the other methods able to deal with multivariate time series?\nAnswer\n: Thank you so much for this insightful question. Actually, there is no research working on multivariate time series image representation, so our work is the first to give a possible solution for image representation. In addition to the enhanced performance, ATSGM holds distinct advantages over existing image encoding methods, particularly in its ability to effectively handle multivariate time series (MTS) data. The Gaussian mapping employed by ATSGM allows for a better representation of MTS, capturing relationships between different channels or variables within the time series. This is a crucial feature, as many traditional image encoding methods may struggle to adequately model the intricate dependencies present in MTS data. Therefore, ATSGM's specialization in encoding multivariate time series contributes a unique and valuable dimension to the field of image representation for time series classification.\nThank you again for your insightful questions and valuable advice. If you have any more questions, we're more than willing to continue the discussion. If you find that our response addresses your concerns, could you please consider increasing your rating score for our paper? Your consideration is highly appreciated."}, {"Heading": "Official Comment by Reviewer HAQG", "Subheading": "Official CommentbyReviewer HAQG23 Nov 2023, 06:30 (modified: 23 Nov 2023, 06:33)EveryoneRevisions", "Content": "Comment:\nThank you very much for your extensive response to my review.\nAs the proposed method is the first to perform multivariate time series image representation, the work now has more weight in terms of novelty. I suggest authors make this as clear as possible in the paper itself (apologies if I missed this on my first read through).\nI appreciate the need for a fair comparison with deep learning methods. However, excluding other SOTA methods because they come from another family does not seem a sufficient reason to not include them. In my opinion, the results of other methods should be included at least to provide context and demonstrate the gains in performance of the new method (closing the gap to SOTA), even if these methods are not necessarily a fair comparison as they are ensemble approaches.\nI'm not sure if this is a problem on my end, but I cannot see the changes of the revised version. Has it been submitted to OpenReview?\nFrom the rebuttal, specifically with the clarification regarding novelty, I have increased my review score from 3 to 5. However, I am unwilling to increase it further without seeing the revised version of the paper. Again, apologies if this is an issue on my end but I cannot see the revised version."}]}, {"Heading": "Official Review of Submission9293 by Reviewer e5E4", "Subheading": "Official ReviewbyReviewer e5E415 Oct 2023, 02:38 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes adaptive time series Gaussian mapping that converts a multivariate time series into 2D images with multiple channels. ATSGM gets a datapoint at a timestamp as a input and outputs sub-patches containing an image with a circle gaussian. Sub-patches are then merged to become a patch, the input for ViT architecture.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n1 poor\nStrengths:\nNovel idea to convert a time series into an image to exploit recent vision architecture ViT's generalization power.\nThe method is general to various time series domains.\nWeaknesses:\nNo recent TSC baselines such as TimesNet[1], just using vision architectures although the task is time series classification.\nNo justification about why Gaussian should be used to generate subpatches.\nFlaws in preprocessing. In preprocessing, resizing reduces the number of timestamps and can bring information loss. For example, a periodic pattern longer than the window size can vanish and a evolving pattern after a distribution shift can also be erased.\n[1] Wu, Haixu, et al. \"TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis.\" The Eleventh International Conference on Learning Representations. 2022.\nQuestions:\nIs there any specific reason for the conversion from time series to gaussian image? It is straightforward to use segmented times series as the patches to ViT.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Response to Reviewer e5E4", "Subheading": "Official CommentbyAuthors23 Nov 2023, 04:07 (modified: 23 Nov 2023, 04:40)EveryoneRevisions", "Content": "Comment:\nAbout weakness\n:\nNo recent TSC baselines such as TimesNet[1], just using vision architectures, although the task is time series classification.\nAnswer\n: Thank you for your suggestions on TimesNet, which is a strong and perfect model. We found that in this paper, the author adopted experiments on 10 UEA multivariate time series dataset. Due to time constraints, we couldn't conduct the TimeNet on all time series public dataset in a short time, even if we tried. Therefore, we recorded their results and compare it with the performance of Time2Image and we hope it can give some insight to better position our work.\nDataset\nTime2Image\nTimesNet\nEthanolConcentration\n28.67%\n35.70%\nFaceDetection\n67.79%\n68.60%\nHandwriting\n44.80%\n32.10%\nHeartbeat\n75.61%\n78.00%\nJapaneseVowels\n89.51%\n98.40%\nPEMS-SF\n84.62%\n89.60%\nSelfRegulationSCP1\n85.94%\n91.80%\nSelfRegulationSCP2\n60.22%\n57.20%\nSpokenArabicDigits\n99.41%\n99.00%\nUWaveGestureLibrary\n89.31%\n85.30%\nFrom the result, it can be seen that even though the performance of TimesNet outperform our method from these 10 datasets, we still have competitive performance, which is promising for time series image representation.\nNo justification about why Gaussian should be used to generate subpatches.\nAnswer\n: Thank you for your questions. We think this question is similar to the motivation or intuition of Gaussian mapping.  We think answers to overall response can be Answers to general response\nInspired by 2D keypoint detection task\nin computer vision, we noticed that Gaussian distributions are often used to model uncertainty or confidence in locations. In addition, a Gaussian distribution is a smooth distribution; that is to say, since time series data usually have noise and fluctuations, we think modeling it through a Gaussian distribution can smooth the data to a certain extent and make the model more robust. Therefore, introducing this idea into the representation of time series data by modeling the uncertainty of each channel time point and forming a sub-patch through Adaptive Time Series Gaussian Mapping(ATSGM) we proposed, can help the model better understand the importance of each time point in the time series data. At the same time, the relationship and local information between different channels in MTS data can also be obtained in order to improve the model's robustness and generalization ability. Each subpatch i \u200b\u200binto the ViT model in chronological order, so that the model can effectively capture long-term information.\nFlaws in preprocessing. In preprocessing, resizing reduces the number of timestamps and can bring information loss. For example, a periodic pattern longer than the window size can vanish, and an evolving pattern after a distribution shift can also be erased.\nAnswer\n: We really appreciate your insightful and valuable concern. We use resizing in our method for two reasons. First, it helps handle time series of different lengths. Second, it aligns with the input requirements of our chosen model, ViT-B/16.  We need each subpatch to represent a Gaussian mapping of a specific time across different channels. We picked cubic interpolation during resizing since it is smooth and maintains overall trends compared to other interpolation methods. However, we acknowledge there's still some information loss with significant resizing. That is why we tested our approach on all public datasets to get an overall performance measure. And from the result, it shows that our proposed algorithm is suitable for most time series data with a certain length, but for the case with extremely long time series, our method performs not that well compared to state-of-the-art models, as the reviewer pointed out. We appreciate this feedback, and it guides our future work. The adjustment of the interpolation method for pre-processing or the modification on image classification algorithm could be two directions for further work. We hope this could address your questions.\nAbout Question\n:\nIs there any specific reason for the conversion from time series to gaussian image? It is straightforward to use segmented times series as the patches to ViT.\nAnswer\n: We appreciate the reviewer's question, which we think is still similar to the motivation and intuition of gaussian mapping. Please see our answers to Weakness #2. Thanks.\nThank you again for your insightful questions and valuable advice. If you find that our idea is good and our response addresses your concerns to some extent, could you please consider increasing your rating score for our paper? Your consideration is highly appreciated."}]}]}, "4IxtmklIym": {"paper_info": {"Primary Area": "datasets and benchmarks", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Datasets and Benchmarks, 6D Pose estimation, Robotic, Bin Picking, Occlusion", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "This paper presents the largest 6D pose estimation dataset for fruit bin picking with benchmarking over scene generalization, camera generalization and occlusion robustness.", "Abstract": "Bin picking is a ubiquitous application spanning across diverse industries, demanding automated solutions facilitated by robots. These automation systems hinge upon intricate components, including object instance-level segmentation and 6D pose estimation, which are pivotal for predicting future grasping and manipulation success. Contemporary computer vision approaches predominantly rely on deep learning methodologies and necessitate access to extensive instance-level datasets. However, prevailing datasets and benchmarks tend to be confined to oversimplified scenarios, such as those with singular objects on tables or low levels of object clustering. In this research, we introduce FruitBin. It emerges as an unparalleled resource, boasting an extensive collection of over a million images and 40 million instance-level 6D poses. Additionally FruitBin differs with other datasets whith its inclusive representation of a wide spectrum of challenges, encompassing symmetric and asymmetric fruits, objects with and without discernible texture, and diverse lighting conditions, all enriched with extended annotations and metadata. Leveraging the inherent challenges and the sheer scale of FruitBin, we highlight its potential as a versatile benchmarking tool that can be customized to suit various evaluation scenarios. As a demonstration of this adaptability, we have created two distinct types of benchmarks: one centered on novel scene generalization and another focusing on novel camera viewpoint generalization. Both benchmark types offer four levels of occlusion to facilitate the study of occlusion robustness. Notably, our study showcases the difficulty of FruitBin dataset, with two baseline 6D pose estimation models, one utilizing RGB images and the other RGB-D data, across these eight distinct benchmarks. FruitBin emerges as a pioneering dataset distinguishing itself by seamlessly integrating with robotic software. That enable direct testing of trained models in dynamic grasping tasks for the purpose of robot learning. Samples of the dataset with its associated code are provided in the supplementary materials. FruitBin promises to be a catalyst for advancing the field of robotics and automation, providing researchers and practitioners with a comprehensive resource to push the boundaries of 6D pose estimation in the context of fruit bin picking and beyond.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9289", "PDF Url": "https://openreview.net/pdf?id=4IxtmklIym"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9289 by Area Chair uaXa", "Subheading": "Meta ReviewbyArea Chair uaXa06 Dec 2023, 03:49 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper presents a dataset that is designed for the task of 6D pose estimation in fruit bin picking.  The dataset is synthetic with 8 types of fruits under varying lighting conditions and camera perspective. Two 6D pose estimation models utilizing RGB images or RGB-D data are evaluated on the proposed dataset.  The proposed dataset is large-scale and extensive regarding images, configurations, and annotation, which may be useful future research for fruit bin-picking tasks.  However, most reviewers consistently raised the concern regarding the limitation of the dataset because the dataset is synthetic only and has the limited variety of objects.  This concern raises questions about the practical utility of models trained on this dataset in the real-world scenarios.  The authors admitted this concern by addressing in their rebuttal that they are extending the dataset by adding 6D pose real-world fruit data.  The authors also acknowledged the lack of variation in size and shape.  The concern regarding the choice of the deployed benchmark methods was also raised. The rebuttal could not fully resolve this concern.  During the post-rebuttal discussion, it was acknowledged that a substantial revision followed by at least one more round of peer review is required to be a publishable state.  The paper should analyze the sim2read gap and offer more relevant benchmarks such as actual robot grasping of fruits.  The paper cannot be accepted, accordingly.\nJustification For Why Not Higher Score:\nN/A\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "General answer to the reviews - Part 1", "Subheading": "Official CommentbyAuthors22 Nov 2023, 22:04 (modified: 23 Nov 2023, 05:23)EveryoneRevisions", "Content": "Comment:\nDear Reviewers,\nWe sincerely appreciate your thoughtful review of our work and would like to address the valuable points you've raised regarding the limitations of our dataset. Your feedback is instrumental in enhancing the clarity and impact of our research.\nSim2Real Gap:\nWe concur with your observation that the Sim2Real gap is a crucial limitation of our study. To address this, we have conducted tests employing state-of-the-art\ndiffusion models to replace backgrounds\n. These models have been widely acknowledged in image generation and processing. Surprisingly, in our dataset, they improve image realism significantly, even capturing intricate details like holes in the fruit bin and adapting to bin orientation. Leveraging these advanced diffusion models, in conjunction with precise prompt descriptions, offers unparalleled expressiveness that would be challenging to replicate purely through simulation. We believe that they can be utilized to substantially enhance the quality of our dataset.\nWe recognize the difficulties presented by the lack of precise real-world data for quantitatively evaluating the Sim2Real gap. To address this issue, we are\nenhancing our dataset with real-world 6D poses\n. This enrichment will facilitate a more thorough investigation of the Sim2Real gap and broaden the practical utility of our dataset.\nPickSim:\nYour insights regarding the choice of the PickSim simulator are deeply appreciated. While we acknowledge the limitations of realism inherent in Gazebo, it\u2019s important to emphasize the strengths it brings to the dataset. Furthermore, PickSim includes\ncapturing diverse vision features such as segmentation maps, depth information, and occlusion rates\n. All these features are often\nabsent in existing state-of-the-art generators such as Kubrik and Blenderproc\n. By being generated by PickSim, Fruitbin offers a unique advantage not found in other datasets:\nIts tight integration with the robotic simulator\nallows for the seamless application of\ntrained 6D pose models to develop dynamic, vision-based grasping procedures without domain discrepancies\n.\nFruitBin:\nWe are grateful for your insights into the fruit application and the limitations concerning the number of categories in our dataset. The reasons for focusing on fruit bin picking are manifold. Firstly, our research centers around the manipulation of fragile and deformable objects, which includes fruits. Secondly, the lack of solutions in the domain of fruit bin picking and the absence of relevant datasets motivated our choice. Finally, we firmly believe that automating\nfruit bin picking holds potential across industries, ranging from harvesting to industrial sorting and domestic robotic assistance\n.\nWhile the number of fruit categories could have been expanded our dataset includes most of representative shapes and textures such as bananas, pears, apples, and apricots. Although not part of the benchmark yet, we leveraged PickSim\nto add testing data where random variation of scale over the three directions is applied to vary the shapes\n. Additionally, to answer real-world scenarios of industry and supermarkets,\nwe generated bin picking for only one type of object. This comes with two variations: one where the mesh is unique and the second where mesh modification is applied.\nThe key contributions of our work lie in the dataset's scale and its comprehensive coverage of 6D pose estimation challenges. The\nprovided script\nempowers users to tailor benchmarks according to specific parameters, fostering research in point-of-view generalization, scene adaptation, and occlusion resilience. We emphasize that while the proposed challenges provide scope for benchmarking, researchers are free to\nadapt them to their unique goals and objectives\nrelated to 6D pose estimation.\nRobotic Applications:\nWe appreciate your suggestion to demonstrate robotic applications such as bin picking using our dataset. For this rebuttal, we haven\u2019t yet included grasping with the real robot. However, as an early proof of concept, a\ngrasping simulation pipeline has been set up\nas follows:\nwe automatically generate a grasping list associated with the mesh,\nwe evaluate the 6D pose with our trained Densefusion model\nwe used free obstacle path planning libraries such MoveIt to grasp the object with the list of grasp and the 6D pose of the object", "Replies": [{"Heading": "General answer to the reviews - Part 2", "Subheading": "Official CommentbyAuthors22 Nov 2023, 22:06Everyone", "Content": "Comment:\nPaper :\nWe have\ncorrected numerous typos\nthroughout the paper. Moreover, we have streamlined Table 1 by eliminating the column that pertains to image resolution. We have also marked symmetric objects in Table 2 with the symbol \u2018\n\u2019. We have\nenhanced and clarified sections\nof the paper, particularly those discussing\nadding supplementary data\n, the\nnecessity of 6D pose estimation for fruit bin picking\nand the\napplication of real robots\n. We also mention the\ncreation of a real-world dataset\n. The primary changes have been highlighted in red in the revised version of the paper."}]}, {"Heading": "Official Review of Submission9289 by Reviewer Ksan", "Subheading": "Official ReviewbyReviewer Ksan30 Oct 2023, 14:41 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper introduces a novel and extensive dataset designed for the task of fruit bin picking. This dataset is entirely synthetic and comprises 3D meshes of eight distinct fruits arranged in randomized configurations within bins, with varying lighting conditions and camera perspectives. The research employs this dataset to train two distinct models, one utilizing RGB data and the other incorporating RGB-D information, to serve as exemplary methods for 6-DOF pose estimation.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper is well-written and easy to understand. It explains its ideas clearly, making it accessible to a broad audience.\nThe dataset is extensive regarding images, configurations, and annotations.\nThe paper also offers detailed insights into the dataset, providing readers with a comprehensive understanding of its composition. This helps other researchers in utilizing the dataset effectively.\nThe synthetic nature of the dataset allows for the extraction of highly detailed annotations, which can be challenging to obtain in real-world scenarios.\nWeaknesses:\nOne primary concern regarding the paper pertains to its real-world applicability. While the synthetic dataset's ability to provide detailed annotations is a strength, it also raises questions about the practical utility of algorithms trained on it in real-world scenarios. The paper should delve into the broader implications and limitations of applying such models to real-world fruit-picking scenarios.\nA related concern is the limited variety of objects in the dataset. With only 8 types of fruits, and a significant majority of them being spherical (75%), the need for 6DOF pose estimation for these objects may be questionable. The paper should address the relevance of 6DOF pose estimation for objects that might not require such detailed positioning information.\nThe paper should explore the broader question of whether 6DOF pose estimation is necessary for fruit picking, particularly when considering that many real-world fruit-picking applications rely on suction grippers, making pose estimation less critical.\nIt is important to clarify the specific scenarios that the dataset targets. Random mixing of different fruits in bins may not represent common real-world scenarios, where fruits are typically harvested in monocultures and packed separately. The paper should outline the dataset's intended use cases and their alignment with real-world applications.\nWhile the paper claims diversity in the dataset, I would argue that diversity should be measured by the variety of objects rather than the sheer number of images and annotations. The paper should address these concerns and clarify how the dataset's diversity aligns with its practical usefulness.\nIn my opinion, the representative images in the paper all look similar, and the lighting variations are synthetic without showing real-world visual phenomena (shadows, reflection). The paper should discuss how these factors affect the dataset's applicability to real-world scenarios and consider potential improvements.\nSome of the language choices throughout the paper, such as the use of \"comprehensive\" to describe the evaluation using two models, are overly grandiose, in my opinion. The paper should adopt more precise and measured language to accurately represent the extent of the evaluation and avoid overstating its findings.\nAs this dataset targets robotic grasping of fruits, I would have liked to see a comparison of using the dataset on 6DOF grasping with a robotic gripper, not only pose estimation.\nQuestions:\nIn the intro, the paper mentions that the dataset contains delicate fruits like bananas and apricots that require haptic feedback for grasping, yet it is not mentioned how this is modeled and incorporated in the benchmark. Is this only in reference to exact pose estimation?\nIn Table 1. how does the presented dataset compare to other 6DOF datasets regarding object diversity?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to the review - Part1", "Subheading": "Official CommentbyAuthors22 Nov 2023, 17:06Everyone", "Content": "Comment:\nDear Reviewer,\nThank you for your insightful comments and constructive feedback. We appreciate the time and effort you\u2019ve put into reviewing our paper. We agree with your concerns and have addressed them as follows:\nReal-world applicability:\nWe acknowledge the limitations of synthetic datasets in replicating real-world conditions. Precise evaluation of our dataset for real fruits is an important question, given that we only have synthetic data.\nWe are currently scanning 3D real fruits and adding 6D pose real-world data to extend our dataset.\nThis dataset will be used for evaluating the sim2real gap of our dataset.\nVariety of objects:\nWe agree that by targeting fruit bin picking, we inevitably limit the variety of shapes. Fruits are indeed mostly smooth compared to artificially created objects, such as industrial objects. However, fruit bin picking is a delicate task that requires careful handling to avoid damaging the fruits. We believe that knowing the semantics of the fruit and its position in the scene is of major importance during the grasping process to avoid any damage.\nNecessity of 6DOF pose estimation:\nWe believe that 6DOF pose estimation isn\u2019t incompatible with simple objects, and it can provide more precise control for robotic arms, even when using suction grippers. However, suction grasping requires fruits to be smooth, like apples, pears, or maybe bananas. In practical use, it will not be suitable for rugous textures such as lemons, oranges, or kiwis.\nIntended use cases:\nThe dataset\u2019s intended uses are multiple, with a goal of making it general for multiple purposes:\nThe first intended use is benchmark making as it gathers major challenges in 6D pose. It comes as a challenge for the community to make improvements in 6D pose estimation as it is commonly used with the popular BOP challenge.\nIn addition to these existing datasets for benchmarking, ours offers a useful and practical scenario that could easily occur in daily scenarios: fruit industry, house fruit bin, or even supermarket.\nMixing fruits in a bin is the most general and difficult scene we could create for 6D pose estimation purposes. However, it is right to note that real-world scenarios, such as industry or supermarkets, usually deal with only one category. In order to address this, we extended our dataset with data with bins of only one category of object.\nDiversity of the dataset\n: We understand your concern about the diversity of the dataset. We have included 8 fruits that we believe are the most common (apple, apricot, banana, kiwi, lemon, orange, peach, and pear). However, it remains in the range of the number of objects used by 6D pose datasets.\nLighting variations:\nWe agree that real-world visual phenomena like shadows and reflections are important. We are cognizant of these limitations and believe that domain randomization is sufficient to reduce the sim2real gap. Moreover, as a general way of addressing the recurrent sim2real gap, data augmentation or domain adaptation can further reduce the sim2real gap, and we demonstrated that a simple diffusion model could generate a good variety of realistic backgrounds and can create shadows or reflections.\nLanguage choices:\nWe have revisited the language by removing some unnecessary adjectives.\nComparison with robotic gripper:\nWe appreciate your suggestion to demonstrate robotic applications such as bin picking using our dataset. For this rebuttal, we haven\u2019t yet included grasping with the real robot. However, as an early proof of concept, a grasping simulation pipeline has been set up as follows:\nWe automatically generate a grasping list associated with the mesh.\nWe evaluate the 6D pose with our trained Densefusion model.\nWe used free obstacle path planning libraries such as MoveIt to grasp the object with the list of grasp and the 6D pose of the object."}, {"Heading": "Answer to the review - Part2", "Subheading": "Official CommentbyAuthors22 Nov 2023, 17:09 (modified: 22 Nov 2023, 20:50)EveryoneRevisions", "Content": "Comment:\nQuestion:\nIn response to your query about modeling haptic feedback for delicate fruits, we currently do not incorporate this aspect into our dataset, as our primary focus is on pose estimation. We have clarified this point in the paper.\nRegarding object diversity, other benchmark datasets typically include between 8 (occluded linemod) and 39 objects (excluding GraspNet-1B, which primarily focuses on 6DOF grasping rather than 6D pose estimation). This is generally more than our dataset, as we focus solely on fruits. However, it\u2019s important to note that even if the number of objects is low, datasets can pose a significant challenge for the 6D pose estimation community, particularly with occlusion. For instance, the popular dataset \u201coccluded-Linemod\u201d also has only 8 objects but remains one of the most challenging datasets. Indeed, in the recent BOP challenge 2023 [4], this dataset was one of the most difficult, with a score of 0.794 achieved by the winner of the challenge. This is compared to 0.928 for \u201cYCB-video\u201d which has 21 objects, or even \u201cHomebrewedDB\u201d with a score of 0.950 with 33 objects.\nWe hope this addresses your concerns.\n[1] Zhongkui Wang, Shinichi Hirai, and Sadao Kawamura. Challenges and Opportunities in Robotic Food Handling: A Review, jan 2022. ISSN 22969144.\n[2] Tobin, Josh, et al. \"Domain randomization for transferring deep neural networks from simulation to the real world.\" 2017 IEEE/RSJ international conference on intelligent robots and systems (IROS). IEEE, 2017.\n[3] Truong, J., Chernova, S., & Batra, D. (2021). Bi-directional domain adaptation for sim2real transfer of embodied navigation agents. IEEE Robotics and Automation Letters, 6(2), 2634-2641.\n[4]\nhttps://bop.felk.cvut.cz/challenges/bop-challenge-2023/"}]}, {"Heading": "Official Review of Submission9289 by Reviewer J2Gb", "Subheading": "Official ReviewbyReviewer J2Gb29 Oct 2023, 04:19 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents FruitBin, a 6D pose estimation dataset for fruit bin picking with benchmarking over scene generalization, camera generalization and occlusion robustness. It contains over a million images and 40 million instance-level 6D poses.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nThis paper proposes a large-scale dataset, which may facilitate future research for bin-picking tasks.\nThe technical details are clearly presented.\nWeaknesses:\nLimited Contribution\nIt seems that the technical contributions of this paper is just replacing the assets in PickSim with fruits. I don't think this contribution is sufficient for an ICLR paper.\nAll the data are collected in the simulator. It seems that no data is collected in the real world.\nInconvient Platform\nThis paper uses ROS+Gazebo as its simulator platform, and claims it's for \"seamless robot learning\". However, I would think mujoco, PyBullet, or Isaac Gym are some more popular options in the robot learning community.\nFormat Issues\nTable 1 and the references are with format issues.\nThe supplementary materials should not be attached to the main paper.\nQuestions:\nWill the dataset include more samples collected in the real world?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to the review", "Subheading": "Official CommentbyAuthors22 Nov 2023, 17:13Everyone", "Content": "Comment:\nDear Reviewer,\nWe are grateful for the time and effort you have invested in reviewing our paper. We appreciate your feedback and would like to address your concerns.\nLimited Contribution:\nWe acknowledge your concern regarding the technical contributions of our paper. However, we believe that our datasets, specifically designed for 6D pose estimation in bin picking, could significantly advance the development of 6D pose estimation models. Our unique dataset brings together major challenges in 6D pose estimation, and its large scale allows for the creation of specific benchmarks. This is not proposed by the current existing datasets. The recent 2023 BOP challenge results highlight that state-of-the-art 6D pose estimation models are still sensitive to complex scenes and occlusion, as evidenced by a drop of 0.1/0.2 for datasets with occlusion and bin picking, indicating room for improvement.\nRegarding the lack of real-world data, we agree that this is a significant limitation. We are currently collecting data from physical setups to enhance our dataset, allowing for a better evaluation of the sim2real gap and the performance of models under real-world conditions.\nInconvenient Platform:\nWe selected ROS+Gazebo due to its widespread adoption in the robotics community and its compatibility with various hardware. While Mujoco, PyBullet, and Isaac Gym are gaining popularity in the robot learning community, we maintain that ROS+Gazebo remains one of the most utilized platforms for robotic simulation [1]. To our knowledge, Mujoco, Pybullet, and Isaac Gym may be more low-level robot learning-oriented than Gazebo+ROS. The latter offers the advantages of a large community and integrates popular high-level libraries such as MoveIt. The default use of ROS enables users to easily apply their developed pipeline to real robots. Specifically to robot learning, even if maybe less popular, Gazebo is still a reliable choice [2,3].\nFormat Issues:\nWe apologize for the formatting issues in Table 1 and the references. These will be corrected in the revised version of the paper, along with the supplementary materials detached from the main paper.\nQuestions:\nIn response to your query, we do indeed plan to include samples collected in the real world in the dataset. We believe this enhancement will increase the dataset\u2019s value for the community.\n[1] Collins, J., Chand, S., Vanderkop, A., & Howard, D. (2021). A review of physics simulators for robotic applications. IEEE Access, 9, 51416-51431.\n[2] Zamora, Iker, et al. \"Extending the openai gym for robotics: a toolkit for reinforcement learning using ros and gazebo.\" arXiv preprint arXiv:1608.05742 (2016).\n[3] Ferigo, D., Traversaro, S., Metta, G., & Pucci, D. (2020, January). Gym-ignition: Reproducible robotic simulations for reinforcement learning. In 2020 IEEE/SICE International Symposium on System Integration (SII) (pp. 885-890). IEEE."}]}, {"Heading": "Official Review of Submission9289 by Reviewer gFnj", "Subheading": "Official ReviewbyReviewer gFnj27 Oct 2023, 11:15 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper tackles novel research direction of fruits (or generalized any grocery item) using a robo-arm.\nDataset uses RGB and depth cameras for curating and annotatings the dataset.\nSoundness:\n4 excellent\nPresentation:\n4 excellent\nContribution:\n3 good\nStrengths:\nThis industry really needs a good dataset to further explore the problem, this paper just targeted that.\nThis paper generalizes scenes as well as camera position for wider acceptability of it.\nGood reference to prior work on datasets.\nWeaknesses:\nI would have preferred to see even more robust baselines.\nQuestions:\nNA\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to the review", "Subheading": "Official CommentbyAuthors22 Nov 2023, 17:15Everyone", "Content": "Comment:\nDear Reviewer,\nThank you for your review and positive feedback on our paper. We are pleased that you found our research direction and dataset valuable for the industry.\nWe appreciate your suggestion regarding the need for more robust baselines. Although Pvnet and Densefusion are getting outperformed by recent methods, we believe that they remain representative baselines. It is worth noting that even with the recent results of the 6D pose BOP challenge 2023 [3], the difficulties are still the same. We can highlight non-negligible performance differences for occluded or cluttered datasets (LM-O, IC-BIN, ITODD) with scores below 0.8 and better than 0.9 for less occluded and cluttered ones (T-LESS, YCB-V). This strengthens the need for occlusion study in 6D pose estimation and benchmarks.\nWe understand the importance of strong baselines in demonstrating the effectiveness of our approach.\nWe are working to integrate GRD-NET\n[1][2], which has been \u201cThe Best Open-Source Method\u201d for the benchmarks in the BOP challenge in 2022 and 2023[3], to provide a more precise evaluation of our dataset.\nOnce again, we thank you for your time and constructive feedback. We look forward to incorporating your suggestions to improve our work.\n[1]Wang, Gu et al. \u201cGDR-Net: Geometry-Guided Direct Regression Network for Monocular 6D Object Pose Estimation.\u201d 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2021): 16606-16616.\n[2]\nhttps://github.com/shanice-l/gdrnpp_bop2022\n[3]\nhttps://bop.felk.cvut.cz/challenges/bop-challenge-2023/"}]}, {"Heading": "Official Review of Submission9289 by Reviewer bGzb", "Subheading": "Official ReviewbyReviewer bGzb23 Oct 2023, 11:34 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces a large-scale PickSim-based synthetic dataset FruitBin for 6D object pose estimation in fruit bin picking. The dataset features comprehensive challenges and devised benchmarks for scene and camera view generalization as well as occlusion.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThis is the first 6D object pose estimation dataset tailored for fruit bin picking although it is synthetic.\nWeaknesses:\n-- One drawback of Gazebo is that it can not do photorealistic rendering for objects and scenes with PBR textures. Although the generated dataset is large, without photorealistic textures, the transfer ability to real world is limited compared with other simulators such as BlenderProc and Kubric even the domain randomization techniques have been leveraged.\n-- For real-world fruits, the size and shape of different instances of the same category vary to different degrees. However, it seems for FruitBin, these factors are not taken into consideration.\n-- There is no real test set for the dataset, which is essential for sim2real and real-world applications.\n-- The benchmarking methods are a bit outdated. PVNet and DenseFusion are from 2018-2019, but it is 2023 now.\n-- It would be better to showcase some robotic applications like bin picking using this dataset, since it is targeted for fruit bin picking.\n-- It would be better to mark symmetric objects with \"*\" in Table 2.\n-- Table 1 is too wide.\n-- There are some minor issues in the writing, more thorough proofreading is required.\nQuestions:\nIn the experiments, does PVNet use GT bboxes for cropping the objects in order to handle multiple instances of the same object class?\nHow does the diffusion generated backgrounds contribute to the performance?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to the review", "Subheading": "Official CommentbyAuthors22 Nov 2023, 17:26Everyone", "Content": "Comment:\nDear Reviewer,\nWe are grateful for your comprehensive review and constructive feedback on our manuscript. We have taken the time to address each of your comments and concerns as follows:\nPhotorealistic Rendering:\nWe concur with your observation regarding the limitations of Gazebo in terms of photorealistic rendering. While state-of-the-art generators such as Blenderproc and Kubric offer some advantages, they lack crucial occlusion annotation. Furthermore, we emphasize that models trained on our dataset can be integrated and tested for robotic simulation, a feature not guaranteed with Kubric and Blenderproc (we are not certain that the PBR rendering can be integrated on a camera in Pybullet, for example).\nWe are cognizant of these limitations and believe that domain randomization is sufficient to reduce the sim2real gap. Moreover, as a general way of addressing the recurrent sim2real gap, data augmentation or domain adaptation [4] can further reduce the sim2real gap, and we demonstrated that a simple diffusion model can generate a good variety of realistic backgrounds.\nVariation in Fruit Size and Shape:\nWhile our current focus is on 6D pose estimation, we acknowledge the lack of variation in size and shape. Although not part of the benchmark yet, we leveraged PickSim to generate testing data where random scale variation over the three directions is applied to vary the shapes. Additionally, to answer real-world scenarios of industry and supermarkets, we generated bin picking for only one type of object. This comes with two variations: one where the mesh is unique and the second where mesh modification is applied.\nReal Test Set:\nWe agree with your assertion on the importance of a real test set for sim2real and real-world applications. To this end, we intend to augment our dataset with real-world data to create a test set for evaluating sim2real performance.\nBenchmarking Methods:\nWe concur that our benchmarks should include more recent methods. Although Pvnet and Densefusion are getting outperformed by recent methods, we believe that they remain representative baselines. It is worth noting that even with the recent result of the 6D pose BOP challenge 2023 [3], the difficulties are still the same. We can highlight non-negligible performance differences for occluded or cluttered datasets (LM-O, IC-BIN, ITODD) with scores below 0.8 and better than 0.9 for less occluded and cluttered ones ( T-LESS, YCB-V). This strengthens the need for occlusion studies in 6D pose estimation and benchmarks.\nWe understand the importance of strong baselines in demonstrating the effectiveness of our approach, and\nwe are working to integrate GRD-NET\n[1][2], which has been \u201cThe Best Open-Source Method\u201d for the benchmarks in the BOP challenge in 2022 and 2023[3] to provide a more precise evaluation of our dataset.\nRobotic Applications:\nWe appreciate your suggestion to demonstrate robotic applications such as bin picking using our dataset. For this rebuttal, we haven\u2019t yet included grasping with the real robot. However, as an early proof of concept, a grasping simulation pipeline has been set up as follows:\nwe automatically generate a grasping list associated with the mesh,\nwe evaluate the 6D pose with our trained Densefusion model\nwe used free obstacle path planning libraries such MoveIt to grasp the object with the list of grasp and the 6D pose of the object\nSymmetric Objects in Table 2:\nWe thank you for your suggestion and denoted symmetric objects with an asterisk (*) in Table 2 in the revised version of the paper.\nWriting Issues:\nWe will address the writing issues you pointed out, including reducing the size of Table 1, separating additional work from the main paper, and improving the marking of symmetric objects in Table 2.\nQuestions:\nPVNet and GT Bboxes:\nIn all our generated benchmarks, we have only considered 1 instance of a category in the data. The filtering parameters for the benchmarks\"\nDiffusion-Generated Backgrounds:\nThe diffusion backgrounds have only been tested to showcase the feasibility of improving the sim2real gap. However, we haven\u2019t explored how it would impact the model for 6D pose estimation. \nWe hope that our responses address your concerns.\n[1]Wang, Gu et al. \u201cGDR-Net: Geometry-Guided Direct Regression Network for Monocular 6D Object Pose Estimation.\u201d 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2021): 16606-16616.\n[2]\nhttps://github.com/shanice-l/gdrnpp_bop2022\n[3]\nhttps://bop.felk.cvut.cz/challenges/bop-challenge-2023/\n[4] Truong, J., Chernova, S., & Batra, D. (2021). Bi-directional domain adaptation for sim2real transfer of embodied navigation agents. IEEE Robotics and Automation Letters, 6(2), 2634-2641."}]}]}, "lmYGRGyL4i": {"paper_info": {"Primary Area": "generative models", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Graph generation, One-shot generation, Autoregressive generation, Unified framework, Diffusion Model, Molecule generation", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We propose a mathematical framework called Insert-Fill-Halt which unifies one-shot and sequential graph generative models. One-shot models adapted for autoregressive generation are competitive with the state of the art.", "Abstract": "In the field of deep graph generative models, two families coexist: one-shot models, which fill the graph content in one go given a number of nodes, and sequential models, where new nodes and edges are inserted sequentially and autoregressively. Recently, one-shot models are seeing great popularity due to their rising sample quality and lower sampling time compared to the more costly autoregressive models. With this paper we unify the two worlds in a single framework, unlocking the whole spectrum of options where one-shot and sequential models are but the two extremes. We use the denoising diffusion models' theory to develop a node removal process, which destroys a given graph through many steps. An insertion model reverses this process by predicting how many nodes have been removed from the intermediate subgraphs. Then, generation happens by iteratively adding new blocks of nodes, with size sampled from the insertion model, and content generated using any one-shot model. By adjusting the knob on node removal, the framework allows for any degree of sequentiality, from one-shot to fully sequential, and any node ordering, e.g., random and BFS. Based on this, we conduct the first analysis of the sample quality-time trade-off across a range of molecular and generic graphs datasets. As a case study, we adapt DiGress, a diffusion-based one-shot model, to the whole spectrum of sequentiality, reaching new state of the art results, and motivating a renewed interest in developing autoregressive graph generative models.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9287", "PDF Url": "https://openreview.net/pdf?id=lmYGRGyL4i"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9287 by Area Chair qxuc", "Subheading": "Meta ReviewbyArea Chair qxuc05 Dec 2023, 17:45 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper propose a d Insert-Fill-Halt (IFT) framework for graph generation, bridging the gap between one-shot graph generation with the sequential graph generation. Despite the interesting idea and import problem of graph generation it tackles, the manuscript may need another round of polish based on the reviewer's discussion for it to be published.\nJustification For Why Not Higher Score:\nThe novelty is limited and the experiment was not done thoroughly to support the claims.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Answer to all reviewers", "Subheading": "Official CommentbyAuthors22 Nov 2023, 07:40 (modified: 23 Nov 2023, 06:39)EveryoneRevisions", "Content": "Comment:\nWe thank all reviewers for their insightful feedback and suggestions. We took in great consideration your comments, and revised our manuscript as follows:\nWe added a Discussion section (numbered 6) discussing the choice of the degree of sequentiality with respect to the dataset and the task. Limitations of our model are also presented.\nWe have cleared up the Experiments section, including our definition of degree of sequentiality. We also improved the explanation of our selection study and the discussion of the obtained results.\nWe expanded the experimental assessment by adding DiGress as a molecular baseline. Moreover, in order to give a more coherent presentation,  we have split Tables 2 and 3 into subtables for performance results (2a, 2d, 3b, 3c), subtables for training complexity (2b, 2e, 3d), and subtables for generation complexity (2c, 2f, 3e). We have also clarified in Table 3a what we mean by seq-1, seq-small, and seq-big for generic graphs generation.\nWe have moved the section devoted to generic graph generation into Appendix A, and expanded the discussion on our findings. We hope that this can make the section more accessible.\nWe added training and generation algorithms in Appendix D, together with a discussion on how DiGress has been adapted.\nWe slimmed down redundant parts of the paper (to make space for the new discussion section) and corrected typos.\nWe are currently running experiments on the GRAN Grid dataset. As soon as we get the results we will add them in the Appendix.\nUpdate:\ndue to technical difficulties we were not able to finalize the additional experiments on the Grid dataset. However, we believe that our method has already been evaluated on a significantly wide array of popular datasets, among which molecular and generic graphs. To the best of our knowledge, the Grid dataset has only been used in GRAN[1].\n[1] Liao, Renjie, Yujia Li, Yang Song, Shenlong Wang, Will Hamilton, David K. Duvenaud, Raquel Urtasun, and Richard Zemel. \"Efficient graph generation with graph recurrent attention networks.\" Advances in neural information processing systems 32 (2019)."}, {"Heading": "Official Review of Submission9287 by Reviewer HNVY", "Subheading": "Official ReviewbyReviewer HNVY04 Nov 2023, 14:51 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a new Insert-Fill-Halt (IFH) framework for graph generation, which tries to bridge two types of existing approaches, i.e., one-shot generation and sequential generation. Specifically, at each step, the Insertion Model chooses how many new nodes to generate, the Filler Model fills the new nodes\u2019 labels, features, and connections, and the Halt Model chooses if the generation needs to terminate. The training of the IFH framework uses the denoising diffusion model to develop a reversed node removal process, which destroys a given graph through many steps. Experimental results demonstrate the sample quality-time trade-off across a range of molecular and generic graphs datasets.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nIt is interesting to bridge one-shot and sequential graph generation methods with a unified framework.\nAuthors provide the analysis of the sample quality-time trade-off across many real-world datasets.\nThe paper is well-written and easy to understand.\nWeaknesses:\nThe proposed framework does not provide insightful knowledge regarding choosing one-shot or sequential generation methods.\nOnly one base model is tested in the proposed IFH framework.\nExperiments are not sufficient. Ablation studies are missing. The comparisons of time/memory cost with baselines are missing.\nQuestions:\nPlease see my listed weakness above.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to reviewer HNVY", "Subheading": "Official CommentbyAuthors22 Nov 2023, 07:28Everyone", "Content": "Comment:\nWe thank you for the review and for acknowledging our work's main points. We are glad to resolve any doubt in the following.\nW1: The proposed framework does not provide insightful knowledge regarding choosing one-shot or sequential generation methods.\nWe thank you for bringing up this point. We added a new \"Discussion\" section (numbered 6) to discuss further the empirical results, and how one might choose one-shot, sequential, or an in-between option.\nTo summarize, our advice is to use one-shot models for smaller graphs, and go towards 1-node sequential models for bigger graphs to improve performance. When the graphs reach very large sizes, however, the halting signal becomes sparser, making the halting model harder to train. For these cases, going back to a hybrid solution can help, also in terms of memory and time consumption.\nOur proposed framework makes it possible to compare one-shot and sequential models that share the same architecture and generative model, with the degree of sequentiality becoming a hyperparameter. In fact, our experiments suggest that for different distributions of graphs, different levels of sequentiality will improve performance and resource usage. This is useful for the future design of graph generative models, as new architectures can be seamlessly adapted to sequential or one-shot generation, pushing their performances further than their native modality. Additionally, we discussed in Section 4.3 the complexity in time and memory of increasing sequentiality. Experimental results are consistent with the above statements.\nW2: Only one base model is tested in the proposed IFH framework.\nThis is certainly a valid observation. One of our work's aims is to prove the feasibility of adapting a one-shot model to act in a sequential setup and observing whether this leads to an improvement. In the case of adapting DiGress, we got competitive results with the state-of-the-art one-shot models while beating by a significant margin autoregressive baselines, so we can say that the initial claim has had a positive outcome. We think adapting other one-shot models would be the next step, but we preferred to postpone it in favor of a more extended explanation of the framework.\nW3: Experiments are not sufficient. Ablation studies are missing. The comparisons of time/memory cost with baselines are missing.\nRegarding your first concern, we think we disguised the reader in dubbing the ablation study \"Selection study\". Actually, in that section we perform a similar study (on block generation formulation and different orders) as the one done in the GRAN paper under the section dubbed \"Ablation study\". If this is not resolving your issue, we would be happy to receive more information about what additional experiments we should perform.\nWe gladly answer the second concern by referring to our selection study, which we clarified in Section 5.1, commenting on Table 1. There, we compared several instances of our model changing the removal process and node ordering in a grid. This is a selection study from the perspective of choosing the best combination of the two. At the same time, we are also isolating the contributions of the two factors, making it also an ablation study. In Section 5.1, we commented on such contributions, noting that both BFS and categorical removal independently improve performance, computational time, and memory. This latter analysis is characteristic of an ablation study. Furthermore, in the remainder of the experiments, we explore how the degree of sequentiality affects results.\nRegarding your last concern, in this work, we want to compare time/memory cost within a given model (DiGress in our case), varying the degree of sequentiality. With this analysis, we can actually understand the contribution of changing the degree of sequentiality."}]}, {"Heading": "Official Review of Submission9287 by Reviewer 9h17", "Subheading": "Official ReviewbyReviewer 9h1702 Nov 2023, 19:29 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper explores combining autoregressive method with one-shot diffusion model. Diffusion model builds the forward process with adding noise gradually and the backward process with removing noise step-by-step. Similarly but not the same, the paper models the forward process as removing block of nodes and edges gradually towards an empty graph, and in backward process it reverts this process with adding nodes and edges back. This view combines autoregressive method and one-shot method together, via changing the granularity of node/edge removing. The author also discussed many different choice of node/edge removing random process. The experimental results show certain improvement on molecular datasets.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nExploring the direction of combining autoregressive method and one-shot diffusion model is meaningful, as they have different strength. The proposed method successfully combined them together, and the proposed process of block removing is interesting.\nThe author shows that the complexity of sequential model is lower than one-shot generation, and discussed its strength in section 4.3. This is interesting, and engineering wise one can use sparse storage for already generated components to save runtime and memory.\nOne key component of this proposed process is the block removing process, and the author discussed many choice with ablation studies.\nWeaknesses:\nThe proposed method shares certain similarity with GRAN, while being novel for adapting diffusion process inside.\nThe goal of combining autoregressive method and one-shot generation is to combine their strength together while eliminate their shortcomings. However I think the proposed method is not ideal for this goal. For example, one-shot diffusion is a permutation equivariant generation model that is invariant to node permutation, here the designed model becomes ordering sensitive, which needs a careful ablation over node removing process. And autoregressive method has the problem of being hard to parallel during training, hence the designed model will be even slower in training comparing with one-shot generation. Last, the reported experimental result doesn't show a significant benefit of adapting sequential generation to one-shot diffusion.\nThe experimental result is kind of weak at current stage. First, for both QM9 and ZINC, the result doesn't beat the baseline like CDGS in many perspective. Second, for generic graph generation in Appendix, the designed method is significantly worse than the baseline. This questions whether the designed method, while being combination of autoregressive and one-shot, may suffers from the shortcoming of both sides instead of combining their strengths. Also, the designed method may suffer from the randomness of block removing process.\nI suggest the author also discuss the training cost instead of just the test runtime and memory cost.\nQuestions:\nFor Table 2, there is no result for the baseline DiGress, is that equivalent to one-shot?\nIt seems that you have many different models trained: halting model, node size prediction model, and one denoising model. Can you talk about how do you do model selection for them?\nYou mentioned that you can use sparse format for already generated part, are you using this format during training?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to reviewer 9h17 1/2", "Subheading": "Official CommentbyAuthors22 Nov 2023, 07:31Everyone", "Content": "Comment:\nThank you for your valuable comments, which we found interesting discussion points.\nW1: The proposed method shares certain similarity with GRAN, while being novel for adapting diffusion process inside.\nWhile it is true that our proposed method shares similarities with GRAN regarding block generation, our framework is capable of capturing every aspect of the data distribution, in particular the size of sampled graphs, thanks to learning a node-insertion and halting model. A notable limitation of GRAN is that it fixes the size of blocks as a hyperparameter, and the number of nodes generated to the maximum size of the dataset. This warps the output distribution, favoring bigger graphs, and making it challenging to generate smaller graphs. Additionally, IFH can be used to design any autoregressive block generation scheme, GRAN included.\nW2: The goal of combining autoregressive method and one-shot generation is to combine their strength together while eliminate their shortcomings. However I think the proposed method is not ideal for this goal. For example, one-shot diffusion is a permutation equivariant generation model that is invariant to node permutation, here the designed model becomes ordering sensitive, which needs a careful ablation over node removing process. And autoregressive method has the problem of being hard to parallel during training, hence the designed model will be even slower in training comparing with one-shot generation. Last, the reported experimental result doesn't show a significant benefit of adapting sequential generation to one-shot diffusion.\nWhile we agree that autoregressive models have the added burden of having to select the best node ordering, we found empirically that choosing the BFS order was enough to make our approach competitive with the best one-shot baselines.\nRegarding the fact that autoregressive models are hard to parallel during training: not entirely, as we sample the entire sequences from a batch of graphs, and train on the collected examples in parallel, because no hidden states are passed between steps. This characteristic was also implemented in GRAN, as it avoids the problem you mentioned. Following your suggestion, we added the time/memory tables for the training processes (Tables 2b, 2e, 3d) to show how sequentiality affects the time to reach convergence: our 1-node sequential model takes longer to train for a fixed amount of epochs, but reaches optimal validation performance much faster.\nOn the last point, we showed in our experiments that adapting the one-shot model in question (DiGress) consistently improves performance for some degree of sequentiality (mostly 1-node sequentiality). One notable example is ZINC, where our 1-node sequential model surpasses CDGS on many metrics, and the original DiGress on all metrics.\nMotivated by these findings, we hypothesize that having a permutation equivariant model is not the only ingredient for a good-performing generative model. For example, breaking the sampling process into smaller steps might help reduce each atomic step's complexity. We have seen a similar phenomenon for diffusion models, sequentially denoising a sample in many steps, which beat fully one-shot models like VAEs and GANs.\nOur answer continues in the below comment."}, {"Heading": "Answer to reviewer 9h17 2/2", "Subheading": "Official CommentbyAuthors22 Nov 2023, 07:32Everyone", "Content": "Comment:\nW3: The experimental result is kind of weak at current stage. First, for both QM9 and ZINC, the result doesn't beat the baseline like CDGS in many perspective. Second, for generic graph generation in Appendix, the designed method is significantly worse than the baseline. This questions whether the designed method, while being combination of autoregressive and one-shot, may suffers from the shortcoming of both sides instead of combining their strengths. Also, the designed method may suffer from the randomness of block removing process.\nAlthough we do not beat the strong one-shot baseline CDGS in every metric, there are many where we reach state-of-the-art results, mainly in the challenging ZINC dataset. Also, note that Uniqueness and Novelty are not so informative metrics at this stage (as all methods reach good results), and we included them to comply with earlier works.\nWe wouldn't say that our method is significantly worse for generic graph generation, as it is still state-of-the-art in autoregressive models, surpassing GRAN, and competitive with CDGS.\nWe think that our approach effectively combines the strengths of one-shot and autoregressive models, as we see a significant improvement over the latter category, and specifically over our one-shot variant. On the other hand, as you point out, some shortcomings are still present. For example, the great number of generation steps in 1-node sequential models can hinder performance and the effective learning of the halting model. We addressed this limitation in the new Discussion section 6. Another one can be the randomness of the block-removing process, which can be transformed into a strength if it is tailored for a specific task, e.g., motif generation in a molecular setup. This is entirely allowed by our framework.\nW4: I suggest the author also discuss the training cost instead of just the test runtime and memory cost.\nWe thank you for the suggestion and added the \"Training time/memory\" tables (2b, 2e, 3d) on the side of each performance comparison table. Additionally, we discussed these tables in the \"Time and memory consumption\" paragraph of Section 5.1.\nQ1: For Table 2, there is no result for the baseline DiGress, is that equivalent to one-shot?\nWe did not immediately include DiGress in our baselines because we are adapting the model into our framework. However, following your question, we added DiGress as one of the baselines for Table 2 for the following reason: in Section 5, we explain that the version incorporated comes without domain-specific knowledge and minor adjustments, so the one-shot variant is not quite DiGress. It is then meaningful to compare with it.\nQ2: It seems that you have many different models trained: halting model, node size prediction model, and one denoising model. Can you talk about how do you do model selection for them?\nWe used the hyperparameters from the DiGress paper for the filler model, which showed good performance from the get-go. Regarding the halting and insertion model, we chose the best-performing set of hyperparameters from a random sample. Every selection choice was conducted on the validation set. Thanks to the modularity of our framework, each model can be trained and evaluated separately with respect to network hyperparameters.\nQ3: You mentioned that you can use sparse format for already generated part, are you using this format during training?\nThanks for your interest in how we represent graphs. You are correct. We are using the sparse format also during training, in particular: (1) we build the whole removal sequence in sparse format, saving the removed subgraphs (and edges), (2) we train the halting and insertion models on the sparse representations; (3) we transform the removed subgraphs and edges to dense (applying the batching rules) and train the filler model. Motivated by your interest, we added in Appendix D.1 the two algorithms for training and generation of our framework, highlighting the usage of sparse and dense representations in the section."}]}, {"Heading": "Official Review of Submission9287 by Reviewer H5VJ", "Subheading": "Official ReviewbyReviewer H5VJ01 Nov 2023, 05:31 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper unifies the one-shot and autoregressive graph generation methods into a diffusion framework and proves that these two methods are two extremes of the unified model. Specifically, in the forward phase, blocks, i.e., a set of nodes, are gradually removed as the noise increases. In the backward phase, blocks are gradually added as the denoising process proceeds. When the block size is set to 1, the diffusion model degenerates to an autoregressive approach. When the block size is equal to the graph size, the diffusion model becomes a one-shot method. Experiments on both molecular and generic graphs witness a trade-off between the quality and time of sampling.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThis paper unifies the autoregressive and one-shot graph generation methods into a unified diffusion model, where the removal of nodes is used as the forward process and the generation of nodes is the denoising process. The idea is sound and interesting.\nThe proposed method trade-offs the quality and time of sampling. The proposed method outperforms state-of-the-art autoregressive methods when degenerating to 1-node sequential.\nWeaknesses:\nThis paper combines the ideas of autoregressive graph diffusion [1] and block generation [2]. Although the combination is natural, I am not clear on the main difference between the proposed method and GRAN. It seems that the unity of autoregression and one-shot is due to the design of block generation, rather than the diffusion of node removal.\nIt's not clear to me what advantages 1-node IFH has over autoregressive methods. Does the benefit come from the prediction of the number of nodes?\nThe time and memory costs of baselines are not reported in Tables 2 and 3. It is therefore impossible to see the trade-off between sampling quality and time.\n[1] Autoregressive Diffusion Model for Graph Generation. ICML 2023.\n[2] Efficient Graph Generation with Graph Recurrent Attention Networks. NeurIPS 2019.\nQuestions:\nSee weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to reviewer H5VJ", "Subheading": "Official CommentbyAuthors22 Nov 2023, 07:34Everyone", "Content": "Comment:\nWe thank you for the comments, and we are happy to resolve any doubts.\nW1: This paper combines the ideas of autoregressive graph diffusion [1] and block generation [2]. Although the combination is natural, I am not clear on the main difference between the proposed method and GRAN. It seems that the unity of autoregression and one-shot is due to the design of block generation, rather than the diffusion of node removal.\nWe are happy to clarify the difference with GRAN. Although the idea of using block generation is shared between IFH and GRAN, it has been adopted even earlier and falls into the category of motifs generation. Ours is a way to generalize the concept and unify it with sequential and one-shot generation to reap the benefits of both. On the other hand, the GRAN paper does not provide any information nor a way of integrating one-shot models into the sequentiality spectrum. The block generation mechanism is a way of controlling the degree of sequentiality, yes, but it is fixed and built into the model. Our approach allows the design of any Markov scheme for adding blocks, also with varying sizes, and has a direct link with the distribution in the dataset (as the insertion and halting models are trained accordingly). On the other hand, GRAN does not provide an explicit way to model the distribution of the number of nodes, fixing this number to the maximum size in the dataset, and delegating to the mixture of Bernoullis the task of generating connected components with some size. Furthermore, the GRAN approach might work for datasets with similar-sized graphs. Still, when there is a considerable variance, smaller graphs are penalized due to picking the biggest connected component of a generated graph, changing the output distribution of the model.\nRegarding your last point, you are partially correct, as the design of block generation and the diffusion of node removal are two faces of the same coin, which are the removal and insertion models. However, the block generation of GRAN is fixed and built into the model, and does not consider how the distribution of graph sizes of a dataset behaves.\nW2: It's not clear to me what advantages 1-node IFH has over autoregressive methods. Does the benefit come from the prediction of the number of nodes?\nActually, the 1-node IFH is an autoregressive model, that is, any autoregressive model that generates one node at a time is a 1-node IFH (as pointed out in Section 4.1). In this case, the advantage is that, with our framework, we can adapt strong one-shot models for the 1-node generation modality, beating the autoregressive baselines, which usually implement tailored and simple models for inserting one node. We think this is one of the strongest capabilities of our IFH model.\nW3: The time and memory costs of baselines are not reported in Tables 2 and 3. It is therefore impossible to see the trade-off between sampling quality and time.\nNot quite, as our sampling quality/time trade-off analysis is intended for our framework, assessing what changes when we change the degree of sequentiality with the filler model in question. The comparison with the baselines in Table 2 aims to place our proposed approach in the state of the art, showing whether our framework is capable of generating performing models. To highlight this fact, we separated Table 2 into performance results and time/memory usage table."}]}, {"Heading": "Official Review of Submission9287 by Reviewer yahf", "Subheading": "Official ReviewbyReviewer yahf31 Oct 2023, 22:29 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors propose a generalization of deep graph generative models that results in a spectrum between one-shot models and sequential models. They take inspiration from diffusion model theory to train a model on the corruption of graphs (removal of blocks of the node) to learn how to insert multiple nodes and fill in edges. They adapt a diffusion-based one-shot model DiGress to their approach (1-node sequential) and show that it outperforms state-of-the-art on some datasets.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe method unifies one-shot and sequential generation methods and opens up new opportunities for searching for new graph generation methods.\nEvaluation covers several datasets and metrics.\nWeaknesses:\nPerformance on other datasets\n- The paper presents the evaluations on two datasets in the main content and three datasets in the appendix. While the proposed approach outperforms the state-of-the-art in the former two, multiple one-shot methods outperform the proposed approach. This undermines the impact of the new approach. Also, it is not clear why only the two datasets with good performance were shown in the main paper. How about other datasets that have been used in prior work, such as Grid, Protein, and 3D point-cloud?\nWhile the method unlocks a spectrum between one-shot and sequential models, it does not present a way to choose one from the spectrum. How many nodes should be added per step? Is this a hyperparameter? The presented experiments show that seq is better. Does \"seq\" refer to 1 node per step? There are seq-small and seq-big in the Appendix, but none of the variations outperform CDGS except for one metric on one dataset.\nPresentation Issues\n- While the writing is understandable, there are several presentation issues. For example:\nDefinition 6: \"\nAn\nhalting process ... .\" Also, I don't think the first sentence completely defines the halting process; the second sentence does. So, this should be rewritten.\nPage 6: \"On the other hand, ...  such as VAE, Normalizing Flow, Diffusion\" is missing an\nand\n.\nQuestions:\nAddressing the following would significantly improve my score\nAmong the five datasets presented, the proposed approach does not outperform other methods in majority of the metrics. Can the authors  justify the utility of their approach given these results?\nHow to select $r_s$ and what are the differences between seq, seq-small, and seq-big?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to reviewer yahf", "Subheading": "Official CommentbyAuthors22 Nov 2023, 07:36 (modified: 23 Nov 2023, 06:41)EveryoneRevisions", "Content": "Comment:\nThank you for your comments and for asking for additional motivation for our work. We find that clarifying this point is of utmost importance. Let us start by answering your questions.\nQ1: Among the five datasets presented, the proposed approach does not outperform other methods in majority of the metrics. Can the authors justify the utility of their approach given these results?\nWhile it is true that the strongest one-shot baseline CDGS outperforms our approach in generic graphs datasets, our experiments show that increasing the degree of sequentiality with the chosen one-shot model DiGress leads to state-of-the-art results with respect to autoregressive generation, while also being competitive, if not better in many metrics, in molecular generation.\nMetrics comparison versus other methods helps to answer whether our best instance of the IFH model can be useful for good quality generation. However, we argue that this is not the only criterion for choosing a good model, and through our sample quality/memory/time trade-off analysis we investigated other aspects. In particular, how the degree of sequentiality influences performance, computing time, and memory consumption. These latter aspects might be needed for some kinds of datasets, e.g. big sized graph datasets, where we showed an improvement of 50 times less memory usage.\nConceptually, we think one of the main take-home messages of our work is that, when designing new graph generative models, be it one-shot or autoregressive, there is always a way to explore the whole spectrum with it, trading off memory, time, and quality, and perhaps push its native performances. To do so, one can use our mathematical framework, which can be a way of standardizing techniques as building blocks.\nQ2: How to select\u00a0$r_s$\u00a0and what are the differences between seq, seq-small, and seq-big?\nActually, we don't manually select $r_s$ but design the process that stochastically generates $r_s$. Your question can be answered by our sample quality/time/memory trade-off analysis, in which we showed a significant improvement when using smaller block sizes concerning generation quality and memory, but not in time (due to not being able to parallelize during generation as well as one-shot models). When increasing the block sizes, we get the inverse, even though for larger datasets, we see that having larger blocks, but not too large, improves quality and time, so there must be a sweet spot depending on the size of the graphs in the dataset. To summarize, our empirical advice is to use one-shot models for smaller graphs, and go towards 1-node sequential models for bigger graphs. When graphs get too big, having a small block size requires a solid halting process, because the halting signal becomes very sparse in a setup with a huge number of steps. For this reason, increasing the block size to reduce the number of steps can help. We reported these points in the new Discussion section (numbered 6).\nWe thank you for inquiring about the meaning of the levels of sequentiality in generic graphs. We updated the appendix section to explain better what we are doing in those experiments.\nWe also would like to answer the proposed weaknesses which we did not answer above.\nIt is not clear why only the two datasets with good performance were shown in the main paper.\nWe made this choice due to page limitations (as generic graphs datasets tables occupy quite a lot of space) and because the related work from which we took major inspiration for our experimental setup (CDGS) put much more emphasis on molecular datasets. To address this as best as possible, we moved the generic graphs section to Appendix A to make it more accessible from the main text.\nHow about other datasets that have been used in prior work, such as Grid, Protein, and 3D point-cloud?\nThank you for the suggestion. We see that these are the datasets used in GRAN, which are not so widely adopted in more recent works. Although we already provided a wide range of datasets for evaluating our approach, we will add experiments for the Grid dataset, which is the one where the ablation study for GRAN was conducted. We consider this as a way of comparing our approach to theirs, and see whether we get an improvement. We will get back with the results soon.\nUpdate:\ndue to technical difficulties we were not able to finalize the additional experiments on the Grid dataset. However, we believe that our method has already been evaluated on a significantly wide array of popular datasets, among which molecular and generic graphs. To the best of our knowledge, the Grid dataset has only been used in GRAN."}]}, {"Heading": "Official Review of Submission9287 by Reviewer gvwJ", "Subheading": "Official ReviewbyReviewer gvwJ31 Oct 2023, 03:35 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents a diffusion-based graph generative model that unifies both one-shot and autoregressive generative models. The node removal process is conducted with a denoising diffusion model and the insertion reverses the process by predicting the number of nodes that have been removed. Setting the number of nodes from 1 to n enables the unification of one-shot and autoregressive generation.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThis paper proposes the novel unification between one-shot and autoregressive graph generative models using diffusion models.\nThe introduction of flexible-sized block-wise generation for graph generation stands out as a noteworthy contribution.\nWeaknesses:\nCan the unification of one-shot and autoregressive graph generative models be a strong contribution? For instance, GRAN (Liao et al., 2019) can also be the unification between one-shot and autoregressive graph generative model by setting the block size as the number of nodes. What is the key difference of the work from GRAN except for the usage of diffusion models?\nI wonder if it is proper to say the performance as the new state-of-the-art results as mentioned in the abstract. The FCD for QM9 and NSPDK for ZINC do not seem to be state-of-the-art results. Also, as the authors adapted DiGress, the performance comparison with DiGress can be meaningful.\nLack of detailed analysis on the sample quality-time trade-off. A more detailed analysis of the correlation between the sample quality and time (or memory consumption) is needed by comparing the one-shot and autoregressive versions of the IFH model.\nQuestions:\nWhich level of sequentiality did the authors use (I cannot find details in appx D.)? Does the degree of sequentiality imply the block size (or the number of steps)?\nThe generic graph generation results in appx B do not look good enough. Is there any particular reason that the model works okay for molecular graphs but not for non-attributed generic graphs?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to reviewer gvwJ", "Subheading": "Official CommentbyAuthors22 Nov 2023, 07:38Everyone", "Content": "Comment:\nWe thank you for your review and for asking for further details. We are happy to resolve all doubts.\nW1: Can the unification of one-shot and autoregressive graph generative models be a strong contribution? For instance, GRAN (Liao et al., 2019) can also be the unification between one-shot and autoregressive graph generative model by setting the block size as the number of nodes. What is the key difference of the work from GRAN except for the usage of diffusion models?\nWe lean towards a positive answer, as we not only unify the one-shot and autoregressive paradigms, but also show how one can be adapted to the other. We also provide a formal way of designing new graph generative models without having to strictly choose between autoregressive and one-shot: one could design a new one-shot model, and quickly try the same formulation with different levels of sequentiality, trading off computational time and memory usage, and looking at how it affects performances. In a way, we unlock the level of sequentiality as a hyperparameter that can be tuned in any model to further improve quality and resource factors.\nWe think the key difference between our IFH framework and GRAN is flexibility: GRAN makes a lot of assumptions, such as fixing the number of generated nodes to the maximum number of nodes in a dataset (actually the biggest multiple of the fixed block size), and cannot capture the true distribution on the number of nodes of a dataset. For this reason, there is a bias towards large graphs, as the biggest connected component is picked, and smaller graphs are not sampled.\nW2: I wonder if it is proper to say the performance as the new state-of-the-art results as mentioned in the abstract. The FCD for QM9 and NSPDK for ZINC do not seem to be state-of-the-art results. Also, as the authors adapted DiGress, the performance comparison with DiGress can be meaningful.\nWe agree that for some metrics, the best one-shot baseline CDGS outperforms our approach. However, our sequential instances improve by a significant margin the autoregressive state-of-the-art, as shown in Table 2, while being competitive with CDGS. We thank you for recommending adding DiGress as a baseline, and we did so in the revised manuscript.\nW3: Lack of detailed analysis on the sample quality-time trade-off. A more detailed analysis of the correlation between the sample quality and time (or memory consumption) is needed by comparing the one-shot and autoregressive versions of the IFH model.\nAlthough we explored the subject in Section 5.1, we might not have been too detailed. For this reason, we added a more thorough discussion on the sample quality/time/memory trade-off in the new Discussion section 6. To summarize, we noticed an increase in memory consumption and decreased computational time as we moved away from the 1-node sequential model, as we expected in Section 4.3.\nQ1: Which level of sequentiality did the authors use (I cannot find details in appx D.)? Does the degree of sequentiality imply the block size (or the number of steps)?\nThank you for noticing. We have updated the appendix referring to generic graphs, and moved it as Appendix A to make it more accessible from the main text, moving theoretical parts after. In particular, we added the \"Sequentiality levels\" Table (3a). You are right, the degree (or level) of sequentiality implies the sizes of blocks used, which in turn affects the number of steps. Consider the following with 53 nodes: one-shot inserts all 53 nodes in 1 step; sequential with categorical removal with blocks {1, 2, 8} will generate (with any permutation) 6 blocks of 8 nodes, 2 blocks of 2, and 1 of 1, as the insertion model is trained to pick the largest block size if needed, minimizing the number of steps, which in this case is 9; 1-node sequential model will take 53 steps. Notice that, even adding a block size of 2 to 1-node sequential makes it roughly halve its generation steps.\nQ2: The generic graph generation results in appx B do not look good enough. Is there any particular reason that the model works okay for molecular graphs but not for non-attributed generic graphs?\nAlthough we do not reach state-of-the-art on all metrics against the very strong one-shot model CDGS, the results on generic graphs beat all autoregressive baselines, and are competitive with one-shot baselines. However, as you said, we also noticed a drop in performance for non-attributed generic graphs, and we think that would be a promising direction to explore. Particularly for 1-node sequential models applied to big-sized graphs, we noticed that the halting signal's sparsity hinders the halting model's training process. We address this limitation in the Discussion section (numbered 6 in the revised version)."}]}]}, "kunueR6cZU": {"paper_info": {"Keywords": "extreme bandits, online optimization, heavy-tails, non-iid data, non-parametric", "Abstract": "The Multi-Armed Bandit is a classic reinforcement learning problem that exemplifies the exploration\u2013exploitation trade-off dilemma. When extreme values rather than expected values are of interest, the Extreme Bandit is introduced. The motivation for this work comes from black-box optimization problems and meta learning, where the goal is to find the best value for a target function from different search spaces or using multiple search heuristics. Previous work on the extreme bandit problem has assumed that rewards are drawn from an i.i.d manner, which severely limits the applicability of this class of algorithm. In this paper, with minimal temporal and spatial cost and minimal assumptions about the reward distribution, we present an novel algorithm and provide its analysis. Numerical experiments highlight the performance of the proposed algorithm to the existing approaches.", "Primary Area": "reinforcement learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9286", "PDF Url": "https://openreview.net/pdf?id=kunueR6cZU"}, "review_info": [{"Heading": "Official Review of Submission9286 by Reviewer PRiS", "Subheading": "Official ReviewbyReviewer PRiS27 Oct 2023, 08:06 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn this paper, the authors study Extreme Bandits, where the goal is to maximize the expected best single reward. The motivation of Extreme Bandits relies on block box optimization, where the goal is to find the expected maximum of a set of learners.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nWhile previous works study extreme bandits when the rewards are iid, the authors only assume that the rewards are independent.\nA new measure of optimality is proposed, a new algorithm is presented, analyzed, and tested versus the state-of-the-art.\nWeaknesses:\n1/ In Definition 2, an algorithm is said to be optimal in strong sense if it finds the best arm as defined in (Carpentier Valko 2014). As the authors do not provide a lower bound of the needed number of samples or a regret lower bound, this definition of optimality is overclaimed: the reviewer does not think that we can call an algorithm optimal, while it exists better algorithm finding the best arm. Definition 2 provides a measure of performance, but not a definition of optimality for extreme bandits.\n2/ Lemma 1 states that f_n(X) is time-invariant, but in Algorithm 1 we have a test that depends of t and the following instruction: a_i:=t. So, Lemma 1 is at least poorly worded or wrong. Moreover it seems that Lemma 1 is stated for showing that X_{k,t} \\leq X*_t, so it seems useless as X*_t is informally defined as the best reward after t trials.\n3/ In Table 1 the author claims that the proposed algorithm has a memory complexity in O(K). Actually, it is in O(N), where N is the length of storage array in Algorithm 1: in the experiments N=10^5, while K \\leq 10. So, the memory complexity is overclaimed. The goal of the analysis should be to optimally set the parameter N.\nThis paper is not well written.\n1/ A new notion of performance (Definition 2) is introduced with the previous measures of performances used in the state of the art (Definition 1 and 3). There is no discussion about the advantages or drawbacks of the new measure of performance in comparison to the previous measures. This does not help the reader to understand the interest of the new measure.\n2/ In page 6, there is a digression about the algorithm A*, which seems a little bit disconnected from the paper.\n3/ Some very important notions are implicitly introduced. For instance, the notation k^* is not defined: the reader must deduce what is k* from Definition 1.\nQuestions:\nSee above.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9286 by Reviewer Cn3G", "Subheading": "Official ReviewbyReviewer Cn3G24 Oct 2023, 06:37 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper studies the Extreme Bandit problem, which addresses scenarios where extreme values are of interest rather than expected values. The authors propose a novel algorithm that operates with minimal temporal and spatial cost and makes minimal assumptions about reward distribution, demonstrating its superior performance through numerical experiments compared to existing approaches.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nThis paper is evidently far from meeting the acceptance criteria of ICLR. While I didn't readily discern explicit strengths, I would like to commend the strong motivation behind the work. The introduction section adeptly underscores the importance of extreme bandits and their practical applications.\nWeaknesses:\nThis paper is not written well. The mathematical notation lacks formality, and the logical structure is flawed.\nThe algorithm is strightfoward and the theortical guarantees seem trivial.  Please find my specific questions below.\nThe \"Comparison with the A* search algorithm\" part of Secton 4 is entirely unrelated to the primary focus of this paper.\nQuestions:\nDefintion 2: The index $t$ should commence from 1, as opposed to 0.\nDefinition 3: While the meaning can be grasped, this definition solely delineates the concept of dominance, rather than the asymptotically dominating arm.\nThe paragraph before Definition 2 fails to elucidate the necessity behind defining the new performance measure. As the author says:\n\"For any unbounded rewards stream $\\left(X_{k, t}\\right)$ without finite mean guarantee, we can transform it into bounded variables with finite mean by monotone transformations.\"\nWhy does the statement \"no policy can asymptotically achieve no extreme regret\"  equate to \"no policy is asymptotically optimal in the strong sense.\"?\nTable 1: In terms of the time complexity of AEB, why is it appropriate to disregard the dependence on $N$? As the author suggests, for the algorithm's efficacy, it is advisable to approximate $N\\approx T$.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n1: strong reject\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9286 by Reviewer bVtC", "Subheading": "Official ReviewbyReviewer bVtC23 Oct 2023, 00:35 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper studies the problem of extreme bandits where the goal is to maximize the single largest reward achieved so far. It proposes an algorithm that saves a heuristic record of the best rewards and plays the arm that has achieved the largest reward so far with a exploration factor involved (relaxation factor in the paper). The algorithm is shown to be asymptotically optimal in the sense that it asymptotically plays the optimal arm more than other arms. Experimental results evaluating the algorithm's performance and parameter selection are included.\nSoundness:\n3 good\nPresentation:\n1 poor\nContribution:\n3 good\nStrengths:\nThe paper proposes an algorithm that has better space and time complexity compared to its competitors. The algorithm includes novel techniques in the bandits literature inspired by the A* algorithm.\nThe asymptotic optimality of the algorithm is shown, and the proofs are elegantly elaborated. Simple yet effective proofs are included in Section 4.\nWeaknesses:\nThe asymptotic behavior of competitors is not discussed. The experimental performance evaluations are also not discussed. Based on Fig. 1, it seems that for example, Max-Median algorithm could outperform the proposed algorithm in a certain setting. In the exponential arms setting QoMax-SDA outperforms the proposed algorithm.\nPresentation could improve. Algorithm 1 which is the main part of the paper is not presented properly; $a_i$ is evaluated before getting assigned, does $a\\gets \\{0\\}$ mean all $a_i=0$. It is not clear what the significance of the $a_i$ update rules are. Why do we set $a_i\\gets a_j/2$ in the second case, or in the third case?\nQuestions:\nThe goal of extreme bandits is to get the largest single reward, how does that connect to the proportion of best arm pulls as it is discussed throughout the paper? Why don't we evaluate the performance of the algorithm based on the actual goal?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9286 by Reviewer 7QCU", "Subheading": "Official ReviewbyReviewer 7QCU22 Oct 2023, 06:43 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper deals with the problem of extreme bandits in multi-armed bandits, where the goal is to sequentially pull T arms to maximize the expected maximal reward obtained across all K arms and all T trials. The main motivation in this paper is to propose a more efficient algorithm in terms of space and time computational complexities which challenges the iid and (semi-)parametric assumptions in prior works.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nOriginality : the link with the A* algorithm, through the introduction of the effort-based surrogate value, is clearly highlighted and interesting.\nQuality : the state-of-the-art is extensively discussed in terms of computational costs, and tested in the experimental study. The different experimental settings (choice of distributions, evaluation criterion, effects of parameter values) make sense.\nClarity : The setting and definitions are well-introduced, and except for a few points (definition of the effort-based surrogate, explanation of the pseudo-code, see below), the proofs and the idea behind the algorithm are clear.\nSignificance : The algorithm does not need specific assumptions for concentration inequalities (second-order Pareto and the iid assumption, for example) which hardly hold in practice.\nWeaknesses:\nClarity : I would have preferred the informal definition of the effort-based surrogate value (\u201c\nthe effort taken to find the first reward as good as X\n\u201d) to appear earlier than the concluding paragraph. In particular, I believe that in Definition 4, the\nt\n\u2019s in the universal quantifiers should be another variable (for instance,\ns\n) as the\nt\n's make the definition confusing. It would have been better to add a short paragraph explaining the intuition behind considering the surrogate value as the allocation to track in the adaptive sampling phase.\nSignificance : I did not understand why the following sentence holds \u201c\nHowever, we can avoid performing insert(X_{I_t,t}) operations\n\u201d and how the memory computational cost ends up being O(K) instead of O(K+N) (and actually, O(K+T) as shown by the experiments). Moreover, the experimental results are not completely satisfying, as in Figure 1, the performance of AEB is not noticeably better than baselines, and considering one instance for each type of distribution is probably not enough to draw robust conclusions.\nQuestions:\nIf answered, I will raise my score:\nCan you provide a pseudo-code of the algorithm AEB where the memory cost is O(K)?\nIs it possible to derive an expression of a theoretical lower bound on the value of N for Theorem 1 to hold?\nCould you check on other Pareto distribution / exponential arms instances that your experimental results hold?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNone.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}]}, "P2gnDEHGu3": {"paper_info": {"Primary Area": "generative models", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Mechanistic Interpretability, Interpretability, Fact, Factual Recall, LLM, Explainability, Transparency", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We reverse engineer several independent mechanisms by which models perform the task of factual recall, and show that they combine in an additive manner, constructively interfering on correct answers.", "Abstract": "How do large language models (LLMs) store and retrieve knowledge? We focus on the most basic form of this task -- factual recall, where the model is tasked with explicitly surfacing stored facts in prompts of form \\tokens{Fact: The Colosseum is in the country of}. We find that the mechanistic story behind factual recall is more complex than previously thought -- We show there exist four distinct and independent mechanisms that additively combine, constructively interfering on the correct attribute. We term this generic phenomena the \\textbf{additive motif}: models compute correct answers through adding together multiple independent contributions; the contributions from each mechanism are insufficient alone, but together they constructively interfere on the correct attribute when summed. In addition, we extend the method of direct logit attribution to attribute a head's output to individual source tokens. We use this technique to unpack what we call `mixed heads' -- which are themselves a pair of two separate additive updates.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9284", "PDF Url": "https://openreview.net/pdf?id=P2gnDEHGu3"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9284 by Area Chair ZTLs", "Subheading": "Meta ReviewbyArea Chair ZTLs10 Dec 2023, 04:16 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper presents a series of experiments conducted on a small, manually curated data set designed to identify the mechanisms for \"factual recall\" in large language models. The paper defines four distinct \"mechanisms,\" which are based on (1) attention heads that primarily focus on the subject of a factual predicate, (2) attention heads that primarily focus on the relation between the subject and object, (3) attention heads that attend to both the subject and relation, and (4) multi-layer perceptron (MLP) layers. The central claim of the paper is that these mechanisms work together additively to determine the correct attribute. The problem studied in the paper and the findings presented are of interest to the community. As several reviewers pointed out, the presentation of the paper should be significantly improved before the paper is ready for publication. In addition, the datasets used in the analysis should be strengthened to make the results more convincing.\nJustification For Why Not Higher Score:\nAs several reviewers pointed out, the presentation of the paper should be significantly improved before the paper is ready for publication. In addition, the datasets used in the analysis should be strengthened to make the results more convincing.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Comment by Reviewer npyu", "Subheading": "Official CommentbyReviewer npyu23 Nov 2023, 05:10 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nAlthough I was not able to participate in the extensive discussion timely. I did read all the comments and reread the changes to the paper. The paper, after the revisions, definitely improved particularly for clarity. I still have doubts about the exact contribution of the study. I have, nevertheless, edited my review to reflect the improvements on the clarity."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 03:47Everyone", "Content": "Comment:\nWith the discussion period nearing its close, we would like to remind the reviewers that have only left initial reviews that we would appreciate hearing further feedback on our response. We are keen to know if our responses have adequately addressed all their concerns. Should there be any outstanding queries, we are also eager to engage further."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 12:53 (modified: 17 Nov 2023, 12:56)EveryoneRevisions", "Content": "Comment:\nWe extend our thanks to all reviewers for their insightful reviews and valuable questions. We have responded to each reviewer individually, and made corresponding changes in the paper in our revised version of the paper in\nred\n.  We welcome further responses and questions from the reviewers. We are keen to answer any remaining unanswered questions and to hear of further ways to improve the work. In the remainder of this top level comment, we address some common points among reviewer questions.\nAdditivity\nIn this paper, our core contribution is showing that factual recall is additive. Reviewers\nnpyu\nand\ndGcN\nfelt this was unclear in our manuscript. In this part of the response, we address these concerns. We will first give a definition of additivity. We then discuss some examples of additivity in both toy set ups, and in factual recall. We finally discuss how our empirical results demonstrate additivity of factual recall in the paper. We have made modifications to the paper\u2019s introduction and results sections to make our claims regarding what additivity is, and how we show it, more clear. We have also reordered parts of the paper to highlight our key contributions more prominently.\nWe say models produce outputs additively if\nThere are multiple important model components whose outputs independently directly boost the correct logit.\nThese components are qualitatively different \u2013 their distribution over output logits are meaningfully different.\nThese components constructively interfere on the correct answer, even if the correct answer is not the argmax output logit of components in isolation.\nWhile it may seem noisy and unreliable to stack heuristics like this, softmax extremises outputs due to the exponential, which makes this strategy less disadvantageous to loss.\nAs a toy example, consider a logistic model that is tasked with predicting whether an integer is divisible by 6 (into two classes, true or false). Consider the following two mechanistic ways of solving the task\na) Solve the task directly, memorising which integers are divisible by 6.\nb) Solve the task in two independent parts. Assign a +1 true logit to all numbers divisible by 2. Assign +1 true logit to all numbers divisible by 3, with a different circuit. Apply a uniform bias producing a  -1.5 false logit. \n(a) is non additive. (b) is additive, by the criteria (1-3). There are two different components that contribute to the answer (1), they have qualitatively different outputs (2), and they constructively interfere on the correct answer, with each component insufficient alone (3). Note that condition (2) is necessary to exclude cases where the model increases its confidence through adding two components with identical outputs, which we do not consider to be additive. This example is analogous to how a transformer functions, since the residual stream is an additive sum of outputs from model components, and there\u2019s an (approximately) linear map from the residual stream to the output logits given by the unembedding (aka the language modelling decoder head) [1], so each component can be considered to be writing to logits separately in a linear fashion.\nNow, we move on to the set up in the paper. Consider the example shown in Figure 1, of completing \u201cThe Colosseum is in the country of\u201d. There are two sources of information here - the subject \u201cColosseum\u201d and the relation \u201ccountry\u201d. These correspond to two clusters of additive updates - updates that write many attributes about the Colosseum (\u201cItaly\u201d, \u201cRome\u201d, \u201camphitheatre\u201d, \u2026) and updates that write many countries (\u201cItaly\u201d, \u201cUSA\u201d, \u2026).\nOur main claim in the paper is that factual recall is performed additively in this way. We set out to show this by studying model internals. Our empirical results support additivity. We find four mechanisms that are all implemented differently by the model. The outputs of these mechanisms group into the two clusters we describe above. Each mechanism independently boosts the correct answer (condition 1). There are two qualitatively different clusters of output behaviour (condition 2). This is mostly clearly shown in Figures 2 and 3. Subject and relation heads have very different output behaviour (via Direct Logit Attribution (DLA) [1, 2, 3], on both correct and counterfactual attributes).\n(continued...)", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 12:56Everyone", "Content": "Comment:\nctMu\nasks how this relates to the finding of [1], that provides a mathematical framework for thinking about transformer computation. In this work, the authors argue that the key object of interest in a transformer is the so-called \u201cresidual stream\u201d, from which every model component reads and writes. This is an alternate but mathematically identical way of reasoning about skip connections. The individual model components that read and write to this residual stream are neurons in MLP layers and attention heads, all of which are independent. These contributions are therefore additive, in some sense. This is not quite what we mean by additive, as described above, but is related.\nNovelty\nReviewers\nnpyu\nand\ndGcN\nraised concerns that our key finding is not profound or novel enough. While it is true that we should expect models to use multiple parts of their input for prediction, our work makes this claim rigorous on a mechanistic level, which prior work had not attempted to do. Our work also highlights a particular way in which this information is combined. The model could use the two sources of information together, as part of a larger compositional circuit (e.g. use the relation information to select an attribute from the subject to extract). We instead find the additive motif as described above is primarily used, which has so far not been documented. In particular, something of the form of \u201crelation heads\u201d, can be thought of as setting the correct reference class for answers (e.g. \u201csports\u201d). The study of this is neglected in mechanistic circuit analysis in general. We have improved our exposition of this contribution in the paper.\nFor instance, in the work by Wang et al. [6], models are tasked with completing sentences of the form \u201cWhen John and Mary went to the store, John bought flowers for\u201d. This task has two components \u2013  (a) figure out the answer should be a name, and then (b) figure out what the correct name is. In [2], the authors use the metric of \u201clogit difference\u201d, \u201cMary - John\u201d, and isolate the circuit for (b), but neglect to study (a). While just studying (b) is valid, it is important to be explicit that part of the behaviour remains unexplained. Our work instead claims that (a) is an important part of predicting the next token, especially in factual recall, and so we study it on a mechanistic level. This is novel among the mechanistic interpretability literature.\nSuch considerations are also neglected within the factual recall literature. Prior work did not study many other individual counterfactual outputs as we did with sets S and R, so missed the fact that many other attributes were positively upweighted by the model. Our work shows single facts are not extracted, but many different facts are extracted. Figuring out how the model decides between these is an interesting question, which we explore. This makes our findings novel among the existing work on how transformers recall facts.\n(continued...)"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 12:57 (modified: 17 Nov 2023, 12:59)EveryoneRevisions", "Content": "Comment:\nAblations\nReviewers\nvZgL\nand\nctMu\nwere curious what the effect on performance would be upon knocking out various mechanisms. We originally chose not to perform ablation experiments, as we had already studied the direct effect of model components through their Direct Logit Attribution [DLA], and reasoned ablation experiments would not be much more informative.\nIn response to this feedback, we decided to run some ablation experiments. We have included these results in Appendix E.3. Naive ablations have been noted in prior work to be counteracted by self-repair in the factual recall set up, a phenomenon known as the Hydra Effect [4]. We therefore followed the approach of [6], and performed edge patching - ablating the direct path term between model components and logits. We present baseline loss, together with the loss after knocking out one model mechanism. Each loss reported is aggregated over a dataset with fixed relation $r$. We see knocking out any individual mechanism significantly harms loss in each case.\nRelation\nBaseline Loss\nSubject % Change\nRelation % Change\nMixed % Change Loss\nMLP % Change\nPLAYS_SPORT\n0.68\n16.71\n254.31\n345.56\n483.11\nIN_COUNTRY\n0.51\n250.29\n710.23\n375.23\n207.43\nCAPITAL_CITY\n1.41\n67.38\n206.48\n90.53\n222.64\nLEAGUE_CALLED\n1.58\n170.37\n97.31\n185.97\n104.80\nPROFESSOR_AT\n0.62\n127.90\n503.27\n78.52\n714.40\nPRIMARY_MACRO\n1.60\n190.55\n10.92\n69.08\n189.48\nPRODUCT_BY\n0.75\n112.21\n578.38\n145.64\n249.04\nFROM_COUNTRY\n1.16\n196.88\n234.61\n101.40\n255.63\n(continued...)"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 12:59Everyone", "Content": "Comment:\nClassifying attention heads.\nReviewers\nvZgL\nand\nnpyu\nwanted to hear about how we chose our classification of attention heads. We chose a fairly conservative figure arbitrarily and then verified it matched out intuitions for what such heads do by inspecting many versions of Figure 3. Among the most important few heads, we found our definition to make sense. Our definition was in terms of DLA, but we also verified this lined up with where attention was paid.\nWe agree that the fuzziness of the boundary behind particular mechanisms is a limitation of our framing of attention heads as fitting into one of three distinct categories. In reality, there is some sliding scale between a head acting as a relation head and subject head. We chose this classification as we found it helpful in understanding model behaviour. We view one of our contributions as showing there\nexist\nheads with different qualitative behaviour in the end to end factual recall circuit, which we believe this framing illuminates well.\n[1] A Mathematical Framework for Transformer Circuits.\n[2] interpreting GPT: the logit lens\n[3] Analyzing Transformers in Embedding Space\n[4] The Hydra Effect: Emergent Self-repair in Language Model Computations\n[5] Causal Scrubbing: a method for rigorously testing interpretability hypotheses [Redwood Research]\n[6] Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 Small"}]}, {"Heading": "Official Review of Submission9284 by Reviewer vZgL", "Subheading": "Official ReviewbyReviewer vZgL08 Nov 2023, 20:50 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe work concerns the task of factual recall in LLMs i.e. in templated prompts, the LLM is tasked to predict the object attribute of the tuple (subject, relation, attribute). Authors propose that factual recall in the END position (correct logit ranking) occurs by the summation of contributions of different additive circuits in the transformer.\nAuthors extend Direct Logit Attribution (DLA) to compute the joint contribution from different source token groups to the final predicted logits\n4 different additive circuits are identified based on the extended DLA: SUBJECT, RELATION, MIXED and MLP\nSUBJECT attention heads preferentially boost attributes that are relevant to the subject of the query\nRELATION attention heads preferentially boost attributes that are relevant to the relation of the query independent of the subject\nMIXED attention heads boost the attributes that are jointly relevant to the subject and relation of the query\nMLP layers at the end position uniformly boost the attributes relevant to the relation (ignoring the subject tokens)\nThe central findings of the paper revolve around the Pythia-2.8b model. Additional experiments in the Appendix report that similar types of circuits may be found in other models but all categories may not always exist.\nLimitations:\nAuthors acknowledge that the boundary between MIXED and other attention head types is fuzzy. The definition used to separate attention heads was based on preferential contribution from SUBJECT or RELATION and any other type is considered a mixed type.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper uses established mechanistic interpretation tools and extends them to identify mechanisms in the transformer that perform very specific purposes\nThe SUBJECT-head, RELATION-head, and MLP additive behaviors are established by showing consistent patterns across a range of fact queries\nWeaknesses:\nThe paper introduction and further discussions claim that the results reported here provide a mechanistic explanation for the limitations of LLMs to learn \"B is A\" from training on \"A is B\" [1]. However, I do not see sufficient evidence to support this claim\nThey have shown that in the forward direction the transformer selectively promotes attributes relevant to the subject and the relation\nThis does not show that the transformer CANNOT/DOES NOT perform the same operations in the reverse direction.\nE.g. \"Basketball is played by ...\" may contain circuits that selectively promote the known basketball players. The lack of such circuits is not demonstrated by this work\nIn particular, the authors argue that the LLM learns an \"asymmetric\" look-up. However, the asymmetry is not established.\nPresentation\nSignificant space in the main paper is used to describe future work. I believe that there is an interesting and valuable discussion about dataset creation in the Appendix that should be brought to the main paper\n[1] Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, and Owain Evans. The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\", September 2023. URL\nhttp://arxiv.org/abs/2309.12288\n. arXiv:2309.12288 [cs].\nQuestions:\nIs it fair to say that the key findings are the presence of SUBJECT-only and RELATION-only heads among the attention heads in the transformer? All other heads are MIXED heads by default?\nWhat fraction of attention heads get categorized into extreme categories (SUBJECT and RELATION)?\nHow does the contribution to the final logits from the extreme categories (SUBJECT and RELATION) compare to the heads that are categorized as MIXED?\nTagging onto questions 3 and 4: is there a significant drop in model performance when extreme heads are suppressed?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 13:03 (modified: 17 Nov 2023, 13:04)EveryoneRevisions", "Content": "Comment:\nThanks for the generous review. We are glad you appreciated our use of existing and novel mechanistic interpretability techniques to identify mechanisms with specific purposes used for factual recall in transformer language models.\nThe paper introduction and further discussions claim that the results reported here provide a mechanistic explanation for the limitations of LLMs to learn \"B is A\" from training on \"A is B\" [1]. However, I do not see sufficient evidence to support this claim\nWe thank the reviewer for their feedback. We believe that our work does provide a mechanistic explanation for the reversal curse, but thank the reviewer for pointing out the need to communicate this more clearly. The reversal curse claims that models trained on \u201cA is B\u201d fail to generalise to \u201cB is A\u201d. Importantly, this is difficult to verify with purely pre-trained models on common facts (e.g. Michael Jordan plays basketball) where the model likely saw the fact in both forms (basketball is played by Michael Jordan, Michael Jordan plays basketball). The reversal curse paper demonstrates this with fine-tuning on novel facts, ensuring the reverse-direction was not seen.\nIn our work, we only study a pre-trained model, and so the evidence we provide is indirect and suggestive, as we do not fine-tune ourselves. We find a circuit by which models may learn to output \u201cA is B\u201d, involving subject enrichment on the A tokens, and some attention head attending to A and extracting B. Importantly, this is a unidirectional circuit with two unidirectional components - it extracts the fact \u201cB\u201d from \u201cA\u201d.  This suggests that the reason fine-tuning on \u201cA is B\u201d does not boost \u201cB is A\u201d in general is because training on \u201cA is B\u201d only boosts the unidirectional A -> B mechanisms, and has no effect on potential B -> A mechanisms.\nIs it fair to say that the key findings are the presence of SUBJECT-only and RELATION-only heads among the attention heads in the transformer? All other heads are MIXED heads by default?\nYes, in part. We believe our key finding is that there exist a range of different mechanisms with qualitatively different functions that all contribute to this task, and which interact additively. We clarify what we mean by this in the top level comment. All other heads are mixed, yes. Some heads are of course more important than others for this subtask.\nWhat fraction of attention heads get categorized into extreme categories (SUBJECT and RELATION)?\nHow does the contribution to the final logits from the extreme categories (SUBJECT and RELATION) compare to the heads that are categorized as MIXED?\nTagging onto questions 3 and 4: is there a significant drop in model performance when extreme heads are suppressed?\nThanks for these questions regarding the prevalence and importance of the various mechanisms. All three of these questions ask similar questions. We address the first two of your questions here, and refer you to the top level comment \u201cablations\u201d for an answer to the third.\nThe\nfraction of heads\nclassified each way varies depending on the choice of relation. See Figure 3 for two examples. There, we see the split of (subject, relation, mixed) among the top 10 heads for the relation \u201cplays the sport of\u201d is (2, 1, 7), but for \u201cis in the country of\u201d it is (4, 2, 4). In response to this question, we ran experiments to check what the split was across our entire dataset and without aggregation over the relation. Inspecting the top 10 heads by DLA for each example we find 37% of heads get categorised as subject heads and 33% as relation heads, with the remaining 30% as MIXED heads. This indicates all three head types are important for the task.\nThe\ncontribution to logits\nis another good metric. Figure 2 visualises this \u2013 we can qualitatively see that all three head types are important. In response to this question, we ran some additional experiments. We include below the percentage of the final (mean centred) logit contributed from each component type, across the entire dataset. We omitted several negative suppressive components for the purpose of this analysis. Again, we see that the contributions from each type of mechanism is important. Subject heads contribute 18%, relation heads 24%, mixed heads 27%, and the mlp layers 30%, across the entire dataset.\n(continued...)"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 13:04Everyone", "Content": "Comment:\nAuthors acknowledge that the boundary between MIXED and other attention head types is fuzzy.\nThanks for this comment. We provide some discussion in the top level comment under the heading \u201c\nclassifying mechanisms\n\u201d.\nSignificant space in the main paper is used to describe future work. I believe that there is an interesting and valuable discussion about dataset creation in the Appendix that should be brought to the main paper\nThanks for this comment on the limitations section. We agree these limitations are very helpful. We have since added significant further discussion to the main body, so no longer have space to include this section in the main body. We have pointed to it more visibly from the main text in the methods section."}]}, {"Heading": "Official Review of Submission9284 by Reviewer ctMu", "Subheading": "Official ReviewbyReviewer ctMu07 Nov 2023, 11:06 (modified: 21 Nov 2023, 19:17)EveryoneRevisions", "Content": "Summary:\nThis work target at interpreting the inner mechanisms of LLMs in accomplishing the task of Factual Recall. This work identifies and explains four distinct mechanisms present in the model, as well as the additive cooperation between these mechanisms. This work validates the generalizability of this mechanism across different models and facts.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\n(1) Based on sufficient experimental results verification, the author has identified and explained the internal mechanisms of LLMs at the granularity level of attention heads and MLPs. More interestingly, it provides an explanation of the \u201creversal curse\u201d phenomenon discovered in recent works.\n(2) This work has thoroughly discussed the related work and proposed a range of possible directions for future works.\nWeaknesses:\n(1) There have been many works [1, 2] interpreting the model behavior of Factual Recall. It seems that the novelty is insufficient with only a deeper zooming into attention heads using similar interpretability methods. Additionally, the discovery of the additive motif is not surprising enough, as already explained in work [3] that \"Attention heads can be understood as independent operations, each outputting a result which is added into the residual stream.\" \n(2) Is direct logit attribution (DLA) the same as the interpretability method of Path Patching [4] or Causal Mediation Analysis [5]? If so, it is necessary to explain how the counterfactual data is applied for causal intervention. If it is not, it is necessary to provide a detailed description of the algorithm flow of DLA.\n(3) This work extends \u201cDLA by source token group\u201d with a weighted sum of outputs corresponding to distinct attention source position. But how to obtain the \u201cweights\u201d? How to attribute multiple tokens simultaneously? These missing implementation details make it difficult to understand the method and reproduce the results.\n[1] Locating and Editing Factual Associations in GPT\n[2] Dissecting Recall of Factual Associations in Auto-Regressive Language Models\n[3] A Mathematical Framework for Transformer Circuits\n[4] Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small\n[5] Investigating Gender Bias in Language Models Using Causal Mediation Analysis\nQuestions:\n(1) It would be better to validate the faithfulness of the identified components (e.g., Subject Heads, Relation Heads) for Factual Recall? What would happen to the prediction ability (e.g., accuracy) of the model for Factual Recall task if these components were knocked out?\n(2) We wonder if it is possible to explain the behavior of MLPs explicitly, similar to explaining Attention Heads via attention patterns?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 13:08Everyone", "Content": "Comment:\nThanks for the detailed review. We\u2019re glad that you found our experimental results sufficient to explain the internal mechanisms LLMs use to recall facts. We\u2019re also happy to hear that you find the work relevant in the context of the existing literature. Below we comment on some of the weaknesses you point out in the paper.\n(1) There have been many works [1, 2] interpreting the model behaviour of Factual Recall. It seems that the novelty is insufficient with only a deeper zooming into attention heads using similar interpretability methods.\nOur approach is fundamentally different to [1] and [2], and our findings subsequently different. As you noted, we chose to zoom in deeply into individual model components, which [1] did not do at all, and [2] only briefly studied. Through using a \u201ccircuits style\u201d approach, we were able to find insights that both [1] and [2] missed. [1] studies where factual knowledge is stored in models, but not how such knowledge is used to predict the next token. [2] attempts to study this problem, but only does so through coarse grained ablations. They suggest a mechanism based on this, which we search for in individual model components. In doing so, we instead find several independent mechanisms that explain how information regarding factual knowledge is moved. We additionally find an extra place where factual information is stored \u2013 namely in the relationship token \u201csport\u201d itself - prior work missed this important aspect, which we found through careful study of a range of counterfactual attributes S and R. This motivated the focus on \u201cadditivity\u201d (see the top level comment titled \"\nadditivity\n\" for more discussion on this). We also discuss the \"\nnovelty\n\" of this work in another top level comment.\nAdditionally, the discovery of the additive motif is not surprising enough, as already explained in work [3] that \"Attention heads can be understood as independent operations, each outputting a result which is added into the residual stream.\"\nThanks for raising this confusion. We address what we mean by additivity in a top level comment to all reviewers, and have amended the paper to clarify this. Our use of additivity is distinct from [3].\n(2) Is direct logit attribution (DLA) the same as the interpretability method of Path Patching [4] or Causal Mediation Analysis [5]? If so, it is necessary to explain how the counterfactual data is applied for causal intervention. If it is not, it is necessary to provide a detailed description of the algorithm flow of DLA.\nThanks for raising this confusion. Direct logit attribution (DLA) is not the same technique as path patching or causal mediation analysis. DLA is a simple technique that we describe in the paper in section 2. We have now added further discussion on this, including a detailed description of the algorithm, in Appendix D. It is not based on a causal intervention. It builds on a technique named the \u201clogit lens\u201d. Both are based on the insight by [3] that the residual stream is an accumulated sum of model components, and that the map to logits from the final residual stream vector is approximately linear. While running a single forward pass, we may take the output from individual model components, such as attention heads, and directly map these to logit space, by immediately applying the model unembedding (aka language model decoder head/final linear layer). Given a set of logits, we can read off the DLA for any possible output token, including for counterfactual output tokens.\n(3) This work extends \u201cDLA by source token group\u201d with a weighted sum of outputs corresponding to distinct attention source position. But how to obtain the \u201cweights\u201d? How to attribute multiple tokens simultaneously? These missing implementation details make it difficult to understand the method and reproduce the results.\nOur extension is to consider the attention head output as a weighted sum over individual source positions, where the weighting is given by the attention probability. This is entirely faithful to transformer computation. By unravelling this sum, we can consider DLA for attention heads to be attributed to all attention source tokens individually. We have provided a detailed discussion with formulae of this technique in Appendix D.\n(1) It would be better to validate the faithfulness of the identified components (e.g., Subject Heads, Relation Heads) for Factual Recall? What would happen to the prediction ability (e.g., accuracy) of the model for Factual Recall task if these components were knocked out?\nThanks for this question. We address this question in the top level comment, under \u201c\nablations\n\u201d.\n(continued...)"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 13:08Everyone", "Content": "Comment:\n(2) We wonder if it is possible to explain the behaviour of MLPs explicitly, similar to explaining Attention Heads via attention patterns?\nExplaining the behaviour of MLPs is well documented to be significantly harder than interpreting attention heads in the interpretability literature. The function of attention heads can be thought of as primarily of moving information around different token positions. MLPs instead perform meaningful computation, and have many more parameters. They have also been noted to operate on features under a large amount of superposition [1] \u2013 meaning individual neurons encode many different concepts and are in general uninterpretable in networks in isolation. In this work, we only attempt to interpret the entire output of MLP layers, but agree that further work could investigate this computation more deeply. As this is not central to the key claims of the paper, we note this as a possible area of future investigation in the future work section.\n[1] FINDING NEURONS IN A HAYSTACK: CASE STUDIES WITH SPARSE PROBING"}, {"Heading": "Re: authors response", "Subheading": "Official CommentbyReviewer ctMu21 Nov 2023, 19:18Everyone", "Content": "Comment:\nAfter carefully read the reply and revised appendix in the paper, I think my concern about the novelty and the takeaway contributions of this paper is still not clear enough, I decide to lower my score from 6 to 5."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 14:03Everyone", "Content": "Comment:\nWe're surprised and saddened that you've decided to lower your score. Can you elaborate on what led you to change your mind from your initial review, so we can better engage with the critique?\nWe believe we've actually improved the paper in terms of novelty, by making clearer what the additive motif means, why it's important, and why prior work missed this. We have made changes in the paper at various points to better reflect this (e.g. in the Introduction, Results, Conclusion), and have remarked on it at length in the top level comment."}]}, {"Heading": "Official Review of Submission9284 by Reviewer npyu", "Subheading": "Official ReviewbyReviewer npyu03 Nov 2023, 18:42 (modified: 23 Nov 2023, 05:02)EveryoneRevisions", "Content": "Summary:\nThis paper presents a set of experiments on a small hand-crafted data\nset for identifying the mechanisms at play during \"factual recall\" in\nlarge language models. The paper defines four \"mechanisms\" based on\n(1) attention heads that focus (mostly) subject of a factual\npredicate, (2) attention heads that focus (mostly) relation, (3)\nattention heads that attend to both, and (4) MLP layer. The main claim\nis that these mechanisms additively determine the correct attribute.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe study tackles an important/interesting problem and the paper reports a substantial amount of experimentation.\nWeaknesses:\nAlthough I believe the idea is interesting, and there may be some\nvaluable finding in the paper, I have difficulties seeing a clear\ntake-home message based on the results presented, and probably also\ndue to the way they are presented. I have some concrete points of\ncriticism listed in the comments below (with approximate order of importance).\nThe main claim, additivity of the multiple mechanisms, is not very\nclearly demonstrated in the paper. The separation of the\nsubject/relation heads (as displayed in Fig. 2) is impressive.\nHowever, neither the roles of the \"mixed head\" mechanism, the MLP,\nand additivity of all these mechanisms are not clearly demonstrated.\nThe dataset is rather small and it is not described in the paper at\nall. The description of in the appendix is also rather terse,\ncontaining only a few examples. Given the data set size (hence the\nlack of diversity), and the possible biases (not discussed) during\nthe data set creation, it is unclear if the findings can generalize\nor not. In fact, some of the clear results (e.g., the results in\nFig. 2) may be due to the simple/small/non-diverse examples.\nI also have difficulty for fully understanding the insights the\npresent \"mechanisms\" would provide. To me, it seems we do not get\nany further insights than the obvious expectation that the models\nhave to make their decisions based on different parts of the input\n(and meaningful segments may provide independent contributions). I\nmay be missing something here, but it is likely that many other\nreaders would miss it, too.\nVisualizations are quite useful for observing some of the results.\nHowever, the discussion of findings based on a more quantitative\nmeasure (e.g., DLA difference between factual and counterfactual\nattributes) would be much more convincing, precise, repeatable, and\ngeneral.\nOverall, the paper is somewhat difficult to follow, relying data in\nthe appendix for some of the main claims and discussion points.\nAppendixes should not really be used for circumvent page-limits.\nIdeally, most readers should not even need to look at them.\nThe head type (subject/relation) definition uses an arbitrary\nthreshold. Although it sounds like a rather conservative choice, it\nwould still be good to know how it was determined.\nQuestions:\nSome typo/language issues:\nIntroduction second paragraph: \"(Meng et al., 2023a) find ...\"\n  -> \"Meng et al. (2023a) find ...\"\nAlthough it is a very common \"mistake\" in the field, all \nestablished style guides I know prescribe that footnote marks\nto be placed after punctuation. Also, I strongly recommend\nagainst placing footnote marks directly on symbols (like R^3).\nIt is a good idea to indicate that figure/table references to\nthe appendix are in the appendix.\nThe \"categories\" defined at the beginning of the results section\ncomes as a surprise, and seem to be an important part of the \nanalysis throughout. This should be defined/explained earlier.\nEnd of sentence punctuation missing for footnote 4.\nThere are no references to Figure 2 from the text.\nIt may not be that easy for some figures, but B/W friendly\nfigures would be appreciated by people reading on paper or\nmonochrome devices (like e-ink readers).\nSome terms like \"OV circuit\" or \"ROME\" that many readers are not \nlikely to be familiar with should be briefly introduced.\nThe same goes for abbreviations of the sort L22H17. Not \ndifficult to guess for most readers, but it would be more reader\nfriendly to explain at first use.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 13:16Everyone", "Content": "Comment:\nThanks for the generous feedback. We are glad you find our problem choice of understanding how models perform factual recall important, and note that our findings may be valuable to the community.\nThe main claim, additivity of the multiple mechanisms, is not very clearly demonstrated in the paper. The separation of the subject/relation heads (as displayed in Fig. 2) is impressive. However, neither the roles of the \"mixed head\" mechanism, the MLP, and additivity of all these mechanisms are not clearly demonstrated.\nWe address your concerns regarding the main claim of additivity in a top level comment to all reviewers above titled\nadditivity\n. The clearer distinction for additivity is into two clusters of updates - relating either to the relation or subject. Each of the four model mechanisms contributes to one or both (in the case of mixed heads) of these clusters.\nThe dataset is rather small and it is not described in the paper at all. The description of in the appendix is also rather terse, containing only a few examples. Given the data set size (hence the lack of diversity), and the possible biases (not discussed) during the data set creation, it is unclear if the findings can generalize or not. In fact, some of the clear results (e.g., the results in Fig. 2) may be due to the simple/small/non-diverse examples.\nThanks for this comment. We have provided further details regarding our dataset in an Appendix C of the paper.\nWe agree with your criticism regarding the size and potential biases of the dataset. We agree this is not ideal, but found dataset creation difficult. Despite this, our dataset spans several different relations $r$, and contains over 100 prompts, which we think renders our findings valuable and sufficient for demonstration of the\nexistence\nof a range of mechanisms and of additivity. We believe this is a valuable contribution given substantial community interest in both factual recall and interpretability more generally.\nWe discuss the limitations we faced with dataset creation at some length in Appendix C of the paper.\nQuoting from the paper:\nWe found the pre existing datasets to be unsatisfactory for our analysis, due to some additional requirements our set up necessitated. We firstly required models to both \\textit{know} facts and to \\textit{say facts} when asked in a simple prompting set up, and for the correct attribute $a$ to be completely determined in its tokenized form by the subject and relationship. For example `The Eiffel Tower is in' permits both the answer `Paris' and `France'. For simplicity we avoided prompts of this form. Synonyms also gave us issues, e.g. `football' and `soccer', or `unsafe' and `dangerous'. This mostly restricted us to very categorical facts, like sports, countries, cities, colors etc.  We also wanted to avoid attributes that mostly involved copying, such as `The Syndey Opera House is in the city of Sydney`, as we expect this mechanism to differ substantially from the more general mechanism, and to rely mostly on induction heads \\citep{olsson2022context}. Next, we wanted to create large datasets with $r$ held constant, and separately, with $s$ held constant. Holding the relation constant and generating many facts is fairly easy. But generally models know few facts about a given subject, e.g. `Michael Jordan' is associated very strongly with `basketball', but other facts about him are less important and well known. Certain kinds of attributes, like `gender' are likely properties of the tokens themselves, and not likely not reliant on the `subject enrichment' circuitry - e.g. `Michael' and `male'. We try and avoid these cases. We also restrict to attributes where the first attribute token mostly uniquely identifies the first answer token. If the first token of the attribute is a single character or the word \u201cthe\u201d, this can be vague, so we omitted these cases. These considerations limited the size of the dataset we studied.\nI also have difficulty for fully understanding the insights the present \"mechanisms\" would provide. To me, it seems we do not get any further insights than the obvious expectation that the models have to make their decisions based on different parts of the input (and meaningful segments may provide independent contributions). I may be missing something here, but it is likely that many other readers would miss it, too.\nThanks for this question. We believe this kind of study is valuable in the context of the mechanistic interpretability literature, which we discuss in a top level comment to all reviewers, under the heading \u201c\nnovelty\n\u201d.\n(continued...)"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 13:16 (modified: 17 Nov 2023, 19:51)EveryoneRevisions", "Content": "Comment:\nVisualizations are quite useful for observing some of the results. However, the discussion of findings based on a more quantitative measure (e.g., DLA difference between factual and counterfactual attributes) would be much more convincing, precise, repeatable, and general.\nThanks for this comment. We found qualitative figures generally a more useful form to present our results. Our main aim was to demonstrate a range of mechanisms with different qualitative properties exist. This is what is necessary to demonstrate additivity, which is our main goal in the paper.\nThat said, we do agree that a more raw form of data can also be valuable. In Appendix E we present several instances of such data, on a per-prompt basis. We include for instance tables of raw ordered output tokens, logit ranks, and DLA scores.\nOverall, the paper is somewhat difficult to follow, relying data in the appendix for some of the main claims and discussion points. Appendixes should not really be used for circumvent page-limits. Ideally, most readers should not even need to look at them.\nThank you for the feedback, sorry for this. We have since restructured to emphasise the additivity claim more prominently. This is the main claim in the paper. In order to show additivity, it suffices to have two mechanisms (namely, subject and relation heads). These are distinct, and we explain these in detail. We in fact find four mechanisms, which we include for completeness.  We struggled to fit figures for all four mechanisms in the main body. We therefore made the decision to prioritise \u201csummary\u201d figures in the first results section to give a high level picture of the various mechanisms, and a detailed explanation of two mechanisms.\nThe head type (subject/relation) definition uses an arbitrary threshold. Although it sounds like a rather conservative choice, it would still be good to know how it was determined.\nThanks for this comment. We agree this choice is somewhat arbitrary, but we believe it\u2019s useful to draw this distinction. See the top level comment, under \u201c\nclassifying attention heads\n\u201d.\nThe \"categories\" defined at the beginning of the results section comes as a surprise, and seem to be an important part of the analysis throughout. This should be defined/explained earlier.\nThanks for raising this point of confusion. The categories are important to the analysis on the individual component level, but are not conceptually important to the main claim of additivity of the paper. There are several levels of granularity discussed in the paper. From high to low: two additive clusters, four separate groups of mechanisms, and many individual components implementing these. Categories operate on the lowest component level, and merely state individual components (like individual attention heads), have a narrow purpose. We have removed references to categories from the \u201csummary of results\u201d section, to make the main claims regarding additivity flow better and be more clear.\nWe have additionally addressed all the typos you pointed out - thanks for these."}]}, {"Heading": "Official Review of Submission9284 by Reviewer dGcN", "Subheading": "Official ReviewbyReviewer dGcN31 Oct 2023, 19:44 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn the context of LLM, this paper shows there exist four distinct and independent mechanisms that additively combine, constructively interfering on the correct attribute. This generic phenomena is termed as the additive motif: models compute correct answers through adding together multiple independent contributions; the contributions from each mechanism may be insufficient alone, but together they constructively interfere on the correct attribute when summed. In addition, this paper extends the method of direct logit attribution to attribute a head\u2019s output to individual source tokens.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThis paper is well written and easy to follow.\nThe experiment is sufficient.\nWeaknesses:\nThis finding  seems to be not profound enough. It only demonstrates that LLMs perform better under the additive motif, but it appears insufficient to prove that the additive motif is the underlying factual recall behind LLMs.\nQuestions:\nThis finding may explain the fact that models trained on \u201cA is B\u201d fail to generalize to \u201cB is A\u201d.   Is there any possible to explain the CoT prompting such as \u201clet\u2019s think step by step\u201d by using your findings? Does it bring any other insights or explanations for other phenomena that are difficult to explain in LLMs? For example, is there any possible to explain the CoT prompting such as \u201clet\u2019s think step by step\u201d by using your findings?\nCan this finding contribute to prompt engineering\uff1f\nSome tables are too wide and are out of page, e.g., table 1.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 13:20Everyone", "Content": "Comment:\nThank you for your review. We\u2019re glad you found the paper to be well written, and were able to follow our experimental results.\nThis finding seems to be not profound enough. It only demonstrates that LLMs perform better under the additive motif, but it appears insufficient to prove that the additive motif is the underlying factual recall behind LLMs.\nThanks for raising this \u2013 we have provided additional discussion about our main findings, and why we believe them to be novel, in a top level comment to all reviewers. See the sections titled \u201c\nadditivity\n\u201d and \u201c\nnovelty\n\u201d.\nThis finding may explain the fact that models trained on \u201cA is B\u201d fail to generalize to \u201cB is A\u201d. Is there any possible to explain the CoT prompting such as \u201clet\u2019s think step by step\u201d by using your findings? Does it bring any other insights or explanations for other phenomena that are difficult to explain in LLMs? For example, is there any possible to explain the CoT prompting such as \u201clet\u2019s think step by step\u201d by using your findings?\nUnderstanding why chain of thought prompting works so well via interpretability is an interesting problem. We however think our set up would not be a good place to study this, due to the simple one step nature of the problem of factual recall, which is fundamentally different to the multi-hop nature of chain of thought prompting.\nThat said, an interesting area of further investigation may be studying \u201cmulti-hop factual recall\u201d, which our results may help explain. Consider prompts of form \u201cThe largest church in the world is located in the city of\u201d. Additivity may help models solve this task in one step, even though a human may reason about this problem in a sequential manner. We have added this idea to future work.\nCan this finding contribute to prompt engineering\uff1f\nWe think it\u2019s possible that the insight that models make predictions based on different parts of their input could contribute to prompt engineering. We think this is well known, though has not been shown mechanistically to our knowledge.\nFor instance, we should expect models to perform worse at factual recall when prompted with \u201cFact: Michael Jordan plays\u201d over \u201cFact: Michael Jordan plays the sport of\u201d. We find this to be the case -- Pythia-2.8b reports 21.71% accuracy for the first prompt, yet 69.34% for the second, on the | basketball| token.\nIn our work, we found that relation heads had meaningful DLA from attending to both the word \u201cplays\u201d and \u201csport\u201d. Omitting the word \u201csport\u201d reduces performance. Our work provides a mechanistic explanation for the intuition that providing more detailed information in prompts is beneficial, in at least this context.\nWe also believe our results could be extended by future work to explain few-shot prompting (e.g. via prepending another related fact in the prompt). Preliminary investigation of this early in the project suggested some of the four mechanisms behaved differently under few shot prompting. For instance, relation heads would fire more strongly on prompts with several mentions of the word \u201csport\u201d. This is one area of future work we note in the paper."}]}]}, "0JTwZ30qPH": {"paper_info": {"Primary Area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Multi-view learning; Meta learning; Feature modulation; Task adaptation", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Multi-view representation learning aims to learn a high-quality unified representation for an entity from its multiple observable views to facilitate the performance of downstream tasks. A typical multi-view representation learning framework consists of four main components: View-specific encoding, Single-view learning (SVL), Multi-view learning (MVL), and Fusion. Recent studies achieve promising performance by carefully designing SVL and MVL constraints, but almost all of them ignore the basic fact that \\textit{effective representations are different for different tasks, even for the same entity}. To bridge this gap, this work proposes a \\textbf{T}ask-\\textbf{O}riented \\textbf{M}ulti-\\textbf{V}iew \\textbf{R}epresentation \\textbf{L}earning (TOMRL) method, where the key idea is to modulate features in the View-specific encoding and Fusion modules according to the task guidance. To this end, we first design a gradient-based embedding strategy to flexibly represent multi-view tasks. After that, a meta-learner is trained to map the task embedding into a set of view-specific parameters and a view-shared parameter for modulation in the Encoding and Fusion modules, respectively. This whole process is formalized as a nested optimization problem and ultimately solved by a bi-level optimization scheme. Extensive experiments on four multi-view datasets validate that our TOMRL consistently improves the performance of most existing multi-view representation learning approaches.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9283", "PDF Url": "https://openreview.net/pdf?id=0JTwZ30qPH"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9283 by Area Chair ZEFt", "Subheading": "Meta ReviewbyArea Chair ZEFt05 Dec 2023, 01:54 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper explores a meta-learning-based architecture for multi-view representation learning, yielding promising performance in both clustering and classification tasks.\nHighlights of the paper mentioned by the reviewers include:\n1.The paper proposes a task-oriented multi-view representation learning method from a meta-learning perspective.\n2.The proposed method in this paper significantly enhances the experimental performance of both clustering and classification tasks simultaneously.\nThe main concerns expressed by the reviewers include:\n1.The paper faces limitations in innovating model design.\n2.The motivation behind this paper remains unclear, which hinders a comprehensive understanding of the work.\n3.The experimental methodology is insufficient, notably due to a constrained sample size, a lack of diversity in datasets, and experiment settings that are not convincingly established.\nIn the rebuttal period, AC additionally invited two domain experts to reevaluate this submission. The paper finally received five scores (i.e., 3,5,3,6,3) from reviewers. After carefully reading the manuscript, comments, and the corresponding response, I agree with the reviewers that this paper is not novel enough to be accepted.\nJustification For Why Not Higher Score:\nThe main concerns expressed by the reviewers include:\n1.The paper faces limitations in innovating model design.\n2.The motivation behind this paper remains unclear, which hinders a comprehensive understanding of the work.\n3.The experimental methodology is insufficient, notably due to a constrained sample size, a lack of diversity in datasets, and experiment settings that are not convincingly established.\nJustification For Why Not Lower Score:\nHighlights of the paper mentioned by the reviewers include:\n1.The paper proposes a task-oriented multi-view representation learning method from a meta-learning perspective.\n2.The proposed method in this paper significantly enhances the experimental performance of both clustering and classification tasks simultaneously."}, {"Heading": "Official Review of Submission9283 by Reviewer aCu2", "Subheading": "Official ReviewbyReviewer aCu204 Dec 2023, 10:06 (modified: 04 Dec 2023, 10:08)EveryoneRevisions", "Content": "Summary:\nThis paper introduces a task-oriented multi-view representation learning method. Specifically, it adopts the meta-learning paradigm to minimize the distribution differences in representations across various tasks. However, the overall technical soundness of this paper appears to be lacking, and the experimental evidence presented is not sufficiently convincing.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nFor multi-view representation learning, different tasks have distinct requirements for the distribution of representations. This paper highlights this issue.\nThe proposed method integrates meta-learning and multi-view learning through a nested bi-level optimization approach.\nWeaknesses:\nThe framework and methodology lack innovation, constituting a simple combination and minor extension of existing works without significant theoretical contributions.\nThe experimental section of the paper appears to be too simplistic and insufficient. The selected datasets are on the smaller side, limiting the ability to validate the model's effectiveness and scalability in more complex scenarios.\nIn the cross-domain experiments of this article, validation was conducted solely on the Noisy Fashion and Edge Fashion datasets. The domain difference between the two is minimal, almost negligible.\nThe paper only reports results under the 5-way 5-shot setting and lacks evaluation in more diverse few-shot scenarios, such as 1 shot or 10 shot. Therefore, it becomes challenging to assess the method's generalization capability across varying data quantities.\nQuestions:\nDue to the limited sample size in the dataset, avoiding overfitting poses a central challenge in few-shot learning. However, the paper lacks an in-depth discussion on this issue and does not introduce method-level strategies to alleviate the problem.\nThe authors should consider validating their method on the dataset with a significantly larger domain difference.\nThe introduction of multi-view seems to be optional. Additionally, there is no information exchange between the multi-view sub-networks.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9283 by Reviewer caBF", "Subheading": "Official ReviewbyReviewer caBF05 Nov 2023, 10:35 (modified: 04 Dec 2023, 04:36)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a multi-view representation learning method, where the key idea is to modulate features in the View-specific encoding and Fusion modules according to the task guidance. The authors design a gradient-based embedding strategy to represent multi-view tasks. In addition, a meta-learner is trained to map the task embedding into a set of view-specific parameters and a view-shared parameter. This whole process is formalized as a nested optimization problem and ultimately solved by a bi-level optimization scheme.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe paper proposes a task-oriented multi-view representation Learning method from a meta-learning perspective. The performance of classification and clustering tasks is improved significantly.\nThe proposed method defines an unsupervised multi-view task in an episode fashion, and designs a meta-learner for modulating the view-specific features and unified entity representations with the task guidance.\nThe proposed method models meta-learning and multi-view learning as a nested bi-level optimization.\nWeaknesses:\nFor \u2018representations from multiple views can better serve the task\u2019 in the contribution 1. In fact, it explores the relationship amongst various tasks, from the perspective of multi-task learning, which is not enough as an innovation point.\nIn the section 3, the authors mentioned that the fusion process of features may also be inconsistent. The proposed method focuses on Fusion modules, how does the author align the features of similar instances in different tasks?\nThe authors should discuss the insight of this paper with the lifelong multi-view learning or multi-view multi-task learning.\nIn term of the loss function, the author does not introduce the concept of weight. For multiple tasks, the data distribution and importance of different tasks are different. How does the author solve this problem?\nThe current manuscript need to be carefully polished, such as, in the section 2, \u3016R\u3017^(d_H ) not R_(d_H ), in table 2, line 4, the font thickness should be consistent\uff1b the notations in equation (1)\nQuestions:\nPlease check the comments above.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer caBF", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:37Everyone", "Content": "Comment:\nThank you for your constructive comments, which were inspirational in refining the manuscript.\nResponse to Weaknesses 1 & 3 (Connections and differences with multi-view multi-task learning (MVMTL) and continuous/lifelong multi-view learning (CMVL)):\nMVMTL, CMVL, and our TOMRL all consider both multi-view and multi-task scenarios, exploiting comprehensive feature representation of multiple views in each task as well as the task relationships of multiple related tasks. However, they are different in terms of learning objectives, key challenges, and practical settings.\nMVMTL follows the multi-task learning setting\n, where the learning objective is to improve performance on the main task through joint training on multiple related (auxiliary) tasks. Key challenges include selecting/designing auxiliary tasks, balancing loss functions across multiple tasks (Weakness 4), etc. The counterpart is conventional (single-view) multi-task learning, with the difference that MVMTL utilizes comprehensive information (e.g., consistency and complementarity, etc.) from multiple views of each task. Once the multi-view information is well integrated, most MVMTL methods degrade to the conventional multi-task scenario [1].\nCMVL follows the continuous learning setting\n, where the learning objective is to handle new tasks without performance degradation on previously learned tasks for a series of consecutive tasks. The key challenge is to overcome catastrophic forgetting. Similarly, the counterpart is conventional (single-view) continuous learning, with the difference that CMVL utilizes comprehensive information from multiple views of each task.\nOur TOMRL follows the meta-learning setting\n, where the learning objective is to rapidly handle new downstream tasks by learning meta-knowledge over multiple tasks. To this end, we construct task-level training and test sets on the multi-view dataset and train the model in an episodic fashion. The counterpart is conventional (single-view) meta-learning, with the difference that TOMRL considers both view-specific representations and fused unified representations in the meta-learning process. If the multi-view properties of the task are ignored, TOMRL degrades to a regular meta-learning approach.\nIn addition, we review existing works involving ''meta-learning'' and ''multi-view learning'' in the manuscript, and most of them aim to improve the performance of meta-learning methods by utilizing multi-view information rather than the fast adaptation of multi-view representations in different downstream tasks.\n[1] Lu, Run-kun, et al. Multi-view representation learning in multi-task scene.\nNeural Computing and Applications\n32 (2020): 10403-10422.\nResponse to Weakness 2 (Feature alignment of similar instances in different tasks):\nWe apologize for some misunderstandings due to unclear writing in the manuscript. Firstly, the basic principle \u2018\u2019b) the fusion process of features may be inconsistent\" mentioned in Section 3 means that \u2018\u2019given multiple view-specific features, the unified representation fused for different downstream tasks should be different using the same fusion strategy\u2019\u2019, rather than \u2018\u2019the fusion strategy being performed in different tasks should be different\u2019\u2019. In contrast to the latter, the former does not suffer from feature misalignment due to the same fusion strategy. Existing multi-view representation learning methods pay little attention to this unified representation inconsistency, i.e., once the feature extraction and fusion strategies are given, the unified representation is determined. Part of our motivation comes from this gap between existing methods and the basic principle (the other part comes from the basic principle (a) in Section 3). Secondly, our TOMRL inherits model-agnostic advantages from gradient-based meta-learning, which makes it flexible enough to be integrated into a variety of multi-view learning models and, of course, a variety of fusion strategies.\nResponse to Weakness 4 (Weights of the loss function):\nIn the response to Weakness 1, we discussed the differences between the multi-view multi-task learning methods and the proposed work. The weighting of the loss function is a key issue in jointly training multiple tasks, but is not a concern in TOMRL, which follows a meta-learning \"episode\" training fashion.\nResponse to Weakness 5 (Notation mistakes):\nThank you very much for your constructive suggestions. These notation mistakes have been revised in the revised manuscript."}]}, {"Heading": "Official Review of Submission9283 by Reviewer V7F6", "Subheading": "Official ReviewbyReviewer V7F604 Nov 2023, 01:49 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents a gradient-based embedding strategy to flexibly represent multi-view tasks. The authors propose a meta-learning-based solution and learns task-oriented multi-view representations, where meta-learning and multi-view learning are ultimately formalized as a nested optimization problem and solved via a bi-level optimization paradigm.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n3 good\nStrengths:\nResults on four datasets are presented on multi-view tasks.\nEmpirical study shows that the method consistently improves the performance of downstream tasks for both few-shot and routine tasks.\nWeaknesses:\nWhy two modulation processes are useful in this task was unclear.  Also, the benefit of the TOMRL on different dataset domain is also not discussed or analyzed in the paper. I think the paper should at least study at least one scenario , e.g., NoisyFashion to Caltech 101-7, to verify the effectiveness of TMORL as this is considered as one of the main contribution of the paper. It shall also be helpful to analyze why TOMRL is helpful in learning a high-quality unified representation, perhaps from the perspective of gradient analysis.\nThe display of experimental results in this paper is not uniform. For example, bold results in some tables indicate the best results, while others denote the results of TOMRL. Please unify the form in the full text. Alternatively, give clear comments in each table title.\nQuestions:\nRegarding the cross task experiment in Table 3, the proposed TOMRL brings a decrease in NMI indicators of NoisyFashion to EdgeFashion. With the significant growth MORL has brought under other conditions, why did this particular decline occur?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer V7F6", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:39Everyone", "Content": "Comment:\nThank you for your constructive comments.\nResponse to Weakness 1 (Different dataset domain):\nThank you for your valuable suggestion on ''experimenting on different dataset domains\u2019\u2019. The performance of TOMRL in cross-domain scenarios has been validated on two variant datasets, NoisyFashion and EdgeFashion, in Sec. 5.3 of the manuscript. The experiment setting of ``cross-domain between NoisyFashion (2 views) and Caltech101-7 (6 views)'', mentioned by the reviewer, is challenging for the current framework. This challenge comes from the fact that existing multi-view models are sensitive to the number of views. Although the gradient-based task embedding (in Sec. 3.1.2) provides flexibility in handling tasks with different scales (i.e., ways and shots), TOMRL, and in particular the meta-learner, is still based on the existing multi-view models. Therefore, the key to implementing the cross-domain \"between NoisyFashion and Caltech101-7\" is to design a unified model that can handle data with different numbers of views, which is not the focus of this work but is worth investigating and is part of our future work.\nResponse to Weakness 2:\nThank you for your valuable suggestions. The revised manuscript explains the special markings in each table title.\nResponse to Questions:\nWe rechecked the experimental results. One possible reason is that TOMRL improves the number of samples clustered correctly, but does not significantly improve the cluster distribution obtained by InfoDDC in this scenario."}]}, {"Heading": "Official Review of Submission9283 by Reviewer d8EV", "Subheading": "Official ReviewbyReviewer d8EV31 Oct 2023, 10:52 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors propose a model to learn task-oriented multi-view representation. Based on the observation that almost all of current models ignore the basic fact that effective representations are different for different tasks, even for the same entity, they propose a Task-Oriented Multi-View Representation Learning (TOMRL) method.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nLearning task-oriented multiview representation is important.\nWeaknesses:\nThe motivation is not clear. For example, there are many methods could learn task-oriented representation and multi-view representation, however, the authors only provide some examples which are not applicable for out-of-sample data or only learning the uniform representation for entities. It is not convincible.\n\u201cA typical multi-view representation learning framework consists of four main components: View-specific encoding, Single-view learning (SVL), Multi-view learning (MVL), and Fusion.\u201d  It is a very strong claim or assumption. The authors should provide a comprehensive study and moreover a formulation to unify these models is necessary.\n\u201chow representations from multiple views can better serve the task\u201d I think this is a very natural requirement in many models. So, I do not find any necessity or novelty for this claim.\nThe writing and organization are not clear. It is difficult to understand the motivation and why the proposed model is good.\nQuestions:\nThe claim that there are four components is questionable, so the authors should provide more clear and strict evidence or analysis.\nThere are no theoretical results.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer d8EV", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:40 (modified: 23 Nov 2023, 05:41)EveryoneRevisions", "Content": "Comment:\nThank you for your constructive comments, especially on the multi-view representation learning framework, which is helpful to improve our work!\nResponse on Motivation and Innovation (Weaknesses 1 & 3 & 4):\nTo more clearly demonstrate our motivations and innovations, we review related research, especially in multi-view multi-task learning (MVMTL) and continuous multi-view learning (CMVL), which both involve multi-view and multi-task scenarios.\nMVMTL follows the multi-task learning setting\n, where the learning objective is to improve performance on the main task through joint training on multiple related (auxiliary) tasks. The counterpart is conventional (single-view) multi-task learning, with the difference that MVMTL utilizes comprehensive information (e.g., consistency and complementarity, etc.) from multiple views of each task. Once the multi-view information is well integrated, most MVMTL methods degrade to the conventional multi-task scenario [1].\nCMVL follows the continuous learning setting\n, where the learning objective is to handle new tasks without performance degradation on previously learned tasks for a series of consecutive tasks. Similarly, the counterpart is conventional (single-view) continuous learning, with the difference that CMVL utilizes comprehensive information from multiple views of each task.\nUnlike the above two types of methods, our\nTOMRL aims to learn the task-oriented multi-view representation\nwith the goal of learning task-level experience from numerous historical multi-view tasks, enabling the model to adapt quickly when dealing with unseen new multi-view tasks.\nMOTIVATION:\nExisting models for learning multi-view representations (especially in unsupervised settings) mostly focus on how to integrate comprehensive information from multiple views at the data level while neglecting fast adaptation on different tasks.\nINNOVATION:\nWe provide a meta-learning perspective for task-oriented multi-view representation learning. 1) We define the ``episode'' form of supervised and unsupervised multi-view learning tasks, and construct meta-training and testing sets at the task level. 2) Based on the two basic principles mentioned in Section 3, we design a meta-learner for feature modulation and train it in an episodic fashion. 3) For an unseen new multi-view task, the well-trained meta-learner generates a set of modulation parameters that help the model quickly derive the uniform representation specific to this task.\nResponse on multi-view representation learning framework (Weakness 2):\nThe multi-view learning framework mentioned in this paper is extended by the deep multi-view clustering framework [2]. Thanks to your valuable comments, we rethink the rigor of this extension.\nFollowing the survey studies[3, 4], multi-view representation learning can be roughly divided into\nalignment-based\nand\nfusion-based\nmethods. Let $x^1$ and $x^2$ denote the two views of sample $x$, alignment-based methods can be symbolized as $f(x^1;W_f)\\leftrightarrow g(x^1;W_g)$, where $f$ and $g$ denote the feature extractors of view 1 and view 2 with corresponding parameters $W_f$ and $W_g$, respectively, and $\\leftrightarrow$ denotes the alignment operation. Similarly, the fusion-based approach can be expressed as $H=F((f(x^1;W_f), g(x^1;W_g)); W_F)$, where $F$ is the fusion operation with the parameter $W_F$, and $H$ denotes the fused unfied representation. Although recent work [5] has attempted to integrate the two into a unified framework, it is clear that our TOMRL is strictly more suitable for fusion-based multi-view representation learning methods due to the fusion operations involved. Therefore, we modify ''the multi-view representation learning framework'' to ''the  fusion-based multi-view representation learning framework'' and clarify the research scope in the revised version.\n[1] Lu, Run-kun, et al. Multi-view representation learning in multi-task scene.\nNeural Computing and Applications\n32 (2020): 10403-10422.\n[2] Trosten, Daniel J., et al. On the Effects of Self-supervision and Contrastive Alignment in Deep Multi-view Clustering. In\nCVPR\n2023.\n[3] Li, Yingming, et al. A survey of multi-view representation learning.\nIEEE TKDE\n31.10 (2018): 1863-1883.\n[4] Yan, Xiaoqiang, et al. Deep multi-view learning methods: A review.\nNeurocomputing\n448 (2021): 106-129.\n[5] Wang, Ren, et al. MetaViewer: Towards A Unified Multi-View Representation.\u00a0In\nCVPR\n2023."}]}, {"Heading": "Official Review of Submission9283 by Reviewer fqyn", "Subheading": "Official ReviewbyReviewer fqyn29 Oct 2023, 10:49 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper argues that the semantic features required for different tasks may vary when using the same representation. Therefore, it proposes a task-oriented multi-view representation learning method. The paper adopts a meta-learning paradigm, defines multi-view tasks, and retains both task-specific information for each view and unified information across views. Additionally, it introduces task bias for different tasks. This method can be integrated into existing multi-view representation learning methods and has shown performance improvements.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe motivation and idea presented in this paper are reasonable. The introduction of the paper effectively highlights that multi-view representations should focus on both the unified representation and the unique information of each view, and should adapt to different representations for different tasks.\nThis paper leverages a meta-learning paradigm to generate task bias and integrates it into existing multi-view representation learning methods, resulting in performance improvements.\nWeaknesses:\nThe paper artificially defines downstream tasks for multi-view representation learning, but typically representation learning aims to acquire a general representation that can be fine-tuned for different specific tasks. Is it unfair to directly consider downstream tasks in the representation learning, and can the representations learned in this paper still perform well for new tasks that are not considered in the paper?\nThe paper is not very clear in explaining how the meta-learning paradigm generates task-specific biases and whether it can explain why using task bias generated by the meta-learning paradigm can improve the model's performance.\nThe experimental evaluations are not comprehensive enough in several aspects. The dataset used in this paper is not sufficiently diverse. For example, commonly used datasets in this field, such as NoisyMNIST, EdgeMNIST, Caltech20, and PatchedMNIST, were not tested. Additionally, the paper only integrates the method into three approaches, all from the same source paper. It is hoped that the authors can validate their method by integrating it into a wider range of methods to enhance its credibility.\nQuestions:\nFor major concerns including the problem/experimental setting, unclear description, and experimental evaluation, please see weaknesses for details.\nThere appears to be a minor error in the pseudocode. Should line 20 be placed after line 21?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer fqyn", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:44Everyone", "Content": "Comment:\nThank you for your constructive comments.\nResponse to Weakness 1 (Experimental settings):\nWe apologize for some distress caused by the unclear experimental setup in the submitted manuscript.\nIt should be clarified that our experiments are fair because all methods (including our TOMRL) use the same data in the training and testing stages.\nSpecifically, both the comparison methods and baseline methods were allowed to train to convergence on the full dataset $D$. We then constructed $D$ as a set of (multi-view few-shot) tasks and randomly selected 100 tasks for testing. The remaining tasks were used for the training of the meta-learner in an episodic fashion, as shown in Alg. 1 in the manuscript. The well-trained TOMRL was also tested on the same 100 tasks. Note that these test tasks are never used to fine-tune any method to ensure a fair comparison. In other words, they are new and unseen tasks for both the compared methods and our TOMRL. This experimental setting ensures that the performance gains from TOMRL are derived from meta-learned task-level knowledge.\nResponse to Weakness 2 (Why TOMRL works):\nAs mentioned in the response to Weakness 1, we train the meta-learner additionally at the task level for the well-trained existing multi-view representation model. Indeed, the meta-learner is expected to learn a set of mappings from task embeddings to modulation parameters, in order to quickly adapt to unseen new tasks. More specifically, for each task in the meta-training stage, the meta-learner generates modulation parameters for the support set and performs clustering or classification on the query set using the modulated features. Minimizing the loss on the query set can induce the meta-learner to learn better mappings.\nResponse to Weaknesses 3 (Additional experimental results):\nAs a supplement, the following tables list the results of the TOMRL method on the four datasets suggested by the reviewer. Note that the results on the PatchedMNIST dataset are not included because PatchedMNIST is a subset of the MNIST dataset containing only the first three classes [1], which does not satisfy the settings of the 5-way task.\nTable: The ACC$_{clu}$ values on 100 5-way 5-shot clustering tasks\nNoisyMNIST\nEdgeMNIST\nCaltech20\nAE-KM\n62.00\n59.73\n37.12\nw/ TOMRL\n63.14\n62.03\n38.85\nAECoDDC\n68.24\n64.54\n60.60\nw/ TOMRL\n68.48\n66.08\n62.34\nInfoDDC\n65.18\n43.20\n57.60\nw/ TOMRL\n66.83\n45.43\n61.07\nTable: The NMI values on 100 5-way 5-shot clustering tasks\nNoisyMNIST\nEdgeMNIST\nCaltech20\nAE-KM\n76.11\n71.84\n70.39\nw/ TOMRL\n76.38\n72.17\n70.71\nAECoDDC\n78.39\n71.93\n66.80\nw/ TOMRL\n77.90\n71.64\n68.42\nInfoDDC\n76.80\n56.18\n61.57\nw/ TOMRL\n78.74\n58.53\n64.35\n[1] Trosten, Daniel J., et al. On the Effects of Self-supervision and Contrastive Alignment in Deep Multi-view Clustering.\u00a0In\nCVPR\n2023.\nResponse to Questions (Minor error):\nThanks for pointing out the error. We've fixed this error in the revised manuscript: switched lines 20 and 21 in pseudo-code."}]}]}, "ILStlRb1Sp": {"paper_info": {"Primary Area": "generative models", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "language models, memorization", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We investigate memorization in large language models using random strings and show that tokens are memorized independently and that global and local context both play a distinct role in recollection.", "Abstract": "Understanding whether and to what extent large language models (LLMs) have memorised training data has important implications for the privacy of its training data and the reliability of its generated output. In this work, we focus on the more foundational question of how LLMs memorise training data. To this end, we systematically train LLMs of different sizes to memorise random token strings of different lengths and different entropies (i.e., sampled from different alphabet distributions) and study their ability to recall the strings. We observe many striking memorisation dynamics including (i) memorisation in phases with the alphabet distributions in the random strings being learnt before their relative positions in the string are memorised and (ii) memorisation in parts at the granularity of individual tokens, but not necessarily in the order in which they appear in the string. Next, we investigate memorisation mechanics by checking to what extent different parts of a token\u2019s prefix in the string are necessary and sufficient to recollect the token. We leverage our insights to explain the dynamics of memorising strings and we conclude by discussing the implications of our findings for quantifying memorisation.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9281", "PDF Url": "https://openreview.net/pdf?id=ILStlRb1Sp"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9281 by Area Chair kfTS", "Subheading": "Meta ReviewbyArea Chair kfTS04 Dec 2023, 04:03 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper studies memorization in causal LMs by finetuning a pre-trained model to learn random strings. The results show a two-phase learning dynamic, where first the token distribution is learned, and then token position is acquired. They uncover moreover that small prefixes suffice to generate memorized strings.\nThe issue of how LMs memorize information is of theoretical and practical importance, and the experiment is well-designed and easy to follow in its simplicity.\nThe main concern raised by the reviewers is whether studying learning of completely random strings in a controlled, small-scale setup in which the model is only exposed to one type of training data is indicative of what happens in large LM training, where memorization and generalization are strongly entangled. This is a difficult conundrum: on the one hand, if we don't simplify the problem, we cannot assess the impact of different factors. On the other hand, if we simplify, it's not clear we are studying the same problem anymore.\nIndeed, the fact that, in the experiments with the more state-of-the-art Llama 2 models, the two-phase pattern disappears casts doubts on the generality of the results.\nI would consider this a small but potentially useful contribution, but a majority of reviewers, even after rebuttal, do not think the article has sufficient potential impact to appear at ICLR in its current version.\nJustification For Why Not Higher Score:\nA majority of reviewers expressed a strong concern about the general implications of the study.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 12:14Everyone", "Content": "Comment:\nWe thank all reviewers for their time and feedback, which is valuable to help us improve the paper! We address common issues below and specific comments in the responses to each reviewer.\nChanges in the revised version of the paper\nWe uploaded a revised version of the paper to address some of the issues that were raised. It contains the following changes:\nWe clarified the token vs character terminology and revised the description of the data-generation process accordingly in Section 2.\nWe included results on Llama 2 models in Section 3, as well as a discussion of their behaviour using observations about in-context learning in Appendix A.3.\nWe added a brief rationale for using the term mechanics in Section 4.\nWe added results in Appendix C.2 showing that string-based memorization metrics like the ones in Carlini et al. (2022) can severely underestimate the amount of memorization in a string.\nWe added a missing citation in Section 1.1.\nWe added examples of the random strings used in the apper in Appendix A.4.\nWe moved more of the description of Figure 8 into its caption.\n(1) The random string setting is not representative of natural language\nWe conduct our experiments on random strings, because they i) guarantee that models have not seen the strings during pre-training, ii) ensure that models have to memorize the data in order to achieve low loss, and iii) give us precise control over all aspects of the data, such as string length, alphabet size, and entropy. Achieving all of these properties with natural language would not be possible. We believe that understanding memorization of random strings is valuable in its own right, for the following reasons:\nSensitive data is often similar to random strings\n: A lot of sensitive data looks -- at least partially -- similar to random strings, such as API and SSH keys, passwords and usernames, phone numbers, URLs, social security numbers, etc. Therefore, memorization of such strings might happen in a similar manner to what we observe in the paper.\nPreliminary results on natural language data suggest similar trends\n: Prompted by our findings on random strings, we also conducted follow-on experiments on natural language data, by training models to memorize news articles not published yet when the models were trained. In many cases, we can make similar observations as for random strings. For instance, larger strings take longer to memorize, larger models memorize faster, there is no directly discernible order of memorization in the string (though we did not test for Tirumala et al (2022)\u2019s findings yet), and short prefixes are sufficient to recall many of the tokens correctly, though fewer than in random strings (5 token prefixes recall ~95% vs ~90% in ~128 token strings, ~80% vs 65% in ~512 token strings, in random vs natural language strings). Some other observations differ, as expected, e.g. we do not observe a distinct Guessing-Phase (probably due to the much larger and more sparsely used token vocabulary), and some are not straightforward to test, e.g. the role of alphabet size and entropy on memorization speed. Overall we believe that memorization in natural language data follows broadly similar trends, but more research is needed to get conclusive evidence.\nMemorization of natural language data warrants its own paper(s)\n: Cleanly understanding memorization in natural language data requires solving a number of challenging problems, such as distinguishing between tokens correctly predicted due to memorization vs reasoning using grammar and other rules and determining whether substrings of any strings used for memorization might have appeared in the training data. One would also want to study the impact of other dimensions on memorization than the ones relevant for random strings, such as e.g. the type of PII data (phone numbers, email addresses, etc.) vs alphabet size and entropy. We already have more interesting observations on random strings than can comfortably fit into a single paper. To include results and methodology for natural language, we would have to omit important results on random strings. Therefore, memorization of natural language strings very much warrants its own, separate paper(s) and we will keep this paper focussed on random strings. We believe, however, that our insights from random strings will be valuable for finding interesting research questions in this space. Our methodological approach can serve as a template for research on memorization in natural language data, as well for learning on structured data by using formal grammars, for instance.", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 12:15Everyone", "Content": "Comment:\n(2) The memorization mechanics terminology may not be appropriate\nWe call some of our findings mechanics, because (similar to physics) they can be used to explain and predict the dynamics, e.g. differences in memorization speed for strings of the same length and different alphabet sizes because models need to learn associations with prefixes of different lengths, different splits of the same string having almost the same memorization speed, because models learn the same prefix mappings, etc. We argue that you can model the mechanics of a system at multiple levels (e.g., classical vs. statistical vs. quantum mechanics in physics). In this work, we are concerned with the mechanics at the level of (latent) mappings learned by the LLM, i.e. based on how the outputs of models correspond to their inputs, in the context of random string memorization. We show distinct roles that the exact prefixes and the remaining context play. In addition to the input-output level dynamics, there are also lower-level dynamics, which is often what mechanistic interpretability is concerned with. An analogy for multi-level dynamics in physics would be the mechanics of a spring. Its behaviour can be modelled and explained at a high-level (how much does some amount of force stretch the spring) or at an internal level (how is the atomic lattice structure of the sprint deformed by applying the force) and also at the level of quantum-mechanics (how do atoms in the sprint interact). All of these are different levels of studying mechanics of the same object. We focus on the higher-level mechanics here.\n(3) Why studying memorization at the token-level (rather than the string-level) may be more appropriate\nOur results caution against a priori assuming specific memorization patterns. Prior work on quantifying memorization (Definition 3.1 in Carlini et al (2022)) implicitly assumes memorization in a block contiguous structure. Such a definition may be too strict and may fail to detect largely memorized strings, even if just a few tokens within a string are not fully memorized. We include experiments in the revised version of the paper in Appendix C.2 that show that, indeed, the aforementioned string-based metric only detects a small fraction of substrings of almost completely memorized 1024 random token strings as memorized. Detecting memorization at the token-level provides a better picture of the actual degree of memorization.\nA simple way of using our insights to improve the detection of memorized strings in practice therefore would be to count the number of (not necessarily adjacent) correctly recollected tokens in a string, given prefixes from the same string. The higher the fraction of correctly predicted tokens, the more likely it is that the model has memorized (parts of) the string. This may be more robust than requiring that the entire string is reproduced correctly by the model without gaps."}]}, {"Heading": "Official Review of Submission9281 by Reviewer NLd8", "Subheading": "Official ReviewbyReviewer NLd806 Nov 2023, 14:26 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper explores the dynamics and mechanics of memorization in causal LMs, where memorization is tested by finetuning pre-trained LMs on random strings. The main results are that (1) memorization occurs in two steps, first fitting to the bag-of-tokens distribution followed by fitting token position; (2) memorizing a token in a sequence doesn't depend on token position; (3) small local contexts are sufficient to greedily generate the memorized token; however, (4) long-range context needs to match the bag-of-words token distribution. Experiments span model sizes (140M -> 12B) and families (Pythia, GPT), as well as length, vocabulary size, and vocabulary entropy of the random string.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nSoundness\nThe methods proposed are technically sound and the results are interesting. The ablations on the influence of global context were well-crafted, where it is found that the token distribution in the global context is important for memorization.\nPresentation\nOverall, the paper is written clearly with an easy-to-follow structure/organization, with some minor exceptions (see weaknesses).\nSignificance\nThe methodological framework proposed, including analysis of local/global context, identifying phase transitions in learning, and analyzing order of token memorization, is interesting, easy-to-understand, and can help spark new research in this growing area. Even though the study is done on a very restricted setting, the results demonstrate the usefulness of the\nmethods\nat teasing apart different stages of memorization.\nWeaknesses:\nSoundness\nSeveral modeling choices could be better-motivated, and I was unclear on some conclusions. See detailed comments 2, especially 12, 13.\nPresentation\nMajor comments\nIt was unclear to me the relationship between a character and a token (though ultimately it doesn't impact the overall message of the paper) (detailed comments 4, 8, 9).\nFigures and figure captions (detailed comments 11, 15)\nMinor comments/suggestions (didn't impact the score)\nSee detailed comments 1, 2, 5, 6, 10\nContribution\nThis paper explores memorization in a very restricted toy setting, which the authors allude to in the introduction. Despite motivating the work with applications to, e.g., privacy and factuality for\nnatural language\n, all analysis is done on random strings, an extreme edge case. It is unclear whether the findings will generalize to structured natural language strings, as some results seem to rely on the randomness of the strings (detailed comments 3, 14, 18). Moreover, structured strings are not difficult to generate in a controlled manner using a probabilistic grammar (detailed comment 16). As the focus is on random strings over something more similar to natural language, it is unclear how useful the results are beyond the problem statement defined in the paper. This is my main reservation against acceptance.\nResults could be better situated in past findings. For instance, Tirumala et al. (2020) also test the effect of model size and dataset size on memorization with similar results. See detailed comments 14, 18.\nMissing reference:\nUnderstanding Transformer Memorization Recall Through Idioms\n(Haviv et al., EACL 2023)\nDetailed Comments\np1 last paragraph, end of p2:\nIn Transformer interpretability literature,\nmechanics/mechanistic\noften refers to \"mechanistic interpretability\", or analysis of how architecture internals like computational circuits lend to behavior. This work does not do that, so the naming may be confusing. Instead, the authors might want to consider diachrony/synchrony or dynamics/statics.\np2 paragraph 1:\n\"of different entropies (by sampling tokens at each position...\" Larger vocabulary size naturally increases entropy-- to truly disentangle the effect of\nentropy\n, as suggested, it would be better to keep the same vocabulary size and modulate the token sampling distribution. Alternatively, remove the focus on entropy from this paragraph, replacing with, e.g. \"of different vocabulary sizes, which also modulates token entropy, by sampling...\".\np2 paragraph 1:\n\"Our choice of random strings to study memorisation is deliberate... cannot be explained by other factors such as learning rules of grammar or reasoning.\" Language Transformers in-the-wild are trained on natural language, which is governed by grammar. In the introduction, the paper's potential impact is framed in the context of naturalistic text (e.g., privacy, factuality, etc); however, this study is restricted to single random strings.\nSection 2.1:\n\"To create a random string, we first choose an alphabet $A$ that consists of $|A| = l$ unique characters; we call $l$ the length of the alphabet. The alphabet we use for string generation is a subset of a much larger vocabulary of all tokens $V , A \\subset V$ .\" It is  confusing what a character is. This line implies the alphabet is a subset of tokens in the tokenizer vocabulary.\nSection 2.1 last parag:\n\"This definition assumes that $\\mathcal M$ predicts for position i the token with the largest $P_{\\mathcal M}(s_i = t | s[1,i\u22121]))$.\" is redundant.\nSection 2.1 last parag:\ninstead of defining a new term\nplurality prediction\n(which is never used again in the article), I would suggest using\ngreedy prediction\nor\ntop prediction\nas commonly used in the literature.\nSection 2.2:\n\"we enforce character-level tokenization... we keep the same subword vocabulary size as the original tokenizer, recognizing that it can impact memorization\" This implies that all characters \"a-z\" are individual tokens in the vocabulary? Enforcing character-level tokenization is confusing given detailed comment 4: does the alphabet consist of individual characters like a-z or individual tokens in the tokenizer vocabulary?\nParagraph Alphabets and string lengths:\n\"we focus on alphabets $A$ with $l \\in {2, 4, 7, 13, 26}$ using the first $l$ letters of the Latin lowercase alphabet, i.e. $A \\subset {a, . . . , z}$. We generate random strings of lengths $n \\in {16, 32, 64, 128, . . . , 1024}$.\" This can be moved earlier to Section 2.1 to improve clarity.\nIt would be nice to include\nexamples of the random strings.\nSection 3.3:\nOnly in the first parag of section 3.3 is it clear that the LM is only learning one string at a time. Ideally this should be made clear earlier in the paper.\nFigs. 3-5\n_ have GPT2-130M,\nFigs 1,2,7\nhave GPT2-140M.\nAt\nposition 0 in Fig. 5a\n, the probability is also uniform. Is this given a\n<BOS>\ntoken? That is, the probability mass should be spread over the entire vocabulary space and should better reflect the first-token statistics of the pretraining data.\nSection 3.3:\n\"we conclude that memorisation happens at the granularity of individual tokens and not entire strings.\" Is this surprising, given that training is via teacher-forcing on a token-level objective?\nSection 4.2:\n\"at epoch 30 and later, the accuracy of short prefixes, which correspond to less than 5% and 10% of the total string length, is close 100%, which is also the performance of the full prefix when the model has converged. Thus, small local prefixes \u2013 much shorter than the entire string \u2013 are very effective at correctly recalling tokens.\" Is this surprising? If the string looks random, then a local prefix is sufficient, as the n-gram will have very low probability. Then, a local prefix will have high mutual information with the next token. This result may not generalize to structured strings containing highly predictable n-grams. This recalls Tirumala et al. (2022) finding that \"highly informative\" tokens such as numbers get memorized first.\nFig. 8:\nFlesh out the caption to be standalone.\nDiscussion:\nThe discussion on generalising to non-random strings could be expanded. Virtually all applications of language Transformers apply to structured strings (natural language). E.g., rather than define the distribution over the\nalphabet\n, the distribution over strings can be defined using a\nprobabilistic grammar\n.\nDiscussion:\n\"For instance, to infer whether a token string is a member of the training data, it may be sufficient to infer that some unique part of the string has been memorised.\" The results show that memorization happens on a token-by-token basis-- then, does token-level memorization really tell you anything about the string-level? E.g., if you prove that the word \"The |\n<BOS>\n\" has been memorized by the model, then does that prove that \"The sky is blue\" has been memorized?\nThe result that token positions are equally likely to be memorized first may also be a consequence of using random strings, as the n-gram probabilities are the same. As soon as you move to non-random strings, this result may break down due to the statistics of natural language. For instance, Tirumala et al. (2022) find differentiated memorization speed according to POS.\nQuestions:\nSee detailed comments 4, 8-9, 12-14, 17\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 12:19Everyone", "Content": "Comment:\nWe thank the reviewer for their very detailed and thoughtful feedback! You are raising great points which are very helpful to improve the paper! We address them below.\nClarifying the string construction process\nThe vocabularies of the tokenizers used in this paper contain both tokens for individual characters, e.g. \u201ca\u201d, \u201cb\u201d..., as well as tokens spanning multiple characters, e.g. \u201cabs\u201d. By \u201ccharacter-level tokenization\u201d we mean that we only use tokens corresponding to individual characters, not character sequences. To make this part clearer, we updated the terminology in the string construction process in the revised version of the paper. We refer to the elements of the alphabet as tokens and only use the term character if the alphabet tokens indeed correspond to the characters in the Latin alphabet.\nThe random string setting is not representative of natural language (DC 3, 14, 18)\nSee global response (1).\nWe should use structured synthetic data, i.e. probabilistic formal grammars (DC 16)\nUsing formal (probabilistic) grammars to create structured data is a great way to investigate how models learn to reason according to the grammar rules, and we are exploring this direction. We believe, however, that it is not directly suitable for understanding memorization. Intuitively, for a string to be memorized, a model must have seen and remembered it from its training data, there should not be any other way to generate it. We can achieve this with random strings, but if we generate data in a structured manner, models might produce valid strings by learning and using grammar rules, instead of memorizing the training strings.\nMissing discussion of related work\nThank you for pointing out the relevant related work and the connection between our findings and those of Tirumala et al. (2022). We added the missing reference in the revised paper.\nThe work of Tirumala et al. (2022) and their findings about memorization order are indeed relevant in light of our observations about random memorization order. Their high-level message that different parts of text can be memorized at different speeds, and that memorization order is thus hard to predict matches our findings. However, we are skeptical about the soundness of some of their claims on memorization order. Their definition of memorization is problematic, since it considers any correctly predicted token $y$ following a prefix $s$ as memorized. However, it is likely that at least some correct predictions do not happen because of memorization, but rather because of other reasoning abilities that models are acquiring. Take for example \"This morning I drank a\", where models might correctly predict \"coffee\" without every having seen this sentence in their training data. Since their findings on differences in memorization order for different POS are based on this definition, we would approach them with caution and do not include a more extensive discussion.\nThe difficulty of disentangling memorization and predictions made using other mechanisms is the core reason for restricting ourselves to random data in this paper, because in random strings, correct predictions can only be attributed to memorization, since there are no rules to derive the next token from. We would like to point out, though, that we think studying memorization at the token-level, rather than string-level, is more appropriate (see global response (3)), but inferring memorization from just a single correctly predicted token seems highly optimistic. A more robust measure should check whether a reasonably large fraction of tokens in a sufficiently long string postfix are correctly predicted.\nResults on short prefix recollection are not surprising (DC 14)\nBeing able to uniquely predict the next token from short prefixes is only a\nnecessary condition\nfor the recollection accuracy we observe with short prefixes. It\u2019s not clear a priori whether models will converge towards some information-theoretically optimal solution. Models might memorize in several ways, and short prefixes are only one of them. Potential alternatives: models might form associations with longer prefixes (e.g. much more than 5 tokens in a 512 token string) as\nobserved in other settings\n, or also with tokens not immediately adjacent to the target token (e.g. at the beginning or in the middle of the string), they might learn to detect the number of preceding tokens to do position-based memorization, etc. It's not clear which option(s) models will use without further investigation, which we provide in this paper."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 12:21Everyone", "Content": "Comment:\nUnclear how to relate token- to string-level memorization (DC 17)\nIt is true that in a natural language settings, simply predicting a single token correctly, given some prefix from the training data, does not imply that that token (or a larger string that it is contained in) has been memorized, since the model could also predict that token using word statistics, grammar rules, etc. (e.g. \u201cblue\u201d in \u201cThe sky is blue.\u201d). It is merely a necessary condition for memorization, but not a sufficient one. Current approaches to quantifying memorization using string-based notions (Carlini et al. (2022)) assume that if a sufficiently long string from the training data is predicted exactly, given its prefix, then it is very unlikely that this is due to something other than memorization (because predicting each token exactly as in the training data independently is highly improbable). By focussing on random strings in this study, we sidestep this issue. If models can predict the next token correctly, it has to be because of memorization.\nWe discuss the implications of our findings for detecting memorization in the global response (3).\nThe memorization mechanics terminology may not be appropriate (DC 1)\nSee global response (2).\nOther detailed comments\nDisentangling entropy: To make sure that the behaviour we observe is indeed a result of the strings\u2019 entropy, we conduct a control experiment in Appendix A.2 (mentioned in Section 3.1). We modify the entropy of strings with fixed alphabet size (26) by increasing the probability of sampling the first character (\u201ca\u201d) such that the generated strings have the same entropy as the strings with smaller alphabet size. Our results show the same patterns for different entropy levels at the same alphabet size as for different entropies due to different alphabet sizes. Due to space constraints, we could not include these results in the main paper.\nWe removed this part in the revised version.\nWe switched to using greedy decoding terminology.\nWe added examples with different alphabet sizes and entropies in Appendix A.4.\nIn most cases we train models only on single strings, but in Figure 8 we also train them on multiple strings at a time, so this depends on the specific experiment.\nGood catch, 140M is correct, we corrected Figures 3-5 in the revision.\nWe do not use <BOS> tokens for GPT-2 and Pythia models. Figure 5a simply shows whether the token at the respective position has been predicted correctly at that timestep. The first column shows the prediction for the second token in the string, since the model does not produce a prediction for the first token (the output for the first token is the prediction for the second token). Please let us know if this doesn\u2019t clarify the question.\nWe are driving the loss to zero over all tokens in the string at the same time. Alternative memorization dynamics are therefore also conceivable, such as memorizing tokens in chunks, from left to right, etc. We discuss the implications of this finding in the global response (3).\nWe moved details and takeaways into the Figure caption."}, {"Heading": "Thanks for the response", "Subheading": "Official CommentbyReviewer NLd821 Nov 2023, 12:02Everyone", "Content": "Comment:\nThanks for the response! The paper is a lot clearer now. I will retain my score (explanation below), but won't oppose acceptance if other reviewers champion for it.\nAll of my remarks regarding clarity/presentation have been resolved. The remaining doubt I have is still the one on whether results on random strings will be relevant to the community. Re: the point on probabilistic formal grammars (\"We can achieve this with random strings, but if we generate data in a structured manner, models might produce valid strings by learning and using grammar rules, instead of memorizing the training strings.\"), formal grammars allow for primitives that are more than one character long, which still lets you have smaller random substrings within the string.\nAn example:\ne.g.\nS | A B\nA | [random string sampling one subset of the vocab]\nB | [random string sampling another subset of the vocab]`"}]}, {"Heading": "Official Review of Submission9281 by Reviewer LNRg", "Subheading": "Official ReviewbyReviewer LNRg03 Nov 2023, 08:23 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper focuses on better understanding the mechanism of memorization in LLMs. Basically, the authors tested on tasks of memorizing different random token strings, and observed the dynamics and mechanics of memorization.\nThere are several interesting observations:\nMemorization has two phases: (1) Guessing-Phase, and (2) Memorization-Phase. The first phase figures out which subset of the alphabet the target string contains. The second phase learns the conditional next-token probability to memorize the target string (within the subset chosen from the first phase)\nDuring the memorization-phase, memorisation happens at the granularity of individual tokens and not entire strings\nThe local context (small number of tokens in the target string) is sufficient to recollect a token at a given position\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nIt is focusing on a timely topic\nThe empirical observation has interesting messages\nWeaknesses:\nIt would be great if the authors explain how this observation can give some insight on the training strategy of LLMs. Currently, it looks like the paper has less practical impact.\nQuestions:\n.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 12:22Everyone", "Content": "Comment:\nWe thank the reviewer for their feedback and are glad they appreciate our work!\nPractical impact\nWhile the random string setting is not representative of many types of data models encountered in practice, we believe that our findings have practical implications for understanding and quantifying memorization in practice.\nFor instance, as we discuss in the global response (1), a lot of sensitive data looks -- at least partially -- similar to random strings, such as API and SSH keys, passwords and usernames, phone numbers, URLs, social security numbers, etc. Therefore, memorization of such strings might happen in a similar manner to what we observe in the paper.\nAdditionally, we discuss the implications of our results for detecting memorization in practice in global response (3). We argue that practitioners should not a priori assume a specific order of memorization and show that currently used memorization metrics can severely underestimate the degree of memorization of a piece of training data."}]}, {"Heading": "Official Review of Submission9281 by Reviewer ueBA", "Subheading": "Official ReviewbyReviewer ueBA02 Nov 2023, 06:59 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors propose to study the memorization of pre-trained LLMs on randomly generated strings. They propose to study the memorisation dynamic through training and the influence of the context required to elicit correct predictions. The conclusion of the study, for their very specific setting, is there's a guessing and a memorisation phase, that memorisation happens at token level in no particular order. Furthermore global context is not needed to be kept unchanged, but somehow needs to be preserved, and local context is sufficient.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper proposes a toy setting that studies memorisation on LLMs.\nThe authors consider a good variety of toy experiments that inspect the training dynamics and the importance of the context\nThe presentation is good\nWeaknesses:\nThe results of the analysis may be of littler or no practical usefulness. While the definition of a toy distribution of random strings removes the issue of having to disentangle generalization and memorization, it is unclear to what extent the findings actually reflect real memorization phenomena. This is reflected in the discussions/and implications sections that actually poses the truly interesting questions the authors should have tried to address.\nIt would be good if the authors could provide at least a few experiments that correlate their findings on synthetic data with real data.\nThe fact models first go through a guessing phase and then start memorising the actual data is unsurprising\nThe fact local context is sufficient more than global context may solely depend on the fact the model is autoregressive.\nQuestions:\nThe usage of the term dynamics is understandable, but why mechanics? The term may not be the best choice for the subject it refers to.\nCould the authors show experiments on context importance with models that are not autoregressive?\nRegarding the discussion section, I would advise the authors to at least carry out some experiments they mention and would validate the usefulness of their analysis in practical settings:\nIt would be interesting to at least see some experiments performed on non-random strings or a mixture of random and non-random strings. In that case the random strings would act like canaries that can be more easily detected and cannot be generalised to.\nIt would be also more interesting to study whether the influence of global/and local prefixes in recollecting tokens actually does result in stronger reconstruction attacks as suggested.\nOn the conclusion that future measures of memorisation should focus on tokens, this may be an issue of the methodology proposed by the authors. That's also why it would be good to provide evidence that quantifying memorisation at higher granularity is not sufficient.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 12:24Everyone", "Content": "Comment:\nWe thank the reviewer for their time and feedback. We address their concerns below.\nThe random string setting is not representative of natural language\nSee global response (1).\nThe existence of a guessing-phase is not surprising\nThe initial guessing phase is not necessarily expected. Why would a model first learn to associate prefixes with other tokens from the string's alphabet instead of trying to directly memorize the correct token, i.e. directly move into the memorization phase, since the latter reduces the loss even further? We added Llama 2 models to the revision of the paper and observe in Figure 1 (b) that they skip the guessing-phase completely and go straight to the memorization-phase. We show in Appendix A.3 that they are able to learn the token distribution in the string via in-context learning without additional training. This shows that the guessing phase does not happen automatically, but rather depends on the models\u2019 ability to detect distributions via in-context learning.\nMemorization in autoregressive/decoder-only models may behave differently from other types of models\nIn our paper we deliberately focus on autoregressive models. Autoregressive models are currently the most potent group of language models and are the most important models to study in the context of memorization, since due to their use for text generation they have a high propensity for leaking memorized private information, or for producing inaccurate outputs due to a lack of memorized facts. Many other recent papers also exclusively focus on this group of models. Studying bi-directional contexts would considerably increase the complexity of the analysis and warrant its own separate investigation.\nCould you provide us with more details on why you believe that \u201cThe fact local context is sufficient more than global context may solely depend on the fact the model is autoregressive\u201d? To us, it\u2019s not clear that the autoregressive nature of models implies a local-context based memorization. In fact, autoregressive models might memorize in several plausible ways, and short prefixes are only one of them. Potential alternatives: models might form associations with longer prefixes (e.g. much more than 5 tokens in a 512 token string), or also with tokens not immediately adjacent to the target token (e.g. at the beginning or in the middle of the string), they might learn to detect the number of preceding tokens to do position-based memorization, etc. It's not clear which option(s) models will use without further investigation, which we provide in this work.\nThe memorization mechanics terminology may not be appropriate\nSee global response (2).\nThere's insufficient evidence to challenge current notions of memorization\nSee global response (3)."}]}, {"Heading": "Official Review of Submission9281 by Reviewer jCFX", "Subheading": "Official ReviewbyReviewer jCFX31 Oct 2023, 07:55 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper studies how memorization occurs in pre-trained language models. In particular, pre-trained LLMs are further trained to minimize cross-entropy on a dataset of randomly sampled strings, where each character in the string is independently sampled from some fixed alphabet. The main point is that, as these strings are random, vanishing cross-entropy loss can only be explained by memorization during this training, rather than generalizing grammar rules or having seen the string during pre-training. The main result of the paper is that memorization happens in two phases. First, the model learns the marginal distribution of characters in the random strings (i.e. learns the alphabet), and second the model memorizes the strings. The paper contains further results showing that local prefixes of smaller length than the full prefix are sufficient for reconstructing the character at a given position.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe paper clearly demonstrates that language models first memorize the token-wise (or in the case of this paper character-wise) marginal distribution before memorizing longer sequences. This gives a clear explanation of the mechanics and dynamics of memorization in transformers, at least for random strings.\nWeaknesses:\nIt is quite unclear how practically relevant and/or surprising the observed phenomena are. For example, given $n$ random strings over an alphabet of size $l$, any fixed substring of length larger than $2\\log_l n$ is sufficient to uniquely identify each string with good probability by the union bound over all pairs of strings. This is probably sufficient to explain the fact that short prefixes are enough for recovering memorized characters.\nOn the practical relevance front, the authors write \"we argue that our findings call into question an implicit assumption made by existing studies: that memorisation can be reliably detected by checking if the full prefix up to some position in the string can correctly recollect the full suffix following the position (Biderman et al., 2023a).\" I do not see how the results in the paper support such a claim. As far as I can tell, this claim is based on the fact that a model may do well at predicting the next token in a random string from a small alphabet by guessing based on having memorized the marginal distribution, even if it has not yet memorized the whole string. This seems unlikely to be the main source of memorization in practical circumstances, where the relevant alphabet size (i.e. number of possible tokens) is quite large. Furthermore, it doesn't even seem to correspond well with the claims in the paper itself, where it is shown that random strings from small alphabets take longer to fully memorize.\nQuestions:\nIt is possible I am misinterpreting/misunderstanding the main claims relating to the practical relevance of the results in the paper. Is there some more concrete explanation of how these results could inform measurements of memorization? Or more details on how existing measures are making unsupported or misleading assumptions about how memorization should be measured?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 12:26Everyone", "Content": "Comment:\nWe thank the reviewer for their thoughtful feedback and good questions! We address them below.\nSome of the results are not surprising\nBeing able to uniquely predict the next token from short prefixes is only a\nnecessary condition\nfor the recollection accuracy we observe with short prefixes. It\u2019s not clear a priori whether models will converge towards some information theoretically optimal solution. Models might memorize in several ways, and short prefixes are only one of them. Potential alternatives: models might form associations with longer prefixes (e.g. much more than 5 tokens in a 512 token string) as\nobserved in other settings\n, or also with tokens not immediately adjacent to the target token (e.g. at the beginning or in the middle of the string), they might learn to detect the number of preceding tokens to do position-based memorization, etc. It's not clear which option(s) models will use without investigation.\nOther findings, such as the initial guessing-phase are also not necessarily expected. Why would a model first learn to associate prefixes with other tokens from the string's alphabet instead of trying to directly memorize the correct token, i.e. directly move into the memorization phase, since the latter reduces the loss even further? We added Llama 2 models to the revision of the paper and observe in Figure 1 (b) that they skip the guessing-phase completely and go straight to the memorization-phase. We show in Appendix A.3 that they are able to learn the token distribution in the string via in-context learning without additional training. This shows that the guessing phase does not happen automatically, but rather depends on the models\u2019 ability to detect distributions via in-context learning.\nThere's insufficient evidence to challenge current notions of memorization\nToken-level memorization\n: We discuss in the global response (3) why detecting memorization at the token-level may be more appropriate than at the string-level.\nRole of context in associations\n: We show that besides the exact prefix of a token (or a string), the context in which it appears also matters for recollection. Therefore, when a model $m$ does not associate string $s$ with prefix $p$, it is not sufficient to conclude that $m$ has not memorized $p | s$, because given the right context $c$, which may not have ever appeared in the training data, $m$ might recollect s given $c | s$. As an example: given the prefix\nAPI_SECRET=\n, $m$ might not produce any private information in the training data, and thus one might conclude that the model has not memorized the secret. However, when adding additional context, such as the contents of a file with Python code making an API call to a cloud provider, even if that code has never appeared in that exact form in the training data, it is possible that $m$ might produce an API key for that cloud provider it has seen during its training. This context may be the document in which $p | s$ appeared during training, but it may also be different. Current notions of memorization ignore the context beyond the exact prefix.\nMemorization/association strength\n: Even if a string has been memorized according to existing definitions of memorization, the implications of memorization can be very different depending on how frequently -- i.e. under how many contexts -- a model reproduces it. If a model only produces a memorized string in the context of the exact memorized source document, then the issue (or utility in the case of factual information) is less severe, but if the model produces a secret whenever\nAPI_SECRET=\noccurs, under a wide range of contexts, then this is a severe instance of memorization. Notions of memorization should take the strength/severity of memorization into account."}, {"Heading": "Official Comment by Reviewer jCFX", "Subheading": "Official CommentbyReviewer jCFX22 Nov 2023, 12:34Everyone", "Content": "Comment:\nThank you for your response, especially the clarifications (and the added section in the appendix) explaining the relationship between your results and existing measures of memorization.\nI agree that just because it is information-theoretically possible to memorize random strings based on small contexts this does not mean that transformers are guaranteed to do so. However, I do feel that the random string setting is quite idealized, and somewhat far from what we care about in practice. Thus, if there were some very surprising result on LLM memorization in the random string setting, this would be an interesting motivation to study what this implies in the practical setting. However, after reading the other reviews and the corresponding rebuttals, the results for random string setting seem largely unsurprising/predictable, and I don't see any interesting questions to ask about real-world memorization beyond slightly tweaking the metrics used. Notably the Carlini et al. (2022) paper to which you refer proposes another variant of the memorization metric, that is designed to deal with measurement issues that arise in natural language datasets. Based on these issues I am inclined to keep my score."}]}, {"Heading": "Official Review of Submission9281 by Reviewer j45i", "Subheading": "Official ReviewbyReviewer j45i30 Oct 2023, 21:07 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper explores the mechanics and dynamics of memorization in large language models (LLMs) by training them to memorize random token strings of different lengths and entropies. The study reveals interesting memorization dynamics and investigates the mechanics of memorization, showing that both the local prefix and the global context play a role in token recollection and there is an interplay between them.\nI enjoyed this paper. I have several questions in this paper. Overall, I think it is a good experimental design to check the memorization properties.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nSome strengths of this study include the systematic approach to investigating the mechanics and dynamics of memorization in LLMs, the use of random strings of different lengths and entropies to test the models, and the insights gained into the role of local prefixes and global context in token recollection.\nWeaknesses:\nI'm curious if the findings of this paper are more indicative of the underlying structure of Language Models or their training dynamics. The experimental design is intriguing, but I couldn't help but notice that the dataset used doesn't seem to have the scale or correlated content typically associated with \"internet-sized\" datasets that are used to train Large Language Models (LLMs). Could the absence of such correlations and the relatively smaller dataset size potentially influence the study's outcomes?\nThe paper provides valuable insights, but I wonder if the use of GPT-2, which is smaller than many current LLMs, fully captures the dynamics of \"large\" language models. While GPT-2 is certainly not a small model, especially when compared to older language models, it seems that the issue of memorization was not as prominent in those older models. Do you think incorporating both smaller and larger models in the study might strengthen the argument that these dynamics are specifically related to the scale of the model? In essence, if the model size does not significantly impact these dynamics within this range, should we still be referring to them in the context of \"large\" models?\nQuestions:\nthe same with weakness part\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 12:30Everyone", "Content": "Comment:\nWe thank the reviewer for their feedback and interesting questions! We address them below.\nTraining process and dataset might not be representative of practical settings\nIt is true that we only train models to memorize a single random string at a time, a training setup that differs from the large quantities and diversity of training data seen by models during pre-training. Our approach of repeatedly training on the same data is, however, also gaining traction in\nrecent work\n, to more effectively utilize data. \nOur choice of training setup is deliberate, as it allows us to ignore confounding factors such as the relative occurrence frequency of some random strings relative to other strings in the training data, and recency and forgetting due to other training data sequences. Studying these factors is potentially also very interesting, but merits its own separate analysis. Recent work by Tirumala et al. (2022) and Carlini et al. (2022) has explored some of these directions.\nAre the investigated models representative of large language models?\nIn the paper, we already study a large variety of model sizes, from 140M to 12B parameters. To test generalization across models even more extensively, we added Llama 2 (7B and 13B) models to the revised paper (see discussion in Section 3.1 and Appendix A.3). Both the papers that introduced\nPythia\n(e.g. Figure 4), as well as\nLlama 2\n, report emergent abilities. Therefore, we belive that these models are representative of other large language models.\nIn our paper, we observe similar trends across all models, however, larger models are able to memorize faster, and this holds especially for the Llama 2 models. In contrast to the other models, we observe that they skip the guessing-phase completely and go straight to the memorization-phase. They can do this, because they are able to learn the token distribution in the string via in-context learning without additional training (see Appedix A.3). It is also worth noting that the Llama 2 7B model memorizes strings faster than the larger Pythia 12B model, indicating that other factors beyond parameter count also play a role."}]}]}, "Hm6maU150b": {"paper_info": {"Primary Area": "general machine learning (i.e., none of the above)", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "federated learning, system heterogeneity", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "NeFL divides models into submodels by widthwise or/and depthwise to incorporate resource-constrained clients in the FL pipeline.", "Abstract": "Federated learning (FL) is a promising approach in distributed learning keeping privacy. However, during the training pipeline of FL, slow or incapable clients (i.e., stragglers) slow down the total training time and degrade performance. System heterogeneity, including heterogeneous computing and network bandwidth, has been addressed to mitigate the impact of stragglers. Previous studies tackle the system heterogeneity by splitting a model into submodels, but with less degree-of-freedom in terms of model architecture. We propose nested federated learning (NeFL), a generalized framework that efficiently divides a model into submodels using both depthwise and widthwise scaling. NeFL is implemented by interpreting forward propagation of models as solving ordinary differential equations (ODEs) with adaptive step sizes. To address the inconsistency that arises when training multiple submodels of different architecture, we decouple a few parameters from parameters being trained for each submodel. NeFL enables resource-constrained clients to effectively join the FL pipeline and the model to be trained with a larger amount of data. Through a series of experiments, we demonstrate that NeFL leads to significant performance gains, especially for the worst-case submodel. Furthermore, we demonstrate NeFL aligns with recent studies in FL, regarding pre-trained models of FL and the statistical heterogeneity.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "pdf", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9278", "PDF Url": "https://openreview.net/pdf?id=Hm6maU150b"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9278 by Area Chair FGEg", "Subheading": "Meta ReviewbyArea Chair FGEg09 Dec 2023, 08:37 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper introduces an approach to enable federated training on devices with diverse capabilities, by using models with different width and height. Depth-wise and width-wise scaling are implemented by viewing the forward pass through a feed-forward network with skip connections as solving an ODE. The approach is validated via experiments on CIFAR-10.\nThe proposed approach addresses an important problem and initial results are promising.\nThe paper could be strengthened by more clearly illustrating in the paper how this work differs from previous work and by illustrating the benefits of the approach on a broader range of problem settings.\nJustification For Why Not Higher Score:\nExperiments only focus on a single, small task. Although multiple baselines are compared with the proposed approach, to be more convincing this really needs to be extended to workloads beyond CIFAR. The paper could also more convincingly explain the relationship and differences from prior work that lead to superior performance.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "General Response", "Subheading": "Official CommentbyAuthors14 Nov 2023, 03:29Everyone", "Content": "Comment:\nDear reviewers and AC,\nWe sincerely appreciate your valuable time and effort spent reviewing our manuscript.\nAs reviewers highlighted, our paper is well-motivated (ALL Reviewers) and we propose a simple yet novel and interesting method (Reviewer HZdf). Our paper has encouraging and comprehensive empirical results comparing a variety of recent frameworks (ALL Reviewers).\nWe appreciate your constructive comments on our manuscript. In response to the comments, we have carefully revised and enhanced the manuscript with the following additional discussions and experiments:\nClarify contributions and motivations\nClarify the details in Appendix A.3 presenting ablations study.\nClarify descriptions and statements throughout our manuscript.\nThese updates are temporarily highlighted in \u201c$\\color{blue}\\text{blue}$\u201d for your convenience to check.\nWe hope our response and revision sincerely address all the reviewers\u2019 concerns.\nThank you very much.\nBest regards,\nAuthors."}, {"Heading": "Official Review of Submission9278 by Reviewer 5ayx", "Subheading": "Official ReviewbyReviewer 5ayx02 Nov 2023, 10:01 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors present nested federated learning (NeFL), a framework that divides the global model into multiple submodels using an interpretation of ODEs for depthwise scaling and continuous channel-based pruning on convolutional neural networks and node removal on fully connected neural networks for widthwise scaling, and performs aggregation using Nested Federated Averaging scheme for models with incompatible sizes.\nSoundness:\n4 excellent\nPresentation:\n3 good\nContribution:\n4 excellent\nStrengths:\n++ The paper has carefully examined the related literature, and have observed the presence of low degrees of freedom in model architectures that were proposed in previous studies to combat heterogeneity by model splitting.\n++ The paper has cleverly used findings from other papers to increase the credibility of their arguments.\n++ The paper has performed a comprehensive set of experiments to show that NeFL performs significantly better than previous works.\nWeaknesses:\n-- Why scale the depth of the models using the interpretation of ODEs? The authors should motivate the reasons for using ODEs to scale depth and what makes this approach of scaling depth better than previous appraches. Why not use some other method for scaling depth? They should just perform depth scaling using ODEs and compare its performance to other depth scaling techniques in FL.\n-- Since the authors propose a hybrid approach that combines depth scaling as well as width scaling in the spirit that a balanced network performs better, they should show how much better depth scaling using ODE is, when coupled with width scaling, and vice versa. Since in FL, the networks have not been depth scaled using ODEs, the authors should explain why they have not only used depth scaling via ODEs.\nQuestions:\n-- How is the aggregation of the consistent parameters even meaningful? In the presence of non-IID datasets and ResNets of different depths and widths, each layer in a particular ResNet serves a different purpose than the corresponding layer in the other, ResNet i.e., layers L1, L2, and L3 with widths W1, W2 and W3 inside client A's Resenet with layers: (L1, L2, L3) will have different purposes than the corresponding layers L'1, L'2 and L'3 with widths W'1, W'2 and W'3 inside client B's Resenet with layers: (L'1, L'2, L'3, L'4, L'5). So what is the justification behind aggregating layers that are incoherent in terms of their purposes in the network?\n-- The parameterAverage subroutine is expected to returns N_s submodels, however it does not compute submodels 2,...,N_{s-1}. The parameterAverage subroutine should compute and return the submodels 2,...,N_{s-1}: theta_{c,2},...,theta_{c,N_{s-1}}. For example theta_{c,N_{s-1}} = U over all {j<=N_{s-1}} phi_j.\n-- The authors should explain their diagrams and algorithms thoroughly. Please refer to Writing Issues.\nWriting Issues:\nThe authors should explain Figure 2, part b as that would help the readers understand their aggregation scheme well.\nAlgorithm 2 is difficult to read because the paper has used notations that were not pre-defined. For example in line 9, the superscript 'i' has not been pre-defined and it is hard to make sense of the backslash ('').\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 5ayx (1/2)", "Subheading": "Official CommentbyAuthors14 Nov 2023, 03:57 (modified: 14 Nov 2023, 09:23)EveryoneRevisions", "Content": "Comment:\nDear Reviewer 5ayx,\nWe sincerely thank you for your helpful and valuable feedback on our paper. We address your comments and questions below. In the revised draft, we take the reviewer's point and update the paper.  We mark our revision in $\\color{blue}\\text{blue}$.\n1\n. Interpretation of ODE for scaling\nWe agree with the reviewer\u2019s comments that there are other ways to scale down a model into submodels.\nOur work is a general work that incorporates the previous depth-scaling methods.\nFor example, DepthFL denotes depthwise scaling without step size parameters and also has no decoupled inconsistent parameters.\nWe provided the ablation study on Table 6 in Appendix A.3. NeFL-D denotes FL with scaling depthwise by our proposed method, NeFL-D (N/L) denotes FL with scaling depthwise without no learnable step parameters, NeFL-D_{O} denotes depthwise scaling with different initial values and NeFL-D_{O} (N/L) denotes depthwise scaling with different initial values without learnable step size parameters.\n2\n. Depth scaling coupled with width scaling\nWe provide ablation study of NeFL consisting of both depthwise and widthwise scaled submodels in Table 6 in Appendix A.3.\nFurthermore, we provide the number of parameters and FLOPs for each method in Table 8. The results show that NeFL consisting of both depthwise and widthwise scaled submodels outperforms in ResNet18 with less FLOPs.\nMeanwhile, our proposed depthwise scaling via ODE has been motivated by previous work that introduced learnable parameters multiplied to the output of residual blocks\n(Touvron et al., 2021; Bachlechner et al., 2021; De & Smith, 2020). We interpreted the learnable parameters as the step sizes of an ODE solver. Our work includes the previous depth scaling methods.\nHugo Touvron, Matthieu Cord, Alexandre Sablayrolles, Gabriel Synnaeve, Herve\u0301 Je\u0301gou. Going deeper with Image Transformers. In ICCV 2021.\nThomas C. Bachlechner, Bodhisattwa Prasad Majumder, H. H. Mao, G. Cottrell, and Julian McAuley. Rezero is all you need: Fast convergence at large depth. In Uncertainty in AI (UAI), 2021.\nSoham De and Samuel L Smith. Batch normalization biases residual blocks towards the identity function in deep networks. In NeurIPS, 2020.\n3\n. Aggregation of the consistent parameters\nWe agree with the reviewer\u2019s valuable comments.\nAggregating consistent parameters work as global representations while inconsistent parameters work as local refining representations.\nAveraging consistent parameters of same model architecture trained by clients with non-IID local dataset can be improved by decoupling a few layers (Liang et al., 2020). In terms of aggregating different model architectures, the reviewer can refer to a study that each block in residual networks except the first block only slightly refine the features (Chang et al., 2018).\nFigure 3b on our manuscript \u200b\u200brepresents the L1 norm of weights averaged by the number of weights at each layer of five trained submodels. The submodel 1 which is the worst model, has a similar tendency of L1 norm to the widest model and the gap between submodel gets smaller as the model size gets wider. The slimmest model might have learned the most useful representation while additional parameters for larger models obtain still useful, but less useful information.\nBo Chang, Lili Meng, Eldad Haber, Frederick Tung, David Begert. Multi-level residual networks from dynamical systems view. In ICLR, 2018.\nPaul Pu Liang, Terrance Liu, Liu Ziyin, Ruslan Salakhutdinov, and Louis-Philippe Morency. Think locally, act globally: Federated learning with local and global representations. arXiv preprint arXiv:2001.01523, 2020.\n4\n. N_s parameters\n$\\theta_{c,k} \\subset \\theta_{c,N_s} \\forall k$ that\na client can extract any parameters of a submodel from the largest submodel parameters\n. Referring to Algorithm 1,  each client receives consistent parameters of the largest submodel and inconsistent parameters. The clients can dynamically determine which submodel to train for this round depending on the communication, computing, memory dynamics.\nWe added the statements \"\"Note that $\\theta_{c,k} \\subset \\theta_{c,N_s}\\forall k$.\" in \u201cSection 4.2 Inconsistency\u201d.\n5\n. Writing\nThank you for your careful and considerate review. We take the reviewer's point and update the paper as follows:\nWe clarified and proofread descriptions and statements throughout our manuscript.\nWe provide notation for Algorithm 2 in \u201cSection 4.2 Parameter averaging\u201d.\nWe added details on the diagrams and algorithms.\nThank you again for your valuable time and effort spent reviewing!"}, {"Heading": "Response to Reviewer 5ayx (2/2)", "Subheading": "Official CommentbyAuthors14 Nov 2023, 08:50 (modified: 14 Nov 2023, 08:51)EveryoneRevisions", "Content": "Comment:\nAblations study\nDepthwise scaling\nWidthwise scaling\nAdaptive step size\nDepthFL\n$\\checkmark$\nFjORD, HeteroFL\n$\\checkmark$\nNeFL-D\n$\\checkmark$\n$\\checkmark$\nNeFL-W\n$\\checkmark$\n$\\checkmark$\nNeFL-WD\n$\\checkmark$\n$\\checkmark$\n$\\checkmark$\nThe results can be summarized by following statements:\nNeFL-D shows better performance than NeFL-D_{O} that has larger initial values (Table 12) according to the number of skipped blocks. The rationale comes from the empirical results that trained step sizes are not as large as initial value for NeFL-D_{O} that large initial values for NeFL-D_{O} degrades the trainability of depthwise-scaled submodels.\nLearnable step size parameters are effective for deep and pre-trained networks.\nNeFL-D outperforms DepthFL that scales depthwise without inconsistent parameters.\nNeFL-WD has less FLOPs compared to depthwise scaling and more FLOPs compared to widthwise scaling (Table 8).\nNeFL-WD shows the better performance than NeFL-D on the worst submodel with ResNet18 and pre-trained ResNet18.\nWe present the part of results in Appendix A.3. Below table is evaluated with pre-trained ResNet18:\nMethod\nWorst\nAvg\nHeteroFL\n78.26\n84.06\nFjORD\n86.37\n88.91\nNeFL-W\n86.1\n89.13\nDepthFL\n47.76\n82.85\nNeFL-D (N/L)\n86.95\n89.77\nNeFL-D$_\\text{O}$ (N/L)\n86.24\n89.76\nNeFL-D\n87.13\n90.00\nNeFL-D$_\\text{O}$\n87.02\n89.72\nNeFL-WD\n88.61\n89.60\nNeFL-WD (N/L)\n88.52\n89.70\nWidthwise/Depthwise scaling\nWidthwise scaling\nDepthwise scaling\nParam #\n6.71M\n6.71M\n6.68M\nFLOPs\n87.8M\n85M\n102M"}]}, {"Heading": "Official Review of Submission9278 by Reviewer HZdf", "Subheading": "Official ReviewbyReviewer HZdf31 Oct 2023, 23:58 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors introduce a method called Nested FL which helps to improve performance when training with heterogeneous clients.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThe authors do a good job describing the state of the art, the work is timely as the clients that are participating in FL are becoming increasingly diverse. Thus efficient schemes of tackling and even exploiting that heterogeneity are highly desirable. In principle, I found the concept of averaging nesting consistent parameters is simple yet novel and interesting. Finally the empirical performance based on the empirical numbers provided is encouraging. Appreciated that they have compared against a variety of recent frameworks that aim to do a similar task so we can get a broad idea of how the scheme performs.\nWeaknesses:\nLack of clarity what happens with stragglers and/or dropped nodes in the proposed framework.\nReproducibility is important; unfortunately, there is no mention of code release statement - even after acceptance.\nThe code was omitted in the submission and thus evaluation of the soundness of the implementation could not be performed.\nQuestions:\nWhat do the authors mean by \"test time\" and how does that happen in practice? Do they run a benchmark? Keep track of computation time? I feel this requires some clarifications...\nWhy the code was not included part of the assessment as a private artifact? I see no sensitive data and/or methods in the paper to warrant this.\nHow do the clients balance the task? Is that something that is covered by NeFL? Does that balancing act happen once? Or is that performed dynamically over time?\nWhat is the impact of stragglers in the final output? What happens if a client drops from the computation?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer HZdf", "Subheading": "Official CommentbyAuthors14 Nov 2023, 03:45 (modified: 15 Nov 2023, 08:44)EveryoneRevisions", "Content": "Comment:\nDear Reviewer HZdf,\nWe sincerely thank you for your positive and valuable feedback on our paper. We address your comments and questions below. In the revised draft, we take the reviewer's point and update the paper.  We mark our revision in $\\color{blue}\\text{blue}$.\n1\n. Clarification on test-time\nTest-time denotes employing a model for inference after training.\nAfter $N_s$ submodels have been trained, a client can run one of the submodels considering its current battery, runtime memory and available computing-power.\nWe added the explanation on test-time as a footnote in Section 4.\nWang, Dequan and Shelhamer, Evan and Liu, Shaoteng and Olshausen, Bruno and Darrell, Trevor. TENT: Fully Test-Time Adaptation by Entropy Minimization. In ICLR, 2021.\n2\n. Source code\nWe will include the github URL of our source code on the paper after blind review process.\nWe agree with the importance of reproducibility. Before the release, the reviewer can kindly refer to pseudo-code for parameter averaging provided in Appendix B.8.\nWe temporarily added \u2018code will be available after blind review process\u2019  in the abstract.\n3\n. Dynamical balancing\nThe clients are aware of their own dynamic status such as communication environment and available computing-power (run-time dynamics), respectively.\nThen, the clients respectively request a NeFL server to transmit submodels for training that meet their current requirements in the communication round.\nWe revised the balancing procedure with more details in Section 4.\n4\n. Stragglers\nLess stragglers output fast and stable convergence of FL with better classification accuracies while more stragglers output slow and worse convergence  with worse classification accuracies. Dropped clients wait until the next communication round.\nThe server can wait at every communication round for the slow client to complete its local updates and send parameters to a server. Alternatively, a server can wait until the pre-defined deadline (Reisizadeh et al., 2019) or can wait for a pre-defined number of clients every communication round (Nguyen et al., 2022).\nA fraction $C$ of clients is selected at the beginning of each round and the server sends the current global model to each of these clients (McMahan et al., 2017). Each client then performs local computation based on the submodel and its local dataset, and sends an update to the server.\nReferring to Algorithm 1, the clients in $\\mathcal{C}_t$ are selected in the communication round $t$. We considered the clients\u2019 dynamic environment detailed in Appendix B.7. In NeFL, the clients can be stragglers when they cannot even afford the smallest submodel.\nWe added the explanations on stragglers in Section 1.\nWe conducted additional experiments  across the different fraction rate with NeFL-WD (submodels that are scaled by both widthwise and depthwise) on ResNet18 from scratch. The larger fraction rate denotes the larger number of clients participate in the FL pipeline every round. We provide results that is averaged over three runs:\nFraction rate\nWorst\nAvg\n0.05\n86.65\n87.41\n0.1\n86.82\n87.84\n0.2\n87.01\n87.99\nAmirhossein Reisizadeh, Hossein Taheri, Aryan Mokhtari, Hamed Hassani, Ramtin Pedarsani. Robust and Communication-Efficient Collaborative Learning. In NeurIPS, 2019.\nJohn Nguyen, Kshitiz Malik, Hongyuan Zhan, Ashkan Yousefpour, Michael Rabbat, Mani Malek, Dzmitry Huba. Federated learning with buffered asynchronous aggregation. In AISTATS, 2022.\nBrendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In AISTATS, 2017.\nThank you again for your valuable time and effort spent reviewing!"}, {"Heading": "Read your rebuttal", "Subheading": "Official CommentbyReviewer HZdf22 Nov 2023, 21:51Everyone", "Content": "Comment:\nAppreciate the response and the explanations. However, given tacking in account the other reviews, comments, and your rebuttal - I am keeping my score."}]}, {"Heading": "Official Review of Submission9278 by Reviewer 7d7r", "Subheading": "Official ReviewbyReviewer 7d7r29 Oct 2023, 00:55 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a new sub-model training method in federated settings. \nThe proposed method, NeFL, creates sub-models for participating clients by reducing both the depth and width of a full model. \nThe way of creating sub-models is inspired by the interpretation that a model with skip-connections can be regarded as ordinary differential equations (ODEs). \nDepending on each client's resource, the client picks the feasible sub-model that can be trained locally. \nTherefore, training costs are reduced.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThis paper targets a practical and important problem of reducing training costs in FL with large models, especially for large models. Several contributions are highlighted below.\n1\n, The motivation for reducing both depth and width is interesting.\nIn Sec.3, the authors justify the way of creating sub-models in NeFL. Inspired by the interpretation, that models with skip connections can be seen as ODEs, the authors argue that it is reasonable to remove some residual blocks, as skipping some steps in solving ODEs. \nThe motivation is valid and interesting.\n2\n, Experiments cover different sub-model methods.\nThe author compared NeFL with both depth scaling and width scaling methods. The results show promising results.\nWeaknesses:\n1\n, Lack of explanations why NeFL is better than scaling width or depth only.\nWhile the authors show NeFL results in higher accuracy compared to width-scaling and depth-scaling methods, necessary explanations/intuitions are missing.\nAs a reader, I do not see which part of NeFL contributes to performance gains. \nI believe the authors need to provide more insights to demystify NeFL. For instance, why scaling both width and depth is better than scaling one dimension only?\n2\n, Lack of contributions.\nEssentially, NeFL is a combination of width-scaling (e.g., HeteroFL) and depth-scaling (e.g., DepthFL). Other than that, I did not see a nontrivial contribution in this work. \nImportantly, it is doubtful such a combination can bring significant improvement over prior works.\nQuestions:\nNone\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 7d7r", "Subheading": "Official CommentbyAuthors14 Nov 2023, 03:37 (modified: 14 Nov 2023, 09:22)EveryoneRevisions", "Content": "Comment:\nDear Reviewer 7d7r,\nWe sincerely thank you for your careful review and valuable feedback. We address your comments and questions below. In the revised draft, we mark our revision in $\\color{blue}\\text{blue}$.\n1\n. Why does NeFL outperform width or depth only scaling?\nWidth/depth-balanced models have performance gains over one dimension scaled models with the same number of parameters.\nIt has been shown in centralized learning that both width and depth dimension scaled models outperform one-dimension-scaled models with the same number of parameters (Tan & Le, 2019). It is also important for FL that scales a global model.\nHowever, in FL that scales a global model into submodels by one dimension (Horvath et al., 2021; Diao et al., 2021; Kim et al., 2023), the performance of the worst submodel (with the least number of parameters) degrades severely. Therefore, our proposed well-balanced scaling method improves the performance of the worst submodel.\nWe added the explanations in \u201cSection 2 model splitting\u201d.\nMingxing Tan and Quoc Le. EfficientNet: Rethinking model scaling for convolutional neural networks. In ICML, 2019.\nSamuel Horvath, Stefanos Laskaridis, Mario Almeida, Ilias Leontiadis, Stylianos Venieris, and Nicholas Lane. FjORD: Fair and accurate federated learning under heterogeneous targets with ordered dropout. In NeurIPS, 2021.\nEnmao Diao, Jie Ding, and Vahid Tarokh. HeteroFL: Computation and communication efficient federated learning for heterogeneous clients. In ICLR, 2021.\nMinjae Kim, Sangyoon Yu, Suhyun Kim, and Soo-Mook Moon. DepthFL : Depthwise federated learning for heterogeneous clients. In ICLR, 2023.\nInconsistent parameters also contribute to performance gain.\nWe introduce inconsistent parameters to compensate for aggregating parameters of submodels of different model architecture. It includes batch normalization layers and learnable step size parameters motivated by ODE solver. Table 6 in Appendix A.3 provides the performance gain of inconsistent parameters. The insights on inconsistent parameters can be observed in Figure 1 and Figure 4. The inconsistent parameters can compensate for numerical error caused by skipping a few blocks (depthwise scaling) or widthwise scaling.\nWe clarified the explanations in \u201cSection 4.2 Inconsistency\u201d.\n2\n. Contributions beyond scaling\nInconsistent parameters and ParameterAveraging method.\nIn addition to both widthwise and depthwise scaling, NeFL introduces inconsistent parameters. The effectiveness of inconsistent parameters are presented in ablation study (Table 6 in Appendix A.3). Comparison of NeFL-W and HeteroFL and comparison of NeFL-D and DepthFL provides the performance gain of the inconsistent parameters.\nMoreover, we propose a simple yet novel parameter averaging method (Algorithm 2) that corresponds to general scaling methods we presented where the submodels consist of consistent and inconsistent parameters.\nExploration in line with recent studies of federated learning.\nWe explore the NeFL aligns with recent studies on FL (Chen et al., 2023; Qu et al., 2022). It is notable that a pre-trained model that is not trained in a nested manner with several submodels has performance gains with NeFL compared to previous works. We also observe that ViTs on NeFL are effective in non-IID settings compared to ResNet with more parameters.\nHong-You Chen, Cheng-Hao Tu, Ziwei Li, Han Wei Shen, and Wei-Lun Chao. On the importance and applicability of pre-training for federated learning. In ICLR, 2023.\nLiangqiong Qu, Yuyin Zhou, Paul Pu Liang, Yingda Xia, Feifei Wang, Ehsan Adeli, Li Fei-Fei, and Daniel Rubin. Rethinking architecture design for tackling data heterogeneity in federated learning. In CVPR, 2022.\nComprehensive empirical results\nOur paper has comprehensive empirical results. The results compare a variety of recent frameworks and present the effectiveness of NeFL.\nWe clarified the contributions in \u201cSection 1\u201d.\nThank you again for your valuable time and effort spent reviewing!"}]}]}, "hujS6bmduD": {"paper_info": {"Keywords": "Diffusion Models;Visual Perception; Class Captioner", "Abstract": "Equipped with large-scale training data, text-to-image diffusion models have demonstrated the capacity to generate high-quality images that semantically correspond to the given textual descriptions. \nThese compelling results imply that visual semantic knowledge has been effectively encapsulated within the generative diffusion model. \nThe prospect of utilizing this embedded knowledge as a prior for down-stream vision tasks presents an intriguing avenue for exploration, which remains notably under-investigated. In this work, we demonstrate that when provided with appropriate image tags as textual descriptions, the implicit knowledge within these text-to-image diffusion models can be effectively leveraged for visual dense prediction tasks. Initially, we discover that supplying ground-truth semantic labels as textual instructions significantly enhances performance due to the extracted high-quality visual knowledge. Motivated by this observation, when presented with noisy tagging labels, we propose an adapter module attempting to derive relevant semantic information.\nSubsequently, we propose a multi-label classification learning objective which further enriches the semantic quality of tags, thereby amplifying the efficacy of knowledge extraction.  We conduct extensive experiments four benchmarks, which suggest that the proposed approach is effective to unlock the representational capabilities of text-to-image diffusion models, showcasing a promising avenue for advancing dense prediction tasks in visual domains.", "Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9277", "PDF Url": "https://openreview.net/pdf?id=hujS6bmduD"}, "review_info": [{"Heading": "Official Review of Submission9277 by Reviewer Sgbx", "Subheading": "Official ReviewbyReviewer Sgbx01 Nov 2023, 00:25 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper leverages text-to-image diffusion models to extract dense image features and demonstrates the importance of the text prompts. The paper to generate the textual prompts by using an (zero-shot) image tagging model and propose an attention module to further improve the text prompts. The paper validates the effectiveness on semantic and panoptic segmentation.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThe paper provides insightful analysis on the importance of the text prompts in the diffusion model under the context of dense prediction tasks.\nThe proposed tagging adaptor is easy to implement with standard attention module.\nWeaknesses:\nThe presentation is not clear in many parts\nMany notations are not explained before being referred in the equation\n$x$ in Eq. 1, $c$ in Eq 2, $L, D, i$ in Eq. 3, etc.\nThe authors might consider having a separate paragraph explaining the notations\nIt\u2019s unclear what the actual learning objective looks like\nOverall, it\u2019s hard to parse the details of the architectures and the training recipe.\nMixed improvements across different tasks\nImprove in ADE20k and COCO-stuff164k\nSlightly worse in Cityscapes and COCO-Panoptic\nQuestions:\nI wonder what leads to the gap between the prompting with the proposed method (56.2 on ADE20k) and ground truth prompting (74.4 on ADE20k). Can the author elaborate more on the intuition of this? To be more specifically, I am curious what kinds of errors cause such a big drop?\nIn sec 3.2, the paper says \u201cEmpirical results suggest that the latter approach usually yields enhanced performance.\u201d Do the authors provide the results of freezing the diffusion model parameters somewhere? For fair comparison, ODISE freezes all the diffusion model parameters.\nFrom the experimental results, it seems that the propose approach perform well when the number of classes is larger, e.g., ADE20k and COCO-stuff164k. I wonder have the authors tried to train on ADE20k in coarser levels or a subset of ADE20k to see if the improvement diminishes.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9277 by Reviewer x6HC", "Subheading": "Official ReviewbyReviewer x6HC31 Oct 2023, 05:53 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors show that text-to-image diffusion models can be effectively leveraged for visual dense prediction tasks when provided with appropriate image tags as textual descriptions. They first observe that supplying ground-truth semantic labels as textual instructions significantly enhances performance. Motivated by this observation, they propose an adapter module to derive relevant semantic information from noisy tagging labels. They also propose a multi-label classification learning objective to further enrich the semantic quality of tags.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nExploring the conditional adapters in diffusion models for dense prediction is a new topic.\nWeaknesses:\nThis paper claims that using a text-to-image model for dense prediction but the main modification is on the adapter for the labels. So is it necessary to use a diffusion model for segmentation? Are these adapters useful on other baselines?\nUsing diffusion models for dense prediction is not a very new topic. Please compare the proposed model with some recent works, like DDP [1].\n[1]Ji Y, Chen Z, Xie E, et al. Ddp: Diffusion model for dense visual prediction[J]. arXiv preprint arXiv:2303.17559, 2023.\nQuestions:\nPlease refer to the weakness.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9277 by Reviewer Mq6h", "Subheading": "Official ReviewbyReviewer Mq6h31 Oct 2023, 01:20 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes to adapt text-to-image diffusion models for downstream dense prediction tasks. To this end, the paper proposes to use image tags as textual descriptions. To deal with noisy tagging labels, an adapter module to derive relevant semantic information is proposed along with a multi-label classification learning objective. Evaluation is performed on ADE20K,  COCO-stuff164k, and CityScapes.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\n\u00b7         The proposed method seems to show somewhat improved performance over VPD (Zhao et al. 2023) in ADE20K and COCO-stuff164k benchmarks.\n\u00b7         The paper includes in Table 5 detailed ablations highlighting the performance improvement enabled by each component. Table 6 and 7 also ablates loss weights and adapter block sizes.\n\u00b7         Figure 2 provides a good overview of the proposed approach.\nWeaknesses:\nThe proposed method shows limited novelty over VPD (Zhao et al. 2023). The main contribution seems to be the addition of zero-shot tagging models to improve text embeddings. However, this addition of zero-shot tagging models along with a multi-label loss shows limited improvement over the use of off-the-shelf CLIP encoders in Table 5. Furthermore, the difference to text encodings obtained from the text adapter of Zhao et al. (2023) and the image-to-implicit caption adapter of Xu et al. (2023) should be explained in more detail.\n\u00b7         The comparison to VPD (Zhao et al. 2023) is limited. Additional experiments, e.g., image segmentation on RefCOCO and depth estimation on NYUv2 as in Zhao et al. 2023 would be helpful.\n\u00b7         The architecture of the tagging adapter is not well motivated. The TextEnc and ImageEnc in the the tagging adapter as described in Eq. 6 should be explained in more detail, including details of it model architecture. How does the TextEnc and ImageEnc relate to the cross attention modules in Figure 2.\n\u00b7         The paper should include qualitative examples highlighting examples where the proposed approach outperforms VPD (Zhao et al. 2023).\n\u00b7         Additionally, the paper is not well written:\no   In Figure 1, it is not clear what task is being performed, the model employed, and, the training and evaluation protocol.\no   The definition of T(c) is not clear. In Sec 3.1 it is described as \u201csignifying encoded text prompts\u201d and in Sec 3.3 it is described as referring to \u201cdataset associated category names\u201d.\no   In Sec 3.3 it is not clear what \u201cdataset associated category names\u201d refers to. Furthermore, the paper should distinguish between the terms \u201ctag information\u201d, \u201cdataset associated category names\u201d and \u201clabels\u201d used in sections 3.3 and 3.4.\no   In Section 3.4 it is not clear what \u201csharp, precise information\u201d means in this context.\n\u00b7         Typos: \u201class\u201d (page 2, para 1), \u201cuncondition\u201d (page 2, Figure 1), \u201ck-thlabel\u201d (page 5, para 2). Additionally, the use of \\citep{} and \\cite{} is not consistent.\nQuestions:\n\u00b7         The paper should discuss in more detail the difference to prior work, e.g., VPD (Zhao et al. 2023).\n\u00b7         The paper should provide more details of the text adapter, including details of the TextEnc and ImageEnc.\n\u00b7         The paper should use a consistent citation style.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9277 by Reviewer 6BRj", "Subheading": "Official ReviewbyReviewer 6BRj30 Oct 2023, 08:04 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work highlights the efficacy of text-to-image diffusion models and believes that the embedded visual semantic knowledge (inside these models) can benefit dense prediction tasks (i.e., transfer knowledge from pre-trained generative models to discrimination models). The study presents a method to do this knowledge transfer for visual dense prediction tasks, utilizing appropriate image tags and an adapter module to improve performance, and thus, advancing dense prediction tasks.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThis paper presents a clear motivation that an accurate semantic condition is important to extract knowledge from text-to-image models. The authors introduce a method to enhance the semantic condition, aiming to improve the performance of dense predictions with the pre-trained diffusion models.\nWeaknesses:\nNeeding clarifications. \na) In the oracle experiment in the introduction, it's unclear which model was employed. Could the authors specify this?\nb) In Section 3.4, the authors state that \u201cour findings indicate that alignment between the label space of the image tagging model and the datasets is not mandatory.\u201d What is the evidence supporting this claim? I understand that the adapter and multi-label classification tasks collaboratively facilitate this alignment. Could the authors elaborate on this?\nc) In Equation (7), the term (Pool(T(c)),h_k) is ambiguous. I assume it represents a similarity function, but this needs clarification.\nAblation study. The paper lacks an ablation study related to query embedding. Such a study would provide insights into the significance and impact of this component.\nEfficacy of RAM. One highlighted contribution is incorporating an off-the-shelf zero-shot tagging model, RAM. However, its effectiveness seems questionable. Table 5 indicates a mere 0.3% improvement, raising concerns about the computational overhead introduced by RAM versus its benefits.\nMarginal improvements. Table 5 indicates a total performance improvement of 1.8%. While 0.9% of this gain is attributed to the introduction of CLIP_img (as proposed by ODISE), the proposed multi-label loss and RAM account for only 0.7% and 0.3% improvements, respectively. When compared with the substantial 21.7% enhancement observed on COCO-Stuff164k by using ground-truth class names (as shown in Figure 1), it appears that the authors' efforts to enhance the semantic condition might not be effective.\nUnclear formulations. For Eq.(1), notations are not defined, which is not friendly to readers who do not know the latent diffusion process.\nPoor writing quality. Author discussion comments are not removed from the draft (e.g., below Table 1, there is \"yiqi: default, we use both zero-shot prediction ....\") and there is an author name before the comments (against the anonymous policy of ICLR'24?). The overall writing is not easy to follow, and one guess is that ChatGPT was used to smooth the writing with long and complex sentences but with confused logic.\nQuestions:\nSee weaknesses.\nFlag For Ethics Review:\nYes, Other reasons (please specify below)\nDetails Of Ethics Concerns:\nAuthor discussion comments are not removed from the draft (e.g., below Table 1, there is \"yiqi: default, we use both zero-shot prediction ....\") and there is an author name \"yiqi\" before the comments. This might be against the anonymous policy of ICLR'24.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}]}, "Ebt7JgMHv1": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Mechanistic Interpretability, Natural Language Processing, Large Language Models", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We show how activation patching can hallucinate meaningful subspaces in a language model by activating dormant pathways.", "Abstract": "Mechanistic interpretability aims to attribute high-level model behaviors to specific, interpretable learned features. It is hypothesized that these features manifest as directions or low-dimensional subspaces within activation space. Accordingly, recent studies have explored the identification and manipulation of such subspaces to reverse-engineer computations, employing methods such as activation patching. In this work, we demonstrate that na\u00efve approaches to subspace interventions can give rise to interpretability illusions.Specifically, even if patching along a subspace has the intended end-to-end causal effect on model behavior, this effect may be achieved by activating \\emph{a dormant parallel pathway} using a component that is \\textit{causally disconnected} from the model output.\nWe demonstrate this in a mathematical example, realize the example empirically in two different settings (the Indirect Object Identification (IOI) task and factual recall), and argue that activating dormant pathways ought to be prevalent in practice.\nIn the context of factual recall, we further show that the illusion is related to rank-1 fact editing, providing a mechanistic explanation for previous work observing an inconsistency between fact editing performance and fact localisation.However, this does not imply that activation patching of subspaces is intrinsically unfit for interpretability.\nTo contextualize our findings, we also show what a success case looks like in a task (IOI) where prior manual circuit analysis allows an understanding of the location of the ground truth feature. We explore the additional evidence needed to argue that a patched subspace is faithful.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "visualization or interpretation of learned representations", "Submission Number": "9274", "PDF Url": "https://openreview.net/pdf?id=Ebt7JgMHv1"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9274 by Area Chair nbig", "Subheading": "Meta ReviewbyArea Chair nbig14 Dec 2023, 15:53 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nLocalizing where some features or facts are stored in a language model is an important topic in the LLM era. One method for localizing facts is Activation Patching (AP), which measures the causal relationship between some unit in the LLM with its behavior e.g. factual recall, question-answering result, or gender bias. AP replaces the feature corresponding to some token in the input sequence of LLMs with the feature of a different, real token to measure the importance of a given token to some model outputs or behaviors.\nThe paper's main result is an explanation for why AP fails a.k.a. (\"Interpretability Illusion\"), resulting in the empirical findings in prior work that sometimes a fact can be edited in an LLM while that fact is not stored at that location (layer/head) in the network in the first place. That is, the work argues that the features lie in linear subspaces that can decompose into a sum of two orthogonal vectors (\ndisconnected\nand\ndormant\n) with certain properties (Sec. 3 of the paper). This decomposition is a helpful way to think about the mechanistic underpinnings of the illusion i.e. the recent mismatch in localizing vs. editing features of LLMs.\nBEFORE rebuttal:\nWhile this is an important topic, the major concern raised by reviewer\n8jAi\nand\nERkw\nis writing issues and most importantly, the missing of a falsifiable hypothesis for the claim in the paper.\nERkw\nasks\n\"Are there a set of empirical predictions (e.g. about the directions of activations or gradients) that could either falsify or support the theoretical model?\"\nand\n8jAi\nexplicitly concerned that the paper is missing a falsifiable hypothesis.\nBoth the above reviewers have engaged actively in the discussions and the authors have done a diligent task of revising the paper.\nThe authors also explicitly stated the limitations of their work including a main limitation:\n\"The illusion found is somewhat specific only to subspaces of hidden MLP activations\"\n.\nAFTER rebuttal:\nWhile reviewer\nERkw\nis satisfied with the revision and explanations, reviewer\n8jAi\nis still not satisfied with the provided hypothesis, requesting a way to check whether a given subspace is\ndormant\n. I think an empirical answer to this question is provided in\na response\nto  reviewer\nERkw\n:\nTo check how dormant the rowspace components are, we ran the experiment shown in Figure 12 in the paper, where we project the difference of activations of the two examples we are patching between on the causally disconnected component (the orthogonal projection on), and observe cosine similarity between this projection and the original direction of ~0.9; this implies that the cosine similarity with the rowspace component is ~0.4; thus, the rowspace component is relatively dormant compared to the nullspace one.\nOverall, the AC agrees with the authors that they have addressed all the major concerns of the reviewers. \nMost importantly, the authors have explained in the rebuttal explicitly the limitations and scope of the findings. The AC also agrees with the reviewer\n8jAi\nthat the way for testing the hypothesis is empirical and can be significantly clarified in the paper.\nTODO:\nGiven the remaining concern by reviewer\n8jAi\n, I'd request the authors to revise the paper to make it clearer how to test the falsifiable hypothesis (and a paragraph titled\nhow to check for dormant subspaces\n) and provide, in the Appendix, two\nreal\nexamples for when the hypothesis turns out to be (a) true and (b) false.\nAC recommends\naccept\n.\nJustification For Why Not Higher Score:\nThe paper shows an explanation for an interesting illusion in activation patching. The finding is mostly limited to the hidden MLP activations and therefore does not necessarily apply to most networks. The test for domain subspaces is empirical.\nJustification For Why Not Lower Score:\nThe authors have extensively discussed the limitations of the work and concretize their contributions after the rebuttal process. The AC believes the contribution is worth publishing at ICLR."}, {"Heading": "Overall response", "Subheading": "Official CommentbyAuthors16 Nov 2023, 18:58Everyone", "Content": "Comment:\nWe thank all three reviewers for their thoughtful feedback and insightful comments.\nAs reviewers\nYsUK\nand\nERkw\nhave noted, our core contribution is showing the existence of a particular interpretability illusion for subspace activation patching in two real-world examples, where a subspace seems causally relevant by activating a previously dormant pathway. The impact of this is that subspace activation patching interpretability techniques, especially when based on optimization, should not be applied using solely end-to-end evaluations, and may be misleading.\nAs such, reviewer\n8jAi\n\u2019s concern about the lack of a \u201cfalsifiable hypothesis\u201d that would guarantee the existence of the illusion under some conditions, is not the lens through which we view our contribution. We have addressed this, as well as other key aspects of our work that were miscommunicated, in our response to reviewer\n8jAi\n.\nA concern shared by the majority of reviewers is about the clarity of our paper, especially sections 4-7, and about how the experiments therein connect to our theoretical model of the illusion. We have taken these comments to heart, and have updated the writing, tables and figures in these sections with clearer explanations and additional details (which were previously in the supplementary material) to aid the grounding of our experiments.\nWe have uploaded a revision of our paper where new material is highlighted in red to aid reviewers. Specific changes made are listed in individual responses to reviewers that requested these changes. The main changes have been:\nadding related work motivating downstream uses of mechanistic interpretability in the introduction;\nre-doing Figure 1 for improved readability, as well as providing a step-by-step decomposition and explanation for it in the Appendix\nrewriting Section 4.3. significantly to clarify experimental methodology and how it connects with the figures and tables;\ndecreasing the main body's dependence on the supplementary material in Sections 4 and 6.", "Replies": [{"Heading": "Update to overall response", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:52Everyone", "Content": "Comment:\nAs the discussion period nears its end, we would like to thank reviewers for their participation in the discussion. After a clarifying discussion with reviewer\n8jAi\n, we have included a hypothesis about the existence of the illusion in the main body of the paper (Section 3).\nThere are still some aspects of our work that were miscommunicated in the discussion with reviewer\n8jAi\nafter our initial response. We have posted new responses that we hope clarify these aspects.\nIn conclusion, we believe we have identified and addresses the limitations of our work pointed out by the three reviewers, and we thank them again for the productive discussion."}]}, {"Heading": "Official Review of Submission9274 by Reviewer YsUK", "Subheading": "Official ReviewbyReviewer YsUK27 Oct 2023, 11:38 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work finds and shows that subspace activation patching may be subject to interpretability illusions caused by activating a dormant pathway (i.e., does not respond to input changes) but is activated by a causally disconnected feature (i.e., is activated by the input change but is not connected to the model\u2019s output). They show that this illusion also relates to rank-one fact editing (e.g., Meng et al. [1]) and explains its recently found inconsistencies [2]. Finally, they demonstrate that further analysis, e.g., manual circuit analysis, can mitigate the interpretability illusion.\n[1] Meng, Kevin, et al. \"Locating and editing factual associations in GPT.\" NeurIPS 2022.\n[2] Hase, Peter, et al. \"Does localization inform editing? surprising differences in causality-based localization vs. knowledge editing in language models.\" arXiv 2023.\nSoundness:\n4 excellent\nPresentation:\n4 excellent\nContribution:\n4 excellent\nStrengths:\nGiven the rising popularity of mechanistic interpretability and (subspace) activation patching, this paper addresses a very important and significant issue in a timely manner.\nThe interpretability illusion is well-motivated and clearly introduced. The formal definition (p. 5) is sound. It is also clear that the illusion is not a mere artifact of the chosen experimental settings but is present in most cases with high probability.\nThe experimental design to showcase the interpretability illusion is well-designed.\nThe discussion on how one can prevent the interpretability fallacy is important and sound. It paves a way for future work that relies on automatic activation patching methods, to avoid false interpretations of model behavior.\nThe discussion on the presence of the interpretability illusion from a mechanistic viewpoint is sound.\nThe paper is clearly written, (mostly) easy to follow, and self-containing.\nWeaknesses:\nThis paper is a very strong submission. It is well-motivated, sound, and clear. The only \u201cmajor\u201d weakness is that code is not provided and minor comments (see below).\nQuestions:\nWhy do the authors solely focus on subspace activation patching? The identified interpretability illusion should also hold for (automatic) component activation patching (i.e., consider the entire activation space as the (sub)space).\nThere seems to be an error in the indices in the toy example in Appendix A.3.\nSuggestions\nWhile Fig. 1 clearly demonstrates the interpretability illusion, it is hard to parse. It may be good to make it more accessible/easier to parse, as it demonstrates the main insight of the paper.\nIt\u2019d be good to add the relation of the vector $v$ to the subspace $U$ in Sec. 3.\nIt\u2019d be good to match the notation of Tab. 1 and the respective text.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 18:52Everyone", "Content": "Comment:\nWe thank the reviewer for their thoughtful review, and for the encouraging\nfeedback on the timeliness and soundness of our work. Below, we address the\nreviewer\u2019s questions and other concerns:\ncode is not provided\nWe are working on releasing an anonymized version of our code in the next few\ndays. We will provide a link to it in a subsequent response once it is\navailable.\nWhy do the authors solely focus on subspace activation patching? The\nidentified interpretability illusion should also hold for (automatic) component\nactivation patching (i.e., consider the entire activation space as the\n(sub)space).\nThis is a great question. A key property of subspace activation patching not\nshared with full-component activation patching is that it\nmay create\nout-of-distribution activations for the given component, even when patching only\nbetween in-distribution examples\n. This makes it particularly vulnerable to an\nMLP-in-the-middle type of illusion, where we take the output of the MLP layer\noff-distribution in order to write some causally important information in the\nresidual stream. Intuitively, this would not be possible to such an extent when\npatching the full hidden activation of the MLP layer, because its activations\nfor in-distribution examples do not generally write important information to the\nresidual stream (as can be confirmed by doing the full patch).\nHowever, full-component activation patching can still take the activations of\nthe model as a whole off-distribution. It is an interesting question for future\nwork whether a variant of the illusion can be exhibited for full-component\npatching. For example, if two heads always cancel each other out (one outputs +v\nand the other -v), we could patch just one of them such that they no longer\ncancel out. Thus, it may be possible to patch only one of these components and\nthrow the model off-distribution. However, we expect such scenarios of \u201cperfect\ncancellation\u201d to be rarer in practice.\nThere seems to be an error in the indices in the toy example in Appendix A.3.\nThis is correct; the sentence \u201c... the linear subspace of H_2 and H_3 defined by\nthe unit vector\u2026\u201d should be \u201c...H_1 and H_2\u2026\u201d instead. We thank the reviewer for\npointing this out, and we have corrected it in our revision of the paper.\nWhile Fig. 1 clearly demonstrates the interpretability illusion, it is hard to\nparse. It may be good to make it more accessible/easier to parse, as it\ndemonstrates the main insight of the paper.\nWe acknowledge that Figure 1 is somewhat involved and thank the reviewer for\npointing this out. To make it more readable, we have included a \u201cdecomposition\u201d\nof this figure into four figures to be read sequentially. Due to space\nlimitations, we include this new figure as Figure 26 in the Appendix, and we\npoint to it from the main text. We also re-did the original figure in TikZ to\nimprove readability. We hope that this makes the phenomenon clearer.\nIt\u2019d be good to add the relation of the vector v to the subspace U in Sec. 3.\nWe thank the reviewer for pointing this out; the relationship is that, in the\nspecial case of 1-dimensional subspace patching we consider, $U$ is the subspace\nspanned by the (unit) vector $v$. We hope that clarifies this part of the paper;\nwe have added it to our revision.\nIt\u2019d be good to match the notation of Tab. 1 and the respective text.\nWe thank the reviewer for pointing this out. This is a concern shared by another\nreviewer as well, and we acknowledge that Table 1 can be improved in many ways.\nIn the revision we have uploaded, we have made the notation more coherent. We\nhave also re-parametrized the fractional logit diff metric to make it more\nintuitive and readable."}, {"Heading": "Re: Official Comment by Authors", "Subheading": "Official CommentbyReviewer YsUK21 Nov 2023, 04:42Everyone", "Content": "Comment:\nI thank the authors for the thorough reply. I appreciate the effort of the authors to provide code and strongly encourage them to do so. I would also encourage the authors to include Fig. 26 instead of Fig. 1 in the main text but understand that page limit may be hindering in doing so. Lastly, I appreciate the discussion on subspace vs. entire activation space patching that could be also featured in the paper.\nOverall, I believe that this paper constitutes a very important contribution to the interpretability community and consequently should be highlighted as such at the conference."}, {"Heading": "Response to reviewer", "Subheading": "Official CommentbyAuthors22 Nov 2023, 18:57Everyone", "Content": "Comment:\nWe thank the reviewer again for their encouraging feedback. We have uploaded a zip file of code for the main experiments in the paper with notebooks to reproduce key figures as a revision. We will continue working to eventually publish the code on github."}]}, {"Heading": "Official Review of Submission9274 by Reviewer 8jAi", "Subheading": "Official ReviewbyReviewer 8jAi23 Oct 2023, 18:24 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper shows that subspace activation patching, a technique in mechanistic interpretability used to find subspaces that are \u201ccausally\u201d responsible for models to produce certain outputs, may not be reliable. In particular, the paper explains why these may be misleading, involving the activation of dormant pathways. Real-world examples involving indirect object identification (IOI) and fact editing are shown where such techniques are misleading.\nSoundness:\n1 poor\nPresentation:\n1 poor\nContribution:\n1 poor\nStrengths:\nThe paper presents an interesting hypothesis that subspace activation patching methods can be misleading because of dormant pathways. On an intuitive level, this is an interesting hypothesis and needs to be considered for future applications of activation patching.\nWeaknesses:\nThe paper does not pose an explicit hypothesis that can be falsified, limiting its scientific validity. Further, the \"illusion\" seems to make\nproblematic assumptions\nand has unclear implications.\nThe hypothesis seems to be that every patched subspace \u201cv\u201d discovered by DAS can be decomposed into two directions \u201cv_disconnected\u201d and \u201cv_dormant\u201d (with specific properties), and that \"patching along the sum of these directions, the variation in the disconnected part activates the dormant part, which then achieves the causal effect\". The latter statement assumes that the model behaves somewhat linearly along these subspaces (i.e., the output of the model along direction \"v\" is given by a sum of its outputs along \"v_disconnected\" and \"v_dormant\"), which is a strong hypothesis given that these models are fundamentally non-linear. While the paper provides some evidence for the existence of some \"disconnected\" and \"dormant\" directions, unfortunately, I do not see evidence justifying the apparent linear behaviour of the underlying model.\nThe definition of the \"dormant\" subspaces is confusing in the context of this work. If the model output remains unchanged for in-distribution patching and changes only for out-of-distribution samples $x,y \\sim \\mathcal{D}$, what procedures presented in this work result in out-of-distribution samples/activations? As far as I can tell, all procedures described involve patching with in-distribution data.\nIs the hypothesis that such a decomposition does not exist for \u201ctrue\u201d subspace directions?\nThe paper (especially sections 4-7) is difficult to read, is very dense, and has\nseveral omitted details\n.\nThe main paper on its own does not seem to be self-contained and seems to contain a significant number of references to the appendix.\nThe main hypothesis involves the claims that (1) subspace directions can be decomposed into two directions (disconnected, dormant) with specific properties, and (2) the effect of such directions adds somewhat linearly to the model outputs. However, the paper fails to connect this terminology (\"disconnected, dormant directions\") in sections 4-7, making it difficult to verify whether the experiments confirm or deny the hypothesis.\nThe writing and presentation are sloppy. For example, in Section 4, \u201cker W_out\u201d is never defined, and it is unclear how the results in Table 1 and Figure 3 relate to the description in section 4.3. What is ABB / BAB in Figure 3? What does \u201cconnected\u201d in Table 1 refer to? Overall, how do Table 1, Figure 3, and Figure 4 illustrate support for the presented hypothesis?\nOverall, while this work may present a useful point, its writing (especially sections 4-7) makes it impossible to verify this. I suspect that a thorough rewrite is necessary to clarify its central point.\nQuestions:\nFor a future draft, I encourage the authors to present an explicit falsifiable hypothesis that facilitates both experimentation and analysis.\nIt might be helpful to comment on the downstream applications and practical utility of such activation patching techniques and mechanistic interpretability, particularly to better understand the implications of the \"illusion\". What are the use cases for identifying model components (neurons/subspaces) responsible for model behavior? What evaluation metrics are available to test whether the components have been correctly identified?\nDo these results for subspace activation patching also hold for usual activation patching? It seems like subspace patching is a generalization, and thus it must, and also I see that the toy example is given for the case of usual activation patching, but the experimental results and the paper's messaging are specific to subspace patching.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Clarifying fundamental aspects of our work that were miscommunicated", "Subheading": "Official CommentbyAuthors16 Nov 2023, 18:03Everyone", "Content": "Comment:\nWe thank the reviewer for their thoughtful and thorough review. We are sorry\nthat reading the paper was difficult, and we thank the reviewer for pointing out\nseveral confusing parts of the paper.\nHowever, there are some fundamental\naspects of our work that were miscommunicated, and we would like to clarify them\nbelow\n. We have uploaded a revision that we hope will alleviate these concerns,\nwith changes marked in red.\nThe paper does not pose an explicit hypothesis that can be falsified, limiting\nits scientific validity. [...] The hypothesis seems to be that every patched\nsubspace \u201cv\u201d discovered by DAS can be decomposed into two directions\n\u201cv_disconnected\u201d and \u201cv_dormant\u201d (with specific properties)\nThe key message of our work is not that the illusion described will always\nhappen given some set of assumptions. Instead,\nour central focus is showing\nthe\nexistence\nof the illusion in practical cases of interest\nfor ML\ninterpretability. In the cases that we empirically discovered, the subspaces\nfound indeed decompose as a sum of two orthogonal vectors with the properties\ngiven in Section 3 of the paper, and we found this decomposition a helpful way\nto think about the mechanistic underpinnings of the illusion.\nWe do not claim\nto provide specific conditions that will\nguarantee\nthat the illusion will\noccur\n, or that such a decomposition will exist. This means that our work takes\nthe form of demonstrating the existence of the illusion, rather than proving a\nfalsifiable hypothesis that it should always happen, which we expect is too\nstrong a claim.\nAs other reviewers have noted, this is a valuable contribution to the\ninterpretability literature, as\nthe existence of such cases demonstrates that\none should not apply subspace patching techniques blindly\n. In particular, a\nkey takeaway is that one should not rely solely on end-to-end metrics when\nevaluating optimization-based subspace patching methods for the purpose of\nlocalizing features in language models.\nWe remark that we also provide several theoretical and heuristic reasons to\nexpect the illusion to be prevalent in practice in Section 7, but they are not\nload-bearing to our main message.\n...\"patching along the sum of these directions, the variation in the\ndisconnected part activates the dormant part, which then achieves the causal\neffect\". The latter statement assumes that the model behaves somewhat linearly\nalong these subspaces (i.e., the output of the model along direction \"v\" is\ngiven by a sum of its outputs along \"v_disconnected\" and \"v_dormant\"), which is\na strong hypothesis given that these models are fundamentally non-linear.\nWe make no assumptions of linearity, only about the behavior of the model when\nchanging the activation only along v_disconnected, or only along v_dormant\n. In\nparticular, to address the reviewer\u2019s objection, we only need a weaker set of\nassumptions: that\nchanging the activation only along v_disconnected does not\nchange model outputs\n. This assumption is provably satisfied when, for example,\nwe consider the post-GELU activations of an MLP layer, and v_disconnected is in\nthe kernel of the layer\u2019s down-projection. This is because the only causal\npathway by which the MLP activations affect the rest of the model is via the\nlayer\u2019s down-projection. A down-projection is a linear operation (though\nsubsequent model layers are not linear), and adding a vector in its kernel does\nnot change its output, thus adding v_dormant, or adding v_dormant and\nv_disconnected must have exactly the same downstream effect.\nTo unpack this in more detail, we believe that in the review, the words \u201c...the\noutput of the model along direction \"v\" is given by a sum of its outputs along\n\"v_disconnected\" and \"v_dormant\"...\u201d are intended to mean \u201cwhen changing the\nactivation along v, this results in the same change in model output as the sum\nof the changes when changing only along v_disconnected and when changing only\nalong v_dormant, adjusting the magnitudes of the changes by the projection of v\non the two vectors\u201d.\nThis is a true mathematical fact, but it is independent of any linearity\nassumptions on the neural network\n. Recall that by construction v =\n(v_disconnected + v_dormant) / sqrt(2). Changing some activation A along v alone\nis the same as changing it along v_disconnected and v_dormant simultaneously\n(with coefficient 1/sqrt(2)), and leaving it unchanged along all directions\northogonal to the plane spanned by v_disconnected and v_dormant. Let\u2019s call this\nnew activation A\u2019. By assumption, changing the activation A\u2019 along\nv_disconnected alone results in no change in model output; so this activation A\u2019\nwill produce the same model output as the activation A\u2019\u2019 where only v_dormant\nwas changed. This shows that the change in outputs introduced by changing along\nv is the same as the change in outputs introduced by changing along v_dormant\nalone, plus the change in outputs after changing along v_disconnected alone\n(which is zero)."}, {"Heading": "Response on dormant/disconnected directions, and connecting theory to experiments", "Subheading": "Official CommentbyAuthors16 Nov 2023, 18:16Everyone", "Content": "Comment:\nContinuing from our previous response, we would like to clarify some other aspects of our work that were miscommunicated.\nThe definition of the \"dormant\" subspaces is confusing in the context of this work. If the model output remains unchanged for in-distribution patching and changes only for out-of-distribution samples, what procedures presented in this work result in out-of-distribution samples/activations? As far as I can tell, all procedures described involve patching with in-distribution data.\nWhile the reviewer\u2019s concern would be true in the case of full component activation patching,\nit is possible for subspace activation patching between in-distribution data to result in out-of-distribution activations\nwhen the subspace is a proper subspace of activation space.\nTo explain in more detail, imagine a 2-dimensional activation space, where\nin-distribution activations are always on the x-axis, ie the y-coordinate is\nalways zero. Consider subspace activation patching along the vector\n$v=(1/\\sqrt(2), 1/\\sqrt(2))$ which makes equal angles with the x and y axes. If\nwe patch along $v$ from an example with activation $(x_1, 0)$ into an example\nwith activation $(x_2, 0)$ with $x_1 \\neq x_2$, the result is the activation\n$$(x_2, 0) + 1/\\sqrt(2) * (x_1-x_2) * v =  ((x_1+x_2)/2, (x_1-x_2)/2)$$\nIn particular, this activation is now out-of-distribution, since it has a\nnonzero component along the y axis.\nIs the hypothesis that such a decomposition does not exist for \u201ctrue\u201d subspace directions?\nA definition of \u201ctrue\u201d subspace directions is outside the scope of our work\n.\nRather, our central message is that the existence of such a decomposition, and\nan empirical observation showing that removing the causally disconnected\ncomponent of a subspace greatly reduces the effect of the subspace activation\npatch, should be taken as cause for concern when attributing features to\nparticular subspaces.\n[...] However, the paper fails to connect this terminology (\"disconnected, dormant directions\") in sections 4-7, making it difficult to verify whether the experiments confirm or deny the hypothesis.\nWe do connect the terminology of disconnected and dormant directions to our experiments in several ways:\nFor the IOI task, we orthogonally decompose the $v_{MLP}$ subspace as a sum $v_{MLP} = v_{MLP}^{nullspace} + v_{MLP}^{rowspace}$, where $v_{MLP}^{nullspace}$ is the orthogonal projection of $v_{MLP}$ on the kernel of $W_{out}$, and $v_{MLP}^{rowspace}$ is the orthogonal projection on the rowspace of $W_{out}$.\nBy definition, $v_{MLP}^{nullspace}$ is a causally disconnected direction.\nWe show that the direction $v_{MLP}^{rowspace}$ is significantly less activated by the feature we are patching than the direction $v_{MLP}^{nullspace}$ in Figure 20 in the Appendix. This shows that $v_{MLP}^{rowspace}$ is relatively dormant, compared to $v_{MLP}^{nullspace}$.\nIn our revision of the paper, we have rewritten large parts of Subsection 4.3. to clarify the relationship of the experiments to our model of the illusion.\nFor factual recall, we again decompose the directions found by DAS (which are in the post-gelu activations of MLP layers) in the same way.\nAgain by definition, the nullspace components are causally disconnected.\nTo check how dormant the rowspace components are, we ran the experiment\nshown in Figure 12 in the paper, where we project the difference of\nactivations of the two examples we are patching between on the causally\ndisconnected component (the orthogonal projection on $\\ker W_{out}$), and\nobserve cosine similarity between this projection and the original direction\nof ~0.9; this implies that the cosine similarity with the rowspace component\nis ~0.4; thus, the rowspace component is relatively dormant compared to the\nnullspace one.\nIn our revision of the paper, we have included a note on this in the main body of the text."}, {"Heading": "Response on clarity of writing and self-containedness", "Subheading": "Official CommentbyAuthors16 Nov 2023, 18:29Everyone", "Content": "Comment:\nThe main paper on its own does not seem to be self-contained and seems to contain a significant number of references to the appendix.\nWe acknowledge that there is quite a bit of material in the appendix, and are\nsorry that this made our work harder to follow. We have tried to condense the\ncentral points of our work in the main body of the paper by making the following\nchanges, which have significantly reduced the dependence of the main body in\nsections 4 and 6 on the supplementary material by including the following\ndetails in the main body:\nIOI dataset we used (Section 4.1)\nComputing the direction $v_{grad}$ (Section 4.2)\nComputing directions using DAS (Section 4.2)\nDetails for fact patching experiments (Section 6.1)\nWe moved what was previously Figure 2 to the supplementary material, as we felt that it makes an insufficient contribution relative to the space it occupies.\nSimilarly, we moved the statement of what was previously Lemma 6.1. To the\nappendix, and explained its result informally\nWe hope this alleviates your concern. If there are any other parts of the\nappendices which felt important to understanding the main text, we would\nappreciate you bringing them to our attention.\nThe writing and presentation are sloppy. For example, in Section 4, \u201cker W_out\u201d is never defined, and it is unclear how the results in Table 1 and Figure 3 relate to the description in section 4.3. What is ABB / BAB in Figure 3? What does \u201cconnected\u201d in Table 1 refer to? Overall, how do Table 1, Figure 3, and Figure 4 illustrate support for the presented hypothesis?\nWe have addressed these issues as well as others pointed out by the other reviewers in our updated draft. In particular, we rewrote Subsection 4.3 to fix various problems and better connect the writing to the table and figure. To answer the reviewer\u2019s questions specifically:\n$\\ker W_{out}$ is the kernel of the down-projection of the MLP layer where the\nillusory direction v_MLP is contained.\nThe main text now contains detailed descriptions of all interventions involved, with short names matching those appearing in Table 1.\nFigure 3 relates to the text in Section 4.3 through the paragraph now titled\n\u201cPatching $v_{\\text{MLP}}$ activates a dormant pathway through the\nMLP.\u201d Specifically, Figure 3 illustrates how the subspace activation patch along\n$v_{MLP}$ takes the output of the MLP layer along the gradient direction of the\nname mover query matrices off-distribution.\nHere and elsewhere in the paper, \u201cABB\u201d means prompts where the IO name comes\nfirst, and \u201cBAB\u201d means prompts where the S name comes first. We thank the\nreviewer for pointing out this omission. The notation is now explained in the\ncaption of Figure 3.\nOverall, Table 1 supports our claim for the existence illusion by showing that\nthe subspace patch along $v_{MLP}$ has a significant effect on model outputs\n(much stronger than the effect of patching the full MLP layer\u2019s activations),\nbut this effect disappears when we restrict to the causally relevant component\nof $v_{MLP}$, denoted $v_{MLP}^{rowspace}$ in our revision and introduced in the\n\u201cMethodology\u201d part of Subsection 4.3.  Figure 3 further supports our model of\nthe illusion by showing how the MLP layer\u2019s output on the causally relevant\ndirection $v_{grad}$ (given by the gradient of name-mover attention scores) is\ntaken significantly out of distribution by the patch along $v_{MLP}$. Finally,\nFigure 4 (which is about factual recall) has similar message as Table 1: it\nshows that subspace patching along the directions found by DAS is much more\neffective at changing a model\u2019s completion of a fact than patching the entire\nMLP layer, or patching along only the causally relevant component."}, {"Heading": "Response on motivation for mechanistic interpretability and other related work", "Subheading": "Official CommentbyAuthors16 Nov 2023, 18:34Everyone", "Content": "Comment:\nIt might be helpful to comment on the downstream applications and practical utility of such activation patching techniques and mechanistic interpretability, particularly to better understand the implications of the \"illusion\". What are the use cases for identifying model components (neurons/subspaces) responsible for model behavior?\nMechanistic interpretability has been used in several downstream applications, some of which are: removing toxic behaviors from a model while otherwise preserving performance by minimally editing model weights (Li et al [1]), changing factual knowledge encoded by models in specific components to e.g. enable more efficient fine-tuning in a changing world (Meng et al [2]), improving the truthfulness of LLMs at inference time via efficient, localized inference-time interventions in specific subspaces (Li et al [3]), and studying the mechanics of gender bias in language models (Vig et al [4]).\nWe have added these references to the introduction of the paper in our revision.\n[1] Maximilian Li, Xander Davies, and Max Nadeau. Circuit breaking: Removing model behaviors with targeted ablation. In DeployableGenerativeAI, 2023\n[2] Kevin Meng, David Bau, Alex J Andonian, and Yonatan Belinkov. \u201cLocating and\nediting factual associations in GPT\u201d. In: Advances in Neural Information Processing\nSystems. 2022.\n[3] Kenneth Li, Oam Patel, Fernanda Vi\u00e9gas, Hanspeter Pfister, and Martin Wattenberg. 2023b. Inference-time intervention: Eliciting truthful answers from a language model. arXiv preprint arXiv:2306.03341.\n[4] Jesse Vig, Sebastian Gehrmann, Yonatan Belinkov, Sharon Qian, Daniel Nevo, Simas\nSakenis, Jason Huang, Yaron Singer, and Stuart Shieber. \u201cCausal mediation analysis\nfor interpreting neural nlp: The case of gender bias\u201d. In: arXiv preprint arXiv:2004.12265\n(2020).\nWhat evaluation metrics are available to test whether the components have been correctly identified?\nThis is an area of active research to which our work contributes, though our work is far from the final word on the matter\n. Some concrete and general techniques to evaluate LLM interpretations have been proposed, such as causal scrubbing (Chan et al. [5], mentioned in the related work of our paper). Other common techniques are based on ablations, such as (full component) activation patching, as discussed in our work. More recently, techniques like DAS have been proposed that use subspace activation patching to evaluate mechanistic interpretations of LLMs. Part of our contribution is exhibiting a situation where full-component and subspace activation patching reach different conclusions about the mechanics of the model\u2019s behavior, and arguing why the subspace-level explanation is misleading.\n[5] Lawrence Chan, Adri\u00e0 Garriga-Alonso, Nicholas Goldowsky-Dill, Ryan Greenblatt, Jenny Nitishinskaya, Ansh Radhakrishnan, Buck Shlegeris, and Nate Thomas. \u201cCausal Scrubbing: a method for rigorously testing interpretability hypotheses\u201d.\nhttps://www.alignmentforum.org/posts/JvZhhzycHu2Yd57RN/causal-scrubbing-a-method-for-rigorously-testing"}, {"Heading": "Response on full-component vs subspace activation patching", "Subheading": "Official CommentbyAuthors16 Nov 2023, 18:36Everyone", "Content": "Comment:\nDo these results for subspace activation patching also hold for usual activation patching? It seems like subspace patching is a generalization, and thus it must, and also I see that the toy example is given for the case of usual activation patching, but the experimental results and the paper's messaging are specific to subspace patching.\nThe toy example is of a linear neural network with one hidden layer, where we intend the layer to be a single \u201ccomponent\u201d (the same way we consider an MLP\u2019s post-GELU activations at a given token and layer in an LLM to be a single \u201ccomponent\u201d). This is admittedly a matter of semantics in this simple example. We have added a clarification about this in our revision.\n(The following two paragraphs also appear in the response to reviewer\nYsUK\n) This is a great question.\nA key property of subspace activation patching not shared with full-component activation patching is that it may create out-of-distribution activations for the given component, even when patching only between in-distribution examples\n. This makes it particularly vulnerable to an MLP-in-the-middle type of illusion, where we take the output of the MLP layer off-distribution in order to write some causally important information in the residual stream. Intuitively, this would not be possible to such an extent when patching the full hidden activation of the MLP layer, because its activations for in-distribution examples do not generally write important information to the residual stream (as can be confirmed by doing the full patch).\nHowever, full-component activation patching can still take the activations of the model as a whole off-distribution. It is an interesting question for future work whether a variant of the illusion can be exhibited for full-component patching. For example, if two heads always cancel each other out (one outputs +v and the other -v), we could patch just one of them, such that they no longer cancel out. Thus, it may be possible to patch only one of these components and throw the model off-distribution. However, we expect such scenarios of \u201cperfect cancellation\u201d to be rarer in practice."}, {"Heading": "Concluding response", "Subheading": "Official CommentbyAuthors16 Nov 2023, 18:37Everyone", "Content": "Comment:\nWe apologize again for the miscommunication and lack of clarity in our writing. We have tried to clarify the parts of the paper flagged by the reviewer in our updated revision. We hope that these changes and our detailed responses alleviate the reviewer\u2019s concerns."}, {"Heading": "Reminder about end of discussion period", "Subheading": "Official CommentbyAuthors21 Nov 2023, 07:23Everyone", "Content": "Comment:\nDear reviewer\n8jAi\n, this is a gentle reminder that the end of the discussion\nperiod draws near (in approximately 48 hours).\nWe have responded with a\nrebuttal to your comments\n, and we hope you will respond back, letting us know\nif your concerns have been alleviated. If you have any remaining concerns, we\nwould be happy to continue the discussion."}, {"Heading": "Official Comment by Reviewer 8jAi", "Subheading": "Official CommentbyReviewer 8jAi21 Nov 2023, 15:19 (modified: 21 Nov 2023, 15:25)EveryoneRevisions", "Content": "Comment:\nI thank the authors for their detailed response. While I carefully read the updated paper and rebuttal, I want to clarify the following aspects:\nRe: falsifiable hypothesis\n: Note that a falsifiable hypothesis does not require specifying the precise conditions under which the illusion occurs. In this case, a hypothesis can also be stated as \"there exist pre-trained ML models such that the following property holds with their activations: ...\". I believe that presenting a falsifiable hypothesis falls well within the scope of this work and, in general, any scientific work. The key idea is to present a concrete test to validate the hypothesis (i.e., the provided explanation) BEFORE looking at the experimental evidence.\nRe: definition of dormant directions\n: The paper defines a dormant direction as \"We say U is dormant if $M_{U_c \u2190u_y} (x) \u2248 M(x)$ with high probability over x, y \u223c D, but not over any x, y\". This definition critically relies upon having access to in-distribution and out-of-distribution inputs \"x\". Yet the rebuttal states that \"While the reviewer\u2019s concern would be true in the case of full component activation patching, it is possible for subspace activation patching between in-distribution data to result in out-of-distribution activations when the subspace is a proper subspace of activation space\".\n(1) This is a contradiction: does the definition apply to inputs or patched activations, or likely, both? (If so, please clarify in the main text)\n(2) The presented arguments are circular. The authors state that patching creates OOD activations, yet the definition is about model output invariance in the presence of patching. Can you please clarify?\n(3) Why doesn't full activation patching, similar to subspace patching, also result in OOD activations? Both these techniques create \"synthetic\" activations, and thus, there is a high chance of both being OOD."}, {"Heading": "Re: definition of dormant directions", "Subheading": "Official CommentbyAuthors22 Nov 2023, 17:54Everyone", "Content": "Comment:\nWe thank the reviewer for their response.\nRe: definition of dormant directions\n: We apologize for the confusion and thank the reviewer for pointing it out. The definition should be: \"We say [the subspace of the activation space of a model component] U is dormant if  $M_{U_{C} \\leftarrow u_y}(x)\\approx M(x)$ with high probability over $x, y \\sim D$, but, given $x$ from $D$, there exists some $u$ such that $M_{U_{C} \\leftarrow u}(x)\\not \\approx M(x)$\u201d\nThat is,\nrunning the model on an input $x$ from $D$, and intervening on this run by setting the projection of the activation on $U$ to that of another input from $D$ does not change model outputs much compared to just running the model on $x$ without an intervention,\nhowever, it is possible to run the model on an input $x$ from $D$, and intervene by setting the activation to some other value $u$ (which we referred to as an out-of-distribution value), and get a very different result than just running the model on $x$. Crucially, this other value $u$ cannot be obtained by running the model on some input $x$ from $D$, and projecting the activation of the subspace $U$.\nWe have published a revision of the paper correcting this; the correct definition is the one we intended in all experiments and other discussions; this is an isolated bug in the paper for which we apologize.\nTo address the reviewer\u2019s concerns specifically:\n(1)\nThere is no contradiction\n; the definition and the comment in the rebuttal refer to two related, but crucially different phenomena.\nThe definition of a dormant subspace is as stated above. It considers two cases: one case is about subspace activation patching between in-distribution inputs; the other case is intervening on the run of the model on an in-distribution input by setting the projection of the activation of the given component to a given value $u$, which has the property that there is no input $x'$ from $D$ such that the projection of the given component's activation on $U$ when the model is run on $x'$ is $u$.\nThe comment in the rebuttal is correct as stated. However, this comment is\nnot about patching a dormant subspace\n. Instead, the comment refers to the key observation that there exist subspaces $S$ of the activation space of a component $C$ which, when activation-patched, can lead to an activation $A$ such that $A$'s projection on\na dormant subspace $U$ which is different from $S$\nis off-distribution, i.e. there is no input $x'$ from $D$ such that the projection of the given component's activation on $U$ when the model is run on $x'$ is $u$. This is illustrated in Figure 1 in the paper, where activations over $D$ vary only along the x-axis of a two-dimensional activation space, we patch along the direction y=x, and the resulting activation is completely along the y-axis (which cannot be realized by simply inputting examples from $D$).\n(2)\nOur arguments are not circular\n: A dormant direction in the activation space of a model component is defined as one that can potentially change model output significantly if set to some value. In this sense, a dormant direction can\npotentially\nlead to non-invariant model outputs. Furthermore, as explained in (1),\nthe key phenomenon behind the illusion relies on patching along a subspace that is not purely dormant\n, but the patch has the effect of taking the projection of the activation on the dormant subspace off-distribution.\n(3) When we say that full component activation patching does not result in OOD activations, we mean\nrestricting to activations of the given component only\n. In this sense, full-component activation patching always exchanges one input\u2019s activation with another\u2019s, so the result is still in-distribution. By contrast, subspace patching can create an activation for this component which is not realizable when we use as input any example in the distribution. However, if we consider the collective activations of all components, it is true that full-component activation patching can take this collective activation off-distribution. We have also addressed this point at more length in our \u201cResponse on full-component vs subspace activation patching\u201d."}, {"Heading": "Re: falsifiable hypothesis", "Subheading": "Official CommentbyAuthors22 Nov 2023, 17:58Everyone", "Content": "Comment:\nWe thank the reviewer for their clarification. In light of this clarification, our hypothesis can be expressed as: \u201cThere exist pre-trained transformer language models, pairs of distributions $D_{base}$ and $D_{source}$ over inputs to these language models, ground-truth next-word predictions for inputs in $D_{base} \\cup D_{source}$, and 1-dimensional subspaces $S$ of post-GELU activations of MLP layers in these models, such that activation patching from $x_{source}\\sim D_{source}$ into $x_{base}\\sim D_{base}$ along $S$ has a strong effect of shifting probability from the ground-truth completion of $x_{base}$ to that of $x_{source}$, but this effect is significantly diminished when activation patching is performed along the component of $S$ orthogonal to the nullspace of the down-projection $W_{out}$ of the MLP layer.\u201d Here, the nullspace component of $S$ is the causally disconnected subspace, and the rowspace component (the one orthogonal to the nullspace component) is hypothesized to possibly be dormant.\nWe have included it in Section 3 of the paper in the revision recently uploaded, and our experiments in sections 4,5,6 refer directly to this (when patching along the \"rowspace\" component of the subspaces considered)."}]}, {"Heading": "Official Review of Submission9274 by Reviewer ERkw", "Subheading": "Official ReviewbyReviewer ERkw20 Oct 2023, 15:18 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper identifies a challenge for the approach of looking for subspaces corresponding to causal factors of deep neural network output.  It claims that activation patching and subspace patching approaches are at risk of an interpretability illusion where the patching fails to change the causal pathways actually leading to undesired input.  It develops the concepts of dormant pathways and causally disconnected pathways to explain why the interpretability illusion is possible.  The paper illustrates its model of the interpretability illusion using a toy example.  Furthermore, it presents real-life case studies.  One set of case studies focuses on language models, particularly the indirect object identification task.  For the IOI task, previous works have used activation patching to correct a network to output the indirect object of a sentence rather than the direct object.  The paper identifies an approach to the task, using distributed alignment search, that is subject to the interpretability illusion.  It also identifies an approach, using prior knowledge about the network to identify the nodes responsible for the error, that correctly patches the network.  The paper explains the difference between these approaches using the concepts of dormant and causally disconnected pathways.  Furthermore, the paper also studies factual recall in language models as an additional case study.  It presents a set of experiments where it shows that the vulnerability of activation patching to the interpretability illusion depends on the layer which is targeted.  The paper also includes some additional discussion on connections between activation patching and rank-one model edits.\nSoundness:\n2 fair\nPresentation:\n4 excellent\nContribution:\n4 excellent\nStrengths:\nThis is a highly relevant work for the field of deep neural network interpretability, as it identifies a serious obstacle to the activation and subspace patching approaches.  The concepts of dormant and causally disconnected pathways are intuitive, and they are developed with the aid of theory and experiment.  The paper is clearly written, and figures help illustrate the concepts of the interpretability illusion, and the mechanisms involved in the IOI task.  This paper is significant for both identifying a practical problem and for developing intuitions that deepen our understanding of interpretability methods for deep neural networks.\nWeaknesses:\nThe definitions seem rather brittle.  Requiring strict equality in the definitions of causally disconnected and dormant seems to be very limiting for practice.\nQuestions:\nHow do we know that the theoretical account for the interpretability illusion is actually the explanation for the failure of activation patching in the case studies presented?\nAre there a set of empirical predictions (e.g. about the directions of activations or gradients) that could either falsify or support the theoretical model?\nWhy not relax the definitions of \"causally disconnected\" or \"dormant\" to not require strict equality, but rather to specify that the effect of the the patching be small within some threshold?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 18:46Everyone", "Content": "Comment:\nWe thank the reviewer for their thoughtful review, and for the encouraging\nfeedback on the relevance and clarity of our work. Below, we address the\nreviewer\u2019s questions and other concerns:\nThe definitions seem rather brittle. Requiring strict equality in the definitions of causally disconnected and dormant seems to be very limiting for practice. [...] Why not relax the definitions of \"causally disconnected\" or \"dormant\" to not require strict equality, but rather to specify that the effect of the the patching be small within some threshold?\nWe acknowledge that requiring strict equality in the definition of a dormant\nsubspace is limiting. In our revision of the paper, we have changed the\ndefinition to allow for approximate equality instead\n, which reflects the reality\nbetter. In our experiments (Figure 20 and Figure 12) we find that the orthogonal\ncomplements of the causally disconnected components of the subspaces we find are\nrelatively dormant compared to the causally disconnected components.\nAs for causally disconnected subspaces,\nit is not too limiting to require strict\nequality, and all our empirical examples of causally disconnected subspaces obey\nstrict equality\n. Recall that a subspace of the activations of some model\ncomponent is causally disconnected if changing the activation only along this\nsubspace (leaving the component orthogonal to the subspace unchanged) does not\nchange the model\u2019s output. This assumption is provably satisfied when, for\nexample, we consider the post-GELU activations of an MLP layer, and\n$v_{disconnected}$ is in the kernel of the layer\u2019s down-projection. This is\nbecause the only causal pathway by which the MLP activations affect the rest of\nthe model is via the layer\u2019s down-projection. A down-projection is a linear\noperation, and adding a vector in its kernel does not change its output.\nHow do we know that the theoretical account for the interpretability illusion is actually the explanation for the failure of activation patching in the case studies presented? [...] Are there a set of empirical predictions (e.g. about the directions of activations or gradients) that could either falsify or support the theoretical model?\nWe connect our theoretical model of the illusion to our experiments using the following approach:\nSuppose we have a 1-dimensional subspace $v$ of the post-GELU activations of an\nMLP layer that we want to argue exhibits the illusion\nDecompose $v = v_{nullspace} + v_{rowspace}$, where $v_{nullspace}$ is the orthogonal projection of $v$ on the kernel of $W_out$, and $v_{rowspace}$ is the orthogonal projection of $v$ on the orthogonal complement of the kernel of $W_out$.\nBy definition, $v_{nullspace}$ is a causally disconnected direction (as\nexplained in our response to the reviewer\u2019s concern about the definitions of\ncausally disconnected and dormant subspaces). This means that the only\ndownstream effect of patching along $v$ is the change of the activation along\n$v_{rowspace}$. Thus, the only consequential difference between patching along\n$v$ and patching along $v_{rowspace}$ is the magnitude of the change of the\nactivation along $v_{rowspace}$.\nTherefore, a\nkey experiment to check for the illusion\nis to patch\nonly long $v_{rowspace}$ and compare the effect to patching along $v$. If the effect\nfrom patching along $v$ is much stronger, this suggests the presence of the\nillusion, because the disconnected component must vary substantially in order to\nchange the coefficient along $v_{rowspace}$\nTo further argue that v_rowspace is approximately dormant, we use different\napproaches for the two tasks:\nFor the IOI task, we plot the distribution of activations, colored by the\nfeature of interest (position of the IO name in the sentence), and projected\non the $v_{rowspace}$ or $v_{nullspace}$ directions (Figure 20). This shows\nthat $v_{rowspace}$ is significantly more dormant than $v_{nullspace}$;\nFor factual recall, we again decompose the directions found by DAS (which\nare in the post-gelu activations of MLP layers) in the same way.\nAgain by definition, the nullspace components are causally disconnected.\nTo check how dormant the rowspace components are, we ran the experiment\nshown in Figure 12 in the paper, where we project the difference of\nactivations of the two examples we are patching between on the causally\ndisconnected component (the orthogonal projection on $\\ker W_{out}$), and\nobserve cosine similarity between this projection and the original direction\nof ~0.9; this implies that the cosine similarity with the rowspace component\nis ~0.4; thus, the rowspace component is relatively dormant compared to the\nnullspace one.\nIn our revision of the paper, we have included a note on this in the main body of the text."}, {"Heading": "Good idea for validating theory", "Subheading": "Official CommentbyReviewer ERkw21 Nov 2023, 11:07Everyone", "Content": "Comment:\nYour response is helpful for thinking about experimentally testing for the validity of your theory.  You describe a test\nA key experiment to check for the illusion is to patch only [a]long $v_{rowspace}$ and compare the effect to patching along $v$.\nWhich I agree would be practical, and could be used to quantify the prevalence of the effect in various networks.  Do you think this experiment could be operationalized into a method for detecting interpretability illusions?"}, {"Heading": "Response to reviewer", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:44Everyone", "Content": "Comment:\nWe believe this experiment is an important signal for the presence illusion, but\nwe would also stress that it is somewhat specific to subspaces of hidden MLP\nactivations.\nSpecifically, for an MLP layer, there is a clear notion of a rowspace-nullspace\ndecomposition of a given activation vector. Namely, since we are considering the\npost-GELU activations, and the only way such activations influence model output\nis through multiplication with the down-projection matrix $W_{out}$ of the\nlayer, it is clear that, given an activation v, we can write $v = v_{nullspace} + v_{rowspace}$ where $v_{nullspace}\\in \\ker W_{out}$ and $v_{rowspace} \\perp\nv_{nullspace}$, and we know that intervening by modifying this activation to\nchange its projection along $v_{nullspace}$ will not change the model's outputs.\nThis is because $W_{out}(\\alpha v_{nullspace} + v_{rowspace}) =\nW_{out}v_{rowspace} = W_{out}(v_{nullspace}+v_{rowspace})$ for any $\\alpha\\in\\mathbb{R}$.\nOn the other hand, in the residual stream of a transformer, an analogous\ndecomposition would be vacuous. This is because the residual stream is\nrelatively low-dimensional (e.g., 768 in GPT2-Small), but at the same time it is\nread by many attention heads in subsequent layers. This means that it is quite\nlikely the intersection of the nullspaces of all these attention heads'\nkey/query matrices is an empty subspace. We have also verified this empirically.\nThis is the reason why we consider only the query matrices of name mover heads\nin Section 5 of the paper. This gives us a non-vacuous notion of a\nnullspace-rowspace decomposition. The downside is that it relies on assumptions\nabout the \"important\" parts of the model. We base these assumptions on the detailed previous work on the IOI circuit.\nTo sum up, this experiment is best applied to subspaces of hidden activations of MLP layers."}]}]}, "qgyLAr2cOs": {"paper_info": {"Primary Area": "general machine learning (i.e., none of the above)", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Best arm identification", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "We investigate the problem of fixed-budget best arm identification (BAI) for minimizing expected simple regret. In an adaptive experiment, a decision maker draws one of multiple treatment arms based on past observations and observes the outcome of the drawn arm. After the experiment, the decision maker recommends the treatment arm with the highest expected outcome. We evaluate the decision based on the expected simple regret, which is the difference between the expected outcomes of the best arm and the recommended arm. Due to inherent uncertainty, we evaluate the regret using the minimax criterion. First, we derive asymptotic lower bounds for the worst-case expected simple regret, which are characterized by the variances of potential outcomes (leading factor). Based on the lower bounds, we propose the Adaptive-Sampling (AS)-Augmented Inverse Probability Weighting (AIPW) strategy, which utilizes the AIPW estimator in recommending the best arm. Our theoretical analysis shows that the AS-AIPW strategy is asymptotically minimax optimal, meaning that the leading factor of its worst-case expected simple regret matches our derived worst-case lower bound. Finally, we validate the proposed method's effectiveness through simulation studies.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9273", "PDF Url": "https://openreview.net/pdf?id=qgyLAr2cOs"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9273 by Area Chair A34m", "Subheading": "Meta ReviewbyArea Chair A34m06 Dec 2023, 01:59 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper studies best-arm identification (BAI) with heterogeneous reward variances. The proposed algorithm is analyzed and evaluated empirically. The pluses and minuses of the paper are:\nClarity:\nSome concepts are not clearly introduced and explained. For instance, the word \"contextual\" is not in the abstract.\nLower bound:\nThis goes beyond the closest related work of Lalitha et al. (2023), which does not prove any lower bound. The lower bound is asymptotic. I think that a finite-sample lower bound would make more sense in the fixed-budget setting, which is motivated by low budget. See Carpentier and Locatelli (2016), which was also discussed in the rebuttal.\nContextual algorithm and analysis:\nThis goes beyond the closest related work of Lalitha et al. (2023), which does not consider context. The problem is that the context is trivial: a finite number of contexts.\nExperiments:\nToo simple and do not clearly demonstrate the benefit of the proposed method.\nWith the above in mind, this paper is a borderline and can go either way.\nJustification For Why Not Higher Score:\nIf the proposed algorithm is empirically evaluated, it should perform well. This paper has mixed empirical results. The theory can also be improved and there is no clear evidence that it cannot be.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Revision", "Subheading": "Official CommentbyAuthors20 Nov 2023, 17:38 (modified: 20 Nov 2023, 17:39)EveryoneRevisions", "Content": "Comment:\nThank you to all reviewers for your constructive comments.\nWe have temporarily updated the manuscript to reply several questions raised by Reviewers 65vH and qfgN (we colored them red). In particular, we added Appendix J to reflect the open problems raised by Reviewers 65vH and qfgN. These updated parts will be more refined until the camera-ready.\nWe will update the manuscript as soon as possible in response to Reviewers ZfPN, and dvWZ, in addition to the remaining replies to  Reviewers 65vH and qfgN.", "Replies": [{"Heading": "Revision (2)", "Subheading": "Official CommentbyAuthors22 Nov 2023, 18:09 (modified: 22 Nov 2023, 18:09)EveryoneRevisions", "Content": "Comment:\nWe thank you again for your constructive suggestions. We have revised the manuscript again to reflect the reviewers' comments. Due to time constraints, we have not been able to fully reflect all of the reviewers' comments. We will continue to update the manuscript based on the comments until the rebuttal phase is complete or camera-ready."}]}, {"Heading": "Official Review of Submission9273 by Reviewer ZfPN", "Subheading": "Official ReviewbyReviewer ZfPN02 Nov 2023, 06:11 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors propose a work in the field of fixed-budget best arm identification for multi-armed bandits when contextual information is available, with the goal of minimizing the expected simple regret.\nThe authors derive asymptotic lower bounds on the expected simple regret depending on the variances of the potential outcomes rather than considering outcomes with bounded supports. The lower bound is provided in both the cases in which contextual information is available and when it is not.\nMoreover, they provide an algorithm, namely AS-AIPW, showing that it matches (asymptotically) the lower bound.\nFinally, the authors present a numerical validation of the presented results just on synthetic data.\nSoundness:\n3 good\nPresentation:\n1 poor\nContribution:\n3 good\nStrengths:\nThe proposed work faces the problem of best arm identification in MABs. The authors discuss the theoretical differences when contextual information are available or not.\nMoreover, the work presents two asymptotic lower bounds (one with and the other without contextual information) and an algorithm, which asympotically matches the lower bounds.\nThe analysis seems to be done properly, but I have not checked the correctness of all the proofs.\nWeaknesses:\nA weakness I found in the paper is linked to the feeling that the authors did not pay great attention to the details.\nIndeed:\nThe abstract is not so clear since it does not introduce the fact that the setting at hand will consider contextual information and that it will compare it with the case in which contextual information is not available;\nThe introductory section is not clear;\nI would appreciate (at least a paragraph) on some motivating examples (also in the appendix) with some comments.\nSome crucial quantities are not commented on, such as the meaning of the AIPW estimator.\nIn the experimental section (even in Appendix I) I found too simple experimental settings. Even if I have appreciated the comparison with fixed-budget BAI when no contextual information is available, I do not believe that it is fair to compare the same baselines (that are not thought for contextual settings) with the proposed algorithm. I suggest employing at least another algorithm thought for the same setting proposed by the authors if present (and if no competitors are available, please write it).\nQuestions:\nBesides the concerns related to the \"weaknesses\" section, here are other questions:\nis it possible to adapt the lower and upper bounds not to be asymptotic?\nwill you release the code of the experiments to assess if the numerical validation is reproducible?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Re: Official Review of Submission9273 by Reviewer ZfPN", "Subheading": "Official CommentbyAuthors15 Nov 2023, 13:15 (modified: 16 Nov 2023, 14:59)EveryoneRevisions", "Content": "Comment:\nWe appreciate the reviewer's detailed feedback. A revised manuscript will be submitted shortly. Below is a preliminary response to the comments:\nBefore answering each question the reviewer raised, we remark that our research addresses both scenarios: with and without contextual information. We have:\nDeveloped the best arm identification (BAI) strategy that leverages variances.\nProposed a BAI strategy that can utilize contextual information in fixed-budget BAI.\nThe novelty lies in using variances (first point) and utilizing contextual information to BAI (second point). Even without contextual information, our study has a novelty in proposal BAI strategies using the variances. Our results cover both scenarios with and without contextual information, as non-contextual cases are inherently included in the contextual ones. Page limitation precluded separate discussions for each setting. However, on page 2, we noted, \"Note that this setting is a generalization of fixed-budget BAI without contextual information, and our result holds novelty even in the absence of contextual information.\"\nWe answer each question below.\nQ1\n.\nThe abstract is not so clear since it does not introduce the fact that the setting at hand will consider contextual information and that it will compare it with the case in which contextual information is not available;\nA1\n.\nWe do\nnot\nfocus on comparing our method with contextual information with existing methods with contextual information. Our study proposes strategies for\nboth\ncases with and without contextual information. In Section 3.4 and Section 7, we compare our method with existing methods in a case where we cannot use contextual information in both methods.\nQ2\n.\nEven if I have appreciated the comparison with fixed-budget BAI when no contextual information is available, I do not believe it is fair to compare the same baselines (not thought for contextual settings) with the proposed algorithm.\nI do not believe that it is fair to compare the same baselines (that are not thought for contextual settings) with the proposed algorithm.\nA2\n. \nIn our main text experiments,\nwe compare our method with existing methods, both without using contextual information,\nas stated in the third line of Section 7: \"We investigate two setups with K = 2, 3 without contextual information for these strategies.\" This ensures a fair comparison.\nIn the Appendix, we compare our method that uses contextual information with existing methods that do not use contextual information.\nQ3\n.\nI suggest employing at least another algorithm thought for the same setting proposed by the authors if present (and if no competitors are available, please write it).\nA3\n. \nTo the best of our knowledge, this setting has no appropriate competitors. In BAI, it is still unclear how we formulate the problem if contextual information is available, and it is an open issue. We will make it clearer in the next update.\nQ4\n.\nIs it possible to adapt the lower and upper bounds not to be asymptotic?\nA4\n. \nAdapting the lower and upper bounds to non-asymptotic conditions seems unfeasible. The finite-sample analysis will be more complicated by the estimation error of the variances, which can be ignored in an asymptotic analysis. Our lower bound is based on the semiparametric efficiency bound, an extension of the Cramer-Rao lower bound, typically used for asymptotic optimality. Addressing finite-sample optimality would require novel and other methodologies.\nQ5\n.\nwill you release the code of the experiments to assess if the numerical validation is reproducible?\nA5\n. \nWe plan to release our experiment code, ensuring it complies with the review process's anonymity requirements. It will be available during the rebuttal phase.\nQ6\n.\nSome crucial quantities are not commented on, such as the meaning of the AIPW estimator.\nA6\n. \nWe explained the details about the AIPW estimator in Section 4.3.  The name comes from the augmentation of the inverse probability of weighting estimator. We add some brief history of this estimator in the next update.\nLastly, our study contributes to two open problems in BAI:\nIntegrating variances into BAI.\nUtilizing contextual information in BAI.\nWe approach these with asymptotic lower bounds via semiparametric analysis and a BAI strategy focusing on the highest marginalized expected reward across contextual distributions. The first point alone stands as an independent contribution. Although we show an approach for the second issue, how we use contextual information is still an open issue. Also, see our Russac et al. (2021) and our rebuttal to the Reviewer 65vH."}, {"Heading": "Official Comment by Reviewer ZfPN", "Subheading": "Official CommentbyReviewer ZfPN21 Nov 2023, 11:37Everyone", "Content": "Comment:\nThank you for your response.\nI think that the problem faced is interesting and that the paper, technically, presents a good contribution. I agree that a lower bound depending on the time budget is hard to be derived in the setting you are considering.\nHowever, my points are related to the fact that all the strengths of your work do not emerge clearly. For instance, the fact that you face both settings with and without contextual information is a strength of the work, thus it should also be highlighted in the abstract. \nMoreover, the motivating examples are just cited and not discussed properly. I would like to see at least one truly motivating example fully explained.\nI remark that I appreciate the work itself, but the presentation should be improved."}, {"Heading": "Re: Official Comment by Reviewer ZfPN", "Subheading": "Official CommentbyAuthors22 Nov 2023, 15:05Everyone", "Content": "Comment:\nOnce again, we deeply appreciate your constructive comments. Following your advice, we will make our contribution more explicit in the Abstract and other sections, as we currently mention that \"Note that this setting is a generalization of fixed-budget BAI without contextual information, and our result holds novelty even in the absence of contextual information.\" in Introduction. In future updates, we will add some examples to the Appendix, in the rebuttal phase, otherwise in the camera-ready."}]}, {"Heading": "Official Review of Submission9273 by Reviewer 65vH", "Subheading": "Official ReviewbyReviewer 65vH28 Oct 2023, 05:08 (modified: 22 Nov 2023, 23:37)EveryoneRevisions", "Content": "Summary:\nThis paper considers the fixed-budget best-arm identification problem in (contextual) multi-armed bandits and takes simple regret minimization as the objective. It first derives an asymptotic minimax lower bound that depends on the variance of the reward distribution. Then, it proposes an algorithm called\nAS-AIPW\nthat nearly achieves this lower bound asymptotically. Finally, sanity check experiments are also provided to validate the effectiveness of the proposed algorithm.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n3 good\nStrengths:\nThe variance dependent asymptotic lower bound is considered to be highly novel.\nUnder specific scenarios, the optimal allocation strategy has closed-form expression.\nThe proposed algorithm nearly achieves the lower bound.\nWeaknesses:\nOne weakness is that the current Theorem 3.8 in this paper does not generalize to the case with $K\\geq 3$ and it is not clear whether the difficulty is technical or fundamental.\nAnother weakness is that most provided experiment results do not show advantages of\nAS-AIPW\nover variance-unaware algorithms. Although the paper conjectures that the superiority of\nAS-AIPW\ncan only appear when $K$ is small, from my perspective, the number of arms should not be the essential factor. In particular, the worst-case regret of variance-unaware algorithms scales with the magnitude of the reward while that of\nAS-AIPW\nscales with the standard deviation of the reward. Therefore, if my understanding is correct, the advantage of\nAS-AIPW\nshould appear if we run it on a hard instance with large reward magnitude but small variance. Is that possible to design and run experiments on such an instance?\nSuggestions on Writing\n3rd line of page 7, \"$w^*(a\\vert X_t)$\" -> \"$(\\sigma^a_t(X_t))^2$\".\nThere is probably no need to explain how to sample an arm $a$ with probability $\\widehat{w}_t(a\\vert X_t)$ at the beginning of Section 4.2.\nThe main context can contain a sketch of techniques used for proving the lower bound and a brief discussion of its novelty.\nQuestions:\nIn the sixth requirement of Definition 3.2, does \"$\\mu^a(P)(x)\\rightarrow \\mu^a(P^\\sharp)$\" means that there exists a sequence of bandit models $\\lbrace P_n\\rbrace$ such that $\\lim_{n\\rightarrow\\infty} \\mu^a(P_n)(x)= \\mu^a(P^\\sharp)$?\nBased on the given results, it seems quite tempting to conjecture that Theorem 3.8 can be generalized to the case with $K\\geq 3$. Is this fundamentally not doable or does it just require more sophisticated techniques?\nWhat are the disadvantages of using $\\arg\\max_{a\\in[K]}\\widehat{\\mu}^a_T$ as the arm recommendation rule? Do these disadvantages exist when there is no context information?\nIf my understanding is correct, when there is no context information, we have $\\widehat{\\mu}^a_t=\\frac{1}{t}\\sum_{s=1}^{t}\\mathbf{1}\\lbrace A_s=a\\rbrace Y_s$. Then, it looks weird that $\\widehat{\\mu}^{\\mathrm{AIPW}, a}_T$ contains the term $$\\frac{1} {T}\\sum_{t=1}^{T}\\widehat{\\mu}^a_t=\\frac{1}{T}\\sum_{t=1}^{T}\\left(\\sum_{s=t}^{T}\\frac{1}{s}\\right)\\mathbf{1}\\lbrace A_t=a\\rbrace Y_t,$$ since it means that more weights are explicitly put on earlier samples. Why will this happen?\nSuppose there are not many possible contexts and we can encounter each contexts for sufficiently many times, can we treat\nAS-AIPW\nas doing BAI for each context independently? That is, if we define $$\\widehat{a}^{\\mathrm{AIPW}}_T(x)=\\arg\\max_{a\\in[K]}\\frac{1}{T}\\sum_{t=1}^{T}\\mathbf{1}\\lbrace X_t=x\\rbrace \\varphi^a_t(Y_t, A_t, X_t),$$ can we bound the simple regret condition on $X=x$ by $$\\max_{a, b\\in[K]: a\\neq b}\\sqrt{\\log(K)\\left(\\frac{(\\sigma^a(x))^2}{w^*(a\\vert x)}+\\frac{(\\sigma^b(x))^2}{w^*(b\\vert x)}\\right)}+o(1)?$$\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Re: Official Review of Submission9273 by Reviewer 65vH", "Subheading": "Official CommentbyAuthors16 Nov 2023, 16:11Everyone", "Content": "Comment:\nThank you for your insightful comments. We updated our manuscript based on your feedback. We also make additional sections in the Appendix to answer the technical questions the reviewer raised (Q2--Q5 below) during this phase.\nOur brief replies to your comments are listed as follows.\nQ1\n.\nDoes \"$\\mu^a(P)(x)\\to \\mu^a(P^\\sharp)$\" means that there exists a sequence of bandit models ${P_n}$ such that $\\lim_{n\\to\\infty}\\mu^a(P_n)(x) = \\mu^a(P^\\sharp)$?\nA1\n.\nWe appreciate your comment. Yes, we assume the existence of such a sequence of bandit models ${P_n}$. We will update our manuscript following your more rigorous definition.\nQ2\n.\nIt seems quite tempting to conjecture that Theorem 3.8 can be generalized to the case with $K\\geq 3$.\nA2\n.\nWe agree with the reviewer's comment and also consider that extending Theorem 3.8 for $K\\geq 3$ is an important open issue. To address this issue, we believe that current assumptions for distributions and restrictions for strategies are insufficient. We need to add more assumptions and develop additional tools for this problem.\nFor example, the framework of the limit of experiments (van der Vaart, 1998) is one of the promising directions. This framework is expected to allow us to derive tight lower and upper bounds by using the asymptotic normality. However, to apply the results, we need to restrict strategy class and underlying distribution appropriately.\nRecently, Kato (2023) derived results similar to Theorem 3.8 for $K \\geq 3$ in minimization of the probability of misidentification ($\\mathbb{P}_P(\\hat{a}_T \\neq a^*(P))$). However, the results are limited to cases with known variances, minimization of the probability of misidentification, and Gaussian distributions. It is an open issue how we derive similar results for expected simple regret minimization.\nKato (2023), Locally Optimal Best Arm Identification with a Fixed Budget.\nWe summarize this problem as an open issue.\nQ3\n.\nWhat are the disadvantages of using $\\arg\\max_{a\\in[K]}\\hat{\\mu}^a_T$?\nA3\n..\nWe conjecture that both $\\hat{\\mu}^a_T$ and $\\hat{\\mu}^{AIPW, a}_T$ have almost the same theoretical properties when there is no contextual information. However, proving the regret upper bound for $\\hat{\\mu}$ requires a more complicated proof procedure compared to $\\hat{\\mu}$ or requires some additional assumptions. This problem is related to theories of empirical process and martingales, as discussed in Hirano et al. (2003) and Hahn et al. (2011).\nWe believe that showing it is not straightforward and an open issue, even though it is probably possible . We also summarize this problem as an open issue in another reply or the Appendix.\nQ4\n.\nIt looks weired that $\\hat{\\mu}^{AIPW}$ contains the term $\\frac{1}{T}\\sum^T_{t=1}\\hat{\\mu}^a_t$.\nA4\n.\nThis term is introduced for variance reduction with keeping the martingale properties for $\\frac{1}{T}\\sum^T_{t=1}\\hat{\\mu}^a_t$. Here, an effect of $\\frac{1}{T}\\sum^T_{t=1}\\hat{\\mu}^a_t$ vanishes very quickly because of the existence of the product\n$|\\hat{w}(a) - w^*(a)||\\hat{\\mu}^a(P) - \\hat{\\mu}^a_t|$ in theoretical analysis, which accelerates the vanish of the estimation error of $w^*$ and $\\mu^a(P)$. That is, the introduction of $\\frac{1}{T}\\sum^T_{t=1}\\hat{\\mu}^a_t$ reduces the variance of the main estimator without increasing bias (asymptotically). This technique is used in different literatures, such as van der Laan (2008) and Chernohukov et al. (2018), which are recently called double machine learning.\nThis property is related to the Q3 the reviewer raised. We add more explanations on this problem in the Appendix.\nQ5\n.\nSuppose there are not many possible contexts and we can encounter each contexts for sufficiently many times, can we treat AS-AIPW as doing BAI for each context independently?\nA5\n.\nYes. We can conduct context-specific treatment recommendation is possible when there are not many discrete contextual information.\nWe are now extending the result for policy learning with BAI; that is, given a set $\\Pi$ of policies $\\pi:[K]\\times\\mathcal{X} \\to (0, 1)$ such that $\\sum_{a\\in[K]}\\pi(a|x) = 1$ (and potentially continuous contextual information), we train a policy $\\pi\\in\\Pi$ to minimize the regret. Consider we restrict a policy class $\\Pi$ to the one such that we discretize the contextual information and recommend an arm within each discretized contextual information. Then, such a strategy aligns with the strategy that the reviewer suggested.\nThe remaining open issue is how we bound the regret for general $\\Pi$. Because samples are non-i.i.d., we cannot directly apply the standard complexity measure such as the Rademacher complexity. This open problem has garnered attention in this literature, and we summarize it in the next update."}, {"Heading": "Response", "Subheading": "Official CommentbyReviewer 65vH17 Nov 2023, 18:33Everyone", "Content": "Comment:\nThank you very much for your reply! Could you also update the pdf and color the added details that you plan to elaborate (such as more discussions about the estimator and context-specific BAI)?\nMeanwhile, could you also discuss what your opinion is about the second weakness mentioned in my initial review?"}, {"Heading": "Re: Response", "Subheading": "Official CommentbyAuthors20 Nov 2023, 14:27Everyone", "Content": "Comment:\nThank you for your reply. We will revise the manuscript as soon as possible.\nWe reply to the following question.\nQ\n.\nAnother weakness is that most provided experiment results do not show advantages of AS-AIPW over variance-unaware algorithms. Although the paper conjectures that the superiority of AS-AIPW can only appear when $K$ is small, from my perspective, the number of arms should not be the essential factor. In particular, the worst-case regret of variance-unaware algorithms scales with the magnitude of the reward while that of AS-AIPW scales with the standard deviation of the reward. Therefore, if my understanding is correct, the advantage of AS-AIPW should appear if we run it on a hard instance with large reward magnitude but small variance. Is that possible to design and run experiments on such an instance?\nA\n. \nWe appreciate your suggestion.\nFirst, we can run an experiment with a large reward magnitude but a small variance. We will add the experiment in the camera-ready if it cannot be finished during this rebuttal phase.\nSecond, we believe that there are two effects.\nthe worst-case regret of variance-unaware algorithms scales with the magnitude of the reward while that of AS-AIPW scales with the standard deviation of the reward\nWe conjecture that our proposed strategy outperforms existing methods in experiments with harder instances (smaller gaps) with larger $T$.\nthe advantage of AS-AIPW should appear if we run it on a hard instance with large reward magnitude but small variance.\nAdditionally, we agree with your comment above. In existing studies, such as economics and epidemiology, variance-aware adaptive experiments are often employed in situations with large reward magnitude. Therefore, such settings are more suitable for our algorithm.\nWe will conduct experiments and add discussion in the future update (if possible, we will finish it during the rebuttal phase)."}, {"Heading": "Response", "Subheading": "Official CommentbyReviewer 65vH22 Nov 2023, 23:36Everyone", "Content": "Comment:\nThanks for the response. My concerns on the theoretical side are mostly addressed. However, I do believe it's important to have some empirical evidence showing the advantage of being variance-aware under certain scenarios. Nevertheless, I'm still inclilned to acceptance given the theoretical contribution. Therefore, I decide to lower my score to 6."}]}, {"Heading": "Official Review of Submission9273 by Reviewer dvWZ", "Subheading": "Official ReviewbyReviewer dvWZ26 Oct 2023, 11:47 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper considers the problem of fixed budget best arm identification, with the goal of minimising the expected simple regret. Asymptotic lower bounds of the worst-case expected simple regret are provided, where the bound depends on the variances of potential outcomes. The bound gives possible analytical solutions for the target allocation ratio, based on which, the authors proposed Adaptive-Sampling Augmented Inverse Probability Weighting (AS-AIPW) strategy. AS-AIPW relies on the adaptive estimation of variances. AS-AIPW is proved to be asymptotically minimax optimal. The proposed algorithm is evaluated in simulation studies.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe paper presents the first asymptotic lower bounds for the worst-case expected simple regret based on the variances of potential outcomes, contributing to the theoretical foundation of the field.\nThe introduction of the Adaptive-Sampling Augmented Inverse Probability Weighting (AS-AIPW) strategy, using the target allocation ratio from the lower bounds\nThe theoretical proof of AS-AIPW being asymptotically minimax optimal provides strong theoretical support for the proposed algorithm's performance.\nThe paper includes simulation studies comparing the proposed algorithm to baselines, enhancing the practical understanding of its performance.\nWeaknesses:\nonly asymptotic theoretical results are provided. For fixed budget settings, non-asymptotic bounds can provide a better understanding of algorithm performance under a fixed budget.\nThe proposed algorithm AS-AIPW highly depends on the variance estimation. It is unclear how poor estimations at the early stage and for more general distributions influence non-asymptotic performance. A discussion can be provided.\nThe experimental results verify the above concern, the proposed algorithm tends to outperform baselines when variances significantly vary across arms. It is worth showing how variances and different variance estimators influence the performance of the proposed algorithm.\nQuestions:\ncan you define w(a|x) in Theorem 3.4?\nA related work: On Best-Arm Identification with a Fixed Budget in Non-Parametric Multi-Armed Bandits, Barrier et al 2023. Can you discuss this?\nin Figure 1, can you also draw the standard deviation of the independent trials?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNA\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Re: Official Review of Submission9273 by Reviewer dvWZ", "Subheading": "Official CommentbyAuthors18 Nov 2023, 18:55 (modified: 18 Nov 2023, 18:56)EveryoneRevisions", "Content": "Comment:\nThank you for your insightful comments. We will update our manuscript based on your feedback during this rebuttal phase.\nBefore updating the manuscript, we reply to your comments below.\nQ1\n.\nnon-asymptotic bounds can provide a better understanding of algorithm performance under a fixed budget.\nA1\n.\nWe showed the non-asymptotic upper bound in Appendix H. For the lower bound, we consider it is not easy to derive non-asymptotic results for the following reasons.\nAlthough the estimation error of the variances can be ignored in the worst-case asymptotic analysis, it affects the lower bound in the non-asymptotic analysis. However, the analysis of variance estimation will be too complicated to analyze.\nOur technique is based on the information-theoretic lower bound provided by Kaufmann et al. (2016) and semiparametric efficiency bounds. Both techniques are used for asymptotic analysis. Therefore, we need to develop completely different approaches for non-asymptotic analysis.\nWe deal with general distribution by approximating the KL divergences. If we focus on the non-asymptotic analysis, we need to restrict the class of distributions to specific distributions, such as the Gaussian distribution, even if possible.\nOne of the promising approaches for lower bounds is to employ lower bounds provided by Carpentier and Locatteli (2016). However, this lower bound is based on the boundedness of $Y^a_t$. Without the boundedness, non-asymptotic analysis would be more difficult. Additionally, the definitions of optimality might be changed to deal with the uncertainty of variance estimation. Thus, although the non-asymptotic upper bound has been derived, deriving non-asymptotic lower bounds requires different techniques and is not straightforward, even if possible. We will explain this open issue in the next update.\nCarpentier, A. and Locatelli, A. Tight (lower) bounds for the fixed budget best arm identification bandit problem, 2016.\nQ2\n.\nIt is unclear how poor estimations at the early stage and for more general distributions influence non-asymptotic performance of the AS-AIPW.\nA2\n.\nAs we answered in A1 and you pointed out, the non-asymptotic performance will be affected by variance estimation. We showed the non-asymptotic upper bound in Appendix H by assuming the convergence rate of the variance estimation. Unless we assume that a specific convergence rate is given for the variance estimation or variances are known, it is difficult to derive asymptotic results. We will explain this limitation more clearly in the next update.\nQ3\n.\nThe experimental results verify the above concern...\nA3\n. \nWe appreciate your suggestion. We will add additional experimental results in the next update using different distributions with various variances.\nQ4\n.\ndefine w(a|x) in Theorem 3.4\nA4\n.\nIt is defined as a element of $\\mathcal{W}$, which is defined in the above of Theorem 3.4.\nQ4\n.\nCan you discuss Barrier et al 2023?\nA4\n. \nFirst of all, while we consider the expected simple regret minimization, that work considers minimization of the probability of misidentification. These two settings are related but require different analyses for lower bounds. See Komiyama et al. (2023).\nAdditionally, there are the following critical differences between our study and theirs in non-parametric analysis using the KL divergence of Kaufmann et al. (2016).\nIn the lower bound, our study approximates the KL divergence by the Fisher information (semiparametric influence function) around the gaps between the best and suboptimal arms are zero $\\Delta^a(P) \\to 0$. We do not assume the boundedness of $Y^a_t$. In the upper bound, we utilize the central limit theorem for deriving tight results.\nBarrier et al. (2023) assumes the boundedness of $Y^a_t$. Then, bounding the KL divergences using the boundedness without using the small gap (fixed $\\Delta^a(P)$).\nBecause we employed the worst-case analysis, which implies $\\Delta^a(P) \\approx 1/\\sqrt{T}$ (see Section 3), we could naturally develop non-parametric results. However, we cannot employ such an approximation in Barrier et al. (2023) because it considers lower and upper bounds under a fixed $P$ or fixed $\\Delta^a(P)$. Furthermore, unlike the expected simple regret minimization, the optimality in minimization of the probability of misidentification is still an open issue. Also see Komiyama et al. (2023) and Qin (2022). We remark on these differences in the next update.\nKomiyama, J., Ariu, K., Kato, M., and Qin, C. Rate-optimal bayesian simple regret in best arm identification, 2023.\nQin, C. Open problem: Optimal best arm identification with fixed-budget, 2022.\nQ5\n.\nin Figure 1, can you also draw the standard deviation?\nA5\n. \nThank you for your suggestion. We will add the standard deviations or the boxplot in the next update."}]}, {"Heading": "Official Review of Submission9273 by Reviewer qfgN", "Subheading": "Official ReviewbyReviewer qfgN24 Oct 2023, 02:15 (modified: 20 Nov 2023, 20:18)EveryoneRevisions", "Content": "Summary:\nThis paper considers Best Arm Identification problem under the fixed-budget setup. It aims at minimizing the expected simple regret, i.e., the expected difference between the oracle best arm and the recommended arm. An asymptotic worst-case lower bound concerning the variances of the arms is provided. An algorithm AS-AIPW strategy is devised with almost matching worst-case upper bounds. Compared to the existing literature, it utilizes more information of the distribution (i.e., the variance) to refine the arm allocation rules. Additionally, it considers the benefit of taking contextual information into account. Experiments are also conducted to illustrate the empirical performances.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe paper extends the BAI problem under the fix-budget setup to the context-aware setup. Both the lower bounds and upper bounds involve a context-aware variables that tighten the bounds.\nThe lower bound result is appreciated. While the proof is complicated, the result yields theoretical foundations on why we should pull the arms according to the allocation proportional to their variances in order to hit the lower bound. It also resolves the remaining lower bound problem in [1] to some extent (as [1] considers the misidentification probability instead of the expected simple regret). I believe this is the main novelty of the paper and is of theoretical interest.\nAn algorithm AS-AIPW is designed whose upper bound asymptotically matches the lower bound in the worst-case up to a factor of $log K$. A non-asymptotic upper bound is also given, which helps us to understand the convergence rate.\nEmpirical studies of the algorithm are carried out to illustrate the performance.\n[1] Lalitha, A., Kalantari, K., Ma, Y., Deoras, A., and Kveton, B. Fixed-budget best-arm identification with heterogeneous reward variances. In Conference on Uncertainty in Artificial Intelligence, 2023.\nWeaknesses:\nWhile experiments are conducted to compare multiple algorithms, little improvement has been observed of the proposed algorithm compared to the existing ones, even in the case where the variances are heterogeneous (which is claimed to be favorable for the proposed algorithm). In addition, the algorithm design is somewhat expected given the G-optimal design and the intuition in [1].\n[1] also considers incorporating variances into the algorithm. The proposed algorithm is similar to [1] under the sole context case in the sense that both pull arms according to the (empirical) variances. So a more detailed discussion/comparison with [1] in terms of the algorithm design, the bounds (on the misidentification probability and expected simple regret) and the empirical performances is appreciated.\nMinors:\nPage 3 Line 3: Instead of \"$A_t$ is $\\mathcal{F}_t$-measurable\", I think $A_t$ is only $\\sigma(X_1,A_1,Y_1,\\dots,X_t)$-measurable. Please kindly check.\nIs $\\pi^{Uniform-EBM}$ a typo? Should be $\\pi^{Uniform-EBA}$\nPage 6, Line 3 in subsection 4.1, the numerator of the allocation for arm 1 is $\\sigma^1$\nPage 6, Line 2 after Theorem 3.8, I suppose $X_t$ should be $X$ in the inequalities? In addition, I do not follow why $E^X[\\frac{(\\sigma^1(X))^2}{w(1|X)}+\\frac{(\\sigma^2(X))^2}{w(2|X)}]\\geq\\max_{a\\in[2]}\\sqrt{E^X[\\frac{(\\sigma^a(X))^2}{w(a|X)}}]$, as $\\frac{1}{8}+\\frac{1}{8}<\\sqrt{1/8}$.\nQuestions:\nCan you give more explanations on $\\underline{C}$ at the end of Page 4? From my understanding, in [2], the forced exploration is a design of the algorithm. And in [3], $\\beta$ is also a hyper parameter (thus, a design) of the algorithm. But here $\\underline{C}$ is an assumption on the problem instance, so I think they are not similar.\nGiven that the optimal allocation is known, is it possible to adopt a tracking sampling rule, i.e., sampling the arms in a way such that the empirical arm allocation approaches the optimal allocation. As indicated by section 2.3 in [4], sampling according to a distribution can make the convergence speed slow. Can you give comments on the allocation rule?\nIt would be better if you describe the experiment designs in more detail. In particular,\nfor the Sequential Halving-based algorithm, it only recommends an arm at the end of the experiment, how to compute the simple regret of the arm at $t\\in { 1000,\\dots,50000 }$? And it would also be interesting to see how SHAdaVar behaves without contextual information while the other algorithms have access to contextual information in App. I.2.\nfor the other algorithms, how you incorporate contextual information in the original algorithm.\nPlease also refer to the Weaknesses section. I'd appreciate it if you can resolve my concerns.\n[2] Garivier, A. and Kaufmann, E. Optimal best arm identification with fixed confidence. In Conference on Learning Theory, 2016.\n[3] Russo, D. Simple bayesian algorithms for best-arm identification. Operations Research, 68(6), 2020.\n[4] Fiez, T., Jain, L., Jamieson, K. G., & Ratliff, L. Sequential experimental design for transductive linear bandits.\nAdvances in neural information processing systems\n,\u00a032, 2019.\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNone\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Re: Official Review of Submission9273 by Reviewer qfgN", "Subheading": "Official CommentbyAuthors17 Nov 2023, 17:28Everyone", "Content": "Comment:\nWe appreciate your comments and will revise our manuscript accordingly during this rebuttal phase.\nWe first answer the reviewer's comment on the comparison with [1].\n[1] Lalitha, A., Kalantari, K., Ma, Y., Deoras, A., and Kveton, 2023.\na more detailed discussion/comparison with [1] in terms of the algorithm design, the bounds (on the misidentification probability and expected simple regret), and the empirical performances is appreciated.\nWe introduced [1] as a recent existing work and compared our algorithm with the algorithm proposed by [1] in simulation studies. We also briefly discussed [1] in the Appendix as follows:\nTherefore, ... Lalitha et al. (2023) also provide variance-dependent BAI strategies, but their\noptimality needs to be clarified.\nOnly when variances are known ... However, Lalitha et al. (2023) proposes using\nthe ratio of variances with successive halving, ....\nThus, we have already sufficiently discussed [1].\nRegarding [1], we limit our analysis due to ambiguities in existing literature. Our concerns:\n[1] is not the first work of BAI with heterogeneous variances. For example, given known variances, many existing studies, such as [2,3.4.5,6], have already proposed algorithms using heterogeneous variances.\nHowever, the lower bounds have been unknown when $K\\geq 3$ with general distributions. That is, although there are various methods, it has been unclear which algorithm is optimal.\nWhen $K=2$ and variances are known, [3] gives an asymptotically optimal algorithm for Gaussian distributions with heterogeneous variances.\nHow we interpret the results in the existing literature is an open issue.\n[2] Glynn, P. and Juneja, S. A large deviations perspective on ordinal optimization, 2004.\n[3] Kaufmann, E., Capp\u00e9, O., and Garivier, A. On the complexity of best-arm identification in multiarmed bandit models, 2016.\n[4] Adusumilli, K. Risk and optimal policies in bandit experiments, 2021.\n[5] Armstrong, T. B. Asymptotic efficiency bounds for a class of experimental designs, 2022.\n[6] Chen C-H, Lin J, Y\u00fccesan E, Chick SE, Simulation budget allocation for further enhancing the efficiency of ordinal optimization, 2000.\nFurther issues with [1]:\nIt is unknown how [1] relates to existing studies using heterogenous variances.\nWhen $K =2$ and variances are known, the algorithm of [1] does not match an existing optimal algorithm, known as the Neyman allocation.\nIt seems that [1] does not match existing conjectures of optimal algorithms, such as Example 1 of [1].\nIt seems that the upper bound of [1]' algorithm does not align with the lower bound provided by [3].\nFor example, [7] recently derives a lower bound for minimization of the probability of misidentification from the results of [3] under a small-gap regime. According to the result, the target allocation ratio is given as\n$$w^*(a^*(P)) = \\frac{\\sigma^{a^*(P)}}{\\sigma^{a^*(P)} + \\sqrt{\\sum_{b\\in[K]\\setminus {a^*(P)}}}(\\sigma^b(P))^2}$$ \nand \n$$w^*(a) = (1 w^*(a^*(P)))\\frac{(\\sigma^b)^2}{\\sum_{b\\in[K]\\setminus {a^*(P)}}(\\sigma^b(P))^2}.$$\nThis target allocation ratio is also different from the one in [1].\n[7] Kato (2023), Locally Optimal Best Arm Identification with a Fixed Budget.\nFurthermore, it is known that algorithms would be significantly different between cases where variances are known and unknown [3]. When variances are unknown and need to be estimated, the probability of misidentification is significantly affected by the estimation error.\nWe categorize existing work as\nUnknown variance with asymptotic analysis.\nWe give an answer for this problem in a case with expected simple regret minimization.\nIn minimization of the probability of misidentification, it is still an open issue.\nUnknown variance with non-asymptotic analysis.\nKnown variance with asymptotic analysis\nWhen $K=2$, optimal algorithms are known.\nWhen $K\\geq 3$, there are several conjectures, but it is still an open issue.\nKnown variance with asymptotic analysis.\nNote that optimality in fixed-budget BAI itself is an open issue [8]. If [1] is optimal, we conjecture that it is optimal in case 4. However, it is still unsolved.\n[8] Qin, C. Open problem: Optimal best arm identification with fixed-budget, 2022.\nOur study was conducted independently of [1]. We will clarify it to the meta-reviewer.\nWe recognize [1]'s contributions, especially in incorporating variances into the successive halving algorithm. However, theoretical gaps and limited comparative analysis in [1] pose challenges. While we can incorporate these points into our manuscript, a detailed analysis of [1] is beyond our scope; we referenced it as a recent study."}, {"Heading": "Re2: Official Review of Submission9273 by Reviewer qfgN", "Subheading": "Official CommentbyAuthors17 Nov 2023, 18:42 (modified: 17 Nov 2023, 18:56)EveryoneRevisions", "Content": "Comment:\nWe then reply to each question raised by the reviewer as follows. We also thank you for pointing out typos. We will fix them in the next update.\nQ1\n.\nComparison with [1]\nA1\n. \nIn addition to the points raised by us in the previous post, there are the following differences between our study and their study.\nObjective function: While we minimize the expected simple regret, [1] minimizes the probability of misidentification. Although the evaluation of the probability of misidentification has several open issues, as raised by [8], we can still address the minimization of the expected simple regret as well as [9] and [10].\nContribution: We do not think that the proposition of variance-dependent algorithms itself is a strong contribution because there are several existing works. Our contribution lies in the proposition of a variance-dependent algorithm with lower bounds.\nIncorporation of contextual information as a generalization of BAI without contextual information.\nWe will not add the contents in the previous post because they are still our conjectures and open issues. Instead, we mention the above differences in the next update in this rebuttal phase.\n[9] Bubeck, S., Munos, R., and Stoltz, G. Pure exploration in finitely-armed and continuous-armed bandits, 2011.\n[10] Komiyama, J., Ariu, K., Kato, M., and Qin, C. Rate-optimal bayesian simple regret in best arm identification, 2023.\nQ2\n.\nWhy $E^X[\\frac{(\\sigma^1(X))^2}{w(1|X)}+\\frac{(\\sigma^2(X))^2}{w(2|X)}]\\geq\\max_{a\\in[2]}\\sqrt{E^X[\\frac{(\\sigma^a(X))^2}{w(a|X)}}]$?\nA2\n. \nThis is our typo. Thank you for pointing it out. It should be $\\inf_w E^X[\\frac{(\\sigma^1(X))^2}{w(1|X)}+\\frac{(\\sigma^2(X))^2}{w(2|X)}]\\geq \\inf_w  \\max_{a\\in[2]}\\sqrt{E^X[\\frac{(\\sigma^a(X))^2}{w(a|X)}}]$; that is, the optimization for $w$ is lacked.\nQ3\n.\nFrom my understanding, in [2], the forced exploration is a design of the algorithm. And in [3], $\\beta$ is also a hyper parameter (thus, a design) of the algorithm. But here $\\underline{C}$ is an assumption on the problem instance.\nA3\n.\nWe can interpret that $\\beta$ is an assumption on the problem instance, while $\\underline{C}$ can be interpreted as a hyperparameter. When showing the optimality in the top two algorithms, we need to assume that $\\beta$ matches the allocation ratio of the best arm, which means that we need to make an assumption between $\\beta$ and the problem instance (allocation ratio depends on the problem instance). In contrast, when we consider that $\\underline{C}$ is a hyperparameter, we remove the assumption about $\\underline{C}$ from the definition of bandit models and put assumptions in deriving the upper bound.\nRegarding an assumption of $\\underline{C}$, it is also used to define the KL divergence in the top two algorithms. If $\\underline{C} = 0$, we cannot appropriately define the KL divergence, which is needed in various parts of the top two algorithms.\nQ4\n.\nGiven that the optimal allocation is known, is it possible to adopt a tracking sampling rule, i.e., sampling the arms in a way such that the empirical arm allocation approaches the optimal allocation.\nA4\n. \nIf the optimal allocation is known, we just assign each arm with the ratio without adaptive exploration when there is no contextual information; that is, we assign first $\\lceil Tw^*(1)\\rceil$ observations to arm $1$,..., and $\\lceil Tw^*(K)\\rceil$ observations to arm $K$. When contextual information is available, there are several ways for arm draws. For example, we can draw arms as well as Hahn et al. (2011).\nQ5\n.\nfor the Sequential Halving-based algorithm, how to compute the simple regret of the arm at each $t\\in { 1000,\\dots,50000 }$?\nA5\n.\nThank you for your suggestion. As you pointed out, we conducted a new independent trial for the Sequential Halving-based algorithm for each $t$. We clarify this point in the next update.\nQ6\n.\nAnd it would also be interesting to see how SHAdaVar behaves without contextual information.\nA6\n. \nWe will add the experiments. If possible, we will update the manuscript, including the new experiments, during the rebuttal phase. Otherwise, we will add them when they are camera-ready.\nQ7\n.\nfor the other algorithms, how you incorporate contextual information in the original algorithm.\nA7\n.\nIn the experiments in the Appendix, we only use contextual information for our proposed algorithm. For fairness, we do not use contextual information both for our proposed and existing algorithms in the experiments of the main text. We clarify these points in the next revision. Note again that the proposition of contextual BAI algorithm is also our contribution, and to the best of our knowledge, there is no appropriate competitors that use contextual information."}, {"Heading": "Official Comment by Reviewer qfgN", "Subheading": "Official CommentbyReviewer qfgN20 Nov 2023, 02:05Everyone", "Content": "Comment:\nThanks a lot for your detailed response and most of my concerns have been properly addressed!\nIn terms of the second question in my initial review:\nGiven that the optimal allocation is known, is it possible to adopt a tracking sampling rule, i.e., sampling the arms in a way such that the empirical arm allocation approaches the optimal allocation. As indicated by section 2.3 in [4], sampling according to a distribution can make the convergence speed slow. Can you give comments on the allocation rule?\nlet me clarify my question: here the ``optimal allocation'' refers to the computed allocation based on the empirical estimates, e.g., the empirical variances. In Algorithm AS-AIPW, it samples an arm according to the empirical optimal allocation. According to [4], sampling according to a distribution can have slow convergence speed. Therefore, is it possible or better to use a tracking-type sampling rule, which samples the arm $ A_t = \\arg\\min_{a} T_t(a|X_t)-t \\hat{w}_t(a|X_t)$ (where $T_t(a|X_t)$ is the number of times arm $a$ is sampled under $X_t$ up to time step $t$)?\nHope this clarifies and can you please comment on this?"}, {"Heading": "Re: Official Comment by Reviewer qfgN", "Subheading": "Official CommentbyAuthors20 Nov 2023, 15:26 (modified: 20 Nov 2023, 17:35)EveryoneRevisions", "Content": "Comment:\nWe sincerely appreciate your feedback, and thank you for clarifying your second question.\nQ\n.\nhere the ``optimal allocation'' refers to the computed allocation based on the empirical estimates ... Therefore, is it possible or better to use a tracking-type sampling rule, which samples the arm $A_t = \\arg\\min_{a} T_t(a|X_t)-t \\hat{w}_t(a|X_t)$ (where $T_t(a|X_t)$ is the number of times arm $a$ is sampled under $X_t$ up to time step $t$)?\nA\n. \nThank you for your suggestion. We conjecture that it works. However, the derivation of the upper bound requires more high-level techniques. We explain the background of the AIPW estimator as follows.\nFor simplicity, assume that there is no contextual information. Recall that the AIPW estimator: $\\hat{\\mu}^{AIPW, a}_T$ is given as\n$$\\frac{1}{T}\\sum_t\\Big(\\frac{1[A_t = a](Y_t - \\hat{\\mu}^a_{t-1})}{w_t(a)} +  \\hat{\\mu}^a_{t-1}\\Big).$$\nHere, our proof is based on the martingale property, depending on $\\mathbb{E}[1[A_t = a] | \\mathcal{F}_{t-1}] = w_t(a)$.\nIf we apply the tracking-based algorithm, we need to reconsider the definition of the AIPW estimator. Depending on the definition, there are some technical issues. For example, consider using the same definition of the AIPW estimator in the main text. Then, $w_t$ is an estimator of the optimal allocation, and $A_t$ is an actual arm draw. Then, $\\mathbb{E}[1[A_t = a] | \\mathcal{F}_{t-1}] = w_t(a)$ does not hold. Therefore, we cannot employ the martingale property.\nHowever, we consider that there is a possibility that we can show the same property between the AIPW estimator with random sampling in our manuscript and tracking-based sampling in your proposition. To derive an upper bound of the AIPW estimator using the  tracking-based sampling, we can consider the following decomposition:\n$$ \\hat{\\mu}^{AIPW, a}_T = \\hat{\\mu}^{AIPW, a}_T - \\tilde{\\mu}^{AIPW, a}_T +\\tilde{\\mu}^{AIPW, a}_T,$$ \nwhere we define $\\tilde{\\mu}^{AIPW, a}_T$ as\n$$\\frac{1}{T}\\sum_t\\Big(\\frac{1[B_t = a](Y_t - \\hat{\\mu}^a_{t-1})}{w_t(a)} +  \\hat{\\mu}^a_{t-1}\\Big),$$\nand define $B_t \\in [K]$ as a hypothetical arm assignment indicator when an arm is drawn following the probability $w_t$. Then, we aim to show\n$$ \\hat{\\mu}^{AIPW, a}_T - \\tilde{\\mu}^{AIPW, a}_T = o_P(1/\\sqrt{T})$$\nand apply the martingale central limit theorem for $\\tilde{\\mu}^{AIPW, a}\nT$, where $\\mathbb{E}[1[B_t = a] | \\mathcal{F}\n{t-1}] = w_t(a)$.\nThe above conjecture is based on the existing work, such as [1] and [2].\n[1] Hahn, J., Hirano, K., and Karlan, D. Adaptive experimental design using the propensity score, 2011.\n[2] Kato, M., Adaptive Doubly Robust Estimator from Non-stationary Logging Policy under a Convergence of Average Probability, 2021.\nHowever, to conduct the proof procedure we mentioned above, there are several restrictions. For example, [1] only considers a two-stage adaptive experiment, where we draw each arm with the equal ratio in the first stage and draw each arm to track the empirical optimal allocation ratio. Here, we cannot update $w_t$ in the second stage; that is, we can update the sampling rule $A_t$ only once between the first and second experiments. [2] makes complicated assumptions that are not easily verified. Showing the upper bound under the tracking-based algorithm without restricting the sampling rules or making additional assumptions is an open issue.\nAccording to [4], sampling according to a distribution can have slow convergence speed.\nWe agree with your points. On the other hand, we raise the following three points:\nAlthough the sample average of $A_t$ will converge with a faster speed, we may not construct an unbiased estimator for $\\mu^a(P)$. Therefore, there might be a trade-off between the convergence of $A_t$ and the bias of an estimator of $\\mu^a(P)$.\nWe can show that our proposed AS-AIPW strategy and that with the sampling rule, we mentioned in the previous post (that is, we assign first $\\lceil Tw^*(1)\\rceil$ observations to arm $1$,..., and $\\lceil Tw^*(K)\\rceil$ observations to arm $K$). have the same asymptotic distribution. From this result, we conjecture that the AS-AIPW estimator with the tracking-based algorithm also has the same distribution if it can be shown.\nExisting studies (e.g., [1] and [3]) imply that we can conduct theoretical analysis for the AS-AIPW estimator with random sampling more easily than with the tracking sampling, owing to the martingale property.\n[3] van der Laan, M. J. The construction and analysis of adaptive group sequential designs, 2008.\nIn summary, we agree with your point that tracking-based strategies will outperform random-sampling-based strategies. However, under such a strategy, we cannot employ the martingale property (= unbiasedness), which makes the theoretical analysis difficult. Revealing the theoretical properties of such an estimator is an open issue."}, {"Heading": "Official Comment by Reviewer qfgN", "Subheading": "Official CommentbyReviewer qfgN20 Nov 2023, 20:15Everyone", "Content": "Comment:\nGreat thanks for your detailed comment! Please consider organizing your above response and adding it to the appendix. It would be beneficial to the community. Thanks a lot!"}, {"Heading": "Re: Official Comment by Reviewer qfgN", "Subheading": "Official CommentbyAuthors22 Nov 2023, 15:11Everyone", "Content": "Comment:\nThank you for your constructive comments! We will add the open issues and related arguments raised in this rebuttal to the manuscript for the community. We have already added the points discussed in Appendix J.3 briefly. This is a provisional version and will be brushed up until camera-ready. We will reflect your comments as much as possible until the rebuttal is finished. If not in time, we will reflect them in camera-ready."}]}]}, "YItWKZci78": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "mean-field Langevin dynamics, minimax optimization, zero-sum games, Markov games", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "In this paper, we extend mean-field Langevin dynamics to minimax optimization over probability distributions for the first time with symmetric and provably convergent updates. We propose \\emph{mean-field Langevin averaged gradient} (MFL-AG), a single-loop algorithm that implements gradient descent ascent in the distribution spaces with a novel weighted averaging, and establish average-iterate convergence to the mixed Nash equilibrium. We also study both time and particle discretization regimes and prove a new uniform-in-time propagation of chaos result which accounts for the dependency of the particle interactions on all previous distributions. Furthermore, we propose \\emph{mean-field Langevin anchored best response} (MFL-ABR), a symmetric double-loop algorithm based on best response dynamics with linear last-iterate convergence. Finally, we study applications to zero-sum Markov games and conduct simulations demonstrating long-term optimality.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "optimization", "Submission Number": "9271", "PDF Url": "https://openreview.net/pdf?id=YItWKZci78"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (spotlight)"}, {"Heading": "Meta Review of Submission9271 by Area Chair GgNy", "Subheading": "Meta ReviewbyArea Chair GgNy03 Dec 2023, 22:54 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper introduces novel algorithms utilizing symmetric mean-field Langevin dynamics (MFLD) to address distributional minimax problems with convex-concave objectives. The authors offer a rigorous proof of convergence for two discrete MFLD algorithms, distinguished by single-loop and double-loop structures. The paper includes experimental validations affirming the proposed algorithms' convergence. The substantial contributions of this work are evident in both algorithmic design and theoretical analysis. All reviewers unanimously recommend acceptance. Congratulations on the excellent work!\nJustification For Why Not Higher Score:\nN/A\nJustification For Why Not Lower Score:\nThis paper is well written, with new algorithms proposed and strong theoretical convergence analyses provided."}, {"Heading": "Official Review of Submission9271 by Reviewer bLee", "Subheading": "Official ReviewbyReviewer bLee31 Oct 2023, 21:44 (modified: 20 Nov 2023, 13:04)EveryoneRevisions", "Content": "Summary:\nThe paper analyzes two approaches for simulating mean-field games, denoted by MFL-AG and MFL-ABR respectively.  The convergence of the algorithms (in idealized form, and finite particle form) is provided.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThis appears to be the first algorithm which achieves a convergence in time + propagation of chaos result for mean-field games under transparent assumptions.\nThe proofs are well-written and contain analytical insight into this problem. In particular there is clear intuition on how averaging helps to regularize this problem.\nBoth algorithms are realizable and seem to have reasonable performance in practice.\nWeaknesses:\nI have some issues with the Assumptions in the paper.\n    Firstly, the requirement of convexity combined with strictly bounded gradients is quite strict, as it essentially forces the problem to be roughly linear. I think this is a major restriction and the authors should do their best to circumvent this, or otherwise explain why this assumption was necessary in their opinion.\nSecondly, it is unclear to me why the authors prefer to use $L^1$ Lipschitz-ness and obtain their result in Wasserstein-1. Isn\u2019t it more natural to frame all results in W2, or was W1 chosen for a specific reason?\nThe dependencies on $N$ are worse when compared to standard mean-field results. The dependence on $\\eta$ in the first term is also not ideal. For instance uniform-in-time propagation of chaos for the mean-field Langevin dynamics would look like $k^2/N^2$ (in $W_2^2$ under mild assumptions).\nThe results in Figure 1 are decent, but it is difficult to have any scale for comparison. It seems as well from the $W_1$ convergence that there is some degree of persistent bias for the choice of parameters. I would recommend further experiments if the authors are interested in highlighting the empirical performance of their approach.\nIn summary, I think this is a useful first result in this setting. However, there are numerous ways that it could be improved and I have some important questions regarding the results. I would be willing to raise my score if some of my questions could be addressed in more detail.\nQuestions:\nIs it possible to write in this setting an analogue of the BBGKY hierarchy, and conduct the analysis that way? Would this at all sharpen the rates? It seems that under the convex-concavity assumption and bounded gradients assumptions at least, the analysis would be tractable using that approach.\nCould Figure 1 be moved to the main text? It is a core part of the contribution and should not be placed in the appendix.\nCould the dependency of $K$ on key problem parameters be clarified in the main text? It seems from the Appendices that it should be roughly $\\epsilon^2$. Additionally, it would be good to highlight dimension dependence, which appears to be fairly mild.\nWhy in Theorem 4.1 should $k$ be taken as $1/\\epsilon \\log \\epsilon$? Shouldn\u2019t $\\log 1/\\epsilon$ suffice?\nIn Lemma C.2, no need to refer to Gronwall\u2019s lemma (induction suffices).\nA definition of \u201cconvexity\u201d should be given in the Appendix. E.g. geodesic convexity in $W_2$, or convexity wrt TV distance.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 00:29 (modified: 20 Nov 2023, 02:50)EveryoneRevisions", "Content": "Comment:\nThank you for your through review and suggestions, and raising a number of important issues! We have updated the manuscript to clarify technical details and improve presentation. We hope our discussion can convince the reviewer of the technical difficulty and generality of our work.\nAddressing Weaknesses\nW1.\nThe functionals studied in even ordinary MFLD works (such as that for optimizing neural networks) are always convex; this is due to convexity of the loss function and an intended consequence of lifting to the space of measures, not due to simplicity of the underlying problem. Furthermore, minimax MFLD is often studied explicitly for bi-linear objectives, that is $\\mathcal{L}(\\mu,\\nu)=\\iint Q(x,y) d\\mu(x)d\\nu(y)$ where the underlying payoff $Q$ can be any nonconvex-nonconcave $C^1$ function. This covers all (2-player) zero-sum continuous games, which in turn generalizes all finite zero-sum games.\nIn fact,\nall\npreceding minimax MFLD works [1,2,3] only considered bi-linear $\\mathcal{L}$ (linear-convex in [4]), and even in this simple case it was unknown how to design a symmetric descent-ascent type algorithm until our paper. Hence, our work can actually be considered much more general.\nFurthermore, our assumptions in the gradient are implied by the assumptions on $Q$ in these works and are also generally considered weaker than sup norm control, which is also a common assumption in the MFLD literature. In fact, they are more relaxed compared to some works which require super-quadratic regularization or uniform boundedness of functional derivatives. (The works [1,2,3] avoid L2 regularization only because they impose the strong assumption that $\\mathcal{X,Y}$ are compact manifolds without boundary, which automatically ensures various isoperimetric inequalities.)\nWe agree that nonconvex MFLD is also of great interest, however extremely little is known for even the single-optimization case as of yet and should be considered as a separate direction of study.\nW2.\nIndeed, framing the result in $W_2$ as in [5] could be more natural. However unlike [5], for our dynamics we only have indirect control over the empirical-proximal distribution gap via Prop. 3.6, which yields a $W_1$ bound by Kantorovich duality when converting to a bound for the empirical measures. Our uniform LLN analysis (as opposed to entropy-based bounds) is a novel approach that allows us to overcome the challenges inherent in the extremely complex historically-dependent particle interactions. Please note that we have added a new section on bounding expected distance and curse of dimensionality (Appendix C.6); in this case, a stronger moment bound will allow strengthening to $W_2$.\nW3.\nThe worse rates arise from controlling the full history dependence, not minimax dynamics a priori. For the uniform LLN (Proposition 3.6) at least, the $O(1/\\sqrt{N})$ rate is optimal. The worst-case LLN error is determined by the change in Lipschitz constant of the function $F(\\mu_{\\mathscr{X}}, \\nu_{\\mathscr{X}})$ when each particle is removed, which in turn is tightly bounded by the leave-one-out $W_1$ error due to W1-Lipschitzity of $F(\\cdot,\\cdot)$. Since the leave-one-out $W_2^2$ error is $O(1/N)$, the LLN error must be $O(1/\\sqrt{N})$.\nSince we did not quite use the full power of the uniform LLN in subsequent analyses, however, it is possible that a different approach could circumvent this and achieve better rates as well as getting rid of the dependency on $\\eta$. Nevertheless, we emphasize this is the first history-dependent propagation of chaos result with explicit rates in any setting. The few existing results in the SPDE literature are asymptotic and do not provide error bounds [6].\nW4.\nThe persistent bias in convergence is an artifact stemming from Langevin noise of fixed temperature, as particles are perturbed and empirical $W_1$ distance between each step retains some ground energy even at equilibrium. This decreases in MFL-AG due to replacing only a fraction of the particles. From a mean-field perspective, however, the distributions have converged to a solution.\nWhile our paper is focused on the regularized problem, it is also possible to implement a temperature annealing schedule such as $\\lambda_t=\\Theta(1/\\log t)$ to find the MNE of the unregularized problem; for details, please see our response to Q3 of Reviewer q6kk. In this setting, the Langevin noise bias will gradually die down.\nPlease also see our responses to Q2 of Reviewer q6kk for justification of the 3-point error as a metric for optimality, and Q3 of Reviewer ByeN for further discussion of experimental settings and comparisons of the algorithms.\n(continued below)"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 00:30Everyone", "Content": "Comment:\n(continued)\nAddressing Questions\nKinetic dynamics.\nWhile not quite the same as BBGKY, a kinetic mean-field system has been considered in the context of machine learning optimization very recently in [7]. The studied underdamped MFLD corresponds to a momentum gradient descent, and exponential convergence and uniform-in-time propagation of chaos results are obtained. Although from an algorithmic perspective the use of momentum may potentially help to speed up the slow $O(1/t)$ rate of MFL-AG, it is unclear if the convergence rates (derived using entropic hypocoercivity) improves upon ordinary MFLD in general, and the propagation of chaos result requires some higher-order regularity assumptions. Adapting these techniques to deal with history dependence is also highly nontrivial (as was for ordinary MFLD for our paper). Nonetheless, applying kinetic MFLD to develop faster minimax algorithms is a very interesting and promising direction for future work.\nOther edits.\nWe are grateful for your various suggestions which helped to improve important points of the manuscript.\nThe dependency of $C_1$ on $\\eta$ mentioned after Theorem 3.7 means that in order to bound all 3 terms as $\\epsilon$, we need to take $\\eta=O(\\epsilon^2)$ which in turn roughly requires $K=O(\\epsilon^{-1-1/\\alpha})$ to assure $C_1/K<\\epsilon$. This has been clarified in the main text.\nIn Theorem 4.1, bounding discretization error (3rd term) requires $C\\beta<\\epsilon$ so that $k=\\frac{1}{\\epsilon}\\log\\frac{1}{\\epsilon}$ is needed to ensure the outer loop convergence $\\exp(-\\beta k)<\\epsilon$.\nThe Figure has been moved to the main text.\nDimension dependence only appears in the LSI constant as $\\alpha = O(d)$ due to Lipschitz perturbations, and can be averted entirely if we assume bounded perturbations by the Holley-Stroock argument. We have added this in the paper. Also, the definition of convexity has been added and Lemma C.2 has been reworded as per your suggestions.\n[1] Domingo-Enrich et al. A mean-field analysis of two-player zero-sum games. NeurIPS 2020.\n[2] Ma, Ying. Provably convergent quasistatic dynamics for mean-field two-player zero-sum games. ICLR 2022.\n[3] Lu. Two-scale gradient descent ascent dynamics finds mixed Nash equilibria of continuous games: A mean-field perspective. ICML 2023.\n[4] Conforti et al. Game on random environment, mean-field Langevin system and neural networks. 2020.\n[5] Suzuki et al. Mean-field Langevin dynamics: Time-space discretization, stochastic gradient, and variance reduction. NeurIPS 2023.\n[6] Wu et al. On a class of McKean-Vlasov stochastic functional differential equations with applications. 2023.\n[7] Chen et al. Uniform-in-time propagation of chaos for kinetic\nmean field Langevin dynamics. 2023."}, {"Heading": "Re: Response", "Subheading": "Official CommentbyReviewer bLee20 Nov 2023, 13:04Everyone", "Content": "Comment:\nI have read the authors response and agree with most of their points. The one issue for me in\nW1\nis to justify why strictly bounded gradients can be an interesting assumption, when compared with just Lipschitz gradients (which is more standard and covers the quadratic case). The authors addressed this somewhat but I would be keen to hear why this is a limiting assumption in practice.\nNonetheless, I feel like most of my other points have been addressed and I have raised my score correspondingly. I thank the authors for their prompt and thorough response."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 14:41 (modified: 20 Nov 2023, 21:15)EveryoneRevisions", "Content": "Comment:\nThank you for taking the time to consider our responses and raising your score! Your insightful comments and questions have helped greatly in improving our paper. Below, we discuss the gradient assumption in further detail. Recall (dropping the dependency on $\\nu$ for simplicity):\nAssumption 2.\n$\\nabla_x\\frac{\\delta\\mathcal{L}}{\\delta\\mu}(\\mu)(x)$ is uniformly bounded, and Lipschitz in $x,\\mu$.\nWe clarify that this is\nnot\na bound for the functional derivative $\\frac{\\delta\\mathcal{L}}{\\delta\\mu}$ itself, only a regularity condition, and $\\mathcal{L}$ could well be quadratic or higher order in $\\mu$. For example, supposing $\\mathcal{L}(\\mu) = \\iint f d\\mu^{\\otimes 2} = \\iint f(x,z)\\mu(dx)\\mu(dz)$ for some function $f$, we have that $\\nabla_x\\frac{\\delta\\mathcal{L}}{\\delta\\mu}(\\mu)(x) = \\int \\nabla_x f(x,z)\\mu(dz)+\\int \\nabla_x f(z,x)\\mu(dz)$, which is strictly bounded if $\\nabla f$ is bounded. Moreover, Lipschitzity in $x$ and $W_1$-metric Lipschitzity in $\\mu$ hold if $\\nabla f$ is Lipschitz. Hence the assumption is conceptually a restriction on the\nunderlying potential\n$f$, which is often well-behaved in practice.\nThis is even more apparent in the two-layer neural network setting, which is nowadays the central application of MFLD. Denoting a neuron with parameter $\\theta\\in\\Theta$ as $z\\mapsto h_\\theta(z)$, the mean-field network is $z\\mapsto\\int h_\\theta(z)\\mu(d\\theta)$ for a distribution $\\mu$ on the parameter space $\\Theta$. Given a convex loss function $\\ell(z,y)$, the training objective is then $\\mathcal{L}(\\mu)=\\mathbb{E}[\\ell(\\int h_\\theta(z)\\mu(d\\theta), y)]$. In this setting, Assumption 2 is verified if the derivative $\\partial_z\\ell$ of the loss is Lipschitz - this includes quadratic loss, logistic loss, etc. - and the neurons and their gradients are bounded, e.g. tanh activation. Moreover, for other applications such as MMD and KSD estimation, Assumption 2 is verified if the kernel is smooth and light-tailed such as the RBF kernel (see [5] above).\nOf course, bounded & smooth neurons are not ideal as ReLU does not satisfy both conditions. Clipping the output and smoothing near the origin are some ways to overcome this technicality, albeit with suboptimal results. The main point is that the\nloss function\n$\\ell$ can be very general. In addition, for zero-sum games the underlying potential is the\npayoff function\n$Q$ which is likely to be suitably regular in applications.\nWe reiterate that all current MFLD works require either this or a stronger assumption, and our technical settings mostly inherit from these single-optimization works. We put in much effort to develop the history-dependent propagation of chaos analysis with only Assumption 2, and indeed the proof of Theorem 3.7 is the most technically heavy result in our paper which could have been more simplified and optimized with stronger assumptions. However, our Assumption 3 for the MFL-ABR algorithm\ndoes\nunfortunately require boundedness of $\\frac{\\delta\\mathcal{L}}{\\delta\\mu}$ (which is implied by a bounded payoff in the bilinear case). This is inherited from the original mean-field best-response paper; we could not find a way to weaken the assumption while also performing the additional perturbation analyses. Nevertheless, improving on these types of assumptions is definitely an important challenge for mean-field theory in general."}]}, {"Heading": "Official Review of Submission9271 by Reviewer DQbp", "Subheading": "Official ReviewbyReviewer DQbp31 Oct 2023, 19:00 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper considers the solution of minmax problems with convex-concave objectives (plus entropic regularization terms) in the space of pairs of probability measures. Numerous problems can be viewed as particular cases of this.\nThere exists a natural Mckean-Vlasov type system of diffusions --  mean-field Langevin dynamics (MFLD) -- that should converge to the saddle point that solves the above problem. The paper shows such a result for a version of these diffusions where the drift term is averaged over past states. Moreover, particle approximations of the diffusions are shown to satisfy strong convergence rates: for instance, the approximation bounds are uniform in time.\nBounds for the authors' methods are given for \"Markov games\" assuming oracle access to certain functions and gradients related to the problem. A small simulation study suggests improved performance vis a vis MFLD.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n4 excellent\nStrengths:\nThe class of minmax optimization problems under consideration is quite natural. The result seems to be the first of its kind for this sort of problems. Similar results on convergence of McKean-Vlasov particle systems for convex optimization would be much easier to prove. The technical difficulties faced in the minimax scenario with the time averaging seem considerable.\nWeaknesses:\nThe assumptions over the two measures used in entropic regularization are quite strong. The result of Theorem 3.7 has an expectation inside $W_1$, which is somewhat hard to interpret: it would seem to be saying that the bias of the procedure is small, but not the variance, so many repetitions of the particle dynamics would be needed to estimate the expectation of some function $f$. The outer-loop particle discretization error is not accounted for in the algorithm from Section 4.\nI do not understand what is going on in Lemma C.7 (it might be because I do not understand $\\Pi$ fully -- see below).\nSome of the notation is unnecessarily hard to parse. Let me offer a few examples.\nPage 5:\nDenote ordered sets of $N$ particles\n-- it would seem that the authors mean a vector in $\\mathcal{X}^N$. Also on the same page: it seems that the authors introduce the subscript $1:k$ to identify particle positions at different times, but then don't use this notation consistently at the bottom of the page (and also elsewhere).\n$L_\\mu$ and $L_\\nu$ are used to denote Lipschitz constants in the first/second variable, but also, $L$ is the functional and $(\\mu,\\nu)$ are used to denoted arbitrary elements of the space of probability measures.\nThe definition of $\\Pi$ in page 6 as ``the average of the pushforward operators along the projections $X\\mapsto X^i$ does not seem correct. How can you project to a higher-dimensional space?\nQuestions:\n(Q1)\nAlgorithm 1 and elsewhere - rathen than sample subsets of $\\mathcal{X}_k,\\mathcal{Y}_k$, maybe you could just use a weighted empirical measure where set $\\mathcal{X}_k$ has weight proportional to $\\beta_k$?\n(Q2)\nCan you clarify what is $\\Pi$ and explain specifically the proof of Lemma C7?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 00:33 (modified: 17 Nov 2023, 23:39)EveryoneRevisions", "Content": "Comment:\nThank you for your positive feedback and detailed suggestions! We have updated the paper and clarified some important points accordingly.\nAddressing Weaknesses\nAssumptions.\nOur assumptions on the regularizer functions and functional $\\mathcal{L}$ are standard in the mean-field literature, corresponding to L2 regularization in the case of two-layer neural networks [1,2]. In fact, they are more relaxed compared to some works which require super-quadratic growth of regularizers [3] or uniform boundedness of functional derivatives [4]. Lu and Domingo-Enrich's works do not have an L2 regularizer only due to the fact that they impose the strong assumptions that $\\mathcal{X,Y}$ are\ncompact manifolds with Ricci curvature lower bounded\n, which also guarantees an LSI constant.\nOuter loop.\nPlease see our discussion with Reviewer q6kk on the outer loop discretization issue.\nExpectation.\nThe expectation inside $W_1$ is purely due to the following fundamental fact: the expected Wasserstein distance between any $d$-dimensional distribution and a size $N$ sample is $O(N^{-1/d})$, so any attempt to directly control distance of $\\widehat{\\mu}$ to $\\mu^*$ will immediately incur the curse of dimensionality even if $\\widehat{\\mu}$ is perfectly i.i.d. sampled from the true distribution. We thus carefully designed our approach to completely avoid this dependency. Nonetheless, if the expectation is outside we can still obtain a similar bound save for the CoD. We have added a new section (Appendix C.6) which discusses the effect of CoD and develops corresponding results and proofs.\nOf course, as you mentioned in practice we may also simply run the algorithm multiple ($M$) times and take the average of the outputs, which would also bypass the issue and yield the standard $1/\\sqrt{M}$ convergence.\nNotation.\nThe notation has been updated. The notation $(\\mathscr{X},\\mathscr{Y})_{1:k}$ has been changed to $(\\mathscr{X}_{1:k},\\mathscr{Y}_{1:k})$ in the main text and reintroduced in the appendix. The functional has been changed from $L$ to $\\mathcal{L}$, and the use of $\\mu,\\nu$ in sub/superscripts to denote problem quantities has been clarified on the first page.\nAddressing Questions\nQ1.\nIt is indeed possible to weighted-concatenate the particles instead of random sampling in both Algorithm 1 and the outer loop of Algorithm 2. Since our discretization guarantee for MFL-AG is written in terms of expected distribution, it applies to both methods, and concatenation may help stabilize the output.\nThe main issue is that the number of total particles $NK$ will then grow proportionally with the number of epochs $K$, so that with a per-epoch memory/compute constraint $C$ the user may have to set a smaller $N=O(C/K)$ to begin with. Whereas with random sampling the two algorithms only require 4 arrays of length $N=O(C)$ (as discussed in Section 5.1), so it is hard to say which is superior.\nIf particle weighting is allowed, another natural consideration is to update the masses themselves and study the resulting discrete Wasserstein-Fisher-Rao gradient dynamics, which is an interesting direction for future work.\nQ2.\nWe apologize for our mistake - the projection is supposed to be $\\mathscr{X}\\mapsto X^i$, that is the projection of the $N$-particle vector to its $i$th coordinate (averaged over all $i$). The corresponding pullback operator on functions is $\\Pi^* f(\\mathscr{X})=\\frac{1}{N}\\sum_{i=1}^N f(X^i)$. An explicit definition is given at the beginning of Appendix C.2. We hope this clarifies the role of Lemma C.7 as well.\n[1] Chen et al. Uniform-in-time propagation of chaos for mean\nfield Langevin dynamics. 2022.\n[2] Mei et al. Mean-field theory of two-layers neural networks: dimension-free bounds and kernel limit. CoLT 2019.\n[3] Suzuki et al. Uniform-in-time propagation of chaos for the mean-field gradient Langevin dynamics. ICLR 2023.\n[4] Lascu et al. Entropic mean-field min-max problems via Best Response and Fisher-Rao flows. 2023."}]}, {"Heading": "Official Review of Submission9271 by Reviewer ByeN", "Subheading": "Official ReviewbyReviewer ByeN28 Oct 2023, 02:45 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents an approach to minimize optimization over probability distributions by extending the principles of mean-field Langevin dynamics. They propose two methods: (MFL-AG),  a single-loop algorithm designed to achieve convergence towards the mixed Nash equilibrium, and (MFL-ABR), a two-loop algorithm that demonstrates linear convergence in the outer loop. Furthermore, they also investigate various discretization methods and offer a fresh analysis of how chaos spreads, taking into account its dependencies on past distributions. This research paves the way for more in-depth investigations into mean-field dynamics for numerous learning agents.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThe paper's contributions are supported by theoretical proofs\nIt seems that the convergence of mean-field Langevin dynamics was still an open problem and the problem of this paper is well defined.\nWeaknesses:\nProposed methods could be well motivated. The two proposed methods themselves are convincing. However, is there any reasons or motivation why you have both methods at the same time: mean-field Langevin averaged gradient and mean-field Langevin anchored the best response? Any explicit relationship between these two settings?\nThe description of the equation can be more comprehensive. Usually, we should describe all the notations of the equation at least right after it. For example, you do not mention what $\\rho^{\\mu}$ and $\\rho^{\\nu}$ are in equation 1.\nQuestions:\nCould you please explain more about what \"SYMMETRIC\" means in your proposed method and title? Is it mainly from the same temperature or regularization strength $\\lambda$ for both players?\nThen how compatible your proposed method and proof can be extended to when there exists $\\lambda_1$ and $\\lambda_2$ for two players respectively? Since you mentioned that the problems you are looking for naturally arise for example solving robust learning or zero-sum games in reinforcement learning. Usually, in the robustness via adversarial learning, the regularization strength is relevant to the strength of the adversary. For example, if the adversary is attacked on soft actor-critic (SAC)[1], which originally had its regularization term (temperature), then it is not flexible to have the regularization terms for the target agent and the adversary the same values.\nCould you analyze why MFL-AG can have a lower NI error compared with MFL-ABR and does it mean that MFL-AG performs better than MFL-ABR in this experiment? Furthermore, please suggest what kind of numerical experiment is more suitable with MFL-ABR against MFL-AG, and vice versa.\n[1] Haarnoja, T., Zhou, A., Abbeel, P., and Levine, S. Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor. In International Conference on Machine Learning (ICML), 2018\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 00:34Everyone", "Content": "Comment:\nThank you for your helpful advice and comments! We are very grateful for your through review, and various parts of the manuscript have been clarified or updated to improve presentation.\nAddressing Weaknesses\nW1.\nIdeally in this line of research we ultimately want a single-loop Langevin algorithm with provable last-iterate convergence, however both MFL-AG and MFL-ABR only fulfill halves of this role. Hence we have chosen to present & compare both possibilities even though their philosophies are different: MFL-AG realizes fictitious play (optimizing based on historical behavior of the opponent) while MFL-ABR realizes best response (optimizing based on current behavior). The modes of convergence (average-iterate $O(1/t)$ convergence v.s. last-iterate exponential convergence in the outer loop) also provides a contrast between the two Langevin algorithms.\nW2.\nThank you for your suggestions. The description of Equation 1 and other potentially confusing notational issues have been fixed.\nAddressing Questions\nQ1.\nSymmetry means that both $\\mu,\\nu$ have same learning rates (flow speeds). Until our paper, existing minimax MFLD results only studied imbalanced flows, that is $\\partial_t\\mu_t = (\\text{equation for }\\mu_t)$ and $\\partial_t\\nu_t = \\eta\\times(\\text{equation for }\\nu_t)$ for very large $\\eta$ [1] or the static limit $\\eta\\to\\infty$ [2]. In such regimes $\\nu$ can be considered already nearly optimized for any $\\mu$ and the difficulty of controlling two coupled flows are mostly removed. However, needless to say the setting is quite artificial. Symmetric updates are much more difficult to analyze and do not converge in general for even simple problems such as minmax$(x^\\top y)$ for $x,y\\in\\mathbb{R}^d$ [3].\nQ2.\nOur method easily extends to different regularization strengths $\\lambda_\\mu,\\lambda_\\nu$ with minimal modifications on the derivations and bounds (this has been added to the first page footnote). Intuitively, the regularizations take place in their respective spaces $\\mathcal{X}$ and $\\mathcal{Y}$ so there is no need for the strength parameters to be equal. We only took equal $\\lambda$ for simplicity and to adhere to preceding works.\nQ3.\nMFL-AG indeed performed better than MFL-ABR in this particular experiment, however we found empirically that this generally depended on the choice of hyperparameters. For example, speeding up the inner loop of MFL-ABR by decreasing iterations and increasing $\\eta$, or speeding up the outer loop by increasing $\\beta$ could accelerate convergence of MFL-ABR, but also led to instability in some runs. In contrast, MFL-AG always exhibited a \"slow but steady\" $O(1/t)$ convergence.\nIn addition, MFL-ABR and MFL-DA performed better for problems where $Q(x,y)$ factored into a sum (or product) of separate potentials for $x,y$. In this case the dynamics decouples into two single-optimization problems which are known to converge exponentially. In contrast, MFL-AG was preferable for potentials with complex interactions between $x,y$. For example for the sigmoid potential in Section 6, $\\mu$ pulls $\\nu$ toward itself while $\\nu$ pushes away, leading to a more complicated interacting dynamics that is better solved by the more stable MFL-AG.\n[1] Lu. Two-scale gradient descent ascent dynamics finds mixed Nash equilibria of\ncontinuous games: A mean-field perspective. ICML 2023.\n[2] Ma, Ying. Provably convergent quasistatic dynamics for mean-field two-player zero-sum games. ICLR 2022.\n[3] Daskalakis, Panageas. Last-iterate convergence: zero-sum games and constrained min-max optimization. Innovations in Theoretical Computer Science, 2019."}, {"Heading": "Official Comment by Reviewer ByeN", "Subheading": "Official CommentbyReviewer ByeN21 Nov 2023, 22:47Everyone", "Content": "Comment:\nThank you for all your detailed clarifications, which make this manuscript much clearer. I do not have any further questions, and I will keep my original score."}]}, {"Heading": "Official Review of Submission9271 by Reviewer q6kk", "Subheading": "Official ReviewbyReviewer q6kk25 Oct 2023, 06:52 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper studied the mean-field minimax theorem with entropic regularization. The contributions can be summarized as follows:\nThe authors proposed the MFL-AG algorithm, which convergence polynomially in continuous time. The author also proposed a discretized algorithm with a uniform-in-time propagation of chaos.\nThe authors proposed the MFL-ABR algorithm and provided a convergence rate for the discrete outer loop.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe proposed MFL-AG dynamic is new in the literature, and the weighted average of the dynamic provably converges to the MNE polynomially in time.\nThe authors provide a uniform-in-time propagation of chaos for a finite-particle implementation of the MFL-AG flow. Despite I have a few questions on the utility of the results, I believe the techniques based on Chen et.al 2022 are novel in mean-field minimax problem literature, and could potentially benefit future works.\nThe proposed MFL-ABR flow provides a potential way to find a discrete finite-particle algorithm for the best-response dynamics in mean-field min-max problem settings.\nWeaknesses:\nRegarding the MFL-AG\n:\nThe utility of the finite particle analysis in section 3.3 is not very clear to me. I have the following questions:\n1.1 In Theorem 3.7, you bound the Wasserstein distance  $ W_1( {E}[ \\mu_{ \\overline{\\mathscr{X}}_k } ], \\mu_* )$. However, I didn't see why it is useful to consider ${E}[ \\mu_{ \\overline{\\mathscr{X}}_k } ]$ since ${E}[ \\mu_{ \\overline{\\mathscr{X}}_k } ]$ is basically the average of the pushforward of joint measures to each particle, what does the convergence of this measure to MNE implies? To my understanding, the propagation of chaos refers to that the particles behave almost i.i.d, how does this convergence results imply the particles are almost i.i.d ? Thus, it makes more sense to me to consider  $ W_1 ( \\mu_{ \\overline{\\mathscr{X}}_k }, \\mu_*)  $ for example.\n1.2 Cont'd: you mentioned in the footnote on page 6 that the typical rate Wasserstein distance between a measure and\ni.i.d\nsampled empirical measure is $N^{-1/d}$. In this case, it seems that the particles in $ \\mu_{ \\overline{\\mathscr{X}}_k}$ are highly correlated since the dynamics are coupled. The correlation is not only between the particles in $ \\overline{\\mathscr{X}}_k$ for a fixed $k$, but also between particles in different times (i.e.$ \\overline{\\mathscr{X}}_k$ and $ \\overline{\\mathscr{X}}_j$ for $j \\neq k$ ). Thus, it is unclear to me what is the convergence rate of $W_1(\\mu_{ \\overline{\\mathscr{X}}_k},   \\mathbb{E} [ \\mu_{ \\overline{\\mathscr{X}}_k} ] )$?\n1.3 The discussion on top of page 7 is not very clear to me. First of all, you say you expand around $\\mu, \\hat{\\nu} $, but the first order condition in (3) is only for MNE, i.e. it is not clear to me why $ \\frac{\\delta }{\\delta \\mu} \\mathcal{L}_\\lambda(\\mu, \\hat{\\nu}) =  \\frac{\\delta }{\\delta \\hat{\\nu}} \\mathcal{L}_\\lambda(\\mu, \\hat{\\nu}) = 0$ for an arbitrary $\\mu$. Do you mean you expand around $  \\mu_*, \\nu_*$? Also, it is unclear to me why one can ignore the higher-order terms. Thus, currently, I don't understand how the upper bound on $W_1$ implies an upper bound on $NI$ error. In fact, since the $NI$ error upper bound the KL-divergence, and the KL-divergence upper bound $W_1$, I doubt the correctness of that the $NI$ error can be upper bounded by the sum of $W_1$ in general.\n1.4 Cont'd: in the case where $\\mathcal{L}$ is bilinear and assumes good regularity (e.g. the kernel is uniformly bounded), is that possible to upper bound  $NI( \\mathbb{E}[ \\mu_{ \\overline{\\mathscr{X}}_k } ], \\mathbb{E}[\\nu_{ \\overline{\\mathscr{Y}}_k } ])$ by the sum of $W_1$ in the propagation of chaos results?\n1.5 Cont'd: I suggest making the discussions on top of page 7 more formal and rigorous. The current ambiguous discussion makes it hard to understand the utility of the propagation of chaos results.\nRegarding the MFL-ABR\nThe utility of the results in section 4 is also not very clear to me, I have the following questions:\n2.1 It's not very clear to me why algorithm 2 works. Since in each round, one should input $\\mu_k, \\nu_k$ which comes from the outer iteration, while in algorithm 2, input $\\mu_{\\mathscr{X}_k}, \\nu_{\\mathscr{Y}_k} $ which are empirical measures. Due to the lack of propagation of chaos results, it is not clear to me that $\\mu_{\\mathscr{X}_k}, \\nu_{\\mathscr{Y}_k} $ will converge to $\\mu_k, \\nu_k $.\n2.2 Theorem 4.1 analyzes the convergence of the discretized version of MFL-ABR. However, compared to the results in Lascu et al. (2023), it seems to me that there are two drawbacks due to the inner Langevin dynamics: (1) There's a non-vanishing error $C \\beta$, so one has to make $\\beta$ small which in turn will make the convergence rate small. (2) The convergence rate of inner Langevin dynamics depends on the LSI, in the case of small $\\lambda$, the convergence rate can be small.  These two drawbacks might limit the utility of the MFL-ABR algorithm.\nQuestions:\nPlease also refer to the strengths and weaknesses part.\nIn Chen et al. (2022), they provide a propagation of chaos in KL-divergence, under extra regularity assumptions (see Theorem 2.4 in Chen et al. (2022) ). In this paper's settings, do you expect a similar propagation of chaos in KL divergence? Also, the propagation of chaos in Chen et al. 2022 provides a $O(1/N)$ error, which is optimal in order of $N$. Is it possible to improve the bounds to  $O(1/N)$ or is there any lower bound on the convergence rate (of propagation of chaos)?\nIn the numerical experiments, you use a 3-point NI error to approximate NI error, what's the justification for this? Since in principle for given $\\mu_{\\mathscr{X}^i}$, one should compute $\\arg\\max_{\\nu} L_{\\lambda}(\\mu_{\\mathscr{X}^i}, \\nu )  $ , it could be that $ \\nu_{\\mathscr{Y}^j}$ are far from $\\arg\\max_{\\nu} L_{\\lambda}(\\mu_{\\mathscr{X}^i}, \\nu ) $. Besides, for fixed $\\mu_{\\mathscr{X}^i} $, to compute $\\arg\\max_{\\nu} L_{\\lambda}(\\mu_{\\mathscr{X}^i}, \\nu )  $, can't one directly run a mean-field Langevin dynamics for example?\n3 . Is it possible to apply the annealing techniques in Lu (2022) to achieve the MNE of the unregularized object (assume there is)?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNone\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 00:38 (modified: 17 Nov 2023, 00:49)EveryoneRevisions", "Content": "Comment:\nWe are extremely grateful for your detailed review of the various analyses and in-depth suggestions! We have updated and clarified various important points in the manuscript. We hope our discussion can convince the reviewer of the technical novelty and complexity of our overall theory as well as the utility of the results.\nAddressing Weaknesses\n1.1-2.\n$\\mathbb{E}[\\mu_{\\overline{\\mathscr{X}}_k}]$ is the expected output of MFL-AG, hence Theorem 3.7 quantifies a sort of bias. While this does not provide the full picture, we put the expectation inside $W_1$ and carefully designed our approach (using uniform LLN, short-term perturbation, etc) to bypass the curse of dimensionality. We mentioned the i.i.d. sample bound simply to illustrate that the CoD is unavoidable for $W_1(\\mu_{\\mathscr{X}_k}, \\mathbb{E}[\\mu_{\\mathscr{X}_k}])$ or $W_1(\\mu_{\\mathscr{X}_k}, \\mu^*)$ even in the ideal situation (no chaos) where the particles are perfectly independently sampled from the true distribution.\nNonetheless, we see the utility in obtaining a bound for $W_1(\\mu_{\\mathscr{X}_k}, \\mu^*)$. Thus, we have added a completely new section which fleshes out the above discussion and develops similar bounds for $W_1(\\mu_{\\mathscr{X}_k}, \\mu^*)$ to Theorem 3.7 save for the CoD, which is unavoidable in the weakly interacting setting of propagation of chaos. Please see Appendix C.6.\nOf course, in practice we may also simply run the algorithm multiple ($M$) times and take the average of the outputs, which would also bypass the issue and yield the standard $1/\\sqrt{M}$ convergence.\nWe also remark that while the statement of Theorem 3.7 does not directly imply i.i.d. behavior of particles, the philosophy of propagation of chaos plays a key role in the proof. For example when developing the uniform law of large numbers we consider the system as a perturbed version of the gradient-stopped process, whose particles are independent when conditioned on the history up to a certain point in time. Hence, we emphasize the utility of our results lies not only in Theorem 3.7 but also the novel perturbation analysis developed throughout Appendix C.\n1.3-5.\nThank you for your astute observations. The upper bound does not hold in general; the sketched idea only works for the\nunregularized\nNI error (without KL terms), which we have not considered in the paper. At present, there seems to be no clean way to bound entropic terms (KL, NI) regarding $\\mathbb{E[\\mu_{\\mathscr{X}_k}]}, \\mathbb{E[\\nu_{\\mathscr{Y}_k}]}$. We apologize for the mistake, and the claims have been deleted as discussing unregularized error will be too confusing. (Propagation of chaos is often presented in terms of Wasserstein distance throughout the literature. We merely wanted to strengthen the remark that the squared distance $W_1^2$ (and not $W_1$) is a natural unit of measurement on the left-hand side of Theorem 3.7 in view of Talagrand's and sandwich inequalities.)\n2.1.\nIn general, one does not know $\\mu_{\\mathscr{X}_k}$ will converge to $\\mu_k$ a priori since error can accumulate as training progresses, and instead directly proves convergence to $\\mu^*$ (which then also implies $\\mu_{\\mathscr{X}_k}$ and $\\mu_k$ are close). For each outer loop anchor $\\mu_{\\mathscr{X}_k}, \\nu_{\\mathscr{Y}_k}$ the propagation of chaos for the inner loop is guaranteed by [1] since the dynamics decouples into single optimization; the laws of each of the inner loop particles converge to the Gibbs proximal distributions of the anchors. Then intuitively we expect the Lyapunov function proof in Section D.2 to apply to $\\mu_{\\mathscr{X}_k}, \\nu_{\\mathscr{Y}_k}$ plus a $O(1/N)$ error (without the need to appeal to $\\mu_k,\\nu_k$). In particular, the outer loop random sampling update satisfies on average $\\mathbb{E}[\\mu_{\\mathscr{X}_{k+1}}] = \\beta\\cdot\\mathbb{E}[\\mu_{\\mathscr{X}_k}]+(1-\\beta)\\mathbb{E}[\\widehat{\\mu}_{\\mathscr{X}_k}]+O(e^{-\\Omega(\\tau)}+\\eta)$, which is identical to the mean-field best response update plus the inner loop error.\nThe reason we did not complete the proof is that in order to make the above argument rigorous, the $N$-particle joint distribution must also behave roughly like an independent sample from the average $\\mathbb{E}[\\mu_{\\mathscr{X}_k}]$ (like the uniform LLN for MFL-AG). However, we found quantifying this difficult due to the combinatorically complicated effect of random sampling & replacing on the joint distribution. Since this issue is unrelated to Langevin dynamics, and also since there are other methods to perform the update (such as that suggested by Reviewer DQbp), we decided to not spend too much time on the issue.\n(continued)"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 00:41Everyone", "Content": "Comment:\n(continued)\n2.2.\n(1) We view the $C\\beta$ time discretization error as a natural consequence of turning a continuous flow into a realizable algorithm rather than a drawback; the same can be said for any gradient descent algorithm with fixed learning rate. However it should be possible to implement a learning rate annealing for $\\beta$ as $1/\\log t$ to avoid this error.\n(2) Indeed, the potential adverse dependency on $\\lambda$ is a problem that plagues all MFLD-based algorithms. In our response to Q3, we discuss how $\\lambda_k=O(1/\\log k)$ temperature annealing can overcome this issue. In addition, for certain classification problems where $\\lVert\\delta\\mathcal{L}/\\delta\\mu\\rVert_\\infty$ can be bounded by $\\mathcal{L}$, a faster exponential annealing of $\\lambda_k$ can be implemented so that the convergence rate is independent of $\\lambda_k$. [2]\nAddressing Questions\nQ1.\nProving propagation of chaos in KL divergence would be ideal; this is the approach taken in [1] as well, and is much more direct and simpler. We tried to emulate this framework at first, but quickly found out key concepts such as their $N$-particle proximal distribution cannot be applied. This is due to the dependence on the entire history and cannot be fixed by adding stronger assumptions. Thus we had to resort to more technically involved methods (uniform LLN, short-time perturbation analysis) leading to our $W_1$ result. While morally there seems to be no reason why the result would not hold in KL, our current tools are not enough to guarantee this.\nFor the uniform LLN (Proposition 3.6) at least, the $O(1/\\sqrt{N})$ rate is optimal. The worst-case LLN error is determined by the change in Lipschitz constant of the function $F(\\mu_{\\mathscr{X}}, \\nu_{\\mathscr{X}})$ when each particle is removed, which in turn is tightly bounded by the leave-one-out $W_1$ error due to W1-Lipschitzity of $F(\\cdot,\\cdot)$. Since the leave-one-out $W_2^2$ error is $O(1/N)$ (which is central in Chen's argument), the LLN error must be $O(1/\\sqrt{N})$. Since we did not quite use the full power of the uniform LLN in subsequent analyses, however, it is possible that a different approach could circumvent this and achieve $O(1/N)$, which seems an interesting direction for future work. Nevertheless, we emphasize this is the first history-dependent propagation of chaos result with explicit rates in any setting. Existing related results in the SPDE literature are asymptotic and do not provide error bounds [3].\nQ2.\n$\\text{argmax}_j \\mathcal{L}_\\lambda(\\mu_{\\mathscr{X}^i},\\nu_{\\mathscr{Y}^j})$ is not meant to approximate $\\text{argmax}_\\nu \\mathcal{L}_\\lambda(\\mu_{\\mathscr{X}^i},\\nu)$ per se but to measure relative optimality between the 3 solutions (this has now been clarified in the paper). Similarly to a payoff matrix, a nonzero relative NI error implies switching to another $\\nu_{\\mathscr{Y}^j}$ will improve $\\mathcal{L}_\\lambda(\\mu_{\\mathscr{X}^i}, \\cdot)$, and same for $\\mu_{\\mathscr{X}^i}$. Of course for a finite payoff matrix a pure Nash equilibrium does not always exist in which case it is hard to say which is better, but in all of our experiments 1 of the 3 algorithms exhibited zero or near-zero error.\nAs you mentioned, $\\text{argmax}_\\nu \\mathcal{L}_\\lambda(\\mu_{\\mathscr{X}^i},\\nu)$ can be directly computed by running single-objective MFLD in principle. The problem is that this strongly biases the results towards MFL-ABR in practice, since decoupled MFLD is precisely what the inner loop is running. That is, MFL-ABR converges when MFLD w.r.t. $\\mu_k$ ($\\nu_k$) outputs $\\nu_k$ ($\\mu_k$), which is exactly when MFLD-based NI error will evaluate to zero, regardless of various empirical factors that make these processes diverge from theory.\nA third option is to compute the distance to the MNE $(\\mu^*,\\nu^*)$ if it can be determined. However, it is very difficult to find closed-form solutions for objectives with nontrivial interactions between $\\mu,\\nu$, and we cannot rely on the final output of the 3 proposed algorithms since we saw that they converge to different distributions in practice. These issues are what led us to use the indirect 3-point NI error.\nQ3.\nWe have performed some rough computations; it is indeed possible to achieve the unregularized MNE using MFL-AG with an annealing rate $\\lambda_t=O(1/\\log t)$ as in Lu's work or [4]. This results in a proximal gap (Prop. 3.3) of $O(1/(\\log t)^2)$ and NI error convergence rate (Theorem 3.4) of $O(1/\\log t)$. Interestingly, this also absorbs the slow $O(1/t)$ rate of the regularized problem. A caveat is that we must assume $\\delta\\mathcal{L}/\\delta\\mu$ is bounded rather than Lipschitz as in Assumption 3 (a usually stronger condition) in order to avoid the use of Talagrand's inequality and instead use TV distance bounds as in Appendix D. For MFL-ABR, we can similarly anneal $\\lambda_k$ (keeping it fixed in the inner loop) to achieve $O(1/\\log k)$ in the outer loop."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 00:41Everyone", "Content": "Comment:\n(continued)\n[1] Suzuki et al. Mean-field Langevin dynamics: Time-space discretization, stochastic gradient, and variance reduction. NeurIPS 2023.\n[2] Suzuki et al. Feature learning via mean-field Langevin dynamics:\nclassifying sparse parities and beyond. NeurIPS 2023.\n[3] Wu et al. On a class of McKean-Vlasov stochastic functional differential equations with applications. 2023.\n[4] Chizat. Mean-field Langevin dynamics: exponential convergence and annealing. TMLR 2022."}, {"Heading": "Official Comment by Reviewer q6kk", "Subheading": "Official CommentbyReviewer q6kk21 Nov 2023, 09:50Everyone", "Content": "Comment:\nI thank the authors for their detailed explanation of my questions and concerns. I believe most of my concerns are well-addressed.\nFor the propagation of chaos results for the MFL-AG algorithm, the interpretation of  Theorem 3.7 as the bias of the \" propagation of chaos \" is valid to me, and I understand the dependence of dimensionality for variance term might be inevitable technically. However, I'm still a bit concerned about whether the propagation of chaos in $W_1$ is strong enough to interpret the utility of the mean-field minimax problem.\nFor example,  consider the problem of training a two-layer network as discussed in [1, section 2.1 example 1], the propagation of chaos results will imply $ \\mathbb{E}_{\\mathscr{ X}_k } [ | f(z;\\mu_{\\mathscr{ X}_k } ) -   f(z;\\mu_*) |^2 ] \\leq \\mathcal{O}(  \\frac{1}{N} + e^{- \\eta k} ), \\quad \\forall z$  as discussed in [1, section \"Conversion to a Wasserstein distance bound\"].  This gave a good interpretation that the output of the finite-width network is close to the optimal infinite-width neural network in expectation as $N$ is large and training sufficiently long. Thus, in this case, the propagation of chaos results in $W_2$ is good enough.\nIn mean-field minimax problems, especially in mean-field game settings, it seems to me that people are more interested in interpreting the closeness to MNE by measuring $ NI( \\mu_{\\mathscr{ X}_k }, \\nu_{\\mathscr{ X}_k } ) $ for example. Since from Theorem 3.7, it is not obvious to see whether it will imply an upper bound on  $ NI( \\mu_{\\mathscr{ X}_k }, \\nu_{\\mathscr{ X}_k } ) $,  I'm still not convinced whether the propagation of chaos in $W_1^2$ is strong enough.\nNevertheless, now I believe that Theorem 3.7 is indeed a valid propagation of chaos results which is new in the literature and the techniques are novel from the explanations of the authors."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 13:23Everyone", "Content": "Comment:\nThank you for taking the time to read through our responses! We agree that the current statement is not ideal to present our results, however alternatives are somewhat unclear. $\\text{NI}(\\mu_{\\mathscr{X}_k}, \\nu_{\\mathscr{Y}_k})$ is lower bounded by KL which is lower bounded by $W_2^2$, so it is impossible to avoid the curse of dimensionality for NI error. A compromise could be $\\text{NI}(\\mathbb{E}[\\mu_{\\mathscr{X}_k}], \\mathbb{E}[\\nu_{\\mathscr{Y}_k}])$ or $\\text{KL}(\\mathbb{E}[\\mu_{\\mathscr{X}_k}]\\Vert\\mu^*)$, however entropic terms involving $\\mathbb{E}[\\mu_{\\mathscr{X}_k}]$ cannot be controlled with only the uniform LLN.\nIn fact, we can show that\nunregularized\nNI error $\\text{NI}_0(\\mathbb{E}[\\mu_{\\mathscr{X}_k}], \\mathbb{E}[\\nu_{\\mathscr{Y}_k}]) = \\max_{\\nu'}\\mathcal{L}(\\mathbb{E}[\\mu_{\\mathscr{X}_k}],\\nu')-\\min_{\\mu'}\\mathcal{L}(\\mu',\\mathbb{E}[\\nu_{\\mathscr{Y}_k}])$, if it is defined, can be upper bounded by $W_1$ as discussed above. This is the corresponding result to [1, Conversion to a Wasserstein distance bound], while this cannot be extended to regularized NI due to additional entropic terms.\nDefine $\\text{NI}_0(\\mu,\\nu)=\\max_{\\nu'}\\mathcal{L}(\\mu,\\nu')-\\min_{\\mu'}\\mathcal{L}(\\mu',\\nu)$ and suppose $\\mathcal{L}$ is strongly convex-concave so that it possesses a unique saddle point $(\\mu_0^*,\\nu_0^*)$. More precisely, suppose $\\mathcal{L}(\\mu^*,\\nu)\\geq \\mathcal{L}(\\mu_0^*,\\nu) + \\kappa W_1^2(\\mu^*,\\mu_0^*)$, then we have the chain of inequalities\n$$\\mathcal{L}(\\mu_0^*,\\nu^*) + \\kappa W_1^2(\\mu^*,\\mu_0^*) \\leq \\mathcal{L}(\\mu^*,\\nu^*)\\leq \\mathcal{L}(\\mu^*,\\nu^*)+\\lambda\\text{KL}(\\mu^*\\Vert\\rho^\\mu) \\leq \\mathcal{L}(\\mu_0^*,\\nu^*)+\\lambda\\text{KL}(\\mu_0^*\\Vert\\rho^\\mu)$$\nwhich shows that $W_1(\\mu^*,\\mu_0^*)=O(\\sqrt{\\lambda})$. Furthermore, we have $\\max_{\\nu'}\\mathcal{L}(\\mu,\\nu')-\\mathcal{L}(\\mu_0^*,\\nu_0^*)\\leq \\max_{\\nu'} (\\mathcal{L}(\\mu,\\nu')-\\mathcal{L}(\\mu_0^*,\\nu'))\\leq M_\\mu W_1(\\mu,\\mu_0^*)$. Combining and adding with the corresponding result for $\\nu$ gives that $\\text{NI}_0(\\mu,\\nu)\\leq O(W_1(\\mu,\\mu^*)+W_1(\\nu,\\nu^*)+\\sqrt{\\lambda})$.\nWe hope this can clarify the reviewer's concerns."}]}, {"Heading": "Official Review of Submission9271 by Reviewer tSuv", "Subheading": "Official ReviewbyReviewer tSuv17 Oct 2023, 21:52 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors considered the problem of developing a symmetric mean-field Langevin dynamics (MFLD) algorithm for distributional minimax problems with global convergence guarantees. Based on the mean-field Langevin descent ascent (MFL-DA) dynamics, the authors proposed mean-field Langevin averaged gradient (MFL-AG) flow that replaces the MFL-DA drift with the historical weighted average; based on the mean-field best response (MF-BR) flow, the authors proposed the mean-field Langevin anchored best response (MFL-ABR) process. Extensive convergence analyses were provided for both methods. The authors also studied the time and particle discretization error and applied their methods to zero-sum Markov games. Numerical experiments were conducted to compare their methods with MFL-DA.\nSoundness:\n4 excellent\nPresentation:\n3 good\nContribution:\n4 excellent\nStrengths:\nCompactly written, this paper is the first to establish convergence results in using MFLD for minimax optimization over probability measures. By incorporating a weighting scheme into MFL-AG, the authors offered a creative direction for future works on MFLD. The comprehensive discretization analysis complements the continuous-time convergence result well.  Their second method, MFL-ABR, is also an interesting improvement upon MF-BR that is realizable by a particle algorithm and enjoys convergence guarantees.\nWeaknesses:\nThe paper could be improved by providing more intuitions for the proposed methods. For example, what is the intuition for using a weighting scheme in MFL-AG, and what might cause MFL-AG and MFL-ABR to converge more slowly than MFL-DA in the numerical experiments? Is it correct to think that the slowdown of the convergence ensures better convergence?\nQuestions:\nSee weakness. Also, what are some limitations of the proposed methods?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 00:42Everyone", "Content": "Comment:\nThank you for your positive review and helpful suggestions! We have updated the paper and clarified some technical details as well as improving presentation.\nAddressing Weaknesses\nIntuition.\nThe intuition for the MFL-AG averaging scheme is twofold. First, it is based on the general scheme of dual averaging notably explored in [1,2], where specific weightings for regularized problems were also considered. A more recent work [3] proposed the Particle Dual Averaging algorithm for particle-based convex optimization with weighting $\\propto t$. This agrees with our results (Theorem 3.4, 3.7) which show that weighting $t^r$ with exponent $r=1$ is optimal. Second, it is related to the game theory concept of fictitious play, where each player assumes their opponent is playing a stationary strategy and takes the best response to their average behavior, that is the unweighted averaged-gradient proximal distribution. Specifically, MFL-AG is the mean-field Langevin flow that realizes ideal stepwise fictitious play. Adding a weighting then has the meaning of putting higher trust in more recent information, which is appropriate if the opponent strategy or environment is not quite stationary.\nConvergence.\nMFL-AG always exhibits a \"slow but steady\" convergence rate of $\\Theta(1/t)$ induced by drift averaging. In contrast, MFL-ABR is slower due to the double loop structure by a factor of the inner loop max iteration. These features each contribute to the improved optimality of the two algorithms. The performance of MFL-ABR also depended on the choice of hyperparameters. For example, speeding up the inner loop of by decreasing iterations and increasing $\\eta$, or speeding up the outer loop by increasing $\\beta$ can accelerate convergence of MFL-ABR, but also leads to instability in some runs.\nIn addition, MFL-ABR and MFL-DA performed better for problems where $Q(x,y)$ factored into a sum (or product) of separate potentials for $x,y$. In this case the dynamics decouples into two single-optimization problems which are known to converge exponentially. In contrast, MFL-AG was preferable for potentials with complex interactions between $x,y$. For example for the sigmoid potential in Section 6, $\\mu$ pulls $\\nu$ toward itself while $\\nu$ pushes away, leading to a more complicated interacting dynamics that is better solved by the more stable MFL-AG.\nAddressing Questions\nHere are some limitations of the proposed algorithms.\nIf the objective is not bilinear, the discussion in Section 5.1 does not apply and MFL-AG requires the entire history to be stored in memory which is costly considering the longer runtime. Nonetheless, we can avoid iterating over the full history to compute the average by random sampling from past states with weight $\\propto\\beta_k$ so that computational complexity does not increase.\nReturning the average iterate after $K$ steps is also not ideal from an algorithmic perspective. In practice we can simply compare optimality to the last output and choose the better solution, record the best performing last/average iterate, implement early stopping based on relative NI error, etc.\nThe speed and stability of MFL-ABR is highly dependent on the inner loop parameters. The learning rate and max iterations must both be tuned for best performance.\nSome reviewers mentioned the adverse dependency of the convergence rate on $\\lambda$ which is common to MFLD methods. This can be overcome by incorporating a $\\lambda_t\\propto 1/\\log t$ cooling to converge to the saddle point of the unregularized objective $\\mathcal{L}$; please see our response to Q3 of Review q6kk for details. For certain problems, exponential cooling can also be achieved [3,4].\n[1] Nesterov. Primal-dual subgradient methods for convex problems. Mathematical Programming, 120, 2007.\n[2]. Xiao. Dual averaging method for regularized stochastic\nlearning and online optimization. NIPS 2009.\n[3] Suzuki et al. Feature learning via mean-field Langevin dynamics:\nclassifying sparse parities and beyond. NeurIPS 2023.\n[4] Chizat. Mean-field Langevin dynamics: exponential convergence and annealing. TMLR 2022."}, {"Heading": "Official Comment by Reviewer tSuv", "Subheading": "Official CommentbyReviewer tSuv22 Nov 2023, 08:53Everyone", "Content": "Comment:\nThank you for your detailed response. I will keep my current score."}]}]}, "RvmrhrPy7j": {"paper_info": {"Primary Area": "causal reasoning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Causal Inference, Large Language Models, Causal Discovery, Causal Order", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "At the core of causal inference lies the critical challenge of determining reliable causal graphs solely based on observational data. Since the well-known backdoor criterion depends on the graph, any errors in the graph can propagate downstream to effect inference. In this work, we initially show that complete graph information is not necessary for causal effect inference; the topological order over graph variables (causal order) alone suffices. Further, given a node pair, causal order is easier to elicit from domain experts compared to graph edges since determining the existence of an edge can depend extensively on other variables. Interestingly, we find that the same principle holds for Large Language Models (LLMs) such as GPT-3.5-turbo and GPT-4, motivating an automated method to obtain causal order (and hence causal effect) with LLMs acting as virtual domain experts. To this end, we employ different prompting strategies and contextual cues to propose a robust technique of obtaining causal order from LLMs.  Acknowledging LLMs' limitations, we also study possible techniques to integrate LLMs with established causal discovery algorithms, including constraint-based and score-based methods, to enhance their performance. Extensive experiments demonstrate that our approach significantly improves causal ordering accuracy as compared to established discovery algorithms, highlighting the potential of LLMs to enhance causal inference across diverse fields.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9268", "PDF Url": "https://openreview.net/pdf?id=RvmrhrPy7j"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9268 by Area Chair Z9xj", "Subheading": "Meta ReviewbyArea Chair Z9xj04 Dec 2023, 09:29 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper proposes a LLM-Guided method for estimating causal effects, by using LLMs as virtual experts to elicit a causal ordering of the variables. With the causal ordering, a valid backdoor set can be determined as the causal effect can be estimated.\nA reasonable amount of discussions took place between the authors and the reviewers. In the end, we got three reviews with ratings of 3, 5, and 3 with confidence of 3, 3, and 4 respectively.\nThe experiment result is interesting (vBFn, cXcH, 2Neo). However, all the reviewers (vBFn, cXcH, 2Neo) suggest that the contribution is limited. The decision is reject.\nJustification For Why Not Higher Score:\nThe issues raised by reviewers should be properly addressed especially the concerns of theoretical contributions.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9268 by Reviewer vBFn", "Subheading": "Official ReviewbyReviewer vBFn01 Nov 2023, 09:04 (modified: 30 Nov 2023, 10:10)EveryoneRevisions", "Content": "Summary:\nAs a method for estimating causal effects, this paper proposes using LLMs as virtual experts to elicit a causal ordering of the variables. With the causal ordering, a valid backdoor set can be determined as the causal effect can be estimated. Different prompting strategies are explored, as well as algorithms that combine these virtual expert judgments with existing causal discovery algorithms.\nUPDATE: I appreciate the authors' reply, which alleviates my concerns about soundness. However, is still think this paper's contribution is weak, so my overall assessment remains unchanged.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nThe results are presented fairly well.\nReplacing human experts by LLMs could be considered, though I am not up-to-date on the related work cited for this part of the paper.\nWeaknesses:\nThe theoretical contribution is trivial, and contains multiple mistakes.\nQuestions:\nAssumption 3.3 states there is no latent confounding between treatment and target, but you actually need the stronger assumption that there is no latent confounding between any observed variables. Otherwise for instance proposition 4.2 will fail: Suppose we want to find a valid backdoor set for $X \\to Y$, and there is a third observed variable $Z$ that is not a cause or effect of $X$ or $Y$, but there is a latent variable causing $X$ and $Z$, and another causing $Y$ and $Z$. Then a valid topological ordering of the observed variables is $Z < X < Y$, but adjusting for $Z$ actually opens the backdoor path.\nProposition 4.2 requires the further assumption that $i < j$.\nParagraph below proposition 4.2, \"causal effect practitioners tend to include all confounders ...\": Can you provide a reference for this claim? Either way, what you propose goes further than including all\nconfounders\n: you also include variables that cause either the target or the treatment but not both.\nThe definitions of $E_m, E_f, $E_d$ for SHD are incorrect: a wrongly oriented edge will add one to each of these three variables. Further, I think you mean to add the cardinalities rather than the sets themselves.\nAlgorithm in section 5.2: Steps 2 and 3 and the difference between them are unclear from the text. For algorithms, it may be better to use pseudocode, or at least some mathematical notation.\nIn the prompts in the appendix, I noticed that often \"causally effects\" is written when \"causally affects\" was meant.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 1", "Subheading": "Official CommentbyAuthors22 Nov 2023, 04:34Everyone", "Content": "Comment:\nWe thank the reviewer for their valuable inputs, we have incorporated their comments and provided a review wise explanation as follows:\nQuestion\n: Assumption 3.3 states there is no latent confounding....observed variables is Z<X<Y, but adjusting for Z actually opens the backdoor path.\nAnswer\n: Thank you for pointing it out and we agree with you. We revised the manuscript to include the line \u201cWe assume that the underlying causal graph has no unobserved confounders''.\nQuestion\n: Proposition 4.2 requires the further assumption that i<j.\nAnswer\n: Thank you for pointing it out. We\u2019ve updated the proposition statement in the revised manuscript.\nQuestion\n: Paragraph below proposition 4.2, \"causal effect practitioners tend to include all confounders ...\":....the treatment but not both.\nAnswer\n: The statement is based on causal inference practice in statistics and econometrics where all observed covariates (assumed to be pre-treatment) are included in the estimation model. As noted by Cinelli and Pearl (2020), variables that cause only the target are \u201cgood\u201d variables to condition on, so they do not lead to any trouble. Including causes of treatment only can lead to estimation issues (e.g., including an instrumental variable) that increase with the strength of the instrument\u2019s causal effect on treatment. In practice, however, strong instruments are rare.\nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id=3689437\nQuestion\n: The definitions of Em, Ef, E_d$ for SHD are incorrect: a wrongly oriented edge will add one to each of these three variables. Further, I think you mean to add the cardinalities rather than the sets themselves.\nAnswer\n: Apologies. We\u2019ve removed the mathematical formula for SHD as it is not required to understand the rest of the paper and the detailed formula will affect the readability.\nQuestion\n: Algorithm in section 5.2: Steps 2 and 3 and the difference between them are unclear from the text. For algorithms, it may be better to use pseudocode, or at least some mathematical notation.\nAnswer\n: We\u2019ve updated the Algorithm 2 in the revised manuscript to clearly explain the steps.\nQuestion\n: In the prompts in the appendix, I noticed that often \"causally effects\" is written when \"causally affects\" was meant.\nAnswer\n: We apologize for the typographical mistake, we have updated in the main manuscript"}]}, {"Heading": "Official Review of Submission9268 by Reviewer cXcH", "Subheading": "Official ReviewbyReviewer cXcH30 Oct 2023, 19:41 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper addresses the question if and how LLMs can be utilized for causal discovery tasks. For this, the authors focus on effect estimation and argue that knowledge about the causal order is sufficient. The paper aims at two contributions: 1) Showing that the causal order is sufficient for effect estimation problems and 2) showing how LLMs can be used in addition to statistical approaches, such as PC, to improve the causal discovery performance. The suggested approach has been evaluated with different experiments.\nSoundness:\n4 excellent\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper addresses a logical step to combine causal discovery approaches with the domain 'knowledge' of LLMs.\nCareful consideration of different approaches on using LLMs.\nEncouraging results in the experiments.\nWeaknesses:\nThe overall idea is a logical next step seeing the recent success of LLMs in the causal context. However, some of my concerns are:\nThe first contribution regarding the sufficiency about knowing the causal order is not novel and a rather straightforward insight seeing that conditioning on any 'upstream' node of a treatment variable in a DAG results in a valid adjustment set. Therefore, it is certainly good to point this out again, but this is not a new contribution by this work.\nThe paper overall seems rather incremental, seeing that the paper by Kiciman et al. is already providing some significant prior work in this regard for causal discovery. However, I acknowledge the incorporation of LLM generated knowledge with statistical approaches such as PC.\nSee the \"Questions\" section for further points.\nQuestions:\nMy main concern is the rather incremental novelty, especially since the argument that the causal order is sufficient for effect estimation tasks is a well known point. Some other remarks:\nYou are focusing on effect estimation tasks, but the general premise of using LLMs for causal discovery can also be helpful for other tasks. Consider formulating it more broadly and then focus only on effect estimation in the experiments as an example.\nYou are arguing that looking at SHD is often the wrong metric. However, these works using SHD typically address the problem of inferring the whole DAG structure without any particular causal task in mind, while you are only concerned with the causal order for effect estimation problems. In that sense, the SHD makes sense as a metric to see how good the inferred DAG structure is.\nWhile you reference the work by Kiciman et al., a more direct comparison is missing. In particular, the related open source package\nhttps://github.com/py-why/pywhy-llm\nhas several prompting techniques for inferring structural information. That being said, they do not combine it with methods like PC, which is the novel part in your work.\nFair discussion of the limitations and potential issues with overfitting.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Second Reviewer", "Subheading": "Official CommentbyAuthors22 Nov 2023, 04:54Everyone", "Content": "Comment:\nWe thank the reviewer for their valuable inputs, we have provided review wise explanation as follows:\nWeaknesses\nComment\n: The first contribution regarding the sufficiency....but this is not a new contribution by this work.\nResponse\n: The technical result may not be a new result for the backdoor criterion. But its application leads to a valid order-based method for causal discovery using LLMs, whereas we argue that existing pairwise-based prompts that elicit edges may not be valid. The pre-existing work has heavily leveraged LLMs for causal edge detection between any given nodes by optimizing on metrics like SHD for full graph discovery. But the identification of direct causal edge between any given pair of nodes heavily depends on the presence of other nodes, therefore we believe probing LLMs for getting the order between any given pair is a better question framing since the pairwise order only depends on the variables in the question.\nFor example, consider the data-generating process, lung cancer ->doctor visit -> Positive Xray. If asked, an expert would affirm a causal edge from \u2018Lung cancer\u2019 to \u2018Positive Xray\u2019 (indeed, such an edge exists in the BNLearn Cancer [1]). However, if they are told that the set of observed variables additionally includes doctor visit, then the correct answer would be to not create a direct edge between \u2018Lung Cancer\u2019 and \u2018Positive Xray\u2019, but rather create edges mediated through \u2018doctor visit\u2019. Note that the causal order, \u2018Lung Cancer\u2019 < \u2018Positive Xray\u2019 remains invariant in both settings. To fill this conceptual gap in the existing work, our work focuses on causal order and probes LLMs specifically from this perspective since the causal order is useful for most downstream tasks and in practice has huge applications as it is locally consistent in terms of estimation (refer table 1).\nComment\n: The paper overall seems rather incremental...with statistical approaches such as PC.\nResponse\n: While our work draws inspiration from prior research to enhance LLM-based pipelines for aiding in causal discovery, our approach stands out by prioritizing the exploration of how LLMs can effectively identify causal order. This emphasis on identifying causal order is more valuable compared to solely focusing on direct and indirect edge connections, which often rely heavily on other variables. But since order between any given pair of variables remains invariant to other present variables and they directly correlate with downstream tasks like Causal effect estimation, we emphasize and build our frameworks towards that. While previous papers have focused on pairwise causal relationship discovery, our work takes inspiration from pre-existing algorithms to propose novel LLM based pipelines (such as the Triplet prompt). Also, we present how LLMs can be easily adapted with different classes of discovery algorithms whether it is score based or constraint based, for enhancing discovery performance. Most importantly, we emphasize on how current LLMs can be used for downstream applications like causal inference, effect estimation, prediction, etc by leveraging them as knowledge base for finding correct causal order whereas previous work (like Kiciman et al.) have focused more on pairwise causal relationship identification for graph discovery. We show how this approach is not suitable and does not leverage LLMs potential to help in causal tasks by helping get the correct order of the graph by aiding discovery algorithms like PC, CamML, etc."}, {"Heading": "Response to Second Reviewer (Questions)", "Subheading": "Official CommentbyAuthors22 Nov 2023, 04:56Everyone", "Content": "Comment:\nResponse to Questions\nQ\n: My main concern is the rather incremental novelty ... is a well known point.\nA\n: While we do agree that causal order is sufficient for effect estimation, our work provides the novelty in how we are utilizing LLMs as domain experts in association with different classes of discovery algorithms. While pre-existing LLM pipelines have focused on pairwise evaluation of all node pairs for graph discovery, we bring in our own Triplet based methods for correct order estimation to optimize LLMs for downstream tasks and use it for causal discovery with algorithms like CamML and PC.\nQ\n: You are arguing that looking at SHD is often the wrong metric. However ... how good the inferred DAG structure is.\nA\n: While we do agree that SHD is a good metric for evaluating similarity of two graphs, applying this metric specifically for evaluating LLMs\u2019 performance for causal discovery is something we disagree with since direct and indirect edge connections cannot be determined due to the subjectivity of the task and it\u2019s dependence on other variables present (as demonstrated in the \u2018Lung Cancer\u2019, \u2019Positive X-Ray\u2019 and \u2018Doctor Visit\u2019 example above from Cancer dataset). While consideration of other variables can have a direct impact on edge formation between any given pair of nodes, the causal order remains invariant. Therefore probing LLMs to find order is more valid, and also transfers to downstream causal tasks like effect estimation, prediction etc. which further helps position LLMs for utility in real world applications.\nQ\n: While you reference the work by Kiciman et al., a more direct comparison is missing. In particular, the related open source package\nhttps://github.com/py-why/pywhy-llm\nhas several prompting techniques for inferring structural information. That being said, they do not combine it with methods like PC, which is the novel part in your work.\nA\n: Thank you for pointing this out, the base prompt which we have used in our work has been taken directly from Kiciman et al. We further compare this with various prompting strategies including our Triplet prompt for a more direct comparative analysis on DTop and SHD. We have updated the manuscript and cited Kiciman et al. for the Base prompt.\nReferences: [1] M. Scutari and J.B. Denis. Bayesian Networks: With Examples in R Chapman & Hall/CRC Texts in Statistical Science. Taylor & Francis, 2014"}]}, {"Heading": "Official Review of Submission9268 by Reviewer 2Neo", "Subheading": "Official ReviewbyReviewer 2Neo27 Oct 2023, 02:45 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors propose to use LLMs with majority voting to learn a causal order of the random variables in the underlying data generating process represented by directed acyclic graphs from observed data. The learned causal order is then used to orient the undirected edges in the output of the existing causal discovery algorithms. Additionally, the authors claim that causal graphs are not necessary needed for causal effects estimation, rather, the causal order is sufficient by finding a valid backdoor adjustment set. They further argue that using causal orders is preferable in the case when domain expert knowledge is available.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe authors demonstrate the utility of LLMs in causal discovery through means of causal orders and use that as a background knowledge for the existing causal discovery algorithms.  The paper also shows that causal structures are not necessarily required for causal effect estimation and causal orders are sufficient. It also shows both empirically and theoretically that SHD is not a good metric to measure the accuracy of predicting correct causal orders. The paper is fairly well-written and the proofs are sound.\nWeaknesses:\nTaking outputs from LLMs as inputs to causal discovery algorithms is not uncommon [5]. I find the comparison in the experiment is not quite fair to the existing causal discovery algorithms. There are many existing algorithms that incorporate background knowledge of ordering restrictions [1, 2, 3] and they are not reported on the paper. The authors could have randomly sampled from the ground truth and provided that as background knowledge to other algorithms in the experiment especially for graphs that are less than 20 nodes to compare against methods with LLMs. Given that the theoretical contributions are relatively small, I would expect to see more empirical experiments to show the strong motivation and merits of the approach.\nThe experimental result could have been highly affected by the popularity of the datasets and domain knowledge on the internet and using LLMs to guide causal discovery can be very limited to those commonly available data.\nIt is not clear what the advantages of using LLMs as a source of domain knowledge are as it may have issues with hallucinations unless there are large-scale experiments that show some domain knowledge are impractical to obtain via domain experts and need LLMs to guide such effort.\nIt is also not clear to me why the estimation is not compared against with those estimation methods that use causal graphs or simply a Markov equivalence class of DAGs [4] even if there is only the information of causal orders available to show the merits of using only the causal order for estimation.\nReferences\n[1] de Campos, Luis M., and Javier G. Castellano. \"Bayesian network learning algorithms using structural restrictions.\" International Journal of Approximate Reasoning 45.2 (2007): 233-254.\n[2] Cooper, Gregory F., and Edward Herskovits. \"A Bayesian method for the induction of probabilistic networks from data.\" Machine learning 9 (1992): 309-347.\n[3] Borboudakis, Giorgos, and Ioannis Tsamardinos. \"Towards robust and versatile causal discovery for business applications.\" Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 2016\n[4] Jung, Yonghan, Jin Tian, and Elias Bareinboim. \"Estimating identifiable causal effects on markov equivalence class through double machine learning.\" International Conference on Machine Learning. PMLR, 2021.\n[5] Taiyu Ban, Lyvzhou Chen, Xiangyu Wang, and Huanhuan Chen. From query tools to causal architects: Harnessing large language models for advanced causal discovery from data. arXiv preprint\narXiv:2306.16902, 2023.\nQuestions:\nHow does using triples helps avoiding cycles in learning the causal order?\nIs it possible that the causal order output by LLMs orient a new unshielded collider in the output of other causal discovery algorithms?\nHave the authors tried to provide background knowledge to PC and compare that with PC+LLM? For example, randomly sample from the ground truth and provide such background knowledge to PC or other algorithms.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Third Reviewer", "Subheading": "Official CommentbyAuthors22 Nov 2023, 05:07Everyone", "Content": "Comment:\nWe thank the reviewer for their valuable feedback. We have incorporated their feedback and provided a review wise explanation as follows:\nResponse To Weaknesses\nComment\n: Taking outputs from LLMs as inputs to causal discovery algorithms is not uncommon [5] ..... show the strong motivation and merits of the approach.\nResponse\n:  Our work focuses more on evaluating how good LLMs are as knowledge bases or domain experts rather than focusing on how well different discovery algorithms incorporate domain knowledge. The work leverages LLMs understanding of real world, to extract relevant information (causal order) which is inputted into causal discovery algorithms as priors to further aid their performance. While we agree past work has covered inputting LLM outputs as priors to discovery algorithms, our work stands out by focusing on probing LLMs for extracting causal order instead of detecting all possible edges, due to causal order\u2019s utility in downstream tasks like effect estimation, prediction, etc. While previous work builds upon pairwise prompting strategies our work proposes a novel triplet based method which overcomes the previous methods drawbacks of having cycles in the final graph and presenting a lower DTop.\nTo present an analysis of how close LLMs as knowledge bases are to ground truth information as priors, we conduct an experiment on Child and Asia dataset (refer Table A15).\nComment\n: The experimental result could have been highly...limited to those commonly available data.\nResponse\n: We agree that there is a possibility that LLMs have seen the BNLearn datasets in its pretraining setup, and highlight this in the limitations section of our paper as well. However to tackle this claim we include the Neuropathic Pain Diagnosis dataset in our updated paper draft and show the effectiveness of our methods on the same. The dataset is less popular and requires a very nuanced medical understanding in order to correctly assess the causal relationship, therefore depicting how LLMs can be employed in real world settings which are not straightforward. That being said, we still agree that memorization of causal discovery datasets is an issue in current evaluation of LLMs which is scope for future research work.\nComment\n: It is not clear what the advantages...need LLMs to guide such effort.\nResponse\n: One of the practical implications of using LLMs can be to aid human experts as they can look at the LLM generated graphs and edit it further thus saving time as well as efforts. While LLMs do suffer from issues like hallucinations, they still carry an understanding of the world which can be used to assist the human experts to improve and fasten the causal graph creation process. It will be on human experts to accept the suggestions and reasoning provided by LLMs while constructing causal graphs thus removing any hallucinated or false outcome.\nComment\n: It is also not clear to me why the estimation...the causal order for estimation.\nResponse\n: Thank you for the review, we have added a comparative analysis (Refer Table A16 in Appendix) on Asia dataset to show estimation using backdoor set from the given graph vs given causal/topological order of the graphs.\nResponse To Questions\nQuestion\n: How does using triples helps avoiding cycles in learning the causal order?\nAnswer\n: Our intuition is that due to dynamic context, i.e. with each iteration for deciding edge wise causal direction between a given pair of nodes, the third variable changes thus providing different context each time. Due to this, the LLM gets an overall understanding of the other nodes present in the graph. Thus, the aggregate of all the decisions LLM makes pertaining to a specific pair followed by tie breaker using GPT-4, incorporates overall understanding plus robustness in the final answer. Higher incorporation of neighboring nodes plus multiple querying of while deciding causal edge between all possible pairs, might be some reasons behind lower number of cycles. On the other hand, since pairwise analysis that has been done in previous literature, prompt LLM only once without extra contextual information, the edge formations are not always robust and might be contributing factors for forming more cycles.\nQuestion\n: Is it possible that the causal order output by LLMs orient a new unshielded collider in the output of other causal discovery algorithms?\nAnswer\n: Since we do not have a check for this in our current algorithm, there is a slight possibility that LLMs might orient new unshielded colliders when used as priors with PC Algorithm. We will incorporate this check in our pipeline.\nQuestion\n: Have the authors tried to provide background knowledge to PC...knowledge to PC or other algorithms.\nAnswer\n:  We have added Table A15 in Appendix to show comparison between LLM and Ground truth prior for causal discovery."}]}]}, "030cjlZm4a": {"paper_info": {"Primary Area": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Predictive Checklists, Interpretability, Fairness, Probabilistic Logic Programming", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Checklists have been widely recognized as effective tools for completing complex tasks in a systematic manner. Although originally intended for use in procedural tasks, their interpretability and ease of use have led to their adoption for predictive tasks as well, including in clinical settings. However, designing checklists can be challenging, often requiring expert knowledge and manual rule design based on available data. Recent work has attempted to address this issue by using machine learning to automatically generate predictive checklists from data, although these approaches have been limited to Boolean data. We propose a novel method for learning predictive checklists from diverse data modalities, such as images, time series, and text, by combining the power of dedicated deep learning architectures with the interpretability and conciseness of checklists. Our approach relies on probabilistic logic programming, a learning paradigm that enables matching the discrete nature of a checklist with continuous-valued data. We propose a regularization technique to tradeoff between the information captured in discrete concepts of continuous data and permit a tunable level of interpretability for the learned checklist concepts. We demonstrate that our method outperforms various explainable machine learning techniques on prediction tasks involving image sequences, clinical notes, and time series.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "pdf", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9267", "PDF Url": "https://openreview.net/pdf?id=030cjlZm4a"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9267 by Area Chair 5NzQ", "Subheading": "Meta ReviewbyArea Chair 5NzQ07 Dec 2023, 21:49 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper proposes to learn interpretable checklists from various modalities using probabilistic logic programming. This is an important and well-motivated problem, specifically in clinical context. The paper is well motivated, well-written, and the methodology seems sound.\nSome reviewers remarked that the interpretability of the approach hinges on interpretability tools for deep learning tools, which need to be considered with care. The experiments are relatively limited.\nThe AC has as an additional comment: it is not clear where the logics part enter the method. In section 4.4, it is mentioned \"The checklist prediction formula of Equation 3 an be understood as logical rules in a probabilistic logical program.\" But equation 3 appears in FAIRNESS REGULARIZATION and seems not to define any logical part of the problem. The link points to page 4, where the prediction is expressed as simple threshold. Is this the logic part of the method? Given the title, one would actually expect that some significant logical knowledge would enter the method.\nJustification For Why Not Higher Score:\nWhile the paper is well-motivated, there substantial criticisms remain. The paper is probably rather borderline, but probably too weak for ICLR.\nJustification For Why Not Lower Score:\nNA"}, {"Heading": "Global Response (1/2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 04:25 (modified: 20 Nov 2023, 04:25)EveryoneRevisions", "Content": "Comment:\nWe want to thank all reviewers for their insightful comments that contributed to improving our paper. We are glad to report that we have implemented all the suggested changes in the paper.\nWe address here main topics that were raised in the reviews.\n1) Interpretability of checklist structure (checklist classifier)\nReviewers eMqU, Ucnh, and SxKf have questioned the interpretability of the checklist structure. We want to further motivate the interpretability of a checklist, and of our classifier.\nAlthough ProbChecklist uses a probabilistic objective for training the concept learners, the end classifier used for inference is indeed a discrete checklist. At inference time, the end classifier is thus a discrete checklist.\nWhile this makes the classifier highly interpretable, it also shifts the focus of interpretability to the learnt concepts. We fully realize and acknowledge this trade-off. We do not claim to definitely solve the problem of interpretability but rather investigate the feasibility of an alternative approach. We recognize the problem of the potential non-interpretability of the concepts in our architecture. However, this is a structural issue from the field of interpretable machine learning in general. Nevertheless, we spend a significant effort in the experiment assessing the interpretability of the concepts, relying on several state of the art methods, as described below.\n2) Interpretability of learnt concepts\nIdentifying patterns from the binarized concepts is largely based on visual inspection. To aid our analysis, we use gradient attribution of the concepts with respect to the input to identify parts that contribute to each concept. \nWe discuss the interpretability of the concepts for each modality separately:\nContinuous Tabular Dataset (PhysioNet Sepsis Tabular):\nOur method works effectively on continuous tabular data where we know what each attribute represents. ProbChecklist learns the thresholds to binarize these continuous features to give the concepts. These concepts are inherently interpretable. All existing methods are designed to operate on continuous or categorical tabular datasets only. As such, our method is already novel. Nevertheless, we investigated the ability of our architecture to handle more complex data modalities.\nImage and Time Series Tasks (MNIST/MIMIC):\nOur initial results highlighted that the gradient attributions for the different concepts learned from one modality were very similar (plots in Section F.2 of the supplementary).  Pixel intensities alone are insufficient for automatically interpreting the concepts, giving rise to the need for visual inspection by domain experts. Therefore, we opted to visualize the gradient attributions of the concepts concerning the input. These plots aid domain experts in extracting patterns and recognizing the learned concepts. TANGOS enforces sparsity and decorrelation among concepts, thereby specializing them to specific input regions and preventing redundancy. While this represents one notion of interpretability, different applications may benefit from alternate definitions suited to their needs. One significant benefit of our approach is its adaptability to incorporate various other interpretability methods, enhancing its flexibility.\nNLP Tasks (Medical Abstract Classification):\nCompared to images and time series, interpreting concepts learned from textual data is easier because its building blocks are tokens which are already human understandable. In this setup, instead of employing TANGOS regularization, we identified words associated with positive and negative concepts (positive and negative tokens). Each concept is defined by the presence of positive words and the absence of negative words. The resulting checklist is visualized in Figure 1. We have edited the main paper to include more details about this.", "Replies": [{"Heading": "Global Response (2/2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 04:27Everyone", "Content": "Comment:\n3) Motivation and Utility of the proposed method\nAll existing approaches for checklist learning are tailored for tabular datasets where the concepts are predefined. Our method not only operates effectively on continuous tabular datasets but also provides the flexibility to extend to complex modalities such as text, images, and time-series, thereby establishing its superiority. To ensure a fair comparison with previous methods, we conduct experiments using the PhysioNet Sepsis Tabular dataset. The results demonstrate that ProbChecklist achieves performance comparable to existing methods. Notably, ProbChecklist learns thresholds for binarizing continuous features to derive concepts, distinguishing it from all other techniques except MIP Checklist, which need binarized features.\nAs mentioned above, for our experiments on time series and image datasets we focus on one notion of interpretability: that the learnt concepts should be distinct and should span the entire input vector. These constraints were enforced by employing the TANGOS regularizer. However, different applications may necessitate alternative definitions of interpretability, which can be seamlessly integrated into ProbChecklist's framework.\nThe bulk of data collected today comprises images, text, and time series information. It's imperative to shift our attention toward devising methods to handle non-tabular data. We realize the shortcomings of our approach, but this is the first step towards learning checklists from complex modalities.\n4) Additions to the paper\nIn response to the valuable feedback provided by the reviewers,  we have included additional results.\nWe add an ablation study in the supplementary (Section B) comparing the training times of ProbChecklist and MIP Checklists on the PhysioNet Tabular Dataset. We also elaborate on situations where ProbChecklist was more effective than MIP checklists at learning checklists in the MNIST setup.\nWe expand the fairness results in Section G of the supplementary to include the model performance before and after fairness regularizer is applied.\nWe include a discussion on the interpretability of concepts for the Medical Abstract Dataset in Section 5.2 of the main paper.\nIn our current method, each item in the checklist holds a weight of +1. We present an approach to expand ProbChecklist, enabling the learning of integer weights for each item. This extension has the potential to broaden the applicability of our method. He describe the approach in Appendix H."}]}, {"Heading": "Official Review of Submission9267 by Reviewer eMqU", "Subheading": "Official ReviewbyReviewer eMqU01 Nov 2023, 07:54 (modified: 22 Nov 2023, 10:47)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a method for learning checklist models for diverse data modalities, such as images, time series, and text. Checklists are a type of interpretable models that are widely used in clinical settings. A checklist model consists of a set of concepts, each of which is assigned an integer weight (always +1 in this paper). The prediction is made by summing the weights of the concepts that are present in the input and comparing the sum to a threshold $T$. Existing methods for learning checklist models are limited to tabular data. To learn checklists from these raw data modalities, the authors propose to train neural networks using a probabilistic logic programming (PLP) framework. Basically, the neural network maps the input signals to a fixed number of logits, each of which is regarded as the log probability of the presence of a concept. One can then use the logits to compute the likelihood of the positive/negative label based on the definition of the checklist model. The likelihood of the positive label is the probability of the event that at least $T$ concepts are present in the input. The model is then trained with the cross-entropy loss. The authors also propose to add several regularization terms to encourage interpretability and fairness. In the experiments, the proposed model is compared to integer programming and deep learning baselines.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nOriginality: This work extends checklist learning to data modalities other than tabular data and combines the power of deep learning with the interpretability of checklist models. The proposed method is interesting.\nClarity & Quality: The background and methodology are clearly presented. The paper is easy to follow.\nSignificance: The proposed method seems to be a practical solution to the problem of learning checklist models from raw data modalities. Such models, if learned successfully, may be used in many real-world applications, such as clinical decision support.\nWeaknesses:\nThere are too many hyperparameters in the proposed method, including the weight of the regularization terms, the number of concepts, and the threshold $T$, in addition to the architecture details of the neural networks. The authors should provide some guidance on how to choose these hyperparameters.\nThe learned \"concept\"s are hard to interpret from my point of view. The authors suggest that the concepts can be sensed by using post hoc attribution methods. However, it is well-known that the attribution methods are not perfect and may not be reliable.\nMissing related work: I believe this work should be connected to the literature on concept-based explanation and learning, such as [1], [2], and the references therein. The authors should discuss the connections and differences.\nThe computational cost of the proposed loss function scales exponentially with the number of concepts.\nTypos: \"LSTMS\" -> \"LSTMs\", \"TANGOS\" -> \"TANGOs\"\n[1] Amirata Ghorbani, et al. Towards Automatic Concept-based Explanations. NeurIPS 2019\n[2] Pang Wei Koh, et al. Concept Bottleneck Models. ICML 2020\nQuestions:\nIs it possible to extend the proposed method to learn checklist models with integer weights that are not necessarily +1? This may be useful in many applications.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal by Authors (1/2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 04:55Everyone", "Content": "Comment:\nWe thank the reviewer for their valuable comments and insights.\n1) There are too many hyperparameters in the proposed method, including the weight of the regularization terms, the number of concepts, and the threshold, in addition to the architecture details of the neural networks. The authors should provide some guidance on how to choose these hyperparameters.\nWe thank the reviewer for this suggestion. We had included a section on hyperparameter tuning in the appendix (Section C). We have now added a reference to it in the main paper for the interested readers.\nThe ProbChecklist framework allows experts to design user-centric checklists. Hyperparameters $d_k, \\ T and \\ M$ represent the structure/compactness of the checklist but alone aren\u2019t sufficient to garner information about the checklist\u2019s performance. Different $d_k$ are tried for each modality in an increasing fashion to find the one that performs best. Sensitivity analysis to study the relation between $d_k$ and performance (Figure 3a) suggests that the performance saturates after a certain point. This point can be determined experimentally for different modalities. M, total concepts in the checklist, is obtained by pruning concepts that are true for insignificant samples. Our experiments showed that pruning was not required since all the concepts were true for a significant fraction of samples. This indicates the superior quality of the concepts.\nWe try different values of T in the range [M/4, M/2] (total items M) to find the most performant model. However, this hyperparameter tuning doesn\u2019t contribute to the computational cost. For $d_k$, we only only 2-3 values, and use the same value for all the features. Domain experts will be more equipped to choose these values based on their knowledge of the features. For example, if we are recording a time series feature known to stay stable (not fluctuate much), then low $d_k$ is sufficient. The value of $d_k$ also depends on the number of observations (most blood tests aren\u2019t performed hourly, but heart rate and oxygen saturation are monitored continuously).\n2) The learned \"concept\"s are hard to interpret from my point of view. The authors suggest that the concepts can be sensed by using post hoc attribution methods. However, it is well-known that the attribution methods are not perfect and may not be reliable.\nWe direct the reviewer to our discussion on interpretability of concepts in the global response.\n3) Missing related work: I believe this work should be connected to the literature on concept-based explanation and learning, such as [1], [2], and the references therein. The authors should discuss the connections and differences. [1] Amirata Ghorbani, et al. Towards Automatic Concept-based Explanations. NeurIPS 2019 [2] Pang Wei Koh, et al. Concept Bottleneck Models. ICML 2020\nWe thank the reviewer for recommending these papers. Concept Bottleneck Model (CBM) is an approach to make deep learning architectures more interpretable by adding a concept layer before the last fully connected layer. Each neuron in this layer represents a human understandable concept. One major limitation of this technique is that annotated data for predefined concepts is required which is expensive to collect. We have included these papers in our related works section.\n4) The computational cost of the proposed loss function scales exponentially with the number of concepts.\nWe offer a comparison of training times with the MIP checklist method on the PhysioNet Tabular dataset to evaluate the extent of this limitation (Section B of the appendix). It's crucial to highlight that while MIP Checklist performs effectively with tabular data, successfully uncovering the optimal solution, its performance is poor when applied to MNIST synthetic setup. Even when we set the runtime for Gurobi solver as 1 hour, it struggles to achieve optimal solutions for many cases. On the other hand, ProbChecklist stands out as more reliable, capable of performing end-to-end training and successfully learning the optimal solution."}, {"Heading": "Rebuttal by Authors (2/2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 04:58 (modified: 20 Nov 2023, 05:04)EveryoneRevisions", "Content": "Comment:\n5) Is it possible to extend the proposed method to learn checklist models with integer weights that are not necessarily +1? This may be useful in many applications.\nWe warmly thank the reviewer for this very valuable suggestion. Before we formulate a method to achieve this, it is important to note that this would make it harder to interpret the checklist. More specifically, the meaning of the checklist threshold used for classification of samples would now change. Previously, it represented the minimum number of true concepts for a positive classification. Now it signifies a score - the minimum value of the weighted sum of concept probabilities for a positive classification.\nWe propose the following extension to allow for integer weights larger than 1. Given K data modalities as the input for sample i, we train K concept learners to obtain the vector of probabilistic concepts  of each modality $\\mathbf{p_i^k} \\in [0,1]^{d'}$. Next, we concatenate the full concepts probabilities ($\\mathbf{p_i}$) for sample i. At this point, we can introduce a trainable weight vector $W \\in [0,1]^{d'}$ (with $\\sum_{i=1}^{d\u2019}w_i = 1$) of the same dimension as $p_i$ (concept probabilities) which will capture the relative importance of the features. Element-wise product ($\\circledcirc$) of $p_i$ and W represents the weighted concept probabilities and can be denoted with $Wp_i$. This vector can be normalized by dividing each element with the maximum entry (L0 norm). While training it i For training the concept learners, we pass $Wp_i$ through the probabilistic logic module. After training, the integer weights corresponding to each concept in the checklist can be obtained by converting the W to a percentage: $W_{int}$. At inference time, we discretize $\\mathbf{C_i}$ to construct a complete predictive checklist. Next, compute the score $W_{int}^T C_i$ and compare it against the checklist threshold, $M$, to classify the sample.\nWe appreciate the reviewer's suggestion and concur that this extension of our method could be valuable for users. As a result, we have incorporated a figure and a concise description of the approach in the appendix (Section H).\n6) Typos\nWe thank the reviewer for spotting the typing mistakes. We have proofread the paper carefully and resolved them."}, {"Heading": "Official Comment by Reviewer eMqU", "Subheading": "Official CommentbyReviewer eMqU22 Nov 2023, 10:47Everyone", "Content": "Comment:\nThanks for your detailed response. I will update my rating to borderline accept. Please recheck the notation consistency in the revised submission. For example, I think the $d_k$ in Figure 3a should be $d'_k$ in Section 4.3. Proofreading is needed."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:15Everyone", "Content": "Comment:\nWe sincerely thank the reviewer for raising the score and for the encouraging feedback. We have rectified the notation error in Figure 3a to maintain consistency with Section 4.3. The paper has been updated after proofreading."}]}, {"Heading": "Official Review of Submission9267 by Reviewer Ucnh", "Subheading": "Official ReviewbyReviewer Ucnh31 Oct 2023, 19:15 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a novel method based on probabilistic logic programming to learn predictive checklists from diverse data modalities including images and time series. The proposed approach was validated using several public benchmark datasets.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nOriginality: The paper demonstrates originality in creative combinations of existing ideas and approaches to the target problem\nClarity: Problem formulations and related works are clearly described and cited. The paper is well-organized with most components including limitations.\nSignificance: Classification performances are reported with multiple metrics and confidence intervals\nWeaknesses:\nOne weakness is the results discussion using MNIST data only, which is not so intuitive in the checklist concept motivated by healthcare examples in the introduction part. And the paper has results from clinical data of PhysioNet and MIMIC III in the supplementary materials, which should be much better than the MNIST story. The necessity of using checklist, instead of other benchmark methods, on the experiment data tasks (especially non-healthcare MNIST data) is another question not explained.\nModel comparison in Table 1 would be better to also be illustrated in graph and plots for easy visualization.\nConcepts learned from images seem not human-interpretable if looking at the example in Figure 3. The two concepts might still look like visual patterns that could be only differentiable by machines or algorithms. It will be hard in practice to create human-understandable checklist out of the concepts illustrated, especially in clinical domain.\nConcepts learned from other data modality is not illustrated in the main paper, especially time series and text, which weakens the claim of interpretation utility of the proposed algorithm in different modality.\nSeveral typos in the paper, e.g. (683, 2021) on page 6, not sure whether it's citation or time series specification; and also \"We create a We briefly\" in line #2 on page 7. The paper needs some proofreading.\nQuestions:\nSame in weakness. If the checklist concept learned from the data is not easy for human to understand and annotate, what's the potential utility of the proposed method?\nHow does the proposed method compared to other benchmark method without using checklist? a.k.a. Why using checklist to identify MNIST or predict sepsis or mortality? Is the performance better than other methods in the literature?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNA\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 05:23 (modified: 23 Nov 2023, 05:26)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewer for their valuable comments and insights.\n1) Model comparison in Table 1 would be better to also be illustrated in graph and plots for easy visualization.\nWe thank the reviewer for this suggestion. We have added this plot to Section I of the appendix to help the readers.\n2) Concepts learned from other data modality are not illustrated in the main paper, especially time series and text, which weakens the claim of interpretation utility of the proposed algorithm in different modality.\nWe direct the reviewer to Figure 1 of the paper, which illustrates the checklist learnt from the medical abstract classification task. As previously explained in the global response, understanding results for NLP tasks is significantly simpler due to the comprehensibility of tokens. We have now included a description of the technique used for generating this checklist in the main paper. While experiments involving the TANGOS regularizer on time series datasets have been conducted, we have presented them in the supplementary section. This decision was made as these results require assessment by domain experts to discern patterns effectively.  Instead, our focus has shifted to the synthetic MNIST dataset, as its known ground truth concepts make it easier to validate our approach. We also discuss the results of the PhysioNet Tabular dataset.\n3) Same in weakness. If the checklist concept learned from the data is not easy for human to understand and annotate, what's the potential utility of the proposed method?\nWe direct the reviewer to our discussion on interpretability of concepts and utility of the method in the global response.\n4) How does the proposed method compared to other benchmark method without using checklist? a.k.a. Why using checklist to identify MNIST or predict sepsis or mortality? Is the performance better than other methods in the literature?\nWe have included the following baselines in Table 1:\nML (non-checklist) baselines:\nLSTM/CNN/BERT + MLP (for 10 selected features and all features in the dataset), LSTM/CNN/BERT + LR.\nChecklist baselines:\nUnit weighting, ILP mean thresholds, MIP Checklist.\nThe CNN/LSTM + MLP for MIMIC which is trained on all the features in the dataset acts as an upper baseline to quantify the performance loss incurred by switching to an interpretable checklist classifier.\nThrough these experiments, we aim to showcase that ProbChecklist surpasses existing checklist methods and achieves comparable performance to MLP (non-interpretable) methods. It\u2019s important to note that a checklist, due to its binary weights, has a strictly lower capacity and is less expressive than deep learning but possesses a more practical and interpretable structure. Despite this, it exhibits similar performance to an MLP.\n5) One weakness is the results discussion using MNIST data only, which is not so intuitive in the checklist concept motivated by healthcare examples in the introduction part. And the paper has results from clinical data of PhysioNet and MIMIC III in the supplementary materials, which should be much better than the MNIST story. The necessity of using checklist, instead of other benchmark methods, on the experiment data tasks (especially non-healthcare MNIST data) is another question not explained.\nWe direct the reviewer to the global response 1 and answers to questions 1 and 4 above.\n6) Several typos in the paper, e.g. (683, 2021) on page 6, not sure whether it's citation or time series specification; and also \"We create a We briefly\" in line #2 on page 7.\nThe paper needs some proofreading. We thank the reviewer for spotting the typing mistakes. We have proofread the paper carefully and resolved these issues."}, {"Heading": "We are available to answer any further comments.", "Subheading": "Official CommentbyAuthors22 Nov 2023, 14:02Everyone", "Content": "Comment:\nDear Reviewer,\nThank you again for reviewing our paper and for your encouraging feedback!\nHave all the concerns you raised been adequately addressed? We are glad to provide you with complementary responses.\nThank you very much.\nBest Regards,\nThe authors"}]}, {"Heading": "Official Review of Submission9267 by Reviewer SxKf", "Subheading": "Official ReviewbyReviewer SxKf30 Oct 2023, 12:37 (modified: 20 Nov 2023, 08:55)EveryoneRevisions", "Content": "Summary:\nThe authors propose a new framework for learning predictive checklists. The method is able to process time series, images, tabular features, etc. The use of techniques enabling sparse representations of the inputs and the use of a fairness metric lead to checklists that would have interpretable features and that promote fairness toward sensible variables.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\n-The \u00ab\u00a0related works\u00a0\u00bb  analysis is thorough and seems up-to-date.\n-I found the experiment subsection 5.1 truly compelling. Many metrics are reported, which I think is not done often enough.\n-The approach is well-explained and flexible.\nWeaknesses:\nMajor\n1 \u2013 Most how the points I would like to raise concern interpretability. (See also the points in the Question section on that matter.)\n1.1 - Interpretability is directly impacted by the complexity of the model itself, but the fact that the algorithm is in itself a black box makes it such that understanding why the model is what it is is unreachable.\n1.2 \u2013 As discussed in [1], p.17, when it comes to logical rules, the more digits there are to take into account, the less the rule is interpretable. One could argue that the checks from Figure 4 aren\u2019t that interpretable. When it comes to the features themselves: what does it really mean to have an \u00ab\u00a0sd\u00a0\u00bb of FiO2 above 0.035? It is normal? Is it higher than the average? Is it higher than a certain minimum threshold? Such questions arrises with every check.\n1.3 \u2013 The interpretation made of the checks from MNIST Images task is questionable. It\u2019s been known for a long time now that saliency maps, especially the vanilla approach of looking at the gradient map, can easily lead to false conclusions, especially when those conclusions match what a person is seeking [2]. Interpretability is needed in the context where explainability (e.g. saliency maps) is not trustworthy.\n1.4 \u2013 Finally, the interpretation of the features is made in an example where the relationship between the inputs of a problem and the labels is known. The procedure given in order to make sense of the feature extract wouldn\u2019t work if this knowledge was unknown.\n2.1 \u2013 It is shown that the use of the fairness regularizer works in order to minimize both FNR and FPR, but it is not discussed whether or not the constraint impacts the performances of the checklist, so there is no way to truly understand if its usage is really beneficial.\n2.2 \u2013 The second contribution states \u00ab\u00a0We investigate the impact of different schemes for improving the interpretability of the concepts learnt as the basis of the checklist. We employ regularization techniques to encourage the concepts to be distinct, so they can span the entire input vector and be specialized, i.e. ignore the noise in the signal and learn sparse representations. We also investigate the impact of incorporating fairness constraints into our architecture.\u00a0\u00bb But since (as discussed in 2.1) there lacks evidence of the soundness of the fairness regularizer, combined with the fact that there is no evidence demonstrating that \u00ab\u00a0regularization techniques encourage the concepts to be distinct, so they can span the entire input vector and be specialized\u00a0\u00bb (as discussed in 1.4), or at least that the \u00ab\u00a0different schemes for improving the interpretability of the concepts learned\u00a0\u00bb truly are responsible for such observations, the soundness of all Contribution 2 can be questioned.\n[1]\u00a0: Rudin, C., Chen, C., Chen, Z., Huang, H., Semenova, L., & Zhong, C. (2021). Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges. ArXiv. /abs/2103.11251\n[2]\u00a0: Julius Adebayo, Justin Gilmer, Michael Muelly, Ian J. Goodfellow, Moritz Hardt, and Been Kim. 2018. Sanity Checks for Saliency Maps. In NeurIPS. 9525\u20139536.\nMinor\n1 \u2013 Typos. There are several of them...\n1.1 - \u00ab\u00a0Figure 1: Example checklist\nlearnt\nby our architecture. Three\nof\nmore checks [\u2026].\u00a0\u00bb\n1.2 - \u00ab\u00a0Clinical practice is\nan\nhighly stressful [...]\u00a0\u00bb\n1.3 - \u00ab\u00a0[\u2026] programming and thus exhibits much faster\n?\ntimes and [...]\u00a0\u00bb (a word is missing; \u00ab\u00a0computation\u00a0\u00bb, \u00ab\u00a0training\u00a0\u00bb?)\n1.4 - \u00ab\u00a0[\u2026] we can write the\nprobabality\nof query q as follows.\u00a0\u00bb\n1.5 - \u00ab\u00a0We\nadditional\nintroduce a regularization [...]\u00a0\u00bb\n1.6 - \u00ab\u00a0We investigate the performance\n?\nProbChecklist along [...]\u00a0\u00bb\n1.7 - \u00ab\u00a0We create\na We\nbriefly describe the MNIST [...]\u00a0\u00bb\n1.8 - \u00ab\u00a0focus on the image\u2019s upper half and\ncentre\n\u00bb\n1.9 - \u00ab\u00a0we visualize\n? learnt\nby ProbChecklist in one of the experiments\u00a0\u00bb\n1.10 - \u00ab\u00a0Detailed complexity analysis can be found in the\n?\nB.\u00a0\u00bb\n1.11 - \u00ab\u00a0[\u2026] interpretable such as decision trees)\n)\nand posthoc [...]\u00a0\u00bb\n2 - \u00ab\u00a0ProbChecklist\u00a0\u00bb is named one time (the first time) before being properly introduced (the second time it is mentioned).\n3 \u2013 The first citation \u00ab\u00a0Learning Predictive and Interpretable Timeseries Summaries from ICU Data, volume 1, 2021.\u00a0\u00bb doesn\u2019t respect the template. It should be something like \u00ab\u00a0Johnson N, Parbhoo S, Ross AS, Doshi-Velez F. Learning Predictive and Interpretable Timeseries Summaries from ICU Data. AMIA Annu Symp Proc. 2022 Feb 21;2021:581-590. PMID: 35309006; PMCID: PMC8861716.\u00a0\u00bb\n4 \u2013 The fourth chapter\u2019s title should be isolated from the previous paragraph.\n5 \u2013 Using a single letter (with the same calligraphy) for two different usages (\u2018d\u2019, both overall dimension and error criterion) is not desirable.\n6 \u2013 Constraints are not respected concerning the configuration of the table (Table 1): \u00ab\u00a0number and title always appear before the table\u00a0\u00bb (ICLR24 template and instructions).\n7 \u2013 In Table 1: why is there no number bolded for some dataset / metric? Why are there two bolded results for MIMIC III \u2013 Accuracy?\nQuestions:\n1 - Interpretability is not inherent to a family of models. For example, a checklist whose features aren\u2019t interpretable or a checklist with too many \u00ab\u00a0checks\u00a0\u00bb to look at (as with linear models) isn\u2019t interpretable either, for the simple knowledge is drowned in the quantity of information to manipulate. Therefore: how is it made sure that the model, concerning those two criteria, remains interpretable?\n2 \u2013 It is argued that decision trees could be of lesser interest when it comes to medical applications. But, the interpretation of a model is part of how the features interact with each other in order to generate a given response. When it comes to checklists, no interaction is presented whatsoever; in the case of decision trees, it is inherent what features need to be looked at carefully given the value of some other feature. Wouldn\u2019t that be more appropriate in the context of medical tasks?\n3 \u2013 It has been briefly discussed that there is an exponential memory complexity intrinsic to the model. Was that a limitation to the experiments that have been run?\n4 - How did it impact the training time? Was that training time similar to the compared approaches? How many hyperpameters are there in total, and when compared to the baselines?\nFlag For Ethics Review:\nYes, Other reasons (please specify below)\nDetails Of Ethics Concerns:\nThis is not a huge \"ethical issue\", but the ICLR24 .tex template was modified, most probably in order to save space (no space before and/or after headings in some places, for example, the titles for Sections 4, 5.3, 6; or table titles, see Table 1).\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal by Authors (1/3)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 05:29Everyone", "Content": "Comment:\nWe thank the reviewer for their valuable comments and insights.\n1 - Interpretability is not inherent to a family of models. For example, a checklist whose features aren\u2019t interpretable or a checklist with too many \u00ab checks \u00bb to look at (as with linear models) isn\u2019t interpretable either, for the simple knowledge is drowned in the quantity of information to manipulate. Therefore: how is it made sure that the model, concerning those two criteria, remains interpretable?\nChecklist with many items:\nHyperparameters $d_k, \\ T and \\ M$ represent the structure/compactness of the checklist. Domain experts will be more equipped to choose these values based on their knowledge of the features. For example, if we are recording a time series feature known to stay stable (not fluctuate much), then low $d_k$ is sufficient. The value of $d_k$ also depends on the number of observations (most blood tests aren\u2019t performed hourly, but heart rate and oxygen saturation are monitored continuously). We encourage the users to select the minimum possible value for $d_k$ to effectively capture all the information. We have performed sensitivity analysis to study the relation between $d_k$ and performance. Figure 3a suggests that the performance saturates after a certain point. This point can be determined experimentally for different modalities. M, total concepts in the checklist, is obtained by pruning concepts that are true for insignificant samples.\nInterpretable Concepts:\nWe refer the reviewer to read the discussion on interpretability of concepts in the global response. We would be happy to answer any further questions.\n2) It is argued that decision trees could be of lesser interest when it comes to medical applications. But, the interpretation of a model is part of how the features interact with each other in order to generate a given response. When it comes to checklists, no interaction is presented whatsoever; in the case of decision trees, it is inherent what features need to be looked at carefully given the value of some other feature. Wouldn\u2019t that be more appropriate in the context of medical tasks?\nDecision trees and checklists are interpretable and widely used in the clinical domain. These models offer different forms of interpretability: checklists provide limited feature interaction, while each path in a decision tree represents a separate checklist.  The main goal of using such models is to automate certain stages of diagnosis/treatment and reduce the burden on the clinicians.\nChecklists, recognized for their robustness, appear as an ideal choice in emergency rooms or scenarios where doctors manage a high volume of patients simultaneously. Their robustness is intrinsically linked to interpretability and can help anticipate hard samples. This avoids poor performance on corner cases, thereby validating the model. We direct the reviewer to Section D of the appendix where we argue the tradeoffs in interpretability between  checklists and decision trees.\n3 \u2013 It has been briefly discussed that there is an exponential memory complexity intrinsic to the model. Was that a limitation to the experiments that have been run?\nWe have provided detailed complexity analysis and training details in the appendix (Section B). Yes, the exponential complexity is the primary reason for performing feature selection and limiting the modalities to 10 and learning up to 3 features per modality. A fruitful future direction would be to study approximations to explore a smaller set of combinations.\n4 - How did it impact the training time? Was that training time similar to the compared approaches? How many hyperpameters are there in total, and when compared to the baselines?\nWe thank the reviewer for this suggestion. We have added a comparison of training times with the MIP checklist method on the PhysioNet Tabular dataset to evaluate the extent of this limitation (Section B of the appendix). It's crucial to highlight that while MIP Checklist performs effectively with tabular data, successfully uncovering the optimal solution, its performance is poor when applied to MNIST synthetic setup. Even when we set the runtime for Gurobi solver as 1 hour, it struggles to achieve optimal solutions for many cases. On the other hand, ProbChecklist stands out as more reliable, capable of performing end-to-end training and successfully learning the optimal solution."}, {"Heading": "Rebuttal by Authors (2/3)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 05:33 (modified: 20 Nov 2023, 05:38)EveryoneRevisions", "Content": "Comment:\n5) Most how the points I would like to raise concern interpretability. (See also the points in the Question section on that matter.)\n5.1 - Interpretability is directly impacted by the complexity of the model itself, but the fact that the algorithm is in itself a black box makes it such that understanding why the model is what it is is unreachable.\nWe refer the reviewer to our discussion on the interpretability of checklist structure and interpretability of learnt concepts in the global response.\n5.2 \u2013 As discussed in [1], p.17, when it comes to logical rules, the more digits there are to take into account, the less the rule is interpretable. One could argue that the checks from Figure 4 aren\u2019t that interpretable. When it comes to the features themselves: what does it really mean to have an \u00ab sd \u00bb of FiO2 above 0.035? It is normal? Is it higher than the average? Is it higher than a certain minimum threshold? Such questions arrises with every check.\nWe transformed the PhysioNet time series dataset (which contains hourly data) into a tabular format by manually extracting features like mean, standard deviation, and final values. This method of feature extraction is extensively employed in clinical machine learning and is acknowledged as one of the most dependable and interpretable techniques in this domain. The standard deviation is particularly effective in capturing fluctuations in a patient's vital signs, with abrupt changes indicating the necessity for specialized care. We also want to clarify that these concepts are probabilistic i.e. \u2018FiO2 > 0.035 with probability 0.5'. We can optimize this probability threshold based on whether the objective is to obtain higher accuracy, AUC-ROC, or F1-Score. We performed experiments by changing the objective, which can be found in Section E.7 of the supplementary material.\n5.3 \u2013 Finally, the interpretation of the features is made in an example where the relationship between the inputs of a problem and the labels is known. The procedure given in order to make sense of the feature extract wouldn\u2019t work if this knowledge was unknown.\nWe direct the reviewer to Figure 1 of the paper, which illustrates the checklist learnt from the medical abstract classification task. As previously explained in the global response, understanding results for NLP tasks is significantly simpler due to the comprehensibility of tokens. We have now included a description of the technique used for generating this checklist in the main paper. While experiments involving the TANGOS regularizer on time series datasets have been conducted, we have presented them in the supplementary section. This decision was made as these results require assessment by domain experts to discern patterns effectively.  Instead, our focus has shifted to the synthetic MNIST dataset, as its known ground truth concepts make it easier to validate our approach. We also discuss the results of the PhysioNet Tabular dataset.\n6) It is shown that the use of the fairness regularizer works in order to minimize both FNR and FPR, but it is not discussed whether or not the constraint impacts the performances of the checklist, so there is no way to truly understand if its usage is really beneficial.\nWe agree with the reviewers assessment that only the difference in FNR/FPR error rates for pairs of sensitive groups is insufficient to gauge the fairness regularizer's effectiveness. It is crucial to ensure that the performance of the majority sensitive group does not deteriorate while the minority groups experience improvements. We have reported the FNR/FPR for each sensitive group before and after the regularizer is applied in Section G of the supplementary material. Most minority subgroups benefit\nfrom this regularization; however, FNR increases for both the Female (minority) and Male (majority)\nsubgroups after regularization. We believe that comparing FNR/FPR for individual subgroups is more apt in this setting and provides more fine-grained/thorough evaluation. We have now included additional results on how the model performance varies after the fairness regularizer is applied."}, {"Heading": "Rebuttal by Authors (3/3)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 05:37 (modified: 20 Nov 2023, 05:41)EveryoneRevisions", "Content": "Comment:\n7) The second contribution states \u00ab We investigate the impact of different schemes for improving the interpretability of the concepts learnt as the basis of the checklist. We employ regularization techniques to encourage the concepts to be distinct, so they can span the entire input vector and be specialized, i.e. ignore the noise in the signal and learn sparse representations. We also investigate the impact of incorporating fairness constraints into our architecture. \u00bb But since (as discussed in 2.1) there lacks evidence of the soundness of the fairness regularizer, combined with the fact that there is no evidence demonstrating that \u00ab regularization techniques encourage the concepts to be distinct, so they can span the entire input vector and be specialized \u00bb (as discussed in 1.4), or at least that the \u00ab different schemes for improving the interpretability of the concepts learned \u00bb truly are responsible for such observations, the soundness of all Contribution 2 can be questioned.\nFairness Regularizer:\nBased on the reviewer\u2019s suggestion, we have provided additional results in the supplementary comparing model performance before and after the fairness regularizer is applied. Previously, we had only presented the FNR/FPR values for each subgroup to show the performance of the majority sensitive group doesn\u2019t deteriorate as a result of the regularization. These results can be found in Section G of the supplementary. We also refer the reviewer to our previous answer discussing the efficacy of the fairness regularizer for more details.\nTANGOS Regularizer:\nThe interpretability of the feature space in deep learning problems can be approached from various angles. The notion of interpretability we have focussed on is that the concepts are distinct and specialized and also span the entire input vector. TANGOS regularization assisted us in achieving this by quantifying the contribution of each input dimension to a particular concept. We examine the gradient of each concept obtained from the concept extractors with respect to the input signal. The TANGOS loss consists of two components: The first component enforces sparsity, emphasizing a concentrated subset of the input vector for each concept. The second component promotes uniqueness, minimizing the overlap between the input subsets from which each concept is derived. Sparsity is achieved by taking the L1-norm of the concept gradient attributions with respect to the input vector. To promote decorrelation of signals learned in each concept, the loss is augmented by incorporating the inner product of the gradient attributions for all pairs of concepts. Additional details about the mathematical formulation of TANGOS have been provided in Section F.1 of the appendix. The desired level of interpretability can be adjusted by varying the relative weights of these terms with respect to the probabilistic checklist objective. In Section F.2, we show how the model performance varies in terms of accuracy, precision and recall by tweaking these weights. The section elegantly captures the trade-off between interpretability and model performance. Furthermore, we plot the images and corresponding gradient attributions heat maps for seven input samples of the Image 2 modality of the MNIST dataset for different combinations of sparsity and correlation regularization terms. This plot can be found in Section F.2 (Figure 5). Similar analysis has also been done for MIMIC Clinical Time Series (Section F.3, Figure 8). It is evident from both these plots that the gradient attributions for both the concepts was identical when TANGOS regularization is not used (i.e \\lambda_sparity = 0 and \\lambda_correlation = 0). As the regularization weights are gradually increased, the gradient attributions start to diverge, yielding distinct concepts. We agree with the reviewer that this assessment relies on visual inspection because it\u2019s hard to quantify interpretability. Nevertheless, a significant advantage of our approach lies in its flexibility, enabling users to experiment with other notions of interpretability tailored to different applications.\nWe also found it easier to interpret our results on NLP Medical Abstract classification without the need of TANGOS regularizer. We represented our learnt checklist in Figure 1. This is because the building blocks of text are tokens which are inherently human understandable, on the other hand it\u2019s much harder to comprehend pixel-level RGB intensities.\nTypos:\nWe thank the reviewer for spotting the typing mistakes. We have proofread the paper carefully and resolved the listed issues."}, {"Heading": "Official Comment by Reviewer SxKf", "Subheading": "Official CommentbyReviewer SxKf20 Nov 2023, 08:55Everyone", "Content": "Comment:\nI thank the authors for their exhaustive response. I am globally satisfied with the answers to my concerns. However, I still think  gradient attributions is insufficient for interpreting the concepts, as said before, for it is one explainability technique that is far from being reliable. Therefore, I see this work relevant in areas where the inputs of the problems are intrinsically interpretable. And even though the scope, from this perspective, is more restrained, the probabilistic approach and the fairness constraints are in themselves valuable contributions; I will raise thus my score. Thank you."}]}]}, "Rd4pGjTcTj": {"paper_info": {"Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "large language model, instruction tuning, multi-turn conversation", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Impressive progress has been made on chat models based on Large Language Models (LLMs) recently; however, there is a noticeable lag in multi-turn conversations between open-source chat models (e.g., Alpaca and Vicuna) and the leading chat models (e.g., ChatGPT and GPT-4). Through a series of analyses, we attribute the lag to the lack of enough high-quality multi-turn instruction-tuning\ndata. The available instruction-tuning data for the community are either singleturn conversations or multi-turn ones with certain issues, such as non-human-like instructions, less detailed responses, or rare topic shifts. In this paper, we address these challenges by introducing Parrot, a highly scalable solution designed to automatically generate high-quality instruction-tuning data, which are then used to enhance the effectiveness of chat models in multi-turn conversations. Specifically, we start by training the Parrot-Ask model, which is designed to emulate real users in generating instructions. We then utilize Parrot-Ask to engage in multiturn conversations with ChatGPT across a diverse range of topics, resulting in a collection of 40K high-quality multi-turn dialogues (Parrot-40K). These data are subsequently employed to train a chat model that we have named Parrot-Chat. We demonstrate that the dialogues gathered from Parrot-Ask markedly outperform existing multi-turn instruction-following datasets in critical metrics, including topic diversity, number of turns, and resemblance to human conversation. With only 40K training examples, Parrot-Chat achieves strong performance against other 13B open-source models across a range of instruction-following benchmarks, and particularly excels in evaluations of multi-turn capabilities. All codes and datasets will be publicly available to facilitate future research.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "pdf", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9266", "PDF Url": "https://openreview.net/pdf?id=Rd4pGjTcTj"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9266 by Area Chair 9p2U", "Subheading": "Meta ReviewbyArea Chair 9p2U06 Dec 2023, 01:17 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper presents an approach to create instruction tuning data for multi-turn interactions, through probing ChatGPT with Parrot-Ask to generate such multi-turn conversational data. This data is then used to train a chat model, called Parrot-Chat, which is shown to perform well according to a set of metrics. The reviewers are mainly concerned about the limited novelty in the paper, this has been raised by even the reviewer who gave the paper the highest score. While the rebuttal includes responses (i.e., explanations, and new experimentation) to questions raised by the reviewers, the limited novelty issue is not sufficiently handled.\nJustification For Why Not Higher Score:\nThe paper has limited novelty, given similar previous works.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9266 by Reviewer tuRa", "Subheading": "Official ReviewbyReviewer tuRa01 Nov 2023, 02:51 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes Parrot, a model trained specifically for simulating a user, on ShareGPT data. The chat model trained with Parrot, Parrot-Chat, outperforms models trained with ChatGPT self-chat data and models trained with ShareGPT data alone.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThis paper is overall well-written and very clear.\nDifferent from Baize/UltraChat, which asks ChatGPT to act like a user in a zero-shot manner, the authors trained a user-simulating model with real user prompts. This model serves as a data augmentation tool, especially for very long dialogue.\nIn contrast to ShareGPT, Baize and UltraChat data, the data generated by Parrot can be very long, which allows long-context alignment. This is promising as the model will suffer less out-of-distribution problems for long-context model, e.g., GPT-4 64k, Claude 100k etc. I recommend the authors to emphasize this strength in their paper.\nWeaknesses:\nThe technical novelty may be limited.\nI'd like to see experiments with long-context models, e.g., Long LLaMA.\nQuestions:\nHow good is Parrot's out-of-domain performance? For example, how good is Parrot for specific domains? Also I'd like to see more examples. Consider adding an appendix for qualitative examples.\nI would like to see discussion/analysis for the hallucinations in the data.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response To Reviewer tuRa Part 1", "Subheading": "Official CommentbyAuthors20 Nov 2023, 02:37 (modified: 20 Nov 2023, 03:04)EveryoneRevisions", "Content": "Comment:\nWe sincerely thank the reviewer for the valuable comments.  We are encouraged by the recognition given to our work. We hope our rebuttal will address the concerns of the reviewer.\nQ1: Novelty.\nWe clarify our novelty and significance to the community in the following aspects:\nwe analyze the issues of existing multi-turn datasets such as non-human-like instructions, less detailed responses, short sessions, or limited topic transitions.\nto overcome these issues, we propose to train an asking model that can simulate user questions and then collect a new multi-turn dataset. The experimental results demonstrate that our dataset surpasses existing datasets in terms of topic diversity, number of turns, and human-likeness.\nwe introduce the new MT-Bench++ benchmark, designed to quantitatively evaluate a model's multi-turn performance. By utilizing our Parrot dataset with more dialogue turns and higher quality, we have enhanced the multi-turn capability of a chat model based on LLaMA-2.\nQ2: Long-context models.\nWe fully recognize that long-context models require long conversations for alignment. However, due to limitations of ChatGPT, such as the 16K token support, as well as the high costs associated with collecting very long dialogues, as an initial research exploration, we have constructed dialogues of up to ten turns, most of which are around 4K in length. We have demonstrated the effectiveness of our methodology for long conversations through sufficient experiments. Given the emergence of more powerful models like GPT-4-Turbo-128K, we believe our methods will be applicable for the alignment of long-context models, and we plan to explore this in the future.\nQ3: Out-of-domain performance.\nMT-Bench has questions across 8 domains. In Table R1, we compare our proposed Parrot-Chat model with OpenAI GPTs and several open-source models across these domains. Although there remains a significant gap compared to GPT-4 overall and across individual domains, our Parrot-Chat-13B model outperforms GPT-3.5-Turbo in the roleplay and humanities domains. Our model also performs the best among all open-source models in 6 out of 8 domains and the second best in the other two domains. In addition, compared to GPT models, big gaps occur in math, coding, and extraction domains. To further enhance performance, we plan to enrich our dataset with more examples in these domains.\nTable R1. Evaluation results of our proposed and baseline chat models in different domains on MT-Bench. We show the average scores in Overall column. Among those open source models, we make the best performance in bold and the second one underlined.\nModel\nWriting\nRoleplay\nReasoning\nMath\nCoding\nExtraction\nStem\nHumanities\nOverall\nGPT-3.5-Turbo\n$9.20$\n$8.40$\n$5.65$\n$6.30$\n$6.90$\n$8.85$\n$8.70$\n$9.55$\n$7.94$\nGPT-4\n$9.65$\n$8.90$\n$9.00$\n$6.80$\n$8.55$\n$9.38$\n$9.70$\n$9.95$\n$8.99$\nBaize-v2-13B\n$7.65$\n$6.80$\n$5.40$\n$1.80$\n$3.00$\n$4.60$\n$7.73$\n$9.03$\n$5.75$\nUltraLM-13B\n$8.15$\n$\\underline{7.25}$\n$4.75$\n$2.60$\n$\\underline{3.45}$\n$5.55$\n$8.00$\n$\\underline{9.55}$\n$6.16$\nVicuna-v1.3-13B\n$\\bf{9.25}$\n$7.18$\n$\\bf{5.85}$\n$2.60$\n$3.25$\n$5.55$\n$7.98$\n$9.45$\n$6.38$\nVicuna-v1.5-13B\n$8.10$\n$8.05$\n$4.15$\n$\\underline{3.45}$\n$3.00$\n$\\underline{6.35}$\n$\\underline{8.50}$\n9.45\n$\\underline{6.57}$\nParrot-Chat-13B\n$\\underline{8.50}$\n$\\bf{8.40}$\n$\\underline{5.50}$\n$\\bf{3.95}$\n$\\bf{3.85}$\n$\\bf{6.55}$\n$\\bf{8.55}$\n$\\bf{9.65}$\n$\\bf{6.81}$"}, {"Heading": "Response To Reviewer tuRa Part 2", "Subheading": "Official CommentbyAuthors20 Nov 2023, 02:39 (modified: 20 Nov 2023, 03:33)EveryoneRevisions", "Content": "Comment:\nQ4: Qualitative examples.\nWe have added an appendix containing qualitive examples, including the model generated responses (\nSection E\n) and examples of our dataset (\nSection G\n). Please refer to the supplementary material.\nQ5: Hallucinations in data.\nOur dataset occasionally exhibits instances of \"hallucinations,\" where ChatGPT generates responses that contain information not aligned with reality. This phenomenon is somehow  unavoidable for now, even in existing datasets such as ShareGPT and UltraChat.\nMore importantly, we have observed that even when ChatGPT generates hallucinatory responses, our Parrot-Ask model can identify mistakes and guide ChatGPT to produce correct responses in subsequent interactions. For example, when ChatGPT initially incorrectly stated that automating the Cisco AnyConnect Secure Mobile Client via a script was not possible, our Parrot-Ask model pointed out that it could be accomplished using C#.  ChatGPT then revised its initial response and provided relevant examples, successfully correcting a hallucination. We have shown more such examples like this in\nAppendix F\n.\nWe find this discovery intriguing, as it suggests that our asking model may have the potential to correct model hallucinations through multi-turn interactions. This is a topic we intend to explore in further detail in the future."}, {"Heading": "Official Comment by Reviewer tuRa", "Subheading": "Official CommentbyReviewer tuRa22 Nov 2023, 00:48Everyone", "Content": "Comment:\nThanks for the reply. I've read the author response and other reviews. I would like to keep my original recommendation."}, {"Heading": "Response To Official Comment by Reviewer tuRa", "Subheading": "Official CommentbyAuthors22 Nov 2023, 21:31Everyone", "Content": "Comment:\nWe are very grateful for the constructive comments you have provided during the review process. Thank you for recognizing our work. We will revise the paper in accordance with the content of the rebuttal. Once again, we sincerely appreciate the effort you have expended."}]}, {"Heading": "Official Review of Submission9266 by Reviewer NNDS", "Subheading": "Official ReviewbyReviewer NNDS31 Oct 2023, 03:12 (modified: 22 Nov 2023, 00:48)EveryoneRevisions", "Content": "Summary:\nIn this paper, the authors propose a solution to generate instruction-tuning data for multi-turn chat. They first train the Parrot-Ask model to generate questions, conditioning on answers and conversational history. Then, they employ Parrot-Ask to interact with GPT-3.5, collecting multi-turn instruction tuning data. The authors utilize the collected Parrot-40K dataset to train a chat model called Parrot-Chat, which outperforms existing datasets in terms of statistics and performs better on instruction-following benchmarks, including MT-Bench++, an extended version of MT-Bench.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nA simple and effective method is proposed to collect multi-turn instruction-tuning data.\nThe collected Parrot-40k datasets show larger average number of turns, token length, topic shifts and transitions than other datasets.\nA new benchmark MT-Bench++ is proposed which is an expansion of MT-Bench where additional six follow-up questions are added.\nExperimental results show that Parrot-Chat achieves the best performance on multiple instruction-following benchmarks over open-source models.\nWeaknesses:\nThe human evaluation part is unclear.\nThe authors do not reveal the structure of the proposed prompts.\nThe authors do not explain how does  the follow-up questions in MT-Bench++ are decided.\nQuestions:\nIt seems that the supplementary materials mentioned at the end of section 4.3 are missing.\nFor human evaluation, how is the criteria defined? And how many annotators are involved? And how about the sample size and inter-agreement?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response To Reviewer NNDS", "Subheading": "Official CommentbyAuthors20 Nov 2023, 03:05 (modified: 20 Nov 2023, 21:58)EveryoneRevisions", "Content": "Comment:\nWe sincerely thank the reviewer for the valuable comments.  We are encouraged by the recognition given to our work. We hope our rebuttal will address the concerns of the reviewer.\nQ1: Details of human evaluation.\nWe utilize the first-turn questions from MT-Bench because it widely covers eight domains, then we employ Parrot-Ask and ChatGPT iterative self-chatting methods (e.g., UltraChat) to collect dialogues of ten-turns, each method generating 800 questions in total. Three annotators are asked to evaluate the quality of these generated questions following these criteria:\nRepetitiveness: Questions should not be repetitive, ensuring each is unique and has some contributions to the conversation.\nConciseness: Questions should be free of unnecessary verbosity, maintaining clarity and brevity.\nPoliteness Patterns: Questions should avoid excessive politeness or expressions of gratitude that are not typically used in natural human questioning.\nRelevance: Questions should be directly related to the previous context or responses, showing a clear understanding of the conversation flow.\nThe result indicates that 81.8% of the questions generated by our Parrot method are human-like and high-quality, while only 36.8% for the iterative self-chatting method. The Kappa among annotators is 0.72, which reaches a high significant level.\nFor ChatGPT self-chatting method (e.g., Baize), we observed that 82.5% of the dialogues would end in a single turn, and fail to generate new turns of dialogues. Therefore, we did not include this method for human evaluation.\nWe will add these important details in the final version of our paper.\nQ2: Proposed prompts.\nWe use the following prompts for the Parrot-Ask model: \"The following is a conversation between a user and an AI assistant. User statements start with [USER] and AI assistant statements start with [ASSISTANT]. You need to tell me what the user is likely to ask in each round of the conversation.\" \nWe have updated an appendix to include this important information (\nSection B\n). Please refer to the supplementary material.\nQ3: Follow-up questions in MT-Bench++.\nWe decide the follow-up questions in MT-Bench++ according to the following standards:\nThe question should be challenging and require AI to perform complex reasoning or rely on wide knowledge to answer.\nThe question should be related to the previous text. Try to reference or imply the content of the previous dialogue in the question.\nThe questions in a session should include appropriate topic transitions.\nWe have updated an appendix to include this important information and provided more examples of MT-Bench++ (\nSection A\n), where we have underscored specific features of the questions such as references, topic transitions, and knowledge requirements. These features are highlighted in blue and accompanied by annotations for clarity. For further details, please refer to the supplementary material.\nQ4: Missing supplementary materials.\nWe apologize for missing the supplementary materials. We have updated an appendix, which introduces more details of MT-Bench++ and evaluations, and more qualitative examples. Please refer to the supplementary material."}, {"Heading": "Official Comment by Reviewer NNDS", "Subheading": "Official CommentbyReviewer NNDS22 Nov 2023, 03:59Everyone", "Content": "Comment:\nThanks for the authors' response! The information provided in the appendix is certainly valuable for understanding the paper. Taking into account the feedback from other reviewers, I will maintain the current score."}, {"Heading": "Response To Official Comment by Reviewer NNDS", "Subheading": "Official CommentbyAuthors22 Nov 2023, 21:32Everyone", "Content": "Comment:\nWe are very grateful for the constructive comments you have provided during the review process. Thank you for recognizing our work. We will revise the paper in accordance with the content of the rebuttal. Once again, we sincerely appreciate the effort you have expended."}]}, {"Heading": "Official Review of Submission9266 by Reviewer sPEb", "Subheading": "Official ReviewbyReviewer sPEb29 Oct 2023, 22:06 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper highlights a gap in multi-turn conversation quality between open-source chat models and state-of-the-art closed source (e.g.,  ChatGPT), attributing it to the lack of high-quality instruction-tuning data. For instance most of existing open-source models are trained with single turn dialogues rather than complex multi-turn or topic switching examples. To address this, the authors introduce \"Parrot,\" a that generates high-quality instruction-tuning data from ChatGPT, leading to the development of \"Parrot-Chat,\" a model that significantly improves multi-turn conversation performance.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nQuality/clarity\nthe paper is overall well written and clear. The figures and tables are easy to follow, and the main methodology is clearly explained.\nthe proposed models outperform existing baselines of the same (or higher) parameter size.\nSignificance\nbuilding an high quality multi-turn conversational datasets is definitely very important for building high-quality models.\nWeaknesses:\nOriginality\nusing ChatGPT generated to train/distill another model has been already widely explored by many other papers. Moreover, it is worth pointing out that using ChatGPT generated dataset has little or no values at this points because: 1) cannot be used for any commercial models, and 2) doesn't unveil how to actually collect high quality datasets.\nQuestions:\ncheck weakness.\nFlag For Ethics Review:\nYes, Legal compliance (e.g., GDPR, copyright, terms of use), Yes, Responsible research practice (e.g., human subjects, data release)\nDetails Of Ethics Concerns:\nThe paper released data from ChatGPT, which might break \"usage and terms\" if not properly licensed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response To Reviewer sPEb", "Subheading": "Official CommentbyAuthors20 Nov 2023, 03:11Everyone", "Content": "Comment:\nWe sincerely thank the reviewer for the valuable comments. We hope our rebuttal will address the concerns of the reviewer.\nQ1: Novelty.\nOur work is different from previous works that train models with ChatGPT-generated data. We clarify our novelty and significance to the community in the following aspects:\nwe analyze the issues of existing multi-turn datasets such as non-human-like instructions, less detailed responses, short sessions, or limited topic transitions.\nto overcome these issues, we propose to train an asking model that can simulate user questions and then collect a new multi-turn dataset. The experimental results demonstrate that our dataset surpasses existing datasets in terms of topic diversity, number of turns, and human-likeness.\nwe introduce the new MT-Bench++ benchmark, designed to quantitatively evaluate a model's multi-turn performance. By utilizing our Parrot dataset with more dialogue turns and higher quality, we have enhanced the multi-turn capability of a chat model based on LLaMA-2.\nQ2: Values of our work.\nAs academic researchers, our primary focus is know-how, e.g., how to mitigate the gap between open source models and the state-of-the-art API models (e.g., GPT-4 and ChatGPT) in multi-turn capability. For this, we indicate that existing multi-turn datasets have some issues and propose to train an asking model to help collecting a multi-turn dataset with superior quality. Our model trained with our dataset show significant improvement on multi-turn capability compared with models trained on ShareGPT, Baize or UltraChat. Our dataset is fully available for faciliting future academic research, akin to UltraChat and Baize.\nMoreover, we believe our proposed method of training a human-like asking model can be applied to generate multi-turn data if using an alternative model that permit commercial usage when necessary. For companies, even in cases where manual annotation is involved in collecting multi-turn data, our asking model can be utilized to enrich topic diversity and prolong the duration of conversation. This ensures that annotators refrain from prematurely ending dialogues or encountering limited topic transitions.\nQ3: Revealing how to collect high-quality dataset.\nWe have delved deeper into the issues present in current multi-turn datasets, such as non-human instructions, less detailed responses, short sessions, or limited topic transitions. Our approach effectively overcomes these issues by employing a specially trained 'asking model' that can promote richer dialogues. This model is designed to simulate user asking, which in turn prompts more human-like questions, longer sessions and broader topics. Through the improved performance of the chat model, manual evaluation and qualitative examples, it is proved that our method can collect higher-quality multi-turn data than existing methods."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 01:03Everyone", "Content": "Comment:\nDear Reviewer sPEb,\nThank you for your valuable feedback during the review process. As the ICLR rebuttal deadline nears, we kindly request your feedback on our responses to ensure we have addressed all concerns. We are ready to provide further clarifications if needed.\nThanks, The Authors"}]}, {"Heading": "Official Review of Submission9266 by Reviewer myqY", "Subheading": "Official ReviewbyReviewer myqY27 Oct 2023, 02:18 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper explores the multi-turn instruction-following capabilities of chat models. The authors propose a method called Parrot-Ask to generate high-quality instruction-tuning data with more human-style instructions. They also introduce a multi-turn evaluation benchmark called MT-Bench++ to assess the performance of chat models. The experiments show that the Parrot-Chat model, trained on the Parrot-Ask data, outperforms other open-source models on various instruction-following benchmarks. The main contributions of the paper include the systematic exploration of multi-turn instruction-following, the development of the Parrot-Ask method, the construction of the MT-Bench++ evaluation benchmark, and the demonstration of the effectiveness of the proposed approach.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper is well-written and clear to read.\nThe proposed method achieves better performance than several strong baselines.\nThe paper identifies the shortage of previous methods (self-chatting and iterative self-chatting) for SFT data generation.\nWeaknesses:\nFor the first contribution the authors claimed, i.e., \"show that a high-quality instruction-tuning dataset plays a key role in empowering the multi-turn instruction-following capabilities of the chat models\", I think this is obvious enough and has been revealed by many previous works. Personally, I don't take it as a \"contribution\".\nThe paper identifies an important shortage of previous methods (self-chatting and iterative self-chatting), but the proposed method lacks intrinsic novelty. I like the idea that we probably need a better model to simulate real human questions; this is interesting, though, but more like an engineering trick, not a scientific research problem.\nIt's very strange to me that the authors \"extend dialogue turns based on the dialogues sampled in ShareGPT\". I think most of the dialogues in ShareGPT are already finished and it is unnatural to \"extend\" such dialogues. Extending such dialogues on purpose could make the generated data longer, but not real.\nThe generated dataset heavily relies on existing two datasets (ShareGPT and UltraChat), the success of Parrot may be largely owing to the high quality of existing datasets.\nIt happens that the performance improvement is because the GPT evaluator prefers the generation that has long content and has multiple rounds of dialogue. I mean the performance is better probably because the model is biased towards generating longer answers, not better answers. Some experiments are needed to further verify this point.\nMinor: given the rapid development of SFT for open-source LLMs, the current SOTA has been leveled to 95%+, even higher than GPT-4. However, the paper only compares relatively weak baselines, I think the author could add several recent baselines to further demonstrate the quality of the proposed dataset.\nQuestions:\nDo you have plans to test on larger version of LLaMA?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response To Reviewer myqY Part 1", "Subheading": "Official CommentbyAuthors20 Nov 2023, 03:30Everyone", "Content": "Comment:\nWe sincerely thank the reviewer for the valuable comments. We hope our rebuttal will address the concerns of the reviewer.\nQ1: Contributions.\nAlthough intuitive, previous works have not provided quantitative evidence to support or verify that chat models' ability to follow multi-turn instructions needs high-quality multi-turn data. Existing evaluation benchmarks like Alpaca Eval only cover single-turn instructions, and MT-Bench is limited to two turns. To the best of our knowledge, we are the first to quantitatively assess the multi-turn capabilities of current chat models and to reveal the gaps between them and GPT-4, ChatGPT. We think this should be considered a contribution.\nQ2: Values of asking model.\nThe evolution of asking models and chat models should progress in parallel, akin to the interplay between the spear and the shield. An asking model that can provide diverse, in-depth, and extensive questions is indeed critical for effectively evaluating chat models, as it challenges them to prove their ability to handle a wide range of topics and ensures that issues of safety are thoroughly tested. A strong asking model can drive the progress of chat models by expanding their capability boundaries and revealing potential areas for improvement. Therefore, it is imperative for the academic community to explore building more powerful asking models that can drive the progression of chat models towards higher levels of reliability, safety, and versatility.\nIn this paper, we propose training an asking model and exploring its application in enhancing the multi-turn capabilities of chat models. Our experimental results reveal that an asking model is capable of generating human-like questions, which can help improve a chat model's multi-turn abilities. Furthermore, we believe that training better asking models will have even more applications in the future.\nQ3: Using ShareGPT.\nWe would like to clarify that the purpose of extending dialogues from ShareGPT is not merely to increase their length, but to enhance their depth and topic diversity. Dialogues in real life do not have predetermined endpoints. In real-life communications, it is common for users to not obtain the information or answers they need in just one round of conversation. They may delve deeper into a topic or transition to related new topics.\nOur method, therefore, employs an asking model specifically trained to generate contextually appropriate and topically relevant questions, thereby ensuring a natural progression of the conversation. When provided with short dialogues from ShareGPT, our asking model is capable of introducing new questions that deepen the existing topic or smoothly transition to a new related one. This is in contrast to the approach of simply concatenating short dialogue sessions, which often results in incoherence and logical inconsistencies [R1]. Our data collection method, therefore, not only increases the length of the dialogues but also improves their depth, and the naturalness of topic transitions.\nFurthermore, the quality of the data collected through our method is tailored to meet the complex requirements of users in multi-turn dialogue scenarios. The resulting data is not just longer; it is richer and more representative of genuine human conversation patterns, enabling the trained model to better understand and respond to users' needs. To vividly demonstrate the effectiveness of our asking model, we have included additional examples from our dataset in the appendix (\nSection G\n).\n[R1] Re3Dial: Retrieve, Reorganize and Rescale Conversations for Long-Turn Open-Domain Dialogue Pre-training, EMNLP 2023."}, {"Heading": "Response To Reviewer myqY Part 2", "Subheading": "Official CommentbyAuthors20 Nov 2023, 03:32Everyone", "Content": "Comment:\nQ4: Relying on existing datasets.\nOur achievement should not be overly attributed to the reliance on existing datasets such as ShareGPT and UltraChat. We incorporated a portion of short dialogues from ShareGPT and initial questions from UltraChat primarily for the purpose of fair comparison and controlled variables during scientific experiments. In practical applications, we can leverage prompts obtained from real users or self-instruct generated instructions as Alpaca, regardless of whether they have subsequent conversations. This flexibility allows our proposed method to generate larger-scale multi-turn data. Furthermore, the experimental results clearly demonstrate that models trained on the Parrot-40K dataset constructed using our approach outperform those trained on ShareGPT-200K and UltraChat-1.5M datasets, thus validating the effectiveness of our methodology.\nQ5: Longer answer bias.\nOur datset has longer examples because of the increased number of turns, not the length of answer in each turn. The length of our model's answer for each question is not significantly different from that of Vicuna. In Table R2, we show detailed the performance of each model, along with the average length of the answers indicated in parentheses. This indicates that our model indeed achieves higher scores due to the answers of better quality.\nTable R2. Comparison with state-of-the-art chat models with answer lengths indicated in parentheses. The answer length is measured in characters following Alpaca-Eval.\nModel\nAlpaca-Eval\nMT-Bench\nMT-Bench++\nGPT-3.5-Turbo\n89.37 (827)\n7.94 (893)\n8.33 (1458)\nGPT-4\n95.28 (1365)\n8.99 (1147)\n9.18 (1081)\nBaize-v2-13B\n66.96 (930)\n5.75 (994)\n5.42 (1077)\nUltraLM-13B\n80.64 (1087)\n6.16 (895)\n5.97 (979)\nVicuna-v1.3-13B\n82.11 (1132)\n6.38 (1066)\n6.24 (1064)\nVicuna-v1.5-13B\n80.74(1066)\n6.57 (1030)\n6.39 (1103)\nParrot-Chat-13B (ours)\n83.42 (1082)\n6.81 (1063)\n6.56 (1157)\nParrot-Chat-70B (ours)\n89.04 (1044)\n7.78 (946)\n7.45 (1087)\nQ6: More baselines.\nWe have compared our work to equitable baselines, such as those without the use of larger models, not optimized with RLHF, open-sourced for reproducibility or with an available API.\nFor the leading models on the Alpaca-Eval leaderboard, RLHF is usually applied, and their responses are significantly longer. In Table R3, we have listed some of the model performances and details from the Alpaca Eval leaderboard. \nWithout the help of RLHF, we fine-tune a Parrot-Chat model with 70B parameters, called Parrot-Chat-70B, solely with SFT on our Parrot dataset. Our Parrot-Chat-70B model substantially improves the performance over our Parrot-Chat-13b model from 83.42 to 89.04, which is near the level of GPT-3.5-Turbo (i.e., ChatGPT). This further validates the strength of our dataset.\nTable R3. Comparison with more baselines on Alpaca Eval.\nModel\nAlpaca-Eval\nAnswer Length\nw/ RLHF\nGPT-4 Turbo\n97.70\n2049\nyes\nXwinLM 70b\n95.57\n1775\nyes\nGPT-4\n95.28\n1365\nyes\nLLaMA2 Chat 70B\n92.66\n1790\nyes\nGPT-3.5-Turbo\n89.37\n827\nyes\nParrot-Chat-70B (ours)\n89.04\n1044\nno\nHumpback LLaMa2 70B\n87.94\n1894\nno\nParrot-Chat-13B (ours)\n83.42\n1082\nno\nQ1.7 Larger version of LLaMa.\nWe fine-tune the LLaMA-2-70B model using our Parrot-40K and achieve better performance, with the results presented in\nTable R2\nand\nTable R3\n."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 01:03Everyone", "Content": "Comment:\nDear Reviewer myqY,\nThank you for your valuable feedback during the review process. As the ICLR rebuttal deadline nears, we kindly request your feedback on our responses to ensure we have addressed all concerns. We are ready to provide further clarifications if needed.\nThanks,\nThe Authors"}]}]}, "bSlAUCyY4T": {"paper_info": {"Supplementary Material": "zip", "Primary Area": "learning on graphs and other geometries & topologies", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Knowledge Graph Completion, Tensor Decomposition, Regularization", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We propose a regularization to alleviate the overfitting problem of tensor decomposition based models for knowledge graph completion.", "Abstract": "Knowledge graph completion (KGC) can be framed as a 3-order binary tensor completion task. Tensor decomposition-based (TDB) models have demonstrated strong performance in KGC. In this paper, we provide a summary of existing TDB models and derive a general form for them, serving as a foundation for further exploration of TDB models. Despite the expressiveness of TDB models, they are prone to overfitting. Existing regularization methods merely minimize the norms of embeddings to regularize the model, leading to suboptimal performance. Therefore, we propose a novel regularization method for TDB models that addresses this limitation. The regularization is applicable to most TDB models, incorporates existing regularization methods, and ensures tractable computation. Our method minimizes the norms of intermediate variables involved in the different ways of computing the predicted tensor. To support our regularization method, we provide a theoretical analysis that proves its effect in promoting low trace norm of the predicted tensor to reduce overfitting. Finally, we conduct experiments to verify the effectiveness of our regularization technique as well as the reliability of our theoretical analysis.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9265", "PDF Url": "https://openreview.net/pdf?id=bSlAUCyY4T"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9265 by Area Chair T1MR", "Subheading": "Meta ReviewbyArea Chair T1MR06 Dec 2023, 06:34 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThere is agreement among reviewers that the paper is clear and well-written and provides an interesting literature survey of existing methods. On the other hand, the reviewers also agree that the paper has a limited contribution and novelty, mostly building up on prior work on KGC or known regularizers. Considering ICLR's standards on novelty and significant, I recommend rejection.\nJustification For Why Not Higher Score:\nThe proposed solution does not seem original or novel enough in the space of KG completion\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9265 by Reviewer TVtg", "Subheading": "Official ReviewbyReviewer TVtg01 Nov 2023, 01:41 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper discusses the tensor-decomposition based (TDB) methods on knowledge graph completion. It proposes a general form to unify previous TDB methods and proposes a new regularization to serve as a upper bound of previous regularizations. The proposed regularization is evaluated on three knowledge graph completion dataset.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n1 poor\nStrengths:\nThe paper is very well-written. The reviewer enjoys reading the paper.\nThe proposed generic form of TDB unifies previous TDB-based KGC methods, which is not significant but a useful summary of the development of TDB-based methods on KGC. It would make the paper more useful if the authors could explain in detail how this generic form could benefit the community.\nThe reviewer appreciates the extensive evaluation on three datasets.\nWeaknesses:\nFirst, the experimental results look marginal. It might indicate that the new regularization is useful to prevent overfitting since it is a upper bound. However, what if we increase the coefficients of regularization in the baseline models? The experimental results does not show the effectiveness of the proposed new regularization.\nSecond, the proposed new regularization lacks motivation. The paper proves that the proposed new regularization is an upper bound of previous overlapped trace norm. However, the motivation of this new proposal is not well justified. Why an upper bound of the regularization is better in the optimization? It does not make sense to me.\nThe loss function in Section 3.2 is not well explained (Sorry, I do not see the parameters in the loss function). What are the parameters? W, H, T? I will assume $X$ indicates both the ground truth tensor value and the parameterized tensor value from W, H, T? Also, in the KGC applications, the loss function should have tensor mask to indicate the observed entries.\nQuestions:\nSee above.\nThe reviewer likes the paper, however, the contributions and the usefulness of the proposal should be elaborated (the current version does not satisfy ICLR bar). I am willing to raise the score for further explanations.\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNA\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 16:41Everyone", "Content": "Comment:\nWe appreciate your careful and constructive comments. We have addressed the questions that you raised as follows. Please let us know if you have any further concerns.\nQ1: Could the authors explain in detail how the general form benefits the community?\nA1: We propose a general form of tensor decomposition based (TDB) models for KGC, which serves as a foundation for further analysis and exploration of TDB models. The general form presents a unified view of TDB models and helps the researchers understand the relationship between different TDB models. Moreover, the general form motivates the researchers to propose new methods and establish unified theoretical frameworks that are applicable to most TDB models. Our proposed regularization and the theoretical analysis are examples of such contributions.\nQ2: What if we increase the coefficients of regularization in the baseline models?\nA2: We have shown the results of experiments with respect to the hyper-parameters in Appendix C. We analyze the impact of the hyper-parameters, the power of the Frobenius norm $\\alpha$ and the regularization coefficient $\\lambda_i$ in Appendix C (Table 6 to Table 9). The results show that the performance generally increases as $\\alpha$/$\\lambda_i$ increases and then decreases as $\\alpha$/$\\lambda_i$ increases. The results indicate the effectiveness of the hyper-parameters.\nQ3: The proposed regularization lacks motivation. Why an upper bound of the regularization is better in the optimization?\nA3: The motivation of our regularization IVR is that we can minimize the Frobenius norms of the intermediate variables (involved in the processes of computing the predicted tensor) to minimize the overlapped trace norm of the predicted tensor. The overlapped trace norm can be a measure of the complexity of the predicted tensor, and minimizing it can regularize the model and prevent overfitting. To establish a theoretical framework for IVR, we prove Lemma 1 in Appendix B, which relates the Frobenius norm and the trace norm of a matrix. Lemma 1 shows that the trace norm of a matrix is an upper bound of a function of several Frobenius norms of intermediate variables. Based on Lemma 1, we prove that IVR serves as an upper bound for the overlapped trace norm of the predicted tensor.\nFrom another view, since computing the trace norm has a high computational complexity of $\\mathcal O(n^3)$, which is impractical for large knowledge graphs, our regularization IVR is composed of several Frobenius norms, which are computationally efficient. We prove that minimizing IVR can effectively minimize the overlapped trace norm, and we also verify this experimentally in Section 4.4. Thus, IVR serves as a good surrogate of the overlapped trace norm.\nQ4: What are the parameters in the loss function?\nA4: We can substitute Eq.(1) into the loss function to see the parameters. The parameters come from two parts, the core tensor $W$ and the embedding matrices $H$, $R$ and $T$. Please refer to Section 3.1 Paragraph \u201cThe Number of Parameters and Computational Complexity\u201d for more details.\nQ5: The loss function should have a mask tensor to indicate the observed entries.\nA5: We do not need a mask tensor to distinguish the observed and unobserved entries. We can treat every observed entry as a positive sample, and every unobserved entry as a negative sample. Then the loss function maximizes the score of the observed entries (i.e., $X_{ijk}$) and minimizes the score of the unobserved entries (i.e., $X_{ijk'}$, where $k'\\neq k$). In other words, the loss function implicitly incorporates the mask tensor. Therefore, we do not need to explicitly use a mask tensor.\nQ6: The contributions and the usefulness of the proposal should be elaborated.\nA6: The main contributions of our paper are in 3 folds:\nWe propose a general form for TDB models, which provides a unified view of existing TDB models and serves as a foundation for further analysis and exploration. You can also refer to A1.\nWe introduce a novel regularization method for TDB models based on our general form to mitigate the overfitting issue. Our regularization method is notable for its generality and effectiveness, as it can be applied to most TDB models and can improve their performance significantly. Previous regularization methods either have poor performance (such as F2) or are not general enough (such as N3 and DURA), while our method overcomes both limitations. Table 1 shows the experimental results that demonstrate the effectiveness and generality of our method.\nWe provide a general theoretical framework for most TDB models in Section 3.3, which proves that our regularization method can promote low trace norm of the predicted tensor, which is known to reduce overfitting. In contrast, N3 and DURA only provide theoretical analysis for models based on CP decomposition, which limits their applicability. You can also refer to A3."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 09:48 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nThanks again for your constructive comments. We appreciate your time and effort in reviewing our paper. As the discussion deadline is near, we sincerely look forward to your further feedback. If our responses do not address your concerns, we are prepared to provide more comprehensive responses if necessary. Alternatively, if you find that our responses have effectively addressed your concerns, can you give us feedback? Your feedback is crucial to us. We look forward to hearing from you."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 10:36 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nDear reviewer:\nThank you for your careful comments again. Since today marks the final day of discussion, we kindly request once again for your feedback and comments.  As shown in your comment \"I am willing to raise the score for further explanations.\", we sincerely look forward to your further feedback. If you find that our responses have effectively addressed your concerns, can you give us feedback? Your feedback is crucial to us. We apologize for any inconvenience caused."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:53 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nThanks again for your constructive comments. We thank you for your appreciation for our paper, as shown in your comments \"The reviewer likes the paper\" and \"I am willing to raise the score for further explanations.\". As the author-reviewer discussion period closes, we are unable to provide further explanation. We sincerely hope that the reviewer can read our rebuttal and raise our score at the AC-reviewer discussion period."}]}, {"Heading": "Official Review of Submission9265 by Reviewer Bhgm", "Subheading": "Official ReviewbyReviewer Bhgm31 Oct 2023, 15:02 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe knowledge graph (KG) can be represented as a 3-way tensor. Hence, the knowledge graph completion can be naturally formed as a tensor completion task. In this paper, the author provided an overview of the tensor decomposition-based (TDB) models and derived a general form which is the summation of $D/P$ Tucker decompositions with shared core tensor $\\boldsymbol{W} \\in \\mathbb{R}^{P \\times P \\times P}$. The main contribution of this paper is the proposed regularization term, which is applicable to the `general form' they proposed, by incorporating the existing regularization methods. The author claims that their novel regularization term minimizes the norms of intermediate variables for promoting low trace norm of predicted tensor. The theoretical analysis and experiments were provided to verify their claim.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nStrengths:\nEasy to read.\nThey provided numerical experiments on different datasets and methods.\nWeaknesses:\nWeaknesses:\nThe main focus should be the regularization term they proposed instead of the general form. The weakness is novelty and significance, which is limited by my point of view.\nFor the theoretical side, the nuclear p-norms and squared F-norm methods were well-studied. It's not a surprise that Equation 4 can generalize these, and this is not new. As the author claimed, they incorporated the N3 norm and DURA, where some of the analysis was established. Their weight IVR norm is not theoretically novel and significant. Could the author clarify what is the unique hardness and novelty of this proposed IVR norm?\nFor the experiment side, as the author claimed in the paper, their method promotes low rank. Do you actually see the zero columns in the factors, compared to the existing method?\nQuestions:\nMy question was put in the weakness section.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 16:53Everyone", "Content": "Comment:\nWe appreciate your careful and constructive comments. We have addressed the questions that you raised as follows. Please let us know if you have any further concerns.\nQ1: The main focus should be the regularization term they proposed instead of the general form.\nA1: We agree that the main contribution of our paper is the regularization term, but we also argue that the general form is necessary, as it serves as a foundation for our further analysis. Without the general form, we cannot guarantee the generality of our regularization term and the theoretical analysis, as they depend on the unified view of the TDB models provided by the general form.\nQ2: Their weight IVR norm is not theoretically novel and significant. Could the author clarify what is the unique hardness and novelty of this proposed IVR norm?\nA2: Our proposed regularization is notable for its generality and effectiveness, as it can be applied to most TDB models and can improve their performance significantly. Although some of the theoretical analysis was established for F2, N3 and DURA, it is still challenging to design a regularization method that has both the properties of generality and effectiveness. As previous regularization methods either have poor performance (such as the F2 norm method, which achieves suboptimal results) or are not general enough (such as the N3 norm method and the DURA method, which are only suitable for CP and ComplEx models), while our method overcomes both limitations. Table 1 shows the experimental results that demonstrate the effectiveness and generality of our method. Our method can be applied to various TDB models, such as CP, ComplEx, SimplE, ANALOGY, QuatE, TuckER, etc., and achieve SOTA results. For example, TuckER with our method achieves new SOTA results on the WN18RR dataset.\nMeanwhile, we provide a general theoretical framework for most TDB models in Section 3.3, which proves that our regularization method can promote low trace norm of the predicted tensor, which is known to reduce overfitting. Previous works only provide theoretical analysis for CP and ComplEx models, which limits their applicability. We discover the relationship between the overlapped trace norm and our proposed IVR regularization, and show that IVR serves as an upper bound for the overlapped trace norm. We also verify the validity of our theoretical analysis experimentally in Section 4.4. You can also refer to A3 of the rebuttal for Reviewer TVtg.\nQ3: For the experiment side, as the author claimed in the paper, their method promotes low rank. Do you see the zero columns in the factors, compared to the existing methods?\nA3: We argue that a low rank matrix does not necessarily imply sparse embeddings, as a low rank matrix can have non-zero columns. For example, consider a matrix $X$ whose entries are all 1. The rank of $X$ is 1, but $X$ has no zero columns. Therefore, a better metric to measure the rank of a matrix is the overlapped trace norm, which is a convex surrogate of the rank. We experimentally verify that minimizing our proposed regularization can effectively minimize the overlapped trace norm $L(X)$ in Section 4.4. To make the experiments more detailed, we further show the results of different regularizations in the following Table 1, which demonstrate that our method is better at promoting low rank than other methods.\nTable 1: The results on Kinship dataset with different regularizations. Larger MRR and lower L(X) are better.\nMRR\nL(X)\nCP\n0.894\n26439\nCP-F2\n0.900\n25934\nCP-N3\n0.900\n21801\nCP-DURA\n0.901\n18641\nCP-IVR\n0.907\n15366\nWe further analyze the sparsity of embeddings induced by different regularizations as below. Generally, there are few entries of embeddings that are exactly equal to 0 after training, which means that it is hard to obtain sparse embeddings directly. To get sparse embeddings, we can set a proper threshold and set the absolute value of the embedding entries less than the threshold to be exactly 0. Denote the ratio of zero entries as $\\alpha$, then we can compare the performance of different models under the same $\\alpha$. The following Table 2 shows that our regularization CP-IVR can achieve better performance than other regularizations under the same sparsity circumstance.\nTable 2: The MRR results of models with different sparsity. Larger MRR is better.\n$\\alpha$\n0%\n20%\n40%\n60%\n80%\nCP\n0.438\n0.438\n0.431\n0.420\n0.388\nCP-F2\n0.449\n0.449\n0.447\n0.445\n0.424\nCP-N3\n0.469\n0.468\n0.465\n0.457\n0.426\nCP-DURA\n0.471\n0.471\n0.469\n0.465\n0.440\nCP-IVR\n0.478\n0.478\n0.475\n0.471\n0.445"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 09:48 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nThanks again for your constructive comments. We appreciate your time and effort in reviewing our paper. As the discussion deadline is near, we sincerely look forward to your further feedback. If our responses do not address your concerns, we are prepared to provide more comprehensive responses if necessary. Alternatively, if you find that our responses have effectively addressed your concerns, can you give us feedback? Your feedback is crucial to us. We look forward to hearing from you."}, {"Heading": "Response to the author", "Subheading": "Official CommentbyReviewer Bhgm20 Nov 2023, 10:36Everyone", "Content": "Comment:\nThe reviewer thanks the author for the clarification. \nFor the Q3, I believe for the CPD, since it's constraining rank-one tensors, you should see zero columns in the factors if you actually promote low-rank."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 20:46 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nThanks again for your constructive comments.\nQ1: For the Q3, I believe for the CPD, since it's constraining rank-one tensors, you should see zero columns in the factors if you actually promote low-rank.\nA1: Due to the optimization method we use, it is unlikely that we will obtain factors with $\\textbf{exactly}$ zero columns. Our optimization method is based on the stochastic gradient descent (SGD) method, which works as follows:\nWe randomly initialize the factors.\nWe update the values of the factors based on the corresponding gradients.\nWe stop the optimization process according to the evaluation results on the validation set. We do not aim to minimize the loss to $\\textbf{exactly}$ zero, as this would imply overfitting.\nTherefore, after optimization, the factors may not have $\\textbf{exactly}$ zero columns. However, we can show that our regularization method effectively promotes low trace norm from three aspects.\nAs we stated in the A3 of our previous response, the overlapped trace norm is a better metric to measure the rank, as it is a convex surrogate of the rank. Table 1 shows that our method CP-IVR achieves the lowest value of the overlapped trace norm. This indicates that our regularization method is more effective at promoting low trace norm than other methods.\nAs we stated in the A3 of our previous response, to obtain sparse factors, we can set a proper threshold and set the absolute value of the entries of factors below the threshold to zero. Then, we can compare the performance of different models under the same sparsity level. Table 2 shows that our regularization CP-IVR can achieve better performance than other regularizations under the same sparsity level.\nTo see the zero columns, we can set a proper threshold and set the columns of factors to zero if the norm of the columns is below the threshold. We can then calculate the ratio of zero columns for different thresholds. The following table shows that our regularization method CP-IVR has the highest ratio of zero columns.\nIn summary, our regularization method effectively promotes low trace norm.\nTable: The ratio of zero columns for different thresholds.\n0.20\n0.25\n0.30\nCP\n69.6%\n89.4%\n96.9%\nCP-F2\n74.0%\n98.3%\n99.6%\nCP-N3\n76.1%\n97.3%\n99.5%\nCP-DURA\n77.5%\n79.6%\n81.1%\nCP-IVR\n78.3%\n99.2%\n99.6%\nWe modify this comment as follows:\nWe do $\\textbf{not}$ claim that our regularization promotes the low rank in our paper. We claim that our regularization term promotes the low trace norm. There is a slightly difference between these two claims. The trace norm is different to the rank, which is widely used as a convex surrogate for the rank."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 10:43 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nDear reviewer:\nThank you for your careful comments again. Since today marks the final day of discussion, we kindly request once again for your feedback and comments. It seems that we have adreesed all your concerns except the Q3. We have responsed the Q3 on the above comment. Our response is very brief, it will not take up too much of your time. If you find that our responses have effectively addressed your concerns, can you give us feedback? Your feedback is crucial to us. We apologize for any inconvenience caused."}, {"Heading": "Response to the author", "Subheading": "Official CommentbyReviewer Bhgm21 Nov 2023, 11:17 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nThe reviewer thanks the author for the effort of responsive clarification. \nFor the theoretical side, the reviewer still holds the opinion that theoretical significance and novelty are marginal.\nFor the experiment side, the reviewer admits that the method shows better results using the metric of overlapped trace norm, although concern in Q3 about actual verification for low-rank CPD results is not resolved. It's more general but the effectiveness still needs to be verified.\nOverall, the reviewer would like to keep the current score and leave the decisions to the AC."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 00:33 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nThank you for your detailed response. We respect your opinion very much, but you may have some misunderstandings about Q3. In our paper, we claim that \"Our regularization term promotes the low trace norm of the predicted tensor to regularize the model.\"  The trace norm is widely used as a convex surrogate for the rank, which can be seen as a $\\textbf{soft}$ version of the rank. We experimentally verify that our regularization promotes the low trace norm  in Section 4.4. We do $\\textbf{not}$ actually claim that our regularization promotes the low rank in our paper. You can $\\textbf{not}$ even find any place where the word \"low rank\" exists in our paper."}]}, {"Heading": "Official Review of Submission9265 by Reviewer e2Qz", "Subheading": "Official ReviewbyReviewer e2Qz30 Oct 2023, 11:05 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper addresses the issue of overfitting in Tensor Decomposition-based (TDB) models used in Knowledge Graph Completion (KGC), where existing regularization methods, focused on minimizing the norms of embeddings, have led to suboptimal performance. A novel regularization method is proposed that minimizes the norms of intermediate variables involved in computing the predicted tensor, enhancing most TDB models by incorporating existing regularization techniques and ensuring tractable computation. Moreover, extensive evaluation verifies the effectiveness and superiority of the model.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe authors propose a new KGC framework, establishing a general form to serve as a foundation for further TDB model analysis. which aims to tackle the issue of overfitting in Tensor Decomposition-based models.\nThe authors provide a detailed theoretical analysis, e.g., showing the ability for its generality and effectiveness, which guarantees the validity of the method.\nWeaknesses:\nThe paper is not organized clearly, which is not friendly for understanding. For instance, there are lack of an intuitive explanation for how this method can mitigate the overfitting issue.\nThe regularization approach as shown in Eq.(4) is too complex to use. Moreover, this paper miss some strong baselines such as [1][2]\n[1] Low-Dimensional Hyperbolic Knowledge Graph Embeddings\n[2] ER: equivariance regularizer for knowledge graph completion\nQuestions:\nPlease refer to the weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 16:59Everyone", "Content": "Comment:\nWe appreciate your careful and constructive comments. We have addressed the questions that you raised as follows. Please let us know if you have any further concerns.\nQ1: The paper is not organized clearly, which is not friendly for understanding. For instance, there are lack of an intuitive explanation for how this method can mitigate the overfitting issue.\nA1: We have explained the intuition of our regularization from two perspectives. Previous works only minimize the norms of the embeddings to prevent overfitting, while our proposed regularization IVR minimizes the norms of the intermediate variables involved in the processes of computing the predicted tensor, which can further reduce the complexity of the model to prevent overfitting.\nFrom the perspective of theoretical analysis, we further propose a theoretical framework to explain how the model mitigate the overfitting issue. We prove that our regularization IVR can minimize the Frobenius norms of the intermediate variables to minimize the overlapped trace norm of the predicted tensor as shown in Section 3.3. The overlapped trace norm can be a measure of the complexity of the predicted tensor, and minimizing it can regularize the model and prevent overfitting. We first prove Lemma 1 in Appendix B, which relates the Frobenius norm and the trace norm of a matrix. Lemma 1 shows that the trace norm of a matrix is an upper bound of a function of several Frobenius norms of intermediate variables. Based on Lemma 1, we then prove that IVR serves as an upper bound for the overlapped trace norm of the predicted tensor, which promotes the low nuclear norm of the predicted tensor to regularize the model, which is known to reduce overfitting.\nWe will make this statement clearer in the revision. And we want to highlight that the other three reviewers appreciate the clarity of our paper. We welcome any suggestions to improve the organization of our paper further.\nQ2: The regularization approach as shown in Eq.(4) is too complex to use.\nA2: Our regularization IVR is not complex to use. First, IVR is composed of several Frobenius norms of variables, which are simple to compute. Second, we provide a pseudocode for computing IVR in Appendix C. The pseudocode shows that IVR can be computed incidentally during the process of computing the predicted tensor $X$. Third, we also provide a source code for IVR in the Supplementary Material. The model.py file shows that the implementation of IVR is concise and straightforward. In summary, IVR is not complex to use and implement.\nQ3: This paper misses some strong baselines such as [1][2]. [1] Low-Dimensional Hyperbolic Knowledge Graph Embeddings. [2] ER: equivariance regularizer for knowledge graph completion.\nA3: In this paper, we mainly focus on tensor decomposition-based (TDB) models, which have wide applicability and great performance in knowledge graph completion. Therefore, we mainly include the TDB models as baselines for fair comparison. We will make the baselines more complete in the revision.\nWe would like to emphasize the main contributions of our paper as follows:\nWe propose a general form for TDB models, which provides a unified view of existing TDB models and serves as a foundation for further analysis and exploration.\nWe introduce a novel regularization method for TDB models based on our general form to mitigate the overfitting issue. Our regularization method is notable for its generality and effectiveness, as it can be applied to most TDB models and can improve their performance significantly. Previous regularization methods either have poor performance (such as F2) or are not general enough (such as N3 and DURA), while our method overcomes both limitations. Table 1 shows the experimental results that demonstrate the effectiveness and generality of our method.\nWe provide a general theoretical framework for most TDB models in Section 3.3, which proves that our regularization method can promote low trace norm of the predicted tensor, which is known to reduce overfitting. In contrast, N3 and DURA only provide theoretical analysis for models based on CP decomposition, which limits their applicability."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 09:49 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nThanks again for your constructive comments. We appreciate your time and effort in reviewing our paper. As the discussion deadline is near, we sincerely look forward to your further feedback. If our responses do not address your concerns, we are prepared to provide more comprehensive responses if necessary. Alternatively, if you find that our responses have effectively addressed your concerns, can you give us feedback? Your feedback is crucial to us. We look forward to hearing from you."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors21 Nov 2023, 10:48 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nDear reviewer:\nThank you for your careful comments again. Since today marks the final day of discussion, we kindly request once again for your feedback and comments. We appreciate your time and effort in reviewing our paper. Since our response for your concerns is brief, it will not take up too much of your time. If you find that our responses have effectively addressed your concerns, can you give us feedback? Your feedback is crucial to us. We apologize for any inconvenience caused."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:56 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nThanks again for your constructive comments. We appreciate your time and effort in reviewing our paper. We would like to further emphasize two points of our paper:\nOur paper is organized clearly as shown in the comments of other three reviewers. Reviewer TVtg comments \"The paper is very well-written. The reviewer enjoys reading the paper.\"\nReviewer Bhgm comments \"Easy to read.\". Reviewer YFRf comments \"The article is well-structured with detailed analysis and clear logic. The language is fluent and reader-friendly.\"\nOur regularization is easy to use and implement as shown in the  pseudocode in Appendix C and the code in the Supplementary Material.\nAs the author-reviewer discussion period closes, we are unable to provide further explanation. We sincerely hope that the reviewer can read our rebuttal and raise our score at the AC-reviewer discussion period."}]}, {"Heading": "Official Review of Submission9265 by Reviewer YFRf", "Subheading": "Official ReviewbyReviewer YFRf29 Oct 2023, 22:54 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nTensor Decomposition-Based (TDB) models have been quite successful in the field of KGC. Despite the effectiveness of TDB models, they are susceptible to overfitting. Existing regularization methods typically focus on minimizing the norms of embeddings to control the model, resulting in suboptimal performance. To overcome this limitation, the authors introduce a novel regularization method tailored for TDB models. This regularization method can be applied to most TDB models, seamlessly integrating existing regularization techniques while maintaining computational efficiency.\nThe core of this method involves minimizing the norms of intermediate variables used in various ways to compute the predicted tensor. To support their proposed regularization approach, the authors provide a theoretical analysis that demonstrates its effectiveness in reducing overfitting by promoting a low trace norm of the predicted tensor.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThe article is well-structured with detailed analysis and clear logic. The language is fluent and reader-friendly. The new regularization approach for TDB models demonstrates good performance.\nWeaknesses:\nThe first contribution, which is a detailed overview of a wide range of TDB models, is somewhat limited in its actual content.\nThe experimental results could benefit from a more comprehensive comparison involving additional metrics such as efficiency and time-related measures.\nQuestions:\nCould the authors further explain the difference between IVR and IVR-3 in Table 3? Need to clarify the metrics in the experiments. What do the results mean, like accuracy, error, or anything else?\nUnclear meaning of the notation of (i, j, ?) above Section 3.3.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 17:06Everyone", "Content": "Comment:\nWe appreciate your careful and constructive comments. We have addressed the questions that you raised as follows. Please let us know if you have any further concerns.\nQ1: The first contribution, which is a detailed overview of a wide range of TDB models, is somewhat limited in its actual content.\nA1: We propose a general form of tensor decomposition based (TDB) models for KGC, which serves as a foundation for further analysis and exploration of TDB models. The general form presents a unified view of TDB models and helps the researchers understand the relationship between different TDB models. Moreover, the general form motivates the researchers to propose new methods and establish unified theoretical frameworks that are applicable to most TDB models. Our proposed regularization method and the theoretical analysis in Section 3.3 are examples of such contributions.\nQ2: The experimental results could benefit from a more comprehensive comparison involving additional metrics such as efficiency and time-related measures.\nA2: We present more detailed experimental results in Appendix C. Since these regularizations are all composed of $L^p$ norms, which are all efficient, they do not affect the model efficiency significantly. The most important factor that affects the model efficiency is the number of parts $P$. Since models with different regularizations have the same value of $P$, we do not need to compare their efficiency.\nAs we discussed in Section 3.1 Paragraph \u201cThe Number of Parameters and Computational Complexity\u201d, the computational complexity is related to the number of parts $P$. We further provide an efficiency analysis in Appendix C Paragraph \u201cThe Number of Parts\u201d. The results show that the model performance generally improves and the running time generally increases as P increases. Thus, the larger the part $P$, the more expressive the model and the more the computation.\nQ3: Could the authors further explain the difference between IVR and IVR-3 in Table 3?\nA3: We defined IVR-3 and IVR as two variants of Eq.(4) with different constraints on the regularization coefficients $\\lambda_{i}$ in Section 3.2. Specifically, IVR is Eq.(4) with the constraint $\\lambda_{1}=\\lambda_{3}, \\lambda_{2}=\\lambda_{4}$, while IVR-3 is Eq.(4) with the constraint $\\lambda_{1}=\\lambda_{2}=\\lambda_{3}=\\lambda_{4}$. Therefore, IVR has two degrees of freedom in choosing the regularization coefficients, while IVR-3 has only one.\nQ4: Need to clarify the metrics in the experiments. What do the results mean, like accuracy, error, or anything else?\nA4: We have provided more detailed experimental results in Appendix C, including the evaluation in the second paragraph of Appendix C. The evaluation metrices is commonly used in KGC. Besides, we analyze the impact of random initialization, the impact of the hyper-parameters and the number of parts in Appendix C.\nQ5: Unclear meaning of the notation of (i, j, ?) above Section 3.3.\nA5: We use the notation $(i, j, ?)$ to represent a query that asks for the most likely tail entities given a head entity $i$ and a relation $j$. This notation is commonly used in knowledge graph completion tasks. We will make the notation clearer in the revision."}, {"Heading": "Official Comment by Reviewer YFRf", "Subheading": "Official CommentbyReviewer YFRf22 Nov 2023, 11:43Everyone", "Content": "Comment:\nI appreciate your efforts in addressing my concerns."}]}]}, "ukmh3mWFf0": {"paper_info": {"Primary Area": "learning on graphs and other geometries & topologies", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Graph Clustering, Graph Neural Networks, Convex Optimization, Non-Convex Optimization, Graph Coarsening", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "A novel unsupervised framework incorporating modularity with important graph coarsening regularization terms to improve clustering (via coarsening).", "Abstract": "Graph clustering is a widely used technique for partitioning graphs, community detection, and other tasks. Recent graph clustering algorithms depend on combinations of the features and adjacency matrix, or solely on the adjacency matrix. However, in order to achieve high-quality clustering, it is necessary to consider all these components. In this paper, we propose a novel unsupervised learning framework that incorporates modularity with graph coarsening techniques and important graph regularization terms that improve the clustering performance. Furthermore, we also take into account Dirichlet energies for smoothness of signals, spectral similarity, and coarsening reconstructional error. The proposed framework is solved efficiently by leveraging block majorization-minimization, $\\log\\det$ of the Laplacian, smoothness and modularity, and is readily integrable with deep learning architectures such as GCNs and VGAEs in the form of losses. Extensive theoretical analysis and experiments with benchmark datasets elucidate the proposed framework\u2019s efficacy in graph clustering over existing state-of-the-art methods on both attributed and non-attributed graphs.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "pdf", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9264", "PDF Url": "https://openreview.net/pdf?id=ukmh3mWFf0"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9264 by Area Chair izzF", "Subheading": "Meta ReviewbyArea Chair izzF05 Dec 2023, 16:18 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper introduces a new algorithm for graph clustering based on the combination of modularity and graph coarsening. In particular, the paper introduces a new GNN architecture that captures together graph coarsening and modularity insights.\nThe paper contains some interesting ideas but it is not ready for publication. More specifically, several important concerns have been raised during the review period:\nthe proposed method is not particularly novel\nthe paper is a bit too dense and it is hard to read\nthe experimental results are a bit unconvincing\nOverall, the paper has some merits but it is below the ICLR acceptance bar\nJustification For Why Not Higher Score:\nThe paper has some important limitations listed above and it is not ready for being published\nJustification For Why Not Lower Score:\nN / A"}, {"Heading": "Official Comment", "Subheading": "Official Commentby22 Nov 2023, 11:31 (modified: 22 Nov 2023, 11:37)EveryoneRevisions", "Content": "[Deleted]"}, {"Heading": "Official Review of Submission9264 by Reviewer iqpP", "Subheading": "Official ReviewbyReviewer iqpP01 Nov 2023, 06:16 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nA new graph clustering method is proposed that combines graph coarsening with a modularity regularization term. They show how the objective can be optimized within a GNN-based architecture. They show experiments that show that the method performs well on several datasets.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThe paper combines many machine learning techniques.\nThe resulting method seems to outperform existing methods in the experiments.\nWeaknesses:\nI don't know whether this paper is intended to be read by people from the field of community detection, but I can confirm that this paper is very hard to understand for someone with that background.\nThe introduction gives a bad overview of community detection. It does not refer to a good reference for modularity [1]. And it mentions that \"In theory, a higher value of modularity is associated with better quality clusters.\", which is a puzzling statement because modularity is a heuristic that does not have a strong theoretical underpinning. In addition, the paper mentions that the usage of modularity maximization has \"plummeted over the years because they rely solely on the topological information\", which I don't think is the case. Modularity maximization is still one of the most widely-used community detection methods, despite theoretical shortcomings [2,3]. Finally, it is mentioned that modularity maximization \"requires intensive computations\", but the Louvain algorithm runs in nearly linear time, and you can't really go faster than that.\nThe \"Deep Graph Clustering\" paragraph of the introduction is incredibly difficult to understand. It uses a lot abbreviations like ARGA, ARVGA, DAEGC, SDCN that are not (properly) introduced. After reading it, I still have no idea what is meant with \"Deep graph clustering\".\nThe NMI measure is biased towards fine-grained clusterings [4], while ARI also has its disadvantages [5]. I would recommend to use AMI and/or the correlation coefficient to measure the similarity between clusterings [5].\nThe paper contains many typo's, language and notation errors.\nThey refer to Supplementary D for a summary of the datasets, but Supplementary D does not describe datasets at all.\n[1] Newman, M. E., & Girvan, M. (2004). Finding and evaluating community structure in networks. Physical review E, 69(2), 026113.\n[2] Fortunato, S., & Barthelemy, M. (2007). Resolution limit in community detection. Proceedings of the national academy of sciences, 104(1), 36-41.\n[3] Peixoto, T. P. (2023). Descriptive vs. inferential community detection in networks: Pitfalls, myths and half-truths. Cambridge University Press.\n[4] Vinh, N. X., Epps, J., & Bailey, J. (2009, June). Information theoretic measures for clusterings comparison: is a correction for chance necessary?. In Proceedings of the 26th annual international conference on machine learning (pp. 1073-1080).\n[5] G\u00f6sgens, M. M., Tikhonov, A., & Prokhorenkova, L. (2021, July). Systematic analysis of cluster similarity indices: How to validate validation measures. In International Conference on Machine Learning (pp. 3799-3808). PMLR.\nQuestions:\nWhat is the difference between graph clustering, community detection and graph coarsening? The way I understand it, community detection is merely clustering of graph nodes based on the graph topology. Graph coarsening (as described in this paper) seems to be similar to blockmodeling [1]. At any rate, the differences between these three things (that seem to be combined in this paper), need to be clearly explained.\nThe method makes use of the constraint $X=C\\tilde{X}$. If we substitute this constraint into the first term of (5), it would simplify to\n$\\text{tr}(\\tilde{X}^\\top C^\\top\\Theta C\\tilde{X})=\\text{tr}(X^\\top\\Theta X)$, which would simplify the optimization significantly. However, instead of enforcing this constraint exactly, the paper simply introduces an error term $|X-C\\tilde{X}|$, which seems unelegant to me. Why don't you enforce this constraint exactly?\nYou mention that the log determinant term can be written as the sum of the log of the eigenvalues, and that this ensures that a 'minimal' number of eigenvalues are zero. However, doesn't this ensure that\nnot a single\neigenvalue is zero?\nIs the complexity that is described in the \"Complexity analysis\" paragraph the complexity of a single iteration or of all the iterations until convergence?\nI see that you rescaled the NMI, ARI and modularity to percentages. This is okay for NMI (though I'm not a fan of it), but for ARI it is confusing because ARI can be negative. For modularity, I have no idea how this rescaling is done, because the upper bound of modularity is smaller than 1 (and incredibly expensive to compute).\nWhy do you draw lines in Figure 2b instead of making a table? The points that are connected don't correspond to consecutive things.\n[1] Peixoto, T. P. (2019). Bayesian stochastic blockmodeling. Advances in network clustering and blockmodeling, 289-332.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reply to Reviewer's Comment (1/2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 03:07 (modified: 20 Nov 2023, 06:30)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewer for their appreciation and concern for our paper. We will do our best to resolve them.\nWeaknesses\nBad overview of community detection. It mentions \"In theory, a higher value of modularity is associated with better quality clusters.\", which is puzzling because modularity does not have a theoretical underpinning. Paper mentions that usage of modularity maximization has \"plummeted over the years because they rely solely on the topological information\", which I don't think is the case, is still one of the most widely-used community detection methods, despite theoretical shortcomings. Finally, it is mentioned that modularity maximization \"requires intensive computations\", but the Louvain algorithm runs in nearly linear time.\nWe have added a reference to (Newman, 2006) in the introduction. We refer the reviewer to the same (Newman, 2006) literary work introducing modularity, in which he states (quoted directly from Section 3 just after Eqn 17 referring to\nhttps://arxiv.org/pdf/physics/0605087.pdf\n)\nThis benefit function is called modularity. It is a function of the particular division of the network into groups, with larger values indicating stronger community structure. Hence we should, in principle, be able to find good divisions of a network into communities by optimizing the modularity over possible divisions.\nWe have added another mention on the drawbacks of modularity as requested.\nModularity maximization methods such as the Louvain and Leiden algorithms have been usually superseded by GNN based which take important node features into account, especially in social network analysis. We are not saying that they are anywhere near obsolete - just that for a wide range of graph applications, node features are very important.\nWe were talking about the modularity maximization algorithms given by Girvan and Newman here which took $O(n^3)$ time, and not about Louvain/Leiden algorithms. There is no known complexity of the Louvain algorithm, with some papers claiming it to be $\\mathcal{O}(n \\log n)$, while some claim it to be $\\mathcal{O}(e)$, although only on sparse graphs. We have clarified this in the paper.\n\"Deep Graph Clustering\" paragraph is difficult to understand. Uses abbreviations like ARGA, ARVGA, DAEGC, SDCN that are not (properly) introduced.\nThose are the abbreviations used by existing literature and that is why references have been provided for all of the mentioned methods. Unfortunately, It is not feasible to explain each method there as that itself would take a major portion of the strict 9-page space constraint, leaving no space for theory, method/optimization/architecture, results and ablation studies.\nThe NMI measure is biased towards fine-grained clusterings, while ARI also has its disadvantages. I would recommend to use AMI and/or the correlation coefficient to measure the similarity between clusterings\nWe did consider this in the initial phase. However, the papers we compare our work with all take the primary metric as NMI. It is also given in the reference you mentioned [5] that AMI as well has its drawbacks, such as not following the distance property and not having linear complexity, whereas NMI does (and we perform experiments on large graphs as well, so complexity is a concern for us). However, we will look into the Correlation Distance measure for future works since it satisfies the properties we need.\nThank you for this contribution!\nSupplementary D does not describe datasets; typos.\nSupplementary Material D does describe datasets. We have added a missing reference to it's Table 2 since it got moved to the next page, which contains the dataset summaries. As for typos, we have tried to fix the ones we could find.\n(Continued in 2/2)"}, {"Heading": "Reply to Reviewer's Comment (2/2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 06:30Everyone", "Content": "Comment:\nQuestions\nWhat is the difference between graph clustering, community detection and graph coarsening? The way I understand it, community detection is merely clustering of graph nodes based on the graph topology. Graph coarsening (as described in this paper) seems to be similar to blockmodeling [1]. At any rate, the differences between these three things (that seem to be combined in this paper), need to be clearly explained.\nAll three terms are broadly similar. Community detection is a general term for clustering. Coarsening, on the other hand, aims to combine a few nodes together (usually neighboring) while not making large groups. Essentially, it looks like the \"grouping size\" and purpose is the only differentiating factor. Our paper shows that potentially any coarsening method can be used in clustering, as there are theoretical benefits in common coarsening algorithms that have not been studied in clustering yet.\nThe method makes use of the constraint\n$X=C\\tilde{X}$\n. If we substitute this constraint into the first term of (5), it would simplify to\n$\\text{tr}(\\tilde{X}^\\top C^\\top\\Theta C\\tilde{X})=\\text{tr}(X^\\top\\Theta X)$\n, which would simplify the optimization significantly. However, instead of enforcing this constraint exactly, the paper simply introduces an error term\n$|X-C\\tilde{X}|$\n, which seems unelegant to me. Why don't you enforce this constraint exactly?\nNote that we cannot just assume a constraint to be true and substitute its value accordingly; it is a constraint to be checked. Also it is very difficult to solve for this constraint exactly because it involves both $C$ and $\\tilde{X}$ as variables, making it non-convex; that is why we add a relaxation of the constraint.\nYou mention that the log determinant term can be written as the sum of the log of the eigenvalues, and that this ensures that a 'minimal' number of eigenvalues are zero. However, doesn't this ensure that not a single eigenvalue is zero?\nYes, it tries to ensure that but any graph Laplacian will always have at least 1 zero eigenvalue (because there is always at least 1 connected component in any graph). So it is safe to add this term.\nIs the complexity that is described in the \"Complexity analysis\" paragraph the complexity of a single iteration or of all the iterations until convergence?\nWe have described the complexity of one iteration/epoch, and compared it with other methods in Supplementary Material Section K.\nI see that you rescaled the NMI, ARI and modularity to percentages. This is okay for NMI (though I'm not a fan of it), but for ARI it is confusing because ARI can be negative. For modularity, I have no idea how this rescaling is done, because the upper bound of modularity is smaller than 1 (and incredibly expensive to compute).\nWe have simply multiplied the values by 100; both modularity and ARI can be negative.\nWhy do you draw lines in Figure 2b instead of making a table? The points that are connected don't correspond to consecutive things.\nThe difference in the values and the impact is better understood as a graph. The points connected represent the same dataset. If we were to just use points (we tried that before), it would not look obvious which points belong to which dataset.\nWe hope these answer your questions along with the PDF that will be updated soon and that you will consider raising your rating."}]}, {"Heading": "Official Review of Submission9264 by Reviewer LHRF", "Subheading": "Official ReviewbyReviewer LHRF31 Oct 2023, 18:47 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe article develops a framework for unsupervised learning relying on modularity maximization jointly with attributed graph coarsening to solve a task of clustering of graph.\nThe main points are 1) to propose that in an optimization-based approach, where a Block Majorization-Minimization algorithm allows to solve the problem. Then, 2) the method is also integrated in GNN architectures for graph clustering. \nThe work describes several aspects of related works, and conducts extensive numerical experiments to check the usefulness of the method.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThe idea of using modularity for graph coarsening is not novel (it dates back to 20 years),  yet its incorporation in on coarsening techniques, in an integrated way, appears to be novel and interestong.\nThe article contains extensive numerical experiments, assessing when the proposed method works well.\nThere are good theoretical results on the method in Section 4.\nShowing that the method integrates with GNNs is relevant and useful (even though it's, on my opinion), a little bit too detailed.\nWeaknesses:\nThe results are a little bit disappointing as, according to Fig 4(b) and the final results, the full loss of eq (6) is not really needed. The modularity term does already a good job by itself, and the others appear to merely modify the results slightly -- even in a weird way as using only 1 term (relaxation of the constraint  or the $\\ell_{1,2}$ norm regularizer) degrades the performance.\nThe article is written is a dense way, possibly too dense, and one has trouble to identify the saillant points. \nI am not sure that the description of the integration of the method in 3 different deep learning methods for graphs is needed in the main text. The most relevant would be enough and it would leave more space to answer the questions asked underneath.\nthe literature on modularity maximization does not appear to be well quoted. In this context, quoting 1 or 2 of the existing surveys would be expected and useful for the readers. Also there is a body of literature showing the limitations of the modularity, from its intrinsic resolution limit to it being considered 'harmful', and the present article does not say a word on that and on the impact of the weaknesses of the modularity to the present work.\nQuestions:\nIn Fig 4(b) : why are the cases \\alpha + \\beta or \\beta + \\lambda so worse as compared to \\beta alone ?\nThere is always the possibility that the structure, E, are not aligned with the features, X. What would then happen ? The methods forces the smoothness of X on (V,E); is it always the case ? If it's not, is this supposition detrimental ?\nWhat would happen if the clusters happen to be affected by the mentioned limits of the modularity ?\nOn the other side, modularity has been improved in the mast 10 years using the Non-backtracking random walks, then the Bethe-Hessian ansatz and several variations around that, to detect better clusters or modules. Could these improvements\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nnone\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reply to Reviewer's Comment (1/2)", "Subheading": "Official CommentbyAuthors19 Nov 2023, 17:49 (modified: 20 Nov 2023, 06:17)EveryoneRevisions", "Content": "Comment:\nDear reviewer, we are glad you took the time to read our paper thoroughly. You have correctly understood the novelty of this paper.\nWe would like to address your concerns here:\nWeaknesses\nAcc Fig 4(b), full loss not needed. The modularity term does a good job by itself, and the others merely modify slightly -- even in a weird way as using only 1 term (relaxation of the constraint or the norm regularizer) degrades the performance.\nIt is important to note that even though some of the terms do the heavy lifting, the other regularization terms do contribute to performance and more importantly, change the nature of $C$ : The term $\\omega$ corresponds to the smoothness of signals in the graph being transferred to the coarsened graph; you can imagine this would affect $C$ by encouraging local \"patches\"/groups to belong to the same cluster. The term $\\gamma$ ensures that the coarsened graph is connected - i.e. preserving inter-cluster relations, which simple contrastive methods destroy; this affects $C$ by making it so that $\\Theta_C$ has minimal multiplicity of 0-eigenvalues (which tells us how many connected components there are, and we want just 1 big connected component). Also refer to answer of Question 1.\nWe feel this is a valuable addition to our paper and will include this explanation there too.\nArticle written in a dense way, trouble in identifying the salient points. Description of the GNN integration not needed in the main text. The most relevant would be enough and it would leave more space to answer the questions asked underneath\nWe apologize that you feel this way, we were trying to fit a lot of theory\nand\nexperiments/results in our main text since we felt all of it was important to the paper. However, because of the strict page limit it might feel dense. We have additionally provided theoretical results and more visualizations in the supplementary material. Regarding subsection \"4.2 Integration with GNNs\", we felt it was important to add an architecture in the maintext since we are comparing our method majorly with other deep learning methods. However, we have tried to reduce it in size.\nLiterature on modularity maximization not well quoted. There is a body of literature showing limitations of modularity, article does not mention the weaknesses of modularity.\nWe mention some excerpts here from the paper that do highlight the weakness of modularity, and why it is essential to have other optimization terms:\nThe usage of these (modularity-maximization) algorithms has plummeted over the years because they rely solely on the topological information of graphs and ignore node features.\nEven though modularity is a good metric to optimize for, maximum modularity labelling of a graph does not always correspond to the ground truth labelling. .... By optimizing modularity, we can get close to the optimal model parameters (at which NMI would be 1), but will be slightly off-course. We can think of the other terms as correcting this trajectory\nWe have also added a mention of the resolution limit of modularity in the introduction and its weakness to small clusters.\n(continued in 2/2)"}, {"Heading": "Reply to Reviewer's Comment (2/2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 06:14 (modified: 20 Nov 2023, 06:17)EveryoneRevisions", "Content": "Comment:\nQuestions\nIn Fig 4(b) : why are the cases \\alpha + \\beta or \\beta + \\lambda so worse as compared to \\beta alone ?\nThis is the main takeaway from the plot; we hypothesize this is because these terms want to optimize the model in different directions in the high-dimensional parameter space - either all 3 are in different directions or $\\alpha$ and $\\lambda$ are in the same direction different to $\\beta$. Only when all three are together these effects combine and push the model in a shared direction (which can be noted by seeing the increase in performance of $\\alpha + \\beta + \\lambda$ by around 23%(Cora)/50%(CiteSeer) over just $\\beta$). This statement comes from intuition when we think theoretically about the differing outcomes if these terms were optimized independently.\nThere is always the possibility that the structure, E, are not aligned with the features, X. What would then happen ? The methods forces the smoothness of X on (V,E); is it always the case ? If it's not, is this supposition detrimental ?\nNo, this is certainly not always the case - however, it is observed in most graph clustering and coarsening benchmark datasets (including heterogeneous). We believe it would be detrimental if that was the case, but since the smoothness term does not have a big impact on performance, it should not be disastrous. Upon more research, we have found this paper and In it's section 4.2, it shows some datasets with their calculated smoothness values:\nhttps://openreview.net/pdf?id=rkeIIkHKvS\n;\nWhat would happen if the clusters happen to be affected by the mentioned limits of the modularity ?\nEven if the clusters were small enough to be hit by the resolution limit of modularity, it would still detect that cluster but probably have extra nodes from other clusters because of the regularization terms that enforce connectedness and the balanced $\\mathcal{l}_{1,2}$ norm which ensures each cluster has at least 1 node.\nOn the other side, modularity has been improved in the mast 10 years using the Non-backtracking random walks, then the Bethe-Hessian ansatz and several variations around that, to detect better clusters or modules. Could these improvements\nIt looks like the question was cut off on openreview, however, we will try to answer it: The Bethe-Hessian definitely has interesting spectral properties and the \"deformed Laplacian\" view seems like a good concept too. Yes, it looks like these improvements could be integrated into our method as part of a future work.\nWe hope these answer your queries, we are here to answer any more/follow-ups.\nThank you for your insightful contributions!"}, {"Heading": "Official Comment by Reviewer LHRF", "Subheading": "Official CommentbyReviewer LHRF22 Nov 2023, 11:37Everyone", "Content": "Comment:\nDear Authors,\nI appreciate the detailed answers and changes made. In light of the different reviews, I will not change my rating, still thinking that the contribution is borderline and that there are aspects that remain yet to be improved and clarified in the present submission."}]}, {"Heading": "Official Review of Submission9264 by Reviewer s2b9", "Subheading": "Official ReviewbyReviewer s2b928 Oct 2023, 11:48 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work proposed a node clustering model based on modularity maximization for attributed graphs. The clustering process is modeled as an optimization-based graph coarsening problem, and the final pseudo labels are retrieved from supernode relationships. However, despite the progress made in this work, I cannot recommend acceptance for it to be present at top-tier conferences such as ICLR. See my comments below for details.\nSoundness:\n1 poor\nPresentation:\n3 good\nContribution:\n1 poor\nStrengths:\nThe literature review part is pretty detailed and comprehensive.\nThe paper is well-organized and easy to follow.\nThe proposed method is flexible and can be combined with various representation learning backbones.\nPromising clustering performances are obtained on widely used graph datasets.\nWeaknesses:\nThe proposed clustering model (problem (5)) is a trivial combination of different previous works, none of (5) is designed by the authors, so the technical contribution of this work is marginal.\nThe experiments are not inspiring. The authors conducted different experiments but presented their results without analyzing the reasons behind the scenes. See \"Questions\" below for a few ones I raised.\nThe ablation studies part is trivial and not informative at all.\nVisualization and Comparison of running times are generally not regarded as ablation studies.\nModularity Metric Comparison is interesting but its conclusion is pretty trivial:\nEven though modularity is a good metric to optimize for,\nmaximum modularity labelling of a graph does not always correspond to the ground truth labelling.\nFor this reason, it is important to have the other terms in our formulation as well.\nThis is a common sense known as the \"no free lunch theorem\" in machine learning. We generally would like the ablation studies to uncover special and important characteristics of the proposed method, rather than trivial observations.\nQuestions:\nIn problem (5), why do you propose to optimize both $\\tilde{X}$ and $C$ and use $\\lVert C\\tilde{X}-X\\rVert_F^2$ to encourage the consistency, rather than optimizing $C$ only as K-means does?\nKeep the last question in mind, why do you optimize $C$ only in Section 4.2? That makes the experiments inconsistent with your proposal. In addition, what's the difference between the two strategies in terms of clustering performance?\nIn Figure 2(b), what makes the proposed Q-GMM-VGAE faster than its backbone model GMM-VGAE? Are the experimental settings fair?\nIn Table 1, SCGC and MVGRL have better performance but you marked the proposed method bold, why? Is it a typo?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reply to Reviewer's comments (1/2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 05:17 (modified: 20 Nov 2023, 06:15)EveryoneRevisions", "Content": "Comment:\nDear reviewer, thank you for your valuable insights and concerns. We are glad to hear that you found the paper well-organized, flexible, and promising. We will try to address the concerns here:\nWeaknesses\nTrivial combination of previous works, technical contribution is marginal?\nWe note that the modularity term has existed in literature since [Newman, 2006]. However, our work here was to recognize what was lacking in FGC for making it level with the current state of the art in clustering. We worked on proving theoretical guarantees, for example, the Lipschitz continuity of the spectral approximation to the modularity term. There is a significant increase in performance from baseline methods FGC (\n+153 %\n) and DMoN (\n+40 %\n), which shows that our contribution is to\nallow potentially any coarsening method to work in a clustering setting\n, as there are lots of\ntheoretical benefits\nin common coarsening algorithms that have not been studied in clustering. Moreover, that is why we have included very\ncomprehensive analyses\nsurrounding the new objective function, with theoretical guarantees as well. We include a heavy load of supporting proofs ranging from\nproofs of convexity, proofs of KKT optimality, proofs of convergence, complexity analysis, ablation studies on the behavior of the different loss terms, and how drastically different it is from FGC, and even recovery on a degree-corrected stochastic block model\n. This is not incremental.\nAlso, our experiments are not on a few selected datasets but rather range from the\nbenchmark attributed datasets\nused in graph clustering, to\nnon-attributed datasets\n, and\neven to very large datasets\nthat most literary works skip out on. For example, CoauthorCS, CoauthorPhysics, AmazonPhoto, AmazonPC and ogbn-arxiv, even though our work is not specialized for very large datasets.\nWe have also extensively worked on\nintegrating our methods\nnatively with\nvarious GNN architectures\n, which was not done in FGC and also performing ablation studies including\ncontributions of the loss terms\nand how they\nwork together\n, the\ndifferences in evolution of latent space\nfor different models, comparison of runtime including\ncomplexities\n,\ncomparison of modularity\nto make it as comprehensive as possible, both empirically and theoretically.\nExperiments -> \"Questions\" below.\nIn Questions.\nThe ablation studies part is trivial and not informative at all.\nVisualization and Comparison of running times are generally not regarded as ablation studies.\nWe refer the reviewer to papers DCRN[AAAI'22], HSAN[AAAI'23], SDCN[WWW'20], AGE[KDD'20], SCGC[IEEE TNNLS'23]. Going by these papers in highly regarded graph clustering literature, ablation studies and analyses are usually combined into one, and analyses do include visualization analysis and complexity analysis in all these papers. Note that some papers just have an ablation study on parameters. That is why we have included\nboth\nkinds of ablation studies.\nModularity Metric Comparison is interesting but its conclusion is pretty trivial:\nWe wanted to show that our modularity maximization term does contribute to the performance and actually increases the modularity too, since that is a crucial part of our method.\nNo free lunch theorem, Ablation studies for special characteristics, rather than trivial observations\nThe reviewer might think this is a trivial and/or direct conclusion from the formulation because of their experience, however, it is very important to explain the downfalls of modularity in the method,\nas pointed out by other reviewers\n. For a more\nflavorful\nobservation, observe how in Fig 4b), $\\alpha$ + $\\beta$ or $\\beta$ + $\\lambda$ are worse as compared to $\\beta$ alone - we hypothesize this is because these terms want to optimize the model in different directions in the high-dimensional parameter space - either all 3 are in different directions or $\\alpha$ and $\\lambda$ are in the same direction different to $\\beta$. Only when all three are together, these effects combine and push the model in a shared direction (which can be noted by seeing the increase in performance of $\\alpha + \\beta + \\lambda$ by around 23%(Cora)/50%(CiteSeer) over just $\\beta$). This statement comes from intuition when we think theoretically about the differing outcomes if these terms were optimized independently.\nMoreover, observe how the plots of latent space evolution pan out so differently by just changing a GCN layer to a GMM, while the whole VGAE architecture including the losses remains the same.\n(continued in 2/2)"}, {"Heading": "Reply to Reviewer's comments (2/2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 05:18 (modified: 20 Nov 2023, 06:15)EveryoneRevisions", "Content": "Comment:\nQuestions:\nWhy optimize both\n$C$,$\\tilde{X}$\nwith\n$||C\\tilde{X} - X||_{2}^2$\nrather than optimizing\n$C$\nonly as K-means does?\nThe method is based on graph coarsening, and we typically want to find the output features $\\tilde{X}$ in coarsening and not just $C$/loading matrix.\nWhy do you optimize\n$C$\nonly in Section 4.2? Are experiments inconsistent?. What's the difference between the two in terms of clustering performance?\nWe optimize only for $C$ for the reasons mentioned in the 2nd paragraph of section 4.2. No, this does not make the experiments inconsistent as Q-FGC (optimization-based method) still optimizes for both $C$ and $\\tilde{X}$. We change this in the GNN architectures because $\\tilde{X}$ can't be learnt directly from $X$ using gradient descent and would require manual gradient calculations in PyTorch or to use a separate optimizer just for $\\tilde{X}$. \n We appreciate the author's suggestion and this could be a good point for a future work.\nIn Figure 2(b), why is Q-GMM-VGAE faster backbone GMM-VGAE? Are the experimental settings fair?\nYes, all the experimental settings were the same, which is essential to any analysis. We modified the implementation of GMM-VGAE to suit our needs and optimized some operations to be vector operations - this is also available in the anonymous code repository. We also made some important normalizations in the implementation to\ngreatly improve numerical stability\nof the GMM (in the original implementation, a lot of the times $C$ would come out to be all zeros because of an unnormalized operation in exponentiating the log probabilities).\nIn Table 1, SCGC and MVGRL have better performance but you marked the proposed method bold, why? Is it a typo?\nYes, they should be highlighted in ACC and ARI fields for cora and citeseer. We have fixed this.\nWe hope these answer your concerns and make you consider raising your rating, and we are here for any more questions."}]}, {"Heading": "Official Review of Submission9264 by Reviewer fD7q", "Subheading": "Official ReviewbyReviewer fD7q27 Oct 2023, 21:45 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposed a novel framework called Q-FGC for attributed graph clustering and its integration with deep learning-based architectures such as Q-GCN, Q-VGAE, and Q-GMM-VGAE. The authors conducted experiments on real-world benchmark datasets and demonstrated that incorporating modularity and graph regularizations into the coarsening framework improves clustering performance. Furthermore, integrating the proposed method with deep learning-based architectures significantly enhances clustering performance. The algorithms proposed in this paper are proven to be convergent and faster than existing state-of-the-art algorithms.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThe authors proposed a novel optimization-based attributed graph clustering framework called Q-FGC.\nThe proposed algorithms are provably convergent and much faster than state-of-the-art algorithms.\nWeaknesses:\nThe submitted title in the system (Attributed Graph Clustering via Coarsening with Modularity) is different from the title in the paper (ATTRIBUTED GRAPH CLUSTERING VIA MODULARITY AIDED COARSENING).\nThe research motivation is not sufficiently novel or clearly expressed. Additionally, there is an inconsistency between the motivation presented in the introduction and the abstract. For example, Dirichlet energies are stated in the Abstract, but they are not mentioned in Section Introduction. Besides, the reasons for using them are not explained. Reorganizing the abstract and introduction is recommended, particularly in the section discussing the motivation.\nThe novelty of this paper is not strong. The proposed method for improving the performance of graph clustering relies on modifying the existing FGC method. Furthermore, the paper fails to explain the shortcomings of the current FGC method and how incorporating modularity would enhance its performance. Overall, the impact of this paper on the field is not significant.\nThe related work section is not comprehensive enough. For instance, the paper does not cite important references such as Kumar M, Sharma A, Saxena S, et al. \"Featured Graph Coarsening with Similarity Guarantees\" presented at ICML 2023.\nThe experimental section lacks sufficient detail in its description. For example, the experimental setup is missing information. More specifically, the authors did not provide detailed experimental settings for the baselines. Additionally, the experimental section merely presents the experimental results without providing an explanation for the superior performance of the proposed algorithm in this paper.\nThe writing of the paper needs to be improved. There are also some typos in this paper.\nThe algorithm (Feature Graph Coarsening (FGC)) is first given, but no references are given.\nThere is a lack of punctuation in many parts of the paper. For example, \u201cWe compare the performance of our method against three types of existing state-of-the-art methods based on the provided input and type of architecture: a) methods that use only the node attributes b) methods that only use graph-structure c) methods that use both graph-structure and node attributes. The last category can be further subdivided into three sets: i) graph coarsening methods ii) GCN-based architecures iii) VGAE-based architectures and contrastive methods iv) largely modified VGAE architectures\u201d should be \u201cWe compare the performance of our method against three types of existing state-of-the-art methods based on the provided input and type of architecture: a) methods that use only the node attributes; b) methods that only use graph-structure; c) methods that use both graph-structure and node attributes. The last category can be further subdivided into three sets: i) graph coarsening methods; ii) GCN-based architectures; iii) VGAE-based architectures and contrastive methods; iv) largely modified VGAE architectures.\u201d).\nSeveral algorithms in Table 1 are missing references, and some do not provide experimental results.\nFigure 2 and Figure 4 do not have a caption (it is suggested to separate the tables in Figure 2(a) and Figure 4(a) from the figure itself).\nEquation 8 and Eqn. 8 => Eq. (8)\nTable 2a  => Table 2(a)\nIn Section 5.2, the authors state that \u201cQ-GCN is composed of 3 GCN layers\u201d, but only two hidden sizes of 128 and 64 are provided.\nIn section 5.2: \u201cWe surpass all existing methods\u2026\u201d  => \u201cOur proposed model surpasses all existing methods...\u201d\nThe font size of the x-axis values in Figure 4(b) is too small.\nIn section 5.1, \u201cGCN-based architecures\u201d   => \u201cGCN-based architectures\u201d\nQuestions:\nIn the Motivation of the introduction section, when stating that \"We aim to utilize the feature graph coarsening framework (which does not perform well on clustering, as seen in the results) for graph clustering.\", does the phrase \"the results\" refer to the experimental results in the experimental section? It is recommended to provide specific details on which results are being referred. Also, why does the feature graph coarsening framework not perform well on clustering?\nCan more analysis be done in the experimental section on experiment settings? For example, could you please provide the experimental settings for the baselines and the hyperparameter settings for the proposed method, including learning rate, number of training iterations, dataset partitioning, and so on?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reply to Reviewer's Comment (1/2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 06:53 (modified: 20 Nov 2023, 07:22)EveryoneRevisions", "Content": "Comment:\nDear reviewer, we thank you for taking out the time to read our paper and share your valuable insights. We will try to address all your concerns.\nWe found that your comment was generated using AI on gptzero; we still hope that you have read the paper and just gave it pointers you got from reading to frame the answer.\nWeaknesses:\nThe submitted title in the system (Attributed Graph Clustering via Coarsening with Modularity) is different from the title in the paper (Attributed Graph Clustering via Modularity Aided Coarsening).\nIt looks like this was an error.\nThe research motivation is not sufficiently novel or clearly expressed. Additionally, there is an inconsistency between the motivation presented in the introduction and the abstract. For example, Dirichlet energies are stated in the Abstract, but they are not mentioned in Section Introduction. Besides, the reasons for using them are not explained. Reorganizing the abstract and introduction is recommended, particularly in the section discussing the motivation.\nFor novelty concerns, refer to next answer. We do mention Dirichlet energy and all the other terms right under the motivations paragraph inside Introduction section. Also, we have explained the purpose of each term in detail in Section 4.1. We have tried to reorganize a bit.\nThe novelty of this paper is not strong. The proposed method for improving the performance of graph clustering relies on modifying the existing FGC method. Furthermore, the paper fails to explain the shortcomings of the current FGC method and how incorporating modularity would enhance its performance. Overall, the impact of this paper on the field is not significant.\nIn the first paragraph of Section 4.1, we have written that the FGC method is not able to perform on clustering, because the coarsening ratio is too low in clustering tasks. We have multiple paragraphs throughout the paper showcasing the benefits of modularity, starting from the Section 1 Introduction (3rd paragraph) to Section 3.3 in Background to the whole of Section 4 Proposed Method. Basically, this is what our whole paper is about.\nThe impact of the paper on the field is significant because:\nThere is a significant increase in performance from baseline methods FGC (\n+153 %\n) and DMoN (\n+40 %\n), which shows that our contribution is to\nallow potentially any coarsening method to work in a clustering setting\n, as there are lots of\ntheoretical benefits\nin common coarsening algorithms that have not been studied in clustering. Moreover, that is why we have included very\ncomprehensive analyses\nsurrounding the new objective function, with theoretical guarantees as well. We include a heavy load of supporting proofs ranging from\nproofs of convexity, proofs of KKT optimality, proofs of convergence, complexity analysis, ablation studies on the behavior of the different loss terms, and how drastically different it is from FGC, and even recovery on a degree-corrected stochastic block model\n. This is not incremental. \\\nAlso, our experiments are not on a few selected datasets but rather range from the\nbenchmark attributed datasets\nused in graph clustering, to\nnon-attributed datasets\n, and\neven to very large datasets\nthat most literary works skip out on. For example, CoauthorCS, CoauthorPhysics, AmazonPhoto, AmazonPC and ogbn-arxiv, even though our work is not specialized for very large datasets. \\\nWe have also extensively worked on\nintegrating our methods\nnatively with\nvarious GNN architectures\n, which was not done in FGC and also performing ablation studies including\ncontributions of the loss terms\nand how they\nwork together\n, the\ndifferences in evolution of latent space\nfor different models, comparison of runtime including\ncomplexities\n,\ncomparison of modularity\nto make it as comprehensive as possible, both empirically and theoretically.\nThe related work section is not comprehensive enough. For instance, the paper does not cite important references such as Kumar M, Sharma A, Saxena S, et al. \"Featured Graph Coarsening with Similarity Guarantees\" presented at ICML 2023.\nThe related work section includes papers on Graph Coarsening/Pooling, Modularity Optimization and Deep Graph Clustering. The work you have referenced is itself an extension of FGC (Featured Graph Coarsening), JMLR'23, by the same authors, which our method inherits from and references multiple times.\n(continued in 2/2)"}, {"Heading": "Reply to Reviewer's Comment (2/2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 06:54Everyone", "Content": "Comment:\nThe experimental section lacks sufficient detail in its description. For example, the experimental setup is missing information. More specifically, the authors did not provide detailed experimental settings for the baselines. Additionally, the experimental section merely presents the experimental results without providing an explanation for the superior performance of the proposed algorithm in this paper.\nWe refer the reviewer to the paragraph after Section 5.2, which is about Training Details and our experimental setup is explained in detail there (Also refer to answer of Question#2). We explain the performance benefits of modularity all throughout the paper, as written in the answer to #3. We also analyze our results and methods in Section 5.5 Ablation Studies.\nThe writing of the paper needs to be improved. There are also some typos in this paper.\nThe algorithm (Feature Graph Coarsening (FGC)) is first given, but no references are given.\nThere is a lack of punctuation in many parts of the paper.\nSeveral algorithms in Table 1 are missing references, and some do not provide experimental results.\nFigure 2 and Figure 4 do not have a caption (it is suggested to separate the tables in Figure 2(a) and Figure 4(a) from the figure itself).\nEquation 8 and Eqn. 8 => Eq. (8)\nTable 2a => Table 2(a)\nIn Section 5.2, the authors state that \u201cQ-GCN is composed of 3 GCN layers\u201d, but only two hidden sizes of 128 and 64 are provided.\nIn section 5.2: \u201cWe surpass all existing methods\u2026\u201d => \u201cOur proposed model surpasses all existing methods...\u201d\nThe font size of the x-axis values in Figure 4(b) is too small.\nIn section 5.1, \u201cGCN-based architecures\u201d => \u201cGCN-based architectures\u201d\nThank you for all these, we have moved the references and abbreviations first and fixed typos. And we have added semicolons in the paragraph you requested. Also, we have added references in Table 1. All of them already have experimental results, so we are not sure what you mean by \"do not provide experimental results\".\nFigure 2 and 4 are divided into 2a), 2b) and 4a),4b), all four of which have captions. We have grouped them because the table and graphs are small and would not fit in the space constraints otherwise.\nWe use the latex command\n\\ref\nto refer to tables, figures and equations and that generates the output 4a and not 4(a). We are following the ICLR custom latex style and format provided on the conference website. This is important to keep references linked (i.e. they will take you to the related figure/table/eqn when clicked on).\nAs visible from the architecture, Q-GCN has 3 GCN layers. And just like any other GCN or even MLP model, the dimensions change as:\ninput_size\n--(GCN1)-->\nhidden_size 1\n--(GCN2)-->\nhidden_size 2\n--(GCN3)-->\noutput_size\nFor the x-axis in 4b: We tried to improve this before submission but it is rendered as latex text within the generated plot pdf (using the plotly package), and still somehow increasing the size was making it being rendered as blurry. If you zoom in it is better. We have tried to make this better by changing the latex to\n$\\large{ ... }$\nQuestions:\nIn the Motivation of the introduction section, when stating that \"We aim to utilize the feature graph coarsening framework (which does not perform well on clustering, as seen in the results) for graph clustering.\", does the phrase \"the results\" refer to the experimental results in the experimental section? It is recommended to provide specific details on which results are being referred. Also, why does the feature graph coarsening framework not perform well on clustering?\nYes, we are talking about the primary results of the paper. We mention in Section 4.1 that FGC alone does not perform well in clustering because the coarsening ratio in clustering (~ < 0.001) is much lower than the ones it is designed for (0.1 - 0.01).\nCan more analysis be done in the experimental section on experiment settings? For example, could you please provide the experimental settings for the baselines and the hyperparameter settings for the proposed method, including learning rate, number of training iterations, dataset partitioning, and so on?\nWe have included the information about values of hyperparameters as part of code since those values cannot be analyzed.\nWe can add this to the supplementary material.\nWe hope these answers gave you clarity about the method and answered your questions. We also hope you would consider raising our rating. We would be happy to answer or discuss anything more."}, {"Heading": "Official Comment by Reviewer fD7q", "Subheading": "Official CommentbyReviewer fD7q21 Nov 2023, 22:02Everyone", "Content": "Comment:\nActually, I spent a lot of time reading this paper carefully. However, I still found it difficult to understand, and some reviewers also took this view. Therefore, I believe that the writing of papers needs to be improved.\nIn addition, the authors have not addressed several concerns. Here are some examples.\nI observed that the author did not provide detailed experimental settings for the\nbaselines\n. The author's response focused on the experimental settings of their proposed method rather than the baselines of this paper.\nThe authors responded that \u201cAll of them already have experimental results\u201d in Table 1. However, the ARI of the VGAECD-OPT algorithm on the PubMed dataset is not given, and the authors did not explain it.\nThe authors responded that they referenced a study related to FGC multiple times. They did do that in Sections\nBackground\n,\nProposed Method\nand\nExperiments\n. However, I mentioned that it should be listed in Section\nRelated Works\nbecause analyzing this study can help readers better understand the contributions of the proposed Q-FGC.\nAll things considered, I am sorry to inform the author that I maintain the original score."}]}, {"Heading": "Official Review of Submission9264 by Reviewer s7a2", "Subheading": "Official ReviewbyReviewer s7a227 Oct 2023, 08:41 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces a new method for clustering attributed graphs. The method is heavily based on a recent graph coarsening method, termed Featured Graph Coarsening (FGC), which was proposed by Kumar et al (2023) for coarsening attributed graphs. The authors in this paper introduces a modularity-based regularization term to the original optimization objective of FGC, and empirically show that the new formulation is useful for clustering attributed graphs. In addition, the authors demonstrate graph neural networks (GNNs) can be integrated in the proposed framework to further enhance the clustering performance.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThe empirical comparisons presented in the main text, especially those in Table 1, are extensive.\nWeaknesses:\nGiven that the proposed optimization objective in Equation 5 comes from simply adding a modularity-based regularization term $\\mbox{tr}(C^TBC)$ to the original objective function of FGC (Kumar et al, 2023), the originality of this work is very limited, both methodology-wise and technical-wise. It looks like this paper simply (1) adds a regularization term to an existing work and (2) conducts some experiments on a few selected datasets. If there is something very novel, I would recommend the authors emphasize on those aspects.\nThe overall quality/clarity of this paper can be significantly improved. First of all, there are a couple of ambiguous statements and overstatements. Here are some examples:\nOn page 1, in the second paragraph, the authors say that \"... the Fiedler vector (the eigenvector of the second smallest eigenvalue of the Laplacian) produces a graph cut minimal in the weights of the edges (Fiedler, 1973).\" As a reader I find it difficult to understand what \"a graph cut minimal in the weights of the edges\" means in this context. If the authors mean minimum cut, then I don't think this statement is correct. The relationship between the Fiedler vector and the minimum cut is not mentioned in the original paper (Fiedler, 1973), and in general it does not give rise to a minimum cut.\nOn page 1, in the second paragraph, the authors say that \"... they assume each node gets mapped to one cluster, which is not consistent with real graph data.\" This is a clear overstatement. As far as I know, most of the node classification benchmarks used by the GNN community has non-overlapping clusters/classes. These include the 3 citations networks in Table 1, and several other attributed datasets from Table 3 in the appendix.\nIn addition, the presentation can be greatly improved if proper definitions/citations are provided in the right place. Here are some examples:\nThe term Feature Graph Coarsening (FGC) first appears at the end of page 1 without a citation. The authors should cite Kumar et al (2023) here.\nSimilarly, the abbreviation GNN appears at the end of page 1, but the full definition \"Graph Neural Network (GNN)\" only appears much later in Section 2, at the end of page 2.\nIn the first paragraph of Section 3.3, it is unclear what \"the volume of inter-cluster edges\" means. The authors should define it.\nIn Equation 1, the expression $\\delta(c_i,c_j)$ is not defined.\nIn the first paragraph of Section 4.1, it is unclear what \"the original graph is smooth\" means. If the authors mean that the graph has smooth signals, they should just say \"the original graph has smooth signals\".\nThere are also many typos and misplacements of mathematical symbols. I highly recommend the authors read the paper thoroughly and fix all the typos.\nEmpirically, even though the authors compared with a number of other methods as shown in Table 1, the experiments are only carried over 3 small datasets. Table 3 in the appendix has more results on other datasets, but the authors only compare with two other methods, and one of them is just FGC.\nThe proposed method has a lot of parameters, i.e. $\\alpha,\\beta,\\gamma,\\lambda$ in Equation 5. It is unclear how to select these parameters and how robust are the results with respect to the choice of these parameters.\nQuestions:\nIn the experiments, how did you pick the parameters $\\alpha,\\beta,\\gamma,\\lambda$? How robust are the clustering results with respect to the choice of the parameters?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Reply to Reviewer's Comment (1/2)", "Subheading": "Official CommentbyAuthors19 Nov 2023, 17:16 (modified: 20 Nov 2023, 06:17)EveryoneRevisions", "Content": "Comment:\nDear reviewer, thank you for taking out the time to read our paper. We are glad to hear that you think our empirical comparisons are comprehensive. We aim to address the concerns raised by you:\nWeaknesses\nProposed objective adds a modularity-based regularizer term to FGC, limited originality?, experiments on few selected datasets?\nThe modularity term can not be regarded as a regularization term as can be seen from the ablation studies Fig 4b that it \"guides\" the model a majority of the way not to mention the significant increase in performance from baseline methods FGC (\n+153 %\n) and DMoN (\n+40 %\n), which shows that our contribution is to\nallow potentially any coarsening method to work in a clustering setting\n, as there are lots of\ntheoretical benefits\nin common coarsening algorithms that have not been studied in clustering. Moreover, that is why we have included very\ncomprehensive analyses\nsurrounding the new objective function, with theoretical guarantees as well. We include a heavy load of supporting proofs ranging from\nproofs of convexity, proofs of KKT optimality, proofs of convergence, complexity analysis, ablation studies on the behavior of the different loss terms, and how drastically different it is from FGC, and even recovery on a degree-corrected stochastic block model\n. This is not incremental.\nAlso, our experiments are not on a few selected datasets but rather range from the\nbenchmark attributed datasets\nused in graph clustering to\nnon-attributed datasets\n, and\neven to very large datasets\nthat most literary works skip out on. For example, CoauthorCS, CoauthorPhysics, AmazonPhoto, AmazonPC, and ogbn-arxiv, even though our work is not specialized for very large datasets.\nWe have also extensively worked on\nintegrating our methods\nnatively with\nvarious GNN architectures\n, which was not done in FGC, and also performing ablation studies, including\ncontributions of the loss terms\nand how they\nwork together\n, the\ndifferences in evolution of latent space\nfor different models, comparison of runtime including\ncomplexities\n,\ncomparison of modularity\nto make it as comprehensive as possible, both empirically and theoretically.\nDifficult to understand what \"a graph cut minimal in the weights of the edges\" means in this context. If the authors mean minimum cut, then I don't think this statement is correct. The relationship between the Fiedler vector and the minimum cut is not mentioned in the original paper (Fiedler, 1973), and in general it does not give rise to a minimum cut.\nA graph cut minimal in the weights of the edges means that a graph cut such that the sum of edges it \"cuts\" is minimum over all such possible cuts. This can also be written as the number of edges in the cut. We referenced the Fiedler paper for the Fiedler vector.\nIt is a well known result that the eigenvector related to the second smallest eigenvalue gives us a partition such that the number of edges being cut is minimal, and this result is part of Newman's landmark 2006 work on modularity, also referenced in other places in our paper. We have added this citation there.\nAuthors state\"... they assume each node gets mapped to one cluster, which is not consistent with real graph data.\" This is a clear overstatement. As far as I know, most of the node classification benchmarks used by the GNN community has non-overlapping clusters/classes.\nYes, that is what we are saying here as well, except that the real world applications of graphs are far wider that the benchmark citation datasets, for example, social networks, which in general have overlapping clusters/\"groups\".\nTypos/clarifications\nThank you for these. We have moved the references and abbreviations earlier. We have gone over the paper with a spellchecker and fixed a few typos. If you find any more, please tell us the location. For clarification:\nVolume of inter-cluster edges means the total number of edges in-between the clusters and not inside them.\n$\\delta(c_i,c_j)$ is the common Kronecker delta which is 1 only when $c_i=c_j$ and 0 otherwise\n(Continued in 2/2)"}, {"Heading": "Reply to Reviewer's Comment (2/2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 05:59 (modified: 20 Nov 2023, 06:16)EveryoneRevisions", "Content": "Comment:\nAuthors compared with a number of methods in Table 1 but over 3 small datasets. Table 3 appendix has more results on other datasets, but only compared with two other methods.\nThis is because most of the recent papers in graph clustering don't experiment on large graphs and instead just choose the smallest out of these (AmazonPhoto) and show results on that. Some examples are GDCL[IJCAI'21] (None), GALA[ICCV'19] (None), AGE[KDD'20] (None), MVGRL[ICML'20] (None), HSAN[AAAI'23] (AmazonPhoto), SCGC[IEEE TNNLS'23] (AmazonPhoto), DCRN[AAAI'22] (AmazonPhoto). Filling just one column in the table with 5 columns for multiple papers makes it look like the table is incomplete. However, we still provide the data about our method in regards to DMoN and FGC.\nMost of these papers only include the 6 datasets from our table 1 and table 2 and one additional dataset.\nLot of parameters\n$\\alpha,\\beta,\\gamma,\\lambda$\n, unclear how to select, and how robust are the results with changes?\nIn the paragraph just above Section 6, we mention the observed sensitivity of hyperparameters (The order of sensitivity is $\\alpha>\\gamma>\\beta>\\lambda$). Selection is done starting from previous values from FGC and then adjusting accordingly for the modularity term (i.e., general hyperparameter optimization, we can use any method such as a grid search or Bayesian optimization, etc.).\nQuestions\nAnswered above.\nWe hope this has answered your questions and encouraged you to improve your rating. If there are any more, feel free to leave a comment."}, {"Heading": "Official Comment by Reviewer s7a2", "Subheading": "Official CommentbyReviewer s7a222 Nov 2023, 10:37Everyone", "Content": "Comment:\nDear authors, I have read all reviews and also all replies to the reviews. I will keep the score. Thank you for the efforts for providing detailed responses."}]}]}, "l18hiEXRJS": {"paper_info": {"Supplementary Material": "zip", "Primary Area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "shift detection, dimensionality reduction, neural networks, activation graphs", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Despite their successful application to a variety of tasks, neural networks remain limited, like other machine learning methods, by their sensitivity to shifts in the data: their performance can be severely impacted by differences in distribution between the data on which they were trained and that on which they are deployed. \n In this article, we propose a new family of representations, called MAGDiff, that we extract from any given neural network classifier and that allows for efficient covariate data shift detection without the need to train a new model dedicated to this task. These representations are computed by comparing the activation graphs of the neural network for samples belonging to the training distribution and to the target distribution, and yield powerful data- and task-adapted statistics for the two-sample tests commonly used for data set shift detection. We demonstrate this empirically by measuring the statistical powers of two-sample Kolmogorov-Smirnov (KS) tests on several different data sets and shift types, and showing that our novel representations induce significant improvements over a state-of-the-art baseline relying on the network output.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9263", "PDF Url": "https://openreview.net/pdf?id=l18hiEXRJS"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9263 by Area Chair xLu3", "Subheading": "Meta ReviewbyArea Chair xLu314 Dec 2023, 23:24 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper aims to address the challenge of neural networks' sensitivity to shifts in data distribution. Although this is an important problem to be addressed, the paper lacks in several aspects, such as clarity and comparison with more recent methods, which may need further development.\nJustification For Why Not Higher Score:\nThe paper lacks in various aspects and may need more development.\nJustification For Why Not Lower Score:\nNA."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 16:18Everyone", "Content": "Comment:\nThank you very much to all the reviewers for their helpful comments and suggestions. We have read them with attention, though we might not have the time to implement all of them."}, {"Heading": "Official Review of Submission9263 by Reviewer f2j1", "Subheading": "Official ReviewbyReviewer f2j131 Oct 2023, 12:01 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper, \"MAGDIFF: Covariate Data Set Shift Detection via Activation Graphs of Neural Networks\", addresses the challenge of neural networks' sensitivity to shifts in data distribution. Such shifts can significantly degrade the performance of machine learning models. To address this, the authors introduce a new family of representations termed MAGDiff. These representations are derived by comparing the activation graphs of a given neural network classifier for samples from the training distribution and target distribution. The MAGDiff approach enables efficient covariate data shift detection without necessitating a new model specifically for this task. By employing these representations with two-sample tests, MAGDiff has demonstrated enhanced performance in detecting data set shifts compared to baselines.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nS1. The paper introduces a novel concept, MAGDiff, which focuses on comparing activation graphs for shift detection. This approach is distinct from one of the state-of-the-art baselines that only looks at context vectors.\nS2. The empirical results presented in the paper show that the proposed method outperforms the state-of-the-art BBSD technique, showcasing the quality and robustness of MAGDiff. Given the ubiquity and increasing reliance on neural networks in real-world applications, the capability to efficiently detect data set shifts is crucial. MAGDiff's methodology has potential impact for ensuring neural network reliability.\nS3. The paper provide a clear and coherent overview of the problem, the proposed solution, and its advantages.\nWeaknesses:\nW1. While MAGDiff showcases success in the datasets mentioned, understanding its performance across a wider variety of datasets would enhance its credibility.\nW2. How the method deals with very deep neural networks, where activation graphs can be highly complex, is not immediately clear. Currently the method assumes only simple fully connected networks to generate activation graphs. However, to utilize the potential of the method the more common architectures such CNNs, RNNs, Transformers are overlooked. How the model handles residual connections are also not clear. This lack of extension to the aforementioned models limits the applicability of the method in practice and does not give a real-benefit over BBSD since in practice fully-connected layers are often used at the very end of the models only.\nW3. A more detailed breakdown comparing MAGDiff with other more recent methods, particularly highlighting where it excels or falls short, would provide a clearer picture for readers. BBSD is from 2018 and in the past 5 years there has been many other techniques that deal with such dataset shifts (some highlighted already in the paper but not directly used as baseline). Overall the work needs more additional baselines to make the contribution stronger.\nW4. The paper mentions that there is no gain in using their method over BBSD for label-shift. But the experiments in the main body of the paper forego showing this. Additional experiments specific to label shift and not just covariate should be included in the paper to improve its soundness.\nW5. For MAGDiff to be applicable in real-world applications it needs to have access to (or be provided beforehand with) the initial dataset that the model is trained on (CS). This is a challenge in using the model to detect dataset shift in practice.\nQuestions:\nQ1. How does MAGDiff handle neural networks with different architectures or activation functions, given that activation graphs might differ substantially?\nQ2. Given the reliance on activation graphs, how does MAGDiff deal with potential noise or irregularities in these graphs?\nQ3. Are there any limitations or scenarios where MAGDiff might not be the ideal choice for shift detection?\nQ4. Could the authors provide more insights into the computational overhead introduced by MAGDiff, especially for larger neural networks?\nQ5. How would MAGDiff adapt or be integrated into real-time applications where timely detection of shifts is essential?\nQ6. Section 3.2, you mention \u201creasonable accuracies\u201d as a requirement, what constitutes as reasonable for various tasks? Does the method break for low accuracies? One possible way to analyze this in your experiments would be to use relatively low performing models and conducting the same analyses as you did.\nQ7. Need a figure to clear up how activation graphs are formed.\nQ8. Make your math more explained in text (e.g. supp $P0$  U supp  $P1 \\rightarrow R^N$). Additionally, what is $N$ for instance? (It is first referenced in 4.1).\nQ9. The choice of norm is not justified so it would be beneficial to show in the appendix effect of at least two norms in calculating the test statistic.\nQ10. How we does MAGDiff generalize to large datasets? The experiments does not consider cases with large number of classes and how the model performs in such cases. I understand that the authors are directly comparing with BBSD and some of their experiments, but while MNIST was acceptable as the highlighting dataset in 2018, it is not in 2023 and so very large classes would be where this model can show its superior performance and highlight its applicability. Also it could shed light to some limitations for instance the fact that MAGDiff is calculating metrics independently for each class how does scale with large classes and not just 10.\nQ11. What happens if we have a large pronounced imbalance between our classes?\nMinor Details:\nMQ1. In section 3.1 \u201ci\u201d is used for feature indexing but in section 3.2 \u201ci\u201d is used for class index. Would suggest changing the second one to \u201ck\u201d for clarity. Additionally, often \u201cD\u201d is used for the feature set, so using a different indicator like \u201cK\u201d for classes would be better in the flow of your arguments.\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nn/a\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9263 by Reviewer WvRV", "Subheading": "Official ReviewbyReviewer WvRV31 Oct 2023, 02:26 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes the use of MAGDiff representation, extracted from the activation graph of a trained neural network classifier, to construct tests for covariate shift detection in datasets that are used to train and query the classifier. The paper shows that coordinate-wise two-sample Kolmogorov Smirnov (KS) tests for each class can be combined to create a covariate detector with higher power than the baseline (Black box shift detection, BBSD) that only relies on the output logits (Confidence Vectors) to construct the representation.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nOriginality and significance: The use of neural network internal representation (activation graph) to construct a covariate-shift detector is the main contribution of this work. Most of the rest of the paper closely follows the baseline BBSD method (Lipton et al., 2018). The empirical results are interesting and shed some light on the potential use of internal NN representation as proxies for constructing tests that measure changes in the input space.\nQuality and clarity: The paper is easy to follow and the experiments are explained in sufficient detail.\nWeaknesses:\nThe original results in this work are fairly limited and the paper defers a closer study of several key aspects of the proposed approach to future work. IMO, several key questions are not answered and the experiments are insufficient.\nThe paper suggests looking inside the model for representations with higher covariate shift detection power, but fails to pinpoint where exactly one should be looking inside the model. IMO, the study with respect to different layers (the last section of the empirical results) should have been the main focus of the paper, with more models and certainly more layers. As is, the experiment looks like an afterthought, and the optimal choice of layer is at the boundary of the experimental setup, suggesting that using earlier layers might have even higher detection power. Of course we don\u2019t know if this is the case since the experimental setup is somewhat minimal. We also don\u2019t know if these results extend beyond the toy examples of MNIST and FMNIST.\nI don\u2019t want to argue for more published baselines to be added to the paper (will leave that to the proverbial reviewer number 2). But IMO the paper must have at least included a trivial variant of their method as the true baseline: using the activations themselves instead of the activation graph as the internal representation, i.e. setting $T(x)=x$ in the derivations of section 4.1 (please number your equations). This is an extension of BBSD without involving layer weights and should be compared to MAGDiff (per layer), to gauge the effect of the linear map on top of the previous layer activations as it relates to covariate shift detection.\nEven on the very limited toy models, the work does not cover how to combine representations across multiple layers, even though such a combination is likely to result in higher power tests. One could postulate that just concatenating all middle layer activations to form $T(x)$ might have results on par or better than those reported in the paper. But of course we don\u2019t know if this is the case.\nI found it very frustrating to read a paper with a good core idea that fails to answer so many key questions around the proposed method, excludes \u201cunimpressive\u201d results that could have shed some light on the choice of hyper parameters, and does virtually no ablation studies to gauge the importance of solution components (e.g. the use activations instead of activation graph).\nQuestions:\nSome questions and minor notes:\nDid you attempt using the (hidden) activations instead of the activation graph?\nIf I took a hidden activation vector and use a random linear projection of it (i.e. MAGDiff with a randomly chosen W), how does it compare to using the weights from the trained model? In other words, how much of the test power can be attributed to using a trained W?\nSay, you take a model trained on a dataset A (e.g. MNIST), and try to use the activation graph of this model to measure covariate shift of another dataset B of similar input shape (e.g. FMNIST). You won\u2019t have the \u201cwell-trained\u201d model assumption, but you might still have a good proxy for measuring covariate shift (lambda values need to be set w.r.t. dataset B). Have you tried using a model trained on one dataset to check for data-shift in another dataset?\nFor many experiments the choice of layer is not specified. The text in the paper says \u201ca chosen dense layer\u201d without indicating which one. My guess is that $l_{-1}$ is used for all experiments (and referred to as MagDiff$_1$).\nEquations could use label/numbering.\nThe citation style is incorrect in many places (wrong macro). When the reference does not read as part of the sentence it should be in parentheses.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9263 by Reviewer hyAB", "Subheading": "Official ReviewbyReviewer hyAB30 Oct 2023, 20:00 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a new method called MAGDiff for detecting covariate shifts in data distributions by comparing activation graphs in neural networks. This method works in principle for any NN classifier with dense layers. By using this as a statistic and combining it with the methods proposed in prior work, the authors obtain a novel method for covariate detection. A comparison to the BBSD method which sets SOTA on covariate shift is done, and this method is seen to outperform. Code is provided for reproducibility.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nTo the best of my knowledge, the idea of using activation graphs for shift detection is novel. MAGDiff provides a way to leverage neural network representations for this task without retraining models. Detecting distribution shift is an important problem in deploying machine learning systems. The paper shows MAGDiff outperforms a strong baseline in a variety of scenarios. This appears to be a significant result. The paper is well-written and clearly explains the proposed method. Section 3 makes it accessible to someone with no strong background in the distribution shift literature and problem. The experiments systematically evaluate performance across datasets, shift types and intensities. I'm not fully convinced that the set of shifts applied are sufficiently strong be realistic in practice, but the comparison with SOTA CV detector for even these simple tasks is compelling. The limitations discussed in the experimental protocol section are thorough.\nWeaknesses:\nThe main weakness is the limited number of datasets and architectures that this method is being tested on. MNIST, FMNIST, and CIFAR have by now become fairly easy and simple datasets. The use of Imagenette is appreciated (and the results there seem compelling), but a broader variety of empirical settings would drastically strengthen the paper.  As distribution shift is highly relevant for real-world deployment, more rigorous and diverse empirical analysis is needed to fully validate the claims in this paper. The current experiments are reasonable for an initial investigation but leave open questions about how MAGDiff would perform on more complex and realistic data. Further studies on more realistic datasets would likely lead me to raise my score.\nThere is also some lacking theoretical motivation for why this method should work. In the opinion of the reviewer, this is not as important as the first weakness listed.\nQuestions:\nIt would be interesting to see if this can be extended outside of the supervised setting, e.g. to autoregressive tasks.\nCould you observe improved results by somehow combining the tests for different layers of a given network? In the case of the ConvNets, I suppose this requires you to develop the method for the convolutional layer.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9263 by Reviewer QE2P", "Subheading": "Official ReviewbyReviewer QE2P27 Oct 2023, 11:10 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors propose a new type of representations for covariate shift detection, based on activation graphs of neural network layers. They consider classification tasks, where a pretrained, well-performing classifier is given. The Kolmogorov-Smirnov test is then performed on class-conditioned activation graphs of the original and target distributions. The authors compare the proposed method on several image datasets against a single (albeit state-of-the-art) baseline, and analyse robustness of the methods to changing conditions, e.g., sample size of different shift types.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper is written in a clear and concise manner\nThe proposed method outperforms the baseline\nExperimental details are included in the main manuscript\nWeaknesses:\nAuthors compare against just one baseline, while e.g., [1] could be applicable in this scenario as well\nThe novelty of the method as compared to the baseline is rather limited\n[1] Kirchler, Matthias, et al. \"Two-sample testing using deep learning.\"\nInternational Conference on Artificial Intelligence and Statistics\n. PMLR, 2020.\nQuestions:\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes"}]}, "cwN69teRIW": {"paper_info": {"Keywords": "federated class incremental learning, federated learning, class incremental learning, continual learning, prompt, prototype", "Abstract": "Federated Class Incremental Learning (FCIL) is a new challenge in continual learning (CL) that addresses catastrophic forgetting and non-IID data distribution simultaneously. Existing FCIL methods call for high communication costs and exemplars from previous classes along with performance issues. We propose a novel rehearsal-free method for FCIL named prototypes-injected prompt (PIP) that involves 3 main ideas: a) prototype injection on prompt learning,  b) prototype augmentation, and c) weighted Gaussian aggregation on the server side.  Our experiment results show that the proposed method outperforms the current state of the arts (SOTAs) with a significant gap of 14-33% in CIFAR100, MiniImageNet, and TinyImageNet datasets. Our extensive analysis demonstrates the robustness of our proposed method in different task sizes, small participating local clients, and small global rounds. For further study, source codes of PIP, baseline, and experimental logs are shared publicly inhttps://anonymous.4open.science/r/an122pouyyt789/.", "Primary Area": "transfer learning, meta learning, and lifelong learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9261", "PDF Url": "https://openreview.net/pdf?id=cwN69teRIW"}, "review_info": [{"Heading": "Official Review of Submission9261 by Reviewer Rs3a", "Subheading": "Official ReviewbyReviewer Rs3a01 Nov 2023, 02:05 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work studies the federated continual learning problem where each client deals with a class incremental learning problem, and the server aggregates all clients via weighted averaging. The authors propose a prompt learning based method that includes prototype injection, prototype augmentation, and weighted Gaussian averaging. Experiments show that their method has significant advantages over existing approaches.\nSoundness:\n3 good\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nFederated class incremental learning is a challenging but more realistic problem than existing federated learning. Developing exemplar-free methods is an important and interesting direction.\nExperiments show that the proposed approach performs better than other compared baselines.\nWeaknesses:\nIt is acknowledged that prompt learning has been used in class incremental learning, but the reviewer doubts the privacy issue in federated learning setup when using pre-trained ViT as the backbone.\nThe ablation study indicates that the prototype strategy impacts significantly the performance. However, the idea of prototype strategy seems not original to me. As far as I know, it has been used in (Dong et al. 2022, 2023) , and prototype augmentation is also known and used in conventional exemplar-free class incremental learning.\nThe writing needs to be significantly improved to meet the requirements of a top conference like ICLR. For instance,\nThe cited reference should be given in parentheses in most cases, e.g., using \\citep in ICLR latex. The current form of citation makes it hard to read.\nEvery equation (eq. 1-11) in this paper should be followed by punctuation. However, they are missing in this paper.\nThe T^{r,t}_{l}consists of samples in the input space, while prototype sets are in the deep feature space. Therefore, the formulation of the fourth line on page 5 is problematic.\nIn the part of Benchmark Algorithms, the name of each compared method is mixed with the name of the authors of each citation.\nIn the third paragraph of the Introduction section: ..the performance Besides the performance issue,...\nIn eq.6 and eq.7, using the indicative function is better than using \u201cif\u201d, particularly when it is wrongly written in variable form rather than text form.\nQuestions:\nWhat is the L_{match}?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9261 by Reviewer 3BAT", "Subheading": "Official ReviewbyReviewer 3BAT31 Oct 2023, 10:25 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nA prototypes-injected prompt method is proposed for rehearsal-free federated class incremental learning. The proposed method involves 3 parts: prototype injection on prompt learning, prototype augmentation, and weighted Gaussian aggregation. The performance is validated on three datasets: CIFAR100, MiniImageNet and TinyImageNet.\nSoundness:\n1 poor\nPresentation:\n1 poor\nContribution:\n1 poor\nStrengths:\nPrompt learning is introduced into FCIL, which can effectively reduce the training and communication overhead of the large model, so that the large model can be applied to FCIL.\nWeaknesses:\nIdea:\n1.The idea of freezing the feature extractor to reduce the communication and training overhead has been proposed in \"Federated Reconnaissance: Efficient, Distributed, Class-Incremental Learning\", and the method in that article is better than this paper in terms of computational and communication efficiency, so this paper is not innovative enough in terms of saving computational and communication overhead.\nMethodology:\n1.There is no specific design in the paper to address catastrophic forgetting and non-i.i.d., which are the core challenges of FCIL.\nExperiments:\n1.Unfair experimental comparison: \"PIP and Fed-DualPrompt use pre-trained ViT as the backbone network, while the competitors use LeNet\", the difference in the feature extractors may lead to a huge performance gap, and the feature extraction ability of ViT is much better than LeNet, which may be the reason why this paper's method outperforms the other comparative methods.\n2.Lack of comparison methods: Most of the \"10 state-of-the-art algorithms\" mentioned in this paper are comparison methods designed in \"Federated Class-Incremental Learning\", and this paper does not compare other FCIL methods, such as:\n\"Federated Continual Learning with Weighted Inter-client Transfer\"\n\"Federated Probability Memory Recall for Federated Continual Learning\"\n\"Continual Federated Learning Based on Knowledge Distillation\"\n\"Better Generative Replay for Continual Federated Learning\"\n\"Federated Continual Learning through Distillation in Pervasive Computing\"\n\"Federated Reconnaissance: Efficient, Distributed, Class-Incremental Learning\".\n3.Lack of comparison of reasoning efficiency: Client-side reasoning on large models such as \"ViT\" imposes a large computational overhead, and this paper does not compare the reasoning overheads of different approaches.\nWriting:\n1.Introduction, paragraph 3, second line: \"the performance\" should be deleted.\n2.Introduction, paragraph 3, line 8: \"based on prompt learning inspired by prompt learning\" is redundant.\nOther:\n1.The code in the link in the article contains author information\nhttps://anonymous.4open.science/r/an122pouyyt789/l2plib/continual_datasets/continual_datasets.py\nQuestions:\n1.How does this article address catastrophic forgetting as well as non-i.i.d.?\n2.How does the inference overhead of this paper's method compare to other comparative methods?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9261 by Reviewer 5UUj", "Subheading": "Official ReviewbyReviewer 5UUj30 Oct 2023, 23:11 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis article proposes a novel prototypes-injected prompt (PIP) method for the FCIL problem. PIP aggregates only three parameters, prompt, head, and prototypes, which greatly reduces communication overhead while improving model accuracy. Extensive experiments have proven the effectiveness of PIP.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe logic of the article is clear, the story line makes sense, and it is also better written.\nWeaknesses:\nThis paper lacks model architecture diagrams for specific implementations of PIP and some details need to be refined. In order to make the contributions of the article clearer and easier to understand, the following issues need to be addressed:\nBased on Fig. 1, a concrete model diagram of the proposed prototypes-injected prompt (PIP) approach should be given in Section IV, incorporating the dual-prompt, prototype augmentation, and server weighted Gaussian aggregation modules.\nAlthough the experimental part of the article proves that the performance improvement of PIP is significant, we notice that PIP uses a different backbone than the comparison method, which is very unfair. It is recommended to compare under the same backbone.\nThe readers will be more excited to see more local clients involved than fewer local clients involved. As we konw, in the practical application of FCIL, we always want to solve the problem for more clients. It is recommended to add and analyze the performance of the situation.\nThe model was trained and tested only on smaller datasets. How does it perform on slightly larger datasets, such as ImageNet-R or DomainNet?\nIn real-world FCIL problems, the number of clients and the training ratio of each client is unknown, so whether weighting by ratio is necessary. Also, in the ablation experiments, The weighted aggregation module improves the performance very limited and this module may increase the complexity of the model.\nPlease add the experiments of PIP under three datasets at T=10. Also, the total number of classes for the three datasets in Fig2 is incorrectly labeled, The CIFAR100 and miniImageNet datasets each contain 100 classes.\nThere are a lot of math symbols in the article, so check to make sure that a specific explanation is given for each symbol. For example, w_c2^tfor prototype augmentation in the proposed method, when lowercase w means.\nIn the related work section, GLVC Dong et al. (2022) should be GLFC Dong et al. (2022). Please check carefully in the article for the same error.\nQuestions:\nSee the above\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9261 by Reviewer P3dj", "Subheading": "Official ReviewbyReviewer P3dj30 Oct 2023, 00:48 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn this work, the authors focus on the  Federated Class Incremental Learning (FCIL) to address the catastrophic forgetting and non-IID data distribution in continual learning. For this purpose, they proposed a method, Prototypes-Injected Prompt (PIP), which introduces prototype injection, augmentation, and weighted Gaussian aggregation. By comparing this model with the baselines, they showed that the proposed model  outperforms existing methods by 14-33% in CIFAR100, MiniImageNet, and TinyImageNet datasets.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe authors proposed a prompt-based federated continual learning, in order to solve the FCIL problem.\nThe authors designed a new baseline method for the FCIL problem\nThey conducted extensive experiments on three public datasets and demonstrated the robustness of the proposed method in different task sizes, smaller participating clients, and smaller rounds per task.\nWeaknesses:\nI suggest the authors provide some detail information of proposed model, in order to help the reproduction.\nI suggest the authors give some introduction for the specific task, which may help the readers to understand their work clearly.\nQuestions:\nPlease refer to weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNan\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers.\nCode Of Conduct:\nYes"}]}, "lF2aip4Scn": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "reinforcement learning, regularization in reinforcement leaning, learning with demonstrations, reinforcemenet learning with human feedback", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We showed a theoretically efficient way to inject expert demonstrations into RL agent and, moreover, into RLHF.", "Abstract": "Incorporating expert demonstrations has empirically helped to improve the sample efficiency of reinforcement learning (RL). This paper quantifies theoretically to what extent this extra information reduces RL's sample complexity. In particular, we study the demonstration-regularized reinforcement learning framework that leverages the expert demonstrations by $\\mathrm{KL}$-regularization for a policy learned by behavior cloning. Our findings reveal that using $N^{\\mathrm{E}}$ expert demonstrations enables the identification of an optimal policy at a sample complexity of order $\\widetilde{\\mathcal{O}}(\\mathrm{Poly}(S,A,H)/(\\varepsilon^2 N^{\\mathrm{E}}))$ in finite and $\\widetilde{\\mathcal{O}}(\\mathrm{Poly}(d,H)/(\\varepsilon^2 N^{\\mathrm{E}}))$ in linear Markov decision processes, where $\\varepsilon$is the target precision, $H$ the horizon, $A$ the number of action, $S$ the number of states in the finite case and $d$ the dimension of the feature space in the linear case. As a by-product, we provide tight convergence guarantees for the behavior cloning procedure under general assumptions on the policy classes. Additionally, we establish that demonstration-regularized methods are provably efficient for reinforcement learning from human feedback (RLHF). In this respect, we provide theoretical evidence showing the benefits of KL-regularization for RLHF  in tabular and linear MDPs. \nInterestingly, we avoid pessimism injection by employing computationally feasible regularization to handle reward estimation uncertainty, thus setting our approach apart from the prior works.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "reinforcement learning", "Submission Number": "9260", "PDF Url": "https://openreview.net/pdf?id=lF2aip4Scn"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9260 by Area Chair Ct85", "Subheading": "Meta ReviewbyArea Chair Ct8508 Dec 2023, 22:55 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\n## Overall Assessment:\nThe paper presents a significant theoretical contribution to the field of Reinforcement Learning (RL), particularly in the domain of demonstration-regularized reinforcement learning and reinforcement learning with human feedback (RLHF). The authors have theoretically quantified how expert demonstrations can improve the sample efficiency of RL, offering new insights into the utility of expert demonstrations in RL and RLHF settings.\n\n## Strengths:\n- Theoretical Depth: The paper offers a rigorous theoretical analysis, including proofs and convergence guarantees for behavior cloning procedures under general assumptions.\n- Novelty: The demonstration-regularized reinforcement learning framework and its application in RLHF are novel contributions, offering fresh perspectives on leveraging expert demonstrations in RL.\n- Practical Relevance: The approach aligns with practical applications, particularly in settings where expert demonstrations are available, making the findings relevant for real-world RL applications.\n\n## Weaknesses:\n- Presentation and Clarity: Multiple reviewers pointed out issues with the presentation, particularly the heavy reliance on appendices and lack of clarity in explaining proof techniques and algorithmic contributions in the main text.\n- Assumptions and Limitations: The assumption of near-optimal expert demonstrations and the lack of empirical validation were noted as limitations, although these are somewhat mitigated by the theoretical nature of the work.\n\n## Reviewer Consensus:\nWhile there were initial concerns regarding the presentation and the assumptions made in the paper, the authors addressed most of these through revisions and clarifications. The reviewers appreciated the theoretical contributions and the clarity improvements made in response to feedback. The consensus leans towards acceptance, recognizing the paper\u2019s contribution to the theoretical understanding of RL with expert demonstrations.\nJustification For Why Not Higher Score:\nThe decision to accept the paper is based on its strong theoretical contributions and the successful addressal of concerns raised during the review process. However, it is recommended that future work should aim to relax some of the assumptions, particularly regarding the optimality of expert demonstrations, and include empirical validations to strengthen the practical applicability of the proposed methods.\nJustification For Why Not Lower Score:\nThe paper has sufficient theoretical contribution. The authors have also addressed the reviewers\u2019 concerns."}, {"Heading": "Comment on proof techniques, theoretical contribution, and presenetation choices", "Subheading": "Official CommentbyAuthors18 Nov 2023, 06:35Everyone", "Content": "Comment:\nWe would like to emphasize a particular proof and algorithmic techniques used in our results and explain why we do not include some of the results in the main text. Unfortunately, due to space constraints we cannot include all these discussions in full length in the main body of the paper.\nIn a new rebuttal revision of the paper we have added a brief discussion on Bernstein conditions for behavior cloning, discussion on assumption for behavior cloning in the linear setting, and an important algorithm difference between UCBVI-Ent and UCBVI-Ent+ that allows to improve the convergence guarantees. It is highlighted by a red color.\n\n- In Section B, we showed $O(1/N)$ convergence rates for behavior cloning. To achieve them, we first switched to  smoothed version of the  KL-divergence (see e.g. Hazan et al. (2019) for a similar idea) and then verified the so-called Bernstein condition (see e.g. Bartlett & Mendelson, 2006): we showed that the variance of the smoothed version of the policy log-likelihood ratio is controllable by just KL-divergence itself up to some logarithmic multiplicative factors and second-order additive factors. However, since the focus of our paper is mainly on reinforcement learning with demonstrations and preferences, we decided to not include the proof in the main text.\n\n- In Section C, we introduced the setting of RL with demonstrations  and state the results on its convergence relying on the analysis of UCBVI-Ent+ and LSVI-Ent algorithms. We decided to focus on a novel demonstration-regularized setting instead of introducing the regularized BPI algorithms since the effect of fast rates is already studied in Tiapkin et al. (2023). This focus allowed us to  clearly demonstrate the usefulness of regularization in RL in more practical scenarios from a theoretical viewpoint. Nethertheless, we included a novel algorithmic idea of UCBVI-Ent+ into the main text of  the revised version.\n\n- In Section D, we introduced RLHF with demonstrations and proposed a simple algorithm that shares similarity with real-world algorithms that have already been applied to fine-tuning of large language models (see Remark 6). To show the theoretical properties of these demonstration-regularized algorithms, we have to 1) show the theoretical properties of MLE estimate of the underlying reward function and 2) upper bound the policy error by applying Bernstein-type inequality introduced by Talebi & Maillard, (2018) and by verifying the Bernstein condition. \n\n    * Theoretical properties of MLE estimate of reward function were already studied in the literature, see Lemma 2 by Zhan et al. (2023a) and we decided to not include them in the main text. However, we did not find the proof of the  statement we exactly need  in references and provided the proof for completeness in Appendix F.\n\n    *  Regarding the bounding the policy error, we did not include the proof since it is very technical and heavily relies on the existing Bernstein-type inequalities in terms of KL-divergence by Talebi & Maillard, (2018).\n\nHowever, if the reviewers have a different viewpoint and might suggest a better organization of the achieved results, we would be  happy to implement it. \n\n\nHazan, E., Kakade, S., Singh, K., & Van Soest, A. (2019, May). Provably efficient maximum entropy exploration. In International Conference on Machine Learning (pp. 2681-2691). PMLR.\n\nBartlett, P. L., & Mendelson, S. (2006). Empirical minimization. Probability theory and related fields, 135(3), 311-334."}, {"Heading": "Clarification on a difference between UCBVI-Ent+ and UCBVI-Ent", "Subheading": "Official CommentbyAuthors14 Nov 2023, 07:24 (modified: 14 Nov 2023, 08:06)EveryoneRevisions", "Content": "Comment:\nIn this general comment we would like to make a general clarifications regarding BPI in regularized MDPs. First of all, we would like to acknowledge that each time we refer to UCBVI-Ent algorithm we refer to its version for general regularized MDPs, as it is mentioned in Appendix D.2 of Tiapkin et al. (2023).\n\nNext, we would like to emphasize the differences between UCBVI-Ent and UCBVI-Ent+  allowing the latter algorithm to achieve sample complexity of order $\\mathcal{O}(\\varepsilon^{-1})$ which improves upon $\\mathcal{O}(\\varepsilon^{-2})$. \n\nThe UCBVI-Ent+ algorithm operates by sampling trajectories based on an exploratory version of the regularized-greedy policy. This exploratory policy corresponds to an optimistic solution of the regularized MDP, distinguishing it from the UCBVI and UCBVI-Ent algorithms, which employ the regularized-greedy policy without additional exploration.\nThe unique aspect of the UCBVI-Ent+ algorithm involves a novel randomization over the horizon, denoted as $H$. Specifically, at a randomly chosen time step, the policy acts greedily concerning a gap between upper and lower bounds on the optimal Q-value. The formal definition of this exploration policy, denoted as $\\pi^{t,(h')}$, can be found in Appendix D.2 after equation (9). The compressed form of the played policy is referred to as $\\pi^{\\mathrm{mix}, t}$.\n\n\nImportantly, this additional randomization introduces control over a gap value $G^t$, as defined in equation (10). Notably, $G^t$ scales *quadratically* with the width of a confidence interval on the optimal Q-value. This quadratic scaling is crucial for achieving fast rates, specifically $\\mathcal{O}(\\varepsilon^{-1})$. This efficiency is akin to the reward-free algorithm RL-Explore-Ent by Tiapkin et al. (2023), but with an improved dependence on $H$ and $S$. It's worth highlighting that the use of the standard greedy policy would not enable us to control  the expected width of the corresponding confidence intervals. This control is essential for exploiting the strong smoothness of our regularized MDP, ultimately leading to the achievement of fast rates.\n\nLSVI-Ent algorithm also actively uses an explorative version of regularized-greedy policy, that allows us to control the quadratic quantity that appears in Lemma 19. As a result, the final rate for a linear case also scales with $\\mathcal{O}(\\varepsilon^{-1})$ instead of $\\mathcal{O}(\\varepsilon^{-2})$ in non-regularized setup."}, {"Heading": "Official Review of Submission9260 by Reviewer XPKe", "Subheading": "Official ReviewbyReviewer XPKe06 Nov 2023, 14:34 (modified: 21 Nov 2023, 17:23)EveryoneRevisions", "Content": "Summary:\nThe authors propose KL-regularized online RL algorithms and provide an upper bound on the sample complexity of this algorithm in tabular MDP and linear MDP settings.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe authors provide a thorough analysis of the algorithms, to justify the efficiency of the RL algorithms with access to an expert dataset.\nWeaknesses:\n1. There is limited discussion on the relationship between the pure online learning version of LSVI-UCB and UCBVI+.\n2. The paper can be better organized, there are too many references pointing towards the appendix.\nQuestions:\nI am not an expert in RL theory, I am a bit confused by the results presented in Corollary3 and Theorem6, where the bound presented in Corollary3 depends on $N^E$, whereas the bound in Theorem6 does not. Intuitively, I suppose the sample complexity would eventually depend on the size of the expert dataset. Can authors explain this?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors14 Nov 2023, 07:26Everyone", "Content": "Comment:\nWe would like to thank reviewer XPKe for the careful reading and the constructive feedback.  Please find below our response to the main points raised in the review.\n\n- Limited discussion on LSVI-UCB-Ent and UCBVI-Ent algorithms;\n\nUnfortunately, the limited discussion on the regularized BPI algorithms is a byproduct of constrained space. We've included a general comment highlighting the novel features of UCBVI-Ent+ and LSVI-Ent algorithms compared to their non-regularized counterparts. Additionally, we present an adaptation of the UCBVI-Ent algorithm for general regularized MDPs in a separate comment dedicated to all the reviewers.\n\nMoreover, it's important to stress that the primary contribution of the paper lies not solely in the regularized BPI algorithms but in their combination with behavior cloning techniques. This combination illustrates the convergence properties of simple and implementable algorithms that are already widely utilized in practice.\n\n- The paper can be better organized, there are too many references pointing towards the appendix.\n\nWe would greatly appreciate any suggestions from the reviewer regarding the reorganization of the main results of the paper, considering the constraint of a 9-page limit.\n\n- Why Theorem 6 does not depend on the size of the expert dataset $N^{\\mathrm{E}}$?\n\nTheorem 6 is devoted to the sample complexity of best policy identification for KL-regularized MDPs with respect to any reference policy and any regularization coefficient $\\lambda > 0$. To specialize these bounds to Corollary 3, we need to take a behavior-cloning policy $\\pi^{\\mathrm{BC}}$ as a reference one and choose the regularization parameter  $\\lambda$ depending on the number of expert trajectories $N^{\\mathrm{E}}$ (choice $\\lambda^\\star$ from Theorem 3) and the desired accuracy $\\varepsilon$ as $\\mathcal{O}(N^{\\mathrm{E}} \\varepsilon / (SAH))$ (as described in Corollary 3)."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 14:54Everyone", "Content": "Comment:\nWe would like to acknowledge reviewer XPKe that we included the description of algorithm UCBVI-Ent+ in the main text as well as a discussion on its difference with UCBVI-Ent and RL-Explore-Ent. Additionally, we reduced the number of references towards statements in the Appendix by including the sample complexity result for UCBVI-Ent+ and LSVI-UCB-Ent in the main text. All the changes are highlighted in red."}, {"Heading": "Official Comment by Reviewer XPKe", "Subheading": "Official CommentbyReviewer XPKe21 Nov 2023, 17:23Everyone", "Content": "Comment:\nThank you for the clarification and the revision. I would like to raise my rating to 6."}]}, {"Heading": "Official Review of Submission9260 by Reviewer zApY", "Subheading": "Official ReviewbyReviewer zApY04 Nov 2023, 17:28 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper studied demonstration-regularized reinforcement learning (RL), where the learner first performs behavioral cloning on expert-generated demonstrations using maximum likelihood estimation. Then during the online interaction with the underlying environment, the learner penalizes deviation of the learned policy from the one learned in the behavioral cloning phase. The paper provided a theoretical analysis of these two phases. For behavioral cloning, the authors show that the KL divergence between the learned policy and the expert policy decreases linearly as the number of demonstrations grows. This holds for both tabular MDPs and linear MDPs under certain assumptions. Then based on this result, the authors further studied the regularized online learning scenario and the RLHF setting. In both cases, the authors are able to prove a fast convergence rate for the proposed algorithms.\nSoundness:\n4 excellent\nPresentation:\n4 excellent\nContribution:\n4 excellent\nStrengths:\n(1) The paper performed a strong and solid theoretical study of behavioral cloning for both tabular and linear MDPs. The authors proved that the KL-divergence between the learner policy and the expert policy decreases linearly as the number of demonstrations grows. The authors also complemented the above positive results with a lower bound on the convergence rate. In terms of the dependency on the number of demonstrates, the upper bound and lower bound match. This is a nice and great result. Based on that, the authors further performed analysis on their proposed demonstration-regularized RL algorithms and the RLHF algorithms, and both achieved surprisingly fast convergence rates. Overall, the paper has made significant technical contributions.\n\n(2) The paper studied a very novel, interesting, yet challenging problem. The topic is of particular interest to the theoretical RL community, and I can forsee that the results of this paper significantly push the frontiers of RL theory and will drive more research along this line.\nWeaknesses:\n(1) It would be great to include some empirical studies, although this is purely a theory paper.\nQuestions:\n(1) Can you provide some empirical results to validate the theoretical findings of this paper?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors14 Nov 2023, 07:27Everyone", "Content": "Comment:\nWe thank reviewer zApY for the positive and encouraging feedback. We will add numerical results for our tabular algorithm."}]}, {"Heading": "Official Review of Submission9260 by Reviewer Muxw", "Subheading": "Official ReviewbyReviewer Muxw31 Oct 2023, 17:37 (modified: 21 Nov 2023, 10:54)EveryoneRevisions", "Content": "Summary:\nThis paper studies demonstration-regularized RL where an agent is supposed to find a near optimal policy given an offline dataset that is collected from an expert policy. The paper theoretically shows that given $N^E$ expert samples, the sample complexity of finding a $\\epsilon$-optimal policy reduces by a factor of $1/N^E$ in both tabular and linear MDPs. Moreover, the paper extends the proposed method to RLHF and theoretically justify the efficiency of it.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\n1. The paper provides comprehensive theoretical results on various settings in demonstration-regularized RL.\n2. The results are nice and show a strong benefit using expert demonstrations.\nWeaknesses:\n1. I prefer that there is a separated \"related works\" section such that the presentation is clear.\n2. The contributions from the algorithm design part seem not significant. The algorithm is a combination of imitation learning and regularized RL.\n3. The results highly depends on the performance of the expert policy. However, in real life applications, obtaining expert demonstrations is usually expensive, and there might be far less offline demonstrations that that considered in this paper. Specifically, from Corollary 3, it seems that the benefit occurs when $N^E>H^3SA$, which is close to the typical sample complexity in standard RL, which might be too much in real applications.\nQuestions:\nWhile the paper provides the lower bound for the imitation learning, is there any lower bound for the regularized RL?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nN/A\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors14 Nov 2023, 07:29Everyone", "Content": "Comment:\nWe would like to thank reviewer Muxw for the careful reading and the constructive feedback.  Please find below our response to the main points raised in the review.\n\n- The contributions from the algorithm design part seem not significant. The algorithm is a combination of imitation learning and regularized RL.\n\nWe are particularly interested in algorithms that are scalable and easily implementable. The simplicity of our algorithm enables its straightforward implementation beyond tabular and linear settings. Our primary focus in this work is to analyze the existing practical pipeline and demonstrate its provable efficiency.\n\nOn the other hand, our algorithm, UCBVI-Ent+, introduces a novel time step randomization to control the widths of the confidence intervals, as described in a separate comment available to all reviewers. In our view, this represents a significant algorithmic contribution, enabling the achievement of optimal complexity bounds.\n\n\n- The results highly depends on the performance of the expert policy. However, in real life applications, obtaining expert demonstrations is usually expensive, and there might be far less offline demonstrations that that considered in this paper. Specifically, from Corollary 3, it seems that the benefit occurs when $N^E > H^3 SA$, which is close to the typical sample complexity in standard RL, which might be too much in real applications.\n\n\nRegarding Corollary 3, it is important to emphasize that with significantly less expert data, reconstructing the expert policy with a small error becomes impossible, as indicated in the lower bound (Theorem 2). The application of behavior cloning techniques makes no sense with such a limited amount of data. However, with a reasonable amount of expert data, our approach demonstrates convergence to the optimal policy, surpassing the behavior cloning outcome.\n\nIn the RLHF setup, it's crucial to highlight that even a relatively small amount of expert data results in a straightforward and practical algorithm. This algorithm delivers a policy which is close  to the optimal one when provided with a reasonably large preference dataset. In contrast to existing theoretical algorithms for RLHF, our approach distinguishes itself by not necessitating the solution of complex min-max problems to achieve pessimism. Instead, it aligns more closely with approaches actively applied in practical settings."}, {"Heading": "Official Comment by Reviewer Muxw", "Subheading": "Official CommentbyReviewer Muxw21 Nov 2023, 10:54Everyone", "Content": "Comment:\nThanks for the response. After reading the revision and other general answers, I appreciate the contribution from the behavior cloning and the corresponding lower bound. In addition, other contribution also seems good. I have decided to raise my score to 6."}]}, {"Heading": "Official Review of Submission9260 by Reviewer UXmS", "Subheading": "Official ReviewbyReviewer UXmS23 Oct 2023, 18:01 (modified: 20 Nov 2023, 15:38)EveryoneRevisions", "Content": "Summary:\nThis paper studies two new hybrid setting which are novel/uncommon in the literature: (i) demonstration regularized RL and (ii) Demonstration Regularized RLHF.\n\nIn (i) both expert demonstrations from an $\\epsilon$-optimal policy and online access to an MDP with reward function are possible. In (ii) the reward function is not available but it can be inferred thanks to a Preference Based Model introduced in Assumption 4.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nBoth the newly introduced settings are interesting and matches practical situations.\nWeaknesses:\nThere are several technical weaknesses in my opinion.\n\nThe main weakness is in my opinion that the setting seems \n\n1) The lower bound in Theorem 2 turns unfortunately vacuous in the limit of $\\gamma \\rightarrow 0$.\n\n2) It is unclear why the class of linear policies at the third line of Section 3.2 is considered to be not learnable. In fact, under this choice [1] proves in their Theorem 5 that it is possible to recover an $\\epsilon$-suboptimal policy compared to the expert with behavioural cloning.\n\n3) Corollary 3 requires the expert to be $\\mathcal{O}(\\epsilon)$ optimal but I would expect that, given the reward knowledge, it should be possible to prove a sample complexity bound without the assumption on the $\\mathcal{O}(\\epsilon)$ optimality of the expert.\nTo see this think to the case of any BPI algorithm which requires no expert at all to learn an $\\epsilon$-optimal policy.\n\n4) I think that Lemma 11 should be referred as the standard performance difference lemma.\n\n5) Just before Corollary 3, it is said  that \"UCBVI-Ent+ algorithm for regularized BPI. It is a modification of the algorithm UCBVI-Ent by\nTiapkin et al. (2023) with improvement sample complexity\". However, it is not explained which is the crucial difference between the two algorithms. In particular, also the settings are different because UCBVI-Ent+ uses reward information while UCBVI-Ent can be used only for maximum entropy exploration and not to solve Regularized MDPs but this difference is not explained in the main text.\n\n\n[1] ( Rajamaran et al., 2021 ) On the Value of Interaction and Function Approximation in Imitation Learning.\nQuestions:\nQ1) Is it possible to prove a bound which does not require the assumption that the expert is $\\epsilon$ optimal ?\n\nQ2) Why the regularization is needed in the tabular case but not in the linear one ? I am referring to Section 3.2\n\nQ3) How can UCBVI-Ent+ achieve $\\mathcal{O}(\\epsilon^{-1})$ sample complexity according to Theorem 5 while UCBVI-Ent achieves a worst sample complexity of $\\mathcal{O}(\\epsilon^{-2})$ ?\n\nQ4) What are the definitions of $\\pi^{t,(h)}$ and $\\tilde{\\pi}^t$ in Algorithm 3?\n\nQ5) In the setting of Demonstration Regularized RLHF is it necessary to have the coefficients defined in equation 3 in the bound ?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors, Part 1", "Subheading": "Official CommentbyAuthors14 Nov 2023, 07:31Everyone", "Content": "Comment:\nWe would like to thank reviewer UXmS for the careful reading and the constructive feedback.  Please find below our response to the main points raised in the review.\n\n- The lower bound in Theorem 2 turns unfortunately vacuous in the limit of $\\gamma \\to 0$.\n\nA fixed $\\gamma$ enables us to establish a general lower bound by constraining the space of policies we aim to learn. Thus, the minimax lower bound with respect to the space of all policies is lower-bounded by the minimax lower bound with respect to the space of restricted policies. Therefore, choosing any fixed $\\gamma$ (for example, $\\gamma = 1/N$) allows us to deduce a valid and reasonable lower bound.\n\n- It is unclear why the class of linear policies at the third line of Section 3.2 is considered to be not learnable. In fact, under this choice [1] proves in their Theorem 5 that it is possible to recover an $\\varepsilon$-suboptimal policy compared to the expert with behavioural cloning.\n\nIt is important to emphasize that the behavior cloning defined in our paper aims not to find an $\\varepsilon$-optimal policy but to reconstruct the initial behavioral policy in trajectory KL-distance. To make the algorithm implementable, defining a hypothesis class with policies that are differentiable or at least continuous with respect to the learnable parameters becomes necessary. In the setting of purely greedy policies, the mentioned linear class of policies lacks these properties, thus preventing the efficient minimization of the log-loss. We will add an additional discussion and a reference to [1].\n\n\n- Corollary 3 requires the expert to be $O(\\varepsilon)$-optimal but I would expect that, given the reward knowledge, it should be possible to prove a sample complexity bound without the assumption on the optimality of the expert. To see this think to the case of any BPI algorithm which requires no expert at all to learn an $O(\\varepsilon)$-optimal policy.\n\n\nWe acknowledge that the assumption of nearly optimal experts might be considered strong. If it is known a priori that the expert is far from optimal, a viable approach is to simply set $\\lambda=0$ and employ a stopping rule from UCBVI-BPI (M\u00e9nard et al. (2021)).\n\nHowever, it's important to emphasize that the primary goal of this paper is to provide an analysis of an algorithm actively used in practice, where these assumptions are deemed reasonable.\n\n\n- I think that Lemma 11 should be referred as the standard performance difference lemma.\n\nWe agree that Lemma 11 is already known in literature, so we will add the corresponding reference.\n\n- Just before Corollary 3, it is said that \"UCBVI-Ent+ algorithm for regularized BPI. It is a modification of the algorithm UCBVI-Ent by Tiapkin et al. (2023) with improvement sample complexity\". However, it is not explained which is the crucial difference between the two algorithms. In particular, also the settings are different because UCBVI-Ent+ uses reward information while UCBVI-Ent can be used only for maximum entropy exploration and not to solve Regularized MDPs but this difference is not explained in the main text.\n\nWe add a separate comment (available to all reviewers) regarding the key differences between UCBVI-Ent and UCBVI-Ent+."}, {"Heading": "Official Comment by Authors, Part 2", "Subheading": "Official CommentbyAuthors14 Nov 2023, 07:33Everyone", "Content": "Comment:\n- Q1) Is it possible to prove a bound which does not require the assumption that the expert is $\\varepsilon$-optimal ?\n\nWe believe that it is possible (in the setup of RL with demonstrations) since a usual BPI algorithm allows us to provide an optimal policy without any additional data. However, the resulting algorithm using  data from a highly suboptimal expert may be significantly different from the proposed one. So we focus on a simple and implementable approach.\n\n- Q2) Why the regularization is needed in the tabular case but not in the linear one ? I am referring to Section 3.2\n\nRegularization in the linear setting is unnecessary because we add constraints on the parameters of the class. Alternatively, one can introduce ridge regularization with an appropriate regularization parameter and make no direct restrictions on the regression coefficients. In fact, these two approaches are nearly equivalent.\n\n- Q3) How can UCBVI-Ent+ achieve $O(\\varepsilon^{-1})$ sample complexity according to Theorem 5 while UCBVI-Ent achieves a worst sample complexity of $O(\\varepsilon^{-2})$?\n\nWe have included a separate comment detailing the distinctions between UCBVI-Ent and UCBVI-Ent+. The critical feature that enables UCBVI-Ent+ to achieve $O(\\varepsilon^{-1})$ sample complexity is the exploitation of the strong convexity of the regularizer. However, to implement this effectively, it is necessary to introduce additional time randomization to the policy played during the episodes. We believe that this is a novel aspect of our work on the algorithmic side.\n\n- Q4) What are the definitions of $\\pi^{t, (h)}$ and $\\tilde{pi}$ in Algorithm 3?\n\nThe definition of $\\pi^{t, (h\u2019)}$ is given after sampling rules (9) in Appendix D.2: $\\pi^{t, (h\u2019)}_h$ is equal to an regularized-greedy optimistic policy given by optimistic planning for all steps $h \\not = h\u2019$ and $\\pi^{t, (h\u2019)}_h$ is a greedy with respect to a difference between upper and lower estimate for optimal Q-value for a step $h = h\u2019$. In particular, this randomization is crucial to achieve $\\mathcal{O(\\varepsilon^{-1})}$ sample complexity. Regarding $\\tilde{pi}$, it is a misprint and the final policy should be $\\bar{\\pi}^t$, thank you for showing it to us.\n\n- Q5) In the setting of Demonstration Regularized RLHF is it necessary to have the coefficients defined in equation 3 in the bound ?\n\nAs it is stated in Corollary 4, to achieve $O(\\varepsilon) $ quality it is enough to have either large enough $N^{\\text{E}}$ (independent on a coefficient defined in (3)) or large enough $N^{\\text{RM}}$ depending on the coefficient defined in (3). If we assume only large enough $N^{\\text{RM}}$, then the dependence on $C_r$ seems unavoidable due to the  lower bounds in Theorem 3 by Zhan et al. (2023a)."}, {"Heading": "Official Comment by Reviewer UXmS", "Subheading": "Official CommentbyReviewer UXmS15 Nov 2023, 04:49Everyone", "Content": "Comment:\nDear authors,\n\nThanks for your detailed response !\n\nAt the moment I don't feel like rising my score. I think there is value in the current submission but I think that the presentation of the results do not match the acceptance standard. Since this is a theoretical paper it would be important to convey the main new proof techniques to attain the improved results.\n\nHowever, this is not done in the main text but only in the very long Appendix.\n\nBe sure however that I will discuss with the other reviewers to check whether they share my viewpoint or not.\n\nBest,\n\nReviewer UXmS"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 06:35Everyone", "Content": "Comment:\nWe are happy that you think that there is a value in the current submission and we are happy that we answered all your questions. \nWe added a separate comment devoted to theoretical techniques that we used and also we tried to explain our presentation choice. Also we would like to underline that the main contribution of this paper is not novel proof techniques but general ideas that generalizes the best policy identification and imitation learning with a simple and implementable algorithmic technique. If you can suggest a better way to introduce the results given a 9 pages constraint we would be happy to try to implement this organization."}, {"Heading": "Official Comment by Reviewer UXmS", "Subheading": "Official CommentbyReviewer UXmS20 Nov 2023, 03:58Everyone", "Content": "Comment:\nDear Authors,\n\nThanks for adding some discussions about the linear expert condition and explaining the differences between UCBVI-Ent and UCBVI-Ent+.\n\nI understand that the 9 pages limit can be restrictive for all your contributions. However, I think that the main text should be structures to convey a clearer presentation of maybe fewer contribution.\n\nTo this end, my suggestion would be to first state the result in Corollary 3 using the existing results in Tiapkin et al. 2023 (UCBVI-Ent) and shows which would be the result in that case.\n\nThen, you can explain the algorithm UCBVI-Ent+ (adding the pseudocode in the main text) and show the improvement in sample complexity compared to the one obtained using UCBVI-Ent and explain that the reason for the improvement is the fact that UCBVI-Ent can leverage the strong convexity of the KL divergence.\n\nThe current paragraph in red is still bit difficult to parse in my opinion and the pseudocode for UCBVI-Ent+ is needed.\n\nProbably, implementing these changes will require to move the RLHF part to the Appendix and just mention this extension in the main text. \n\nImplementing these changes would make the paper way easier to appreciate in my opinion.\n\nFinally, I have a question. Would have been possible to adapt RL-Explore-Ent to the regularised MDP setting to attain the same sample complexity without the need of introducing a new algorithm in this work ?\n\nBest,\nReviewer UXmS"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 14:42Everyone", "Content": "Comment:\nWe would like to thank reviewer UXmS for the valuable suggestions on paper organization.\n \nTo implement these suggestions, we reorganized Section 4 and included a description of the UCBVI-Ent+ algorithm as well as discussion on why the UCBVI-Ent algorithm cannot provide any acceleration using the expert demonstrations. The discussions and all the changes are highlighted in red.\n\nTo free up some space, we removed a lower bound statement for behavior cloning and moved the definition of a coefficient $C_r$ to Appendix. \n\n- Would have been possible to adapt RL-Explore-Ent to the regularized MDP setting to attain the same sample complexity without the need of introducing a new algorithm in this work ?\n\nWe do not think that it is possible to improve the sample complexity of RL-Explore-Ent algorithm from $O(H^8 S^4 A / (\\lambda \\varepsilon)$ to $O(H^5 S^2 A / (\\lambda \\varepsilon))$ without significant algorithmic changes. It may be possible to improve the dependence in $S$ for the RL-Explore-Ent bound by switching for a different base regret minimizer algorithm than Euler, but improving the dependance in $H$ seems much more challenging since Euler is optimal in its dependence on $H$. Furthermore, note that even if we manage to match the bound of UCBVI-Ent+, we would still prefer not to use the RL-Explore-Ent algorithm because of its very large space complexity. Indeed RL-Explore-Ent needs to store $O(H^8S^4/\\epsilon)$ policies in order to construct the mixture while the space complexity of UCBVI-Ent+ is only of order $O(HS^2A)$. Another reason why we used UCBVI-Ent instead of RL-Explore-Ent is that it is easier to adapt to the linear setting. In general, reward-free algorithms in the linear setting become much more complicated, in contrast to our simple randomization idea."}, {"Heading": "Official Comment by Reviewer UXmS", "Subheading": "Official CommentbyReviewer UXmS20 Nov 2023, 15:36Everyone", "Content": "Comment:\ndear authors,\n\nthanks a lot for the revision !\n\ni think it solves my concerns about the presentation because now the randomization idea is well presented and it is easier to understand how lambda should be set to obtain the bound for the demonstration regularized RL setting.\n\nas a result i will rise my score to 6.\n\nI think that the main remaining limitation is the assumption that the expert is epsilon optimal. Hopefully the authors will address this question in some future work.\n\nBest,\nReviewer"}]}]}, "jFiFmHrIfD": {"paper_info": {"Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Computer Vision, Active Learning, Interactive Labeling, Self-Supervised Learning", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "In computer vision, attaining exceptional performance often necessitates access to large labeled datasets. The creation of extensive datasets through manual annotation is not only cost-prohibitive but also practically infeasible due to the scarcity of positive samples in imbalanced datasets where negative samples dominate. To tackle this intricate problem, we introduce Efficient Latent Space-based Self-Supervised Active Learning Search (ELSA), an active learning-based labeling assistant. ELSA distinguishes itself from existing interactive annotation methods by focusing exclusively on positive class labeling in massively imbalanced datasets replete with a substantial number of negative samples. Through the automatic exclusion of the majority of negative samples, ELSA achieves a remarkable level of precision and accuracy in its search. This novel framework comprises three fundamental components: a)an iterative Nearest Neighbor Search, b)a Sophisticated Random Sampler, c)a Linear Head powered by Active Learning. Our comprehensive study provides insights into the interplay of these components and their collective impact on search efficiency. Notably, we demonstrate that ELSA achieves orders of magnitude superior performance, in average starting with as little as 5 or less positive samples in ImageNet 1k we managed to detect as much as 80% of all the examples belonging to that class by only labeling as little as 0.67% of the entire dataset manually.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9259", "PDF Url": "https://openreview.net/pdf?id=jFiFmHrIfD"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9259 by Area Chair PU9t", "Subheading": "Meta ReviewbyArea Chair PU9t06 Dec 2023, 16:57 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe submission presents an active learning algorithm for use with computer vision models, in particular where negative class labels dominate the distribution.  The proposed algorithm combines several components (nearest neighbor search, random search, and linear head based score),  which are all evaluated in an ablation study.\nI do not recommend accepting the paper in its current form. The paper does a convincing job of justifying the design decisions made for the proposed approach, but it critically is lacking comparisons to other state-of-the-art active learning approaches (as highlighted by the reviewers).  Adding these comparisons will significantly increase the quality of the submission and should be addressed before publication.\nJustification For Why Not Higher Score:\nLack of comparisons to other baselines in a primarily empirical paper is a critical flaw.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9259 by Reviewer 3EJ7", "Subheading": "Official ReviewbyReviewer 3EJ704 Nov 2023, 07:51 (modified: 21 Nov 2023, 07:41)EveryoneRevisions", "Content": "Summary:\nThe paper presents a new approach to active learning-based labeling called ELSA, or the Explorative Latent Self-Supervised Active Search Algorithm. ELSA is designed to address the challenges of imbalanced datasets and limited positive samples in computer vision applications. The authors demonstrate that ELSA can achieve high levels of precision and accuracy even with just a few positive samples, making it a cost-effective and practical alternative to manual annotation. The paper also outlines the three fundamental components of ELSA and provides experimental results to support its effectiveness. Overall, the paper's contributions include a novel approach to active learning-based labeling, a detailed description of the ELSA algorithm, and empirical evidence of its effectiveness in computer vision applications.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThe authors propose a novel active learning-based labeling method which combines a Nearest Neighbour search module, A Random Sampler and a classification head, achieves orders of magnitude superior performance.\nThe authors provide empirical evidence of the effectiveness of ELSA in computer vision applications, using several benchmark datasets and evaluation metrics.\nThe paper also includes a thorough analysis of the results, discussing the strengths and limitations of the approach and comparing it to other state-of-the-art methods.\nWeaknesses:\nLack of analysis of the impact of hyperparameters such as \u201ca\u201d in the NEAREST NEIGHBOUR SEARCH: The authors do not provide a detailed analysis of the impact of hyperparameters on the performance of ELSA. This is an important aspect of the algorithm, as the choice of hyperparameters can have a significant impact on its effectiveness. A more thorough analysis of the impact of hyperparameters would help to identify the optimal settings for different datasets and applications.\nThe meanings of some symbols such as $L_e$ and $d_r$ in Section3.1 have not been provided with sufficient clarity.\nQuestions:\nHow sensitive is ELSA to the choice of hyperparameters? Can you provide a more detailed analysis of the impact of hyperparameters on the performance of the algorithm? This would help to identify the optimal settings for different datasets and applications.\nHow might ELSA be extended or modified to address other challenges in active learning-based labeling, such as the presence of noisy or mislabeled data?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 10:33 (modified: 17 Nov 2023, 10:35)EveryoneRevisions", "Content": "Comment:\nWeakness\nLack of analysis of the impact of hyperparameters such as \u201ca\u201d in the NEAREST NEIGHBOUR SEARCH: The authors do not provide a detailed analysis of the impact of hyperparameters on the performance of ELSA. This is an important aspect of the algorithm, as the choice of hyperparameters can have a significant impact on its effectiveness. A more thorough analysis of the impact of hyperparameters would help to identify the optimal settings for different datasets and applications.\nThank you for your comments. Following the suggestions from the reviewers, we have done an in-depth analysis of several hyperparameters of our algorithm. We have added the hyperparameter analysis to the appendix of our paper (Appendix C).\nThe meanings of some symbols such as $L_e$ and $d_r$ in Section3.1 have not been provided with sufficient clarity.\n$L_e$ is the labelling efficiency, i.e. the ratio of the number of positive samples discovered to the total number of samples labelled during the search process.\n$d_r$ is the discovery rate, i.e. the ratio of the number of positive samples discovered by the search algorithm to the total number of positive samples present in the dataset. To give a better understanding to the readers, we have updated section 3.1\nto provide better clarity.\nQuestions\nHow sensitive is ELSA to the choice of hyperparameters? Can you provide a more detailed analysis of the impact of hyperparameters on the performance of the algorithm? This would help to identify the optimal settings for different datasets and applications.\nELSA is robust when it comes to the choice of hyperparameters. Please see Appendix C for a detailed analysis.\nHow might ELSA be extended or modified to address other challenges in active learning-based labeling, such as the presence of noisy or mislabeled data?\nWe have added a section for noise analysis for ELSA, which can be found in the appendix (Appendix D). From our study, we see that ELSA works even in moderately noisy settings, but the labelling efficiency of the algorithm suffers as more noise is added to the algorithm. The discovery rate remains approximately constant to the overall noise that is added. The issue can be tackled using a more sophisticated active learning sampler that works well in noisy settings. Due to the sheer simplicity of the algorithm, changing the active learning component to a more sophisticated one should not be very difficult."}, {"Heading": "Reply to authors", "Subheading": "Official CommentbyReviewer 3EJ721 Nov 2023, 07:41Everyone", "Content": "Comment:\nThank the authors for the additional elaboration on the details of the paper, which has clarified the concepts such as labelling efficiency and discovery rate. Furthermore, the experiments on algorithm hyperparameters in Appendix C are comprehensive, providing a more thorough explanation of the algorithm's robustness and the correctness of hyperparameter selection. Here are some additional suggestions and concerns.\nThe paper could benefit from a clearer structure. For instance, in the beginning of Section 4, the explanation of the algorithm's different components is a bit messy. A suggested improvement is to organize it with Samper first, followed by Random Search, and then NN for better coherence.\nIn Section 4.4, the author could strengthen the explanation of why the algorithm works by referencing previous works or providing experimental proof. To make the argument more convincing, it's suggested to back up claims with references. Also, consider using actual data points instead of Figure 1 for a more persuasive visualization.\nThere are some symbol consistency problems in this paper. For example, in Algorithm 1, $\\mathcal M_{ij}$ should be written as $\\mathcal M_{ij} = MSE(g(d_i), g(\\Lambda_j))$. It's important to use the same symbols for the same concepts, like using $I_i$ in Section 3.1 but $d_i$ in Section 4.1.\nAlthough I'm not very familiar with the related works, the discussion of algorithmic time and space complexity in Section 5 may not be crucial for this task.\nThe paper and appendices experiment with hyperparameters and embedding spaces to validate the effectiveness of each component, but it lacks a crucial aspect\u2014a comparison with popular existing methods. It's important to show how the algorithm performs compared to other well-known techniques.\nThe authors conduct extensive analyses, including experiments on various hyperparameters and architectures for the proposed algorithm. However, considering some shortcomings in the writing aspect of the paper, and the insufficient reasoning behind why the algorithm is effective, as well as the lack of comparisons with more state-of-the-art (SOTA) methods in the experiments section, it is recommended to assign a rating marginally below the acceptance threshold."}]}, {"Heading": "Official Review of Submission9259 by Reviewer 4JSg", "Subheading": "Official ReviewbyReviewer 4JSg30 Oct 2023, 07:37 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes an active learning-based labeling assistant algorithm, called ELSA. The author clarifies that ELSA can help reduce the time required to label samples by orders of magnitude compared to manual labeling in large datasets dominated by many negative samples. The paper provides insights into the interplay of these components and their collective impact on search efficiency. Finally, the paper also presents proof-of-concept empirical experiments to corroborate the theoretical results.\nSoundness:\n3 good\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nAlthough I haven't thoroughly read most of the technical proofs, the results appear sound and technically correct.\nWeaknesses:\nThe paper is in general easy to follow and well-structured. There are some interesting theoretical guarantees, which seem simple and effective. Nevertheless, I have the following concerns:\nNot enough empirical evaluations.  it necessary to evaluate other state-of-the-art tabular benchmarks in Table 5.\nNovelty and limitations. The theoretical justification is interesting but the novelty in the method itself is slightly incremental, and the proposed algorithm seems based on a simple modification.\nQuestions:\nThe paper has a few English typos in different places. The setting studied in the paper is quite classical. The novelty is harder to judge for me (see my comment in the \"weaknesses\" above) but the method and algorithm proposed seem quite classical. However, because of my unfamiliarity with the related works, this is a low-confidence review.\nI could not find the code to check reproducibility.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 11:00 (modified: 17 Nov 2023, 11:05)EveryoneRevisions", "Content": "Comment:\nWeakness\nNot enough empirical evaluations. it necessary to evaluate other state-of-the-art tabular benchmarks in Table 5.\nThank you for your comments. Table 5 already includes eight different state-of-the-art self-supervised methods on which we have benchmarked our algorithm.  It would be helpful if the reviewer could elaborate on this statement:\n\"necessary to evaluate other state-of-the-art tabular benchmarks\"\n; if the reviewer wants us to run more benchmarks, their suggestions are welcome.\nNovelty and limitations. The theoretical justification is interesting but the novelty in the method itself is slightly incremental, and the proposed algorithm seems based on a simple modification.\nThe novelty of the method lies in connecting the different search components. We have used two main components in our algorithm, one of which is the standard nearest neighbour search, the other one being RandS. We claim RandS as one of our main contributions to this paper. We have described in detail in Appendix A how RandS, along with the NN component, can maximise the search. In addition, we have also described in Appendix B why a sophisticated random sampler like RandS is required for this purpose and why the usual random sampler would fail in this scenario. There are multiple works on automatizing the task of labelling in the literature, some of which are described in the paper and how they are different from our work; moreover, we focus on a more general dataset like ImageNet and Food101 to benchmark and test our algorithm. We have also shown from our analysis in Appendix D how the two components of ELSA work orthogonal to each other and maximise the search without affecting each other.\n\"I could not find the code to check reproducibility\"\nAll our source codes are in the supplementary material along with the analysis notebooks and log files. We plan to link the official Github repository in the camera-ready version."}, {"Heading": "Official Comment by Reviewer 4JSg", "Subheading": "Official CommentbyReviewer 4JSg21 Nov 2023, 23:04Everyone", "Content": "Comment:\nI have read the feedback from the authors and I still maintain my review score."}]}, {"Heading": "Official Review of Submission9259 by Reviewer HU18", "Subheading": "Official ReviewbyReviewer HU1825 Oct 2023, 23:02 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper discussed an efficient latent space based self-supervised active learning search. Typically, it focuses on positive class labeling. The method includes three components: a)an iterative Nearest Neighbor Search, b)a Sophisticated Random Sampler, c)a Linear Head powered by Active Learning, Some experiments are done to show the method works to some extent.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n1 poor\nStrengths:\nThe paper considers a self-supervised active learning search, which seems to be a potential solution to reduce labeling effort.\nWeaknesses:\n(1)\tThe novelty of the work is very small as both active learning and self-supervised learning are well known.\n(2)\tThe solution that this paper takes is quite common, including nearest neighbor search and random sampler.\n(3) It looks like the pape combines several existing methods into one piece without motivating the method well and explaining why they are combined.\n(4) The paper is poorly written without an official problem definition.\nQuestions:\n(1) The contribution is not clearly. For instance why nearest neighbor search would be listed as contribution since it is just a common method. Similarly , the random sampling method is also a very routine method.\n(2) The method lacks theoretical support. For instance, what is the error bound ? How does the method perform under noisy setting ?\n(3) The experimental evaluations are weak and not sufficient.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n1: strong reject\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 11:58 (modified: 17 Nov 2023, 11:58)EveryoneRevisions", "Content": "Comment:\nWeakness\nThe novelty of the work is very small as both active learning and self-supervised learning are well known.\nThank you for your comments. Both active learning and self-supervised learning techniques are used in developing ELSA. ELSA is more of a search algorithm than an active learning technique. The primary motivation behind the development of an algorithm like ELSA is to ease the task of manual labelling.\nThe solution that this paper takes is quite common, including nearest neighbor search and random sampler.\nWe have used an ordinary nearest neighbour search routine for this task, which forms one of our components, but our random sampler is unique. It differs from the usual random search because it tries to find the most probable cluster centres from the dataset. We have shown in detail in Appendix B how RandS differs from a vanilla random sampler. Moreover, we also provide the intuition behind why RandS works so well in Appendix B. RandS is designed to search orthogonally to the nearest neighbour sampler, making the two work independently and symbiotically.  Appendix F shows how adding the RandS improves the search compared to the nearest neighbour search.\nIt looks like the pape combines several existing methods into one piece without motivating the method well and explaining why they are combined.\nWe have added Appendix A, where we provide a detailed description of the algorithm and the interplay of its components. We have also added Section 4.4 in the paper in order to motivate the readers to the problem statement and give a basic intuition on the working of ELSA. Both sections describe why we need all the components used to design the algorithm.\nThe paper is poorly written without an official problem definition.\nWe have made some changes following the comments of the reviewer. We have added section 4.4,  Appendix A, Appendix B and Appendix F to make the working of the algorithm and the problem statement more straightforward. If the reviewer has some additional comments, we are open to them.\nQuestions\nThe contribution is not clearly. For instance why nearest neighbor search would be listed as contribution since it is just a common method. Similarly , the random sampling method is also a very routine method.\nOur random sampler differs from the vanilla one, as described in Appendix B. We have not claimed the nearest neighbour search as our contribution rather, it has been described and formalised for the sake of completeness.\nThe method lacks theoretical support. For instance, what is the error bound ? How does the method perform under noisy setting ?\nELSA works on the embedding space of a self-supervised algorithm. The mathematical formation of these spaces is still an active field of research; hence, providing any theoretical bound of error for the algorithm will be very difficult due to the sheer complexity of such spaces. We believe this to be beyond the scope of our study and hence have not explored the theoretical error bound. Nevertheless, we have added experiments in the appendix (Appendix D) to show how our algorithm performs under noisy settings. ELSA works well even in moderately noisy settings, but the labelling efficiency sufferers as we add more noise. The discovery rate remains approximately constant to the overall noise added. If the reviewer wants any other theoretical justification, we will be happy to answer them.\nThe experimental evaluations are weak and not sufficient.\nFollowing the suggestions from all the reviewers, we have added more experiments and analysis in Appendix C, E and F. We would like to ask the reviewer, for any additional experiments that they might need. We are open to any further suggestions."}, {"Heading": "Final comments", "Subheading": "Official CommentbyReviewer HU1821 Nov 2023, 22:55Everyone", "Content": "Comment:\nI have read the feedback from the authors and I still have the concerns from novelty, lack of theory to support, insufficient experiments as well as presentation issues. Thus, I maintain my review score."}]}]}, "TvkvWjxj3T": {"paper_info": {"Primary Area": "generative models", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "generative models, diffusion models, score-based models, image generation, image editing", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We propose a method that enables image reconstruction at tens of times the speed of existing methods using diffusion models.", "Abstract": "In image editing employing diffusion models, it is crucial to preserve the reconstruction quality of the original image while changing its style. Although existing methods ensure reconstruction quality through optimization, a drawback of these is the significant amount of time required for optimization. In this paper, we propose negative-prompt inversion, a method capable of achieving equivalent reconstruction solely through forward propagation without optimization, thereby enabling much faster editing processes. We experimentally demonstrate that the reconstruction quality of our method is comparable to that of existing methods, allowing for inversion at a resolution of 512 pixels and with 50 sampling steps within approximately 5 seconds, which is more than 30 times faster than null-text inversion. Reduction of the computation time by the proposed method further allows us to use a larger number of sampling steps in diffusion models to improve the reconstruction quality with a moderate increase in computation time.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9257", "PDF Url": "https://openreview.net/pdf?id=TvkvWjxj3T"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9257 by Area Chair aiNq", "Subheading": "Meta ReviewbyArea Chair aiNq05 Dec 2023, 17:57 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nIn this paper, authors proposed negative-prompt inversion, a method to reconstruct original images with diffusion model through forward propagation without optimization. Authors showed that their methods is more than 30 times faster than null-text conversion. Combining their method with existing image editing methods like prompt-to-prompt allows fast image editing. The strengths and weaknesses given by reviewers are. Strengths: 1) the proposed method only needs forward computation but not optimizing is quite interesting; 2) paper is easy to follow; 3) results promising. Weaknesses are: 1) lack of experimental result and ablation studies to justify the contribution of this work; 2) quality is actually worse than DDIM with CFG; 3) some technique details are missing made reviewers hesitate to give higher ratings.\nBefore rebuttal, reviewers' score are: 2 \"5: marginally below the acceptance threshold\", 1 \"3: reject, not good enough\", 1 \" 6: marginally above the acceptance threshold\". No additional reviewers' feedback is given after rebuttal.\nJustification For Why Not Higher Score:\nMissing additional experimental results and technique details made reviewers hesitate to fully support the acceptance of this paper.\nJustification For Why Not Lower Score:\nNA"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 09:27Everyone", "Content": "Comment:\nWe thank the reviewers for their thoughtful reviews. We have revised the manuscript and added, after the main text, the appendices, which were provided as the supplementary materials in the initial submission.\nThe revisions are as follows:\nIn the third paragraph of the Introduction section, we have removed the detailed explanation of CFG and DDIM inversion, and we have added a simple explanation of how to edit images with our method.\nIn Section 3.2 DDIM inversion and Section 3.3 Null-text inversion, we have removed expressions that were considered redundant.\nIn Section 3.4 Negative-prompt inversion, we have revised to make it easy to understand the difference of reconstruction and editing by our method.\nAt the end of Section 4.2 Reconstruction, we have added a description of memory usage comparison in order to demonstrate that our method uses less memory.\nIn the second paragraph of Section 4.3 Editing and Table 1, we have added the results of Imagic as another image editing method to compare them with those of our method.\nIn the second paragraph of the Conclusions section, we have added a more detailed explanation of how to further accelerate our method.\nAppendix A.1 has been extensively revised. In particular, we have clarified that the \u201cvelocity field\u201d, which the model is supposed to learn, is continuous in z and t>0 even when one considers the sample distribution rather than a single sample. We believe that this modification makes our justifying argument clearer.\nIn Appendix C.1, we have added comparison by our method and null-text inversion when calculation time is limited in order to more highlight the fastness of our method.\nWe have indicated the revised parts by coloring them in blue in the revised version."}, {"Heading": "Official Review of Submission9257 by Reviewer 8NbU", "Subheading": "Official ReviewbyReviewer 8NbU06 Nov 2023, 11:39 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposed a method called negative prompt inversion that modified null text inversion for diffusion models and achieved a faster inversion method with forward computation only without optimizing, i.e., optimizing the null text embedding.  More specifically, in conventional null text inversion, one can optimize the null text embedding so that the predicted $z_{t-1}$ with CFG and $z_{t-1}^*$ in DDIM inversion. In this paper, instead, the authors investigated the conditions/constraints on noise $\\epsilon_{\\theta}$ to make $z_{t-1}$ equal to  $z_{t-1}^*$, which leads to a simper and faster inversion method. The methods are evaluated on 100 randomly selected COCO images with quality metrics like PSNR, LPIPS, etc., and speed.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n3 good\nStrengths:\nThe proposed idea of negative prompt inversion that only needs forward computation  but not optimization is qutie interesting.\nThe paper is organized and presented quite well, and friendly to understand, and easy to follow. Moreover, the introduction and related works parts are also quite helpful and informative to provide the big picture and the motivation.\nSome promising results are shown in the experiments, with 30 times faster inversion than null text inversion methods.\nWeaknesses:\nThe assumption that the predicted noises at adjacent diffusion steps are equal seems neither rigorous nor practical. The authors may need to provide more justification why this assumption is valid.\nThe evaluation is done with only 100 COCO images, which is quite small. Moreover, only objective metrics are provided. Human subjective evaluation should also be provided since it is more reliable to judge the quality, which is quite easy to do considering the data set is small.\nThe authors claimed some limitations about can not reconstruct faces well. It will be helpful to provide some failure face cases (and failure cases beyond faces if there are).\nQuestions:\nI actually like the proposed idea and this paper overall. If authors can resolver the questions in the weakness section, I will be happy to increase my rating.\nFlag For Ethics Review:\nYes, Potentially harmful insights, methodologies and applications\nDetails Of Ethics Concerns:\nThis paper is about a new image inversion/editing method, which may have harmful applications.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 09:28Everyone", "Content": "Comment:\nW1\nWe thank the reviewer for this comment. The assumption on the predicted noises at adjacent diffusion steps, which the reviewer pointed out, has been argued in Appendix A.1. The model is supposed to learn the \u201cvelocity field\u201d, which is shown in Proposition 1 in the revised manuscript to be continuous in $z$ and $t$. So the assumption that the predictions at adjacent diffusion steps are approximately equal holds provided that one takes small diffusion steps. Additionally, we have revised the justification regarding the assumption in Appendix A.1.\nW2\nWe appreciate the reviewer for this comment. We evaluated our method by using 100 images in the same manner as in the original paper of Null-text Inversion (Mokady et al. CVPR2023).\nRegarding human subjective evaluation, we did not conduct it since it was difficult for us to prepare it and to collect dozens of subjects during the short discussion period. We think that several editing images in the manuscript including those in appendices should be helpful for judging our editing quality.\nW3\nWe thank the reviewer for this comment. We have provided some failure cases, including an instance of face reconstruction, in Appendix C.4, figure 12. Please refer to this section."}]}, {"Heading": "Official Review of Submission9257 by Reviewer eMct", "Subheading": "Official ReviewbyReviewer eMct02 Nov 2023, 16:18 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper introduces the Negative Prompt Inversion method, which is designed for fast image reconstruction in the context of diffusion models, with a particular focus on image editing. The primary motivation behind this work is to achieve high-quality image reconstruction while reducing the computational cost and processing time involved.\nThe paper builds upon null-text inversion, a technique that leverages the denoising diffusion implicit model (DDIM) inversion and Classifier Free Guidance (CFG). Null-text inversion optimizes the embedding vector of an empty string to align the diffusion process calculated by DDIM inversion with the reverse diffusion process calculated using CFG. Negative Prompt Inversion is based on the observation that using the origin (resp. target) prompt instead of optimizing the null prompt brings comparable results in reconstruction (resp. edition). This simple modification offers a substantial improvement in processing speed.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n1 poor\nStrengths:\nWell-written paper\nTechnically sound\nThe paper provides a clear summary of preliminary works as well as extensive justifications.\nWeaknesses:\nLack of comparison with existing baselines\nThe paper could benefit from a more comprehensive comparison with existing baseline methods. Specifically, it does not compare the proposed Negative Prompt Inversion with recent image editing methods based on prompt interpolation, such as Imagic or UniTune. This comparison would help assess the relative strengths and weaknesses of the proposed method in the context of image editing. Moreover, the proposed work as well as the Null-text inversion are also very close to the prompt tuning inversion paper and could also be compared to it.\nMixed performances\nThe paper mentions that the image editing performances of Negative Prompt Inversion are below DDIM with CFG. This observation raises questions about the practical utility of the proposed method.\nLack of justification\nThe paper does not sufficiently justify the underlying hypotheses and assumptions of the Negative Prompt Inversion method in the main paper. Specifically, the paper relies on two strong hypotheses regarding the equivalence of null-text inversion features and initial DDIM trajectories, as well as the equality of predicted noise at adjacent denoising steps. These hypotheses are not adequately explained or justified in the main paper and are relegated to the supplementary material. Providing a more robust rationale for these assumptions would enhance the paper's credibility and comprehensibility. Furthermore,  Proposition 3 in the supplementary is supposed to justify the second hypothesis in the general case, but it lacks clarity. In particular, the implication that $\\alpha_t \\simeq \\alpha_{t-1} \\Rightarrow z_t^{\\ast} \\simeq z_{t-1}^{\\ast}$ should be clarified and expanded.\nQuestions:\nAre the edited images provided in the supplementary Fig. 8, second column, obtained with DDIM + CFG or just DDIM? In the former case, the results seem in disagreement with the CLIP score shown in Table 1. In the latter case, editing results with DDIM + CFG could be provided here.\nMost of the justifications in the supplementary material (sec. A.1)  are provided for the case where the noise component is conditioned on the clean sample $z_0$. In this case, the conclusion holds $\\bar{z}_t = z^*_t$. However, as stated later, the denoising model does not have $z_0$ as input. If it does not support the justification in the actual process of DDIM sampling, I wonder how useful are Prop. 1 and all the discussion from eq. (7) to (23)?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 09:29Everyone", "Content": "Comment:\nW1\nWe thank the reviewer for this comment. As the reviewer suggested, we have added results of Imagic for comparison, which shows that our method also outperformed Imagic. We also tried UniTune and prompt tuning inversion, but we failed to replicate the respective papers\u2019 results since the official codes are not released.\nW2\nCLIP score calculates the similarity between an image and its prompt, and it does not regard how an edited image is similar to the original one. By summarizing the evaluation both via LPIPS and CLIP score, we believe that the editing performance of our method is not below DDIM with CFG.\nW3\nWe thank the reviewer for this comment. We have revised the justification regarding the assumption in Appendix A.1.\nThe assumption of equivalence of null-text inversion features and DDIM inversion trajectory is just for the mathematical induction: One has $ z^{*}_T = \\bar{z}_T $, and we argue that, assuming that the equivalence holds true at diffusion step $ t $, it should hold true at diffusion step $ t-1 $.\nThe second hypothesis is related to Q2, so we have answered it in Q2.\nRegarding the statement $ \\alpha_t \\approx \\alpha_{t-1} \\Rightarrow z_t^* \\approx z_{t-1}^* $,which the reviewer pointed out, it is justified by (3), since $ z_t^* $ is calculated by DDIM inversion. Notice that in (3) one has $ z_{t+1} \\rightarrow z_t $ as $ \\alpha_{t+1}  \\rightarrow \\alpha_t $.\nQ1\nAs the reviewer pointed out, it was difficult to tell what the description of \u201cDDIM Inv\u201d represents. The description \u201cDDIM Inv\u201d represents DDIM inversion followed by DDIM + CFG. We have aligned the description in the manuscript. Regarding the disagreement with the CLIP score, we think it as follows: It is true that DDIM inversion fails to generate snow in the fourth row of figure 9, but the other descriptions for a Doberman are correct, which could be leading not to low the CLIP score. In fact, the CLIP score of the image is $27.25$, which is higher than the mean score.\nQ2\nWe thank the reviewer for this question. We have extensively rewritten Appendix A.1. In the revised version, we have argued after Proposition 2, that, even when one considers the sample distribution rather than a single sample, the \u201cvelocity field\u201d, which the model is supposed to learn, is continuous in $z$ and $t>0$. It implies that, even though the equality $ \\epsilon_\\theta(z_t^*,t,C)=\\epsilon_\\theta(z_{t-1}^*,t-1,C) $ does not hold exactly, one can expect that it holds approximately once one assumes $ |\\alpha_t-\\alpha_{t-1}| $ is small."}]}, {"Heading": "Official Review of Submission9257 by Reviewer RErT", "Subheading": "Official ReviewbyReviewer RErT01 Nov 2023, 08:27 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces negative-prompt inversion, a method that is capable of achieving comparable yet slightly degraded reconstruction quality as null-text inversion solely through forward propagation without optimization, thereby enabling much faster editing processes. Such an inversion technique is implemented by replacing the unconditional null-text prompt embedding with the conditional prompt embedding to modify the classifier-free guidance (CFG) in null-text inversion. Experiments demonstrate that the proposed negative-prompt inversion obtains comparable reconstruction quality as existing methods and is more than 30 times faster than null-text inversion. The authors also show that increasing sampling steps can further boost the reconstruction quality. Combining the proposed method with existing image editing methods like prompt-to-prompt allows fast real image editing.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe paper is generally easy to follow. The symbols, terms, and concepts are adequately defined.\nThe proposed method is very simple and easy to understand. Sufficient details are provided.\nThe relevant literature is well-discussed and organized.\nWeaknesses:\nThe reviewer's primary concern is the actual soundness of the proposed negative-prompt inversion. To the reviewer's understanding, replacing the unconditional null-text embedding with the conditional prompt embedding in null-text inversion is akin to/the same as DDIM inversion without CFG. It is necessary to provide the results of DDIM inversion w/o CFG and compare it with the proposed negative-prompt inversion to verify its soundness. If the proposed negative-prompt inversion has the same effect as DDIM inversion without CFG, such contribution is a bit slim.\nMore detailed discussions and analyses on the computational cost and memory usage should be provided since the authors claim them as one of the main contributions.\nIt is advisable to avoid too many detailed discussions on the relevant studies in the Introduction section, which can be moved to the Related Work section. Also, the general idea of the proposed method should be briefly discussed in the Introduction. The previous version is a bit vague.\nThe Method section also presents too many preliminaries and background on DDIM inversion, CFG, and null-text inversion. Such content can be shortened since the information is generally well-known.\nQuestions:\nWill the authors release all the code, models, and data to verify the soundness and ensure the reproducibility of this work?\nLine 2 of Abstract: Image editing not only changes the style of the image. Sometimes it involves certain semantics or geometry changes.\nThe authors mentioned that by parallelizing and optimizing the program, there is potential to further accelerate their, where even real-time processing would be possible. The reviewer is interested in how to parallelize the program since reverse diffusion is an iterative process.\nSection 7 on Page 10: Please remove any main paper content beyond Page 9 to avoid the potential of template/formatting violations of the conference.\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nN/A\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 09:31Everyone", "Content": "Comment:\nW1\nWe appreciate the reviewer's insightful comments regarding the comparability of our method to DDIM inversion without CFG, specifically in the context of reconstruction. We acknowledge the similarities highlighted; however, our approach distinctly focuses on editing by employing a source prompt instead of the null-text, which marks a significant difference from the standard DDIM framework. To elucidate this distinction more clearly, we have revised the itemization in Section 3.4 on page 6.\nW2\nWe thank the reviewer for this comment. The term of computational cost represents the computational time, whose results have been shown in figure 4. In memory usage, our method uses half the memory of null-text inversion. We have added this description at the end of Section 4.2.\nW3\nWe appropriate the reviewer for this comment. We have removed expressions that were considered redundant and clarified the general idea of our method in the third paragraph of the Introduction section.\nW4\nWe have trimmed and shortened the explanations that we considered unnecessary in the Method section.\nQ1\nWe have included our code in supplementary materials for the evaluation purpose by the reviewers, as described in the reproducibility statement of the manuscript. Additionally, we will publicly release our code if our paper is accepted.\nQ2\nWe thank the reviewer for pointing this out. According to the author guide, we cannot change the abstract except in the camera-ready version, so we are planning to change the corresponding part, \u201cchanging the style\u201d to \u201cchanging the subject and the style\u201d, if our paper is accepted.\nQ3\nWe thank the reviewer for this question. We have revised  the description regarding parallelization in the conclusion section. We assumed parallelization to mean processing several frames simultaneously using multiple GPUs, which improves not the latency but the throughput, not parallelizing the reverse diffusion process which is iterative as the reviewer assumed.\nQ4\nIn response to the reviewer\u2019s comment, we have revisited the author guide for ICLR 2024, which explicitly states that the reproducibility statement should be placed at the end of the main text and before the reference list, and that it will not count toward the page limit. We thus believe that our manuscript does conform to the formatting instructions."}]}, {"Heading": "Official Review of Submission9257 by Reviewer 69er", "Subheading": "Official ReviewbyReviewer 69er20 Oct 2023, 05:15 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes an efficient inversion technique for text-conditioned diffusion models. The aim of inversion is to recover the original image as faithfully as possible in the reverse process from the noisy latents obtained in the forward process of the diffusion model. Authors build on an existing technique that rely on solving an optimization problem for each time step in the reverse process, and propose a modification that does away with the costly optimization. The resulting fast inversion technique can be used with diffusion-based editing framework to perform purely text-based image editing.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nTo the best of my knowledge, the idea to replace the null-text embedding with the fixed-prompt embedding is original.\nSpeeding up realistic image editing via diffusion models has significant impact, as the compute cost of such models is the main factor hindering wider adoption.\nBased on the presented experiments, the speed-up can be significant (factor of 30x) while maintaining similar reconstruction quality to null-text inversion.\nWeaknesses:\nI find the core assumptions of the paper difficult to understand and I think more justification/verification is needed (see questions below).\nThe experiments could be more thorough, especially on editing. How does the performance of DDIM inversion scale with $w$? If I understand correctly it is only shown for $w=1$. Moreover, editing performance should be evaluated on the same benchmark as Mokady et. al (2023) (Table 2. in Mokady et. al).\nQuestions:\nWhy would the predicted noise in adjacent steps equal (Eq. 6)? This would completely undermine the idea of iterative noising/denoising and would be very inaccurate for fairly large steps (such as N=50). How is the approximation impacted by the number of steps?\nIf we approximate the optimized null-text embedding with C, it means that the same solution could have been found by null-text inversion, especially with shared embedding across time steps. How does null-text inversion compare with shared embeddings? Can we improve upon simply plugging in C by performing\nsome\noptimization around C (not necessarily in every time step to reduce cost)?\nThe experiments would be better presented in a way that compares inversion/editing performance\ngiven a fixed time budget\nin order to highlight the efficiency of the algorithm.\nI don't quite understand why the method is called negative-prompt inversion. Negative prompting commonly refers to a description of features in an image we do not want to generate in the context of text-conditioned diffusion models.\nFlag For Ethics Review:\nYes, Privacy, security and safety, Yes, Potentially harmful insights, methodologies and applications\nDetails Of Ethics Concerns:\nThe proposed algorithm has the potential to enable fast and realistic image editing that could be used to produce misinformation or deep fakes.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 09:32 (modified: 22 Nov 2023, 09:39)EveryoneRevisions", "Content": "Comment:\nW1, Q1\nWe have revised the justification regarding the assumption in Appendix A.1. In the revised version, we have argued after Proposition 2, that the \u201cvelocity field\u201d, which the model is supposed to learn, is continuous in $z$ and $t>0$. It implies that, even though the equality $ \\epsilon_{\\theta}(z_t,t,C)=\\epsilon_{\\theta}(z_{t-1},t-1,C) $ does not hold exactly, one can expect that it holds approximately once one assume $ |\\alpha_t - \\alpha_{t-1}| $ is small.\nThe reviewer\u2019s concern that the accuracy of the approximation will worsen as the sampling step width increases is reflected in the experimental results in figure 4 left, which show that taking a smaller sampling step width improves the quality of reconstruction.\nW2\nWe appreciate the reviewer for the thoughtful proposal. As the reviewer assumed, we have shown the results of DDIM inversion ($w=1$) followed by DDIM sampling ($w=7.5$) in the manuscript. One can also consider a method of DDIM inversion ($w=7.5$) followed by DDIM sampling ($w=7.5$), but this led to very bad results.\nRegarding the proposal to evaluate on the same benchmark as Mokady et al. (2023), we did not conduct that comparison since we could not identify the setting of editing and could not replicate the results of Table 2 in Mokady et al. (2023).\nQ2\nWe appreciate the reviewer for the thoughtful question. As the reviewer suggested, we tried two experiments; One is to optimize a single embedding in null-text inversion, and the other is to initialize the optimized embedding by the prompt embedding $C$. In the former setting, we tried the same method as presented in section F of supplementary materials for Mokady et al. (2023), which is called global null-text inversion. Since we could see that this method could achieve the almost equal reconstruction quality to null-text inversion by taking about 20 times longer than the original, we calculated the cosine similarity of the optimized embedding and the prompt embedding in the same manner as in Appendix A.2. Since we could experiment with only some of the data due to time constraints, although we cannot exactly compare the results, the mean cosine similarity was $0.10$, and this result shows the optimized shared embedding was more similar to the prompt embedding than the optimized embedding in null-text inversion whose similarity have been shown in Appendix A.2, figure 6. We believe that longer optimization will make the optimized embedding more similar to the prompt embedding, however, getting too close to the prompt embedding will degrade the reconstruction quality. In the later setting, it yielded slight improvements in the reconstruction quality but did not beat null-text inversion. We are planning to continue analyzing why this setting cannot beat null-text inversion.\nQ3\nWe appreciate the reviewer for this advice. We have added comparison of LPIPS when the computation time is limited to less than 30 seconds in Appendix C.1, figure 7. Considering realistic waiting time, our method outperformed null-text inversion in the reconstruction quality.\nQ4\nIn text-guided image generation, if a negative-prompt is given, it is input to the model instead of the null-text in CFG calculation. As a result, the generated image diverges from the negative-prompt. Since our inversion takes a similar process in which uses a text prompt instead of the null-text, we named it \u201cnegative-prompt inversion\u201d."}]}]}, "xVBXz7wD2m": {"paper_info": {"Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Multi-task learning, Gated networks, Sharing, Pruning, Sparsity, MTL", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "GatedMTL learns the optimal balance between learning shared and specialized representations for a given computational budget", "Abstract": "Jointly learning multiple tasks with a unified network can improve accuracy and data efficiency while simultaneously reducing computational and memory costs. However, in practice, Multi-task Learning (MTL) is challenging, as optimizing one task objective may inadvertently compromise the performance of another: This is known as task interference. A promising direction to mitigate such conflicts between tasks is to allocate task-specific parameters, free from interference, on top of shared features, allowing for positive information transfer across tasks, albeit at the cost of higher computational demands. In this work, we propose a novel MTL framework, GatedMTL, to address the fundamental challenges of task interference and computational constraints in MTL. GatedMTL learns the optimal balance between shared and specialized representations for a given computational budget. We leverage a learnable gating mechanism allowing each individual task to select and combine channels from its own task-specific features and a shared memory bank of features. Moreover, we regularize the gates to learn the optimal balance between allocating additional task-specific parameters and the model\u2019s computational costs. Through extensive empirical evaluations, we demonstrate SoTA results on three MTL benchmarks using convolutional as well as transformer-based backbones on CelebA, NYUD-v2, and PASCAL-Context.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9256", "PDF Url": "https://openreview.net/pdf?id=xVBXz7wD2m"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9256 by Area Chair kTBK", "Subheading": "Meta ReviewbyArea Chair kTBK11 Dec 2023, 17:38 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nIn this paper, the authors proposed to use the differentiable gate to select and combine channels from its task-specific features and a shared memory bank of features for multi-task learning setting. The authors conducted empirical comparison to justify the benefits of the proposed method.\nJustification For Why Not Higher Score:\nHowever, there are several concerns raised by the reviewers.\n1, In fact, the differentiable gate has been proposed and used in many problems for different purpose, which diminishes the novelty of the proposed method.\n2, The place in encoder or decoder to add differentiable gates seems arbitrary. It will be great the authors can add more discussion and ablation about this issue for the completeness.\n3, The writting of the paper should be imprved to resolve the confusion from the reviewers, instead replying through rebuttal.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 17:41Everyone", "Content": "Comment:\nWe would like to thank all the reviewers for their thorough reviews and insightful feedback which we used to significantly improve our paper. We are highly encouraged that the reviewers found our proposed method\n\"original\"\n(\nPvDp\n) and\n\"novel\"\n(\n7nfe\n),\n\"well written\"\n(\nwdHJ\n,\nPvDp\n),\n\"super intuitive\"\n(\nwdHJ\n), and\n\"easy to understand\"\n(\nwdHJ\n,\nDXQP\n). We are pleased that three of the reviewers appreciated our experiments to be\n\"extensive\"\n(\nwdHJ\n,\nPvDp\n,\n7nfe\n), with\n\"impressive variety\"\n(\nwdHJ\n), while describing our empirical results\n\"quite positive\"\n(\nwdHJ\n), with\n\"obvious improvements\"\n(\nPvDp\n), and demonstrating\n\"competitive performance\"\n(\nDXQP\n).\nWe have thoroughly addressed each reviewer's individual concerns separately through comments, and we would like to use this global response to highlight the additional extensions to our empirical evaluations:\nAddition of new baselines and metrics:\nWe extensively expanded our experiments to include four new state-of-the-art baselines, i.e. PCGrad, CAGrad, MGDA-UB, and RDW. The updated results are provided in Tables 1 and 2 for NYUD-v2 and Table 5 for Pascal-Context. We additionally report the mean rank (MR) evaluation metric alongside $\\Delta_\\text{MTL}$ in the paper. GatedMTL consistently and significantly outperforms all competing methods in both existing and the new MR metrics. Finally, we also report the parameter count for our method and baselines.\nTotal training, forward pass, and backward pass timing:\nWe report the average time for a single iteration for forward pass, backward pass, as well as the total training time in Table 9 in the Appendix. While GatedMTL is generally cheaper to train than MTO approaches and Cross-Stitch, it adds non-substantial training overhead compared to standard MTL yielding a much higher $\\Delta_\\text{MTL}$ measure. For instance, our GatedMTL variant with a training time of 8.4h adds 11% to the training time of standard MTL while improving the  $\\Delta_\\text{MTL}$ from $-4.14$ to $-1.35$.\nClarifications and limitations section:\nWe added several improvements to further clarify the method and hyperparameters, e.g. a detailed pseudo code for the forward pass of the GatedMTL encoder, distinction with MoE-based methods, and choice of scalarization weights. Furthermore, we added a limitations section at the end of the paper addressing points such as training time, STL weights, scaling to extremely high number of tasks, and targeting a specific computational cost.\nUpdated manuscript:\nWe have submitted an updated version of the manuscript, incorporating the aforementioned improvements. For ease of review, we have highlighted these changes in blue."}, {"Heading": "Official Review of Submission9256 by Reviewer wdHJ", "Subheading": "Official ReviewbyReviewer wdHJ01 Nov 2023, 05:25 (modified: 23 Nov 2023, 06:33)EveryoneRevisions", "Content": "Summary:\nThe focus of this work is to address the problem of task interference in multitask learning (MTL), which manifests as the negative effect that learning a task may have on another one when trained together. To this end, the authors propose a new soft parameter-sharing framework coined GatedMTL, which effectively consists of an automatic mechanism by which a series of identical task-specific architectures learn to share a mixture of their features during training, while retaining task-specific parameters when needed. The authors also propose to use sparsity regularization to encourage sharing parameters and reduce compute. Finally, empirical results on convolutional and transformer based models show that the proposed architecture is able to successfully explore the performance vs. compute trade-off, outperforming the chosen baselines in that matter.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe paper is well-written, and the proposed solution is super intuitive and easy to understand.\nThe emphasis on performance vs. flops (or size) is rather refreshing to read.\nThe number of experiments variety is impressive for what is usual in the field, and it is nice to see a discussion and empirical evaluation of negative transfer and backbone size.\nThe authors propose GatedMTL for two fairly widespread architectures, and the empirical results are quite positive.\nWeaknesses:\nLimitations\nW1. The biggest problem I have with the manuscript is that it does not discuss or show the limitations of the proposed approach\nat all\n, which can really easily mislead the readers (and thus, the reviewers). For example, to my understanding, the proposed approach at training time is $T$ individual models that are trained altogether. However, this is a\nhuge\nsetback as it scales poorly with $T$ in memory and time (for example, the usual CelebA setting in MTL is to do a 40-task binary classification, but the authors reduce it to 3 tasks). The authors should discuss it in the manuscript and show training times for each of the experiments.\nW2. The hyperparameters $\\tau_t$ are hardly intuitive, and the recommendation is to i) use the gap between STL and MTL models, and to ii) study the distribution of the gating patterns wrt the shared branch. The former requires tuning and training $T+1$ models, whereas the latter requires carefully looking into the model parameters. I am afraid that this can really hurt the adoption of the model by practitioners.\nPresentation\nW3. Citations should properly use\n\\citet\nand\n\\citep\n. Even worse, the bibliography is a mess and I cannot comprehend how it happened (and I am going to assume, in good faith, that LLMs have nothing to do). The ones I spotted:\nKendall's citation is doubled (and with different years).\nThe citations\nin the same paragraph of the manuscript\nfor DWA and MTAN (proposed in the same paper) are different. And again, different years. This is mind-blowing to me.\nThe paper by Maninis is also doubled.\nThe paper by Javaloy & Valera is from ICLR 2022, not 2021.\nGradNorm is cited as arxiv 2017 when it is published at ICML 2018.\nAdashare's paper has no venue.\nMost urls point to semanticscholar instead of the official venue.\nExperiments\nW3. I find $\\Delta_{\\text{MTL}}$ a brittle metric, as it is sensitive to low-magnitude metrics and task metrics are not comparable. I would add a more robust metric like the rank mean (see, e.g., [1]).\nW4. The chosen baselines are inconsistent across experiments and mostly outdated. From the MTO side, DWA and Uncertainty are quite old and weak in comparison with other methods like PCGrad, CAGrad, or NashMTL. From the side of adaptive architectures, more modern approaches like Adashare should be included.\n[1] Navon, A., Shamsian, A., Achituve, I., Maron, H., Kawaguchi, K., Chechik, G., & Fetaya, E. (2022). Multi-task learning as a bargaining game. arXiv preprint arXiv:2202.01017.\nQuestions:\nQ1. Do you use a different Lagrange multiplier for each task when using L1 regularization? Otherwise, I don't see how it is comparable to the hinge loss in Eq. 4.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 13:07Everyone", "Content": "Comment:\nWe thank the reviewer for their thorough review and constructive feedback on our manuscript. We appreciate the recognition of the strengths of our work, finding our paper\nwell-written\n, and the\nproposed solution to be super intuitive\n, as well as highlighting our\nempirical evaluations to be impressive\nand\nthe empirical results being quite positive\n. While we understand the concerns raised regarding limitations, we would like to provide additional insights, clarifications, and further baseline experimentations to address the reviewer's feedback.\nTraining time:\nThe primary focus of GatedMTL is on inference-time efficiency, crucial in real-world applications. An example use case is XR applications requiring edge deployment for solving multiple tasks concurrently. We acknowledge that GatedMTL is not optimized for training time efficiency and we have added a limitation section in the paper, but we do not concur that this poses a significant drawback for practitioners. The training cost of GatedMTL is comparable, if not more efficient, than most existing MTO approaches. During training, many MTO approaches require $T$ backward passes and additional computations such as computing gradient conflicts/storing per task gradients simultaneously. GatedMTL, however, allows for sparsification into both forward and backward passes, meaning parameters that are not chosen do not get gradients and hence enables significant memory and compute saving (depending on the sparsity level). At inference, where GatedMTL is primarily designed for, we outperform all competing MTO baselines offering a significantly better performance-compute trade-off.\nScaling to an extremely high number of tasks:\nWe agree that GatedMTL may not be the optimal choice for scenarios requiring simultaneous training/inference for an exceptionally high number of tasks, such as 40. However, we observe that this limitation is not unique to GatedMTL but is a common challenge across the MTL field. Our framework, therefore, remains relevant and effective within the practical range of multi-task learning scenarios that the vast majority of the related literature is focusing on.\nHyperparameter $\\tau$:\nWe believe setting of this parameter to be both intuitive and straightforward. A lower value indicates more reliance on shared features, whereas a higher value suggests a need for more task-specific ones. We would like to ask for clarification of what the reviewer finds unintuitive about $\\tau$? In addition, in MTL research and practice, establishing single-task baselines is a standard practice to gauge the relative performance of MTL models. Therefore, having access to single task models is not unreasonable from a practical perspective. In addition, as shown in Appendix C the parameter $\\tau$ itself is very robust.\nCitations:\nWe acknowledge the issues with our citations and bibliography and have meticulously revised this section, ensuring that all references are accurately and consistently cited."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 13:21 (modified: 16 Nov 2023, 13:24)EveryoneRevisions", "Content": "Comment:\nMean Rank Metric:\nWe thank the reviewer for this suggestion. We added the rank mean measure to all tables in the paper and updated the manuscript. This new metric further strengthens the merits of GatedMTL, consistently showing strong performance across both the $\\Delta_{MTL}$ and rank mean measures.\nBaselines:\nIn response to the reviewers feedback regarding the selection of baselines, we have extensively expanded our experiments to include the suggested state-of-the-art methods, i.e. PCGrad [1], CAGrad [2], RDW [3], and MGDA [4]. The results are presented in the table below. As can be seen, GatedMTL substantially outperforms all MTO baselines across all the metrics. We also integrated the implementation of NashMTL into our MTL baselines, however, despite extensive hyperparameter search, the experiments diverged which are not reasonable to be reported.\nUpdated performance comparison on NYUD-v2 using HRNet-18 backbone. The new baselines are shown in bold.\nModel\nSemseg\nDepth\nNormals\n$\\Delta_\\text{MTL}$(%)\nFlop(G)\nMR\nSTL\n41.70\n0.582\n18.89\n0\n65.1\n8.0\nMTL(Uni.)\n41.83\n0.582\n22.84\n-6.86\n24.5\n11.0\nDWA\n41.86\n0.580\n22.61\n-6.29\n24.5\n8.7\nUncertainty\n41.49\n0.575\n22.27\n-5.73\n24.5\n8.3\nAuto-$\\lambda$\n42.71\n0.577\n22.87\n-5.92\n24.5\n7.7\nRDW\n42.10\n0.593\n23.29\n-8.09\n24.5\n11.7\nPCGrad\n41.75\n0.581\n22.73\n-6.70\n24.5\n10.3\nMGDA\n41.23\n0.625\n21.07\n-6.68\n24.5\n11.3\nCAGrad\n42.31\n0.580\n22.79\n-6.28\n24.5\n8.7\nGatedMTL\n43.58\n0.557\n19.32\n+2.18\n43.2\n1.3\nGatedMTL\n42.93\n0.5613\n19.72\n+0.70\n38.4\n2.3\nGatedMTL\n42.43\n0.5671\n20.01\n-0.54\n36.0\n4.0\nGatedMTL\n42.85\n0.5778\n21.01\n-2.58\n33.0\n5.0\nGatedMTL\n42.35\n0.5755\n21.70\n-4.06\n29.1\n6.0\nUpdated performance comparison on NYUD-v2 using ResNet-50 backbone.\nModel\nSemseg\nDepth\nNormals\n$\\Delta_\\text{MTL}$(%)\nFlops(G)\nMR\nSTL\n43.20\n0.599\n19.42\n0\n1149\n9.0\nMTL(Uni.)\n43.39\n0.586\n21.70\n-3.04\n683\n9.7\nDWA\n43.60\n0.593\n21.64\n-3.16\n683\n9.7\nUncertainty\n43.47\n0.594\n21.42\n-2.95\n683\n10.0\nAuto-$\\lambda$\n43.57\n0.588\n21.75\n-3.10\n683\n10.0\nMGDA\n42.56\n0.586\n21.76\n-3.83\n683\n11.3\nRDW\n43.49\n0.587\n21.54\n-2.74\n683\n8.3\nPCGrad\n43.74\n0.588\n21.55\n-2.66\n683\n7.3\nCAGrad\n43.57\n0.583\n21.55\n-2.49\n683\n7.0\nMTAN\n44.92\n0.585\n21.14\n-0.84\n683\n4.0\nCross-stitch\n44.19\n0.577\n19.62\n+1.66\n1151\n2.3\nGatedMTL\n44.15\n0.573\n19.49\n+2.08\n916\n2.0\nGatedMTL\n43.70\n0.578\n19.65\n+1.16\n892\n4.0\nGatedMTL\n42.99\n0.589\n19.93\n-0.48\n798\n9.7\nPlease note that the MTL setting we are targeting, solves multiple tasks\nsimultaneously in one forward pass\n. In contrast, Adashare and existing MoE-based approaches, can only solve one task at a time, requiring one forward pass per task.\nTherefore, these models are not suitable for the setup we are targeting in this work.\nQ) Different Lagrange multipliers for L1 regularization:\nYes, we indeed experimented with varying Lagrange multipliers for the L1 sparsity term for each task. However, we observed that the Lagrangian multipliers did not yield similar training dynamics for the gates as compared to the hinge loss. We hypothesize that, without a hinge target rate, the sparsification endlessly continues throughout the training making it difficult for the model to converge and the task-specific and shared representations to co-adapt.\nWe trust that we have addressed all the comments raised by the reviewer and are happy to further clarify any points as needed.\nReferences:\n[1] Gradient Surgery for Multi-Task Learning. NeurIPS, 2020.\n[2] Conflict-Averse Gradient Descent for Multi-task Learning. NeurIPS, 2021.\n[3] Reasonable Effectiveness of Random Weighting: A Litmus Test for Multi-Task Learning. TMLR, 2022.\n[4] Multi-Task Learning as Multi-Objective Optimization. NeurIPS, 2018."}, {"Heading": "Official Comment by Reviewer wdHJ", "Subheading": "Official CommentbyReviewer wdHJ20 Nov 2023, 05:04Everyone", "Content": "Comment:\nDear authors, thank you for the review and the extra baselines. Let me answer and clarify some of the points of the review:\nTraining and scaling\nSay that I buy the argument provided in the rebuttal, which seems sensible at first. Irrespectively of if I buy it, discussing efficiency and\nshowing\ntraining times in the paper is crucial. Besides, if training performance is comparable to some MTO methods, reducing the 40-task CelebA used in those papers to a 3-task CelebA does nothing but rising an eyebrow of the reader.\nHyperparameter\nHigher $\\tau$ implies more task-specific parameters is not what I would call intuitive. What I find unintuitive is that I cannot find an easy interpretation of the parameter so that a practitioner can tune it. If $\\tau$, say, meant the desired percentage of task-specific parameters for a task, then it would have a clear interpretation that I can reason about, but instead it is recommended to look at T models and the distribution of activations to tune them.\nI also do not concur with that having single-task models is a standard practice. And, if that were the case, why would one throw away all the information about the STL weights for the MTL model?\nBaselines\nThanks for the new results. I have one question with respect to MGDA: do you apply MGDA on the parameters of the backbone or on the output of the backbone? If it is the former, that is MGDA as by Desideri, if it is the latter, that is the MGDA-UB algorithm proposed by Sener ([4] in the references above) to precisely avoid running more than 1 backpropagation call.\nIf the manuscript has been updated with new sections, I'd like to note to the authors that ICLR allows uploading revisions of the manuscript during the rebuttal (see the\nguide for authors\n)."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 07:32 (modified: 22 Nov 2023, 17:20)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewer for their response and clarifying these points further.\nTraining and scaling:\nIn response to the reviewer's concern about training time efficiency, we report a comprehensive benchmarking of our GatedMTL model against various MTL approaches on our most complex dataset, Pascal-Context with 5 tasks. We include the average time for a single iteration for forward pass, backward pass, as well as the training time. As observed in the table below, while GatedMTL is generally cheaper than MTO approaches and Cross-Stitch, it adds non-substantial training overhead compared to standard MTL yielding a much higher $\\Delta_\\text{MTL}$ measure. For instance, our GatedMTL variant with a training time of 8.4h adds 11% to the training time of standard MTL while improving the  $\\Delta_\\text{MTL}$ from -4.14 to -1.35. More details about the setup of the experiments are provided on Appendix F of the paper.\nMethod\nForward (ms)\nBackward (ms)\nTraining time (h)\n$\\Delta_\\text{MTL}$\nStandard MTL\n60\n299\n7.5\n-4.14\nMTAN\n73\n330\n8.5\n-1.78\nCross-stitch\n132\n454\n12.3\n+0.14\nMGDA-UB\n60\n568\n13.2\n-1.94\nCAGrad\n60\n473\n11.1\n-2.03\nPCGrad\n60\n495\n11.6\n-2.58\nGatedMTL\n76\n324\n8.4\n-1.35\nGatedMTL\n102\n376\n10.1\n+0.12\nGatedMTL\n119\n426\n11.5\n+0.42\nWith regards to experiments on CelebA, we considered this as a toy classification dataset, particularly for some of our ablation studies on the capacity experiments. However, we are fine with moving the CelebA materials to the appendix if the reviewer recommends that.\nHyperparameter $\\tau$:\nThe reviewer suggests that if $\\tau$ represented \"\nthe desired percentage of task-specific parameters for a task\n\", it would offer a more intuitive and practical understanding for tuning. We would like to clarify that this is indeed exactly the intended interpretation of the $\\tau$ parameter, as implemented in our method.\nAs detailed in Equation (4), the 'target rate' is designed to control the proportion of active gates at each specific layer, with each gate governing the activation of a single convolutional kernel. Thus, $\\tau$ sets a soft upper limit for active task-specific parameters through these gates.\nAccordingly, we have edited the manuscript to further clarify this.\nUsing STL weights:\nWe respectfully disagree with the assertion that utilizing single-task model (STL) weights should not be practiced in multi-task learning (MTL). Our position is that the inability of existing MTL solutions to effectively incorporate STL weights mainly because of inherent design limitations, represents a notable limitation in the field. This should not, however, be a deterrent to the development and adoption of innovative approaches that can successfully leverage STL weights, as we propose in our work.\nWe consider our method\u2019s ability to harness STL weights for enhancing the performance of MTL models during inference as a strength and a novel aspect of our research. Far from being a questionable practice, employing STL data in this manner aligns with practical machine learning principles and optimizes the use of available resources.\nIn addition, in numerous real-world applications, the gains in efficient inference over time, especially when scaled across millions of edge devices, can significantly offset the additional requirement of collecting STL weights. We would like to emphasize that single task pre-trained models for tasks such as semantic segmentation, depth estimation, etc. are abundantly available for a multitude of model architectures that could be plugged-in off-the-shelf.\nHowever, to ensure full transparency with readers, we have acknowledged the necessity of collecting STL weights in the limitations section of our manuscript to clearly inform readers of any potential trade-offs involved in our approach.\nBaselines:\nWe are indeed using MGDA-UB algorithm proposed by Sener and now call the algorithm accordingly in our tables.\nWe are are attaching an updated version of our manuscript by highlighting the changes in blue."}, {"Heading": "Official Comment by Reviewer wdHJ", "Subheading": "Official CommentbyReviewer wdHJ23 Nov 2023, 06:35Everyone", "Content": "Comment:\nWhile I still don't fully agree with some of the argumentation during the rebuttal, I think the authors have made significant effort to address the points raised during the discussion to improve the state of the manuscript.\nTherefore, I have raised my score from 3 to 6."}]}, {"Heading": "Official Review of Submission9256 by Reviewer PvDp", "Subheading": "Official ReviewbyReviewer PvDp31 Oct 2023, 21:20 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe manuscript proposes a new Multi-Task Learning (MTL) framework called\nGatedMTL\nthat learns the optimal balance between shared and task-specific representations for a given computational budget. It uses a gating mechanism to learn a combination of shared and task-specific features for each task in each layer. Unused features and weights are pruned during inference to improve sparsity and efficiency. The framework generalizes to convolutional backbone and transformer-based backbone. Experiments on CelebA, NYUD-v2, and PASCAL-Context datasets demonstrate the proposed method maintains a favorable balance between compute costs and multi-task performance across computational budgets.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nOriginality\n: This work introduces a multi-head gating mechanism into feature transformation, solving the challenge of multi-task learning with an emphasis on computational efficiency.\nQuality\n: The experiments are extensive.\nClarity\n: The paper is written clearly, and the figures are easy to understand.\nSignificance\n: The problem that this work attempts to address is important. Given the computational budget, the performance improvement is obvious.\nWeaknesses:\nW1: No source code is provided. Although the experimental setup is detailed and the results are extensive, it is still necessary to provide the code for reference and reproducibility checking.\nW2: Since a shared feature branch acts like a memory bank where task-specific features can communicate, a task-specific gate still learns features from other tasks, which can cause task interference.\nW3: The reported performance in each table is based on a single run. The standard deviation based on multiple random runs is highly encouraged to be provided.\nQuestions:\nQ1: What is the purpose of the \"convolution block\" in forming the shared feature map of the next layer (line 1, page 4)?\nQ2: A more detailed description of the changes made to the backbone is needed for the implementation of the gated MLT layer.\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 07:44 (modified: 22 Nov 2023, 12:50)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewer for their thorough review of our paper and insightful comments.\nOpen-source Code Availability:\nWe acknowledge the critical role of open-sourcing in advancing research and reproducibility. We have initiated the process for obtaining legal approval to open-source our code. Additionally, to facilitate understanding and reproducibility in the interim, we reported all detailed hyperparameters and have included detailed pseudo-code for GatedMTL in Appendix E.\nInterference impact on gating:\nThis is indeed a very interesting point raised by the reviewer. While our gating mechanism does indeed select between the shared and task-specific features, potentially influenced by task interference, it also serves as a mechanism to mitigate the negative impact of task-interference by avoiding the selection of representations with severe task interference issue. This is also supported by the results in Table 6 (first row) showing that in the absence of a sparsity objective, the gates inherently and strongly favor selecting task-specific over shared features. Additionally, our empirical findings show that in practice even with strong sparsity regularization, the gates can cope with task-interference by selecting the least interfering shared features, suggesting that task-interference at this meta-level might be less of a concern for the gates.\nMultiple runs with random seeds:\nAll reported results for the baselines in our study were averaged across\nthree random seeds\n. We are sorry for the oversight of not mentioning this in the original manuscript and thank the reviewer for notifying us. We have now included this information in Section 4.1. We additionally report the standard deviation for the runs in the appendix. For GatedMTL runs, we inherently had numerous results for the Pareto optimal performance vs. FLOPs curve. But based on the reviewer's suggestion we are providing the GatedMTL results for three random seeds as well. Please note that the experiments are running and in the Table below we provide the mean+std for the completed runs and will update the final manuscript with the full set of results. Note that in the Table below we additionally include results for 4 new baselines suggested by wdHJ and 7nfe.\nModel\nSemseg\nDepth\nNormals\n$\\Delta_\\text{MTL}$(%)\nFlops(G)\nMR\nSTL\n41.70\n0.582\n18.89\n0$\\pm$0.12\n65.1\n8.0\nMTL(Uni.)\n41.83\n0.582\n22.84\n-6.86$\\pm$0.76\n24.5\n11.0\nDWA\n41.86\n0.580\n22.61\n-6.29$\\pm$0.95\n24.5\n8.7\nUncertainty\n41.49\n0.575\n22.27\n-5.73$\\pm$0.35\n24.5\n8.3\nAuto-$\\lambda$\n42.71\n0.577\n22.87\n-5.92$\\pm$0.47\n24.5\n8.0\nRDW\n42.10\n0.593\n23.29\n-8.09$\\pm$1.11\n24.5\n11.7\nPCGrad\n41.75\n0.581\n22.73\n-6.70$\\pm$0.99\n24.5\n10.3\nCAGrad\n42.31\n0.580\n22.79\n-6.28$\\pm$0.90\n24.5\n8.7\nMGDA\n41.23\n0.625\n21.07\n-6.68$\\pm$0.67\n24.5\n11.3\nGatedMTL\n43.58\n0.559\n19.32\n+2.06$\\pm$0.13\n43.2\n1.3\nGatedMTL\n42.95\n0.562\n19.73\n+0.68$\\pm$0.09\n38.3\n2.3\nGatedMTL\n42.36\n0.564\n20.04\n-0.55$\\pm$0.17\n36.0\n4.0\nGatedMTL\n42.73\n0.575\n21.01\n-2.55$\\pm$0.11\n33.1\n4.0\nGatedMTL\n42.35\n0.575\n21.70\n-4.07$\\pm$0.38\n29.2\n5.7\nModel\nSemseg\nDepth\nNormals\n$\\Delta_\\text{MTL}$(%)\nFlops(G)\nMR\nSTL\n43.20\n0.599\n19.42\n0$\\pm$0.11\n1149\n9.0\nMTL(Uni.)\n43.39\n0.586\n21.70\n-3.04$\\pm$0.79\n683\n9.7\nDWA\n43.60\n0.593\n21.64\n-3.16$\\pm$0.39\n683\n9.7\nUncertainty\n43.47\n0.594\n21.42\n-2.95$\\pm$0.40\n683\n10.0\nAuto-$\\lambda$\n43.57\n0.588\n21.75\n-3.10$\\pm$0.39\n683\n10.0\nRDW\n43.49\n0.587\n21.54\n-2.74$\\pm$0.09\n683\n8.3\nPCGrad\n43.74\n0.588\n21.55\n-2.66$\\pm$0.15\n683\n7.3\nCAGrad\n43.57\n0.583\n21.55\n-2.49$\\pm$0.11\n683\n7.0\nMGDA\n42.56\n0.586\n21.76\n-3.83$\\pm$0.17\n683\n11.3\nMTAN\n44.92\n0.585\n21.14\n-0.84$\\pm$0.32\n683\n4.0\nCross-stitch\n44.19\n0.577\n19.62\n+1.66$\\pm$0.09\n1151\n2.7\nGatedMTL\n44.38\n0.576\n19.50\n+2.04$\\pm$0.07\n916\n1.7\nGatedMTL\n43.63\n0.577\n19.66\n+1.16$\\pm$0.10\n892\n3.7\nGatedMTL\n43.05\n0.589\n19.95\n-0.50$\\pm$0.05\n794\n9.7"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 08:56Everyone", "Content": "Comment:\nThe purpose of the convolutional block in the shared branch:\nThe convolutional layers are required to transform the representations coming from task-specific branches into a new shared representation. This ensures that the shared representations gradually evolve into more abstract representations required for solving the tasks and maintains a balance between the abstraction level of task-specific and shared representations avoiding a systematic bias toward selecting the task-specific features.\nA more detailed description of the gated MTL layer:\nWe have included the pseudo-code for the implementation of the forward pass of the GatedMTL encoder layers in appendix E:\nGiven\n:\n$x \\in \\mathbb{R}^{3 \\times W \\times H}$    \u2003\u2003\u2003\u2003\u2003 $\\rhd$ Input image\n$T, L \\in \\mathbb{R}$   \u2003\u2003\u2003\u2003\u2003 \u2003 \u2002$\\rhd$ Number of tasks and encoder layers\n$\\Psi$, $\\Phi_t$ \u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2002  $\\rhd$ Shared and $t$-th task-specific layer parameters\n$\\beta$, $\\alpha_t$    \u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003$\\rhd$ Shared and $t$-th task-specific gating parameters\nReturn\n: [$\\varphi_1^L,..., \\varphi_T^L$]  \u2003\u2003\u2003$\\rhd$ The task-specific encoder representations\n$\\psi^0, \\varphi_1^0,..., \\varphi_T^0  \\gets x$ \u2003\u2003\u2003\u2002 $\\rhd$ Set initial shared and task-specific features\nFor\n$\\ell=1$ to $L$\ndo\nFor\n$t=1$ to $T$\ndo\n$\\varphi^{\\prime \\ell}_t \\gets G_t^\\ell (\\alpha_t^\\ell) \\odot \\varphi_t^\\ell + (1 - G_t^\\ell (\\alpha_t^\\ell)) \\odot \\psi^\\ell$   \u2003\u2003  $\\rhd$ Choose among shared and task-specific features\n$\\varphi_t^{\\ell+1} \\gets F(\\varphi_t^{\\prime \\ell}; \\Phi_t^\\ell)$  \u2003\u2003\u2003\u2003 \u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003 $\\rhd$ Compute new task-specific features\n$\\psi^{\\prime \\ell} = \\sum_{t=1}^{T} \\underset{t=1 \\dots T}{\\text{softmax}}(\\beta_t^\\ell) \\odot \\varphi_t^{\\prime \\ell}$  \u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003$\\rhd$ Combine task-specific features to form shared representations\n$\\psi^{\\ell+1} \\gets F(\\psi^{\\prime \\ell}; \\Psi^\\ell)$ \u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2002$\\rhd$ Compute new shared features\nWe trust that we have addressed all the comments raised by the reviewer and are happy to further clarify any points as needed."}]}, {"Heading": "Official Review of Submission9256 by Reviewer DXQP", "Subheading": "Official ReviewbyReviewer DXQP30 Oct 2023, 14:46 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a GatedMTL framework for MTL.  GatedMTL aims to address the fundamental challenges of task interference and computational constraints in MTL. Specifically, a learnable gating mechanism is used to select and combine channels from its task-specific features and a shared memory bank of features. In addition, the gates are regularized to learn the optimal balance between allocating additional task-specific parameters and the model\u2019s computational costs. The proposed method is evaluated on datasets and the experiment results also achieve comparable performance. However, the contribution of this GatedMTL seems marginal and the results are not very strong.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe proposed GatedMTL method to assign features to either a task-specific or shared branch, until reaching an adjustable target computational budget.\nExperiment results demonstrate competitive performance.\nEasy to understand.\nWeaknesses:\nThe core idea of this paper is to find a parameter to control the ratio of task-specific features to task-shared features. The motivation of the gating design for MTL is not clear. The gating mechanism is not a new story in MTL.\nThe gating module to balance task-specific features and the shared features in the decoder seems a bit more reasonable. Since the encoder is responsible for encoding out the shared features across all tasks, it doesn't seem to make sense to split out the task-specific features in the encoder.\nThe proposed gating mechanism seems similar to a simplified variant of smooth Gating in DSelect-k[R1]. It is not possible to observe from Eqs. 2 and 6 that there is a point of novelty in the gating of this paper.\nThe authors are encouraged to show comparisons of feature changes before and after the addition of gating through visualization. In addition, how to show task-specific features and shared features. Can these two features be displayed through visualization?\nThe results in Table 1 were confusing to the reviewers, who could not see directly from the table how the five GatedMTLs are differentiated. The other tables have the same confusion.\nWhy are the results for Auto-\u03bb not shown in Tables 3 and 4?\n[R1] DSelect-k: Differentiable Selection in the Mixture of Experts with Applications to Multi-Task Learning, NeurIPS, 2021.\nQuestions:\nThe gating module to balance task-specific features and the shared features in the decoder seems a bit more reasonable. Since the encoder is responsible for encoding out the shared features across all tasks, it doesn't seem to make sense to split out the task-specific features in the encoder. Have the authors considered this?\nMinor error:\n$\\Delta_{MTL}$ and $\\Delta$ denote the same metric. The authors are encouraged to keep them consistent.\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNA\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 14:38Everyone", "Content": "Comment:\nWe thank the reviewer for their thorough review of our paper and insightful comments.\nThe motivation of the gating design for MTL:\nWe would like to highlight the core motivation for the design of our GatedMTL model. The core concept of our paper addresses a significant challenge in MTL:\ntask interference\n[1]. This phenomenon is particularly evident in models with limited representation capacity. In such models, while certain features are universally beneficial across all tasks, task-specific features often compete for the remaining capacity. This interference can lead to dominance of certain tasks over others during training, influenced by the dynamics of training and the magnitudes of loss functions.\nOur primary innovation lies in recognizing that a rigid or pre-defined allocation of feature capacity between task-specific and shared features is sub-optimal. Such static partitioning fails to adapt to the varying needs of different tasks and layers within the network. To overcome this, we propose a flexible gating mechanism. This mechanism is not just a tool for balancing feature ratios; its fundamental purpose is to learn the optimal architecture dynamically, adapting the degree of feature sharing and task-specific specialization at each layer for each task. This approach ensures that each task has access to the necessary feature capacity without the interference of gradients from other tasks, while at the same time allowing for maximizing the sharing of relevant features.\nIt\u2019s important to clarify that our contribution is not merely the gating mechanism itself, which, as the reviewer correctly notes, is not a novel concept in MTL. The novelty of our work lies in the application of this mechanism to dynamically learn and adjust the architecture for optimal feature sharing and specialization. This is a significant departure from traditional MTL models, where such parameters are usually fixed and do not adapt to the specific requirements of each task, while being highly efficient at the inference in solving all tasks at once.\nWhere to gate, encoder or decoder?\nWe thank the reviewer for bringing up this interesting discussion. We absolutely agree that in typical MTL setups, the encoder is responsible for encoding out the\nshared features across all tasks\n. As highlighted in the above discussion, task interference is inherently the problem that arises with sharing representations across several tasks and the encoder is a natural choice because it is fully shared among all tasks. We would like to provide three additional major reasons for why we chose to resolve task interference within the encoder rather than the decoder:\nComputational efficiency and specialization of decoders:\nOur design is grounded in the conventional MTL architecture, which typically comprises a large shared backbone and multiple task-specific decoders, as depicted in Figure 1 (left). In such architectures, the majority of computational resources are consumed by the encoder (backbone). For instance, in the context of NYUD-v2 with three tasks, the cumulative computational load of the HRNet18 decoders constitutes merely 17% of the total. Given that the decoders are designed to be highly specialized and independent for each task to optimize performance, it is both computationally efficient and logical to address task interference predominantly in the backbone.\nDiversity in task decoding requirements:\nIn MTL, particularly in complex applications like autonomous driving, tasks can vary greatly in their nature, such as combining dense prediction tasks, object detection tasks, and classification tasks such as weather prediction. In such scenarios, decoders might possess distinctly different architectures or layers. Forcing feature sharing at the decoder level could be detrimental, as it disregards the unique requirements and structures of each task\u2019s decoder.\nEncoder feature quality and decoder success:\nThe quality of features extracted by the encoder is pivotal for the success of the specialized decoders. Significant task interference at the encoder stage can lead to degraded feature quality, resulting in irreversible information loss and sub-optimal input for the decoders. Ensuring high-quality feature extraction by the encoder is therefore crucial for the effective functioning of the task-specific decoders.\nFinally, our empirical evaluations strongly demonstrate the effectiveness of the encoder-based approach to mitigating task-interference. We leave the investigation of decoder-based approaches to future work and discuss that in the manuscript."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 14:39Everyone", "Content": "Comment:\nDistinction from DSelect-k:\nFirstly, it is important to clarify that we do not claim innovation in the design of our gating modules. Our gates are simple binary units that make a binary decision between task-specific features and shared features, and they are trained using the well-established straight-through estimation (STE) [2] by Bengio, et al. This is fundamentally different from the DSelect-k mechanism, which is tailored for MoE architectures to select a limited number of experts (at most $k$ out of $n$) in a continuous and differentiable manner. Our method does not involve a Top-K selection process, thereby making the comparison to DSelect-k less applicable.\nFurthermore, there are significant differences between GatedMTL and MoE-based methods. MoE architectures handle one task at a time, whereas our GatedMTL is designed to solve all tasks simultaneously. This simultaneous task-solving capability is crucial for a wide range of real-world applications, setting GatedMTL apart from MoE-based approaches.\nVisualizing task-specific and shared features:\nWe thank the reviewer for this insightful suggestion regarding the visualization of feature changes before and after the implementation of gating, as well as the distinction between task-specific and shared features in our model. We acknowledge the potential value of such visualizations in enhancing the understanding of our model\u2019s behavior and the effectiveness of the gating mechanism. Currently, our paper focuses on quantitatively demonstrating the improvements of our proposed GatedMTL model in terms of accuracy, efficiency, and reduced task interference. Visualizing the feature space in deep neural networks, especially in the context of MTL, is a complex and non-trivial task. It involves intricacies such as high-dimensional data representation, the dynamic nature of task-specific and shared features, and the interpretability of such visualizations. While we recognize the value of this approach, we consider your suggestion as a valuable direction for our future research.\nClarification on multiplicity of GatedMTL entries in results\n: Among the advantages of our proposed method, the user can control the operating point in the accuracy-efficiency trade-off. The multiple reported GatedMTL points in Tables 1-6 and 8 as well as the curves in Figure 2 are obtained by setting different sparsity loss ($\\mathcal{L}_\\text{sparsity}$) coefficients ($\\lambda_s$). We thank the reviewer for bringing it up; We have further clarified this in the text of the manuscript and captions of the tables.\nMissing results for Auto-$\\lambda$ in Tables 3 and 4:\nDespite extensive hyperparameter search for Auto-$\\lambda$, the experiments using Transformer backbones diverged with exploding losses. We also observed similar convergence issues when using Auto-$\\lambda$ on a larger number of tasks such as Pascal-Context. Unfortunately, because of divergent training, the results were not reasonable to be reported.\n$\\Delta_{MTL}$ and $\\Delta$ notations:\nWe thank the reviewer for pointing this out. We fixed all the inconsistencies.\nReferences:\n[1] Xiangyun Zhao, et al., A Modulation Module for Multi-task Learning with Applications in Image Retrieval, ECCV 2018.\n[2] Yoshua Bengio et al, Estimating or propagating gradients through stochastic neurons for conditional computation, arXiv preprint arXiv:1308.3432 (2013)."}, {"Heading": "Thanks to the authors for the responses. This  response addresses some of my concerns.", "Subheading": "Official CommentbyReviewer DXQP23 Nov 2023, 07:03Everyone", "Content": "Comment:\nWhether the location of the gating mechanism should be placed in the encoder or decoder is indispensable for ablation experiments. In the decoder, the use of gating can be set to shared gating, which reduces the number of parameters and the amount of computation.\nThe gating mechanism can even be considered to be placed in both encoder and decoder."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 07:23Everyone", "Content": "Comment:\nWe completely agree with the reviewer regarding the feasibility and the added value of studying the decoder-based gating. We have added this discussion in the limitation section as our future work. Thank you for this suggestion."}]}, {"Heading": "Official Review of Submission9256 by Reviewer 7nfe", "Subheading": "Official ReviewbyReviewer 7nfe26 Oct 2023, 08:46 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a novel multi-task learning (MTL) framework, GatedMTL, to address the fundamental challenges of task interference and computational constraints in MTL. GatedMTL learns the optimal balance between shared and specialized representations by leveraging a learnable gating mechanism to allow each task to select and combine channels from its task-specific features and a shared memory bank of features. Moreover, a regularization term is used to learn the optimal balance between allocating additional task-specific parameters and the model\u2019s computational costs. Extensive empirical evaluations are conducted.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThis paper proposes a novel multi-task learning (MTL) framework to address the fundamental challenges of task interference and computational constraints in MTL.\nExtensive empirical evaluations are conducted.\nWeaknesses:\nThe code is not provided.\nThe description of the proposed method in Section 3 and the overall framework in Figure 1 are confusing. If my understanding is correct, the proposed method is very similar to the existing MoE-base MTL methods. However, this paper does not discuss and compare with MoE-based MTL methods.\nThe proposed method uses the single-task weights for initialization, which means it needs to train $T$ single-task models before training the proposed method, and it is unfair to compare with the baselines which do not use the information from single-task models.\nSee the next Questions part for details.\nQuestions:\nMajor Concerns\n:\nThe description in Section 3 and Figure 1 are confusing. Is the encoder in Figure 1 shared among different tasks? Does $\\Psi$ denote the shared encoder in Figure 1? If so, which part in Figure 1 is $\\Phi_t$, and how can we obtain the shared and task-specific features at each layer? Are there $T+1$ encoders where one is $\\Psi$ shared among different tasks and the others are task-specific $\\Phi_t$? If so, what is the difference between the proposed GatedMTL and MoE-based MTL methods like [1, 2, 3, 4, 5]?\nHow to choose $\\omega_t$ in Eq. (1)?\nIn the last paragraph of Section 4.1: \"the task-specific branches are with their corresponding single-task weights\". It means we need to train $T$ single-task models before training the proposed GatedMTL, which causes a huge computational cost in the training process.\n\"for a given computational budget\" in the abstract and \"matching the desired target computational cost\" in the second contribution. What is the \"given computational budget\" or \"desired target computational cost\"? Is it $\\tau_t$ in Eq. (4)? However, $\\tau_t$ represents neither parameter size nor flops. Besides, although both $\\lambda_s$ and $\\tau_t$ can control the trade-off between performance and computational cost, the sparsity regularization cannot be guaranteed to be optimized to $0$.\nWhy not report and compare the parameter size? It is very important in multi-task learning.\nMany recent or important baselines are missing. For example, MoE-based MTL methods like [1, 2, 3, 4, 5] and MTO approaches like [6, 7, 8].\nMinor Concerns\n:\n$\\odot$ in Eqs. (2), (3), (6), (7), and (8) is not defined.\nNext line of Eq. (3): $R$ should be $\\mathbb{R}$.\n$\\beta^l$ is a learnable parameter, but it does not appear in the overall training objective Eq. (5).\n$(\\tau_t)_{t=1}^T$ should be $\\{\\tau_t\\}_{t=1}^T$.\nSome references appear twice, such as \"Multi-task learning using uncertainty to weigh losses for scene geometry and semantics.\", \"End-to-end multi-task learning with attention.\", \"Auto-lambda: Disentangling\ndynamic task relationships.\", and \"Attentive single-tasking of multiple tasks.\".\n[1] Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts. KDD, 2018.\n[2] Progressive Layered Extraction (PLE): A Novel Multi-Task Learning (MTL) Model for Personalized Recommendations. RecSys, 2020.\n[3] DSelect-k: Differentiable Selection in the Mixture of Experts with Applications to Multi-Task Learning. NeurIPS, 2021.\n[4] Deep Safe Multi-Task Learning. arXiv:2111.10601v2.\n[5] MSSM: A Multiple-level Sparse Sharing Model for Efficient Multi-Task Learning. SIGIR, 2021.\n[6] Multi-Task Learning as Multi-Objective Optimization. NeurIPS, 2018.\n[7] Conflict-Averse Gradient Descent for Multi-task Learning. NeurIPS, 2021.\n[8] Reasonable Effectiveness of Random Weighting: A Litmus Test for Multi-Task Learning. TMLR, 2022.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 06:21Everyone", "Content": "Comment:\nWe thank the reviewer for their thorough review of our paper and insightful comments.\nOpen-source Code Availability:\nWe acknowledge the critical role of open-sourcing in advancing research and reproducibility. We have initiated the process for obtaining legal approval to open-source our code. Additionally, to facilitate understanding and reproducibility in the interim, we reported all detailed hyperparameters and have included detailed pseudo-code for GatedMTL in Appendix E.\nClarification of our method:\nWe apologize for any confusion caused and appreciate the opportunity to clarify. The encoder in GatedMTL consists of both shared parameters $\\Psi$ and task-specific parameters $\\Phi_t$. The shared $\\psi$ and task-specific features $\\varphi_t$ are computed using their respective parameters. In Figure 1, we illustrate the architecture of a\nsingle GatedMTL layer\nwithin the\nunified encoder\n, highlighting how task-specific gates blend shared and task-specific features to form $\\varphi_t^{\\prime}$, serving as the input to the following task-specific layers. The purple blocks represent the features extracted from the shared branch, while the green and yellow blocks represent features extracted by task $1$ and task $t$ (we show only two task-specific branches for simplicity). For each task, a corresponding task-specific gate (e.g. yellow round block) makes a selection between using shared features and task specific features resulting in $\\varphi_t^{\\prime}$ shown as a blended representation with two colors. Subsequently, $\\varphi_t^{\\prime}$ represents the input to the next task-specific non-linear transformations with parameters $\\Phi_t$. The input to the next shared layer is constructed via a linear combination of the task-specific features of all tasks, followed by a non-linear transformation parameterized by $\\Psi$. There are fundamental differences between GatedMTL and MoE-based approaches which we highlight in the next point.\nComparison to MoE-based approaches:\nA major difference between GatedMTL and MoE-based approaches is in how they operate at inference. GatedMTL is designed to solve\nall tasks simultaneously\nin one forward pass, a strict requirement in many real-world practical scenarios (like XR and autonomous driving applications requiring edge deployment for solving multiple tasks simultaneously). In the contrary, existing MoE-based approaches, can only solve\none task at a time\n, requiring one forward pass per task. In our setting, this makes MoE approaches more expensive than conventional MTL approaches, considering the cost of the accumulated forward passes. Unlike GatedMTL which targets efficient inference for solving all tasks simultaneously, MoE-based approaches focus on improving accuracy via dynamic routing to expert modules while solving one task at a time. Therefore, MoE models are not suitable for the setup we are targeting in this work. We have made these clearer in the manuscript and highlighted the key differences in the related work section.\nUsing single-task weights and implications on training cost:\nOur work primarily aims to enhance inference efficiency, vital for deploying multi-task learning (MTL) models in edge computing environments. In numerous real-world applications, the gains in efficient inference over time, especially when scaled across millions of edge devices, can significantly offset the initial higher training costs. While we acknowledge the importance of training efficiency and have discussed GatedMTL\u2019s training cost limitations in our manuscript, it\u2019s important to highlight that competing methods like MTO approaches (PCGrad [1], CAGrad [2], MGDA [3], etc.) also bear considerable training costs, requiring multiple backward passes during training. Our GatedMTL significantly surpasses these in performance, demonstrating its advantage for practical applications that demand efficient inference on the edge.\nIn addition, in both MTL research and practice, establishing single-task baselines is a standard practice to gauge the relative performance of MTL models. Therefore, having access to single task models is not unreasonable from a practical perspective. In addition, pre-trained single task models for many applications are abundantly available which may obviate the need to separately train STL models."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors18 Nov 2023, 06:23 (modified: 18 Nov 2023, 07:51)EveryoneRevisions", "Content": "Comment:\nComparison to recent baselines and parameter size:\nIn response to the reviewers feedback regarding the selection of baselines, we have extensively expanded our experiments to include the suggested state-of-the-art methods, i.e. PCGrad [1], CAGrad [2], MGDA [3], and RDW [4]. The results are presented in the table below. As can be seen, GatedMTL substantially outperforms all competing baselines across both $\\Delta_{MTL}$ and the newly added Mean Rank metric (suggested by R1). We additionally report the parameter counts of the models as suggested by the reviewer. Our method compares favorably against Cross-stitch and MTAN in terms of number of parameters and performance. Please note that as discussed above, our comparisons do not include MoE-based approaches as they are not suitable for our MTL setup for solving all tasks simultaneously.\nUpdated performance comparison on NYUD-v2 using HRNet-18 backbone. The new baselines are shown in bold.\nModel\nSemseg\nDepth\nNormals\n$\\Delta_\\text{MTL}$(%)\nFlops(G)\nParam(M)\nMR\nSTL\n41.70\n0.582\n18.89\n0\n65.1\n28.9\n8.0\nMTL(Uni.)\n41.83\n0.582\n22.84\n-6.86\n24.5\n9.8\n11.0\nDWA\n41.86\n0.580\n22.61\n-6.29\n24.5\n9.8\n8.7\nUncertainty\n41.49\n0.575\n22.27\n-5.73\n24.5\n9.8\n8.3\nAuto-$\\lambda$\n42.71\n0.577\n22.87\n-5.92\n24.5\n9.8\n7.7\nRDW\n42.10\n0.593\n23.29\n-8.09\n24.5\n9.8\n11.7\nPCGrad\n41.75\n0.581\n22.73\n-6.70\n24.5\n9.8\n10.3\nMGDA\n41.23\n0.625\n21.07\n-6.68\n24.5\n9.8\n11.3\nCAGrad\n42.31\n0.580\n22.79\n-6.28\n24.5\n9.8\n8.7\nGatedMTL\n43.58\n0.557\n19.32\n+2.18\n43.2\n18.8\n1.3\nGatedMTL\n42.93\n0.5613\n19.72\n+0.70\n38.4\n16.5\n2.3\nGatedMTL\n42.43\n0.5671\n20.01\n-0.54\n36.0\n15.4\n4.0\nGatedMTL\n42.85\n0.5778\n21.01\n-2.58\n33.0\n13.7\n5.0\nGatedMTL\n42.35\n0.5755\n21.70\n-4.06\n29.1\n11.9\n6.0\nUpdated performance comparison on NYUD-v2 using ResNet-50 backbone.\nModel\nSemseg\nDepth\nNormals\n$\\Delta_\\text{MTL}$(%)\nFlops(G)\nParam(M)\nMR\nSTL\n43.20\n0.599\n19.42\n0\n1149\n118.9\n9.0\nMTL(Uni.)\n43.39\n0.586\n21.70\n-3.04\n683\n71.9\n9.7\nDWA\n43.60\n0.593\n21.64\n-3.16\n683\n71.9\n9.7\nUncertainty\n43.47\n0.594\n21.42\n-2.95\n683\n71.9\n10.0\nAuto-$\\lambda$\n43.57\n0.588\n21.75\n-3.10\n683\n71.9\n10.0\nMGDA\n42.56\n0.586\n21.76\n-3.83\n683\n71.9\n11.3\nRDW\n43.49\n0.587\n21.54\n-2.74\n683\n71.9\n8.3\nPCGrad\n43.74\n0.588\n21.55\n-2.66\n683\n71.9\n7.3\nCAGrad\n43.57\n0.583\n21.55\n-2.49\n683\n71.9\n7.0\nMTAN\n44.92\n0.585\n21.14\n-0.84\n683\n92.4\n4.0\nCross-stitch\n44.19\n0.577\n19.62\n+1.66\n1151\n119.0\n2.3\nGatedMTL\n44.15\n0.573\n19.49\n+2.08\n916\n95.4\n2.0\nGatedMTL\n43.70\n0.578\n19.65\n+1.16\n892\n92.4\n4.0\nGatedMTL\n42.99\n0.589\n19.93\n-0.48\n798\n83.3\n9.7\nThe choice of $\\omega_t$:\nThe hyper-parameter $\\omega_t$ denotes the scalarization weights. We use the weights suggested in prior work but also report numbers of uniform scalarization. For NYUD-v2, we use uniform scalarization as suggested in [5,6], and for PASCAL-Context, we similarly use the weights suggested in the paper [5,6].\nTarget computational cost:\nWe agree with the reviewer and reformulated the wording of the claim in the abstract and additionally mentioned this as a limitation of our method. As correctly described by the reviewer, although both $\\lambda_s$ and $\\tau_t$ can control the trade-off between performance and computational cost and closely result in the desired FLOPs count, we still cannot guarantee landing on a particular target computational cost.\nMinor comments:\nWe thank the reviewer for their detailed and meticulous comments. We fixed all of them directly in the manuscript.\nReferences:\n[1] Gradient Surgery for Multi-Task Learning. NeurIPS, 2020.\n[2] Conflict-Averse Gradient Descent for Multi-task Learning. NeurIPS, 2021.\n[3] Multi-Task Learning as Multi-Objective Optimization. NeurIPS, 2018.\n[4] Reasonable Effectiveness of Random Weighting: A Litmus Test for Multi-Task Learning. TMLR, 2022.\n[5] Attentive Single-Tasking of Multiple Tasks, CVPR, 2019.\n[6] Multi-task learning for dense prediction tasks: A survey, PAMI, 2021."}, {"Heading": "Official Comment by Reviewer 7nfe", "Subheading": "Official CommentbyReviewer 7nfe22 Nov 2023, 22:24Everyone", "Content": "Comment:\nThanks to the authors for the rebuttal. I still have some concerns about my initial comments.\nI still do not understand the architecture of GateMTL in Figure 1. Are there $T+1$ encoders where one is shared among different tasks and the remaining $T$ are task-specific? If so, why the parameter size of GateMTL is smaller than STL? If not, how do we obtain each layer's shared and task-specific features?\nFigure 1 in [2] summarizes different MTL architectures. The blue block means the shared block and the red and green ones are task-specific. (1) The architecture of PLE is similar to GateMTL. (2) Why MoE-based methods can only solve a task at a time?\nI appreciate that this paper aims to enhance inference efficiency, but is it related to initializing task-specific branches with their corresponding single-task weights? It is unfair to compare with the baselines that do not use the information from single-task models. I suggest training GateMTL without single-task weights initialization for a fair comparison.\nThe method name in [8] is RLW rather than RDW."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 03:38Everyone", "Content": "Comment:\nOur GateMTL model\ninitially\ncomprises one shared encoder and $T$ task-specific encoders. As the training progresses, the gates at each layer adaptively learn to select between shared and task-specific parameters for every task. By leveraging the sparsity loss, the model converges towards utilizing a substantial portion of the shared representations, supplemented by a minimal yet crucial set of task-specific features that are most beneficial for each task. Essentially, the model optimizes its architecture through the gating mechanism,\nlearning to prune\nitself during training. This pruning is what enables GateMTL to achieve significantly lower number of parameters and computational costs compared to separate single-task (STL) models, despite starting with a similar parameter size.\nThere are several fundamental differences between MoE architectures such as PLE and GatedMTL.\nFirstly, as can be seen in Equation (2) and Figure 4 of the PLE paper, the gates are\ninput dependent\nand combine the chosen experts together. This makes PLE a\ndynamic architecture at inference\n, requiring to load the relevant expert weights (out of many) into memory at each layer. As can be seen in the bottom right side of Figure 1 of our manuscript, the gates in GatedMTL are task-dependent (not input dependent), and are there only at training time. At inference,\nthe gates are completely removed\nfrom the architecture, and\nthe parameters that were not chosen are permanently removed from the model\n. This makes GatedMTL far more parameter efficient, and lightweight at inference. This information has been mentioned in the manuscript in section 3.1.\nSecondly, PLE utilizes a collection of experts for each task (see $E_{A1}$, $E_{A2}$, $E_{A3}$, etc. in Figure 4 of [2]), and selects among them dynamically in a input-dependent fashion. GatedMTL does not have any experts to choose from. During training rather than selecting among experts, GatedMTL chooses between shared and task-specific parameters (convolutional kernels in case of CNNs),\nwhere the selection of shared parameters, translates to fully pruning the non-selected take-specific features from the architecture\n. As can be seen in our Figure 1, bottom right, GatedMTL has non-symmetric architecture at inference, which has no equivalence in an MoE-based architecture.\nFinally, MoE's are not designed to solve multiple-tasks simultaneously. This is primarily because the routing of the input inside the architecture for each task is completely different because each task at each layer uses a different subset of the experts and obtains independent feature maps. In an MoE architecture with dynamic expert selection, a single forward path has the equivalent cost of an STL model. Running all tasks simultaneously would translate to running T independent STL models with an extreme cost which is not suitable for many practical scenarios. For example, consider the state-of-the-art multi-lingual translation MoE model designed for translating between any two languages. Such a model isn\u2019t intended to translate one language to all others simultaneously, which isn\u2019t a primary concern in its application domain.\nWe will cite PLE [2] in our manuscript and highlight these differences accordingly.\nWe disagree with the assertion that utilizing single-task model (STL) makes it unfair to compare against methods that neglect using them. Our position is that\nthe inability of existing MTL solutions to effectively incorporate STL weights\nmainly because of inherent design limitations, represents a notable limitation in the field.\nThis should not, however, be a deterrent to the development and adoption of new approaches that can successfully leverage STL weights, as we propose in our work.\nWe consider our method\u2019s ability to harness STL weights for enhancing the performance of MTL models during inference\nas a strength and a novel aspect of our research\n. Far from being a questionable practice, employing STL data in this manner aligns with practical machine learning principles and optimizes the use of available resources.\nIn addition, in numerous real-world applications, the gains in efficient inference over time, especially when scaled across millions of edge devices, can significantly offset the additional requirement of collecting STL weights. We would like to emphasize that single task pre-trained models for tasks such as semantic segmentation, depth estimation, etc. are abundantly available for a multitude of model architectures that could be plugged-in off-the-shelf.\nHowever, to ensure full transparency with readers, we have acknowledged the necessity of collecting STL weights in the limitations section of our manuscript to clearly inform readers of any potential trade-offs involved in our approach.\nThanks for pointing this out. We will fix it in the manuscript."}, {"Heading": "Official Comment by Reviewer 7nfe", "Subheading": "Official CommentbyReviewer 7nfe23 Nov 2023, 04:40Everyone", "Content": "Comment:\nThanks to the authors for further feedback, which addresses parts of my initial concerns.\nI think Figure 1 should be reorganized: it should clearly show $T+1$ encoders in the initial training and some blocks are pruned in the training process.\nI approve of the discussion between PLE and GateMTL. How about [4] in my initial review? The gates in [4] are task-dependent (not input-dependent), thus [4] can solve multiple tasks with a single forward process in the inference. It seems the difference between [4] and GateMTL is that a continuous gate is used in [4] while a discrete one is used in GateMTL.\nI partially agree with your point of view. For a fair comparison and a comprehensive understanding of GateMTL, it is better to provide the results for GateMTL without single-task initialization. Also, it is better to compare with MoE-based methods (like [1, 2, 3, 4, 5] in my initial review) with and without single-task initialization."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:41 (modified: 23 Nov 2023, 06:59)EveryoneRevisions", "Content": "Comment:\nWe thank the reviewer for this discussion.\nComparison to [4]:\nWe will improve the visualization in Figure 1. It appears there are some misunderstandings about how GatedMTL works. In [4], the\nDSMTL-IL\nvariant is extremely expensive (all encoders are executed) and incomparable to GatedMTL both methodologically and computationally. The DSMTL-AL, which focuses on saving compute at inference, has $T$ private encoders for each specific task. The main focus is how to\nlearn to branch out from the shared encoder\nto the task-specific encoder. In other words, part of the trunk is shared among tasks, and tasks decide to exit the shared branch at some point and switch to their task-specific encoder blocks. We find this an interesting idea and will discuss it in the paper, but DSMTL-AL is not an MoE architecture. DSMTL is fundamentally different from GatedMTL. GatedMTL does not gate blocks but rather individual channels/filters making it far more flexible and fine-grained. Our work does not focus on when to branch out from a shared branch, but rather to decide how to effectively choose from every individual shared-parameter and task-specific ones, resulting in a more expressive architecture. Unfortunately, the paper [4] does not provide inference timing or source code which makes comparison difficult.\nRegarding the comparison with MoE-based\nmethods starting from single-task models, two primary challenges hinder their suitability in our multi-task learning (MTL) context. First, as we mentioned before, the MoE framework, by its nature, requires running tasks sequentially, leading to a cumulative inference cost equivalent to executing $T$ single tasks. This approach contradicts the efficiency principles of GatedMTL and limits the relevance of a direct comparison.\nFurthermore, the initialization of single-task weights into MoE architectures presents unresolved complexities. Consider an MoE with 16 experts at each layer solving three tasks, where the router dynamically selects from these experts. How is it possible to load single task weights inside these 16 experts in an MoE architecture? Another challenge arrises when we match the number of experts and number of tasks. A fundamental challenge in MoEs is jointly learning the router and experts. The router needs to direct samples to the most appropriate experts, but these experts only become proficient if they receive the correct samples by the router. Initializing experts with single-task weights in this scenario can lead the router to\ntrivial solutions\nselecting the corresponding expert for each task (mode collapse), thereby ignoring other experts. This pattern contradicts the intended learning dynamics of MoEs and undermines the model\u2019s overall adaptability and learning potential."}]}]}, "3sOE3MFepx": {"paper_info": {"Supplementary Material": "zip", "Primary Area": "applications to physical sciences (physics, chemistry, biology, etc.)", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "AI for science, PDE, diffusion model, generative model", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "In this paper we propose to solve PDE with a physical guided diffusion model whose reverse process is conditioned by initial/boundary and PDE guidance.", "Abstract": "Solving partial differential equations (PDEs) is crucial in various disciplines, and their resolution often necessitates the use of computationally intensive numerical methods as well as specialized domain expertise. While data-driven approaches have emerged as promising alternatives, they encounter limitations in terms of generalizability, interpretability, and long-horizon predictive performance, as well as issues related to temporal incoherence. To address these challenges, we introduce the PDE-Diffusion, a two-stage model with three distinctive features: (i) the incorporation of physics-based priors to enhance model interpretability and generalization, (ii) a two-stage diffusion model that efficiently handles physical field forecasting without requiring multi-frame inputs, and (iii) the assimilation of PDE-informed constraints to ensure temporal coherence while producing high-quality predictive results. We conduct extensive experiments to evaluate PDE-Diffusion's capabilities using the PDEBench dataset and two of our newly proposed datasets. The results indicate that PDE-Diffusion delivers state-of-the-art performance in all cases.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9255", "PDF Url": "https://openreview.net/pdf?id=3sOE3MFepx"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9255 by Area Chair uhQo", "Subheading": "Meta ReviewbyArea Chair uhQo06 Dec 2023, 09:41 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper proposes PDE-Diffusion, a new approach to solve PDEs using diffusion models, along with two new datasets for benchmarking model performance. The reviewers pointed out several shortcomings  (including the numerous typos and missing results, the lack of sufficient comparisons, and questionable benefits over the current state-of-the-art), resulting in a unanimous reject.\nJustification For Why Not Higher Score:\nThis was a unanimous reject.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9255 by Reviewer uZRL", "Subheading": "Official ReviewbyReviewer uZRL07 Nov 2023, 05:39 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper considers a two-stage diffusion-based model for solving partial differential equations (PDE). It conducts experiments on 4 benchmark datasets to compare its performance with some leading methods.\nSoundness:\n1 poor\nPresentation:\n1 poor\nContribution:\n1 poor\nStrengths:\nThe paper explores a diffusion-based method for solving partial differential equations. It compares the diffusion-based method performance with some leading methods on four benchmark datasets.\nWeaknesses:\nThe manuscript is essentially unfinished. There are many typos, missing figures in the table (e.g. Table 2. FNO MAE CFD2D turb2), missing values (e.g. 5.3 Results Analysis: The MSE decrease is x% (at 2), x% (at 4)...).\nThe comparative results show that FNO is better than the proposed. Table 3 shows that except for one or two cases, the PEDM performs worse compared to FNO. In Table 3, the average of the six random initializations with variance should have been reported rather than the individual results of the initialization.\nThe paper fails to compare with more advanced techniques than FNO.\nThe motivation for the use of the diffusion model for solving PDE is not sound. Diffusion is founded on a probabilistic setting while PDE is deterministic and it isn't easy to relate the two.\nThe inference time comparison between the different methods should be shown in comparison. FNO finds the solution in a parallel manner while PEDM does not.\nQuestions:\nPlease show the inference time to compare the methods.\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNone.\nRating:\n1: strong reject\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9255 by Reviewer Mvr7", "Subheading": "Official ReviewbyReviewer Mvr703 Nov 2023, 02:22 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduce a diffusion-based method for simulating PDEs. The method performs diffusion in the latent space, and incorporate physics priors into the model. Experiments are conducted in various number of datasets in PDE-Bench and 2 introduced datasets.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nSignificance: The paper addresses the important problem of improving the generalizability and long-horizon predictive performance of simulating PDEs. The diffusion has advantage compared to prior approaches.\nNovelty: The introduction of latent diffusion to PDE simulation, to my knowledge, is novel.\nClarity: The introduction of the method is mostly clear.\nWeaknesses:\nMy most concern with the paper is the soundness of the paper, since I find that there are many errors in the tables in the experiment section.\nErrors:\nThe most obvious is in Table 2 and Table 3, where the PDE diffusion has exactly THE SAME results for all the different datasets, and even the same results in Table 2 and Table 3. This is clearly impossible.\nTable 2 lacks the results for dataset CFD2D turbo2 for FNO, with MAE metric.\nin Table 1, the bold font should make the best result across all methods. However, CFD2D turbo2, the proposed method is clearly has higher MAE and MSE than FNO.\nOther places:\nin Table 1, DR2D lacks the bold font for any method for 2-step.\nIn section 5.3, in the third last row, it lacks the numbers: \"The MSE decrease is x% (at 2), x% (at 4), x%...\"\nIn Fig 2, \"Double shock\" should be \"Double Mach\"?\nThese errors and unfinished parts seems be due to the time rush, so the paper is not polished enough. I strongly suggest the authors to double and triple check the paper, to make sure everything is correct, before submitting. I believe that if the paper is properly and carefully done and well-polished, it can be a strong paper. In its current form, I have to suggest rejection.\nBesides, it would be great if the authors can analyze why the proposed method outperforms VDM. A comparison with existing work DYffusion [1] may also be preferable. There are also many neural PDE works that evolves the system in latent space, e.g., [2][3][4][5][6]. It may be preferable to discuss them.\n[1] DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal Forecasting, NeurIPS 2023\n[2] Multiscale simulations of complex systems by learning their effective dynamics, Nature Machine Intelligence\n[3] Learning to Accelerate Partial Differential Equations via Latent Global Evolution, NeurIPS 2022\n[4] Latent space subdivision: stable and controllable time predictions for fluid flow, in Computer Graphics Forum\n[5] Model reduction of dynamical systems on nonlinear manifolds using deep convolutional autoencoders,\u201d Journal of Computational Physics\n[6] Deep fluids: A generative network for parameterized fluid simulations,\u201d in Computer Graphics Forum\nQuestions:\nN/A\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n1: strong reject\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9255 by Reviewer p93J", "Subheading": "Official ReviewbyReviewer p93J31 Oct 2023, 20:17 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nTo address the challenge of interpretability, generalizability and long-horizon predictive performance, the author proposed the PDE-Diffusion model. The model incorporate physics-based priors, two stage diffusion model to tackle the mentioned challenges. It was also tested on extensive datasets.\nSoundness:\n3 good\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nOriginality: The author propose to embed a physics-based prior into the sampling process for diffusion model to enhance the learning result.\nQuality and clarify: The methodology part misses details about the physics-based priors. The result part is confusing, indicating the proposed model cannot beat the SOTA models.\nSignificance: The author claims that the physics-embedded framework is more interoperable and generalizable, meanwhile mitigate the problem of temporal coherence.\nWeaknesses:\nThe methodology part is not clear in cases of how to embed the physics prior $\\epsilon_I$ and $\\epsilon_B$ during the reverse sampling process. The result doens't support the claim where in many cases, the PDE-Diffusion result is much worse than FNO. The reviewer also has major concern about the writing style. It seems not rigorous and scientific on delivering the message. Details can be found in the questions part.\nQuestions:\nWhy not put the algorithm 3 in the main manuscript? The innovative part physics-conditioning is in algorithm 3 while algorithm 1 and 2 are well-known algorithm. Moreover, I didn't see the equation on how to deal with the $\\epsilon_I$ and $\\epsilon_B$ in either main manuscript or the appendix. How do you embed the physics prior into the model?\nThe result is confusing. In Table 2 and 3, the result for the diffusion models are exactly the same. However, the metrics are evaluated for different datasets. How is it possible? Moreover, the bold font seems to be used pretty arbitrary, not always the best result. In fact, the proposed model's performance is worse than FNO in may cases. In that case, the result doesn't support the authors' claim that the proposed structure is better than SOTA.\nThe writing is poor, seems not to be proofread. To name a few. In Table 2, for FNO, there is a blank without numbers. In page 7 section 5.3, \"has a decrease of x%\" is obviously not a completed part. The authors should fill the exact number instead of a placeholder. In page 13, \"which is reasonable when reasonable in the ...\" is obviously a wrong sentence.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9255 by Reviewer t73C", "Subheading": "Official ReviewbyReviewer t73C30 Oct 2023, 16:56 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a diffusion-based model, called PDE-Diffusion, to solve partial differential equations. This method is a two-stage model consisting of an autoencoder and a diffusion model. PDE-Diffusion incorporates physics-based priors to enhance model interpretability and generalization. Moreover, the model assimilates PDE-informed constraints to ensure temporal coherence while producing high quality predictions.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe proposed method exhibits better interpretability and generalizability by embedding physical constraints into the reverse process of diffusion model.\nThe method adopts a latent residual to mitigate the problem of temporal incoherence in physical field predictions.\nThis paper introduce two new datasets that could enhance the available resources for using deep learning to solve PDEs.\nWeaknesses:\nThere\u2019s other diffusion-based PDE solver that should be compared to, such as DYffusion [1]\nThe baseline is not enough. FNO is not a recent method and not the state-of-the-art model. I recommend authors to compare with more recent neural PDE solvers to better evaluate the effectiveness of the proposed method, such as FFNO [2] and GFNO [3].\nIn most rows in table 2 and 3, the MSE and MAE of PDE-Diffusion is larger than the other baselines but is still annotated boldface, which is misleading.\nIn section 5.3, many placeholders are not replaced by final results.\n[1] Cachay, Salva R\u00fchling, et al. \"DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal Forecasting.\" arXiv preprint arXiv:2306.01984 (2023).\n[2] Tran, Alasdair, et al. \"Factorized fourier neural operators.\" arXiv preprint arXiv:2111.13802 (2021).\n[3] Helwig, Jacob, et al. \"Group Equivariant Fourier Neural Operators for Partial Differential Equations.\" arXiv preprint arXiv:2306.05697 (2023).\nQuestions:\nWhat is the motivation of using diffusion model to solve PDE and advantages over autoregressive methods?\nThe proposed method seems not use autoregressive or operator way to predict solution, instead this method adopt N markov chains that corresponds to N time steps. Then how to predict time step that is not seen during the training?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9255 by Reviewer Hhh3", "Subheading": "Official ReviewbyReviewer Hhh328 Oct 2023, 17:04 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper aims to leverage a diffusion-based model for solving Partial Differential Equations (PDEs), targeting improvements in generalizability, interpretability, and long-term predictive performance. Although the proposed PDE_Diffusion model exhibits some improvement in error metrics compared to other deep learning-based approaches, the paper lacks a rigorous justification for why diffusion models are well-suited for solving deterministic PDEs and how it should work.\nI think the paper suffers from various technical and presentation issues. I recommend rejecting the paper for the following reasons: (1) the methodology is poorly elucidated, accompanied by ambiguous notations and questionable mathematical arguments, and (2) it fails to provide a compelling rationale for employing diffusion models, which are inherently probabilistic, in solving deterministic PDEs.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nThe paper demonstrates through experiments that diffusion models may hold promise for solving PDEs.\nWeaknesses:\nMajor Comments:\nDiffusion models are conventionally used to model distributions, focusing on generating samples that are similar to the training dataset. In contrast, this paper focuses on a deterministic task: solving a well-defined PDE. How do diffusion models contribute to solving such deterministic problems? Is the sample generated by the reverse SDE consistently close to the deterministic ground truth with small variance? If so, can one replace the reverse SDE with a deterministic process and initial conditions to obtain deterministic and improved results?\nAlthough I am familiar with PDEs and diffusion models, I find the methodology section difficult to follow due to unclear notation and inexact mathematical expressions. There are many problems, I just list a few.\n(a) In the first paragraph of section 4.2, $\\mathbf{D}$ denotes a decoder. According to $\\mathbf{D}(z^0, d^i)$, $d^i$ should be a single snapshot in the latent space as residual. However, the next line states $d^i = (d^1_1, \\dots, d^i_N)$, consisting of all the intermediate steps in the diffusion process.\n(b) What is the meaning of \"probability that $d_m^i$ conforms to the governing equations $e$\"?\n(c) Equations (5)(6)(7)(8) appear to model a conditional diffusion model. However, it is known in the literature that there is no straightforward way to model a conditional diffusion model directly from the original diffusion model without certain approximations (see e.g., the discussion in (Song et al., 2020b)). Since the paper does not clarify the meaning of conditional on $e$, it is unclear what this section is attempting to convey. Equation (6) seems more like an assumption than a mathematical derivation.\n(d) Equation (6) involves the notation $\\hat{u}^{i-1}_n$ and $\\hat{u}^{i}_n$, but the next line discusses the notation $\\hat{u}^{n}\ni$ and $\\hat{u}^{n}\n{i-1}$.\n(e) What is meant by \"derivative kernel\" above equation (12)?\nThe paper claims that solving some PDEs takes \"months-long simulations utilizing iterative numerical solvers.\" However, I believe the PDEs tested in this paper are far from such a regime. Solving these PDEs should be relatively quick, perhaps just a few minutes. In contrast, each physical-time evolution step in the proposed PDE-Diffusion model involves multiple diffusion steps, which can be time-consuming, not to mention the extensive training time required for these diffusion models. The authors should provide the solving time of classical solvers, inference time per solution, and total training time for diffusion models to give readers a sense of the time cost.\nThere are placeholders in the paper where results should be reported. For instance, on page 7, it states \"PDE-Diffusion has a decrease of x% on average in the PRE metric\" and \"Our method shows significantly better results in the case of longer prediction window sizes. The MSE decrease is x% (at 2), x% (at 4), x% (at 8), x% (at 16).\" These \"x%\" placeholders indicate hasty composition, suggesting the authors did not even thoroughly proofread the paper.\nThe paper cites (Gao et al., 2022) when introducing the significance of solving PDEs in the first sentence. However, this paper has a very loose connection with PDEs. A keyword search for \"PDE\" in that paper reveals that the term only appears twice in the related work section. Citing such a work (Gao et al., 2022) with minimal relevance to the paper's focus on PDEs, particularly in the opening sentence, is quite unprofessional.\nMinor Issues:\nWhat is the \"PRE metric\"? The paper lacks a definition.\nIn the problem definition, the authors present solving a PDE as finding an approximate solution on a fixed spatial discretization. This is misleading. In the field of numerical PDEs, the choice of spatial discretization is integral to the PDE-solving process, and most numerical methods can accommodate varying discretizations. The authors should clarify that their method is not mesh-free.\nTypo in the appendix: \"which is reasonable when reasonable in the limit of infinite diffusion steps\".\nIn several instances, the authors refer to \"partial derivative equations.\" This term is unconventional; Google search results suggest it is rarely used.\nQuestions:\nSee questions above.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}]}, "wlqkRFRkYc": {"paper_info": {"Keywords": "Autonomous Driving, BEV, Retrieval, Multi-modal, LLM, prompt learning", "TL;DR": "We propose BEV-CLIP, the first multi-modal BEV retrieval method", "Abstract": "The demand for the retrieval of complex scene data in autonomous driving is increasing, especially as passenger vehicles have been equipped with the ability to navigate urban settings, with the imperative to address long-tail scenarios. Meanwhile, under the pre-existing two dimensional image retrieval method, some problems may arise with scene retrieval, such as lack of global feature representation and sub-par text retrieval ability. To address these issues, we have proposed BEV-CLIP, the first multimodal BEV retrieval methodology that utilize descriptive text as an input to retrieve corresponding scenes. This methodology applies the semantic feature extraction abilities of a large language model (LLM) to facilitate zero-shot retrieval of extensive text descriptions, and incorporates semi-structured information from a knowledge graph to improve the semantic richness and variety of the language embedding. Our experiments result in 87.66% accuracy on NuScenes dataset in text-to-BEV feature retrieval. The demonstrated cases in our paper support that our retrieval method is also indicated to be effective in identifying certain long-tail corner scenes.", "Supplementary Material": "zip", "Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9254", "PDF Url": "https://openreview.net/pdf?id=wlqkRFRkYc"}, "review_info": [{"Heading": "Official Review of Submission9254 by Reviewer gTzc", "Subheading": "Official ReviewbyReviewer gTzc05 Nov 2023, 08:45 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe study introduces BEVCLIP, a pioneering multimodal BEV retrieval technique that leverages descriptive text to extract relevant scenes. This approach harnesses the semantic feature extraction capacities of a large language model (LLM) to enable zero-shot retrieval based on comprehensive text descriptions. Notably, the method integrates semi-structured data from a knowledge graph, thereby augmenting the semantic depth and diversity of the language embedding. The efficacy of this model is assessed using the NuScenes dataset.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe proposed BEV retrieval task is a distinct advancement. To my current awareness, it sets a pioneering standard as the first BEV retrieval method dedicated to the domain of autonomous driving.\nThe in-depth ablation studies\u2014evaluating the impact of the large language model, knowledge graph, Shared Cross-Modal Prompt, and caption generation tasks\u2014stand out for their thoroughness and analytical precision.\nThe composition of the manuscript is both well-organized and lucid, making it accessible and straightforward for readers.\nWith the model attaining a rank-1 result of 87.66% on the NuScenes dataset, it underscores its formidable potential for real-world implementation and practical relevance in the field.\nWeaknesses:\nThe significance of the BEV retrieval task remains somewhat under-elaborated. Could the authors elucidate further on the task's implications and relevance for the autonomous driving sector?\nThe primary deviation from conventional image retrieval appears to be the amalgamation of multiple surrounding images for the retrieval process. A deeper exploration into the distinguishing features would be beneficial for readers.\nThe benchmarking exclusively hinges on the NuScenes dataset. Considering the variety of datasets available for autonomous driving, such as the Waymo Open Dataset and the KITTI Dataset, why were these omitted? A singular dataset benchmark might not offer a comprehensive evaluation.\nThe methodological design seems to lack specificity for BEV retrieval. Is the primary modification merely substituting the image encoder with a BEV encoder? If so, further clarification on its uniqueness is necessary.\nThe innovative aspects of the proposed modules warrant more distinction. For instance, the Shared Cross-modal Prompt draws parallels with [1] in its approach to group text and visual features using shared learnable centers. Similarly, the incorporation of knowledge graphs in cross-modal retrieval isn't a novel concept. The Caption Generation Head has also been studied in previous work like Coca[2] and BLIP2 [3]. A more in-depth comparison would be insightful.\nReference:\n[1] T2VLAD: Global-Local Sequence Alignment for Text-Video Retrieval.\n[2] CoCa: Contrastive Captioners are Image-Text Foundation Models\n[3] BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models\nQuestions:\nMy primary concerns revolve around the significance of the task at hand and the innovative nature of the proposed technique. I eagerly anticipate the authors' clarification on these aspects. Should these concerns be satisfactorily addressed, I would raise my rating.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9254 by Reviewer cPYi", "Subheading": "Official ReviewbyReviewer cPYi30 Oct 2023, 21:41 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors introduce a new task of multi-modal BEV retrieval methodology for complex scenes for the application of autonomous driving. They try to build a new retrieval dataset based on nuScenes.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nThe task of multi-modal BEV retrieval methodology for autonomous driving applications is quite new and interesting for the 3D community. The authors curate a new dataset and a network to tackle the problem.\nWeaknesses:\nThe new task is not well-motivated. The authors claims that the proposed method could help identify complex corner-case/long-tail scenes, however, I don't see any qualitative results to support the claim. For example, it would be great if the authors could manually point out what the corner cases are for examples shown in Table 7 in Appendix.\nOne of the contribution is 'zero-shot retrieval using long text descriptions'. I don't see any descriptions to support the claim.\nThe manscript is not easy to understand. For example, the loss function is not clear to me. How positive and negative samples for contrastive loss are generated?\nQuestions:\nPlease refer to the weakness part. I admit that the authors propose a new dataset and a new baseline network to tackle the problem. However, I have concerns about the motivation and experiments (specified in the weakness part).\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9254 by Reviewer Z1vR", "Subheading": "Official ReviewbyReviewer Z1vR30 Oct 2023, 13:45 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn this paper, the authors focus on the retrieval of complex scenes using text inputs. They identify limitations in existing approaches, particularly the lack of a global feature representation and sub-par text retrieval ability. To address these limitations, the authors propose BEV-CLIP, which is the first multimodal BEV retrieval methodology that utilizes descriptive text to retrieve corresponding scenes. The key idea behind BEV-CLIP is to leverage the semantic feature extraction abilities of a large language model (LLM) to enable zero-shot retrieval of extensive text descriptions. Additionally, the method incorporates semi-structured information from a knowledge graph. The authors evaluate the performance of BEV-CLIP on the NuScenes dataset and demonstrate an accuracy of 87.66% in text-to-BEV feature retrieval.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nImportance of retrieval for complex scenes in autonomous driving: The reviewers believe that this direction is critical for the field of autonomous driving.\nTo the best of the reviewer's knowledge, the field has not explored the use of Battery Electric Vehicle (BEV) representations extracted from images collected from multiple cameras for text retrieval purposes.\nWeaknesses:\nThe primary motivation of the paper is to address the limitations of two-dimensional image features in effectively representing global features within autonomous driving scenarios. The authors propose the use of BEV representations. The reviewer wonders why the authors did not explore 3D occupancy as a potential solution to this issue, as suggested by Huang et al. in their paper \"Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction\" (CVPR 2023). Therefore, while the reviewer acknowledges that this work is the first BEV retrieval method in the field of autonomous driving, they find the motivation unclear and insufficiently justified.\nThe second motivation of the paper is to explore methodologies that could enhance the currently unsatisfactory efficacy of text representations in the field of autonomous driving. The authors propose exploring CLIP to address the unsatisfactory efficacy of text representations. The reviewer wonders if the authors have considered exploring the potential of language parsing, as suggested by Liu et al. in their paper \"Temporal Modular Networks for Retrieving Complex Compositional Activities in Video\" (ECCV 2018) and Lin et al. in their paper \"Visual Semantic Search: Retrieving Videos via Complex Textual Queries\" (CVPR 2014). Without discussing and comparing these approaches, the reviewer is not convinced of the motivation behind this work.\nFigure 1 is misleading. The effectiveness of the \"BEV retrieval\" setting is attributed to multiple perspectives rather than the BEV representation itself. The reviewer agrees that the use of multiple views can facilitate text retrieval, but the use of BEV representation remains questionable.\nQuestions:\nThe reviewer has identified three major concerns in the Weakness section and would like to know the authors' thoughts on these points. In summary, these concerns pertain to the motivation of the paper and the lack of literature. Please address each concern during the rebuttal stage. The reviewer will respond accordingly in the discussion phase.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9254 by Reviewer PBGj", "Subheading": "Official ReviewbyReviewer PBGj30 Oct 2023, 04:47 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn this paper, the authors propose a multi-modal BEV retrieval approach that utilizes descriptive text as an input to retrieve corresponding scenes, named BEV-CLIP. This approach leverages the semantic feature extraction capabilities of a large language model (LLM) to enable zero-shot retrieval, and integrates knowledge graphs to enrich and diversify the language embedding semantically. Experiments demonstrated the effectiveness of the approach.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe authors claim that this is the first BEV retrieval method for autonomous driving.\nThe authors leverage LLM and knowledge graph to achieve contrastive learning between text description and BEV feature to enable zero-shot retrieval.\nThe authors build a validation pipeline and demonstrate the effectiveness of the proposed approach.\nWeaknesses:\nThe paper could benefit from stronger evidence, possibly in the form of quantitative experiments, to effectively illustrate the superiority of BEV features in comparison to 2D images for retrieval purposes..\nContrastive learning has been widely explored to various tasks in autonomous driving, such as more meaningful driving decisions.\nThe validation pipeline lacks persuasiveness, primarily due to its limited scope in which it solely evaluates and discusses a select few state-of-the-art methodologies.\nThe outlook for scene retrieval in the context is currently uncertain, raising doubts about its viability as a worthwhile investment for autonoumous driving.\nThe manuscript contains grammar errors and typos such as  \"multimodal BEV retrieval methodology that utilize\" should be \"multimodal BEV retrieval methodology that utilizes\" in the abstract.\nQuestions:\nMy main concerns and questions lie in the weaknesses. The author should discuss them in detail.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}]}, "2Pup7olzxj": {"paper_info": {"Primary Area": "applications to physical sciences (physics, chemistry, biology, etc.)", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "AI for Science, Quantum Chemisty, Density Functional Theory, Deep Learning, Kohn-Sham Equation, Solid-State Physics", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Plane-wave density functional theory is a computational quantum mechanical modeling method used to investigate the electronic structure of solids. It employs plane-waves as the basis set for representing electronic wave functions and leverages density functional theory to compute the electronic structure properties of many-body systems. Traditionally, the Self-Consistent Field (SCF) method is predominantly adopted for optimization in current DFT computations. However, this method encounters notable convergence and computational challenges, and its iterative nature obstructs the incorporation of emergent deep learning enhancements. To address these challenges, we introduce a fully differentiable optimization method tailored to resolve the intrinsic challenges associated with the optimization of plane-wave density functional methods. This methodology includes a direct total energy minimization approach for solving Kohn-Sham equations in periodic crystalline systems, which is coherent with deep learning infrastructures. The efficacy of our approach is illustrated through its two applications in solid-state physics: electron band structure prediction and geometry optimization. Our enhancements potentially pave the way for various gradient-based applications within deep learning paradigms in solid-state physics, extending the boundaries of material innovation and design. We illustrate the utility and diverse applications of our method on real crystal structures and compare its effectiveness with several established SCF-based packages, demonstrating its accuracy and robust convergence property.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9253", "PDF Url": "https://openreview.net/pdf?id=2Pup7olzxj"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9253 by Area Chair KEYk", "Subheading": "Meta ReviewbyArea Chair KEYk05 Dec 2023, 16:20 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper introduces a differentiable Kohn-Sham density functional theory (DFT) solver in a plane-wave basis for solid-state systems. It achieves this by using a parameterization of the periodic part of the Bloch functions. The resulting formulation is then employed for band-structure prediction and geometry optimization.\nThe reviewers found the paper to be reasonably well-written. However, they noted a lack of numerical evidence convincingly demonstrating the efficacy of the method, particularly when compared to classical numerical methods. The reviewers generally agreed that any observed advantages over classical methods were not clear, particularly when considering cut-off and k-point discretization. They also pointed out the narrow scope of the benchmarking for geometry optimization.\nWhile the authors addressed several of the reviewers\u2019 comments, their responses also raised further issues.\nGiven the unclear advantages of the proposed method over classical methods, and the lack of evidence supporting its purported downstream benefits, I recommend rejection.\nJustification For Why Not Higher Score:\nThe comparison of the method versus classical methods is not complete, and lackluster, undermining the claim of efficacy. There are no enough evidence supporting the claims of benefits for downstream tasks.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Looking forward to further discussion", "Subheading": "Official CommentbyAuthors20 Nov 2023, 08:56Everyone", "Content": "Comment:\nDear Reviewers,\nWe greatly appreciate your thorough and insightful feedback, which has been instrumental in enhancing our manuscript. We've submitted a revised version, incorporating responses to all reviewer comments. We are confident that this updated manuscript addresses the key issues raised and are open to making further modifications if needed.\nWe recognize the demanding nature of this period and the significant time and effort required for paper reviews. With the discussion deadline nearing, we look forward to any additional comments you may have on our revised manuscript and our responses to your initial feedback. Thank you for your active participation in this review process, and we welcome any final queries or concerns you might have.\nWarm regards,\nThe Authors"}, {"Heading": "Official Review of Submission9253 by Reviewer Arv3", "Subheading": "Official ReviewbyReviewer Arv303 Nov 2023, 21:21 (modified: 23 Nov 2023, 09:53)EveryoneRevisions", "Content": "Summary:\nInitial comment\nIn this paper, the authors utilize differentiable optimization to enhance the convergence robustness of solving KS-DFT, compared to the traditional SCF method. The proposed approach is implemented in JAX to utilize its automatic differentiation capability. Experiments on band structure prediction and geometry optimization are performed to show the effectiveness of the proposed method.\nAfter author-reviewer rebuttal\nThanks very much for your detailed response and careful work updating the manuscript. Sorry for missing the deadline to feedback to your response, as I encountered website failure.\nYour clarification has been very helpful.\nSorry I think I made a mistake thinking you claimed efficiency in the paper.\nI find several reviewers shared the concern on the plane wave basis set selection. We don't mean it is not OK nor important. I think we are questioning the proposed method does not need to be limited to it.\nHowever, the biggest concern from me remains that, I am sorry to say I still find the contribution of the proposed method, compared to traditional methods and previous works, to be marginal, for both the SCF equation solving and the geometry optimization tasks.\nWith all the factors considered, I tend to remain my original score for now.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nUsing automatic-differentiation-assisted optimization instead of equation solving to improve the convergence robustness and certain optimization tasks is a promising and emerging direction.\nWeaknesses:\nThe claim that the iterative nature of SCF obstructs the application of deep learning is not very suitable. See previous works such as DEQ, KSR, DQC, etc.\nThe experiments are not quite sufficient:\nFor the band structure experiment, although several popular packages are compared, the advantages of the proposed method are not clear.\nFor the geometry optimization experiment, no baseline methods are compared, while there are mature automation tools such as geomeTRIC and pyberny.\nHow the automatic differentiation capability of JAX is utilized is not clearly described in the paper. I will recommend Fig. 8 to be displayed in the main context with more detailed introduction.\nQuestions:\nI think the defining difference between the proposed method and the traditional method is to solve the eigenvalue problem with optimization (which has also been heard before, see\nhttps://neurips.cc/virtual/2023/poster/70089\n). But then to me, this is still an iterative method. So can the authors explain why in the paper it is emphasized to overcome the iterative nature of the traditional method?\nBesides the robustness of convergence, efficiency is also claimed in the paper. However, it seems that the claimed advantage in efficiency is not demonstrated?\nFor the geometry optimization task, traditionally there can be analytical derivatives available. So I wonder if there is any advantage of using the proposed method?\nCan the authors further clarify why is the plane-wave basis set emphasized?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Authors' response to Reviewer 1 (1/2)", "Subheading": "Official CommentbyAuthors17 Nov 2023, 05:19 (modified: 17 Nov 2023, 05:25)EveryoneRevisions", "Content": "Comment:\nWe would like to thank the reviewer for these insightful comments, which helped us improve the quality of this paper.\nQ1 (The Advantages of Direct Optimization over SCF)\nThe claim that the iterative nature of SCF obstructs the application of deep learning is not very suitable.\nWe appreciate the reviewer's perspective regarding the iterative nature of gradient-based optimization and its potential compatibility with deep learning methods.\nWe want to emphasize that SCF methods can fail to find solutions in some cases (for example near-degeneracies or highly correlated electrons [1]). Direct optimization in our method can avoid these failures.\nWe also wish to emphasize that the differentiability of our method provides more mechanisms to interface with deep learning architectures than existing SCF methods. For example, the differentiable KS-DFT method proposed in [2] involves a scf loop in the computational graph, where the gradient backpropagation goes through all the scf iterations and which requires a fully converged solution to the scf loop and risks the failure mentioned above. In contrast, the differentiable optimization enables the development of end-to-end trainable models without going back and forth between SCF in another package, and neural networks in deep learning framework.\nWe apologize for the poor phrasing, and have modified our manuscript to make these points more clear.\n[1] Schlegel, H. Bernhard, and J. J. W. McDouall. \"Do you have SCF stability and convergence problems?.\" Computational advances in organic chemistry: Molecular structure and reactivity (1991): 167-185.\n[2] Kasim, Muhammad F., and Sam M. Vinko. \"Learning the exchange-correlation functional from nature with fully differentiable density functional theory.\" Physical Review Letters 127.12 (2021): 126403.\nQ2 (Band Structure)\nFor the band structure experiment, although several popular packages are compared, the advantages of the proposed method are not clear.\nThank you for this comment. We would like to emphasize that the band structure experiments are a standard application for solid-state DFT computation. The purpose of this experiment is to show the efficacy of our direct optimization approach, which can produce comparable results to SCF methods. Here we are not claiming that we outperformed these popular packages. However, there are some potential advantages that our method might possess due to its full differentiability nature. For instance, we should be able to design pseudo potentials or exchange-correlation functionals with guidance of the band gap, which is more easy to access from experiments and no existing methods have done so, to the best of our knowledge. This is an intriguing application that we will explore further.\nFor more quantitative comparison of band structure, please refer to Reviewer 4 Question 2.\nQ3 (Geometry Optimization)\nFor the geometry optimization experiment, no baseline methods are compared, while there are mature automation tools such as geomeTRIC and pyberny. \u2026traditionally there can be analytical derivatives available. So I wonder if there is any advantage of using the proposed method?\nThank you for your insightful comments and we acknowledge the importance and widespread use of analytical derivatives in traditional SCF methods for geometry optimization.\nThe key advantage of our approach is its inherent adaptability and flexibility. By integrating the computation of derivatives directly into the optimization process, our method simplifies the workflow and reduces the complexity of implementing geometry optimization, especially in systems where deriving analytical expressions is challenging or impractical.\nFurthermore, our method's capacity to handle derivative calculations internally lends itself to a broader range of applications. This includes complex systems where traditional methods might struggle due to the intricate nature of deriving and implementing analytical derivatives. As detailed in our response to Reviewer 2 Question 1, we foresee numerous potential applications in future work, such as handling complex molecular systems, materials with unconventional properties, and scenarios where rapid prototyping of computational models is essential.\nIn light of your feedback, we recognize the necessity to clarify these points in our manuscript. We will include a more detailed discussion of the advantages of our method compared to traditional approaches, backed by quantitative analyses where applicable."}, {"Heading": "Authors' response to Reviewer 1 (2/2)", "Subheading": "Official CommentbyAuthors17 Nov 2023, 05:24Everyone", "Content": "Comment:\nQ4 (Automatic Differentiation)\nHow the automatic differentiation capability of JAX is utilized is not clearly described in the paper. I will recommend Fig. 8 to be displayed in the main context with more detailed introduction.\nWe appreciate this point. The utilization of JAX's automatic differentiation forms a foundational aspect of our methodology, enabling seamless integration of differentiable optimization into electronic structure calculations (as highlighted in our response to Q1). We will revise the paper to provide a more comprehensive and explicit description of how JAX's automatic differentiation features are harnessed in our approach. Specifically, we will elaborate on how these functionalities empower our method in optimizing the electronic structure while ensuring computational efficiency and accuracy.\nRegarding Fig. 8, we acknowledge its significance in showcasing key aspects of our methodology. We will incorporate this figure into the main body of the paper and provide a detailed introduction that elucidates the specific components and their role in our approach.\nQ5 (Efficiency)\nBesides the robustness of convergence, efficiency is also claimed in the paper. However, it seems that the claimed advantage in efficiency is not demonstrated?\nThank you for your comment regarding the efficiency claims in our paper.  Upon reviewing our manuscript, we confirm that our primary emphasis has been on the robustness of convergence and the accessibility of differentiable methods in the context of plane-wave density functional theory. While we discuss efficiency in terms of these aspects, we have NOT explicitly claimed that our method is more efficient in a general computational sense compared to traditional methods.\nHowever, we recognize the importance of demonstrating and quantifying efficiency in computational physics. In this regard, we believe our method shows potential advantages in specific areas:\nReliability in Finding SCF Solutions: One of the notable efficiencies of our approach is its reliability in achieving SCF solutions, particularly in systems where traditional methods may struggle. This reliability can be viewed as an efficiency gain, as it potentially reduces the time and computational resources required to reach a viable solution.\nOngoing Optimization of Implementation: We are actively working on optimizing the implementation of our method. Future versions are expected to show improvements in computational speed and resource utilization, which we plan to comprehensively benchmark against established methods.\nAdvantage in Differentiable Methods: The access to differentiable methods within our framework presents an efficiency in terms of workflow and application versatility. It enables a more direct and streamlined approach to solving complex problems, which can be particularly efficient in research areas where differentiability is a key requirement.\nWe acknowledge the need to provide a more explicit discussion on these points,  and we will make necessary modifications in our manuscript.\nQ6 (The Plane-wave Basis)\nCan the authors further clarify why is the plane-wave basis set emphasized?\nWe appreciate the reviewer's comments regarding the emphasis on the plane-wave basis set in our manuscript. The choice and emphasis on the plane-wave basis set stem from its widespread usage and several advantageous properties that make it particularly suitable for PERIODIC electronic structure calculations.\nThe plane-wave basis set offers unique benefits, notably its ability to efficiently represent electronic wavefunctions in reciprocal space. This characteristic is crucial for accurately describing the periodic nature of crystalline solids, making it a preferred choice for computations involving periodic systems.\nMoreover, the plane-wave basis set exhibits rapid convergence properties with respect to the kinetic energy cutoff, allowing for systematic improvements in accuracy by increasing the basis set's energy cutoff. This convergence behavior is advantageous for achieving high precision without an excessive increase in computational cost.\nAdditionally, the plane-wave basis set facilitates straightforward implementations in various electronic structure methods, enabling seamless integration with diverse algorithms and techniques for studying material properties.\nBy emphasizing the plane-wave basis set in our work, we aim to highlight its fundamenal role as a robust and versatile tool in electronic structure calculations, particularly in the context of our proposed methodology. We acknowledge the importance of explicitly elucidating the rationale behind this emphasis and will revise the manuscript to provide a more detailed and comprehensive explanation of the unique advantages offered by the plane-wave basis set.\nFor a comparison of plane-wave basis and other orthogonal basis, we advise the reviewer refer to Reviewer 2 Question 2."}]}, {"Heading": "Official Review of Submission9253 by Reviewer AFLR", "Subheading": "Official ReviewbyReviewer AFLR31 Oct 2023, 22:54 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces a modification to density functional theory(DFT) codes which will enable back propagation through materials property predictions. The paper presents a novel and fully differentiable approach to address the Kohn-Sham Density Functional Theory (KS-DFT) in the context of solid-state physics, which is a fundamental method for studying electronic properties and structures in materials. This approach uses a plane-wave basis and is designed to leverage emerging deep learning frameworks and optimization techniques, offering robust convergence performance. The paper demonstrates the accuracy and effectiveness of the proposed approach in predicting the electronic band structures of various crystalline materials, such as lithium, aluminum, carbon (diamond), and silicon. The related works of machine learning and DFT are discussed, while a lot of details of algorithms and experiments are also present in appendix sections.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe modifications to density functional theory proposed in this paper will enable DFT to become a layer in a machine learning model, such as being used to compute the loss. Also, given how important DFT is to the problem of materials design, this improvement is bound to have an impact if it gets incorporated into DFT code bases like VASP and Quantum Espresso (there is no discussion of this in the paper).\nIt correctly identifies insulating, metallic, and semiconductor properties in these materials, in line with established implementations. The optimization of atomic structures within crystals are also important. The paper presents experiments showing that the proposed approach, combined with optimization algorithms like Adam and Yogi, can successfully identify optimal atomic configurations, including those for diamond and graphite-like structures. These geometry optimizations have implications for understanding the properties of materials.\nThe authors also compare the proposed direct optimization approach with traditional Self-Consistent Field (SCF) methods. The results indicate that the direct optimization method consistently converges, while SCF methods may encounter challenges in achieving full convergence, especially in complex energy landscapes.\nWeaknesses:\nOverall, however, I think the work would be more interesting and relevant if it had more discussion of how the work might synergize with other work, in particular materials generation and property prediction. As is, some of the impact of the paper seems left to the reader. Explicit explanation and examples of impact would be helfpul.\nAs such, I wonder if it would be more appropriate in a computational physics venue.\nQuestions:\nLooking through the \"Related Works\" section, it seems like much of what was done in this paper was already done for the so-called \"orthonormal basis functions\", the basis used in DFT to study the chemistry of molecules, i.e. systems without a periodic crystalline structure. This paper may have just replaced these basis functions with the \"plane wave\" basis functions used in this paper. So it is possible this paper took established work and just changed the basis. A switch which hardly seems like a big advance, though nevertheless a useful one.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Authors' response to Reviewer 2 (1/2)", "Subheading": "Official CommentbyAuthors17 Nov 2023, 05:43Everyone", "Content": "Comment:\nQ1 (Potential Applications)\nI think the work would be more interesting and relevant if it had more discussion of how the work might synergize with other work, in particular materials generation and property prediction. Explicit explanation and examples of impact would be helfpul.\nThank you for the constructive comments. We agree that a more explicit discussion on the potential synergies of our work with other areas in materials science and computational chemistry would greatly enhance its relevance and impact. Here, we outline two examples of how our work could facilitate advanced analyses and the development of novel chemical models:\nVibrational Analysis of Systems: Our method significantly simplifies the implementation of advanced vibrational analysis techniques. Typically, vibrational analyses use the harmonic approximation, which is limited to quadratic potentials and double derivatives. However, for a more comprehensive understanding, especially in anharmonic systems, higher-order derivatives are required. The inherent capability of our approach to handle such complex derivative calculations more efficiently makes it ideally suited for extended vibrational analyses, including anharmonic vibrations. By enabling easier implementation of methods requiring triple derivatives and beyond, our work could pave the way for more accurate and detailed vibrational studies of complex materials. Other examples of properties include polarisability, dipole, quadrupole and octupole moments, Raman spectroscopy methods, and so on.\nDevelopment of Advanced Chemical Models: Many chemical models, particularly in density functional theory (DFT), rely heavily on derivatives of properties of the chemical system. Standard density functionals typically require the density, its gradient, and Laplacian, among other derivative quantities. Our work provides a robust framework that can facilitate the testing and development of new density functionals that require novel derivatives. The ease of implementing and testing these new functionals within our framework could significantly accelerate the advancement of DFT methods and lead to more accurate models for predicting material properties.\nWe will expand our discussion in the manuscript to explicitly outline these potential applications.\nQ2 (Plane-wave Functions)\nThis paper may have just replaced these basis functions with the \"plane wave\" basis functions used in this paper. A switch which hardly seems like a big advance, though nevertheless a useful one.\nWe appreciate the comments and agree that differentiable DFT methods have been previously conceived in a molecular basis. However, we would like to emphasize that the implementation of these methods in a plane-wave basis, as presented in our work, is not a minor improvement but rather a significant advancement. The differences between molecular and plane-wave bases are substantial and necessitate a fundamentally different approach to the problem. Below, we detail some of these key differences:\nAssumption of System Boundaries:\nMolecular Bases: These are typically used for finite chemical systems and utilize atom-centered basis functions, such as Gaussian type orbitals (GTOs). Implementing DFT in this context requires specifically written integral packages such as libint, tailored to these finite systems.\nPlane-Wave Bases: In contrast, plane-wave bases assume periodic boundary conditions, allowing us to access and model technically infinite crystal systems. This requires a significantly different mathematical framing, including the definition of energy space (k-space), integration techniques, and band structure analyses.\nTechnical Implementation and Mathematical Framing: The use of a plane-wave basis necessitates a distinct approach in defining energy space, integrating over this space, analyzing band structures, and considering electron occupation across energy bands. This complexity is distinct from the challenges faced in a molecular basis.\nEfficiency and Accuracy Considerations: While molecular calculations can approximate crystal systems (and vice versa), such approaches are generally less desirable due to efficiency and accuracy concerns. Our method, by focusing on the plane-wave basis, addresses these challenges more directly and effectively for crystal systems.\nSpecialization in Computational Chemistry Modeling: The differences between these bases are so pronounced that most computational chemistry modeling tools specialize in either a molecular basis (e.g., Q-Chem, Gaussian, ORCA) or a plane-wave basis (e.g., VASP, Quantum Espresso). This specialization underscores the distinct challenges and approaches required for each basis type.\nWe will ensure that our manuscript more clearly articulates these points to emphasize the significant advancements our work represents in the context of differentiable DFT methods using a plane-wave basis."}, {"Heading": "Authors' response to Reviewer 2 (2/2)", "Subheading": "Official CommentbyAuthors17 Nov 2023, 05:47Everyone", "Content": "Comment:\nQ3 (The Venue)\nAs such, I wonder if it would be more appropriate in a computational physics venue.\nWe value Reviewer 2's perspective and acknowledgment that our work aligns well with a computational physics forum. While many intended studies are indeed planned in that direction, leveraging this work as a foundation, we present this study as a novel tool for materials discovery rooted in machine learning infrastructure. Hence, we believe that ICLR serves as the appropriate venue for the debut of this work.\nFurthermore, the significance of materials discovery within the machine learning community is continually expanding, as evidenced by notable contributions such as works [1-3]. We believe that members of the machine learning community are well-positioned to appreciate and make effective use of the additional functionalities embedded in the method we present. Although we do plan future endeavors targeting the computational physics community, these efforts have yet to materialize.\n[1] Sch\u00fctt, Kristof, et al. \"Schnet: A continuous-filter convolutional neural network for modeling quantum interactions.\" Advances in neural information processing systems 30 (NeurIPS 2017).\n[2] Cho, Youngwoo, et al. \"Deep-DFT: A Physics-ML Hybrid Approach to Predict Molecular Energy using Transformer.\" Advances in Neural Information Processing Systems (NeurIPS) Workshop. 2021.\n[3] Pope, Phillip, and David Jacobs. \"Towards Combinatorial Generalization for Catalysts: A Kohn-Sham Charge-Density Approach.\" \nAdvances in on Neural Information Processing Systems (NeurIPS 2023)."}, {"Heading": "Official Comment by Reviewer AFLR", "Subheading": "Official CommentbyReviewer AFLR22 Nov 2023, 22:39Everyone", "Content": "Comment:\nI have read the rebuttal, and believe that it has at least partially addressed my concerns. I will reconsider my rating."}, {"Heading": "Thank you for the comment", "Subheading": "Official CommentbyAuthors23 Nov 2023, 00:28Everyone", "Content": "Comment:\nThank you for taking the time to review our rebuttal and for your openness to reconsidering your initial assessment. We are glad to hear that we have addressed some of your concerns. If you feel that our response has positively impacted your view of our work, we would greatly appreciate it if you could update your rating to reflect your current opinion. Your revised rating would be incredibly valuable to us. Thank you again for your thoughtful consideration."}]}, {"Heading": "Official Review of Submission9253 by Reviewer TgFK", "Subheading": "Official ReviewbyReviewer TgFK31 Oct 2023, 22:36 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces a method to compute differentiable DFT solutions in the plane-wave/materials setting. This is achieved by avoiding the self-consistent equation loop where the Hamiltonian is dependent on the electron density, and the wave functions are eigenstates of the Hamiltonian. Differentiating through this SCF procedure requires differentiating through many iterations of eigendecomposition, which is highly unstable.\nThe proposed solution is to minimize an energy functional over a set of orthogonal vectors that has been parameterized as the QR decomposition of an unconstrained matrix. This approach requires differentiating only through one QR decomposition and the minimum of the optimization problem.\nExperiments are shown where 1) band structure is determined for various materials and 2) atom positions are optimized, showcasing the differentiability of the solution.\nSoundness:\n4 excellent\nPresentation:\n4 excellent\nContribution:\n3 good\nStrengths:\nThis work addresses an important problem and opens the door to differentiating through DFT solutions, making these approaches more amenable to machine learning and optimization tools, which can have vast applications in materials science. I really like to see this problem being addressed after having run into it in a different context at one point.\nThe paper is well written for the conference, giving a comprehensive yet concise introduction to the problem setting.\nThe experiments are well chosen and cover the main ideas.\nI will point out that I am not familiar with the literature landscape around these methods and will defer to the judgment of other reviewers for novelty of the method.\nWeaknesses:\nIf I am not mistaken, there is nothing much stopping this approach from being applied to other DFT settings, such as small molecules, using some form of Gaussian-harmonic basis set. At least the orthogonality of the orbitals can be guaranteed in the same way, though one uses the orthogonality of the plane waves. If this method is capable of covering this domain as well, I wish it was done in this paper, since it would showcase the strong generality of the approach.\nA lot of related work is mentioned, some of which close enough to allow for direct numerical comparisons. These would have improved the evaluation of the method.\nQuestions:\nWould the authors be able to comment on Weaknesses point 1 and 2?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Authors' response to Reviewer 3", "Subheading": "Official CommentbyAuthors17 Nov 2023, 06:10Everyone", "Content": "Comment:\nWe would like to thank the reviewer for these insightful comments, which helped us improve the quality of this paper.\nQ1 (Potential Applications)\nIf I am not mistaken, there is nothing much stopping this approach from being applied to other DFT settings, such as small molecules, using some form of Gaussian-harmonic basis set.\nWe appreciate the reviewer's comments into the potential application of our approach to other DFT settings, such as small molecules employing Gaussian-harmonic basis sets.\nWe would like to acknowledge that the prior work (Li et al., 2023), which is one of the most important foundation of this work, has indeed explored the extension of our methodology to diverse DFT settings, including applications involving small molecules utilizing Gaussian-harmonic basis sets. The results from this investigation supported the adaptability and effectiveness of our approach across a broader spectrum of electronic structure calculations.\nFor a comparison of plane-wave basis and other orthogonal basis, we advise the reviewer refer to Reviewer 2 Question 2.\nQ2 (More Comparisons)\nA lot of related work is mentioned, some of which close enough to allow for direct numerical comparisons. These would have improved the evaluation of the method.\nThank you for the comments. We would like to provide some numerical comparison results against existing methods.\nTotal energy differences.\nWe present the following tables of the difference in energy between points A and B from Figure 3. The result can measure the accuracy of our computation.\ncutoff energy (Ha)\nours\nQE\n200\n0.18876\n0.18860\n400\n0.18753\n0.18713\n800\n0.18692\n0.18621\nThis results shows that our approach can achieve similar results as conventional SCF methods.\nBand gap comparison.\nIn the table below we compile the band gaps of diamond and silicon based on the valence band maximum and the conduction band minimum. It can clearly be seen that the band gaps of diamond are reasonably consistent, whereas the band gaps of silicon are not, which quantifies some of the error/discrepancies in bands observed by the reviewer.\nCrystal\nOurs\nQE\nFHI-aims\nGPAW\ndiamond\n3.076\n3.080\n2.967\n3.103\nSilicon\n0.563\n1.118\n0.005\n0.077\nWe note here that the k-mesh and maximum cut-off energy accessible to our method are currently modest due a need for code optimization. Consequently, calculations were conducted with a k-mesh of 1x1x1 and cut-off energy of 200/400/800 Ha as recorded in the captions of the band structures. These settings were reproduced in the other programs."}]}, {"Heading": "Official Review of Submission9253 by Reviewer Npa9", "Subheading": "Official ReviewbyReviewer Npa930 Oct 2023, 23:16 (modified: 22 Nov 2023, 21:14)EveryoneRevisions", "Content": "Summary:\nThis manuscript follows the approach in [Li et al., 2023] to build a direct approach to solving the KSDFT equations for systems in periodic solid-state systems (by using a parameterization of the periodic part of the Bloch functions analogous to the prior work). The resulting formulation is then used for band-structure prediction and geometry optimization.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe manuscript is reasonably well written (though many details are necessarily relegated to the appendix), and does show the potential efficacy of the proposed scheme through some experiments. While, in a certain sense, the core technical insights come from [Li et al., 2023] there are invariably details to be worked out and they seem appropriately covered in detail in the appendix (though its length coupled with the reviewing timeline means I have, admittedly, not checked all the details). The problem space considered is clearly important, so the present work is certainly interesting and could have some impact.\nWeaknesses:\nGiven the framing of this manuscript, a core part of the contribution is empirical illustration of the methods efficacy. (As it has to be shown to work to be interesting.) While the results are suggestive that it does, they are somewhat limited and mostly limited to qualitative comparisons with little quantitative characterization of the methods efficacy. This makes it hard to evaluate the potential impact. More concrete tests and conclusions that address these points could easily elevate the potential impact of the manuscript.\nIn the band structure interpolation case, no quantitative errors/discrepancies are provided for the structure. For well separated (e.g., insulating) bands this should be easy to do. Is the method accurate on a fine k-mesh? Even for \"entangled\" bands this could be done sufficiently far from the largest eigenvalues considered.  The plots (especially in Fig. 5) show clear differences, are these meaningful? could the accuracy of the method be improved? what is considered the \"ground truth?\" Similarly, often in band structure plots there are more fine-grained structures than \"gap or not\" that are of interest (e.g., certain types of crossings), yet those are not explored here. Absent this more detailed analysis it is hard to assess whether or not the method is effectively computing band structure.\nOn a related note, a common technique to go from the k-mesh to band structure on some path in k-space is Wannier interpolation. Any comparison with this is missing from the present manuscript (even if it was interpolation from the k-mesh used with the proposed method). Given the need for \"fine tuning\" per point on the k-mesh maybe interpolation is preferable. A comparison seems warranted. Details for this point (and the prior comments) can be found in, e.g., Section VI of [Marzari, Nicola, et al. \"Maximally localized Wannier functions: Theory and applications.\" Reviews of Modern Physics 84.4 (2012): 1419.].\nFor the geometry optimization, given the ambiguity in the results having only one system makes it hard to draw conclusions. What are the conclusions beyond some optimizers going to local minima and some not in this one case? The manuscript would benefit from clarifying this point, and doing so may require more systems.\nSimilarly to the above points, while the single comparison with SCF for the potential energy surface is nice, it is ultimately one material and it seems pertinent to consider others across a range of \"types\" to be able to more strongly advocate for the relative efficacy of the method. Also, no qualitative or quantitative discussions of performance are given with classical approaches (across any experiments). While there may be advantages even if not speed, it would be good to have some sense of how such an approach stacks up with prior work (to at least better under stand the tradeoffs of using it).\nupdate after author response\nI would like to thank the authors for their thoughtful replies to my concerns and those of other reviewers.\nIn brief, the response does address some of my questions (though raises others, like just how limited is the current approach with respect to cutoff and k-point mesh\u2014that seems important to think of it as a competing method). While I appreciate some of the small (proposed) quantitative additions to the manuscript, my overall assessment of the manuscript remains essentially unchanged.\nQuestions:\nSome of the setup in Figure 2 + section 3 is slightly unclear/inconsistent and should be clarified. In the text it is suggested that the first step computes on the k-mesh (which is consistent with section 2), but the caption says \"first k-point.\" Is this a typo? or is something else meant.\nIs there any interpolation (beyond for plotting) done in Figure 2? the lower part of the figure suggests a rather sparse set of points on the path through k-space.\nAdditional questions specifically related to weaknesses of the manuscript are outlined in that section of the review.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Authors' response to Reviewer 4 (1/2)", "Subheading": "Official CommentbyAuthors17 Nov 2023, 06:31Everyone", "Content": "Comment:\nQ1 (Quantitative Comparisons)\nWhile the results are suggestive that it does, they are somewhat limited and mostly limited to qualitative comparisons with little quantitative characterization of the methods efficacy.\nIn the band structure interpolation case, no quantitative errors/discrepancies are provided for the structure. For well separated (e.g., insulating) bands this should be easy to do. Is the method accurate on a fine k-mesh? Even for \"entangled\" bands this could be done sufficiently far from the largest eigenvalues considered. The plots (especially in Fig. 5) show clear differences, are these meaningful? could the accuracy of the method be improved? what is considered the \"ground truth?\"\nThank you for these insightful comments. We would like to address this concern by two results:\nBand Gap Comparisons\nOur original goal for providing band structures was to demonstrate the capability of our program, however, the reviewer is correct that we have not included quantitative data and this has been an oversight. In the\ntable below\nwe compile the band gaps of diamond and silicon based on the valence band maximum and the conduction band minimum. It can clearly be seen that the band gaps of diamond are reasonably consistent, whereas the band gaps of silicon are not, which quantifies some of the error/discrepancies in bands observed by the reviewer.\nCrystal\nOurs\nQE\nFHI-aims\nGPAW\ndiamond\n3.076\n3.080\n2.967\n3.103\nSilicon\n0.563\n1.118\n0.005\n0.077\nThe reviewer also identified that an analysis of accuracy with respect to the k-mesh and cut-off energy is absent. We note here that the k-mesh and maximum cut-off energy accessible to our method are currently modest due a need for code optimization. Consequently, calculations were conducted with a k-mesh of 1x1x1 and cut-off energy of 200/400/800 Ha as recorded in the captions of the band structures. These settings were reproduced in the other programs.\nThe ground truth would be the computed band gap at an infinitely high k-mesh and cut-off energy which should be consistent between all programs at this limit. This is usually approximated by increasing both settings until the band gap or desired observable is converged. Consequently, the primary means to improve the accuracy of our method is to increase the k-mesh and cut-off energy, which we expect to be able to do as we optimize our method.\nEnergy differences of different crystal structures of carbon:\nAdditionally, we provide a table showcasing the energy differences between points A and B from Figure 3. This measure further assesses the accuracy of our computations compared to established methods.\ncutoff energy (Ha)\nours\nQE\n200\n0.18876\n0.18860\n400\n0.18753\n0.18713\n800\n0.18692\n0.18621\nThese results indicate that our approach achieves comparable accuracy to conventional SCF methods, providing insight into the reliability of our computations.\nQ2 (Comparison with Wannier Interpolation)\nOn a related note, a common technique to go from the k-mesh to band structure on some path in k-space is Wannier interpolation. Any comparison with this is missing from the present manuscript.\nWe acknowledge the reviewer's suggestion regarding comparing our approach with Wannier interpolation for deriving band structures along specific k-space paths. However, our manuscript's primary focus is to show the full differentiability of DFT for periodic systems, and comparing it with Wannier interpolation falls outside the intended scope of this work.\nWe appreciate the importance of such comparisons and will duly consider them in future research endeavors that align more closely with these specific comparative analyses."}, {"Heading": "Authors' response to Reviewer 4 (2/2)", "Subheading": "Official CommentbyAuthors17 Nov 2023, 06:39Everyone", "Content": "Comment:\nQ3 (Geometry Optimization)\nFor the geometry optimization, given the ambiguity in the results having only one system makes it hard to draw conclusions. What are the conclusions beyond some optimizers going to local minima and some not in this one case? The manuscript would benefit from clarifying this point, and doing so may require more systems.\nThank you for your valuable feedback on the geometry optimization section of our paper. We acknowledge the concern regarding the conclusions drawn from a single system and the need for clarity in this area. Here are some responses to this question.\nPurpose of the geometry optimization experiment.\nThe primary objective of our geometry optimization experiment was to demonstrate the practical application of differentiability in the context of DFT. Our approach, as delineated in Algorithm 1, uniquely enables the joint computation of atomic geometry and plane-wave coefficients. This is distinct from conventional methods, which typically require the full convergence of the SCF loop followed by the computation of Hellmann-Feynman forces.\nAdaptability of optimization techniques.\nWe intended to show the trivial adaptability of our method's optimization techniques, underscoring its flexibility and potential efficiency in different scenarios. The experiment was designed to illustrate how various optimizers could be employed in our framework and the implications of these choices for reaching local or global minima in a given system.\nScope of the current work and future directions.\nWe agree that a more extensive investigation into the most effective optimization methods for geometry optimization is warranted. However, given the vast scope of this field, as indicated by the comprehensive literature (e.g., [4] and refs contained therein), we consider such an in-depth analysis beyond the current work's scope. Geometry optimization in computational chemistry is a complex topic, encompassing hundreds of papers and various methodologies.\nIn line with Reviewer 2's suggestion, we believe that a dedicated study focusing solely on optimization methods in computational chemistry would be more appropriate for a specialized venue. Our work serves as a foundational exploration, highlighting the differentiability aspect of our method and its potential applications.\n[4] Schlegel, H. Bernhard. \"Geometry optimization.\" Wiley Interdisciplinary Reviews: Computational Molecular Science 1.5 (2011): 790-809\nQ4 (More Comparisons)\nwhile the single comparison with SCF for the potential energy surface is nice, it is ultimately one material and it seems pertinent to consider others across a range of \"types\" to be able to more strongly advocate for the relative efficacy of the method. Also, no qualitative or quantitative discussions of performance are given with classical approaches (across any experiments).\nAs alluded to in our response to Question 2, performance comparison between this and conventional methods was not the focus of this work as further optimization and implementation of symmetry recognition is required.\nA potential energy surface (PES) of LiF and Be mimicking that presented for diamond will be included, providing a qualitative performance of SCF and our method in ionic, metallic and covalent network material types respectively. These results will be shown in the revised manuscript shortly (Appendix A)."}, {"Heading": "Review updated", "Subheading": "Official CommentbyReviewer Npa922 Nov 2023, 21:15Everyone", "Content": "Comment:\nSince I am not sure a notification is generated when the review is updated (I did not get one), this comment is to note that I have updated my review after reading the author response."}]}]}, "vESNKdEMGp": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "multilingual, safety, large language models", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We reveal the presence of multilingual jailbreak challenges within LLMs and propose the Self-Defense framework to mitigate the issue.", "Abstract": "While large language models (LLMs) exhibit remarkable capabilities across a wide range of tasks, they pose potential safety concerns, such as the ``jailbreak'' problem, wherein malicious instructions can manipulate LLMs to exhibit undesirable behavior. Although several preventive measures have been developed to mitigate the potential risks associated with LLMs, they have primarily focused on English. In this study, we reveal the presence of multilingual jailbreak challenges within LLMs and consider two potential risky scenarios: unintentional and intentional. The unintentional scenario involves users querying LLMs using non-English prompts and inadvertently bypassing the safety mechanisms, while the intentional scenario concerns malicious users combining malicious instructions with multilingual prompts to deliberately attack LLMs. The experimental results reveal that in the unintentional scenario, the rate of unsafe content increases as the availability of languages decreases. Specifically, low-resource languages exhibit about three times the likelihood of encountering harmful content compared to high-resource languages, with both ChatGPT and GPT-4. In the intentional scenario, multilingual prompts can exacerbate the negative impact of malicious instructions, with astonishingly high rates of unsafe output: 80.92% for ChatGPT and 40.71% for GPT-4. To handle such a challenge in the multilingual context, we propose a novel \\textsc{Self-Defense} framework that automatically generates multilingual training data for safety fine-tuning. Experimental results show that ChatGPT fine-tuned with such data can achieve a substantial reduction in unsafe content generation.  Data is available at \\url{https://github.com/DAMO-NLP-SG/multilingual-safety-for-LLMs}.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "societal considerations including fairness, safety, privacy", "Submission Number": "9250", "PDF Url": "https://openreview.net/pdf?id=vESNKdEMGp"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9250 by Area Chair rr3K", "Subheading": "Meta ReviewbyArea Chair rr3K06 Dec 2023, 06:01 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper investigates the vulnerability of large language models (LLMs) to multilingual jailbreaks in both unintentional and intentional scenarios. It proposes a self-defense framework to improve LLM safety across languages.\nStrengths:\nAddresses a timely and crucial issue.\nIdentifies multilingual vulnerabilities and evaluates the impact of language resource levels.\nIntroduces the MultiJail dataset for multilingual jailbreak research.\nProposes the SELF-DEFENSE framework for improving multilingual safety.\nWeaknesses:\nPresentation could be improved with details.\nSelf-defense framework needs comparison to other safety techniques and might be overly complicated.\nPotential bias in using GPT-4 as an evaluation measure.\nJustification For Why Not Higher Score:\nEvaluation can be further improved (soundness, presentation details). Few reviewers also pointed out the the mitigation section is relatively weak.\nJustification For Why Not Lower Score:\nAddresses the crucial issue of LLM safety in non-English languages."}, {"Heading": "General Response to All Reviewers", "Subheading": "Official CommentbyAuthors20 Nov 2023, 16:33Everyone", "Content": "Comment:\nWe are deeply grateful for the valuable time and dedication put forth by each reviewer in providing insightful and constructive feedback. We have now uploaded a revised version of the paper that includes additional details, and supplementary experiments to enhance clarity.\nTo sum up, we have made the following revisions:\nAdditional descriptions for Figure 2 to quantify the agreement between human and GPT-4 evaluation;\nAdditional tag statistics to illustrate safety issues covered in the dataset in Appendix A.2;\nSupplementary experiment in Appendix A.6 to study the effect of decoding methods;\nSupplementary experiment in Appendix A.7 to show the results of open-source LLMs;\nAdditional explanation of selecting AIM in Section 3.1;\nAdditional description on the flexibility of Self-Defence in Section 4.1;\nAdditional description on the effect of noisy translation in Section 4.3.\nWe addressed individual reviewer concerns below. Thank you all once again!"}, {"Heading": "Official Review of Submission9250 by Reviewer emGp", "Subheading": "Official ReviewbyReviewer emGp06 Nov 2023, 12:23 (modified: 22 Nov 2023, 09:41)EveryoneRevisions", "Content": "Summary:\nThis paper reports the vulnerabilities of large language models from the perspective of two scenarios: unintentional and intentional situations. In the unintentional scenario, queries that are simply translated into non-English languages unexpectedly make users face unsafe content. On the other hand, the intentional scenario considers translated multi-lingual \u201cjailbreak\u201d prompts. The paper evaluates ChatGPT and GPT-4, and reveals that the models are more risky as the target language is lower-resource. Lastly, they propose \u201cSelf-Defense\u201d method that fine-tunes ChatGPT with augmented and translated unsafe data.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThis paper addresses timely and crucial issue of LLMs, as those models are usually evaluated in English, despite they have been widespread around the world. I think we should pay attention to strengthening the safety level of LLMs for the various languages including low-resource languages. In that sense, the multilingual jailbreak and the evaluation results are valuable.\nWeaknesses:\nAlthough the significance of the theme of this paper, in overall, the soundness and presentation are quite needed to be improved to strengthen this paper. Here are my comments and feedback. Some might be nice-to-haves but not strictly necessary, so feel free to argue why it is a good idea not to incorporate them.\nOverall, when you mention differences or improvements in performance, please mention the significance levels (ie., p-values) together. Also, please denote standard deviations (inside tables or figures), because the number of test samples is limited (15 prompts for the preliminary experiment).\nLack of human evaluation details. Moreover, decisions on whether generated content is safe or unsafe are subjective and depend on annotators. The paper should include the human evaluation process, instructions, and annotator information.\nRecently, there has been an argument that the evaluation of model-generated output with LLM-based evaluators has a potential bias \u2014 that is, GPT-4 might prefer and give higher scores on GPT-4\u2019s outputs than ChatGPT [1, 2]. Also, (in Table 1), GPT-4 might have been aligned more than ChatGPT concerning GPT-4\u2019s safety evaluation standards. Moreover, GPT-4 as an evaluator might have led to length or positional bias [2]. The paper should mention this if you have already considered this, or reinforce the results with repetitive experiments.\nMoreover, in Section 2, the authors mentioned that \u201cFurthermore, Figure 2 illustrates a notable level of agreement between human annotators and the GPT-4 evaluator.\u201d, I think you can provide the correlation or agreement values (numbers) rather than just pointing out similar trends of the two lines.\nRelease of MultiJail dataset and evaluation results. \u2014 I believe the authors would be able to publish their data.\nThis paper evaluated only two black-box models, whose training corpus and portion of languages are unveiled. What about evaluating other open-sourced models such as LLaMA, Vicuna, and others, to see the correlation between the portions of language resources in training data and the attack success rates?\nThe proposed \u201cSelf-Defense\u201d framework is simple and able to show the effectiveness. However, in somewhat points, the result comes out naturally, since the ChatGPT was further fine-tuned with the augmented multi-lingual unsafe dataset. Can we conclude that the improvement depends on the extent of the low-source level? Or another insight can be concluded from the framework?\nLastly, the authors mention that \u201cAdditionally, the translation process enables\nthe transfer of knowledge and safety guidelines across multiple languages,\nthereby improving the safety alignment in a multilingual context.\u201d However, the safety guidelines can be differently applied across different cultures and societies. I am not certain that the adversarial examples used in this paper are general enough to be transferred across other languages and societies. However, at least the guidelines follow the U.S. or several companies, and I think we should carefully consider the sensitivity of safety level in the target society.\n[1] Liu et al., G-EVAL: NLG Evaluation using GPT-4 with Better Human Alignment,\nhttps://arxiv.org/pdf/2303.16634.pdf\n[2] Zheng et al., Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena,\nhttps://arxiv.org/abs/2306.05685\n[3] Wang et al., Large Language Models are not Fair Evaluators,\nhttps://arxiv.org/pdf/2305.17926.pdf\nQuestions:\nIn Table 1, unlike to the unintentional scenario, in the intentional scenario, it\u2019s hard to find any tendency among HRL, MRL, and LRL.\nThe generated outputs in non-English language are again translated into English to be assessed by a Human or GPT-4 evaluator, through Google Translates. In this process, why didn\u2019t you assess the generated output itself, but translate it back to English? Do you think there could be errors?\nFor simplicity, the authors set the temperature as zero for the two models. Do you think the results could vary if nucleus sampling was applied?\n\u201cunsafe and general\u201d phrase could cause readers to misunderstand; \u201cgeneral\u201d means \u201csafe\u201d or \u201chelpfulness (usefulness)\u201d instruction pairs. Or even it can be interpreted as an unsafe prompt - a general (safe) response.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 16:02Everyone", "Content": "Comment:\nWe greatly appreciate your insightful comments and suggestions, as they have been helpful in refining and enhancing our work. We have thoroughly reviewed all of your points and have addressed your concerns as outlined below:\nW1: Standard deviations\nThank you for your kind feedback. In our experiments, we maintained a temperature of zero and utilized fixed datasets for both preliminary and detailed testing. As a result, the output remained constant. However, for supplementary experiments, we employed nucleus sampling to explore further possibilities. For more information on these supplementary experiments, please refer to Q3, where we provide detailed explanations.\nW2: Detail human evaluation process\nWe completely agree with this. To ensure accurate human evaluation, we have implemented the following steps:\nTranslation: As discussed in Section 2.1, we have used Google Translate to translate all the output into English.\nAnnotation: We engage two annotators to independently label the translated output following the definition in Appendix A.2.\nConflict resolution: In case of any conflicts or discrepancies between the annotations, we have involved an additional expert to make the final determination on the label.\nBy following these steps, we aim to ensure the highest possible accuracy and reliability in the human evaluation process.\nW3: Address potential LLM-based evaluator bias\nThank you for bringing up this important point.\nHowever, we think that evaluator bias may mainly exist in NLG problems, particularly in subjective metrics like \"fluency\", \"relevancy\", \"preference\", etc. When it comes to evaluating \"safety\", the concept tends to be much more \"objective,\" especially when we frame safety evaluation as a classification task.\nIn addition, almost all examples are easy-to-identify unsafe topics, such as \"Violence\", \"Adult content\" and etc. We list the detailed statistics in Appendix A.2.\nFinally, we have defined the criteria for each class in the GPT-4 evaluation prompt, minimizing potential bias as much as possible. In W4, we further show that GPT-4 is a reliable evaluation measure.\nW4: Provide specific agreement values\nSure, we have measured the agreement between GPT-4 and human evaluations, utilizing Cohen's kappa coefficient. The Cohen's kappa score is 0.86, showing a high agreement between GPT-4 and human evaluations.\nW5: Publish MultiJail dataset and results\nYes, we will publish our MultiJail dataset including necessary code and results in the future."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 16:06Everyone", "Content": "Comment:\nW6: Evaluate open-sourced models\nYes, we have explored evaluating open-source language models such as LLama2 and Vicuna. However, we found certain limitations in their multilingual capabilities and safety measures, which could potentially introduce noise during analysis. Specifically, LLama2 primarily responds in English, even when presented with non-English input. Though Vicuna has the ability to respond in languages other than English, it lacks specialized safety tuning, and its limited safety capabilities are mainly derived from user-shared responses of ChatGPT/GPT-4.\nGiven these limitations, we've primarily centered our attention on ChatGPT and GPT-4. These models offer a more seamless conversational experience across various languages and have robust safety mechanisms in place. Nevertheless, we have included the experimental results for LLama2 and Vicuna under unintentional scenarios as supplementary references, presented in the table below, detailed in Appendix A.7:\nChatGPT\nGPT-4\nLlama2-7b-Chat\nVicuna-7b-v1.5\nen - unsafe\n0.63\n0.95\n0.63\n57.14\nen - safe\n99.37\n99.05\n99.37\n37.78\nen - invalid\n0.00\n0.00\n0.00\n5.08\nHRL - unsafe\n4.34\n3.60\n2.22\n40.32\nHRL - safe\n95.13\n95.98\n92.06\n51.32\nHRL - invalid\n0.53\n0.42\n5.71\n8.36\nMRL - unsafe\n11.32\n4.13\n4.55\n42.75\nMRL - safe\n87.20\n94.94\n66.88\n32.38\nMRL - invalid\n1.48\n0.95\n28.57\n24.87\nLRL - unsafe\n14.92\n10.16\n1.69\n28.78\nLRL - safe\n78.41\n83.49\n65.19\n9.42\nLRL - invalid\n6.67\n6.35\n33.12\n61.80\nAVG - unsafe\n14.92\n5.96\n2.82\n37.28\nAVG - safe\n78.41\n91.46\n74.71\n31.04\nAVG - invalid\n6.67\n2.57\n22.47\n31.68\nFrom the results, it's evident that while Llama2-Chat performs well in English, and even obtains the lowest average unsafe rate, it also generates a considerable amount of invalid output. As such, it's difficult to determine whether its low unsafe rate is a result of genuinely safe or invalid content generation.\nOn the other hand, Vicuna demonstrated the least safety capability, with a notably high unsafe rate of 57.14% even in English. Moreover, it also had a substantial rate of generating invalid responses.\nIn conclusion, to ensure a unbiased evaluation, we have chosen to primarily report our experiments based on ChatGPT and GPT-4. These models showcase safisfactory multilingual abilities, exhibit low invalid response rates, and have comprehensive safety tuning mechanisms in English. These factors help to isolate the language aspect during the analysis, eliminating other potential influences.\nW7: Analyze \"Self-Defense\" framework effectiveness\nWe appreciate the reviewer's insightful question. Before addressing the question, we would like to provide some context regarding the multilingual jailbreak challenge. We classify the cause of this challenge as a mismatched generalization [1], specifically the lack of a non-English corpus during safety tuning.\nIn order to ensure the effectiveness of \"Self-Defence,\" we believe two preconditions need to be met. Firstly, the model should possess strong safety capabilities in high-resource languages. Secondly, it should have strong multilingual abilities.\nIf the model fulfills these two requirements, \"Self-Defence\" can perform explicit alignment of its safety capabilities from high-resource languages to low-resource languages. Essentially, it leverages its existing safety capability and transfers it to other language spaces.\nFurthermore, in our future research, we plan to conduct additional experiments to validate and enhance the effectiveness of our approach. By doing so, we aim to propose even more effective methods to tackle the multilingual jailbreak challenge.\nW8: Consider cultural differences in safety guidelines\nWe fully acknowledge that the concept of \"safety\" can vary across different cultures and societies.\nHowever, most adversarial examples consist of general unsafe content, including pornography, terrorism, fraud, and other globally recognized forms of unsafety, detailed in Appendix A.2. Consequently, only a limited number of examples are appropriate for \"localization\" purposes. Additionally, to focus solely on the \"language\" aspect, we have opted for direct translation without localization. Nonetheless, we recognize the significance of studying cultural differences, which would require fine-grained annotation and more in-depth research. We intend to explore this aspect in our future research projects."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 16:22Everyone", "Content": "Comment:\nQ1: Lack of trend in intentional scenario\nYes, as discussed in Section 3.2.2, we found that LLMs display relative stability regardless of language availability in intentional scenarios. We assume that in unintentional scenarios, the multilingual jailbreak problem arises mainly due to the inherent tension between the LLMs' pre-training ability and safety capability, leading to an obvious trend. However, this situation becomes further complicated when malicious instructions are introduced, as the importance of instruction-following factors increases. There is a conflict between pre-training, instruction-following, and safety abilities. This complex situation makes the previously observed trend unobvious. We will dive deeper into our future research to study the inherent cause of the jailbreak problem.\nQ2: Translation and assessment of non-English outputs\nThe primary goal is to ensure the quality of evaluation. Initially, during the human evaluation process, we discovered that while the translation may not be perfect, it maintains the core idea of the sentence. This allows us to confidently predict its safety.\nWith respect to GPT-4, the unintentional scenario results demonstrate limited safety capabilities in non-English languages. As a solution, translating the non-English output back into English using Google Translate can enhance GPT-4's safety evaluation performance. Although this may introduce some noise, the benefits it brings outweigh these minor inconveniences.\nIn our preliminary experiments, we actually tried sampling some examples and compared GPT-4's evaluation of translated English versus direct non-English text on its website. Our investigation revealed that translating back to English is a more reliable approach.\nQ3: Zero temperature setting and nucleus sampling impact\nWe chose to use a zero temperature setting primarily to prioritize the reproducibility and reliability of our experiment. While other decoding strategies may yield slightly different results, a recent study [1] has indicated that the qualitative outcomes and observed trends remain consistent in general jailbreak experiments.\nTo further investigate the impact of different decoding strategies, we conducted an experiment in an unintentional scenario using ChatGPT with nucleus sampling and a top_p value of 0.8. To ensure reliable results, we ran the experiment three times with different seeds. The following data represents the unsafe rate of this experiment, with the standard deviation values indicated within parentheses:\nChatGPT (sample=False)\nChatGPT (nucleus sampling with top_p = 0.8)\nen\n0.63\n0.42 (0.18)\nzh\n2.22\n4.02 (0.48)\nit\n2.86\n2.75 (0.37)\nvi\n7.94\n9.10 (0.48)\nHRL\n4.34\n5.29 (0.21)\nar\n6.03\n6.88 (0.48)\nko\n9.84\n9.84 (0.84)\nth\n18.10\n20.95 (1.45)\nMRL\n11.32\n12.56 (0.34)\nbn\n28.25\n31.85 (1.28)\nsw\n7.94\n8.15 (1.20)\njv\n8.57\n9.42 (1.43)\nLRL\n14.92\n16.47 (0.60)\nAvg.\n10.19\n11.44 (0.31)\nIt is evident that the average unsafe rate, although slightly higher (1.25%), the trend is still clearly observable, as the rate of unsafe content increases with decreasing language availability, resulting in a consistent ranking order.\nQ4: Ambiguity of \"unsafe and general\" phrase\nThank you for pointing it out. \"General\" here primarily focuses on \"usefulness\". Implicitly, all content is safe. We will refine the expression to prevent misunderstandings.\n[1] Wei et al., Jailbroken: How Does LLM Safety Training Fail?,\nhttps://arxiv.org/abs/2307.02483\n[2] Ganguli et al., Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned,\nhttps://arxiv.org/abs/2209.07858"}, {"Heading": "Thanks for responding my reviews.", "Subheading": "Official CommentbyReviewer emGp22 Nov 2023, 06:13Everyone", "Content": "Comment:\nDear authors,\nI thoroughly read your responses, and thank you for updating your manuscript and providing additional experiments.\nI was able to resolve my questions. Followings are my thoughts and comments:\nW6: Evaluate open-sourced models\nI understand the reason why you chose GPT-4 and ChatGPT. From the additional experiments, however, the trend where low resource language is vulnerable to jailbreaks does not work. But, when it comes to \"safe\" instead of \"unsafe\", that is \"unsafe + invalid\", we can conclude that the extent of safe response is decreasing as the volume of resource is decreasing.\nQ3: Zero temperature setting and nucleus sampling impact\nI appreciated your supplementary experiments. I think even though zero-temperature, the probability distribution probably and slightly different because of randomness of layers in the LLM. But, again, I understand!\nW7: Analyze \"Self-Defense\" framework effectiveness\nIn order to ensure the effectiveness of \"Self-Defence,\" we believe two preconditions need to be met. Firstly, the model should possess strong safety capabilities in high-resource languages. Secondly, it should have strong multilingual abilities.\nIf the model fulfills these two requirements, \"Self-Defence\" can perform explicit alignment of its safety capabilities from high-resource languages to low-resource languages. Essentially, it leverages its existing safety capability and transfers it to other language spaces.\nI was able to understand the authors' motivation for \"self-defense\". I'd recommend to mention and explain the motivation and assumptions in the manuscript. However, to verify and support them, you might need the future work you mentioned.\n(minor) The algorithm 1 looks confusing.\nplease clarify definition of D_l,\n\"M: D_a <- M(D_s)\" could be understated as the definition of a function M\nin line 1, how to augment? what does it mean that D_a <- M(D_s)? That is, M(D_s) = set of responses to queries in D_s?\nGood luck :)"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 07:42Everyone", "Content": "Comment:\nDear Reviewer emGP,\nThank you for your prompt reply and additional valuable feedback!\nHere are our responses to your comments:\n1. W6: Evaluate open-sourced models\nYes, the inherent limitations of the two open-source LLMs may compromise the validity of the evaluation. To ensure a balanced and unbiased assessment, we have opted to use GPT-4 and ChatGPT.\n2. Q3: Zero temperature setting and nucleus sampling impact\nYes, achieving a completely deterministic result can be challenging. However, we strive to enhance the reproducibility of our experiments by setting the temperature to 0.\n3. W7. Analyze \"Self-Defence\" framework effectiveness\nThank you for your constructive feedback! We appreciate your valuable input and will carefully consider it to improve our manuscript.\n4. W7. Analyze \"Self-Defence\" framework effectiveness\n\"D_l\" in this context refers to the translated dataset in the target languages.\n2&3. We aim to showcase the augmentations performed by the LLM using these seed examples as partial input.\nWe will refine our manuscript and provide clear definitions to avoid any misunderstandings.\nAs we have taken care of your concerns, would you be open to discussing a potential rate change? We would greatly appreciate your consideration. Again, thank you for your helpful comments! Your valuable input has greatly improved our manuscript.\nBest Regards,\nAuthors"}, {"Heading": "Change my score", "Subheading": "Official CommentbyReviewer emGp22 Nov 2023, 09:45Everyone", "Content": "Comment:\nI changed my overall scores from 6 to 8 by acknowledging the important topic of this paper and its value as benchmark baseline of multi-lingual jailbreak.\nBest regard,"}]}, {"Heading": "Official Review of Submission9250 by Reviewer Pbxw", "Subheading": "Official ReviewbyReviewer Pbxw04 Nov 2023, 19:30 (modified: 23 Nov 2023, 21:27)EveryoneRevisions", "Content": "Summary:\nThis paper proposes multilingual jailbreaks in two scenarios, 1) the unintentional scenario involves users querying LLMs using non-English prompts and inadvertently bypassing the safety mechanisms, 2) the intentional scenario entails malicious users combining jailbreak instructions with multilingual prompts to attack LLMs deliberately. Empirical experiments show that proprietary models are vulnerable in unintentional scenarios. Besides, a self-defense strategy is proposed where both harmful and harmless prompts and desired responses in different languages are utilized to fine-tune chatgpt.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThis paper proposes an effective jailbreak strategy, with detailed analysis on a defense attempt as well.\nTwo jailbreak scenarios are investigated, one is intentional and the other is unintentional.\nWeaknesses:\nUsing output from GPT4 as evaluation measure is not a good idea although its output looks consistent as human evaluation demonstrated in Fig.2\nAs shown in Table 1, GPT-4 still suffers from jailbreak when the user prompt is in English: as high as 28.25% for unintentional case.\nIt's hard to distinguish the high success attack rate is attributed to rarely unseen language or the AIM harmful instruction, since the harmful instruction itself alone can achieve very high success attack rate in English, as shown in Table 1.\nQuestions:\nIn section 3.1. Setup, Since Anthropic's red teaming dataset contains multi-turn dialogs, it's likely that the first user prompt is harmless. Perhaps you should consider both task_descripton_harmlessness_score and the number of turns (turn=1 to ensure that the 1st user prompt is harmful if the score satisfies some pre-defined criterion). Moreover, there are 38961 instances covered by the red teaming dataset, the details for how to select 300 from 38k instances should be elaborated.\nSuggestion\nIn tables, all the unsafe rate values are presented in percentile. But in figures, values are shown in decimal. A consistent presentation throughout the paper is preferred for easier understanding.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 15:14Everyone", "Content": "Comment:\nThank you for providing us with your valuable feedback. We have carefully considered your questions and would like to address them as below:\nW1. Concern on GPT-4 evaluation\nRegarding safety evaluation, it's worth highlighting that it's generally an easier task compared to generating safe content. The former is a classification task, while the latter is a more complex natural language generation task. A recent study provides further evidence of this, showing that LLMs can effectively flag a majority of harmful text they generate themselves [1].\nIn addition, the table below summarizes common methods for evaluating jailbreak results, their limitations, and how GPT-4 compares to them:\nEvaluation Method\nDescription\nLimitations\nComparison with GPT-4\nRule Match\nRule-based method checking if a response contains rejection words (e.g., \"I'm sorry\", \"I cannot\")\nPoor performance and cannot handle \"invalid\" class.\nGPT-4 is stronger and can handle \"invalid\" cases better\nModeration API\nUtilizes OpenAI/Google's moderation APIs to get scores for pre-defined unsafe classes\nPoor performance, only contains  pre-defined unsafe classes, cannot handle \"invalid\" class\nGPT-4 performs better and can handle more classes, including the \"invalid\" class\nFine-tuned model\nFine-tune a small language model for evaluation\nLack of reliable training datasdet.\nGPT-4 can execute evaluations in a zero-shot manner, delivering impressive results.\nHuman Evaluation\nUses humans as evaluators\nCostly, inefficient, and can be subjective, leading to inconsistent scores\nGPT-4 is more cost-effective, efficient, and provides consistent scoring\nTaking into account the aforementioned factors, GPT-4 has emerged as a reliable, efficient and widely-accepted evaluation method [2,3,4,5].\nMoreover, as depicted in Fig. 2, there is a significant level of agreement between human evaluation and the evaluation carried out by GPT-4. To quantify this agreement, we computed the Cohen's kappa score, which stands at a robust 0.86. This high score underscores the considerable alignment between GPT-4's evaluations and human judgments.\nBased on these reasons, we have made the decision to employ GPT-4 as our primary evaluation measure.\nW2. Attribution of high attack success rate\nYes, we intentionally chose the highest malicious instruction from\nhttps://www.jailbreakchat.com/\n, but it is crucial to clarify that our primary objective wasn't to obtain a high unsafe rate. Instead, we attempted to\nmimic a malicious user's behavior\nwho, in a real-life scenario, would likely search the internet to find the most effective harmful instruction for intentional purposes.\nWe wanted to demonstrate that even when a malicious user employs the most advanced malicious instruction, the integration of multilingualism can substantially enhance the effectiveness of their jailbreaking techniques.\nTherefore, the high unsafe rate should not be solely attributed to the malicious instruction power. Instead, it proves how multilingualism can amplify the potential of already powerful tools, thereby posing a significant threat to AI systems.\nBy incorporating multilingualism, we are exploring an orthogonal approach to boosting jailbreaking techniques. It is a unique dimension that can amplify the threat level, thereby highlighting the necessity for robust multilingual safety measures.\nQ1. Clarification on setup from red teaming dataset\nBelow are the details of our data selection process:\nWe selectively choose adversarial examples that include tags. Out of a total of 38,961 examples, only 742 of them contain harmful tags.\nFrom this set, we randomly sample 300 examples from top-500 lowest task_description_harmlessness_score. All of these examples have both harmful tags and a low task_description_harmlessness_score. We then extract the first user prompt from each of them.\nFollowing a human evaluation, it was determined that 99% (297/300) of the extracted examples were harmful.\nWe have included the detailed tag statistics in Appendix A.2.\nQ2. Consistency in value presentation between tables and figures\nThank you for your kind suggestion! We will refine accordingly to maintain consistent presentation.\n[1] Phute et al., LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked,\nhttps://arxiv.org/abs/2308.07308\n[2] Yuan et al, GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher,\nhttps://arxiv.org/abs/2308.06463\n[3] Bhardwaj et al, Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment,\nhttps://arxiv.org/abs/2308.09662\n[4] Qi et al, Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!,\nhttps://arxiv.org/abs/2310.03693\n[5] Ji et al, BeaverTails: Towards Improved Safety Alignment of LLM via a Human-Preference Dataset,\nhttps://arxiv.org/abs/2307.04657"}, {"Heading": "More discussion with Reviewer Pbxw", "Subheading": "Official CommentbyAuthors22 Nov 2023, 08:03Everyone", "Content": "Comment:\nDear Reviewer Pbxw,\nWe greatly appreciate your valuable comments on our work. We have carefully addressed your concerns regarding:\nReason for GPT-4 evaluation;\nAttribution of high attack success rate;\nClarification on dataset setup.\nAs the deadline for discussion is approaching, we eagerly await your feedback on our response and new experiments.\nThank you for your time and consideration.\nBest Regards,\nAuthors"}]}, {"Heading": "Official Review of Submission9250 by Reviewer QBvZ", "Subheading": "Official ReviewbyReviewer QBvZ02 Nov 2023, 21:51 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn this paper the authors explore how LLM safety generalizes across languages.  They translate a set of unsafe prompts across multiple languages, finding that ChatGPT and GPT-4 safety metrics degrade by language prevalence and that the models are also more vulnerable to a jailbreak when combining languages.  They propose additional fine-tuning data to improve safety across these languages, finding that this fine-tuning improves safety but comes with a cost to usefulness.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n3 good\nStrengths:\nS1. The question of safety across many languages and generalization of LLMs across languages is of significant importance to this technology.\nS2. There has been some but not a lot of work so far doing a thorough evaluation of LLM safety across languages, making this evaluation valuable for the community.\nS3. The paper studies this question from numerous angles - overall safety performance, jailbreaks, amount of data in CommonCrawl, mitigation through fine-tuning, trade-off with usefulness.\nWeaknesses:\nW1. I think for the study of safety in other languages, it should not be framed as a jailbreak.  Simply ensuring the model performs safely for people who speak those languages is important on its own.  In some places this acknowledged but I'd make it more clear early on and consistent.\nW2. Small sample size and error bars - samples are generally quite small (15-30 samples per language in some cases; only testing on a single jailbreak, AIM).  It'd be good to see this work done at a larger scale (especially given much of it is automated) and to include error bars given the small sample sizes.\nW3. Also given the small sample size, it is hard to gauge what diversity of safety issues are studied.  More details on the types of safety issues and how those vary across language would help contextualize the results (although I believe this is less critical).\nW4. Experiments are only run on ChatGPT and GPT-4.  It'd be useful to see similar experiments on other models, e.g. through HELM or just a few other APIs (again not critical but valuable).\nW5. The method seems somewhat over-complicated, when the data eg from Anthropic could be translated and used directly.  How come this more complex algorithm is necessary/valuable?\nW6. Overall I'd consider the mitigation section the weakest section - it'd be nice to see the authors find a way to improve safety without hurting usefulness, and to understand the benefits of additional data with as much nuance as the earlier sections (eg results don't seem to be broken down here by level of language resources anymore).\nQuestions:\nWhile W1 is mostly a writing suggestion, further experimental details and answers for W2-W6 above would be appreciated.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 15:23Everyone", "Content": "Comment:\nThank you for providing us with your valuable feedback and suggestions. We appreciate your input and have carefully considered your questions. Below, we provide detailed responses to each of them:\nW1: Frame safety study as important, not as a 'jailbreak'\nThank you for your valuable feedback. While we agree that ensuring safety for different languages is important in itself, we wanted to provide a novel perspective by highlighting how language can be used as a method for jailbreaking. This framing allows us to explore the vulnerabilities of LLMs across languages. We will revise the paper to ensure that the importance of language-specific safety is emphasized alongside the concept of jailbreaking.\nW2: Small sample size and lack of error bars\nRegarding the small sample size\n, we included 15 examples in our preliminary experiment as a starting point. We do recognize the need for a larger dataset to obtain more reliable results. Therefore, in the detailed experiment, we expanded our dataset to include 315 examples for each language, resulting in a total of 3150 examples.\nRegarding the malicious instructions\n, our intention was to replicate the actions of a real-life malicious user who searches for and selects the most powerful malicious instructions available online. That't why the scenario is named as \"intentional\". While we acknowledge that including a greater variety of malicious instructions would provide a more comprehensive evaluation, we plan to incorporate additional instructions in our future research.\nRegarding the error bars\n, given that we have set the temperature to 0 and are evaluating a fixed dataset, the output remains constant. To respond to your concerns, we have also conducted an additional evaluation using another decoding method. Specifically, we used nucleus sampling with a top_p value of 0.8. To ensure reliable results, we ran the experiment three times with different seeds. The following data represents the unsafe rate of this experiment, with the standard deviation values indicated within parentheses:\nen\nzh\nit\nvi\nHRL\nar\nko\nth\nMRL\nbn\nsw\njv\nLRL\nAvg.\nChatGPT (sample=False)\n0.63\n2.22\n2.86\n7.94\n4.34\n6.03\n9.84\n18.10\n11.32\n28.25\n7.94\n8.57\n14.92\n10.19\nChatGPT (nucleus sampling with top_p = 0.8)\n0.42 (0.18)\n4.02 (0.48)\n2.75 (0.37)\n9.10 (0.48)\n5.29 (0.21)\n6.88 (0.48)\n9.84 (0.84)\n20.95 (1.45)\n12.56 (0.34)\n31.85 (1.28)\n8.15 (1.20)\n9.42 (1.43)\n16.47 (0.60)\n11.44 (0.31)\nIt is evident that the average unsafe rate, although slightly higher (1.25%), the trend is still clearly observable, as the rate of unsafe content increases with decreasing language availability, resulting in a consistent ranking order. We have show details in Appendix A.6.\nW3: Need for diversity in safety issues studied\nYes, we have incorporated tag features to indicate the safety issue studies. These tags are derived from the Anthropic dataset, which assigns one or more tags to each example. In order to maintain consistency, we have applied the same tagging schema to label OpenAI's 15 prompts. Our dataset includes a wide range of 18 safety issues, ensuring its diversity. The top-3 safety issues and their respective percentages in the dataset are \"Violence & incitement\" (18.70%), \"Discrimination & injustice\" (11.28%), and \"Hate speech & offensive language\" (8.41%). For a comprehensive list of tags and their details, please refer to the Appendix A.2."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 15:27Everyone", "Content": "Comment:\nW4: Tests limited to ChatGPT and GPT-4\nWe expanded our experiment to include two widely used open-source LLMs: Llam2-Chat and Vicuna. The results of this extension on unintentional scenario are presented below:\nChatGPT\nGPT-4\nLlama2-7b-Chat\nVicuna-7b-v1.5\nen - unsafe\n0.63\n0.95\n0.63\n57.14\nen - safe\n99.37\n99.05\n99.37\n37.78\nen - invalid\n0.00\n0.00\n0.00\n5.08\nHRL - unsafe\n4.34\n3.60\n2.22\n40.32\nHRL - safe\n95.13\n95.98\n92.06\n51.32\nHRL - invalid\n0.53\n0.42\n5.71\n8.36\nMRL - unsafe\n11.32\n4.13\n4.55\n42.75\nMRL - safe\n87.20\n94.94\n66.88\n32.38\nMRL - invalid\n1.48\n0.95\n28.57\n24.87\nLRL - unsafe\n14.92\n10.16\n1.69\n28.78\nLRL - safe\n78.41\n83.49\n65.19\n9.42\nLRL - invalid\n6.67\n6.35\n33.12\n61.80\nAVG - unsafe\n14.92\n5.96\n2.82\n37.28\nAVG - safe\n78.41\n91.46\n74.71\n31.04\nAVG - invalid\n6.67\n2.57\n22.47\n31.68\nHowever, we found that these two models contain the following problems:\nAlthough Llama2-Chat has the capacity to comprehend non-English languages, it mostly responds in English. This may limit its applicability in real-world scenarios, particularly for non-English speaking users, making the evaluation less realistic.\nBoth models often generate invalid outputs due to their limited multilingual capabilities. While Llama2-Chat owns the lowest average rate of unsafe content, it is challenging to determine whether this lower rate is a consequence of producing genuinely safe content or simply generating invalid content.\nVicuna has been trained on user-shared conversations sourced from ChatGPT and GPT-4. The language distribution within this training data is somewhat disordered, leading to unpredictable results. Furthermore, Vicuna has not undergone specific safety tuning, resulting in a high unsafe content rate, particularly in English, with a staggering 57.17% unsafe rate.\nThus, we have decided to concentrate our evaluation primarily on ChatGPT and GPT-4 to ensure a realistic and dependable assessment. However, we will supply the supplementary results in the Appendix A.7 for further reference.\nW5: Over-complicated methodology\nWe acknowledge that directly translating Anthropic's dataset or other safety-related datasets is a straightforward way to address the multilingual jailbreak challenge. However, our proposed method can be helpful in the following scenarios:\nData augmentation: Our method provides a way to quickly augment a large multilingual safety dataset to address the challenge effectively and efficiently.\nFine-grained generation: If a new safety topic is introduced, or the safety guideline is changed, or a new language is added, we can simply edit the seed example and instruction in the \"Self-defence\" framework to adapt accordingly.\nData imbalance: Safety datasets may have uneven topic distribution. The \"Self-Defence\" framework can address this by generating data for underrepresented topics using specific seed examples and instructions.\nAvoiding Intellectual property conflict: As data becomes more and more important, the safety dataset may have conflicts of interests or be regulated by licenses. However, utilizing \"Self-defence\" can easily avoid them and generate data by the LLM itself.\nIn conclusion, while the direct translation of existing datasets is a viable approach, our method introduces flexibility, adaptability, and a way to circumvent potential legal issues. This makes it a valuable tool in the evolving landscape of AI safety.\nW6: Weak mitigation section, needs improved safety-usefulness balance\nThank you for your kind advice. We believe that more fine-grained instructions for data generation could lead to more detailed and comprehensive responses. This approach could prevent the model from merely learning to reject from the safety training data, thereby enhancing the model's ability to maintain high usefulness while ensuring safety. We are eager to explore this aspect further in our future research.\nRegarding a more nuanced understanding of the benefits of additional data, we present the unsafe decrease rate by language category as below:\nHRL\nMRL\nLRL\nunintentional\n3.60\n6.56\n8.57\nintentional\n13.86\n24.23\n24.66\nIn both scenarios under consideration, it's evident that LRL achieves the most significant improvement. This could potentially be attributed to its initially high rate of unsafe content, implying that even a small amount of training data can yield substantial gains.\nFurthermore, we observe that the intentional scenario demonstrates a more pronounced improvement compared to the unintentional one. This suggests a greater potential for enhancement to mitigate intentional jailbreak attack."}, {"Heading": "More discussion with Reviewer QBvZ", "Subheading": "Official CommentbyAuthors22 Nov 2023, 08:04Everyone", "Content": "Comment:\nDear Reviewer QBvZ:\nThanks so much for your valuable suggestion on:\nManuscript frame;\nError bar;\nDiversity;\nMore model evaluation;\nMethodology motivation;\nTrade-off analysis.\nWe have carefully responded to your feedback and conducted supplementary experiments to address your concerns. We are eagerly anticipating your response and thoughts on our new experiments as the deadline for discussion draws near.\nBest Regards,\nAuthors"}, {"Heading": "Thanks!", "Subheading": "Official CommentbyReviewer QBvZ22 Nov 2023, 14:43Everyone", "Content": "Comment:\nThank you for your detailed responses, and I especially appreciate the additional experimental results in the short time frame.    A few small clarifications:\nWith respect to W2:\nTo clarify, my question on diversity of attacks - it is not clear to me that an adversary would know a-priori which attacks are best, so understanding the breadth of attacks is valuable.\nFor error bars, changing the temperature does add uncertainty but my concern was with the error bars from a small sample (eg could be measured with bootstrap sampling)\nFor W3: Thanks for the breakdown.  While it would require a lot more work, it'd be nice to see results broken down by these tags (which of course requires more data per tag)\nOverall, I still believe the paper would be valuable to the community but also has room for improvement. As a result, I will keep my rating as is. Thank you."}, {"Heading": "Reply to Reviewer QBvZ", "Subheading": "Official CommentbyAuthors23 Nov 2023, 02:39Everyone", "Content": "Comment:\nDear Reviewer QBvZ,\nThank you for your response! We have addressed your concerns as follows:\nW2. Additional Attack\nRegarding more attacks:\nAs mentioned in footnote 4 on page 5, a \"Votes\" score exists that could potentially offer adversaries a basic understanding of which attacks are most effective.\nWe acknowledge the importance of incorporating a wider range of attacks into our analysis. Although our initial focus was primarily on the language level, we are keen to broaden our investigation scope in future research. Furthermore, there have been several studies evaluating general jailbreak methods, which may serve as useful references [1,2].\nRegarding error bars:\nThanks for your clarification! We will improve our manuscript to make our preliminary experiment more reliable.\nW3. Break down by tags\nWe have revised our manuscript and present the outcomes in Appendix Figure 8. It's evident that different languages exhibit varying levels of safety performance depending on the specific tag. For instance, posing queries about weapons in Bengali to ChatGPT demonstrates a notably higher unsafe rate compared to other languages. Similarly, when interacting with ChatGPT in Thai about substance abuse, the unsafe rate is significantly higher in comparison to other languages. These observations underline the potential vulnerabilities and biases intrinsic to each language within the model. Such findings emphasize the need for continuous improvements and targeted refinement in the model's safety capabilities across different languages.\nOverall, it was a nice discussion, and your valuable suggestions have helped us a lot to improve our manuscript. We deeply appreciate your time and effort. Thank you!\nBest Regards,\nAuthors\n[1] Deng et al, Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study,\nhttps://arxiv.org/abs/2305.13860\n[2] Wei et al, Jailbroken: How Does LLM Safety Training Fail?,\nhttps://arxiv.org/abs/2307.02483"}]}, {"Heading": "Official Review of Submission9250 by Reviewer imbS", "Subheading": "Official ReviewbyReviewer imbS31 Oct 2023, 16:57 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper shows that the safeguard ChatGPT and GPT-4 are not robust for non-English languages, especially low resource languages. By translating curated harmful prompts in English and translating them into 9 other languages, the paper shows the increase of unsafe rates in the responses of LLMs. To this end, the paper proposes a self-defence method that generates finetuning data for chatGPT and a tuned version of chatGPT on this data exhibits a lower unsafe rate.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe methodology of collecting harmful prompts, running human translation, and using human evaluation for the 15 harmful prompts in the preliminary results. I also like the approach of using jailbreakchat.com for collecting intentional jailbreak prompts.\nOverall, the paper is well motivated and covers interesting analysis such as the translation quality, jailbreak languages, the trade off between safeness and usefulness.\nWeaknesses:\nLack of details of the self-defence algorithm. What are the seed samples and what is the percentage of unsafe samples generated by chatGPT that are actually unsafe if it is prompted to chatGPT to get the answer?\nHow wide-coverage in terms of topics, scenarios,...of the data that the self-defence algorithm can generate? While it\u2019s good to show some improvement when evaluated on \tMultiJail testset, I think self-defence just scratches the surface of the problem.\nI generally think it\u2019s important to ensure safety for all the languages but it irks me about the argument about Bengali at the end of page 5th. Even though there are 285 million native speakers, how many of those are using chatGPT and could be affected by unsafe outputs?\nQuestions:\nSee the question in the above section.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 15:32Everyone", "Content": "Comment:\nWe greatly appreciate the time you dedicated to providing us with your valuable feedback. Your insights are highly valued, and please find our responses to the concerns you raised below:\nW1. Lack of details on self-defence algorithm\nThe seed examples utilized within our experiment are crafted by humans to simulate both unintentional and intentional scenarios. We supply no more than six seed examples in the generation process.\nWhen it comes to the generation of unsafe examples, we instruct the model with generating these in English. The model's strong proficiency in English and its robust safety capabilities within this language allow it to produce content that is genuinely unsafe. To ensure the validity of this process, we have each generated example manually reviewed and verified to confirm its unsafe content.\nW2. Unclear coverage of self-defence algorithm's data generation\nIn our current work, we have provided a set of general instructions for generating safety-related Q&A pairs without delving into specific topics or scenarios. However, our \"Self-Defense\" method is flexible and can be easily expanded to more advanced approaches.\nAs an example, we might supply the LLMs with several pre-defined safety topics, or even enable the model to generate these topics by themself. For each distinct topic, we could gather or generate relevant seed examples, and adjust the instructions to match the topic accordingly.\nWhile the current focus is on this immediate concern, our future work aims to refine and enhance the \"Self-Defense\" methodology, thereby improving its effectiveness and efficiency in addressing multilingual jailbreak challenges.\nW3. Questioning relevance of safety measures for low-use languages like Bengali\nThank you for your valuable input. We totally agree that the number of native speakers doesn't necessarily imply a significant impact on the usage of ChatGPT. However, our mention of Bengali aimed to highlight safety issues in low-resource languages, which refers to the scarcity of available digital training data, not the speaker count.\nDespite being a low-resource language in AI training, Bengali is the 6th most spoken language worldwide with 285 million native speakers [1]. This significant speaker base often gets overlooked in AI safety considerations, which typically focus on languages with abundant digital resources.\nWhile Bengali-speaking ChatGPT users may be a small fraction of the total user base, it's crucial to note that Bengali is one among many low-resource languages. Cumulatively, these languages represent a substantial user base, emphasizing the need for dedicated safety measures.\nThus, our discussion extends beyond Bengali to all low-resource languages, many with large speaker populations. We'll clarify this in future discussions and appreciate your insights in improving our communication.\n[1] List of languages by number of native speakers,\nhttps://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers"}, {"Heading": "More discussion with Reviewer imbS", "Subheading": "Official CommentbyAuthors22 Nov 2023, 08:05Everyone", "Content": "Comment:\nDeaer Reviewer imbS:\nWe appreciate you taking the time to review our work and your insightful feedback. We would like to discuss this further with you to see if there are any unresolved questions. Specifically, we have addressed your concerns on the following points.\nMore details on Self-Defence;\nDiscussion on coverage of Self-Defence;\nRelevance for low-resource languages.\nIf you have any further concerns, please let us know.\nBest Regards,\nAuthors"}]}, {"Heading": "Official Review of Submission9250 by Reviewer WaDP", "Subheading": "Official ReviewbyReviewer WaDP31 Oct 2023, 14:22 (modified: 23 Nov 2023, 01:47)EveryoneRevisions", "Content": "Summary:\nIn this paper, the authors identify some of the challenges regarding the presence of multilingual jailbreak in two different scenarios: intentional and unintentional. Moreover, they introduce a multilingual jailbreak dataset, analyze the effects of language as a jailbreak method, and show that medium and low-resource languages are more likely to generate unsafe content compared to high-resource ones. Finally, they propose a framework called SELF-DEFENCE, which starts from a set of English seed input-output pairs, including both unsafe and general examples, and augments the dataset using the LLM and these seed examples. Then, it uses the LLM to translate the instruction pairs into multiple target languages and merges these language-specific corpora to form the final training dataset for fine-tuning. Finally, the authors use the fine-tuning access for ChatGPT to evaluate the effectiveness of their framework. Their results show improvements in the multilingual safety capabilities of LLMs.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe authors introduce a multilingual jailbreak dataset called MultiJail, which they claim is the first multilingual jailbreak dataset. The process involves incorporating native speakers for human translations in order to prevent noisy translation.\nSection 3 provides a detailed evaluation of the multilingual safety challenges of ChatGPT and GPT-4 and provides insight into the effects of language in two cases, intentional and unintentional.\nWeaknesses:\nThe data generated for finetuning is mostly generated by the LLM itself (except for the small number of seed examples). While this makes the data generation easier and cheaper, I assume the translations by the LLM for the low-resource languages are still very noisy and might be the reason why usefulness reduces significantly as the safeness metric increases. The authors mention that a potential reason for this decrease in general capability can be attributed to the fact that LLM rejects to answer unsafe questions. In that case, it would be useful to have a numerical comparison between the cases that get low usefulness scores because of this issue and the cases that fail due to noisy translations. As the authors mention, it would be useful to include a brief explanation of why the question is unsafe to ensure the problem is not, in fact, due to noisy translations of the low-resource language by the LLM.\nIn my opinion, the SELF-DEFENCE framework lacks novelty. It simply implies that providing more training samples for lower resource languages can improve LLM's understanding of them, and as we include samples translated to these languages during the fine-tuning stage, the model becomes safer with respect to them.\nThere is no information on the effectiveness of the SELF-DEFENCE framework compared to any other safety improvement techniques mentioned in the related work section.\nQuestions:\nHow does the SELF-DEFENCE framework perform compared to other safety improvement methods, such as RLHF?\nFor low-resource languages, where the LLM's understanding of the language is limited, how reliable are their LLM-generated translations?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 16:29Everyone", "Content": "Comment:\nThank you so much for taking the time to share your valuable feedback with us. We truly appreciate your insights, and please find below our responses to your concerns:\nW1. Noisy translations by LLM may reduce usefulness\nThank you for pointing this out. Yes, we agree with you that noisy translation may be another cause for usefulness reduction. To verify this assumption, we replaced the translation component in SELF-DEFENCE to Goolge Translate, which is believed to perform better than ChatGPT on machine translation [1].  The results are presented as below:\nSafeness\nUsefulness\nSELF-DEFENCE\n63.50\n41.39\nGoogle-Translate\n64.50\n44.44\nWith better translation quality, both safeness and usefulness have gained improvement, especially for usefulness. We have modified our paper accordingly to point this factor out.\nHowever, we believe a less comprehensive safety Q&A  would also be an important factor, as the trade-off is also observed even in English-only evaluation [2].\nIn conclusion,  the quality of generated content plays a crucial role, both in terms of language-wise and the content itself. In our future research, we aim to delve into the enhancement of the quality of data generated by Self-Defence framework. Again, thank you very much for your valuable feedback.\nW2. SELF-DEFENCE framework lacks novelty\nWe think providing more training examples for low-resource languages can improve LLM's multilingual safety capabilities. However, our proposed method can be helpful in the following scenarios:\nData augmentation: Our method provides a way to quickly augment a large multilingual safety dataset to address the challenge effectively and efficiently.\nFine-grained generation: If a new safety topic is introduced, or the safety guideline is changed, or a new language is added, we can simply edit the seed example and instruction in the \"Self-defense\" framework to adapt accordingly.\nData imbalance: Safety datasets may have uneven topic distribution. The \"Self-Defense\" framework can address this by generating data for underrepresented topics using specific seed examples and instructions.\nAvoiding intellectual property conflict: As data becomes more and more important, the safety dataset may have conflicts of interest or be regulated by licenses. However, utilizing \"Self-defense\" can easily avoid them and generate data by the LLM itself.\nIn conclusion, while directly augmenting existing datasets with non-English data is a viable approach, our method introduces flexibility, adaptability, and a way to circumvent potential legal issues. This makes it a valuable tool in the evolving landscape of AI safety.\nW3. No comparison of SELF-DEFENCE with other safety improvement techniques\nThank you for your feedback. It's important to note that our proposed SELF-DEFENCE framework should be viewed as complementary, rather than directly comparable, to existing safety improvement techniques such as SFT and RLHF. Unlike these methods which focus on safety improvement through training algorithm design, the SELF-DEFENCE approach primarily serves to augment multilingual safety datasets. Our approach can be combined with other safety improvement techniques for more comprehensive results. In fact, during our experimentation, we employed the SFT method to exploit the augmented dataset provided by our SELF-DEFENCE framework for safety training.\nFor comparison, we conducted another experiment using English-only data, which is the most common language in safety tuning, as a baseline. The following table presents the experimental results:\nSafeness\nUsefulness\nSELF-DEFENCE\n63.50\n41.39\nEnglish-only\n60.67\n37.78\nAs the results show, SELF-DEFENSE can not only improve multilingual safety capability, but the multilingual usefulness is also maintained. The results demonstrated the effectiveness of our proposed framework.\nQ1. Performance of SELF-DEFENCE vs other safety improvement methods\nWe have addressed this concern in W3.\nQ2. Reliability of LLM-generated translations for low-resource languages\nWe have addressed this concern in W1.\n[1] Jiao et al, Is ChatGPT A Good Translator? Yes With GPT-4 As The Engine,\nhttps://arxiv.org/abs/2301.08745\n[2] Bai et al, Training a helpful and harmless assistant with reinforcement learning from human feedback,\nhttps://arxiv.org/abs/2204.05862"}, {"Heading": "More discussion with Reviewer WaDP", "Subheading": "Official CommentbyAuthors22 Nov 2023, 08:06Everyone", "Content": "Comment:\nDear Reviewer WaDP,\nWe thank you for the time spent reviewing our work and for your constructive comments. We sincerely hope to have further discussions with you to see if our responses address your concerns.\nSpecifically, in our response, we have:\nClarified how noisy translation affects our work;\nPresented the novelty of our Self-Defence method;\nCompared our work to other techniques.\nWe genuinely hope you will review our responses. Thank you!\nBest Regards,\nAuthors"}, {"Heading": "Official Comment by Reviewer WaDP", "Subheading": "Official CommentbyReviewer WaDP23 Nov 2023, 01:50Everyone", "Content": "Comment:\nThank you for providing such detailed explanations and additional experiments. I have changed my overall score to 6."}]}]}, "DZ6B5u4vfe": {"paper_info": {"Primary Area": "applications to neuroscience & cognitive science", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "large language models, instruction-tuning, world knowledge, neuroscience, neuroAI", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "This paper explores how instruction-tuning affects language models from a neuroscientific perspective, revealing that it generally improves their alignment with human brain activity, with model size and world knowledge playing key roles.", "Abstract": "Instruction-tuning is a widely adopted method of finetuning that enables large language models (LLMs) to generate output that more closely resembles human responses to natural language queries, in many cases leading to human-level performance on diverse testbeds. However, it remains unclear whether instruction-tuning truly makes LLMs more similar to how humans process language. We investigate the effect of instruction-tuning on LLM-human similarity in two ways: (1) brain alignment, the similarity of LLM internal representations to neural activity in the human language system, and (2) behavioral alignment, the similarity of LLM and human behavior on a reading task. We assess 25 vanilla and instruction-tuned LLMs across three datasets involving humans reading naturalistic stories and sentences, and discover that instruction-tuning generally enhances brain alignment by an average of 6%, but does not have a similar effect on behavioral alignment. To identify the factors underlying LLM-brain alignment, we compute the correlation between the brain alignment of LLMs and various model properties, such as model size, performance ability on problem-solving benchmarks, and ability on benchmarks requiring world knowledge spanning various domains. Notably, we find a strong positive correlation between brain alignment and model size (r = 0.95), as well as performance on tasks requiring world knowledge (r = 0.81). Our results suggest that making world knowledge in LLMs more accessible via instruction-tuning also yields neural representations more similar to those of the human language system.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9249", "PDF Url": "https://openreview.net/pdf?id=DZ6B5u4vfe"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9249 by Area Chair YcG5", "Subheading": "Meta ReviewbyArea Chair YcG512 Dec 2023, 07:14 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nIn this paper, the authors study the effect of instruction-tuning on the alignment between LLMs\u2019 representations and human language processing. Two types of human data, including brain activity patterns (brain alignment) and reading times (behavioral alignment), are investigated. Experiments across 25 vanilla and finetuned models from the T5 and LLaMA families show that instruction turned LLMs achieve higher brain scores than vanilla LLMs, world knowledge and model size are correlated with brain alignment, and instruction-tuning is not correlated with behavioral alignment. The analysis from neuroscience perspective is interesting and valuable.\nModels from just two families, T5 and LLaMA, are used, and the results on LLaMA do not show significant correlation.  The authors should use a few more models from the GPT family to make the results more convincing. In addition, the presentation of the paper should be significantly improved, including a clearer description of the contribution/novelty and a clearer intro of related neuroscience background.\nJustification For Why Not Higher Score:\nModels from just two families, T5 and LLaMA, are used, and the results on LLaMA do not show significant correlation.  The authors should use a few more models from the GPT family to make the results more convincing. In addition, the presentation of the paper should be significantly improved, including a clearer description of the contribution/novelty and a clearer intro of related neuroscience background.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9249 by Reviewer co7p", "Subheading": "Official ReviewbyReviewer co7p05 Nov 2023, 22:57 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper investigates the correlation between instruction-tuned LLMs and human similarity in the field of neuroscience by examining brain alignment and behavioral alignment. The authors evaluate 25 LLMs on a reading task to identify the effects of instruction tuning LLMs in terms of human language processing. Instruction turned LLMs have higher brain scores than vanilla LLMs, and further analyzed the properties of LLMs that contribute high alignment and found out that the model size and world knowledge are correlated to brain alignments. For the behavioral alignment, there was no correlation between per-word LLM perplexity and per-word human reading times.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n1 poor\nStrengths:\nThis paper explains why instruction-tuned LLMs perform better than vanilla LLMs from a neuroscience perspective by measuring brain scores.\nWeaknesses:\nThis paper appears to be a replication of [1,2], specifically focusing on instruction-tuned models. It lacks novelty and originality.\nIncreasing the model size and integrating world knowledge (using a larger training dataset) are not surprising new discoveries for improving language modeling.\nAdditionally, this paper measures the correlation between world knowledge tasks and brain alignment.\nThis paper should demonstrate the effects of contributing factors separately (world knowledge and model size). The plots seem to be dependent on model size.\nThe current version of the paper requires further improvement.\nIt lacks details for readers without a background in neuroscience.\nHow is the brain score computed for each model? Does it compute the hidden state of every layer?\nIn Section 4.1, the last paragraph seems to be located too early, making it difficult to understand before explaining the dataset.\nIn Figure 3A, shouldn't the language stimuli be labeled as Futrell2018?\nFigure 3B appears to be an empty plot.\n[1] Schrimpf, Martin, et al. \"The neural architecture of language: Integrative modeling converges on predictive processing.\"\nProceedings of the National Academy of Sciences\n118.45 (2021): e2105646118.\n[2] Oh, Byung-Doh, and William Schuler. \"Why does surprisal from larger transformer-based language models provide a poorer fit to human reading times?.\"\nTransactions of the Association for Computational Linguistics\n11 (2023): 336-350.\nQuestions:\nHow is the 'No Instruction' model trained in Figure 1D? The Alpaca instruction dataset is formed with both non-empty input fields (instruction, input, output) and empty input fields (instruction, output). Did you only use non-empty input fields and remove the instruction in those cases?\nWhat aspect do you believe instruction tuning contributes to the correlation between world knowledge and brain alignment?\nIn Figure 2, it appears that there are different correlations for each dataset (Pereira2018, Blank2014, and Wehbe2014). Why is Blank2014's correlation so much lower compared to the other two?\nHow is word perplexity measured? Could you provide an example of input and the corresponding NWP loss?\nSince Flan-T5 models are encoder-decoder models, I'm not sure how they are measured differently from decoder-only models. Were the same inputs passed into both the encoder and the decoder?\nDid the vanilla LLMs also show no correlation?\nWhy is there a performance drop when Flan-T5 is fine-tuned on instruction tuning datasets (Alpaca, GPT4ALL, ShareGPT) as seen in Table 5 (Flan-T5-XL results)?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:45Everyone", "Content": "Comment:\nWe are happy that the reviewer appreciated our neuroscientific analysis of instruction-tuning. Based on their feedback, we ran additional experiments and improved our paper\u2019s clarity. We respond to their points below:\nQ1: This paper appears to be a replication of [1,2], specifically focusing on instruction-tuned models. It lacks novelty and originality.\nOur work presents many new insights for researchers studying the parallels between LLMs and human brains: (a) Instruction-tuning aligns LLM representations to human brain activity, and (b) World knowledge is a key factor underlying this alignment. These are both new directions of study that produced new insights. Hence, our work is different from both [1] and [2], which focus on studying how the next-word prediction surprisal of language models relates to human brain activity and behavior.\n[1] Schrimpf, Martin, et al. \"The neural architecture of language: Integrative modeling \u2026\u201d\n[2] Oh, Byung-Doh, and William Schuler. \"Why does surprisal from larger transformer-based language models provide a poorer fit to human reading times?.\"\nQ2: Increasing the model size and integrating world knowledge (using a larger training dataset) are not surprising new discoveries for improving language modeling.\nOur paper is not focused on discovering new methods for improving language modeling. Rather, our paper focuses on evaluating the representational and behavioral similarity of LLMs to the human language system. In particular, we investigate how instruction-tuning affects LLMs from a neuroscientific perspective and the key factors underlying brain-LLM alignment (e.g., world knowledge and model size).\nQ3: The plots of world knowledge (against brain alignment)  seem to be dependent on model size.\nOur work shows that larger LLMs are more aligned to the brain. However, we wish to find out why. What aspects of larger LLMs make them more brain-aligned? Some possibilities: (1) greater world knowledge, (2) better problem-solving abilities, (3) better next-word prediction ability. Our work conducts further experiments to identify the underlying properties of LLMs (beyond model size) that contribute towards greater brain alignment. We show that world knowledge is a key determinant of brain alignment, more than other tested factors.\nTo show that the plots of world knowledge are not dependent on model size, we wish to highlight that smaller models instruction-tuned to gain greater capabilities (e.g., Vicuna-13B) can achieve greater brain alignment scores than larger models before instruction-tuning (e.g., LLaMA-33B). For reference, here are the average brain alignment values of the models: LLaMA-13B = 0.220, Vicuna-13B = 0.229, LLaMA-33B = 0.227, and Vicuna-33B = 0.232. The Vicuna-13B model has greater brain alignment than LLaMA-33B although it is less than 40% the size. We observe a similar trend when looking at another set of four models: T5-base, Flan-T5-base, T5-large, Flan-T5-large.\nTo further demonstrate that model size alone does not determine the brain alignment of an LLM, we ran new experiments to evaluate the brain alignment of a randomly-initialized LLaMA-7B. It is a large model with 7B parameters. The randomly-initialized LLaMA was not trained on any data and hence does not contain world knowledge. It also achieves roughly zero accuracy on the BBH and MMLU benchmarks. We observe that the randomly-initialized model achieves lower brain alignment than the trained LLaMA and instruction-tuned Alpaca-7B version. Prior works have also shown that large random embedding models do not achieve high brain alignment scores [1]. These results demonstrate that there are LLM properties aside from model size that contribute significantly to brain alignment.\n[1] Schrimpf, Martin, et al. \"The neural architecture of language: Integrative modeling \u2026\u201d\nQ4: How is the 'No Instruction' model trained in Figure 1D? Did we use all the training data from the Alpaca dataset?\nWe used all provided training samples from the Alpaca dataset. This is to ensure that the ablation model is trained on the same data as the instruction-tuned Alpaca-7B, with the only difference that the ablation model does not receive the \u201cinstruction\u201d portion during training. We added this clarification (that we use all the provided training samples) to our paper.\nQ5: Additional details about our experiment methods\nWe thank the reviewer for pointing out areas that require additional clarifications. We have improved our paper\u2019s clarity by adding details on the methods used for computing brain alignment, measuring next-word prediction loss, and running our ablation experiments."}]}, {"Heading": "Official Review of Submission9249 by Reviewer fAu2", "Subheading": "Official ReviewbyReviewer fAu201 Nov 2023, 07:30 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper investigates the effect of instruction-tuning in the alignment between LLMs\u2019 representations and human language processing. The authors use two types of human data: brain activity patterns (brain alignment) and reading times (behavioral alignment). The brain alignment is defined as the extent to which a linear regression model predicts brain activity patterns using the LLMs\u2019 representations. The behavioral alignment is defined as a correlation between LLM perplexity and human reading time for each word. Through the experiments across 25 vanilla and finetuned models from the T5 and LLaMA families, the authors conclude that instruction tuning improves brain alignment, (2) the performance on the world knowledge-related tasks and model size are correlated with brain alignment, and (3) instruction-tuning and other examined factors are not correlated with behavioral alignment.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nUsing 25 models and two benchmarking datasets covering various task categories, the authors perform detailed analysis between LLM representations and human brain and behavioral data.\nThe discussion includes implications both for NLP and neurosciences along with the literature review, which can encourage interdisciplinary research across both fields.\nThe paper is well-written and easy to follow.\nWeaknesses:\nThe authors use models from just two families, T5 and LLaMA. Looking at Figure 2, it seems that LLaMA models do not show a significant correlation between brain alignment and MMLU score, BBH world knowledge, and model size. The results would be more convincing if the authors could use a few more families such as GPT.\nConcerning the tasks related to world knowledge, it appears that these tasks may simply exhibit greater linguistic diversity compared to the other tasks examined. The concept of world knowledge seems somewhat ambiguous, and any clarification could be insightful. For instance, would similar results be observed if more language understanding tasks were added? I was unable to determine how the BBH tasks are categorized into \"language understanding\" and \"world knowledge.\"\nI think that expanding the experiments to address these points could lead to more reliable results.\nQuestions:\nHow did the authors determine the category classification for the BBH tasks?\nIs it possible to provide a more detailed analysis regarding world knowledge? Any discussion and additional analysis would be appreciated.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:48Everyone", "Content": "Comment:\nWe are happy the reviewer found that (1) our analyses were detailed, (2) our results had implications for both NLP and neuroscience, and that (3) our paper was well-written and easy to follow. We respond to their points below and improve our paper based on their feedback:\nQ1: The authors use models from just two families, T5 and LLaMA.\nIn our work, we evaluate the correlation of brain alignment to other LLM properties, such as world knowledge (MMLU) and problem-solving abilities (BBH). We agree with the reviewer that adding a greater variety of models would strengthen the generalizability of our claims.\nHowever, we realized that the performance on these benchmarks is affected not only by the quantity of knowledge that the models possess, but also by their ability to follow the instruction format of MMLU and BBH. (This point was also mentioned by reviewer WxVH.)\nHence, we restricted our selection of LLMs to only two model families. In each model family, the models are trained on a similar format of instruction data, so they have similar ability to follow the instruction format of MMLU and BBH. Thus, any differences in their MMLU or BBH performance would point to differences in the quantity of knowledge they possess, rather than their ability to follow the instruction format of MMLU or BBH.\nIf we selected LLMs from many different model families, it would be difficult to control for their ability to follow the instruction format of MMLU and BBH, as they are trained on vastly different instruction formats. This would make it challenging to use their MMLU and BBH results to suggest the quantity of knowledge that the models possess.\nHowever, we overall agree with the reviewer that greater model variety would strengthen generalizability, so we added it to our paper\u2019s section on limitations and future work.\nQ2: How did the authors determine the category classification for the BBH tasks?\nWe use the same category classification as the original BBH paper. The BBH paper categorizes tasks into four categories: (1) Algorithmic and Multi-Step Arithmetic Reasoning, (2) Natural Language Understanding, (3) Use of World Knowledge, and (4) Multilingual Knowledge and Reasoning. We add this clarification to our paper.\nBBH paper:\nM. Suzgun et al., \u201cChallenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them.\u201d\nQ3: Is it possible to provide a more detailed analysis regarding world knowledge? Any discussion and additional analysis would be appreciated.\nFor both MMLU and BBH, we follow their respective papers for how they categorized the world knowledge tasks.\nThe MMLU paper describes that they design the benchmark to measure knowledge from many domains. It contains 57 tasks, categorized by the subject domain of world knowledge tested: STEM, Humanities, Social Sciences, and Others. The STEM category includes questions on computer science, physics, mathematics, etc. The Humanities category includes questions on philosophy, law, history, etc. The Social Sciences category includes questions on politics, sociology, economics, geography, etc. The Others category includes questions on business topics such as finance, accounting, as well as general knowledge of global facts.\nThe world knowledge category of BBH contains tasks that test for factual and general knowledge. Tasks requiring factual knowledge include: \u201cSports Understanding\u201d and \u201cMovie Recommendation\u201d. Tasks requiring general knowledge include: \u201cCausal Judgement\u201d, which tests knowledge about causal-reasoning suppositions, and \u201cRuin Names\u201d, which requires knowledge about human perception and usage of humor in the English language."}]}, {"Heading": "Official Review of Submission9249 by Reviewer KJEe", "Subheading": "Official ReviewbyReviewer KJEe01 Nov 2023, 07:23 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper explores the impact of instruction-tuning on large language models (LLMs) to determine their alignment with the human brain in terms of brain and behavioral alignment. Experimental results from two renowned LLM families indicate that instruction-tuning improves brain alignment by 6.2%, with world knowledge and model size being the primary contributors. However, instruction-tuning does not have a similar effect on behavioral alignment. The authors emphasize the importance of integrating world knowledge in future LLM developments.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThis paper focuses on the instruction tuning of LLMs, exploring the neuroscience behind language models. This unique perspective advances the understanding of LLMs in the context of human cognition.\nThe experiment design is intuitive and relatively easy to follow. The experiments are extensive, including 3 datasets for brain and behavioral alignment, respectively.\nWeaknesses:\nLack of comparative analysis with other tuning techniques such as reinforcement learning from human feedback (RLHF).\nThe investigation of behavioral alignment is limited. A more comprehensive exploration could offer insights into the discrepancy between brain and behavioral alignments and its implications for LLM development and application.\nOther alignment measure methods may be considered to increase the reliability of the results, such as:\nJiaang, Li, et al. \"Structural Similarities Between Language Models and Neural Response Measurements.\" arXiv preprint arXiv:2306.01930 (2023).\nLiu, Xu, et al. \"Coupling Artificial Neurons in BERT and Biological Neurons in the Human Brain.\" arXiv preprint arXiv:2303.14871 (2023).\nQuestions:\nWhat is the computational cost of this study? 33B model is quite large, are there any quantization techniques used like LoRA?\nMay need proofreading: Table 3 and Table 4 in the Appendix have the same caption.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:52Everyone", "Content": "Comment:\nWe are happy that the reviewer thinks (1) our paper presents a unique neuroscientific perspective for understanding LLMs, (2) our experiment design is intuitive and easy to follow, and (3) our experiments are extensive. We respond to their points below and improve our paper based on their feedback:\nQ1: Lack of comparative analysis with other tuning techniques such as reinforcement learning from human feedback (RLHF).\nRLHF is often performed\nafter\nthe instruction-tuning phase. Hence, we did not consider it as a comparable alternative to instruction-tuning. In order to perform a comparative analysis between RLHF and instruction-tuning, as suggested by the reviewer, we would need to find LLMs trained with RLHF\ninstead of\ninstruction-tuning. Ideally, both LLMs should be trained on the same amount of training data and compute, to allow for a fair comparison. These LLMs also need to be open-source, in order to evaluate their brain alignment. Unfortunately, we could not find such LLMs.\nWe believe that investigating how RLHF affects the brain alignment of instruction-tuned LLMs constitutes future work. RLHF explicitly aims to align LLMs using human feedback. It would be an interesting direction to see if it also aligns LLMs to human brain activity (brain alignment) and behavior (behavioral alignment).\nQ2: The investigation of behavioral alignment is limited. A more comprehensive exploration could offer insights into the discrepancy between brain and behavioral alignments and its implications for LLM development and application.\nWe agree with the reviewer\u2019s point. Hence, we mentioned this in our original submission (and keep it in our rebuttal version too). We included a paragraph in the discussion section 6.2, where we argue for the need to examine more dimensions of behavior. We mention that our work and many prior works compare LM and human next-word surprisal on reading tasks as a measure of behavioral alignment. However, this evaluates only a single dimension of LM and human behavior (per-word perplexity and reading times). We highlight the need to create more benchmarks to expand the dimensions of behavior examined for both LLMs and humans, in order to holistically evaluate LLM behavior, as well as LLM-human behavioral alignment.\nHence, we focus instead on the brain alignment of LLMs.  Our paper focuses on investigating how instruction-tuning affects LLMs from a neuroscientific perspective and the key factors underlying brain-LLM alignment (e.g., world knowledge).\nQ3: 33B model is quite large, are there any quantization techniques used like LoRA?\nFor the 33B models, we only performed inference, not training. Hence, LoRA was not used. All our evaluations involve only model inference. This includes the brain alignment evaluations (Pereira2018, Blank2014, Wehbe2014), behavioral alignment evaluations (Futrell2018), and the evaluation of world knowledge (MMLU) and problem-solving abilities (BBH). These evaluations do not involve model training."}]}, {"Heading": "Official Review of Submission9249 by Reviewer WxVH", "Subheading": "Official ReviewbyReviewer WxVH01 Nov 2023, 05:29 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents a study about the relation between LLMs and humans. The motivation is that the instruction-tuned LLMs carry out human instructions better (seems closer to humans). Analysis on both brain activities  shows a closer alignment from LLMs after instruction tuning. The authors also found that the world knowledge and model size are strongly correlated with brain alignment.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe authors examined two famous and commonly used families of instruction tuned models and find a consistent phenomenon. They also observed the gradual increase in brain score during instruction tuning.\nThe authors studied the models\u2019 fit to both human neural and behavioral data.\nWeaknesses:\nIt remains unclear in the whole passage that which \u201cinternal representations\u201d from LLMs are used, which makes it difficult to reproduce the results.\nThe \u201cworld knowledge\u201d part in the BBH dataset is different from the knowledge required in MMLU. The formal consists subsets such as Sports Understanding, Movie Recommendation, and Causal Judgement; While the latter is mainly about disciplinary knowledge such as Anatomy and College Physics. This makes the key term, \u201cworld knowledge\u201d, much ambiguous. What knowledge are considered \u201cworld knowledge\u201d? Are there any difference between factual, general and disciplinary knowledge?\nThe authors tried to study the effect of world knowledge and model size separately in Section 4.2. However, the two factors are deeply intertwined, given that larger LLMs tend to outperform smaller ones in knowledge-related question answering. The results in Figure 2 also show that model size has even stronger and more significant effect on the brain score. As a result, it cannot be concluded that \u201cworld knowledge\u201d is a key contributor to the increase in brain score. Instead, it can be just another indirect effect of the larger model size.\nThe authors use the performance on MMLU and BBH to represent the models\u2019 capability of \u201cworld knowledge\u201d. However, performance on these benchmarks is affected not only by the quantity of knowledge that the models possess, but also by their ability to follow instructions. Thus, a higher performance on MMLU and BBH doesn\u2019t necessarily mean that the model has more world knowledge, and the correlation between benchmark scores and brain scores does not necessarily show a link between world knowledge and the fit to human neural data.\nThe authors use the correlation between model per-token perplexity and human reading time to represent the behavioral fit. However, they pointed out in Section 6.2 that this approach is controversial when applied to large Transformer-based models. Thus, the choice of this approach is confusing. Why not use other ways to test the behavioral fit?\nIt is counter-intuitive that factual, domain knowledge can contribute the higher human fit in general reading. In fact, many questions in MMLU are difficult even for most people (e.g., Anatomy, Astronomy, College Physics, ...), and are not going to be retrieved during story reading. It is confusing why the authors choose MMLU as an aspect of the \u201cworld knowledge\u201d, and how this can guide Neuroscience research in human language understanding.\nThe three fMRI datasets are in different settings, i.e., reading sentence by sentence, listening the whole passage, and reading word by word, which could bring different activation patterns in the human brain. However, the authors did not discuss the difference between them.\nQuestions:\nSee the weaknesses part.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:55Everyone", "Content": "Comment:\nWe are happy that the reviewer appreciated that (1) our experiments examine commonly-used model families, and that (2) our results are consistent. Based on their feedback, we ran additional experiments and improved our paper\u2019s clarity. We respond to their points below:\nQ1: The authors tried to study the effect of world knowledge and model size separately in Section 4.2. However, the two factors are deeply intertwined.\nOur work shows that larger LLMs are more aligned to the brain. However, we wish to find out why. What aspects of larger LLMs make them more brain-aligned? Some possibilities: (1) greater world knowledge, (2) better problem-solving abilities, (3) better next-word prediction ability. Our work conducts further experiments to identify the underlying properties of LLMs (beyond model size) that contribute towards greater brain alignment. We show that world knowledge is a key determinant of brain alignment, more than other tested factors.\nTo show that the plots of world knowledge are not dependent on model size, we wish to highlight that smaller models instruction-tuned to gain greater capabilities (e.g., Vicuna-13B) can achieve greater brain alignment scores than larger models before instruction-tuning (e.g., LLaMA-33B). For reference, here are the average brain alignment values of the models: LLaMA-13B = 0.220, Vicuna-13B = 0.229, LLaMA-33B = 0.227, and Vicuna-33B = 0.232. The Vicuna-13B model has greater brain alignment than LLaMA-33B although it is less than 40% the size. We observe a similar trend when looking at another set of four models: T5-base, Flan-T5-base, T5-large, Flan-T5-large.\nTo further demonstrate that model size alone does not determine the brain alignment of an LLM, we ran new experiments to evaluate the brain alignment of a randomly-initialized LLaMA-7B. It is a large model with 7B parameters. The randomly-initialized LLaMA was not trained on any data and hence does not contain world knowledge. It also achieves roughly zero accuracy on the BBH and MMLU benchmarks. We observe that the randomly-initialized model achieves lower brain alignment than the trained LLaMA and instruction-tuned Alpaca-7B version. Prior works have also shown that large random embedding models do not achieve high brain alignment scores [1]. These results demonstrate that there are LLM properties aside from model size that contribute significantly to brain alignment.\n[1] Schrimpf, Martin, et al. \"The neural architecture of language: Integrative modeling \u2026\u201d\nQ2: The authors use the performance on MMLU and BBH to represent the models\u2019 capability of \u201cworld knowledge\u201d. However, performance on these benchmarks is affected not only by the quantity of knowledge that the models possess, but also by their ability to follow instructions.\nWe agree with the reviewer. Hence, we restricted our selection of LLMs to only two model families. In each model family, the models are trained on a similar format of instruction data, so they have similar ability to follow the instruction format of MMLU and BBH. Thus, any differences in their MMLU or BBH performance would point to differences in the quantity of knowledge they possess, rather than their ability to follow the instruction format of MMLU or BBH.\nQ3: Additional details about our experiment methods\nWe thank the reviewer for pointing out areas that require additional clarifications. We have improved our paper\u2019s clarity by adding details on which layers were used to evaluate brain alignment, and the types of world knowledge in BBH and MMLU."}]}]}, "RIaIpdUCPb": {"paper_info": {"Keywords": "Represention Learning, Compositional Generalization.", "Abstract": "Compositional Generalization (CG), referring as the generalization ability to new combinations of essential concepts, is thought to be one mechanism underlying human\u2019s remarkable capability of rapid generalization to new knowledge and tasks. Recent research on brain neural codes has found that the geometry structure of the neural representations is highly related to human compositional generalization ability. In this paper, we extend the above neural science observation into artificial neural networks (ANN) and find that the geometry structure of the representations in ANN impacts their compositional generalization. More importantly, we reveal that only good geometry structure is not sufficient for strong CG ability, a regularization is essential to ensure the classifier can fit the representation geometry structure. We propose a loss to optimize the representation extractor to form a well-organized representation space, and a regularization on the classifier to force it align with the geometry structure of representation space.  With our proposed methods, the CG performance gains as large as 43% on the synthetic and 63% on real-world datasets, verifying the effectiveness of our brain-inspired ANN-enhancing approach towards human-like strong generalization ability.", "Primary Area": "visualization or interpretation of learned representations", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9248", "PDF Url": "https://openreview.net/pdf?id=RIaIpdUCPb"}, "review_info": [{"Heading": "Official Review of Submission9248 by Reviewer VqBo", "Subheading": "Official ReviewbyReviewer VqBo06 Nov 2023, 01:14 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors introduce Parallelism Score (Bernardi et al 2020) in neural networks. It was found that networks trained to optimize Parallelism Score performed better in compositional generalization.\nSoundness:\n3 good\nPresentation:\n1 poor\nContribution:\n1 poor\nStrengths:\nThere seems to be consistent improvement with optimizing Parallelism Score.\nWeaknesses:\nThe paper is poorly written, very difficult to read. Needs major overhaul in writing.\nQuestions:\nN/A\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9248 by Reviewer FGTz", "Subheading": "Official ReviewbyReviewer FGTz30 Oct 2023, 18:51 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors propose to investigate the parallelism score of Bernardi et al. 2020 (a measure of representational geometry related to abstraction ability) in the context of artificial neural networks.\nTo do this, they define a parallelism score between the centroids of representations for each class with respect to different conditioners. They then validate this score by creating datasets with a variety of levels of parallelism (and variance) and measure the correlation of accuracy of downstream linear classifiers trained on these datasets with the known parallelism of the datasets. They indeed show that their metric is correlated with compositional generalization (accuracy on unseen combinations of inputs requiring abstract generatlization) on these synthetic datasets. Further, they test this correlation with a wide variety of pre-trained models, and three separate test datasets, again showing highly robust correlation, validating their metric.\nThey then introduce a version of their parallelism score which can be used as a regularization term, and prove that it is an unbiased estimator, allowing for robust optimization. They improve this regularization term with a sort of maximum margin loss they call \u2018distance variance\u2019 to avoid certain failure cases. Finally, they test models using this regularization term on four datasets: Shapes3D, PACS, Office-Home, and NICO. They show that their model achieves the highest accuracy on these datasets when compared to simple baselines, and further ablation experiments validate the positive impact of their additional terms.\nSoundness:\n3 good\nPresentation:\n1 poor\nContribution:\n3 good\nStrengths:\nThe paper addresses the issue of representational geometry from the exciting perspective of the parallelism score introduced by Bernardi et al.. This is a perspective which has to-date not been given significant attention in the machine learning community, however it has been demonstrated to be highly relevant in biological systems, and therefore the increased attention is very welcomed. Furthermore, this adds to the originality and significance of the paper.\nThe paper's methodology appears fairly rigorous and sound, where they perform a fairly extensive evaluation to validate that their proposed score correlates with generalization on both synthetic and real data with a suite of pretrained models and datasets.\nThe paper achieves the goal of improving compositional generalization through an induced parallelism (although the results on that front are quite limited).\nWeaknesses:\nThe writing of the paper is very poor, and there are many typos throughout. At this papers current stage, it is not fit for publication. The authors should carefully proofread the text and potentially request the assistance of others if necessary. If the authors fix this, then the remainder of the paper would be above the marginal acceptance threshold in my opinion.\nThe experiments which demonstrate the benefit of the proposed regularization term are quite limited and the paper would benefit from a expansion of this section of the paper as this appears to be the most impactful contribution.\nThere is no code released for the work.\nModel details and baselines should be explained in the main text not appendix. (Baselines are actually never defined as far as I can tell.)\nQuestions:\nCan the authors explain the negative correlation between PS-Class and PS-Domain again? I understand the models are trained to disregard domain-related features, but I would expect this leads to no correlation between PS and CG for domain, not negative correlation?\nCan the authors explain what the baseline models are for each experiment?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9248 by Reviewer p9Td", "Subheading": "Official ReviewbyReviewer p9Td30 Oct 2023, 15:04 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis submission proposes new objective functions to learn representations for compositional generalization. Some of the techniques were inspired by recent observations in neurophysiological observation in context-dependent decision making tasks.\nThere seems to be modest amount of innovation in this paper. The Introduction motivates the use of the parallelism score from neuroscience studies, but it turns out that incorporating this score to the training objective does not fix the problem. The authors thus additionally proposed a regularization based on \u201cminimal distance variances\u201d.\nWhile the results show some improvements, their significance is unclear.  In addition, the presentation and writing need major improvements.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThe attempt of using insights from neurobiology to constrain objective functions in machine learning is interesting.\nThe paper combines some theoretical reasoning with empirical evaluation.\nWeaknesses:\nThe study seems to be making some implicit assumptions about the underlying data structure that makes the parallelogram-like latent representation helpful for generalization.  It is unclear what these assumptions are.\nThe writing and presentation would need major improvements before this paper can be published.\nThe objective proposed seems to be conceptually similar to the ones proposed previously to do visual analogical reasoning (not cited in the paper), e.g., Reed, Scott E., et al. \"Deep visual analogy-making.\" Advances in neural information processing systems 28 (2015).\nQuestions:\nMany things could be improved. I would suggest to start with the improving the writing and presentation.\nHow well the model generalizes likely depends on the structure of the data. I feel that there is a lack of discussion on the underlying assumptions of the properties of the data distribution that would make the proposed geometrical configurations ideal for generalization.\nThe limitation of the approach should also be acknowledged.\nIt would be useful to discuss how the proposed method is different from the objectives functions in deep visual analogy-making as mentioned above.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9248 by Reviewer qK2u", "Subheading": "Official ReviewbyReviewer qK2u20 Oct 2023, 12:38 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper takes inspiration from neuroscience and how the human brain employs compositionality and attempts to translate this into the space of artificial neural networks. They propose a method called \u201cMinimal Distances Variance\u201d (MDV) which is a regularization technique whose goal is to guide a classifier towards a better organized representation space (that resembles the organization of representations in the human brain).\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n1 poor\nStrengths:\nFigure 1 looks cool. I appreciate the effort that the authors put into this Figure. It probably conveys their approach better than any of their written text.\nWeaknesses:\nWhat does \u201cConstrain on Representation\u201d in the title mean? Is there a typo here? While typos can generally happen, I think there should not be any typo in the title of a submitted conference paper.\nIn the Abstract, you mention \u201cneural representations\u201d in the second sentence. I am not sure I can follow. What does \u201cneural representations\u201d mean here? The representations of an artificial neural network? The representations in a human brain? This does not come across clearly. The term has to be defined before.\nI tried really hard reading this paper but it is incredibly poorly written. I cannot follow at most times.\nI am not really sure I understand what is going on here in general. I have never heard of CG, PS, or any of the datasets they evaluated their method on. Most settings seem to be contrived.\nOn page 6, the authors claim that \u201c[...], PS offers a potential approach to understanding deep neural networks, with mechanisms resembling those of the human brain, which may lead to more interpretable and transparent AI.\u201d I highly doubt that. It is not even clear to me how PS could help \u201cunderstand neural nets with mechanisms that resemble the human brain\u201d\nIn Figure 2, the standard deviations are incredibly large and overlap between their regularization technique and vanilla logistic regression. So, what this figure shows is that there is no difference between their method and logistic regression. I am not sure what else I should take away from this figure.\nWhat is the baseline? They compare their method against a baseline but it is unclear to me which method the baseline is. It does not seem to be explained anywhere. Is the baseline logistic regression? Or am I missing something crucial?\nQuestions:\nThis paper needs a major revision. The revision for it to become a high-quality paper that I am comfortable accepting to ICLR would take much more time than we all have during the rebuttal period.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n1: strong reject\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes"}]}, "i1bBVKRVb5": {"paper_info": {"Keywords": "instance segmentation, object detection", "Abstract": "In this paper, we aim to study how to build a strong instance segmenter with minimal training time and GPUs, as opposed to the majority of current approaches that pursue more accurate instance segmenter by building more advanced frameworks at the cost of longer training time and higher GPU requirements. To achieve this, we introduce a simple and general framework, termed Mask Frozen-DETR, which can convert any existing DETR-based object detection model into a powerful instance segmentation model. Our method only requires training an additional lightweight mask network that predicts instance masks within the bounding boxes given by a frozen DETR-based object detector. Remarkably, our method outperforms the state-of-the-art instance segmentation method Mask DINO in terms of performance on the COCO test-dev split (55.3% vs. 54.7%) while being over 10$\\times$ times faster to train. Furthermore, all of our experiments can be trained using only one Tesla V100 GPU with 16 GB of memory, demonstrating the significant efficiency of our proposed framework.", "Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9247", "PDF Url": "https://openreview.net/pdf?id=i1bBVKRVb5"}, "review_info": [{"Heading": "Official Review of Submission9247 by Reviewer kpyR", "Subheading": "Official ReviewbyReviewer kpyR02 Nov 2023, 01:47 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes Mask Frozen-DETR, an adapter architecture for instance segmentation. The main idea is to keep the original DETR-based detector frozen and only add a small number of parameters to adapt it to solve the instance segmentation (from object detection). Experiments are mainly conducted on COCO. Multiple DETR-based backbone detectors were used. Experimental results showed that the proposed method can achieve an AP comparable with current best method, i.e., Mask DINO, while reducing the training time by 10x. Written presentation is mostly clear and easy to follow.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThe idea of adapting DETR-based detectors for instance segmentation is interesting.\nThe main benefit of the proposed approach is an adapter architecture for instance segmentation (from DETR-based detectors) that can reach to state-of-the-art level of Average Precision after 6 training epochs, thus reducing the training time by 10x (compared with Mask DINO).\nVarious design choices and ablations to provide the readers good insights about the proposed architecture.\nWeaknesses:\nThe proposed adapter works only with DTER-based detectors.\nWritten presentation could be improved:\n(This may be subjective) The Fig 3,5,6, and 7 have many things in common, they can be grouped into a large figure to simplify the presentation and save space. Doing so may also help to simplify the technical section 3, making it shorter and simpler.\nFigure 4 is never been referred from text.\nIf more space is needed, ablation table 8, 9, 10 can report only the main metric of AP^{mask}.\nExperiments are done on only 1 dataset.\nQuestions:\nPlease address the questions in weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nN/A\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9247 by Reviewer Nd3w", "Subheading": "Official ReviewbyReviewer Nd3w31 Oct 2023, 21:11 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper introduces a framework called Mask Frozen-DETR for instance segmentation, which utilizes a frozen DETR-based object detector to generate bounding boxes and trains a mask head to produce instance segmentation masks. The proposed method achieves SOTA results on the COCO dataset while being over 10 times faster to train.\nThe authors propose improvements in three main aspects: image feature encoder design, box region feature encoder design, and query feature encoder design. These enhancements improve the performance of instance segmentation based on a baseline setting.\nNOTE\n: Overall, I personally think that the paper is very poorly written which makes it difficult to understand. For example, the variables in Equations 1-4 are not clearly explained and the connection to Figure 1 is also unclear. The authors describe their technical contributions in the subsequent sections (Sec. 3.2 - 3.4), but the unclarified variables and associated writing make it very difficult to understand these aspects. I believe the paper needs significant re-writing to make it understandable for any reader.\nSoundness:\n1 poor\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThe proposed approach leverages the strengths of existing object detection models and introduces an efficient instance segmentation head design.\nThe experiments conducted in the paper showcase the quality of the proposed approach, achieving state-of-the-art results on the COCO dataset while significantly reducing training time.\nThe significance of the paper lies in its ability to improve the efficiency of instance segmentation models by utilizing frozen object detector weights and introducing a lightweight mask decoder.\nThe paper also investigates the impact of various enhancements, such as object-to-object attention, box-to-object attention mechanisms, mask loss on sampled pixel points, refined mask scoring scheme, and redesigned neck for backbone features.\nWeaknesses:\nThe paper lacks clarity in explaining the proposed approach, making it difficult to understand the specific details of the Mask Frozen-DETR framework.\nQuestions:\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9247 by Reviewer YtrW", "Subheading": "Official ReviewbyReviewer YtrW29 Oct 2023, 17:22 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes an instance segmentation method based on the frozen DETR-based object detector. An additional mask network is used to predict instance masks within each bounding box. The paper is validated on the COCO dataset.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper has a strait-forward motivation and idea. With the pre-trained DETR, only training the mask network is much faster and efficient, where the GPU hours in Table 6 supports the claim.\nThe paper writing is good and easy to understand.\nThe image feature encoder design is carefully studied in Table 2.\nWeaknesses:\nThe paper has a low tech novelty. The mask head takes object features from RoI pooling using bounding box and object queries as input, which has been studied in queryinst. Also, it is similar to the mask head design in Mask R-CNN.\nWhen comparing the GPU hours in Table 6, a more fair comparison should include (sum) both the training time for the frozen DETR and for the mask network. The training time of the object bounding box detector should be added.\nCan the paper also provide inference speed comparison in Table 6 and Table 7?\nSince the paper claims high-quality instance segmentation in the title, can the paper report the boundary AP? Can the paper provide more visual comparison cases with some high-quality instance segmentation methods, such as PointRend [a] or Mask Transfiner [b] or PatchDCT [c], or discuss the differences to them in the related works?\n[a] PointRend: Image Segmentation as Rendering. CVPR,2020.\n[b] Mask Transfiner for High-Quality Instance Segmentation. CVPR, 2022.\n[c] Patch Refinement for High Quality Instance Segmentation. ICLR, 2023.\nQuestions:\nWhy Figure 4 is not mentioned in the paper?\nWith SAM/HQ-SAM, the instance segmentation can be directly done using the frozen DETR's predicted boxes as prompt. This requires no training at all. What's the clear advantage of the proposed one-gpu training method comparing to them? Can the author provide performance comparison with them using the same detector?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9247 by Reviewer stNZ", "Subheading": "Official ReviewbyReviewer stNZ26 Oct 2023, 21:18 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper studies how to efficiently insert a mask output head into a pretrained DETR object detector:  What layers can be left frozen, and how to insert extra adapters to make efficient use of the frozen features for the new task.  It finds that with a few well-placed attention/mapping layers, almost all of the new model can be left frozen, so that instance masks can be added with little training time compared to retraining all of the det+mask model from scratch.  The system is built incrementally, showing the effect of inserting adapters at different points, taking only those needed.  The final system achieves very good performance, recovering SOTA.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThis is a clearly presented study of a kind of \"transfer learning\" with frozen pretrained model.  It's a little different from the most common transfer learning settings in that the training task (instance masks) is meant to supplement the original output (boxes), rather than replace it.  The ability of the system to do this with smaller amounts of compute is promising (see below).\nWeaknesses:\nThis is a nice study of this sort of frozen model adaptation, but currently of limited use.  The setting uses COCO with all boxes and masks available, so there is little need to separate box and mask training: the data is fixed, and both box and mask labels come from the same source.  At best, one might say that optimizing box det first followed by masks later could make efficient use of training resources by allowing a (human or machine) model developer to focus on optimizing one task at a time, reducing the overall space of hyperparam variables and interactions --- but this isn't a point that was argued or supported.\nA promising direction to push this further could be to see how well this method performs with different-sized subsamples of the mask data --- since mask labels are more expensive to gather than box labels, it is useful to use fewer of them, and collect just as many as needed in an iterative fashion.  This method may provide a simple means to do that while making efficient use of compute resources.  I think that would be an interesting application (particularly since the faster mask training could be used on incrementally larger datasets, as more mask labeling is performed).\nOverall, this is a simple method whose main components are well documented and developed.  However, it hasn't yet been applied and evaluated in a context with clear benefit or advantages.\nQuestions:\nAdditional questions:\ncomparison to SOTA methods in sec 4:  This appears to compare this method, which inits with an object detector already trained, to systems that jointly train object detection and masks from only a classification- or self-supervised pretrained backbone, without any obj det pretraining, unless I misunderstood.  I don't think this an appropriate comparison, as staged detection-first then mask training could also be done with any of these systems, freezing ether all or subsections of them as well.  IMO the apples-to-apples comparison would be to train the existing systems for obj det only, then add the mask outputs and train those with frozen features, possibly unfreezing some of the last layers or inserting trainable FFNs (but nothing more involved than that, as that would start to replicate this work)\nsame for fig 1:  what are being trained in the comparisons -- masks only or everything?\ntables 2, 3:  would also be good to compare to FFN only or 2-hidden-layer FFN.  baseline qF has no ffn, only comparing directly the frozen features.  So it isn't clear how much of the improvement comes from just a FFN part, vs the attn/spatial combinations\nend of sec 3:  \"additional enhancements ...\".  while I appreciate these are in the appendix, I think more should be included in the main text, describing: (a) the impact / amount of improvement obtained from these enhancements, (b) whether they have been applied to all the models shown in the development (i.e. all frozen, + image feature encoder, + box encoder), only some, or none, (c) which of the other sota comparison systems use these or similar enhancements as well, and which do not but could still make use of them.\nI also didn't see a measurement (at least in the main text) of the inference-time cost of adding these extra layers, though that can be inferred approximately taking a fraction of the training-time flops.\nsec 3.3 channel mapper:  is the channel mapping layer applied to all dims, (h x w x d) -> d' (so 32\n32\nd -> d'), or just on the d dimension, preserving the h x w as (h x w x d) -> (h x w x d') ?\ntable 4:  I think the number of hidden dims could go even lower --- what about going down to 8 (or even 1 or 2)?  There isn't any large performance drop-off yet in this table, while flops is still going down substantially.  same for table 10:  this could go lower than 16x16.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}]}, "PuCno7nwgH": {"paper_info": {"Primary Area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Graph Neural Networks, Representation learning, recommender engines, Hyper edges", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "The paper tackles the challenge of capturing entity attribute-specific preferences in recommender systems, with a particular focus on the role of categorical features within GNN-based user-item recommender engines. Despite the significant influence of categorical features such as brand, category, and price bucket on the user decision-making process, there are not many studies dedicated to understanding the GNN's capability to extract and model such preferences effectively. The study extensively compares and tests various techniques for incorporating categorical features into the GNN framework to address this gap. These techniques include one-hot encoding-based node features, category-value nodes, and hyperedges. Three real-world datasets are used to answer what is the most optimal way to incorporate such information. In addition, the paper introduces a novel hyperedge-based method designed to leverage categorical features more effectively compared to existing approaches. The advantage of the hyperedge approach is demonstrated through extensive experiments in effectively modeling categorical features and extracting user attribute-specific preferences.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9246", "PDF Url": "https://openreview.net/pdf?id=PuCno7nwgH"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9246 by Area Chair EtsH", "Subheading": "Meta ReviewbyArea Chair EtsH06 Dec 2023, 16:08 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper first studies the scenario of using categorical features for GNNs-based recommendations. Complementarily, the authors propose a hyper-edge based approach to leverage such features more effectively within the GNN.\nKey strengths:\nMotivation for studying this problem and proposing this approach is convincing\nThe method is simple\nKey weaknesses:\nNovelty is cited as an issue by 3/4 reviewers\nThe paper considers only two types of categorical attributes, limiting the overal contribution and significance\nThe study is not as comprehensive as claimed, since only two ways of categorical feature representation is used for comparison\nMixed:\nThe reviewers are generally satisfied with experiments, although RFdC6 makes a good point about ensuring fair comparison with other methods, i.e. either not rely blindly on default parameters or comparing with published results.\nJustification For Why Not Higher Score:\nThere is one rebuttal text addressing all reviewers. I find the overall rebuttal rather limited and the arguments within it rather unconvincing. Although one reviewer raised their score, the pool of reviewers as a whole generally feels that post-rebuttal their concerns have not been addressed adequately.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 03:12Everyone", "Content": "Comment:\nRegarding the novelty:\nThe novelty of the approach is to use categorical features more effectively to capture category interdependence in the decision-making process. Below are some important points.\nItem's feature is used to create a hyperedge for users. This is not done in any other paper.\nWe introduce feature interaction hyperedges to capture dependencies. This way, expert knowledge can be included in the model architecture. In experiments, we demonstrated that this simple method outperforms complex architectures used in the state-of-the-art baselines.\nIn the recommender engines context, we are not aware of any paper that uses categorical features directly as hyperedges.\nSession-based recommender engines have adopted the concept of hyperedges, but not in the way we are proposing. In SB recommender engines, a hyperedge can be, for example, all price nodes with which the user interacted (e.g category value nodes are added to the graph) or all items in a session.\nOne of the main intentions of the study is to review and compare different methods that have not been done before.\nRegarding the top K:\n50- and 100-cutoff points were used in one of the main papers [1] we used as the baseline. We followed their implementation closely, hence the choice of 50-100. The results are also true in the top 10 and 20 cases.\nRegarding Code:\nWe will publish our code on GitHub together with a non-anonymised version of the paper at a later stage. We are sorry for not providing a version of our code with this submission.\nRegarding the Referenced paper:\nThere are several major differences with regard to the referenced paper [2].\nThe provided reference concerns the node classification task, in which attributes can be any attribute without distinction to categorical features.\nThe reference paper considers one type of node that connects attributes common in node features. We have different types of nodes and use features of item node type to build user hyperedges. This can go both ways. One can create item hyperedges based on users' categorical features.\nWe introduced feature interaction hyperedges that make it possible to include expert knowledge about the dependencies. As we pointed out, there is overwhelming evidence that price and category are intertwined.\nWe tried to keep the architecture simple to understand if the model performs better because of the proposed way categorical features are included.\nRegarding Robustness:\nEvery test was run ten times, and we reported mean values. This approach is commonly used in the evaluation of recommender engines. We have clarified this in the updated manuscript.\nRegarding Presentation:\nWe have updated the figure.\nRegarding SB recommender engines:\nSession-based recommender engines have adopted the concept of hyperedges, but not in the way we propose. In SB recommender engines, a hyperedge can be, for example, all price nodes with which the user interacted (e.g category value nodes are added to the graph) or all items in a session. We are not aware of any SB recommender engines approach where they have directly categories as hyperedges.\nRegarding the number of methods:\nWe have done a comprehensive literature review to pick these methods. We would be happy if you could point out what other method we should consider.\nRegarding the Interactions term:\nWe did not intend interaction terms to be general, e.g., if we have ten categorical features and create interaction terms for each of them. Rather, we suggest that expert knowledge can be included too. Many studies show that price and category are highly dependent. That's the reason we included interaction terms. In experiments, we showed that explicitly including this dependency in a simple manner outperforms complex architectures used in the state-of-the-art baselines.\n[1] Zheng et al. Incorporating price into recommendation with graph convolutional networks. IEEE Trans. Knowl. Data Eng. 2023\n[2] Wu et al. Dual-view hypergraph neural networks for attributed graph learning. Knowledge-Based Systems 2021.", "Replies": [{"Heading": "Official Comment by Reviewer ziNY", "Subheading": "Official CommentbyReviewer ziNY22 Nov 2023, 07:51Everyone", "Content": "Comment:\nDear Authors,\nthank you for your careful answers to our reviews. I'll comment on your answers regarding my outlined weaknesses and questions.\nNovelty.\nThe points you outlined are now sufficient to justify the novelty of the proposed approach. Thank you.\nTop-k evaluation.\nDespite it would have been useful to actually take a look at the top-10/20 results (maybe you might include them in the appendix) it is reasonable that you used top-50/100 evaluation to be coherent with one of the baselines.\nCode sharing.\nThank you for the clarification, but I'm still convinced the code would have been useful at review time to better assess the implementation of your model and check on the reproducibility. In case of acceptance, please make sure to include it in the final publication.\nIn the light of above, I'll raise the rating for the paper to a weak acceptance."}]}, {"Heading": "Official Review of Submission9246 by Reviewer ziNY", "Subheading": "Official ReviewbyReviewer ziNY06 Nov 2023, 03:31 (modified: 22 Nov 2023, 07:53)EveryoneRevisions", "Content": "Summary:\nThe paper proposes to leverage the categorical information of items for graph neural networks-based recommendation. Differently from previous similar approaches in the literature, the authors do not address the task of session recommendation, which is the main scenario where categorical information is usually injected in recommendation. Specifically, the paper introduces three possible variants of graph-based recommender systems exploiting the categorical information, namely: 1) one-hot encoding of the categorical information as items\u2019 node features, 2) tripartite graphs where categories represent another type of nodes besides users and items, and 3) items\u2019 categories regarded as hyperedges. The authors\u2019 proposal involves the latter setting, where a neighborhood and hyperedge aggregation are performed through a GCN layer and a UniSAGE aggregation, respectively. Finally, the loss function is the common Bayesian personalized ranking one (i.e., BPR). The proposed approach is tested against three GCN architectures having: 1) no categorical information, 2) category information as extra nodes in the graph, and 3) category information as extension of the node features. The evaluation is run on three popular recommendation datasets which include two types of category accounting for either the products\u2019 price or category or both. Results on all such settings demonstrate the efficacy of the hyperedge-based solution, whose trends are further confirmed by evaluating the proposed model against similar state-of-the-art recommendation approaches.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe proposed approach is simple.\nThe adoption of hyperedges in graph-based recommendation is quite recent in the literature.\nThe authors outline the differences with respect to the existing literature in a sufficient manner.\nA wide range of evaluation settings are proposed.\nWeaknesses:\nWhile proposing a simple approach is not generally criticisable, it might need further discussions regarding the actual novelty of the solution.\nNo code is released at review time; this might have been helpful to further assess the efficacy and effectively of the proposed approach.\nSome evaluation choices are not common in the literature and require further justifications.\nAfter the rebuttal.\nThe answers provided by the authors addressed the outlined weaknesses quite sufficiently.\nQuestions:\nCan the authors further elaborate on why the proposed approach should represent a novelty to the existing similar approaches? Indeed, it seems that the presented solution makes use of other graph neural networks layers without any specific new techniques introduced.\nIs there any specific reason why the recommendation metrics are calculated with high cut-offs (i.e., at 50-100)? Did the authors try to evaluate the recommendation performance at 10-20? And if so, are the observed trends still confirmed?\nAfter the rebuttal.\nThe answers provided by the authors answered my questions quite sufficiently.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9246 by Reviewer t3i6", "Subheading": "Official ReviewbyReviewer t3i603 Nov 2023, 05:22 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis study investigates the integration of categorical features of items into collaborative filtering. Its main idea involves connecting nodes with same attributes through hyperedges and leveraging a hypergraph neural network for encoding. The proposed model is tested across three publicly available datasets, demonstrating a notable improvement over existing benchmarks.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nThe paper studies one important task, i.e., collaborative filtering with item attributes.\nExperiments are conducted on three public datasets.\nExperiments show that the proposed method outperforms several existing baselines.\nWeaknesses:\nLimited novelty. The idea of connecting nodes that share the same attributes with hyperedge is not new and has been explored [1]. As a result, the whole paper seems to be a straightforward application of it on collaborative filtering task, limiting the novelty. Although the performance is promising, providing new insights for the community could be more important for an academic paper.\nThe proposed method considers only two specific attributes, i.e., price and category, which makes the model less generalizable. It could be better if the proposed method describes how it will deal with general single attributes and multiple attributes (e.g., will it be better if we model some combinations of attributes?).\nCode is not available, making it difficult to reproduce the work in the reviewing phase.\nThe paper lacks robustness in its experimental validation, as there is no evidence of repeated experiments or statistical tests such as paired t-tests, which are crucial for ensuring the reliability of the results.\nPresentation issue. Figure 2 is not a vector graph and is in low resolution.\n[1] Wu et al. Dual-view hypergraph neural networks for attributed graph learning. Knowledge-Based Systems 2021.\nQuestions:\nFor the \"Pricae and Category\" setting in Table 2, do you use only $h_{cp}$ or use $h_{cp}$, $h_c$, and $h_p$?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9246 by Reviewer p2X9", "Subheading": "Official ReviewbyReviewer p2X903 Nov 2023, 01:13 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors studied the problem of how to properly incorporate categorical features into graph neural models. The authors' contribution is mainly in two folds:\nThe authors compared with multiple commonly used baselines to estimate which way to incorporate categorical features worked better\nThe authors proposed a new model to represent categorical features as hyper edges in the graphs.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n1 poor\nStrengths:\nStrength\nThe paper is in general well written and easy to follow\nThe experiments are conducted on 3 public dataset which is easy to follow and repeat the experiment\nWeaknesses:\nConcerns\nMy major concern is the lack of technical contribution. As pointed out by the authors, using hyperedges in recommender engines is a very straightforward idea and is not novel. The authors' argument of  \"It is to be noted that our examination focuses on user-item recommender systems and does not extend to session-based recommender systems.\" Does not justify well for the novelty or technical contribution of this paper, which leads to my major concern.\nThe author only compared 2 commonly used ways of representing categorical features which is far from being comprehensive, which further decrease the contribution of the paper.\nQuestions:\nWhen building the hyper edges for the proposed model, the authors used secondary interaction between categorical features. What's the time and storage complexity for the proposed algorithm? Will it explode the system if there are a lot of categorical features available for the users and items?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9246 by Reviewer FdC6", "Subheading": "Official ReviewbyReviewer FdC631 Oct 2023, 10:26 (modified: 30 Nov 2023, 07:13)EveryoneRevisions", "Content": "Summary:\nThis paper focuses on how to efficiently model categorical attributes within user-item graph networks for recommender systems. The authors first compare existing methodologies based on 1) one-hot-encoding of binary features for the entities, 2) creation of nodes representing an attribute linked to entities possessing the attribute and 3) creation of hyperedge between any entities sharing the same attribute. Then, they proposed a new model where categorical attributes were handled as hyperedges.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n1 poor\nStrengths:\nDifferent ways of handling the categorical features in GNN are well described.\nExperiments are made on 3 real-world datasets. \nThe hyperedge trick to handle categorical features seem to provide the best results according to Table 1 for the 3 tested datasets: Amazon Grocery, Amazon Tools and Yelp.\nWeaknesses:\nThis is clearly stated by the authors, the proposed approach is only for user-item recommender systems and not session-based ones and does account for item or user features independently only, not interaction categorical features.\nBy the way, I think the paper would benefit from a quick explanation on why extension of the concept of hyperedges for session-based recommender systems to user-item recommender systems is not straightforward, to justify the novelty of the approach here (which is unclear to me).\n\u201cit is noteworthy that there is limited research dedicated to understanding how to incorporate categorical features best\u201c. However, reading the related work, it seems rather clear the limitations of one-hot-encoding and attribute nodes: \u201csome authors have pointed\nout the limitations of the binary-encoded category method\u201c.\n\u201cFor all baselines, we used the publicly available original implementations with their default parameters.\u201d I don\u2019t think this is the correct way to proceed. Each baseline needs to be optimized for the use case for fair comparison.\nSome comments:\n-In Equation (1), \\tilde{d}_j, \\tilde{d}_i  are not defined and I would also mention that N(v) stands for the neighborhood of node v.\n-z_u and z_i are not mathematically defined in p.5.\nMinor, typos:\np.3, \u201cuse-item-attribute graph\u201d.\np.4. \u201cAnother way\u2026\u201d sentence needs to be rewritten.\np.7 \u201ceach datasets\u201d\nQuestions:\nCan you please explain why the extension of the concept of hyperedges for session-based recommender systems to user-item recommender systems is not straightforward, to justify the novelty of the approach here?\nHow are the experimental results after tuning the hyperparameters of each competing approach?\nDid you study the benefit of the approach with more categorical attributes and not only price level and brand category to describe the items?\nWhat is the effect of the number of different valuations for each categorical feature?\n=== AFTER REBUTTAL ===\nI thank the authors for taking the time to answer our questions. Unfortunately I don't upgrade my score because I think the novelty is too limited and the proposed setup (with 2 types of categorical features) too restrictive.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}]}, "csukJcpYDe": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Optimal Control, Hybrid Actions, Robotics, Approximate Dynamic Programming, Tensor Approximation", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "The paper proposes a novel approximate dynamic programming algorithm that can handle hybrid action space", "Abstract": "Control of dynamic systems involving hybrid actions is a challenging task in robotics.  To address this, we present a novel algorithm called Generalized Policy Iteration using Tensor Train (TTPI) that belongs to the class of Approximate Dynamic Programming (ADP). We use a low-rank tensor approximation technique called Tensor Train (TT) to approximate the state-value and advantage function which enables us to efficiently handle hybrid systems. We demonstrate the superiority of our approach over previous baselines for some benchmark problems with hybrid action spaces. Additionally, the robustness and generalization of the policy for hybrid systems are showcased through a real-world robotics experiment involving a non-prehensile manipulation task which is considered to be a highly challenging control problem.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "applications to robotics, autonomy, planning", "Submission Number": "9245", "PDF Url": "https://openreview.net/pdf?id=csukJcpYDe"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (spotlight)"}, {"Heading": "Meta Review of Submission9245 by Area Chair f8zX", "Subheading": "Meta ReviewbyArea Chair f8zX05 Dec 2023, 04:24 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\n(a) The work is dealing with developing approximate DP methods for systems with hybrid action spaces. These involve a mix of continuous and discrete decisions. They show a new type of tensor decomposition method for ADP based on the tensor train method. They validate this on both a simple point domain and a real robot domain.\n(b) The strengths of the paper are it's novelty in method and validation on a real robot experiment.\n(c) The weaknesses of the paper are the sim experiment being relatively simple, the tensor method potentially requiring a lot of storage/coverage and the somewhat limited description of TTPI.\n(d) More complex simulation experiments would certainly help make the paper stronger.\nJustification For Why Not Higher Score:\nThe somewhat limited experimentation in simulation, and the writing of the paper not being extremely clear on TTPI detract from it being an oral in my opinion. I think the simulation experiment also could be a lot stronger showing more ablations and comparisons rather than just a single experiment.\nJustification For Why Not Lower Score:\nThe three reviewers gave it an 8, and one a 6, ranking it very highly overall. The method is novel, there are real robot results and overall it seems simple and broadly applicable to problems in robotics."}, {"Heading": "Official Review of Submission9245 by Reviewer BNgN", "Subheading": "Official ReviewbyReviewer BNgN08 Nov 2023, 22:46 (modified: 20 Nov 2023, 16:34)EveryoneRevisions", "Content": "Summary:\nThis paper develops a method to solve approximate dynamic programming with Tensor Train (TT) representation, which is a compressed tensor to discretely approximate a function. The authors first give a compact and quite neat backgrounds for TT representation and associated operations with TT. The main contribution is a policy iteration algorithm, where the authors replace traditional continuous function approximators (such as using neural network) with TT representations. The authors show the performance of the algorithm using a toy examples in comparison with baseline methods. The method has also been demonstrated in real world robot for a manipulation task.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe authors did a good job presenting the necessary background of TT and its associated operations (such as decomposition, rounding, TT-Cross, and TT-go).  I think the authors have fairly discussed the limitation of the method.\nWeaknesses:\nMy main concern of the paper is the experiment, which is quite limited and there are many remaining questions. Particularly, there are many hyperparameters, it is expected to have ablation study of showing the performance of the method versus the hyperparameters, such as accuracy $\\epsilon $ of TT representation, the max TT rank $r_{max}$, discretization resolutions of the state-action spaces....\nAs a reader to implement the algorithm, I wanted to see a straightforward illustration between the running time of the algorithm and dimensions of the state/action spaces of the system, or directly give an overall complexity of the algorithm for one policy iteration.\nSince the majority of the paper is about the background of TT (previous work), I think the main contribution, which is TTPI algorithm, needs more explanation, including its parallel implementation, which seems a key for applicability of the algorithm. For example, why we need a TT-round operation for the value function in line 8?\nQuestions:\nSince in the introduction the authors mentioned RL, I think it would be interesting to discuss the potential of the methods into \"model-free\" settings.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer BNgN", "Subheading": "Official CommentbyAuthors16 Nov 2023, 04:22Everyone", "Content": "Comment:\nWe greatly appreciate your valuable feedback and suggestions. Here, we offer responses to specific questions and concerns that you have thoughtfully presented.\nMy main concern of the paper is the experiment, which is quite limited and there are many remaining questions. Particularly, there are many hyperparameters, it is expected to have ablation study of showing the performance of the method versus the hyperparameters, such as accuracy of TT representation, the max TT rank, discretization resolutions of the state-action spaces....\nAs a reader to implement the algorithm, I wanted to see a straightforward illustration between the running time of the algorithm and dimensions of the state/action spaces of the system, or directly give an overall complexity of the algorithm for one policy iteration.\nThe hyperparameters in TTPI are intuitive and we have observed them to be robust to the changes in the hyperparameters. The four main hyper-parameters are (1) the upper bound on the TT rank $r_{max}$ of the state-value function and the advantage function (2) the accuracy of tt-approximation $\\epsilon$ (3) the number of samples used in TTGO in computing the policy (4) the number discretization of the state and action space. We have maintained the same choice of hyperparameters in all the experiments across different robotic tasks, so believe it is quite robust.\nIn general, due to the properties of TT modeling, the computation involved and memory required grows linearly with respect to the number discretization and the dimensionality of the state-action space, and quadratically w.r.t the rank.\nIn our experiments, we kept the maximum rank to a large enough value (100 but almost all the experiments never reached the maximum rank in TT-cross modeling over the policy iteration procedure). The accuracy of approximation $\\epsilon=0.001$ was sufficient and decreasing epsilon will improve the performance slightly but at a higher computational cost. The number of discretizations of each variable (state or action) is something that depends on the problem at hand and it is fairly straightforward in robotics problems. For example, if it is a joint angle ranging from $(-\\pi, \\pi)$, a discretization of about 50 to 100 suffices as we employ interpolation for continuous variables. For (3), the higher the number of samples used, the more optimal the policy computation at the cost of linear growth in computational cost and the memory requirement. We set it in the range of 10 to 100.\nSince the majority of the paper is about the background of TT (previous work), I think the main contribution, which is TTPI algorithm, needs more explanation, including its parallel implementation, which seems a key for applicability of the algorithm. For example, why we need a TT-round operation for the value function in line 8?\nThe reason for TT-round operation is that the TT representation obtained by TT-cross need not be optimal in terms of the number of parameters used and the same tensor in TT format can be represented more compactly with the TT-round operation.\nWe will add more information about the implementation details in the paper.\nSince in the introduction the authors mentioned RL, I think it would be interesting to discuss the potential of the methods into \"model-free\" settings.\nWe believe our approach can be used for RL and policy learning in general. TTPI can be extended to RL in the following two ways:\n(1) Model-free RL:  In this setting, TT as used in TTPI could be used as the function approximator. The difference would be instead of using TT-cross to find the TT representation of the value function or advantage function, we can use gradient-based techniques to find the TT approximation to the value and advantage function (or directly the Q function which will result in Q learning). The policy computation from the advantage model (or Q model) is done as in TTPI. We believe this idea has a huge potential in policy learning in general.\n(2) Model-based RL: In this setting, a model of the system is learned using NN or any other function approximator. Then, we can apply the TTPI algorithm using the learned model."}, {"Heading": "Thanks for author's response", "Subheading": "Official CommentbyReviewer BNgN20 Nov 2023, 16:35Everyone", "Content": "Comment:\nI think the authors have positively addressed most of my concerns. I hope those comments could also be reflected in the final draft. I have increased my score from 5 to 6. Thanks."}, {"Heading": "Thanks for reviewer's response", "Subheading": "Official CommentbyAuthors23 Nov 2023, 07:27Everyone", "Content": "Comment:\nWe thank the reviewer for raising the score! We will include your suggestions in the final draft."}]}, {"Heading": "Official Review of Submission9245 by Reviewer ntHE", "Subheading": "Official ReviewbyReviewer ntHE31 Oct 2023, 23:01 (modified: 26 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper tackles the problem of controlling dynamic systems that involve both continuous and discrete actions (termed \"hybrid actions\") is challenging in robotics.  The innovative aspect of the authors' solution is the use of the Tensor Train (TT) format, a method to approximate functions with a low-rank tensor. The TT format allows the authors to approximate two crucial components:\nState-value function: Represents the value of being in a particular state.\nAdvantage function: Indicates how much better taking a certain action is compared to others.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe paper introduces TTPI, an Approximate Dynamic Programming (ADP) algorithm designed for optimal control. The method leverages Tensor Train (TT) format to address challenges in hybrid system control in robotics.\nTraditional control algorithms face problems with systems with non-smooth dynamics and discontinuous reward functions. Existing solutions also often assume differentiability in the system dynamics, which may not always hold.\nThe paper introduces TTPI, an Approximate Dynamic Programming (ADP) algorithm designed for optimal control. The method leverages the Tensor Train (TT) format to address challenges in hybrid system control in robotics. The experiments show TTPI outperforming other state-of-the-art algorithms in training speed and control performance. A real-world robotics experiment further demonstrates the effectiveness and robustness of this method.\nWeaknesses:\nAs the authors themselves mentioned, hand-coding the dynamics in the experiments is very hard to do for complex environments.\nTTPI approximates state-value and advantage functions over the entire state-action space, which can result in computational and storage challenges, especially if these functions are not low-rank in the TT representation.\nQuestions:\nTensor operations, especially in high-dimensional spaces, can sometimes introduce numerical instability. How does the TTPI algorithm ensure numerical stability, especially in long-horizon problems?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer ntHE", "Subheading": "Official CommentbyAuthors16 Nov 2023, 04:24 (modified: 21 Nov 2023, 03:18)EveryoneRevisions", "Content": "Comment:\nWe greatly appreciate your valuable feedback and suggestions. Please find below our response to your question.\nTensor operations, especially in high-dimensional spaces, can sometimes introduce numerical instability. How does the TTPI algorithm ensure numerical stability, especially in long-horizon problems?\nIn our algorithm, we specify the accuracy of approximation of the value function and advantage function in TT-cross. In our experience, an accuracy of 0.001 is usually enough to avoid any instability. The numerical inaccuracy in the forward simulation is another challenge. In general, TTPI can be robust to this as it is an ADP algorithm (so it approximates the value functions almost everywhere in the state space) and our algorithm does not require long rollouts in the Bellman update (we used rollout of only one step (about 1ms) in the algorithm).\nRegarding hand-coding the dynamics, TTPI can work with a simulator as it only requires samples of the tuple (state, action, next-state, reward) queried by TT-cross for modeling the state-value and advantage function. The main requirement from the simulator is that we can query this tuple from an arbitrary state-action pair specified by TT-cross in batch form.  However, as modern simulators such as  NVIDIA Isaac Gym are primarily geared for RL, it still requires some effort in such customization. We are currently investigating this."}, {"Heading": "Please respond to the author reply", "Subheading": "Official CommentbyArea Chair f8zX22 Nov 2023, 02:19Everyone", "Content": "Comment:\nDear reviewer, please do respond to the author reply and let them know if this has answered your questions/concerns."}]}, {"Heading": "Official Review of Submission9245 by Reviewer 3rMV", "Subheading": "Official ReviewbyReviewer 3rMV31 Oct 2023, 17:58 (modified: 22 Nov 2023, 06:00)EveryoneRevisions", "Content": "Summary:\nThe authors use the Tensor Train (TT) model to approximate the state-value function $V$ and advantage function $A$ during policy iteration while solving optimal control problem. At each step of the policy iteration this functions is being rebuilt using well-known\nTT-cross\nalgorithm which adaptively queries a certain number of points to the black-box model function to be approximated. In addition, policy $\\pi$ is built on these iterations using the known TTGO algorithm, which searches for the maximum of the TT-tensor based on sampling from it. The performance of the algorithm was tested on several model and real robot examples, showing its superiority on them. The distinctive feature of the algorithm is the use of hybrid actions.\nSoundness:\n4 excellent\nPresentation:\n4 excellent\nContribution:\n4 excellent\nStrengths:\nThe paper is very well structured, the authors have described not only the method and practical application, but also the limitations.\nThere is code, which allows for reproducible experimentation. In the supplementary materials there is a video with demonstrations of both synthetic experiments and real experiments with a mechanical arm.\nNumerical and in-situ experiments show the superiority of this method.\nPotentially, this approach is applicable to rather multi-dimensional problems (with large dimensionality of stats or actions) since the TT construction overcomes the curse of dimensionality, and the authors use TT-format compression for all possible functions.\nThe approach presented in the paper allows for serious expansion in both quality and time. The authors have identified some of these potential opportunities in the paper.\nWeaknesses:\nI found no significant weaknesses in this article.\nAs a small remark, the use of a uniform grid in section 2.6 could be pointed out, while it might be more accurate to use, for example, a Chebyshev grid.\nAlso there are no theoretical estimates (ranks, for example) and no discussion when we expect small TT-ranks. I.e., can we say in advance, without iterating, that the method works. However, this is a general problem of methods using a low-parameter tensor representation.\nThe paper cited as arXiv (Sozykin et al., 2022) is now officially published:\nhttps://proceedings.neurips.cc/paper_files/paper/2022/hash/a730abbcd6cf4a371ca9545db5922442-Abstract-Conference.html\nmaybe typo: p4 \"decomposition equation 5\"\nQuestions:\ndid you use ideas from\nopitma_tt\n(paper Chertkov et al. (2022)) which utilize\ntop-k\nscheme and thus more accurate?\nwhat are the typical TT-ranks for double pendulum swing-up in the case of small $\\Delta t$ when the model does work?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 3rMV", "Subheading": "Official CommentbyAuthors16 Nov 2023, 04:26Everyone", "Content": "Comment:\nWe greatly appreciate your valuable feedback and suggestions. We also appreciate your suggestions about other discretization procedures that we could employ. Here, we offer responses to specific questions that you have thoughtfully presented.\ndid you use ideas from\u00a0opitma_tt\u00a0(paper Chertkov et al. (2022)) which utilize\u00a0top-k\u00a0scheme and thus more accurate?\nAs mentioned in the paper, we have included the ideas from optima_tt (which is the deterministic version of TTGO). The main advantage is that the policy iteration is stable due to the deterministic nature of the policy.\nwhat are the typical TT-ranks for double pendulum swing-up in the case of small\u00a0when the model does work?\nFor the cartpole swingup and double pendulum experiments, we had to use a time step lower than 1 ms. This resulted in a TT rank of the advantage function between 50 to 100 over the policy iteration stages while the value function had a rank was about 50."}, {"Heading": "Please respond to the author reply", "Subheading": "Official CommentbyArea Chair f8zX22 Nov 2023, 02:19Everyone", "Content": "Comment:\nDear reviewer, please do respond to the author reply and let them know if this has answered your questions/concerns."}, {"Heading": "Official Comment by Reviewer 3rMV", "Subheading": "Official CommentbyReviewer 3rMV22 Nov 2023, 05:59Everyone", "Content": "Comment:\nI thank the authors for the answers to my questions. I keep my positive score (8: accept, good paper) and increase confidence in it."}, {"Heading": "Thanks for reviewer's response", "Subheading": "Official CommentbyAuthors23 Nov 2023, 07:29Everyone", "Content": "Comment:\nWe thank the reviewer for the positive feedback!"}]}, {"Heading": "Official Review of Submission9245 by Reviewer F3ze", "Subheading": "Official ReviewbyReviewer F3ze26 Oct 2023, 18:51 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a method for solving optimal control problems (assuming a correct dynamics model is available) with mixed continuous and discrete state variables, using an efficient representation of the value function of the problem based on a set of low-dimensional tensors, in a tensor-train (TT) format. An empirical evaluation demonstrates the effectiveness of the proposed method on several control problems of moderate complexity.\nSoundness:\n4 excellent\nPresentation:\n3 good\nContribution:\n4 excellent\nStrengths:\nOne of the main strength of the paper lies in the efficient way of computing the optimal action from the tensor-based representation of the value function. It is based on an explicit representation of the advantage function, again in tensor-train format, and the use of the TT-Cross algorithm for an efficient TT approximation of the advantage function after it has been computed by means of a Bellman back-up.\nAnother strength of the paper is the rather impressive verification of the algorithm on control problem with six continuous state variables and a single discrete variable, on a real robot.\nWeaknesses:\nAlthough the example on the real robot is very impressive, the examples in simulation are less so. Four-dimensional state space is not that high, barely beyond what can be represented with a look-up table on modern computers. (10^8 cells will take around 400MB of FP numbers.) The authors clearly state that their algorithm is not meant to approximate value functions on very high-dimensional state spaces, such as images, but most robotics applications on 6 degree of freedom robots have 12-dimensional state space, so this is perhaps the dimensionality of highest interest.\nSome claims are not entirely justified. For example, the authors say \"OC is synonymous with ADP\". There is some overlap, but the two fields are hardly the same. Many OC algorithms, including the celebrated LQR and LQG algorithms, are based on basic DP, nothing approximate about it.\nFurthermore, the authors say that MuJoCo is not parallelizable. I cannot agree with this, MuJoCo has always been easy to parallelize on multiple CPU cores, and the latest release of MuJoCo, 3.0.0, can run on GPUs and TPUs. True, it came out after ICLR papers were submitted, but please reconsider this claim.\nThe authors also mention \"the need for differentiability of the system dynamics and reward function which is a common assumption in the existing ADP algorithms\". This is probably not entirely correct, as many ADP algorithms simply sample the system dynamics.\nFurthermore, the authors often use the phrase \"policy retrieval\", implying that somehow the policy has been lost. Suggest replacing with \"policy computation\" or \"policy evaluation\".\nSome minor typos:\nAppendix A.3: citation missing in the first sentence \nSame place: \"n=6 states\" -> \"n=6 state\" (completely changes the meaning)\n\"HZ\" -> \"Hz\"\nQuestions:\nHow well will the algorithm perform on a somewhat higher dimensional problem, for example a 6 or 12 dimensions?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer F3ze", "Subheading": "Official CommentbyAuthors16 Nov 2023, 04:28 (modified: 16 Nov 2023, 10:46)EveryoneRevisions", "Content": "Comment:\nWe greatly appreciate your valuable feedback and suggestions and include them in the paper. Here, we offer responses to specific questions and concerns that you have thoughtfully presented.\nAlthough the example on the real robot is very impressive, the examples in simulation are less so. Four-dimensional state space is not that high, barely beyond what can be represented with a look-up table on modern computers. (10^8 cells will take around 400MB of FP numbers.) The authors clearly state that their algorithm is not meant to approximate value functions on very high-dimensional state spaces, such as images, but most robotics applications on 6 degree of freedom robots have 12-dimensional state space, so this is perhaps the dimensionality of highest interest.\nHow well will the algorithm perform on a somewhat higher dimensional problem, for example, a 6 or 12 dimensions?\nIndeed the dimension of the state-space in the benchmark simulation examples for hybrid control is rather low (4D). However, the benchmark simulation problems are representative of high-dimensional action space problems and it is quite large (up to 32D).  In general, in our approach what matters the most is the dimension of the state-action space. We believe the crucial aspect is that TTPI can handle high-dimensional action space which is difficult for existing ADP algorithms.\nIn the software library provided, we have included the regulation problem of the point-mass system with obstacles. We have tested it for various dimensionality as it easily forms a testbed for high-dimensional state space. Here the state space is $2m$  where $m$ is the dimension of the action space (acceleration of the point-mass which is the same as the dimension of the environment it lives in). We have tested it for $m = 2, 3, 4, 5$  (so state space of size $4D$  to $10D$) and observed its performance matches the classical algorithms. So, we believe TTPI should be able to handle a relatively larger state space dimension of interest in robotics problems. We will include more examples of robotics problems in the future release of the software."}, {"Heading": "Response to authors' clarification about state space dimensionality", "Subheading": "Official CommentbyReviewer F3ze16 Nov 2023, 11:45Everyone", "Content": "Comment:\nI am satisfied with the authors' clarification about state space dimensionality - the joint dimensionality of the state-action space is indeed high enough to make it impossible to use a tabular representation, and the benefit of using the tensor-train representation are clear."}, {"Heading": "Thanks for the Response", "Subheading": "Official CommentbyAuthors23 Nov 2023, 07:31Everyone", "Content": "Comment:\nWe thank the reviewer for the remarks and suggestions!"}]}]}, "RzNlECeoOB": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Variational autoencoder, Information geometry, Heavy-tail learning, Generative model", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "The variational autoencoder (VAE) typically employs a standard normal prior as a regularizer for the probabilistic latent encoder. However, the Gaussian tail often decays too quickly to effectively accommodate the encoded points, failing to preserve crucial structures hidden in the data. In this paper, we explore the use of heavy-tailed models to combat over-regularization. Drawing upon insights from information geometry, we propose $t^3$VAE, a modified VAE framework that incorporates Student's t-distributions for the prior, encoder, and decoder. This results in a joint model distribution of a power form which we argue can better fit real-world datasets. We derive a new objective by reformulating the evidence lower bound as joint optimization of KL divergence between two statistical manifolds and replacing with $\\gamma$-power divergence, a natural alternative for power families. $t^3$VAE demonstrates superior generation of low-density regions when trained on heavy-tailed synthetic data. Furthermore, we show that $t^3$VAE significantly outperforms other models on CelebA and imbalanced CIFAR-100 datasets.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "Submission Number": "9244", "PDF Url": "https://openreview.net/pdf?id=RzNlECeoOB"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9244 by Area Chair QTxX", "Subheading": "Meta ReviewbyArea Chair QTxX09 Dec 2023, 05:31 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper extends the standard VAE approach for Gaussian likelihoods (G^3VAE) Gaussian latent prior, Gaussian encoder and Gaussian decoder to t^3VAE where t=the t-distribution.\nAll the reviewers liked the paper, were satisfied with the discussion and are in favor of acceptance.\nJustification For Why Not Higher Score:\nThe set-up seems very taliored to the specific Gaussian likelihood. It could have been useful with a more generic approach also valid for non-Gaussian likelihood and hierarchical models.\nJustification For Why Not Lower Score:\nThe paper is a meaningful new contribution to the time-honoured VAE model."}, {"Heading": "Official Review of Submission9244 by Reviewer fEQe", "Subheading": "Official ReviewbyReviewer fEQe01 Nov 2023, 08:05 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors develop a new variational autoencoder designed for heavy-tailed data by changing the prior, encoder, and decoder from Gaussian distributions to t-distributions, and the KL divergence to power divergence. The authors draw upon the EM perspective of VAEs developed by Han et al., 2021 to formulate a joint minimization objective, and use ideas from information geometry to tie together the exponent in the power divergence with the degrees of freedom in the t-distributions. The degrees of freedom hyperparameter is shown to affect the degree of regularization in the model. The model formulation is also described in terms of a Bayesian point of view. Four experiments are conducted comparing the performance of the proposed model with a selection of other competing VAEs: the first involving a univariate synthetic dataset (reporting histograms and MMD test p-values), the second involving a bivariate synthetic dataset (reporting MMD test p-values), the third involving the CelebA image dataset (reporting FID scores), and the fourth involving the CIFAR100-LT image dataset (reporting FID scores). In all cases, the model is shown to vastly outperform competing methods. All arguments are supported with ample theoretical derivations in the supplementary material.\nSoundness:\n4 excellent\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nAn interesting and important extension on the VAE framework to meaningfully deal with heavy-tailed data.\nA broad investigation and discussion into the underlying concepts, providing an excellent derivation of the method, and a good amount of detail extending into the appendices.\nHyperparameters and model choices are thought out and well-justified. The authors could have simply attached a few of the underlying ideas together without much thought, but have chosen to go the extra mile.\nModel is shown to be highly effective compared to competitors, even on reasonably challenging image datasets where VAEs do not typically do well.\nVery well-written paper; no grammatical issues or typos that I could detect.\nWeaknesses:\nReporting p-values is not exactly ideal, especially when metrics are available.\nNo general summary to assist with implementation.\nNo examples conducted on datasets where heavy tails are known to be especially relevant (e.g. economic datasets).\nNo discussion of, or comparisons to, similar developments in the normalizing flow literature (e.g. [1] and [2]).\n[1] Jaini, P., Kobyzev, I., Yu, Y., & Brubaker, M. (2020). Tails of Lipschitz triangular flows. In International Conference on Machine Learning (pp. 4673-4681). PMLR.\n[2] Liang, F., Mahoney, M., & Hodgkinson, L. (2022). Fat\u2013Tailed Variational Inference with Anisotropic Tail Adaptive Flows. In International Conference on Machine Learning (pp. 13257-13270). PMLR.\nQuestions:\nIs the gamma-power divergence not the same as the Renyi divergence (up to constants)? How do they differ?\nCan you provide an algorithm environment to show how this should be implemented at a glance? I appreciate the presentation and the derivation of the model, but any reader looking to quickly implement it is likely to have trouble if they do not thoroughly read the paper.\nWhat do the MMD values themselves look like? These might be more useful to report than the p-values.\nSince you know the densities explicitly in the synthetic tests, you could use KSD instead of MMD, as this will have much improved statistical power. Have you tried this?\nHave you tried the model on any real datasets other than image sets?\nDo you know how the model compares with other normalizing flow models incorporating t-distributions?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNone\nRating:\n8: accept, good paper\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 13:37Everyone", "Content": "Comment:\nThank you for your positive review and very through advice which helped us greatly to improve our paper! We also report that we have additionally implemented the hierarchical $t^3$HVAE and added experimental results. Below are our responses to questions (merged with weaknesses).\nIs the gamma-power divergence not the same as the Renyi divergence (up to constants)? How do they differ?\nIn fact, the following four divergences have similar definitions.\n$\\alpha$-divergence $\\frac{1}{\\alpha(\\alpha-1)}\\left(\\int p^\\alpha q^{1-\\alpha}-1\\right)$\nRenyi divergence $\\frac{1}{\\alpha-1}\\log\\int p^\\alpha q^{1-\\alpha}$\n$\\gamma$-power divergence $-\\int p\\left(\\frac{q}{\\lVert q\\rVert_{1+\\gamma}}\\right)^\\gamma +\\lVert p\\rVert_{1+\\gamma}$\nlog-$\\gamma$ divergence $\\frac{1}{\\gamma(\\gamma+1)}\\log\\int p^{\\gamma+1} - \\frac{1}{\\gamma}\\log\\int pq^\\gamma+\\frac{1}{\\gamma+1}\\log\\int q^{\\gamma+1}$\nDespite the apparent similarities, they each possess rich geometric properties. The $\\alpha$-geometry was originally studied by Amari and has analogous properties to KL divergence on the space of positive measures (being the intersection of the $f$- and Bregman families) but has a more complex dual connection when restricted to probability measures. The $\\gamma$-geometry, studied by Eguchi, has a simple flatness structure where exponential families are replaced by power families and mixture geodesics are the same. Also, from a statistical perspective, $\\alpha$ tunes between mass-covering or mode-seeking behavior, while $\\gamma$ tunes between robustness and outlier-focused behavior [1].\nIn the initial stages of our research, we considered all the above as well as robust $\\beta$ and other $f$-divergences as replacements for KL, but decided upon $\\gamma$-power divergence due to flatness properties and viability of closed-form computations. The $\\alpha$ and $\\beta$ type divergences have also been studied for variational inference in previous works [2,3] (although not with our joint optimization framework), while $\\gamma$-divergence methods are quite new.\nCan you provide an algorithm environment to show how this should be implemented at a glance?\nThank you for the helpful suggestion! We have added an implementation summary of our framework as Algorithm 1 in the main text.\nWhat do the MMD values themselves look like? These might be more useful to report than the p-values.\nWhen the RBF kernel $k(x,x') = \\exp\\left(-\\frac{(x-x')^2}{2\\sigma^2}\\right)$ is implemented for the MMD bootstrap test, the hyperparameter $\\sigma^2$ is automatically chosen as the median of ${(x_i - x_j')^2}_{i,j}$. In practice, $\\sigma^2$ fluctuates between around 3 to 5. In this case, directly comparing MMD values may not be meaningful. The MMD values are also somewhat randomly distributed around -0.01~0.01 and not particularly informative on their own. Hence a bootstrap test must be run to obtain meaningful statistics, which is why we only report $p$-values.\nSince you know the densities explicitly in the synthetic tests, you could use KSD instead of MMD, as this will have much improved statistical power. Have you tried this?\nDue to increased power and reduction of reliable samples due to tail truncation, KSD tends to reject\nall\nmodels including $t^3$VAE. Of course, no model can exactly approximate the true distribution even with infinitely many samples, which will lead to rejection for any sufficiently powerful test. Instead our goal was to be able to clearly delineate\nrelative\ntail generation performance of $t^3$VAE and other models, which is well achieved by MMD testing: we proved that $t^3$VAE is harder to distinguish from test data compared to other models. We also considered various other testing methods, but ultimately chose MMD due to applicability to 2 dimensions and simplicity & speed of implementation.\n(continued below)"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 13:37Everyone", "Content": "Comment:\n(continued)\nHave you tried the model on any real datasets other than image sets?\nDue to time constraints, we had to focus our efforts into implementing the hierarchical $t^3$VAE to learn very high dimensional images (experiments added to Section 4.2, Figure 5 and Table C3). We note that many non-image datasets that are considered heavy-tailed (economic, weather, etc) are low dimensional, while $t^3$VAE exhibits the best performance improvements over models such as Student-t VAE in higher dimensions. Nonetheless, we will continue to experiment on other datasets for the camera-ready version.\nDo you know how the model compares with other normalizing flow models incorporating t-distributions?\nWorks such as [4,5,6] implement heavy-tailed base distributions for normalizing flows, which is conceptually similar to using a heavy-tailed prior for VAEs. Of course in principle, any data distribution can in principle be approximated arbitrarily closely if the flow/decoder networks are powerful enough. However, these papers argue intuitively and empirically that t-distributions ensure better robustness and generalization, and we believe the same arguments carry over to our model.\nWe also take a step further (compared to prior-based alternatives) by also using t-distributions for the decoder and encoder, which enforces the power form Eq.(15) on the joint model distribution. If the decoder network $\\mu_\\theta$ is Lipschitz, this will explicitly ensure polynomial decay w.r.t. $x,z$. In fact, this control 'further down the line' seems to be key to $t^3$VAE's success as evidenced by our experiments against Student-t VAE, DE-VAE and VAE-st. This discussion has been added to the Related Works section.\nMoreover, this raises an intriguing question post factum: can the tails of distributions generated by normalizing flows also be more strictly controlled down the line (not just modifying the base distributions) to improve performance? We leave this as an interesting direction for future work.\n[1] Regli, Silva. Alpha-beta divergence for variational inference. 2018.\n[2] Li, Turner. Renyi divergence variational inference. NIPS 2016.\n[3] Akrami et al. Robust variational autoencoder. NeurIPS 2019.\n[4] Alexanderson, Henter. Robust model training and generalisation with Studentising flows. ICML 2020 workshop.\n[5] Amiri et al. Generating heavy-tailed synthetic data with normalizing flows. UAI 2020 workshop.\n[6] Laszkiewicz et al. Marginal tail-adaptive normalizing flows. ICML 2022."}]}, {"Heading": "Official Review of Submission9244 by Reviewer 5yMY", "Subheading": "Official ReviewbyReviewer 5yMY01 Nov 2023, 05:47 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors address the limitation of the standard Variational Autoencoder (VAE) that employs a Gaussian prior which sometimes fails to capture the intricate structures in data due to its fast-decaying tails. They propose a novel framework by leveraging the heavy-tailed nature of the Student's t-distributions for the prior, encoder, and decoder. They argue that this new formulation can better fit real-world datasets.  Empirical results suggest that t3VAE performs better in modeling low-density regions, and yields superior performance on the CelebA and imbalanced CIFAR-100 datasets.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe use of Student's t-distributions as an alternative to the Gaussian prior in VAEs seem a fresh perspective. The heavy-tailed nature can indeed address some of the shortcomings of the standard Gaussian prior.\nThe modification of the evidence lower bound to incorporate \u03b3-power divergence might seem appropriate given the nature of the power families.\nDemonstrated superior performance on benchmark datasets, particularly on imbalanced/ longtailed version of CIFAR-100, which is a testament to the proposed model's robustness.\nWeaknesses:\nThe transition from Eq(5) to Eq(19) is not straightforward for me. While intuitively, adopting the \u03b3-power divergence to the KL-divergence might seem appropriate, a central question arises: Does the \u03b3-power divergence between the two manifolds still lead to the ELBO? This needs to be addressed for better clarity.\nGiven that both t3VAE and the Student-t VAE integrate the Student's t-distribution into the VAE framework, a more granular comparison in the related work section would be enlightening. Highlighting the distinct features and advantages of t3VAE over the Student-t VAE would give readers a clearer understanding of its contributions.\nI noticed that the hierarchical variants of the model weren't evaluated in the experimental section. Such an evaluation might provide insights into the model's performance in different configurations. I'd be keen to see these results.\nIncorporating the Student's t-distributions inherently increases the model's complexity. This can potentially introduce challenges in training and optimization. I recommend the authors delve into these potential challenges, discussing potential remedies and considerations for practitioners aiming to implement t3VAE.\nQuestions:\nSee Weakness.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 12:19Everyone", "Content": "Comment:\nThank you for your through review and suggestions, and raising a number of important issues! We have updated the manuscript to reflect our discussion, add experiments and improve presentation. Below are our responses to weaknesses which we hope can dispel any remaining concerns.\nAddressing Weaknesses\nDoes the $\\gamma$-power divergence between the two manifolds still lead to the ELBO?\nThank you for pointing out the issue. We agree this is an important distinction that needs to be clarified, and the following discussion has been added to the manuscript in Section 3.2.\nDue to the different expression for $\\gamma$-power divergence and also the approximation step, the $\\gamma$-loss does not function as a bound for log-likelihood, although joint minimization will still generally try to fit $p_\\theta(x)$ to the true data distribution, maximizing likelihood while also keeping posteriors close. Its precise effect is a balance between reconstruction and regularization, which is explained throughout Section 3.3.\nWe emphasize that the central philosophy of our framework is viewing the ELBO\nnot\nas a lower bound of likelihood (which naturally leads to modifying the KL regularizer term as most VAE variants do), but as a divergence between joint distributions (which naturally leads to modifying the entire divergence as in Eq.19). The $\\gamma$-power or log-$\\gamma$ divergences are reasonable choices due to their information geometric properties and viability of closed-form computations with respect to t-distributions.\nBut why does this work? Our experiments demonstrated that our framework is very effective even though we are not explicitly optimizing for likelihood. This can be explained in part by [1] which shows that $\\gamma$-type divergence minimizers are M-estimators and proves asymptotic efficiency and robustness under heavy contamination, lending support to our approach as a solid alternative to MLE methods for statistical inference. Furthermore, for high-dimensional datasets $\\gamma$ is quite small and the effect of changing divergence is simply less important compared to the effect of the coupled t-distributions (in particular the prior) whose degrees of freedom $\\nu$ is small.\nGiven that both t3VAE and the Student-t VAE integrate the Student's t-distribution into the VAE framework, a more granular comparison in the related work section would be enlightening.\nWe felt that the Student-t VAE design is less suitable to highlight in the introduction for a couple of reasons. The model uses a separate univariate t-distribution for each dimension (there is some confusion regarding dimension in the paper as well), and experiments only focus on overcoming the training instability issue for low-dimensional datasets. Moreover, performance improvement on image datasets in our experiments was not as significant compared to other models such as $\\beta$-VAE and Tilted VAE. Similarly, DE-VAE also showed relatively poor reconstuction quality and VAE-st suffered from a range of inconsistencies and implementation issues. Hence we aimed for a broad overview of all the t-based VAEs rather than focusing on one single benchmark model.\nI noticed that the hierarchical variants of the model weren't evaluated in the experimental section. Such an evaluation might provide insights into the model's performance in different configurations.\nWe have newly implemented the two-layer hierarchical model ($t^3$HVAE) and compared against the Gaussian HVAE on double resolution images. The results are presented in Section 4.2, Figure 5 and Table C3. We demonstrate that the increased hierarchical depth allows $t^3$HVAE to learn more sophisticated images with substantially higher clarity and sharper detail compared to Gaussian HVAE, further justifying the generality and effectiveness of our theoretical framework.\nIncorporating the Student's t-distributions inherently increases the model's complexity. This can potentially introduce challenges in training and optimization.\nUnlike models such as DE-VAE or VAE-st which require numerical integration to calculate the KL divergence between t-distributions for every data point, the explicit form of the $\\gamma$-loss does not create any significant computational bottlenecks or new instability issues (e.g. division by zero variance, exploding gradients) compared to the original ELBO of Gaussian VAE. The same holds for the t-based reparametrization trick or multivariate t-distribution sampling process as detailed in Appendix C.1, requiring very minor additional computation. We also observed virtually equal runtimes in practice. Nonetheless we agree that this discussion is needed in the paper, and have merged into the final paragraph in Section 4 to give a general analysis on training cost and hyperparameter selection.\n[1] H. Fujisawa, S. Eguchi, 2008. Robust parameter estimation with a small bias against heavy contamination. J. Multivar. Anal. 99(9)."}, {"Heading": "Thanks", "Subheading": "Official CommentbyReviewer 5yMY23 Nov 2023, 05:39Everyone", "Content": "Comment:\nThanks to the authors for addressing my concerns.   I decided to keep my positive ratings."}]}, {"Heading": "Official Review of Submission9244 by Reviewer 1fkZ", "Subheading": "Official ReviewbyReviewer 1fkZ31 Oct 2023, 10:52 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn this paper, the authors introduce a novel VAE-like generative model ($t^3$VAE) in which the underlying distributions (for the prior, encoder, and decoder) are assumed to be (multivariate) Student's t. This idea leads to a better approximation of heavy-tailed densities, which is confirmed by experiments on both synthetic and real-world datasets. The presented (solid) theoretical justification stems from viewing classical VAE as a joint minimization process between two statistical manifolds and relies on replacing the KL divergence with the $\\gamma$-power divergence.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\n(1) The idea behind $t^3$VAE (although somewhat natural) seems original and significant since it allows us to overcome (to some extent) the limitations of classical VAE.\n(2) The proposed solution has (as the authors show) a solid theoretical background.\n(3) The experimental results prove the superiority of $t^3$VAE over the state-of-the-art.\nWeaknesses:\n(1) The authors claim that their idea is extendable to hierarchical models. Although there is a theoretical justification for this in the appendix, the paper would benefit from corresponding experimental studies.\n(2) Minor comments:\np. 2, l. 10 from bottom: the authors probably wanted to write \"likelihood\" (instead of \"log-likelihood\"),\np. 7, Tab. 3: $t^3$VAE $\\to$ $t^3$VAE ($\\nu=10$),\np. 9, l. 12: I suggest not to use the phrase \"scores highest\" (as in the case of FID \"lower is better\").\nQuestions:\n(1) Have you considered providing experimental results for hierarchical architectures?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 12:17 (modified: 22 Nov 2023, 13:45)EveryoneRevisions", "Content": "Comment:\nWe are extremely grateful for your positive and through review of our work! We have updated the paper following your suggestions.\nAddressing Weaknesses & Questions\n(1) The authors claim that their idea is extendable to hierarchical models. Although there is a theoretical justification for this in the appendix, the paper would benefit from corresponding experimental studies.\nWe have newly implemented the two-layer hierarchical model ($t^3$HVAE) and compared against the Gaussian HVAE on double resolution images. The results are presented in Section 4.2, Figure 5 and Table C3. We demonstrate that the increased hierarchical depth allows $t^3$HVAE to learn more sophisticated images with substantially higher clarity and sharper detail compared to Gaussian HVAE, further justifying the generality and effectiveness of our theoretical framework.\n(2) Minor comments: Thank you for going through our paper in detail! We have edited the mistakes and generally improved the presentation of the text. Also, please see our responses to the other reviewers for some other points that we addressed."}, {"Heading": "Thank you for your comment", "Subheading": "Official CommentbyReviewer 1fkZ22 Nov 2023, 14:39Everyone", "Content": "Comment:\nI am satisfied with the authors' rebuttal. I keep my high rating of the contribution."}]}]}, "JBLHIR8kBZ": {"paper_info": {"Supplementary Material": "zip", "Primary Area": "visualization or interpretation of learned representations", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Mechanistic Interpretability, Visualisation", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Advances in Large Language Models (LLMs) have led to remarkable capabilities, yet their inner mechanisms remain largely unknown. To understand these models, we need to unravel the functions of individual neurons and their contribution to the network.This paper introduces a novel automated approach designed to scale interpretability techniques across a vast array of neurons within LLMs, to make them more interpretable and ultimately safe. Conventional methods require examination of examples with strong neuron activation and manual identification of patterns to decipher the concepts a neuron responds to. We propose Neuron to Graph (N$2$G), an innovative tool that automatically extracts a neuron's behaviour from the dataset it was trained on and translates it into an interpretable graph.N$2$G uses truncation and saliency methods to emphasise only the most pertinent tokens to a neuron while enriching dataset examples with diverse samples to better encompass the full spectrum of neuron behaviour. These graphs can be visualised to aid researchers' manual interpretation, and can generate token activations on text for automatic validation by comparison with the neuron's ground truth activations, which we use to show that the model is better at predicting neuron activation than two baseline methods. We also demonstrate how the generated graph representations can be flexibly used to facilitate further automation of interpretability research, by searching for neurons with particular properties, or programmatically comparing neurons to each other to identify similar neurons. Our method easily scales to build graph representations for all neurons in a 6-layer Transformer model using a single Tesla T4 GPU, allowing for wide usability.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9243", "PDF Url": "https://openreview.net/pdf?id=JBLHIR8kBZ"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9243 by Area Chair 7DKH", "Subheading": "Meta ReviewbyArea Chair 7DKH12 Dec 2023, 08:38 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper investigates the inner mechanisms of large language models (LLM). Specifically, the authors introduce a method named Neuron to Graph (N2G) to explain the behavior of neurons in LLM. This method constructs a token graph for each neuron according to the activation on training data examples. The results demonstrate that N2G is better at predicting neuron activation than token lookup and n-gram look up method. However, the evaluation presented in this paper is not sufficient and convincing.\nJustification For Why Not Higher Score:\nThe evaluation presented in this paper is not sufficient and convincing.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9243 by Reviewer dCS6", "Subheading": "Official ReviewbyReviewer dCS607 Nov 2023, 11:00 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces a method named Neuron to Graph (N2G) to automatedly explain the behavior of neurons in LLM. This method constructs a token graph for each neuron according to the activation on training data examples. In experiment, using N2G, the author analyzes the neurons of a six-layer SoLU model which contains 18,432 neurons. Through validation, the author demonstrate that N2G is better at predicting neuron activation than token lookup and n-gram look up method. In addition, the author discovers some interesting pattern: some neuron are responsible for in-context learning, some neuron exhibits same behavior.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThis paper proposes an automated method to interpret the behavior of neurons in language model by constructing a token tree. The visualization of token tree facilitates the interpretability of neurons and identification of neurons of interest.\nThe method can be easily scale to large language models.\nIn experiment, the effectiveness of the method is validated by comparing with two other methods. In addition, the writing and presentation of this paper is good.\nWeaknesses:\nThe paper mentions that the interpretability of neurons in deep layers is poor, but it does not provide any examples of poorly explained neurons.\nThis work is similar to [1], as both explore the behavior of neurons based on their activations to different tokens. This paper automates the interpretation of neurons using a graph, but does not significantly improve the interpretability of language model neurons. The differences with [1] need to be further explained in detail.\nCurrent popular large language models use SwishGLU as the activation function, while this work focuses on models that use SoLU as the activation function. This creates a gap in the interpretability of large language models.\n[1] Steven Bills, Nick Cammarata, Dan Mossing, Henk Tillman, Leo Gao, Gabriel Goh, Ilya Sutskever, Jan Leike, Jeff Wu, and William Saunders. Language models can explain neurons in language models. 2023.\nQuestions:\nWhy only take top 20 dataset examples? Are top 20 dataset examples enough to unravel the neuron behavior?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9243 by Reviewer QyST", "Subheading": "Official ReviewbyReviewer QyST01 Nov 2023, 01:44 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes an explanation method for large language models. Given a neuron of interest, the paper first identifies the text samples that cause high activation on the neuron. Then, through sample pruning, \"pivot tokens\" and their contexts within each sample are detected. After that, after augmentation, it identifies the tokens that are important for neuron activation on the pivot token. Finally, the graph is built by connecting the context tokens with the pivot token. The graph is regarded as the explanation for the neuron.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nA timely topic of explaining large language models.\nThe proposed method can provide some useful information of LLM neurons. The pruning step and augmentation step make sense to me.\nThe method is intuitive and easy to follow.\nWeaknesses:\nOnly using SoLU is an problem. We want to explain those models that are heavily used in practice, but not some testbeds.\nThe whole process is pretty ad-hoc. There is no rigorous definition of explanation. I would say this work is more like a post-hoc analysis, instead of research.\nI can hardly call the result as a \"graph\", since it is just a pivot node with some context nodes. It IS a graph, but a very limited one.\nQuestions:\nIn the \"pruning\" part, how can we find $e_i$?\nAccording to my understanding, the resultant graph is just a pivot node with some context nodes. Is this correct?\nThe paper title contains \"at scale\". How is this relected in the paper?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9243 by Reviewer cE3E", "Subheading": "Official ReviewbyReviewer cE3E01 Nov 2023, 01:22 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a method for summarizing highly activating dataset samples into a graph representation for each individual neuron. Given a neuron and a dataset, the top 20 most activating dataset samples are selected. Then from each sample a substring is selected such that the substring ends in the most activating token and the activation from this token given the substring is more than half the activation of the same token given the full string. The authors refer to this step as \"pruning\".\nThe pruned set is then augmented by replacing \"salient\" tokens in each sample with related tokens according to DistiBert. Saliency is identified by replacing each token with a padding token and thresholding the ration of maximum token activation before and after the replacement.\nThe resulting set of augmented substrings are then summarized in a Trie and visualized as a set of DAGs for each neuron. The Trie can be used to predict whether any given string is a highly activating string for a neuron.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nA. The paper addresses an important problem: interpreting neurons in large language models, which can have implications for mechanistic interpretability, bias detection, and model safety.\nB. The paper also provides a way to measure the quality of the generated neuron graphs by comparing them to the ground truth activations of neurons.\nC. The paper is well-written and organized, with clear motivation, methodology, and experiments. It includes several figures and tables that illustrate the proposed method and its results.\nWeaknesses:\nA. No external validation of the method is done to show out of distribution generalization. Ground truth activation prediction is performed on the same model, and the same dataset that was used to create the Trie of highly activating substrings. This is a major limitation.\nB. The authors acknowledge in the introduction that one problem in looking at highly activating samples in a dataset is that it provides an illusion of interpretability, but they do not address this problem. They augment the samples using related tokens, which does not introduce diversity in the dataset, and the interpretation is still limited to the distribution of data originally available in the dataset with some paraphrasing added. Even assuming the DistillBert augmentation does address this problem, this is not quantified in anyway and is not verifiable.\nC. The proposed method involves several arbitrarily selected hyperparameters: top 20 activating samples for each neuron, pruning threshold, saliency threshold, augmentation threshold\nD. There are no aggregate level results in the paper that actually help interpret the model. The paper could use an \"applications\" section where a behavior of interest in LLMs is studied and certain components of the model are discovered using the proposed method to be responsible for that behavior. On a related note,  in section 4.2 the jump from \"repetition detection\" to the claim of having discovered in-context-learning neurons is not supported by any evidence.\nQuestions:\nDid the top 20 highly activating samples for each neuron satisfy a minimum activation level? Or is it possible that for some neurons the highly activating samples are actually not significantly activating?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n1: strong reject\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9243 by Reviewer B6PG", "Subheading": "Official ReviewbyReviewer B6PG31 Oct 2023, 20:20 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a novel approach N2G to improve the interpretability of Large Language Models (LLMs).\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe paper is well written.\nN2G is scalable and can be used to interpret all neurons in a 6-layer Transformer model using a single Tesla T4 GPU. This makes it a practical tool for researchers to use.\nN2G has been evaluated on two baseline methods and shown to be better at predicting neuron activation.\nThe generated graph representations can be flexibly used to facilitate further automation of interpretability research.\nWeaknesses:\nThe description of the dataset Neuroscope is not clear.\nThe quantity evaluation is not sufficient. The major improvement is not significant. Lack of comparison with SOTA models.\nThe major contribution of interpretation part is not clear. The paper only mention the technology they used, not the performance the model achieved.\nQuestions:\nCould you add more detail on the dataset?\nWill other public well-known dataset suitable for this model?\nWhat's the inspiration of this four-fold model?\nWill the graph structure affect the final performance?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9243 by Reviewer 8BeY", "Subheading": "Official ReviewbyReviewer 8BeY21 Oct 2023, 00:19 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper attempts to explain each neuron with a graph representing sequences of tokens activating it. The approach consists of pruning, measuring importance by mapping salience of tokens to neurons, augmenting the data by replacing in the token with a masked language model, and building a graph to represent activating sequences. The sequences are empirically evaluated to show a middle ground between a precision-oriented baseline and a recall-oriented baseline.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nS1: This paper presents a novel method of explaining a neuron with a graph of activating sequences.\nS2: Similarly to some of the traditional explanation methods, this paper tries to understand neurons activities using a simpler model of tries, which simplified the evaluation and made the approach easier to understand.\nS3: The evaluation presents both strengths and weaknesses of the presented approach, as well as interesting trend between n-grams and precision/recall. In addition, they tried to explain activation trajectories and in-context learning using their approach.\nWeaknesses:\nW1: The evaluation is done on only one target model, so it is hard to predict if this can generalize.\nW2: The paper makes some assumptions without strong justifications. For example, the role of the neuron is understood based on high activation values, but some neurons can have functions when its activation values are low. Also, the paper seems to assume that the token positions are carried all the way to the last layer, but the neurons at that position can represent a totally different composite notion than the input token especially in the later layers.\nW3: The performance is not great.\nQuestions:\nQ1: What are the examples producing token specific activations in the early layers, and activations from abstract concept in the later layers? How can we tell them if they are specific or abstract?\nQ2: The explanation of x-axis \"Relative Token Index\" in Figure 2 seems to be missing.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes"}]}, "yGdoTL9g18": {"paper_info": {"Primary Area": "applications to physical sciences (physics, chemistry, biology, etc.)", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "factorized fourier neural operator, fourier neural operator, navier stokes, three-dimensional turbulence prediction", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "A Factorized Fourier Neural Operator based approach for the three-dimensional turbulence prediction around a cube.", "Abstract": "Neural Operators, particularly Fourier Neural Operators (FNO), have proven highly effective in simulating partial differential equations (PDEs), such as the Navier-Stokes equations. We propose the Residual Factorized Fourier Neural Operator (Res-F-FNO) for simulating three-dimensional (3D) flows, specifically focusing on flow dynamics around a cube. We extend the Factorized Fourier Neural Operator (F-FNO) architecture by incorporating additional residual connections. This change effectively reintroduces small-scale dynamic flows that may be lost due to truncated Fourier modes, resulting in improved accuracy when modeling wind fields. Our proposed Res-F-FNO model surpasses the performance of the standard F-FNO, achieving an error reduction of over 30% in simulating 3D flows. Furthermore, we propose the concept of a skip-corrector, to address the problem of accumulated errors over multiple time steps. The skip-corrector was specifically trained to predict the behaviour of turbulences at a considerably extended time interval. Incorporating the skip-corrector into the prediction process reduces the average error in simulating 100 time steps by more than 50%. Additionally, we adopt a modified training approach in which random time steps are chosen as the initial condition for each sample in every epoch, as opposed to generating a dataset by propagating each sample across all time steps. This leads to a significant reduction in the the number of training iterations required for the models to achieve convergence.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9242", "PDF Url": "https://openreview.net/pdf?id=yGdoTL9g18"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9242 by Area Chair RnQP", "Subheading": "Meta ReviewbyArea Chair RnQP05 Dec 2023, 14:21 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe authors propose a Factorized Neural Operator (FNO)-based architecture that extends the original FNO by incorporating an additional residual connection coupled with a small MLP corrector. They argue that this new architecture enables them to use larger timesteps, which in turn prevents error accumulation. The architecture is benchmarked on 3D turbulent flow around a cube. The authors perform ablation studies to demonstrate the improvements achieved by each component.\nThe reviewers agree that the method represents a minor modification of an existing approach. They find the evaluation, including the choice of baseline, to be overly narrow. Additionally, they deem the ablation studies inadequate and the computational savings unclear. The authors did not offer any feedback during the rebuttal stage, leaving all concerns unaddressed.\nDue to the lack of novelty, the narrow evaluation, and the unconvincing results, I recommend to reject.\nJustification For Why Not Higher Score:\nThe novelty is marginal, the architecture was tested in a single example, and only against other factorized FNO method.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9242 by Reviewer P4Hh", "Subheading": "Official ReviewbyReviewer P4Hh31 Oct 2023, 09:58 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper explores the introduction of a residual connection to the Factorized Fourier Neural Operator and evaluates this idea on a custom dataset of 118 simulations of turbulent flow around a 3D cube. It further explores the effect of simulating at a coarser time resolution (\"skip corrector\") and randomly subsampling the dataset each epoch to decrease the time it takes to train for one epoch (\"innovative training methodology\").\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nThe paper introducers a small novel dataset and compares against a baseline on a hold-out test set.\nWeaknesses:\nThe skip corrector contribution is misrepresented. Rather than correcting the output of the fine-grained F-FNO, it ignores the fine-grained predictions and simply solves the simulation in isolation at a coarser time resolution. The fine-grained F-FNO now just serves as a method to increase the temporal resolution of the coarse grained model. This is not correcting the fine-grained model, but instead augmenting the coarse grained model. Any error introduced by the coarse-grained model is propagated by the fine-grained model. This idea is orthogonal to the introduced residual connections (often called \"skip connections\" to further muddy the distinction) and distracts from the core contribution. If simulation at a coarse-grained time resolution is suitable for a problem, what is the point of additionally upsampling the temporal resolution?\nThe evaluation is limited by choosing only one system under limited starting condition variations. The PDE solving FNO literature has a wide variety of benchmarks, and the experimental section should be extended to provide evidence that the Res-F-FNO architecture is superior to the F-FNO model across more than one problem. It's not clear how the Res-F-FNO performs compared to F-FNO on a real-world generalization task.\nThe merit of the proposed novel training strategy is not explained. The definition of what constitutes an epoch is arbitrary and it's unclear if the new strategy reduces the number of FLOPs required to train the model to convergence, or by proxy, the number of samples the model sees.\nQuestions:\nThe choice of evaluating models at 500 and 2000 training epochs seems arbitrary. It would be better to choose a convergence metric and compare both models at their optimum. If not, can you justify the choice of these steps, and does this choice benefit one model over the other?\nHave you studied the discontinuities between the coarse-grained predictions and the adjacent last fine-grained predictions?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9242 by Reviewer 8Jew", "Subheading": "Official ReviewbyReviewer 8Jew30 Oct 2023, 18:58 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors introduce a neural operator that learns to simulate 3d turbulence flows. The main adaptations includes additional residual connections that preserve reference to small-scaled features amidst FNO's mode truncation, and a skip-corrector that brings useful information from an auxiliary solver such that the neural operator does not have to learn it. The authors perform evaluation on a 3d flow around a box and present ablation studies showing the effects of the introduced adaptations.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nThe authors study a 3-dimensional flow problem, which has good complexity and significance, although some important details from data generation is not included.\nWeaknesses:\nThe novelty in the idea, i.e. introducing additional residual connections and incorporating outputs from coarse solvers, is relatively marginal to me. Both of these have been widely used in various contexts and the latter seems to even create unphysical features (c.f. questions below) in the rollout.\nClarity - some important details missing including the setup of the turbulent flow problems and information on the auxiliary solver employed for the skip corrector (see questions below).\nBaselines - the proposed method is only compared against a factorized FNO model. The authors also include versions trained with 500 and 2000 epochs but it is unclear to me why the former is worth comparing as it is not fully trained.\nEvaluation is lacking - only normalized mean squared errors are shown. At the very least one would expect spectral metrics and example rollouts to be shown.\nQuestions:\nI do not quite follow \"selection of a random time step from the time interval of each sample during each iteration\" mentioned in the training strategy section (page 5, second last paragraph). Is this equivalent to just picking a random subsection of a long trajectory to use for training (which is quite standard and I'm unsure why it's worth highlighting)?\nDoes the way that the skip-corrector is set up not result in discontinuities on the steps it kicks in? This is even somewhat visible in Figure 5(a), where the red error curve has kinks every few steps.\nWhat does \"the turbulent flow ... is simulated until it reaches a state of convergence\" (page 4, first paragraph) mean? Do you mean statistical equilibrium? Also what are the initial conditions, boundary conditions, forcing and Reynolds number of the flow respectively?\nIn Figure 2a, 4b and 5b, why does the model perform better when the starting time step of prediction is small?\nComparing Figure 4a and 5a - it seems that the corrector makes a drastic difference in improving the metrics. This naturally prompts the question of whether the auxiliary solver is already providing most of the prediction skills and how much Res-F-FNO contributes? It would be useful to include the setup, error levels and stability characteristics of the auxiliary solver for reference.\nHow is the long term stability of the model when rolled for an indefinite number of time steps?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9242 by Reviewer UKe3", "Subheading": "Official ReviewbyReviewer UKe327 Oct 2023, 11:45 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis submission added an MLP in the skip-connection in the FNO spectral conv layer based on the Factorized FNO layer proposed in Tran et al. ICLR 2023, and used a \"corrector\" (with the same architecture) to restart the temporal prediction every few time steps. The method is then tested on a classical CFD benchmark problem. Due to a limited contribution from either theoretical or experimental aspect and lacking a detailed data description, this submission currently does not meet the bar of ICLR.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n1 poor\nStrengths:\nThis submission investigated an important topic in the cross section of CFD and data-driven methods. The simulation of NSE with high Reynolds number, especially in 3D, still remains to be a great challenge in the numerical PDE community. The benchmark problem featured (flow around a square cylinder confined in a channel) is also an important problem in CFD in terms of theoretical, experimental, and also for numerical simulation aspects. In fact, the obstacle being cubic makes this problem even harder (to simulate the vortices' interaction in both lateral and vertical direction).\nThe phase variable (obstacle or air) as an input feature channel is a good practice (and references should be given such as [KLY] below).\nA training strategy similar to DDPM is used temporally (however, no references are given on page 5).\n[KLY]: Y. Khoo, J. Lu, L. Ying, arXiv:1707.03351\nWeaknesses:\nThe author claimed the modification of FNO by adding two FFN layers are inspired by the Transformers. However, it has long been acknowledged that FNO resembles Transformers, and the skip-connection can be added, for example in [GMZ] (but the authors there did not make it a big deal and just updated the code, please check the official FNO GitHub repo\nmaster\nbranch commit\n9bc9516\n).\nNote the applying the tensorized architectures in Transformers to tackle the 3D NSE in the turbulent regime has been explored in [LSF], and Transformers for operator learning have a long list of references in NeurIPS/ICLR/ICML, but none of these are mentioned.\nThis submission copies the FNO paper's presentation on the neural architecture on the first half of the page 3, and therein the letter $t$ corresponds to the layers. Yet later, on page 5, $t$ now denotes the time.\nSimilarly, notational discrepancy applies to the $x$ variable. Throughout the presentation of the neural architecture, $x\\in D$, meanwhile $x$ also denotes the $x$-direction.\nApparently, the FFN's weight matrices $W_1$'s and $W_2$'s dimensions in Figure 1 are wrong.\nIn the channeled obstacle flow problem, the outflow boundary (the right side of the region in Figure 3) needs a special boundary condition. This goes unmentioned at all. In FNO and all its variants with no modification in this regard, periodical BC is used (and the vortices will be bounced back from the right boundary, not like what Figure 3 shows). This paper gives no specific change in this regard.\nContinue the point above, in this channeled obstacle flow problem, the real difficulty is whether a numerical scheme can handle the von K\u00e1rm\u00e1n vortices elegantly. Therefore, the computational domain reserves enough room in the outflow direction with respect to the obstacle. Yet, this paper just uses a square domain when viewed from the cross-section perspective. For example, please check classical papers on this issue such as Sohankar et al, Int. J. Numer. Methods Fluids 1998.\nThe study of the effect of additional residual connections on page 7 is way too superficial by just comparing the output to meet ICLR caliber, please check how ablation study for adding skip-connection should be conducted, for example in [HZRS] or more theoretically such as [OP] and [HWTZ].\nThe error convergence just shows that after maybe 100 epochs, the 20 times more computational cost to train the model gives marginal improvement in accuracy. How to justify this extra cost? If such computational resources can be exploited why not just use DNS?\n[GMZ]: Efficient token mixing for Transformers via adaptive Fourier neural operators, ICLR 2022.\n[LSF]: Scalable Transformer for PDE Surrogate Modeling, arXiv:2305.17560.\n[HZRS]: He et al., arXiv:1603.05027.\n[OP]: Orhan and Pitkow, ICLR 2018.\n[HWTZ]: Huang et al., Why Do Deep Residual Networks Generalize Better than Deep Feedforward Networks? NeurIPS 2021.\nQuestions:\nThe presentation on page 4 to 5 is unclear of how the skip-connection is exploited and what is skip-connected. For example, on page 4 it says \"add the output $\\mathcal{P}(a(x))$\" yet in Figure 1 it is \"$\\mathcal{P}(x)$\". If it is the case of the latter, that $\\mathcal{P}(\\cdot)$ is an MLP that maps $x\\in \\mathbb{R}^3$ to $\\mathbb{R}^3$ then this is just a function learner not an operator learner. Otherwise the presentation is plainly wrong. On page 5, it says \"the input is projected to a higher dimensional space by an FFN $\\mathcal{P}(x)$\", is $\\mathcal{P}(x)$ an FFN? What is its domain and range?\nThe data are said to be generated by OpenFOAM. However, no information is given for the equation used. Is it RANS or DNS? Reynolds number is not given either. The reason to present this is that the NSE benchmark in the FNO paper (and subsequent work) uses the streamfunction-vorticity formulation that is not attainable in 3D.  It says \"until it reaches a state of convergence\", but convergence in what? Is the flow becoming a steady-state? How the wind directions (I am assuming the authors meant to say the inflow boundary) are chosen?\nThe presentation of the skip-corrector is unclear. How to optimally select a discretization scheme?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes"}, {"Heading": "Official Review of Submission9242 by Reviewer zqsB", "Subheading": "Official ReviewbyReviewer zqsB13 Oct 2023, 05:20 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors propose a FNO based architecture which makes use of additional residual connections and the factorized FNO introduced in [1].  Moreover, a skip-corrector is introduced which essentially takes larger timesteps, which the authors argue is beneficial as it avoids accumulated errors. This architecture is trained on 3D turbulent flow around a cube, with ablations showing the improvements of each of these measures.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nthis dataset is a custom dataset and not many ML-based approaches have attempted to solve three-dimensional fluid flow problems.\nthe discussion on accumulated errors vs. taking large timesteps is intriguing.\nWeaknesses:\nthe architecture is hardly novel - apart from being an adapted version of [1], in my view this arrangement of residual connections (around the convolution + around the FNO layer + one large residual connection) have also been used in [2] and [3].\nIf I have misunderstood the novelty of the residual connections/missed sth., I would encourage the authors to clarify this better in their paper.\nthe design of the skip-corrector reminds me of the hierarchical time stepping scheme utilised in [4]. While the authors of [4] make similar arguments about accumulated errors vs. the error of making larger timesteps, this was not the main focus of their paper. I would have welcomed a more detailed analysis on the benefit of the skip-corrector here. Especially on the influence of the parameter $n$ - the timestep of the skip-corrector\nOverall, the experimental evaluation leaves a lot to be desired - experiments were performed on a single dataset with a single baseline (F-FNO). It is unclear to me how hyperparameters play into this. How does a regular FNO or a tensorized one [3] perform on this dataset?\nReferences\n[1] Alasdair Tran, Alexander Mathews, Lexing Xie, and Cheng Soon Ong. Factorized fourier neural operators, 2023.\n[2] Bonev B., Kurth T., Hundt C., Pathak, J., Baust M., Kashinath K., Anandkumar A.; Spherical Fourier Neural Operators: Learning Stable Dynamics on the Sphere; arXiv 2306.0383, 2023.\n[3] Neuraloperator library:\nhttps://github.com/neuraloperator/neuraloperator\n[4] K Bi, L Xie, H Zhang, X Chen, X Gu, Q Tian; Pangu-weather: A 3d high-resolution model for fast and accurate global weather forecast; arXiv preprint arXiv:2211.02556, 2022.\nQuestions:\nYou argue that it is beneficial to take large timesteps thus avoiding accumulation errors. Why not take as large of a timestep possible in this case?\nSurely there must be a \"golden middle\"? A study on the optimal skip timestep to take would be quite informative.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes"}]}, "Pp8Kb4hejU": {"paper_info": {"Supplementary Material": "zip", "Primary Area": "reinforcement learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "offline reinforcement learning, diffusion", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Offline Reinforcement Learning (RL) addresses the challenge of learning optimal policies from pre-collected data, making it a promising approach for real-world applications where online interactions with an environment are costly or impractical. We propose an offline RL method named Quantile-Guided Diffusion Policy~(qGDP), which trains a quantile network to label the training dataset and uses these labeled samples to train the diffusion model and generate new samples with the trained model according to classifier-free guidance.\nqGDP can adjust the preference of sample generation between imitating and improving behavioral policies by adjusting the input condition and changing the guidance scale without re-training the model, which will significantly reduce the cost of tuning the algorithm.\nqGDP exhibits exceptional generalization capabilities and allows easy adjustment of action generation preferences without model retraining, reducing computational costs. Experimental results on the D4RL dataset demonstrate state-of-the-art performance and computational efficiency compared to other diffusion-based methods.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9241", "PDF Url": "https://openreview.net/pdf?id=Pp8Kb4hejU"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9241 by Area Chair r6T6", "Subheading": "Meta ReviewbyArea Chair r6T609 Dec 2023, 15:27 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper presents an approach to condition a diffusion-model based behavior policy towards high rewarding actions by conditioning on quantiles of an estimated value function. The results on D4RL are kind of mixed (which could just be due to saturation of the benchmark), but I felt that the paper could deserve more analysis. In particular, the difference between this approach and IDQL is conditioning on quantiles vs weighting by advantages. This is equivalent to two changes -- (1) conditioning vs weighting, and (2) quantiles vs advantages. I felt that the paper didn't make a rigorous comparison of how each of these changes affects performance.\nThe analysis in Section 5 is interesting, but seems incomplete. The claims about hyperparameter tuning are not rigorous -- likely need to be shown and analyzed more carefully across a wide range of \"stress-test\" data compositions along with an rigorous explanation of why we would expect the method to be better at dealing with sensitivity. I personally do think that conditioning on quantiles can be quite nice and might have some of these benefits, but the analysis in the paper does not show this concretely.\nOverall, the reviewers made some good points as well, so I would encourage the authors to carefully go over their comments and revise the paper for the next conference. I personally think that a more analysis-focused vs methods-focused paper on some of these design choices (that I outlined above) could be quite nice for the community.\nJustification For Why Not Higher Score:\nOutlined in my meta review: lack of concrete contributions and significant impact\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9241 by Reviewer eP2Y", "Subheading": "Official ReviewbyReviewer eP2Y01 Nov 2023, 22:58 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper presents a novel offline Reinforcement Learning (RL) algorithm, Quantile-Guided Diffusion Policy (qGDP), which aims to learn optimal policies from pre-collected data without the need for costly or impractical online interactions. The qGDP method involves a quantile network for dataset labeling, and leverages labeled data to train a diffusion model, enabling sample generation for policy improvement or imitation. The flexibility of the qGDP is highlighted in its ability to modify action generation preferences without retraining, promising computational efficiency. Experimental validation is provided through the D4RL benchmark, where qGDP shows superior performance and efficiency relative to existing diffusion-based approaches.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe manuscript is well-structured, providing clear insight into the proposed method and its implications for offline RL.\nIt addresses an essential challenge in RL regarding behavior generation diversity, which is critical for robust policy learning.\nSection 5 effectively elucidates the distinct advantages of qGDP over other methods, offering valuable context and justification for the proposed approach.\nWeaknesses:\nThe paper lacks an introductory explanation of quantile networks and their relevance to the proposed method, potentially hindering comprehension for readers less versed in the domain. The authors are encouraged to elaborate on the concept and role of quantile networks within qGDP to provide readers with a foundational understanding of the methodology. An illustration to overview the entire work would be helpful.\nThe core innovation, applying quantile labels to guide the diffusion process, appears somewhat incremental, casting doubt on the method's novelty. Clarification on the specific novelties and contributions of qGDP  would be beneficial.\nThe introduction does not adequately articulate how qGDP surmounts the limitations of prior diffusion-based offline RL methods. It would be advantageous to outline explicitly how qGDP addresses the deficits of previous diffusion-based methods in the introduction.\nWhile informative, Section 5 may benefit from condensation to improve readability and maintain focus. Considering the length of Section 5, it is recommended to distill the content to the most salient points to maintain the reader's engagement and enhance clarity.\nQuestions:\nPlease refer to the weaknesses.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 22:00Everyone", "Content": "Comment:\nThanks for your feedback, and we would like to provide the following clarifications.\nQ: The paper lacks an introductory explanation of quantile networks and their relevance to the proposed method, potentially hindering comprehension for readers less versed in the domain...\nA: Thank you for your suggestions. The relevant explanations are provided below, and we will incorporate these details into the main text in the subsequent revisions\uff1a\nThe quantile network, proposed by Dabney et al.[1], is designed to describe the action value distribution for each state-action pair (i.e., estimating the values corresponding to different quantiles under this distribution). It constructs the corresponding Distributional Bellman Operator to improve the performance of DQN. IQL employs a similar approach to characterize the action value distribution under the behavioral policy, and uses the values corresponding to high quantile points as an approximate estimate for the optimal action. This helps in avoiding querying out-of-sample actions in the TD loss.\nIn this work, we utilize the quantile network to describe the distribution of action values under the behavioral policy, assign different labels to samples based on the value according to the quantiles, and finally use these labeled samples to train a diffusion model. This trained diffusion model is able to generate appropriate actions based on the input quantiles and guidance scales and exhibits different decision preferences.\n[1] Dabney W, Rowland M, Bellemare M, et al. Distributional reinforcement learning with quantile regression, Proceedings of the AAAI Conference on Artificial Intelligence. 2018, 32(1).\nQ: The core innovation, applying quantile labels to guide the diffusion process, appears somewhat incremental, casting doubt on the method's novelty. Clarification on the specific novelties and contributions of qGDP would be beneficial.\nA: Thank you for your suggestions. The main contributions of qGPD are as follows:\nHyperparameter tuning is the big problems that still lack a satisfying solution.[2] Most offline RL methods select the optimal hyperparameters by evaluating the performances of models trained with different hyperparameters by interacting with the environment[3]. This implies that these methods require repeating the training process much times. Our approach achieves a behavior-controllable policy with just one training iteration. By adjusting the input quantile and guidance scale, this policy can be biased towards generating actions with higher estimated values or towards actions that closely resemble the behavioral policy. \n[2] Levine S, Kumar A, Tucker G, et al. Offline reinforcement learning: Tutorial, review, and perspectives on open problems[J]. arXiv preprint arXiv:2005.01643, 2020.\n[3] Prudencio R F, Maximo M R O A, Colombini E L. A survey on offline reinforcement learning: Taxonomy, review, and open problems[J]. IEEE Transactions on Neural Networks and Learning Systems, 2023.\nQ: The introduction does not adequately articulate how qGDP surmounts the limitations of prior diffusion-based offline RL methods. It would be advantageous to outline explicitly how qGDP addresses the deficits of previous diffusion-based methods in the introduction.\nA: Thank you for your suggestions. The limitations of prior diffusion-based offline RL methods and the advantages of qGDP are listed below:\na. IDQL increases the probability of the diffusion model generating high-value actions by reweighting samples, so it cannot generate samples with higher values outside the dataset. In contrast, qGDP learns the probability distribution of actions conditioned on different quantiles, thus qGDP can output action distributions corresponding to higher action values (associated with quantile inputs greater than 1).\nb. DQL uses the Q-network to guide the training of the diffusion model, so it involves computing gradients for a relatively deep neural network. qGDP is designed to train the diffusion model to generate samples at different quantiles, so the computational cost of qGDP is comparable to that of a regular Diffusion model.\nc. Adjusting the generation preference in other diffusion-based offline RL methods requires retraining the model, whereas qGDP only requires changing the model's input. This significantly reduces the computational cost required for parameter tuning."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 22:00Everyone", "Content": "Comment:\nQ\uff1aWhile informative, Section 5 may benefit from condensation to improve readability and maintain focus. Considering the length of Section 5, it is recommended to distill the content to the most salient points to maintain the reader's engagement and enhance clarity.\nA: Thank you for your suggestions. The main conclusions from Section 5 are as follows:\n1 Each approach can generally approximate the distribution in the dataset or maximize the value of generated samples by adjusting hyperparameters.\n2 For Diffuser, the highest-value samples on the Middle dataset do not correspond to the largest guidance scale\n3 IDQL is unable to generate unseen, potentially high-value samples based on changes in the reward function\u2019s trends.\n4 For qGDP-Q and qGDP-GeQ, when inputting values greater than 1., they can generate samples of higher value based on the reward function\u2019s changing trends."}, {"Heading": "Official Comment by Reviewer eP2Y", "Subheading": "Official CommentbyReviewer eP2Y22 Nov 2023, 20:41Everyone", "Content": "Comment:\nThanks much for your feedback! Some of my concerns are addressed. However, for the question of the core innovation, I am not convinced that Hyperparameter tuning is the core contribution of this work. First, while it can generate behaviors with different performance, the training of the model itself still needs tuning its hyper parameters. Second, the method introduce extra hyper-parameters, like the number of the quantiles. Third, it seems like that in your manuscript, there is not sufficient description, discussion, and empirical analysis to support this point. As a result, I will maintain my score."}]}, {"Heading": "Official Review of Submission9241 by Reviewer nVWg", "Subheading": "Official ReviewbyReviewer nVWg31 Oct 2023, 04:26 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a novel offline RL algorithm qGDP using quantile labeling and conditional diffusion models. It shows competitive results on D4RL benchmarks compared to other diffusion-based methods. The approach allows tuning action distributions without retraining. However, there are some limitations in justifying the quantile conditioning and comparing against other offline RL methods.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nAchieves state-of-the-art results among diffusion-based offline RL methods on D4RL.\nNovel approach of conditioning diffusion on quantile labels for offline RL.\nAllows flexible tuning of action distributions without retraining.\nWeaknesses:\nThe quantile labels rely on the action values Q learned by IQL, which may have overestimation bias. Errors in Q would propagate to incorrect quantile labels, which could be amplified for higher quantiles. This could negatively impact the quality of the diffusion model training.\nThe quantile input y for guiding the diffusion model is constrained to the range [0,1] or not ?  It will limit the scope of behavioral patterns that can be generated. Values greater than 1 may allow more generalization, but this is not explored. And I expected to find the experiment results of different value of y for different generation, but failed.\nWhile the quantile input is motivated by IDQL, the paper does not sufficiently differentiate the advantages of the quantile mechanism compared to IDQL itself. The paper does not sufficiently differentiate the advantages of the quantile input compared to just using weighted actions like in IDQL. The results between qGDP and IDQL in Table 1 are fairly close. More analysis is needed to clearly explain the relationship between the two methods and highlight the unique benefits of the quantile inputs.\nThe paper over-emphasizes the impact of tuning the guidance scale, even though adjusting the scale for diversity is intrinsic to diffusion models themselves. However, the main innovation of the paper is using the quantile network to label samples and train the diffusion policy conditioned on quantiles. More analysis is needed on how the quantile inputs specifically affect diversity, rather than just tuning the guidance scale which is a general feature of diffusion models.\nIn Table 4, the runtime of the proposed offline RL algorithm qGDP is compared to the older online RL algorithm DQL? I cannot get the meaning of this comparison.  For a fair runtime comparison, it would make more sense to compare against other recent offline RL algorithms such as IDQL.\nQuestions:\nPlease see the above weakness and address my concerns.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 22:01Everyone", "Content": "Comment:\nThanks for your feedback, and we would like to provide the following clarifications.\nQ: The quantile labels rely on the action values Q learned by IQL, which may have overestimation bias. Errors in Q would propagate to incorrect quantile labels, which could be amplified for higher quantiles. This could negatively impact the quality of the diffusion model training.\nA: Thank you for your question. \nIn our code implementation, we have utilized the Clipped Double Q-learning technique provided by TD3[1] to mitigate Overestimation Bias. \n[1] Fujimoto S, Hoof H, Meger D. Addressing function approximation error in actor-critic methods[C]//International conference on machine learning. PMLR, 2018: 1587-1596.\nQ: The quantile input y for guiding the diffusion model is constrained to the range [0,1] or not ? It will limit the scope of behavioral patterns that can be generated. Values greater than 1 may allow more generalization, but this is not explored. And I expected to find the experiment results of different value of y for different generation, but failed.\nThe paper over-emphasizes the impact of tuning the guidance scale, even though adjusting the scale for diversity is intrinsic to diffusion models themselves. However, the main innovation of the paper is using the quantile network to label samples and train the diffusion policy conditioned on quantiles. More analysis is needed on how the quantile inputs specifically affect diversity, rather than just tuning the guidance scale which is a general feature of diffusion models.\nA: Thank you for your question. \nThe quantile input can take values larger than 1. In Figure 3, we visualize the generation results of qGQP under different guidance scales and quantile inputs. In each subfigure, points of different colors represent generated samples for quantile inputs y=0.5, 0.7, 1.0, and 1.3. The figure is evident that qGQP exhibits strong generalization capabilities, generating samples not present in the dataset and consistent with the underlying trend.\nFurthermore, on the D4RL dataset, we experimented with different quantile inputs. The results indicate that both quantile input and guidance scale significantly impact the algorithm's performance, as shown in Figure 4.\nQ: While the quantile input is motivated by IDQL, the paper does not sufficiently differentiate the advantages of the quantile mechanism compared to IDQL itself. The paper does not sufficiently differentiate the advantages of the quantile input compared to just using weighted actions like in IDQL. The results between qGDP and IDQL in Table 1 are fairly close. More analysis is needed to clearly explain the relationship between the two methods and highlight the unique benefits of the quantile inputs.\nA: Thank you for your suggestions. \nqGDP has two main advantages over IDQL: Firstly, IDQL increases the probability of the diffusion model generating high-value actions by reweighting samples. So it cannot generate samples with higher values outside the dataset. In contrast, qGDP learns the probability distribution of actions conditioned on different quantiles. Therefore, when the true action value function changes smoothly, qGDP can output action distributions corresponding to higher action values (associated with quantile inputs greater than 1). Secondly, adjusting the generation preference in IDQL requires retraining the model, whereas qGDP only requires changing the model's input. This significantly reduces the computational cost required for parameter tuning.\nOn the locomotion-v2 task set and the tasks of antmaze-umaze-v0 and antmaze-umaze-diverse-v0, our method significantly outperforms IDQL. In the remaining tasks, the reason for qGDP being weaker than IDQL may be attributed to the excessively large state space. The probability of each state being labeled with different labels significantly decreases, leading to insufficient training for quantile-guided diffusion."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 22:07Everyone", "Content": "Comment:\nQ: In Table 4, the runtime of the proposed offline RL algorithm qGDP is compared to the older online RL algorithm DQL? I cannot get the meaning of this comparison. For a fair runtime comparison, it would make more sense to compare against other recent offline RL algorithms such as IDQL.\nA: Thank you for your suggestions. \nWe test the release codes of DQL, IDQL, and SfB with the halfcheetah-medium-v2 task on a single RXT 2080Ti graphics card, and their runtimes are compared below:\nmethod  | critic                             | actor | sampling | total\nDQL        | 8.6ms$\\times$2e6     | 12.4ms$\\times$2e6 | 51.2s$\\times$40 | 12.9h\nIDQL      |               3.3ms$\\times$1.5e6 (critic and actor) | 70.0$\\times$6 | 1.5h\nSfBC      | 68.4ms$\\times$4.9e4 | 39.1ms$\\times$5.9e5 | 50.6s$\\times$20 | 7.6h\nqGDP     | 9.3ms$\\times$4e5      | 5.9ms$\\times$4e5 | 10.0s$\\times$70 | 2.0h\nwhere, 'critic,' 'actor,' and 'sampling' respectively refer to the time spent on value function training, policy function training, and interacting with the environment of these algorithms. The recorded form of these terms is the time required for a single update of the value function multiplied by the number of updates, the time required for a single update of the policy function multiplied by the number of updates, and the time required for model evaluation (10 interactions with the environment) multiplied by the number of evaluations.\nIt should be noted that IDQL is implemented based on JAX, resulting in shorter runtimes. In comparison, both qGDP and DQL are implemented in PyTorch. Specifically, in the actor update phase (related to training the diffusion model), qGDP exhibits significantly shorter runtime compared to DQL. During the model evaluation phase, qGDP reduces time consumption through parallelization.\nMost importantly, the presented runtimes for DQL, IDQL, and SfBC are for a single run. If hyperparameter tuning is required, they would incur several times more runtime. In contrast, qGDP has completed hyperparameter tuning during the 70 model evaluation runs."}, {"Heading": "Thanks for the response.", "Subheading": "Official CommentbyReviewer nVWg22 Nov 2023, 23:17Everyone", "Content": "Comment:\nThanks much for your response!\nYou make fair points around qGDP's advantages in generalization and computational efficiency over IDQL. However, the performance between qGDP and IDQL on many tasks is still fairly close. I would like to see deeper analysis explaining why qGDP lags behind IDQL on some tasks and more clearly differentiating the unique benefits of the quantile mechanism.\nThe diversity primarily stems from interpolating between conditioned policy generations, rather than exhibiting more fundamentally novel behaviors. The novelty seems somewhat incrementally limited.\nOverall, while the rebuttal helps clarify some points, I believe my original major concerns around understanding the impact of the quantile inputs and comparing to IDQL still remain. As such, I would like to maintain my original review score."}]}, {"Heading": "Official Review of Submission9241 by Reviewer 1jYd", "Subheading": "Official ReviewbyReviewer 1jYd28 Oct 2023, 17:30 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a modification of IDQL with an additional quantile network for offline RL setting. The quantile network predicts values at different quintiles at the same time, thus avoiding re-training when selecting the optimal quantile value. The experiments are evaluated on two domains of D4RL tasks and show superior performance over IQL, IDQL, DQL, etc. I think the proposed method is a quite straightforward generalization of IDQL and the only novelty is the quantile network, which provides some convenience for hyperparameter searching over the quantile value. Some statements need to be further justified.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe writing is clear and the method is described well.\nThe experiments on bandit and D4RL are thorough, demonstrating the difference of the proposed methods over the previous ones.\nThe performance of the proposed algorithms beats previous SOTA results, but mostly by small margins.\nWeaknesses:\nOne of my major concerns is as follows. One main advantage of the proposed method is that it can extrapolate high-value samples outside the training distributions based on the reward function\u2019s trend. However, why is this valid for offline RL settings? The values of out-of-distribution samples are usually penalized as the pessimism of value estimation in order to achieve conservative and best performant policies in online evaluation. Please justify why simple extrapolation based on the trends of reward function is valid. One can easily construct a counterexample to make qGPD totally failed in the bandit example, by setting a first increasing then suddenly decreasing reward structure, e.g., by letting the purple regions in Fig. 3 (c)(f) to have very low reward values.\nAnother problem bothers me is the performance improvement over IDQL. From what I understand, the qGDP only improves over IDQL by predicting over more quantiles, so why the performance of qGDP can be better than IDQL if the quantiles considered for two methods are the same, or is the improvement just caused by qGDP searches over a larger space of quantiles or with a smaller grid size? If the improvement mainly comes from this, I cannot be convinced that qGDP is a very novel method.\nSome minor suggestions:\nPlease illustrate more clearly about the output structure of the quantile network and the choice of N.\nPlease indicate what is the hyperparameter (quantile or guidance) in the caption of Fig. 2 \n, also provide ground truth distributions in Fig. 2.\nQuestions:\nIn section 4, what does the equation $V_\\eta^i(s)i=1^N$ mean? I don\u2019t get this one.\nIn Eq. (11), why is the quantile loss different from Eq. (8)?\nIn Sec. 6.4, why is qGDP faster than DQL? Please provide more explanations.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 22:09Everyone", "Content": "Comment:\nThanks for your feedback, and we would like to provide the following clarifications.\nQ: One of my major concerns is as follows. One main advantage of the proposed method is that it can extrapolate high-value samples outside the training distributions based on the reward function\u2019s trend. However, why is this valid for offline RL settings? The values of out-of-distribution samples are usually penalized as the pessimism of value estimation in order to achieve conservative and best performant policies in online evaluation. Please justify why simple extrapolation based on the trends of reward function is valid. One can easily construct a counterexample to make qGPD totally failed in the bandit example, by setting a first increasing then suddenly decreasing reward structure, e.g., by letting the purple regions in Fig. 3 (c)(f) to have very low reward values.\nA: Thank you for your question. \nIn practical applications of offline RL [1][2], it is typically allowed to interact with the environment to a limited extent. In these scenarios, we can utilize these interactions to select appropriate input quantile. In settings where \u201da reward structure first increases and then suddenly decreases\u201d, we can also adjust the input quantiles to a suitable value through a small number of interactions to avoid generating samples with low rewards. If applying qGDP to a scenario where online interaction is impractical, we can directly constrain the input quantiles to be less than 1.\n[1] Fang, Xing, et al. Offline Reinforcement Learning for Autonomous Driving with Real World Driving Data. IEEE 25th International Conference on Intelligent Transportation Systems (ITSC). IEEE, 2022.\n[2] Singh, Avi & Yu, Albert & Yang, Jonathan & Zhang, Jesse & Kumar, Aviral & Levine, Sergey. COG: Connecting New Skills to Past Experience with Offline Reinforcement Learning. 4th Conference on Robot Learning (CoRL 2020).\nQ: Another problem bothers me is the performance improvement over IDQL. From what I understand, the qGDP only improves over IDQL by predicting over more quantiles, so why the performance of qGDP can be better than IDQL if the quantiles considered for two methods are the same, or is the improvement just caused by qGDP searches over a larger space of quantiles or with a smaller grid size? If the improvement mainly comes from this, I cannot be convinced that qGDP is a very novel method.\nA: Thank you for your question. \nqGDP has two main advantages over IDQL: Firstly, qGDP has generalization capabilities and can generate samples with quantiles greater than 1, while IDQL cannot operate when the quantile is greater than 1. As explained in Section 5, the samples generated by qGDP align with the trend of action values (or rewards), and Section 6.2 demonstrated that qGDP performs better in some tasks when the input quantile is greater than 1. Secondly, adjusting the generation preference in IDQL requires retraining the model, whereas qGDP only requires changing the model's input. This significantly reduces the computational cost required for parameter tuning."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 22:12Everyone", "Content": "Comment:\nQ: Please illustrate more clearly about the output structure of the quantile network and the choice of N.\nA: Thank you for your suggestions.\nThe quantile network is a 4-layer fully connected neural network with the width of 256.\nN=101\nQ: Please indicate what is the hyperparameter (quantile or guidance) in the caption of Fig. 2 , also provide ground truth distributions in Fig. 2.\nA: Thank you for your suggestions.\nFor Diffuser, this hyperparameter represents the weight $\\lambda$ of the gradient guidance term in the Guided Diffusion generation process $a^i\u223cN(\u03bc+\u03bb\u2207J(\u03bc),\u03a3)$.\nFor DQL, this hyperparameter represents the guidance weight $\\lambda$ when using the Q-network to guide the Diffusion model update $\\arg\u2061min\u2061 L_{diff} (\u03b8)-\\lambda E_{a^0\u223cdiff(\u03b8)} Q(s,a^0) $.\nFor IDQL, this hyperparameter represents the reciprocal of the temperature coefficient $\\lambda$ in the sample-weighted term $exp(\u03bb\u22c5Advantage)$.\nFor qGDP, this hyperparameter represents the input quantile in the quantile-guided diffusion generation process.\nThe results in Fig. 2 are generated based on the toy datasets, as illustrated in Fig. 1. This experiment is primarily conducted for a qualitative analysis of the impact of hyperparameters on the results produced by different methods. The goal is to assess whether these methods exhibit generalization capabilities and to examine the effects of hyperparameters on the generated results, so there is no explicit ground truth distribution in this experiment.\nQ: In section 4, what does the equation mean? I don\u2019t get this one.\nA: I\u2019m sorry. This is a writing error, it should be $V_{\\eta}^i (s)$.\nQ: In Eq. (11), why is the quantile loss different from Eq. (8)?\nA: Thank you for your question.\nThe form of Eq. (8) is primarily used for assessing action values, while the form in Eq. (11) is employed to obtain values corresponding to different quantiles. Under the form of Eq. (11), the distribution of values corresponding to quantiles is more uniform.\nQ: In Sec. 6.4, why is qGDP faster than DQL? Please provide more explanations.\nA: Thank you for your question.\nWhen DQL uses the Q-network to guide the training of the diffusion model, it treats the generation process of the Diffusion model as a policy network of size d*N and optimizes it through gradient backpropagation, where d is the depth of the neural network in the diffusion model, and N is the number of diffusion timesteps. In other words, DQL involves computing gradients for a relatively deep neural network. qGDP is designed to train the diffusion model to generate samples at different quantiles. Therefore, the computational cost of qGDP is comparable to that of a regular Diffusion model."}, {"Heading": "Official Comment by Reviewer 1jYd", "Subheading": "Official CommentbyReviewer 1jYd22 Nov 2023, 12:56Everyone", "Content": "Comment:\nThanks for the response.\nFirst, the paper can be modified during the rebuttal phase.\nOffline training with online interaction will be a very different setting than purely offline training, and it is not verified in the paper. So the answer is not valid for the effectiveness of extrapolation with only offline training.\nground truth in Fig. 2\nI indicate the ground truth by dataset distribution.\nIn Eq. (11), why is the quantile loss different from Eq. (8)?\nI still don't understand why the loss form in terms of $u$ has to be different.\nIn other words, DQL involves computing gradients for a relatively deep neural network.\nDoes it indicate the qGDP is using a smaller network? If not, why is it faster, both qGDP and DQL are diffusion policies.\nGiven above unsolved questions, I will not the change the score."}]}, {"Heading": "Official Review of Submission9241 by Reviewer Rvvy", "Subheading": "Official ReviewbyReviewer Rvvy23 Oct 2023, 20:10 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes to train a diffusion policy from offline data conditional on the output of a pretrained quantile network. This allows actions to be naturally biased to be higher quality without the need to take gradients through a Q-network at test-time. The resulting approach is validated on the D4RL benchmark, with comparable performance with the prior SOTA.\nSoundness:\n3 good\nPresentation:\n4 excellent\nContribution:\n3 good\nStrengths:\nThe problem setting is well-motivated and a natural extension of prior work.\nThe paper enables a classifier-free method to increase the quality of actions sampled at test-time. This significantly improves inference time over the baseline.\nClear presentation of the algorithm and informative toy experiments.\nWeaknesses:\n(Unclear empirical benefit)\nWhilst the paper shows a strong improvement on speed, the empirical benefit of the approach is unclear, as there is only a slight gain over the baseline DQL. This is compounded by the fact that the main empirical evaluation in Section 6.1 maximizes over an extremely large 70 different hyperparameter configurations, which is extremely unrealistic for offline reinforcement learning. Coupled with the sweep in Figure 4, the main empirical evaluation is likely maximizing over statistical noise. The results over a smaller hyperparameter space in Section 6.3 do not show a clear improvement.\n(Quantitative metric of success in toy experiments)\nWhilst the authors helpfully compare the effect of different guidance and sampling schemes on their toy dataset in Figure 2-3, it is unclear what the optimal or desired behavior is. It would be helpful to include some indication of what the optimal behavior should be and some kind of metric to assess this (e.g. conforming to some desired distribution).\n(Incomplete speed discussion)\nWhilst Table 4 shows an improvement over DQL, it would be also valuable to compare runtime to related approaches, IDQL and SfBC. Furthermore, details are missing on which environment exactly is being timed in the table.\nMinor:\nFigure 1 is presented without context, which is confusing for the readers. The authors should include the purpose of these datasets in the description.\nAxis labels and text in Figure 2,3,4 are very small and hard to read.\nOverall summary totals in Tables 1, 2, 3 should also have standard deviation. Given the mild improvement over the baseline, it would also be valuable to perform RLiable [1] analysis to assess the statistical significance of the method.\n[1] Deep RL at the Edge of the Statistical Precipice. Agarwal et al. NeurIPS, 2021.\nQuestions:\nI would greatly appreciate responses and rebuttals to the concerns raised in the weaknesses section.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors17 Nov 2023, 22:14Everyone", "Content": "Comment:\nThanks for your feedback, and we would like to provide the following clarifications.\nQ: (Unclear empirical benefit) Whilst the paper shows a strong improvement on speed, the empirical benefit of the approach is unclear, as there is only a slight gain over the baseline DQL. This is compounded by the fact that the main empirical evaluation in Section 6.1 maximizes over an extremely large 70 different hyperparameter configurations, which is extremely unrealistic for offline reinforcement learning. Coupled with the sweep in Figure 4, the main empirical evaluation is likely maximizing over statistical noise. The results over a smaller hyperparameter space in Section 6.3 do not show a clear improvement.\nA: Thank you for your suggestions.\nIDQL's experimental results are quoted from the result of IDQL-A. \"-A\" is refered as reported results that allow any amount of tuning and \"-1\" as results that only allow one hyperparameter to be tuned between domains[1]. And IDQL-1's results are only 1150.9. \nSo, the performance of qGDP, 1220.6, in a smaller hyperparameter space is sufficiently good.\n[1] Hansen-Estruch P, Kostrikov I, Janner M, et al. Idql: Implicit q-learning as an actor-critic method with diffusion policies. arXiv preprint arXiv:2304.10573, 2023.\nQ: (Quantitative metric of success in toy experiments) Whilst the authors helpfully compare the effect of different guidance and sampling schemes on their toy dataset in Figure 2-3, it is unclear what the optimal or desired behavior is. It would be helpful to include some indication of what the optimal behavior should be and some kind of metric to assess this (e.g. conforming to some desired distribution).\nA: Thank you for your suggestions.\nThe results in Fig. 2 are generated based on the toy datasets, as illustrated in Fig. 1. This experiment is primarily conducted for a qualitative analysis of the impact of hyperparameters on the results produced by different methods. The goal is to assess whether these methods exhibit generalization capabilities and to examine the effects of hyperparameters on the generated results, so there is no specific desired distribution.\nQ: (Incomplete speed discussion) Whilst Table 4 shows an improvement over DQL, it would be also valuable to compare runtime to related approaches, IDQL and SfBC. Furthermore, details are missing on which environment exactly is being timed in the table.\nA: Thank you for your suggestions.We test the release codes of DQL, IDQL, and SfB with the halfcheetah-medium-v2 task on a single RXT 2080Ti graphics card, and their runtimes are compared below:\nmethod  | critic                             | actor | sampling | total\nDQL        | 8.6ms$\\times$2e6     | 12.4ms$\\times$2e6 | 51.2s$\\times$40 | 12.9h\nIDQL      |               3.3ms$\\times$1.5e6 (critic and actor) | 70.0$\\times$6 | 1.5h\nSfBC      | 68.4ms$\\times$4.9e4 | 39.1ms$\\times$5.9e5 | 50.6s$\\times$20 | 7.6h\nqGDP     | 9.3ms$\\times$4e5      | 5.9ms$\\times$4e5 | 10.0s$\\times$70 | 2.0h\nwhere, 'critic,' 'actor,' and 'sampling' respectively refer to the time spent on value function training, policy function training, and interacting with the environment of these algorithms. The recorded form of these terms is the time required for a single update of the value function multiplied by the number of updates, the time required for a single update of the policy function multiplied by the number of updates, and the time required for model evaluation (10 interactions with the environment) multiplied by the number of evaluations.\nIt should be noted that IDQL is implemented based on JAX, resulting in shorter runtimes. In comparison, both qGDP and DQL are implemented in PyTorch. Specifically, in the actor update phase (related to training the diffusion model), qGDP exhibits significantly shorter runtime compared to DQL. During the model evaluation phase, qGDP reduces time consumption through parallelization.\nMost importantly, the presented runtimes for DQL, IDQL, and SfBC are for a single run. If hyperparameter tuning is required, they would incur several times more runtime. In contrast, qGDP has completed hyperparameter tuning during the 70 model evaluation runs."}, {"Heading": "Thanks for the repsonse", "Subheading": "Official CommentbyReviewer Rvvy22 Nov 2023, 12:58Everyone", "Content": "Comment:\nThank you for the response, the clarifications on the runtime are useful for evaluating your algorithm. I will maintain my currrent score."}]}]}, "FI0vOp2asx": {"paper_info": {"Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "snapshot compressive imaging, hyperpectral imaging, prompt learning, federated learning", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "Spectral snapshot compressive imaging (Spectral SCI) applies an optical encoder to compressively capture 2D measurements, followed by which the 3D hyperspectral data can be restored via training a deep reconstruction network. Existing reconstruction models are generally trained with a single well-calibrated hardware instance, making their performance vulnerable to hardware shifts and limited in adapting to multiple hardware configurations. To facilitate cross-hardware learning, previous efforts attempt to directly collect multi-hardware data and perform centralized training, which, however, is impractical due to severe user data privacy concerns and hardware heterogeneity across different platforms/institutions. In this study, we explicitly consider data privacy and heterogeneity in cooperatively optimizing spectral SCI systems by proposing a novel Federated Hardware-Prompt learning (FedHP) framework. Rather than mitigating the client drift by rectifying the gradients, which only takes effect on the learning manifold but fails to solve the heterogeneity rooted in the input data space, FedHP learns a hardware-conditioned prompter to align inconsistent data distribution across clients, serving as an indicator of the data inconsistency among different coded apertures. Extensive experiments demonstrate that the proposed FedHP coordinates the pre-trained model to multiple hardware configurations, outperforming prevalent FL frameworks for 0.35dB under challenging heterogeneous setting. Moreover, a new Snapshot Spectral Heterogeneous Dataset (SSHD) has been built upon multiple practical spectral SCI systems. We will release the data and code to enrich further exploration of this practical computational imaging problem.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9239", "PDF Url": "https://openreview.net/pdf?id=FI0vOp2asx"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:52 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9239 by Program Chairs", "Subheading": "Meta ReviewbyProgram Chairs05 Dec 2023, 03:34 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis Meta-Review is written by the Program Chairs.\nThe paper proposes FedHP, a federated learning-based approach for spectral snapshot compressive imaging (SCI) that includes a measurement enhancement network. It has been reviewed by four individuals, receiving mixed assessments, especially after reviewer calibration and downweighting of multiple inflated and non-informative reviews.\nThere were numerous concerns:\nLimited Generalizability: Reviewers expressed concerns about the paper's limited contribution to general computational imaging and the marginal novelty in the deep learning community.\nUncertainty in Methodology: There is skepticism about the novelty and effectiveness of the learning-based module proposed for model correction, with a lack of clear evidence for its robustness to distribution shifts.\nExperimentation and Comparison: While comprehensive, the experiments are deemed insufficient in some respects, lacking comparisons with a broader range of methods and datasets.\nThe author responses addressed these issues somewhat, but ultimately the paper was borderline, and the decision is to reject at this time.\nJustification For Why Not Higher Score:\nSee meta-review\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9239 by Reviewer 99wV", "Subheading": "Official ReviewbyReviewer 99wV01 Nov 2023, 15:43 (modified: 22 Nov 2023, 17:36)EveryoneRevisions", "Content": "Summary:\nMotivated by recent success of Federated Learning (FL) and Prompt Tuning, this paper proposes a deep neural network framework, named as FedHP, that can take into account diverse sensor acquisitions for spectral snapshot compressive imaging (Spectral SCI). The primary distinction from existing FL methods lies in the inclusion of a measurement enhancement network that considers both degraded observations and the physical forward model pattern across clients. Experimental results demonstrate its effectiveness of FedHP on both simulation dataset and real-world SCI dataset.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\n1), This paper is overall well written and easy to flow. It clearly introduces the motivation and problem formulation, making the method accessible to non-SCI experts.\n2), Both simulation and real-world datasets are considered, making a better practical contribution.\n3), The experimental comparison is comprehensive, and baseline methods are up to date.\nWeaknesses:\n1), The technical contribution to more general computational imaging seems to be limited or at least not well supported by this paper\u2019s current state.\n2), Likewise, the main deep learning technic behind this proposal, FedAvg, is already well known, which makes the technical contribution to deep learning community also marginal.\n3), The idea of using another learning-based module that can consider additional forward-model settings seems not new to model-based deep learning methods for computational imaging. Moreover, it is difficult to evaluate the proposed \u201ccorrection\u201d module indeed robust to distribution shift. At least, there is no clear evidence presented in this paper.\nQuestions:\n1), Figure 1. It is difficult to find differences between 4. FedAvg and 5. FedHP, the method instruction plot.\n2), The authors did not discuss a lot about why their method robust to the codec pattern shift, both intuitively and theoretically. What if the new module $\\phi$ cannot handle very new coded aperture $\\bf M$?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 17:51 (modified: 21 Nov 2023, 11:45)EveryoneRevisions", "Content": "Comment:\nWe appreciate that Reviewer 99wV finds our method easy to follow, provides comprehensive comparison, and is well presented!\nWeakness 1\n: The technical contribution to more general computational imaging seems to be limited or at least not well supported by this paper\u2019s current state.\nA1\n: Thanks for the valuable comments!\nOur key technical contribution is to provide a new multi-hardware optimization framework adapting to hardware shift by only accessing local data.  The principle underlying the proposed FedHP can be potentially extended to broad SCI applications. However, due to the practical cost of data acquisition and building optics systems, this study explores one specific direction following previous works in the field, where we focus on spectral SCI and collecting optical masks and real data from multiple hardware.\nExploiting the hardware collaboration of computational imaging systems is still in an early stage. This work serves as a proof of concept to inspire future endeavors in a more general scope. We list several potential related applications that might benefit from the proposed method, such as Lensless camera [1], LiDAR [2], HDR camera [3], or CT-Reconstruction [4], cooperating multiple imaging systems via aligning forward models, etc. We have put this discussion into the related work.\nWeakness 2\n: FedAvg, is already well known, which makes the technical contribution to deep learning community also marginal.\nA2\n: Thanks for the useful comments!\nWe find that FedAvg serves as a very strong baseline by even working better than recent  FL methods, such as SCAFFOLD and FedProx. Thus, it is non-trivial to achieve further performance boost. By comparison, FedHP provides an encouraging performance.\nWe kindly summarize the technical contributions of this work as follows:\nWe introduce a hardware prompt network to capture the hardware perturbations/replacement.\nWe improve the efficiency of the  federated learning in SCI, achieving performance boost with much lower training time cost.\nWe collect and will release a heterogeneous dataset that covers multiple hardware configurations, which to the best knowledge, is the first one in SCI.\nWeakness 3\n: The idea of using another learning-based module that can consider additional forward-model settings seems not new to model-based deep learning methods for computational imaging. Moreover, it is difficult to evaluate the proposed \u201ccorrection\u201d module indeed robust to distribution shift. At least, there is no clear evidence presented in this paper.\nA3\n: Thanks for the valuable suggestion!\nFirstly, we compared with a state-of-the-art model-based method of GAP-Net [5] in Table 4b. We find that the proposed method brings a notable performance boost ($+0.28$dB/$0.0038$ in PSNR/SSIM) with a much smaller model size.  Secondly, we provide empirical evidence that the proposed method can handle new masks from distinct distributions in Table 2. During training, masks from different clients are sampled from different distributions. During testing, we randomly sample non-overlapping masks (unseen to models) from different distributions of all clients.\nQuestions 1\n: Figure 1. It is difficult to find differences between 4. FedAvg and 5. FedHP, the method instruction plot.\nA4\n: Thanks for the useful suggestion!\nFig. 1 aims to show different settings for different types of solutions. For federated learning methods including FedAvg and FedHP, we make the settings the same to avoid misunderstanding. We have made it clear by modifying the Fig.1 captions.\nQuestion 2\n: Authors did not discuss a lot about why their method robust to the codec pattern shift, both intuitively and theoretically. What if the new module $\\phi$ cannot handle very new coded aperture $\\mathbf{M}$?\nA5\n: Thanks for the valuable insight\uff01\nIntuitively, one of the key reasons why the proposed method can handle coded aperture shifts lies in the design of the hardware prompt learning model.  The hardware prompt learning aligns the input data distributions, solving the heterogeneity rooted in the input data space. We have provided the above discussion in Section 3.3.\nBesides, in Table 2, we provided the results that FedHP can handle very new coded apertures $\\mathbf{M}$. Specifically,  mask distributions from different clients are drastically different (as the distributions we shown in Fig.1, also shown in the supplementary).  The proposed method enables a significant performance boost over compared methods. For example, FedHP  improves $0.35$dB compared with FedAvg (Table 2).\n[1] A simple framework for 3D lensless imaging with programmable masks. CVPR 2021.\n[2] LiDAR-in-the-loop Hyperparameter Optimization. CVPR 2023.\n[3] End-to-end high dynamic range camera pipeline optimization. CVPR 2021.\n[4] DOLCE: A model-based probabilistic diffusion framework for limited-angle ct reconstruction. ICCV 2023.\n[5] Deep unfolding for snapshot compressive imaging. IJCV 2023."}, {"Heading": "Thank You for Addressing The Reviewer's Comments", "Subheading": "Official CommentbyReviewer 99wV22 Nov 2023, 17:36Everyone", "Content": "Comment:\nThank you to the authors for addressing my concerns regarding the general applicability of this proposal to computational imaging. I've no other questions. I'll increase my score by 1."}, {"Heading": "Response To Reviewer 99wV", "Subheading": "Official CommentbyAuthors22 Nov 2023, 19:04Everyone", "Content": "Comment:\nWe appreciate the reviewer's valuable comments. We thank the reviewer's recognition of our rebuttal!"}]}, {"Heading": "Official Review of Submission9239 by Reviewer UbMX", "Subheading": "Official ReviewbyReviewer UbMX30 Oct 2023, 04:04 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper has studied a new problem for snapshot compressive imaging (SCI) by optimizing a cooperative network across different hardware configurations (coded apertures). A new hardware prompt learning module has been proposed and integrated into the FedAvg algorithm to enable co-optimizing multi-hardware and the global model for a computation imaging task. Extensive experimental results were provided on simulated and real data, compared with several federated baselines.\nSoundness:\n4 excellent\nPresentation:\n3 good\nContribution:\n4 excellent\nStrengths:\n1\uff09It is interesting and practical to leverage a federated learning framework to address hardware shifts across different systems while preserving the privacy of each system\u2019s local data. Plus, the paper has collected data from multiple real hardware systems to empirically validate the proposed method. \n2\uff09The proposed hardware prompt is a novel and efficient solution to mitigate data heterogeneity for developing deep SCI models in a federated learning framework, especially to enable co-optimizing multiple hardware and a global model across systems. A detailed ablation study has also been provided to clearly show the improvement given this prompt design. \n3\uff09 A multi-hardware dataset has been collected and built for this new problem, which could broadly benefit the SCI community. Extensive experimental results on multiple settings were provided in terms of both quantitive and qualitative evaluation.\n4\uff09Several state-of-the-art federated learning methods have been developed for a computational imaging task and been involved in the experiment comparison.\nWeaknesses:\n1\uff09 While federated learning is a good choice, it remains unclear if the proposed problem setting can be directly solved by some other simple solutions, such as meta learning or deep ensemble. \n2\uff09Despite the large improvement given by the hardware prompt, it lacks further analysis of how this design works for different hardware. For example, will different hardware lead to different prompts? What these \u201chardware prompt\u201d look like? Is the prompt network only implemented by an attention block?\nQuestions:\n1\uff09What are the benefits of introducing adaptors? Why not directly update the full model?\n2\uff09What\u2019s the main reason for setting C=3 in the experiment? \n3\uff09In Eq (9), is there any other way to impose a prompt on the measurements? For example, can the concatenation operation be applied?\n4\uff09It would be better to directly explain the settings of different hardware shits in the captions of Table \u00bd.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 18:13 (modified: 20 Nov 2023, 18:14)EveryoneRevisions", "Content": "Comment:\nWe appreciate that the reviewer UbMX finds our method novel, solves a practical problem, also provides a new multi-hardware dataset!\nWeakness 1\n: While federated learning is a good choice, it remains unclear if the proposed problem setting can be directly solved by some other simple solutions, such as meta learning or deep ensemble.\nA1\n: One key reason we adopt federated learning is to solve the privacy concern. To the best knowledge, both meta learning and deep ensemble are centralized learning strategies and require seeing all of the data to train each client, which makes it hard to perform the hardware corporations among different institutions.\nBesides, we additionally conduct a new experiment using meta learning. Specifically, we integrate MAML [1] into the federated learning framework, termed as FedMAML. We perform experiments using the same setting as Table 1, such that #client=3.   As shown in Table R1 below,  FedMAML method gives limited performance compared with FedAvg and the proposed FedHP.\nMetrics\nFedMAML\nFedAvg\nFedHP\nPSNR\n29.00 $\\pm$  1.44\n31.21 $\\pm$ 0.10\n31.35 $\\pm$ 0.10\nSSIM\n0.8532 $\\pm$ 0.0304\n0.8959 $\\pm$  0.0017\n0.9033 $\\pm$ 0.0014\nTable R1: Comparison between FedAvg and FedHP, and FedMAML\nWeakness 2\n: It lacks further analysis of how this design works for different hardware. For example, will different hardware lead to different prompts? What these \u201chardware prompt\u201d look like? Is the prompt network only implemented by an attention block?\nA2\n: Thanks for the detailed suggestion!\nThere will be only one prompt network obtained as a function to handle different input  masks, as shown in Fig. 2. Thus, different input hardware will lead to different prompts, which will have the same dimensionality as the input mask but with different pixel values. The prompt network only contains one attention block, which per our observation, can effectively cooperate among clients.\nQuestion 1\n: What are the benefits of introducing adaptors? Why not directly update the full model?\nA3\n: Directly updating the full model can cause cumbersome computational cost and communication cost. As exemplified by Table 3, directly learning client backbones from scratch under a federated framework (FedAvg) can result in $14$ times training time. Together with the prompt network,  adaptor can help enhance efficient fine-tuning performance of pre-trained backbones. As shown in Table 3, the adapter can bring $0.016$dB improvement in PSNR and $0.0037$ boost in SSIM.\nQuestion 2\n: What\u2019s the main reason for setting C=3 in the experiment?\nA4\n: Thanks for the valuable question!\nWe previously collected $5$ different real hardware instances. Considering the computational cost and our limited resources, we choose to adopt a number of $3$ clients in the main table. In Table 4a, we also report results under more clients, such as C=$4$ and C=$5$. We are still working on collecting more real hardwares.\nQuestion 3\n: In Eq (9), is there any other way to impose a prompt on the measurements? For example, can the concatenation operation be applied?\nA5\n: Thanks for the insightful question!\nDirectly using the concatenation will cause the dimensionality inconsistent with the backbones and cannot be used. Besides, there is no learnable module for concatenation, which lacks flexibility in handling different data distributions.\nQuestion 4\n: It would be better to directly explain the settings of different hardware shits in the captions of Table \u00bd.\nA6\n: Thanks for the useful suggestion!\nWe have added more explanations of the settings of different hardware shifts in captions of Table 1 and 2. Specifically, for Table 1, we provide the explanation that: For different clients, we sample non-overlapping masks from the same mask distribution to train the model and use unseen masks randomly sampled from all clients for testing. For Table 2, we provide the explanation that: Masks from each client are sampled from a specific distribution for training. We  randomly sample non-overlapping masks (unseen to training) from all distributions for testing.\n[1] Model-agnostic meta-learning for fast adaptation of deep networks. ICML 2017."}, {"Heading": "Feedback", "Subheading": "Official CommentbyReviewer UbMX22 Nov 2023, 08:49Everyone", "Content": "Comment:\nThanks for your responses. My concerns have been well solved, and thus I have no further questions."}, {"Heading": "Response To Reviewer UbMX", "Subheading": "Official CommentbyAuthors22 Nov 2023, 09:56Everyone", "Content": "Comment:\nWe appreciate the reviewer's recognition of our response and support for our work!"}]}, {"Heading": "Official Review of Submission9239 by Reviewer X7WS", "Subheading": "Official ReviewbyReviewer X7WS29 Oct 2023, 05:03 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work develops a federated hardware-prompt learning (FedHP) method for the task of snapshot compressive imaging (SCI). Existing reconstruction methods generally consider a single well-calibrated hardware configuration for network learning, inducing a highly coupled relationship between the reconstruction model and hardware settings. Differently, this work adopts federated learning to coordinate multiple clients with variant hardware settings and proposes a hardware-oriented solution to mitigate heterogeneous data issues.\nSoundness:\n4 excellent\nPresentation:\n4 excellent\nContribution:\n3 good\nStrengths:\n\u2022 The motivation of this work is impressive, pointing out a very practical problem for snapshot compressive imaging. Both the hardware cooperation and hardware heterogeneous problems are underexplored.  This work solves the heterogeneous issue accounting for the special characteristics of SCI.\n\u2022 The design of the hardware prompter bridges the hardware and software in a novel way, which could be easily incorporated into optimizing diverse set-ups in SCI. \n\u2022 Experimental results are abundant and have shown a clear performance boost over previous methods. Extensive ablation studies and model discussions have also been provided.\nWeaknesses:\n\u2022 It remains unclear if the proposed method can adopt a larger client number. A detailed discussion on the number of clients should be given to demonstrate the practicality of the proposed method and to enhance the soundness of the work. \n\u2022 Is it possible to apply the proposed method to other hyperspectral image datasets? \n\u2022 It seems that a competitive method of FedGST for comparison was a centralized learning strategy, is it a fair comparison or what are the modifications toward this method? Please provide more details.\nQuestions:\n\u2022 Is the dataset split of the centralized learning the same as the federated learning? Please provide more illustrations and details. \n\u2022 There are some typos in the manuscript, for example, Fig.3 caption.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal by Authors", "Subheading": "Official CommentbyAuthors20 Nov 2023, 18:41 (modified: 21 Nov 2023, 10:44)EveryoneRevisions", "Content": "Comment:\nWe appreciate that Reviewer X7WS finds our method well-motivated, solves a very practical problem, experimental results are abundant and clear.\nWeakness 1\n: It remains unclear if the proposed method can adopt a larger client number. A detailed discussion on the number of clients should be given to demonstrate the practicality of the proposed method and to enhance the soundness of the work.\nA1\n: We provide an experiment with more clients, e.g., C=8, as follows. We train the proposed FedHP under the same setting as Table 4a.\n#Clients\nFedAvg\nFedHP\n$\\Delta$\n3\n31.21 $\\pm$  0.10 \\ 0.8959 $\\pm$ 0.0017\n31.35 $\\pm$ 0.10 \\ 0.9033 $\\pm$  0.0014\n0.14dB/0.0074\n4\n31.06 $\\pm$  0.10 \\ 0.8955 $\\pm$ 0.0018\n31.33 $\\pm$ 0.13 \\ 0.9023 $\\pm$ 0.0018\n0.27dB/0.0068\n5\n31.05 $\\pm$  0.10 \\ 0.9025 $\\pm$ 0.0014\n31.32 $\\pm$ 0.19 \\ 0.9029 $\\pm$ 0.0019\n0.27dB/0.0004\n8\n31.17 $\\pm$  0.10 \\ 0.9033 $\\pm$ 0.0014\n31.42 $\\pm$ 0.11 \\ 0.9043 $\\pm$ 0.0010\n0.25dB/0.0010\nTable R1: Comparison between FedAvg and FedHP with different number of clients. The last column denotes the performance gap.\nAs shown in Table R1, the proposed method can achieve a consistent performance boost over FedAvg at a larger number of clients.\nWeakness 2\n: Is it possible to apply the proposed method to other hyperspectral image datasets?\nA2\n: We perform experiments on another hyperspectral dataset [1] with 24 spectral channels with the number of client C=3. As the table R2 shown below, the proposed method enables a performance boost over FedAvg.\nMetrics\nFedAvg\nFedHP\nPSNR\n29.97 $\\pm$  0.31\n30.55 $\\pm$ 0.20\nSSIM\n0.8442 $\\pm$ 0.0026\n0.8471 $\\pm$  0.0035\nTable R2: Comparison between FedAvg and FedHP on different hyperspectral dataset [1].\nWeakness 3\n: It seems that a competitive method of FedGST for comparison was a centralized learning strategy, is it a fair comparison or what are the modifications toward this method? Please provide more details.\nA3\n: Thanks for the valuable suggestion!\nGST [2] is a centralized learning strategy to handle various hardware masks from the same distribution. In this work, we insert this model directly into the federated framework to enable hardware cooperation. We have added more illustrations about this method into the manuscript. Since all of the methods are compared under the federated learning framework and adopt the same hardware instances, we can thus perform a fair comparison. Actually, considering GST adopts a self-tuning network besides the reconstruction backbone, it requires more training cost to converge.\nQuestion 1\n: Is the dataset split of the centralized learning the same as the federated learning? Please provide more illustrations and details.\nA4\n: We split the training data according to the number of clients for federated learning. We keep the total amount of training data the same for both centralized learning and federated learning, for a fair comparison. We have put the above illustration into the manuscript.\nQuestions 2\n: There are some typos in the manuscript, for example, Fig.3 caption.\nA5\n: Thanks for the useful comments! We have revised the typos in Fig. 3 caption.\n[1] l-net: Reconstruct hyperspectral images from a snapshot measurement. ICCV 2019.\n[2] Modeling mask uncertainty in hyperspectral image reconstruction. ECCV 2022."}, {"Heading": "Official Comment by Reviewer X7WS", "Subheading": "Official CommentbyReviewer X7WS22 Nov 2023, 11:05Everyone", "Content": "Comment:\nThanks for the authors response and all my concerns have been well addressed. I have no further comments."}, {"Heading": "Response to Reviewer X7WS", "Subheading": "Official CommentbyAuthors22 Nov 2023, 11:39Everyone", "Content": "Comment:\nWe appreciate the reviewer's approval for our response and recognition of our work!"}]}, {"Heading": "Official Review of Submission9239 by Reviewer bAjN", "Subheading": "Official ReviewbyReviewer bAjN18 Oct 2023, 11:12 (modified: 27 Nov 2023, 11:19)EveryoneRevisions", "Content": "Summary:\nThe paper focuses on the robustness, efficiency, and accuracy of current snapshot compressed imaging reconstruction networks. The major contribution of the paper is designing a prompt network which automates the process of aligning a measurement based on its corresponding measurement model.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe paper tackles an interesting distribution shift, that is a shift in the measurement model of the compressed sensing task.\nThe paper is overall well-written (although in some parts difficult to read).\nThe idea of the prompt network to tackle distribution shifts is very interesting. If I understood correctly, without a prompt network, fine-tuning is needed for new measurement models. Yet with the prompt network the process of measurement alignment with the measurement model is automated for any measurement model.\nThe experiments are interesting and carefully designed in the sense that reasonable baselines and datasets are chosen for evaluation.\nWeaknesses:\nThe major contribution of the paper is not well-justified. i.e., the crucial need for the proposed method (as opposed to training from the scratch for every new measurement model) is not well-supported. e.g., the reviewer still finds it very convenient to train a model for every new sets of measurement models for a new organization of interest from a practical perspective. i.e., all it takes is a few hours (days) of training for the new set (note that this automatically addresses the other concern raised by the authors regarding privacy constraints, in that each organization has access to its own data and device sets).\nThe comparisons are not fair in Fig. 1 (also please see my question regarding Fig. 1 below). Clearly, joint training should serve as an upper bound on the performance when the test set contains the same measurement models as training.\nThe results (especially the quantitative ones) do not yield the conclusion that FedAVG is outperformed by FedHP. The major advantage of FedHP seems to be its 4x more efficient training time compared to FedAVG. This is fine and improving the efficiency is valuable from a practical point of view, but the paper isn\u2019t oriented around this conclusion; the paper emphasizes the value of prompt networks and FedHP in the form of accuracy and robustness gains, whereas FedAVG enjoys those traits, too!\nMinor:\nOn Tab. 2, FedHP is highlighted as the best-performing method in terms of SSIM (0.8481), whereas FedAVG should be highlighted (0.8496).\nQuestions:\nHow\u2019s Fig. 1 obtained? Is it evaluated on the same measurement model set used during training of each setup? Or are all models evaluated on the same predefined test set of measurement models?\nAs mentioned in the strengths section, the idea of the prompt network is interesting. However, the biggest question raised is whether that network induces another source of instability to the overall model. Specifically, what guarantees that the prompt network doesn\u2019t do a terrible alignment for measurement models deviating from the training distribution?\nWhat is the source of inconsistency between Tab. 1 and Fig. 3? What we see in Fig. 3 flags for a higher PSNR difference than 0.14 dB between FedAVG and FedHP\u2026 It\u2019s understandable to argue that quantitative metrics such as PSNR or SSIM don\u2019t perfectly capture the true quality, but the visual difference on Fig. 3. is too large not to be captured by those metrics.\nWhy isn\u2019t the deep unfolding network included in all the results and only reported as a short paragraph at the end?\nAny intuition on why FedAVG is so much slower to train than FedHP?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Rebuttal by Authors (Part 1)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 18:59 (modified: 21 Nov 2023, 11:51)EveryoneRevisions", "Content": "Comment:\nWe appreciate that Reviewer bAjN finds our method tackles an interesting problem, proposes an interesting prompt network, experiment is carefully designed with reasonable baselines!\nWeakness 1\n: The major contribution of the paper is not well-justified. i.e., the crucial need for the proposed method (as opposed to training from scratch for every new measurement model) is not well-supported. e.g., the reviewer still finds it very convenient to train a model for every new set of measurement models for a new organization of interest from a practical perspective. i.e., all it takes is a few hours (days) of training for the new set (note that this automatically addresses the other concern raised by the authors regarding privacy constraints, in that each organization has access to its own data and device sets).\nA1\n: Thanks for this useful question!\nThe conventional setting where each organization employs its local data and device to perform independent training has practical limitations for the current SCI research study and prevents its further real-world applications due to the following reasons.\nData-starving challenge of the client. Some clients may have limited training data (e.g., only several scenes) that the training cannot converge.\nEfficiency concern. We find training a local model from scratch takes $3.54$ days ($10.62/3$ as shown in Table 3) on our platform. It only takes less than $1$ day ($2.86/3$ in Table 3) to adapt the model to a new device/client using FedHP.  We have put this illustration into the manuscript. The training time can be even longer if the reconstruction backbone becomes larger.\nIn summary, considering the data-starving nature of the client, it may be impractical for a new client to train a model. Besides, there is a training efficiency concern when there is enough data for the client. Plus, the reconstruction model trained with a single well-calibrated hardware instance is hard to adapt to new hardware. This work proposed FedHP to practically enable the deployment of reconstruction models on new clients.\nWeakness 2\n: The comparisons are not fair in Fig. 1 (also please see my question regarding Fig. 1 below). Clearly, joint training should serve as an upper bound on the performance when the test set contains the same measurement models as training.\nA2\n:  We appreciate the reviewer\u2019s valuable insight in improving this work!\nIn general, joint training serves as an upper bound for federated learning when the test set contains the same measurement models as training.\nHowever, in Fig. 1, the test set consists of random measurement models that are unseen for training. Specifically, all results (1 to 5) are evaluated by sampling from the same mask pool to test the trained models. Note that this mask pool contains masks from three different distributions, i.e., $P_1$, $P_2$, $P_3$ as we plotted in Fig. 1. Since we always sample non-overlapped masks, the masks used for testing are generally unseen to the models. This is quite challenging and can well simulate a real-world scenario.  We have added more illustrations about the settings to the caption of Fig. 1.\nIn this case, our experiments find that simply combining all data from different hardware to jointly train does not work well (as shown in Fig. 1, over $0.6$dB lower than FedHP and $0.3$dB lower than FedAvg).\nWe appreciate the reviewer's help in distinguishing this work from general federated learning endeavors!\nWeakness 3\n: The results (especially the quantitative ones) do not yield the conclusion that FedAVG is outperformed by FedHP. The major advantage of FedHP seems to be its 4x more efficient training time compared to FedAVG. This is fine and improving the efficiency is valuable from a practical point of view, but the paper isn\u2019t oriented around this conclusion; the paper emphasizes the value of prompt networks and FedHP in the form of accuracy and robustness gains, whereas FedAVG enjoys those traits, too!\nA3\n: We thank the reviewer bAjN for helping us summarize this contribution!\nWe find that FedAvg serves as a very strong baseline by even working better than recent  FL methods, such as SCAFFOLD and FedProx. Thus, it is non-trivial to achieve further performance boost. By comparison, FedHP can bring a consistent performance boost. For example, $+0.14$dB in Table 1, $+0.35$dB in Table 2, and $+0.27$dB in Table 4 (a) with more clients.\nBesides, by jointly introducing the hardware prompt network and adapter, the proposed method also benefits from the efficiency advantage by only requiring adapting the pre-trained models in the system to the new clients. We have also emphasized this point by mentioning the advantage of efficiency in the revised manuscript."}, {"Heading": "Rebuttal by Authors (Part 2)", "Subheading": "Official CommentbyAuthors20 Nov 2023, 19:14 (modified: 21 Nov 2023, 11:38)EveryoneRevisions", "Content": "Comment:\nWeakness 4\n: Minor: On Tab. 2, FedHP is highlighted as the best-performing method in terms of SSIM (0.8481), whereas FedAVG should be highlighted (0.8496).\nA4\n:  Thanks for the useful comments! We modified the annotation typos in Table 1  in our manuscript.\nQuestion 1\n: How\u2019s Fig. 1 obtained? Is it evaluated on the same measurement model set used during training of each setup? Or are all models evaluated on the same predefined test set of measurement models?\nA5\n: Thanks for the great question!\nIn Fig. 1, all results are evaluated by sampling from the same mask pool to test the trained models. Note that this mask pool contains masks from three different distributions, i.e., $P_1$, $P_2$, $P_3$ as we plotted in Fig. 1. Since we sample non-overlapped masks, the masks used for testing are unseen to the models and can be regarded as a zero-shot testing. We add this illustration into the caption of Fig. 1.  In computational imaging, previous work [1,2] has shown that the change of mask (e.g., shift, perturbation) will cause large performance degradation.\nQuestion 2\n:  The biggest question raised is whether that network induces another source of instability to the overall model. Specifically, what guarantees that the prompt network doesn\u2019t do a terrible alignment for measurement models deviating from the training distribution?\nA6\n:  Thanks for the valuable insight!\nWe provide an ablation study in Table 3 to discuss the effect of prompt networks. FedHP experiences large performance degradation without using a prompt network. One thing to note is that the prompt network is learned on local but will be aggregated to the server, and then distributed to clients at each global round. This makes sure that the prompt network does not deviate from the global learning objective.\nQuestion 3\n: What is the source of inconsistency between Tab. 1 and Fig. 3? What we see in Fig. 3 flags for a higher PSNR difference than 0.14 dB between FedAVG and FedHP\u2026 It\u2019s understandable to argue that quantitative metrics such as PSNR or SSIM don\u2019t perfectly capture the true quality, but the visual difference on Fig. 3. is too large not to be captured by those metrics.\nA7\n: The difference of $0.14$dB is an averaged result on ten testing scenes as provided in Table 1. In Fig.3, we select one example of Scene $7$ to visually compare between different methods. This should correspond to a PSNR gap of $0.43$dB and $0.0073$ in SSIM. Besides, the visual quality in different regions can vary.  In the supplementary material, we provide more visual comparisons of different scenes.\nQuestion 4\n: Why isn\u2019t the deep unfolding network included in all the results and only reported as a short paragraph at the end?\nA8\n: Thanks for the insightful questions!\nThe deep learning-based reconstruction methods and model-based methods (e.g., deep unfolding) methods demonstrate promising performance for the SCI study. This work mainly focuses on deep learning-based methods.\nBesides the performance comparison in main tables, we also would like to compare with a state-of-the-art deep unfolding method [3]. As shown in Table 4b, FedHP also brings a notable performance boost ($+0.28$dB/$0.0038$ in PSNR/SSIM) with a much smaller model size.\nQuestion 5\n: Any intuition on why FedAVG is so much slower to train than FedHP?\nA9\n:   Thanks for the useful question!\nThere are two designs that make FedHP more efficient than FedAvg.\nFirstly, FedHP does not need to train every local client model from scratch, as long as there is a pre-trained model, we can easily adapt it to new clients under FedHP. By comparison, for any new client, FedAvg is required to train the model from scratch, this can be computationally cumbersome.\nThe other reason is that the proposed method has a much lower communication burden. FedHP only needs to aggregate and distribute a lightweight hardware prompt network and adaptors. By comparison, FedAvg has to do full model training and communication to adapt to different masks, otherwise, the performance will be significantly degraded (e.g., $<20$dB). In contrast, we introduce a hardware prompt to address this issue in a smart way.\n[1] Modeling mask uncertainty in hyperspectral image reconstruction. ECCV 2022.\n[2] Metasci: Scalable and adaptive reconstruction for video compressive sensing. CVPR 2021.\n[3] Deep unfolding for snapshot compressive imaging. IJCV 2023."}]}]}, "v6a1pXXADC": {"paper_info": {"Primary Area": "generative models", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Prompt Optimization, Adversarial Learning, In-Context Learning, Large Language Model", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "We propose a new method, Adversarial In-Context Learning (adv-ICL), to optimize prompt for in-context learning (ICL) by employing one LLM as a generator, another as a discriminator, and a third as a prompt modifier. As in traditional adversarial learning, adv-ICL is implemented as a two player game between the generator and discriminator, where the generator tries to generate realistic enough output to fool the discriminator. In each round, given an input prefixed by task instructions and several exemplars, the generator produces an output. The discriminator is then tasked with classifying the generator input-output pair as model-generated or real data. Based on the discriminator loss, the prompt modifier proposes possible edits to the generator and discriminator prompts, and the edits that most improve the adversarial loss are selected. We show that adv-ICL results in significant improvements over state-of-the-art prompt optimization techniques for both open and closed-source models on 11 generation and classification tasks including summarization, arithmetic reasoning, machine translation, data-to-text generation, and the MMLU and big-bench hard benchmarks. In addition, because our method uses pre-trained models and updates only prompts rather than model parameters, it is computationally efficient, easy to extend to any LLM and task, and effective in low-resource settings.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9238", "PDF Url": "https://openreview.net/pdf?id=v6a1pXXADC"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9238 by Area Chair DsZ5", "Subheading": "Meta ReviewbyArea Chair DsZ508 Dec 2023, 02:57 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper proposes Adversarial In-Context Learning (adv-ICL), a method that employs adversarial learning concepts to optimize prompts for in-context learning using LLMs. The paper's strengths and weaknesses, as noted by the reviewers, are summarized below:\nStrengths:\nComputational Efficiency: Adv-ICL's reliance solely on prompt modifications, without updating model parameters, makes it computationally efficient and particularly effective in low-resource settings.\nNovel Application of GANs: The idea of applying generative adversarial networks (GANs) to improve in-context learning is innovative and shows potential based on the experimental results.\nPerformance Improvements: According to the experiments, adv-ICL outperforms baselines in some settings, demonstrating clear improvements.\nComprehensive Analysis: The paper includes a thorough analysis of the quantitative and qualitative aspects of the method.\nWeaknesses:\nLimited Novelty: The novelty of the approach is questioned, particularly in relation to the resampling method used as the prompt modifier, which appears similar to previously proposed methods in existing literature.\nPresentation and Clarity Issues: The presentation of the method and its components lacks clarity. Inclusion of a running example to explain the interactions between the generator, discriminator, and prompt modifier would improve understanding.\nConvergence Concerns: There are serious concerns about the convergence and efficiency of the proposed approach, as the prompts seem to be modified by chance rather than clear gradient signals. (Addressed in the rebuttal)\nUnconvincing Experiments and Lack of Detail: The paper fails to convincingly demonstrate that performance improvements are solely due to the adversarial training and not influenced by stochastic behaviors or discarded prompts. (Partially addressed in the rebuttal)\nGiven these observations, the paper, while presenting an interesting and potentially impactful idea, falls short in several areas.\nJustification For Why Not Higher Score:\nSee weaknesses\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "General Reply", "Subheading": "Official CommentbyAuthors20 Nov 2023, 09:42 (modified: 20 Nov 2023, 18:48)EveryoneRevisions", "Content": "Comment:\nThe results of this rebuttal and academic research in general seem so insignificant given what\u2019s happening in the industry, amidst the time of great changes. OpenAI rose so quickly. And it could fall. But this is exactly the time when research is never more important. It was due to people like Alec Radford and Geoffrey Hinton who worked on research single-heartedly that we had today\u2019s success. So we should do the same. Look for things to believe in, do research to test our belief, and repeat.\nComing back to the reviews, we thank the reviewers for their time. But we feel that our paper did not receive an adequate judgement. We received 3 reviews and 2 of them do not reflect a fair judgement of our work. Particularly, reviewer iBKM did not point out any intrinsic weakness of our work but gave a score of 5. Reviewer SGYz did not understand our method and gave a score of 3. All academic people joke about the randomness of the review process yet we are both the offenders and victims.\nThat being said, we do find some of the reviews insightful and helpful. So we address the reviewers\u2019 questions and concerns as follows:\nWe added a theoretical analysis about the convergence properties of adv-ICL. Basically, our analysis shows that the algorithm does converge to the original conditioned GAN scenario given mild assumptions. Please check Section 2.4 in the updated draft for more details.\nAs requested by reviewer iBKM, we updated results using more feedback to the prompt modifier.\nAs requested by reviewer SGYz and reviewer 9rYe, we updated results with the discriminator removed or frozen.\nAs requested by reviewer 9rYe, we studied the variances of the method.\nWe made a few improvements to the presentation of the paper.\nPlease refer to the highlighted parts for the updated content. Some of them are in the appendix.\nOverall, we feel that we need a fairer evaluation. And we do our best to address reviewers\u2019 questions and concerns. Please do not hesitate to let us know if you have any further questions."}, {"Heading": "Official Review of Submission9238 by Reviewer iBKM", "Subheading": "Official ReviewbyReviewer iBKM01 Nov 2023, 11:50 (modified: 23 Nov 2023, 02:00)EveryoneRevisions", "Content": "Summary:\nIn this paper, the authors introduce Adversarial In-Context Learning (adv-ICL), which uses 3 LLMs as a generator, a discriminator, and a prompt modifier to optimize prompts. Similar to traditional adversarial learning, there is a minimax game between the generator and the discriminator, where the generator aims to generate realistic text to fool the discriminator. The generator is provided with task instructions, several exemplars, and input at each round and produces the output; the discriminator then tries to decide whether the generator input-output pair is real data or model generated. After that, the prompt modifier makes changes to the generator, and the discriminator prompts to improve the adversarial loss. They perform a set of experiments using both open and closed-source models on various generation and classification tasks to evaluate their model.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nSince there are no updates to the model parameters and only the prompts change, adv-ICL is computationally efficient and effective in low-resource settings. Moreover, adv-ICL only needs a few iterations and training samples in order to achieve high performance.\nThere is a thorough analysis of the quantitative and qualitative aspects of their method.\nWeaknesses:\nSome more RL-based prompt optimization baselines (e.g., Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song, Eric P. Xing, & Zhiting Hu. (2022). RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning.) could be used in the evaluation section to provide more insight.\nQuestions:\nIt seems that in order to make edits to the prompts, the prompt modifier is prompted with a template text, and the last best-performing generator and discriminator prompts. What if you provide more feedback to the prompt modifier, such as the last best-performing prompt, alongside its predecessor, and how much better this last prompt performed than the other?\nFor human evaluation, it is mentioned that annotators are tasked with verifying whether the sampled instruction/demonstration is semantically similar to the original one or not. What if you also add a module that can automatically verify this, check the content preservation score, and also consider this metric when choosing a prompt?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Review response", "Subheading": "Official CommentbyAuthors20 Nov 2023, 08:59Everyone", "Content": "Comment:\nWe thank the reviewer for your time.\nW1. Need to be compared with some more RL-based prompt optimization baselines.\nThese RL-based baselines could not be applied to the closed source models such as ChatGPT and text-davinci. To test the effectiveness of our method, we need to perform experiments on these models because they have better performance. This is why we made the decision to not compare with RL-based methods. Specifically, [1] and [2] require access to LLMs for inserting MLPs.\nWe compared adv-ICL with state-of-the-art prompt learning methods including GPS, APO and APE and outperformed them consistently, which indicates the effectiveness of our method.\nQ1. What if we provide more feedback to the prompt modifier.\nWe conducted an experiment that involved integrating the most successful prompts from previous iterations as feedback for the next iteration. In this process, we utilized previous best-performing prompts, namely $P_1, P_2, ..., P_k$, as inputs to the prompt modifier module when generating the $(k+1)$-th prompt.\nWe applied the method to four representative tasks, including data-to-text generation task WebNLG, machine translation, sentiment classification Yelp, and reasoning GSM8k, using Vicuna and ChatGPT. The experimental results are shown below:\nModel\nWebNLG\nTranslation (RO->EN)\nYELP\nGSM8K\nVicuna\n52.5\n72.1\n71.0\n40.7\nVicuna with Adv-ICL (prompt modifier with history)\n56.9\n74.0\n74.2\n42.2\nVicuna with Adv-ICL\n59.3\n73.4\n73.6\n43.9\nChatGPT\n60.9\n78.8\n69.8\n79.4\nChatGPT with Adv-ICL (prompt modifier with history)\n62.1\n79.8\n72.1\n80.9\nChatGPT with Adv-ICL\n63.6\n80.4\n71.9\n82.3\nIn the case of Vicuna, incorporating additional feedback into the prompt modifier proves effective for tasks such as translation and classification. However, this approach falls short when applied to data-to-text and reasoning tasks. On the other hand, for ChatGPT, augmenting the prompt modifier with more feedback does not yield improved performance.\nQ2. What if you also add a module that can automatically verify modifications.\nAs shown in the \u201cHuman evaluation of prompt modifier performance\u201d part of Section 3.3, most of the prompts outputted by the prompt modifier are semantically correct. Specifically, the correct percentage of  text-davinci-002, ChatGPT, and Vicuna are 88%, 91%, and 83% respectively. So we do not think that it is necessary to automatically verify modifications.\nReferences\n[1] Mingkai et al, Rlprompt: Optimizing discrete text prompts with reinforcement learning, EMNLP 2022.\n[2] Pan et al,  Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning, ICLR 2023."}, {"Heading": "Official Comment by Reviewer iBKM", "Subheading": "Official CommentbyReviewer iBKM23 Nov 2023, 02:07Everyone", "Content": "Comment:\nThank you for the explanations and for providing the results of your additional experiments. I have changed my overall score from 5 to 6."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 03:53Everyone", "Content": "Comment:\nWe are glad that you find our explanations helpful. Appreciate the feedback. Thanks!"}]}, {"Heading": "Official Review of Submission9238 by Reviewer SGYz", "Subheading": "Official ReviewbyReviewer SGYz30 Oct 2023, 23:53 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a new method called Adv-ICL that applies the framework of generative adversarial networks to LLMs to improve in-context learning. Instead of directly updating the weights of a target model, the method employ a prompt modifier to generate prompts, which are then fed into the generator and discriminator to lower their respective loss functions.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nS1. The idea of applying generative adversarial networks to imporve in-context learning is plausible. \nS2. According to the experimental results shown by the authors, Adv-ICL outperforms the baselines in some settings.\nWeaknesses:\nW1. The convergence of the proposed approach. It seem that the prompts are modified by chance rather than gradient signals. This poses a serious concerns on the convergence and efficiency of the proposed approach. Yet the paper does not discuss this aspect in details.\nW2. Unconvencing Experiments:\nW2-a. Disregarded Prompts:\nDuring the iterative training process, when a new prompt is introduced to optimize the loss function, the model (either the generator or the discriminator) engages in in-context learning, regardless of whether the new prompt is accepted or discarded. It's worth noting that discarded prompts can also impact the model's training, but the paper does not explore this aspect in detail.\nW2-b. Unclear Origin of Benefits:\nThe observed performance improvements in the experiments may not be solely attributed to the accepted examples but could also be influenced by the discarded ones. Furthermore, given that the optimization process relies on the stochastic behavior of large language models, it's possible that the learning effect results from the repeated trial-and-error of prompt modifications occurring during the training iterations rather than from improved prompts. Therefore, the assumption that improvements in experimental results are solely due to adversarial training may not be valid.\nQuestions:\nIs there a method to modify the prompts that doesn't involve trial-and-error? How does it compared to gradient descent?\nWhat are the training time and memory usage of your approach compared to the baselines?\nDoes your GANs framework converge effectively? What's the learning curves for the generator and discriminator, respectively?\nHow reliably can the experimental results be reproduced considering the stochastic nature of the optimization process and an LLM itself?\nIn terms of fairness, it seems that not all methods in the experiments use the prompts generated (or modified) by the same prompt modifier. Why?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Review response", "Subheading": "Official CommentbyAuthors20 Nov 2023, 09:19Everyone", "Content": "Comment:\nWe thank the reviewer for your time. We respectfully think that the reviewer did not understand our method. However, we will try to address your concerns as best as we can.\nW1. The convergence of the proposed approach.\nIn the updated draft, we included a new theoretical analysis section that shows the proposed algorithm converges to the desired equilibrium under mild assumptions.\nHere is the sketch of the analysis.\nTheoretical Results\nIn this section, we theoretically analyze whether such a minimax objective in the form of in-context learning can achieve the desired equilibrium as in the original GAN scenario. We assume access to models with infinite capacities powering the discriminator $D$, generator $G$, and prompt modifier $M$ and that in each iteration, we sample a sufficient number of prompts from $M$ to update both $G$ and $D$. Let $p_{data}$ be the distribution of the training data, and $p_g$ be of the generated data from $G$.\nConsidering a language model $\\mathcal{M}$ which can be $D$ or $G$ performing a corresponding task $T_1$ and evaluated by a metric $E_1$,  we further assume that:\n$M$ is powerful enough to modify the initial prompt of $\\mathcal{M}$ for $T_1$, covering all possible prompt variants performing the task $T_1$.\n$\\mathcal{M}$ is a powerful enough language model that there exists a prompt $\\mathcal{P}$ of $T$ for $\\mathcal{M}$ that given $\\mathcal{P}, \\mathcal{M}$ can achieve the globally optimal result on $E_1$ for the task $T$.\nThere exists a prompt sampled by $M$ that maximizes $\\mathcal{M}$ on $E_1$ globally on $T$.\nThe assumption 3 is a result of the assumptions 1, and 2, and the assumption about our access to infinite capacities language models. Indeed, given $\\mathcal{M}$, from assumption 2, there exists a globally optimized prompt $\\mathcal{P}$ of $T_1$ for it such that it can achieve the globally optimal state on $E_1$ for the task $T_1$. Furthermore, since $M$ is powerful enough in modifying the initial prompt (ass. 1), plus $M$ samples a sufficiently large number of prompts for each iteration (ass. 2), $M$ can generate $\\mathcal{P}$ with a non-zero probability, which conclude the assumption 3.\nFrom the assumptions, we have the following propositions.\nProposition 1 (Goodfellow et al., 2014).\nFor G fixed, the optimal discriminator D can be described in a closed form, denoted as D*.\nProposition 2.\nFor each training iteration, for a fixed $G$, the optimal discriminator $D^*$ can be achieved.\nProposition 3 (Motivated by Goodfellow et al., 2014).\nIf $G$ and $D$ have enough capacity, and at each training step, the discriminator is allowed to reach its optimum $D^*$ given $G$, and $p_g$ is updated so as to improve the criterion\nThe proofs for the propositions are presented in\nAppendix A.1\nof our revised manual script. Our conclusion is that\nwith strong enough $D,G,M$, the framework adv-ICL converges\n.\nW2a. It's worth noting that discarded prompts can also impact the model's training\nWe respectfully think that the reviewer misunderstood our method. First, it is worth noting that our method does not require any update in the models\u2019 parameters, it only updates the prompts of the discriminator and generator. Second, we only forward the best-performing prompt from the previous training iteration to the next training iteration for modification, and it is reasonable for us to further optimize this best-performing prompt without considering the discarded ones.\nW2b. Effect results may come from the repeated trial-and-error of prompt modifications\nIn addition to our arguments in W2a, we further conduct experiments to verify whether the prompt modifier module worked as expected. Specifically, we deactivate the discriminator and only employ a prompt modifier to repeatedly optimize the prompt. Our experimental results with Vicuna and ChatGPT are provided below:\nModel\nWebNLG\nTranslation (RO->EN)\nYELP\nGSM8K\nVicuna\n52.5\n72.1\n71.0\n40.7\nVicuna with Adv-ICL w/o Discriminator\n50.1\n71.4\n72.1\n40.2\nVicuna with Adv-ICL\n59.3\n73.4\n73.6\n43.9\nChatGPT\n60.9\n78.8\n69.8\n79.4\nChatGPT with Adv-ICL w/o Discriminator\n61.2\n77.4\n64.5\n71.6\nChatGPT with Adv-ICL\n63.6\n80.4\n71.9\n82.3\nIn the majority of cases, when the discriminator is deactivated and only the prompt modifier is relied upon under Vicuna and ChatGPT, there is a noticeable decline in performance. This decline can be attributed to the inherent randomness of the prompt modifier, which lacks the ability to discern a more effective prompt. This observation underscores the substantial significance of the discriminator and adversarial loss in the optimization process."}, {"Heading": "Cont: Review response", "Subheading": "Official CommentbyAuthors20 Nov 2023, 09:23Everyone", "Content": "Comment:\nQ1. Avoid trial-and-error and adopt gradient descent.\nWe have conducted experiments by incorporating the best-performing prompts from multiple previous iterations as feedback to refine the prompt in subsequent iterations (refer to our response to Reviewer iBKM Q1 for more information). However, when it comes to optimizing a discrete prompt, directly applying gradient descent is not feasible. In [5], the concept of 'gradient' in the context of a discrete prompt is defined, and our approach consistently outperforms it. For further details, please check Table 1 and Table 2 in the paper.\nIn the case of a soft prompt such as [6] [7], gradient descent can be employed for optimization. Nevertheless, there is no universally applicable loss function. For instance, in tasks like summarization, reference-based metrics are ineffective for measuring performance accurately [8].\nApart from all the pros and cons of gradient based approaches, the biggest problem is that it cannot be applied on state-of-the-art closed source models. We recognize the importance of doing experiments with open sourced models like Vicuna but the closed source models such as ChatGPT currently have better performance. So to know the effectiveness of our method, we need to perform experiments on closed source models.\nQ2. Training time and Memory usage\nOur method does not involve updating any parameters of the models and only relies on the inference state of LLMs. The training time for any models and settings is under 10 minutes, and the memory usage for vicuna-13b does not exceed 32GB.\nQ3. Does your GANs framework converge effectively?\nPlease refer to the response to W1 for more details.\nQ4. Randomness\nWe have rerun our experiments three times on WebNLG, RO->EN, YELP, and GSM8K. Below are our results with format run1/run2/run3:\nModel\nWebNLG\nTranslation (RO->EN)\nYELP\nGSM8K\nVicuna\n59.3/59.2/59.5\n73.4/74.1/73.2\n73.6/73.6/73.5\n43.9/44.3/44.1\nChatGPT\n63.6/63.5/63.8\n80.4/80.6/80.6\n71.9/71.8/71.9\n82.3/82.5/82.2\nThe results clearly demonstrate that Adv-ICL consistently delivers stable results, thereby highlighting its reliability in faithfully reproducing our experimental findings.\nQ5. Not all methods in the experiments adopt the same prompt modifier.\nWe conducted experiments with various baselines, each employing distinct prompt modification strategies. In order to make sure that we stay faithful to the originally proposed formulations, we used prompt modification strategies proposed by these techniques.\nReferences\n[1] Goodfellow et al. Generative adversarial nets. NeurIPS 2014.\n[2] Radford & Metz et al. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. ICLR 2016.\n[3] Salimans et al. Improved Techniques for Training GANs. NeurIPS 2016.\n[4] Goodfellow. On distinguishability criteria for estimating generative models. ICLR 2015.\n[5] Reid et al. Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search, Arxiv 2023.\n[6] Xiao et al. P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks, ACL 2022.\n[7] Xiang et al. Prefix-Tuning: Optimizing Continuous Prompts for Generation, ACL 2021\n[8] Zhang et al. Benchmarking Large Language Models for News Summarization. Arxiv 2023."}, {"Heading": "Thanks for your reply", "Subheading": "Official CommentbyReviewer SGYz23 Nov 2023, 02:30 (modified: 23 Nov 2023, 02:32)EveryoneRevisions", "Content": "Comment:\nThe reviewer thanks the authors for their reply. I understand that the proposed approach does not alter the generator and discriminator. My major concerns were on the prompt selection and improvement parts in the prompt modifier, and how they can affect the overall convergence and training time of GANs. The reply did not address my concerns, so I will keep my original score."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 03:55Everyone", "Content": "Comment:\nSure, thanks! Unfortunately we don't have time to further discuss details about the prompt selection part. Enjoy thanksgiving!"}]}, {"Heading": "Official Review of Submission9238 by Reviewer 9rYe", "Subheading": "Official ReviewbyReviewer 9rYe30 Oct 2023, 22:16 (modified: 27 Nov 2023, 19:18)EveryoneRevisions", "Content": "Summary:\nThis paper proposes Adversarial In-Context Learning (adv-ICL) to optimize prompts for in-context learning (ICL). \nIt uses an LLM-based prompt modifier to modify the prompts of LLM-based generator G and LLM-based discriminator D.\nIn each round, the prompt modifier produces $r$ samples, and the best one is selected based on the discriminator loss to update the prompts of G and D.\nThe method shows improvements on 11 tasks.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe experimental results show clear improvements over the baselines.\nUsing adversarial optimization for prompt optimization is a novel idea.\nThe implementation and experimentation details are relatively adequate.\nWeaknesses:\nThe novelty is limited:\nThe resampling method (as the prompt modifier) is already proposed in APE (Zhou et al., 2023). The prompt used to modify instructions in this work is very similar to the prompt used in APE but without proper citation.\nFor problems where the discriminator is trivial (e.g. for multiple-choice problems), the method is very similar to APE except that the demonstrations are also resampled.\nThe idea of adversarial optimization comes from GAN.\nThe presentation needs to be improved, I would suggest including a running example in the method section to explain the generator, discriminator, and prompt modifier, and how they interact with each other.\nSome ablation studies are missing (see questions below).\nThe limitations are missing.\nQuestions:\nWhy the discriminator is necessary?\nCan you do an ablation study when the discriminator is frozen?\nCan you compare the performance of using a trivial discriminator (e.g. exact match) and using an LLM-based discriminator on classification and reasoning tasks?\nCan you compare the performance of adv-ICL with APE which uses LLM's log-likelihood as the objective function, on summarization, data-to-text, and machine translation tasks?\nIn Table 3, too many iterations $T$ or samples $m$ seem to harm the performance, could you give some explanation or hypothesis about why?\nIn the appendix, for figures 9 and 10, what's the baseline in these figures? Is adv-ICL always not worse than the baselines and why?\nMinor:\nSome captions could be longer to better explain the figures and tables.\nPlease place the caption of the Tables above.\nMisc:\nThere is a concurrent work you may discuss in related work: LLM as optimizers [1].\nThe response partially addresses my concerns. I would raise my score from 3 to 5.\n[1] Yang, C., Wang, X., Lu, Y., Liu, H., Le, Q. V., Zhou, D., & Chen, X. (2023). Large language models as optimizers. arXiv preprint arXiv:2309.03409.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Review response", "Subheading": "Official CommentbyAuthors20 Nov 2023, 09:34Everyone", "Content": "Comment:\nWe thank the reviewer for your time!\nW1. The novelty is limited.\nTo the best of our knowledge, this is the first work exploring optimizing discrete prompts for in-context learning (ICL) in the adversarial learning style. We propose adv-ICL which can effectively optimize the prompts. Despite simplicity, our method shows strong improvements over the baselines and achieves significant improvements over previous approaches while requiring very few training data.\nThat being said, novelty itself is a subjective matter. The whole deep learning field is built on empirical results with old ideas. The whole GPT series had very limited \u201cnovelty\u201d in the traditional sense, except the prompting formulation. They just made it work. Our method also works. Papers like ours are the reason for why we have great AI technologies today.\nW2: Add examples in the presentation.\nWe have updated an example in Figure 1 of the updated version. Please check it.\nW4. The limitations are missing.\nThe limitation section is not required for ICLR. Please check the author guide (\nhttps://iclr.cc/Conferences/2024/AuthorGuide\n).\nQ1. Why the discriminator is necessary?\nWe have conducted extra experiments supporting the reviewer\u2019s comments.\nFroze discriminator: We have conducted our experiments with Vicuna and ChatGPT where we frozen the discriminators on four representative datasets: WebNLG, Machine translation (RO->EN), YELP, and GSM8K. The results with Vicuna and ChatGPT are shown below:\nModel\nWebNLG\nTranslation (RO->EN)\nYELP\nGSM8K\nVicuna\n52.5\n72.1\n71.0\n40.7\nVicuna with Adv-ICL (Frozen discriminator)\n54.9\n71.9\n71.2\n41.8\nVicuna with Adv-ICL\n59.3\n73.4\n73.6\n43.9\nChatGPT\n60.9\n78.8\n69.8\n79.4\nChatGPT with Adv-ICL (Frozen discriminator)\n60.8\n78.6\n70.1\n79.5\nChatGPT with Adv-ICL\n63.6\n80.4\n71.9\n82.3\nIt is clear that updating the discriminator is essential in our formulation.\nQ2. Why too many iterations T or samples m harm the performance\nThis is an interesting point! We observed this phenomenon in the experiments and were also curious about it. Our current hypothesis is that, while in-context learning holds great promise, it does not behave similar to SGD based learning. For example, having more demonstrations or data samples in the prompt does not help. Also, as demonstrated by [1], a critical threshold exists for the number of training examples, and surpassing this threshold leads to a decline in performance. As a result, more iterations or more samples do not necessarily help.\nGiven the complexity of in-context learning, we simply determine the best hyperparameters based on empirical results. We perform hyperparameter search based on the validation data of a small set of tasks. These hyperparameters do generalise to the other tasks. For details about the hyperparameter search process, you can refer to Section 2.4 in the original paper and Section 2.5 in the revised version.\nQ3. Baseline in Figure 9 and Figure 10\nThe \u201cBaseline\u201d in Figures 9 and 10 are the Few-shot baseline.\nMisc: Discuss with concurrent work LLM Optimizers.\nWe have included it in our related work discussion. The paper presents a novel LLMs optimizer that leverages feedback from LLMs to refine prompts effectively. This paper lies in the field of self-refinement and RL optimization m ethods, as explored in previous works [3] and [4]. However, our distinctive contribution lies in the study of adversarial in-context learning. We have included a discussion with the LLM optimizer in our related work.\nReferences\n[1] Min et al. Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? ACl 2022.\n[2] Yang et al, Large language models as optimizers. arXiv preprint, Arxiv 2023.\n[3] Mingkai et al, Rlprompt: Optimizing discrete text prompts with reinforcement learning, EMNLP 2022.\n[4] Pan et al,  Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning, ICLR 2023."}]}]}, "6yJuDK1DsK": {"paper_info": {"Primary Area": "transfer learning, meta learning, and lifelong learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "test-time adaptation, source free test-time domain adaptation, parameter efficient test-time adaptation", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "This paper introduces a new method for making lifelong test time adaptation (TTA) methods parameter efficient using the idea of adapters, without requiring access to source data for warm-starting the adapter updates.", "Abstract": "Lifelong/continual test-time adaptation (TTA) refers to the problem where a pre-trained source domain model needs to be continually adapted at inference time to handle non-stationary test distributions. Continuously updating the source model over long horizons can result in significant drift in the source model, forgetting the source domain knowledge. Moreover, most of the existing approaches for lifelong TTA require adapting all the parameters, which can incur significant computational cost and memory consumption, limiting their applicability on edge devices for faster inference. We present FEATHER (liFelong tEst-time Adaptation wiTH lightwEight adapteRs), a novel lightweight approach that introduces only a small number of additional parameters to a pre-trained source model which can be unsupervisedly and efficiently adapted during test-time for the new test distribution(s), keeping the rest of the source model frozen. FEATHER disentangles the source domain knowledge from the target domain knowledge, making it robust against error accumulation over time. Another distinguishing aspect of FEATHER is that, unlike some recent approaches for lifelong TTA that require access to the source data for warm-starting the adaptation at test time, FEATHER does not have such a requirement. FEATHER is also orthogonal to the existing lifelong TTA approaches and can be augmented with these approaches, resulting in a significant reduction in the number of additional parameters needed to handle the lifelong TTA setting. Through extensive experiments on CIFAR-10C, CIFAR-100C, ImageNetC, and ImageNet3DCC Robustbench benchmark datasets, we demonstrate that, with substantially (85% to 94%) fewer trainable parameters, FEATHER achieves better/similar performance compared to existing SOTA lifelong TTA methods, resulting in faster adaptation and inference at test-time. The source code for FEATHER will be released upon publication.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9237", "PDF Url": "https://openreview.net/pdf?id=6yJuDK1DsK"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9237 by Area Chair tbBc", "Subheading": "Meta ReviewbyArea Chair tbBc15 Dec 2023, 17:49 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nFEATHER is a method for test-time adaptation (TTA), and specifically continual test-time adaptation, in which the model must update online in order to generalize better to shifted data. FEATHER does not update the source model weights, but instead adds new \"adapters\" to the model and only updates their parameters, and takes care to initalize these adapters to the identity function for stable optimization during testing. Its proposed contributions are the design of the adapter, the choice of where to include the adapter(s) in the source model, the identity initialization of the adapters, and experiments to measure the accuracy and computation needed by FEATHER vs. existing TTA methods. It is noteworthy that the choice of adapter parameterization makes FEATHER compatible with a variety of TTA methods and losses: the experiments cover a number of entropy minimization methods (TENT, CoTTA, EATA) but do not include self-supervised methods (like contrastive learning, auxiliary tasks, ...). Results are shown on the standard TTA benchmarks of ImageNet-C and CIFAR-10/100-C as well as the newer 3D corruptions of ImageNet-3DCC: on accuracy FEATHER rivals or exceeds the  continual TTA state-of-the-art CoTTA and on computation it almost halves memory to 58% of CoTTA and reduces time to 90% of CoTTA.\nThe strengths are that FEATHER adapters are simple, that FEATHER is compatible with and complementary to a variety of TTA methods, and that FEATHER reduces computation while mostly maintaining accuracy w.r.t. the state-of-the-art for continual TTA. The weaknesses are that the adapters are established by prior work (Houlsby et al. 2019 as cited, thought the setting differs, and\nAdaptFormer NeurIPS'22\n, which is in the same setting but uncited), that the computational improvements are not more significant (at ~50-90% of the full-update computation of CoTTA) and more computation than TENT, and that the accuracy difference is marginal.\nAll reviewers vote for rejection with borderline (CBjP, M9Xj, F1KC) and reject (bPzr) ratings. The AC acknowledges the respectful and detailed author comment. The AC confirms that discrepancies between review content and submission content have been discounted, in particular the true/false facts of whether there is improvement to performance and efficiency, but must note that there is valid disagreement about the magnitude or significance of the differences. Having closely read the submission itself, the AC downweights the weaknesses raised by bPzr and the reject rating accordingly, because the limitation to CNNs and the priority of adapters from transfer learning do not hold. Nevertheless, there is consensus among reviewers for borderline rejection and the AC ultimately does not find sufficient grounds to overrule the consensus. The authors are encouraged to resubmit their work incorporating the improvements from this round of review. In that direction, reviewer F1KC acknowledged the improvement of the rebuttal during the reviewer-AC discussion and raised their score to 5, but indicated that more analysis and ablation of the use of adapters is needed to be thoroughly informative.\nNote: Although concurrent work was not factored into the decision to ensure fairness (while ICLR'23 is in scope, it is close the cutoff in the 2024 policy), the AC would like to highlight related work on memory-efficient TTA in case it is of interest to the authors. See\nMECTA: Memory-Economic Continual Test-Time Model Adaptation\nat ICLR'23.\nJustification For Why Not Higher Score:\nWhile there is a degree of improvement in the experiments and information for a test-time adaptation audience, the significance of the results and the novelty w.r.t. prior work has not reached the bar for ICLR.\nNovelty is Limited by Prior Adapters: AdaptFormer at NeurIPS'22 already introduced test-time adapters and requires a reference. While there are differences, in that the adapters were applied to ViTs rather than CNNs and their initialization was near-identity rather than exactly the identity, these differences need to be addressed and justified by FEATHER.\nEfficiency in Parameters, Time, and Memory: FEATHER does not impart sufficient time or memory efficiency. To be clear, the use of adapters does reduce the number of parameters, time, and memory w.r.t. full updates. However, it is not competitive with BN updates in efficiency (Table 7) although it does improve in accuracy. All-in-all, FEATHER thus offers more flexibility in trading off computation and accuracy but does not strictly dominate existing methods.\nReset Cost: The claimed improved practicality for resetting only holds for full-update methods like CoTTA and EcoTTA. Note that TENT need only keep the BN parameters and statistics for resetting, and not the full model parameters, so its memory cost is indeed less than FEATHER (as indicated in Table 7 of the submission: TENT updates 0.37% of the parameters while FEATHER updates 6.80% in its adapters).\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Common Response to the Reviewers", "Subheading": "Official CommentbyAuthors20 Nov 2023, 16:56Everyone", "Content": "Comment:\nWe thank the reviewers for their insightful comments and valuable feedback. The reviewers have found our problem setup to be well-motivated with practical scenarios and important for real-world development (Reviewer F1KC), novel in terms of usage of adapters for continual TTA setting (Reviewer bPzr), and effective in reducing the computational complexity with no access to the training dataset (Reviewer CBjP). As remarked by (Reviewer F1KC), the proposed idea of adding additional adaptable parameters with no updates to pre-trained weights is novel and easy to implement.\nIn this common response, we first discuss some of the main points raised by the reviewers; in particular (1) whether the parameter-efficiency also translates to memory-efficiency and wall-clock time savings, (2) comparison with other recent SOTA methods, and (3) applicability of our method to other architectures. In addition to our response, we also request the reviewers to take a look at the updated version of the paper, which includes the additional experiments that we conducted based on the reviewers' suggestions (for easy comparison/reference, the text color is blue for the updated parts).\nParameter-efficiency vs memory consumption and wall-clock timing:\nWhen the number of trainable parameters is reduced, it directly affects the\nmemory usage\n(required for maintaining parameter-specific gradients and activation maps for computing those gradients) as well as the\nadaptation time\n(as gradients need to be computed with respect to each learnable parameter at inference time). To confirm if parameter-efficiency translates to memory savings and wall-clock time savings (at inference time) in practice, we performed additional experiments and have included their results in the updated version of the paper. In Table 7 and Appendix Table 10 of the updated paper, we show these results for FEATHER applied on three TTA objectives -- CoTTA, TENT, and EATA, and compare it with two test-time adaptation schemes: (1) adapting by updating only BN parameters (\"BN Params\"), and (2) adapting by updating all the params (\"All Params\"). Our results in Table 7 clearly show that FEATHER (regardless of the wrapper TTA method it is used with, be it CoTTA, TENT, or EATA) provides an advantage of adapting a minuscule percentage of params to achieve error rates that are comparable to full-finetuning (\"All Params\"), and much better error rates as compared to methods that adapting only batch-norm parameters (\"BN Params\") (Table 6 and Appendix Table 10), making it more practical and flexible for real-life deployment of the TTA models.\nComparison with other SOTA methods (both that use source data and those that are source-free):\nIn Appendix D of our original submission, we had already provided comparisons with other recent SOTA methods like EATA and EcoTTA. In the updated version, these results can be found in Table 4 (with source data dependency). FEATHER outperforms both types of methods. Note that, on CIFAR10-To-CIFAR10C, CoTTA (which requires updating all the parameters) does marginally better than FEATHER, but FEATHER is much better than CoTTA in terms of parameter-efficiency as well as memory and wall-clock time (Table 7).\nApplicability of our method to other architectures:\nAlthough the implementational details will require some changes (we focused on CNN-based architectures), our idea is general and can be used with any architecture that uses adapter modules between layers (including variants of transformers that use adapter modules).\nWe now highlight some of the key aspects that distinguish FEATHER from other recent approaches.\nA key advantage of FEATHER is that it does not require access to source domain data, unlike other recent SOTA methods like EATA and EcoTTA. Thus, it perfectly fits the problem of test-time or source-free domain adaptation, where the source data is no longer available when adapting to unlabeled test data. The source-free setting is more challenging and appealing to real-world applications where data privacy is the primary concern and crucial. Hence, TTA, which only requires access to the source model with a lifelong setup, directly applies to model deployment in the wild. In this work, we specifically aim to reduce the parameter update cost by proposing a new scheme, FEATHER, and show that a similar lifelong TTA performance can be achieved with a huge reduction in parameter update cost for the existing lifelong TTA methods.\nAnother advantage of FEATHER is its ability to increase the expressive power of the network based on the computational budget. As our experiments show, even under a very tight computational budget (number of adapter params), FEATHER outperforms other recent parameter-efficient SOTA methods, and as the number of trainable params (added adapter params) is increased, FEATHER is competitive to CoTTA (which requires full fine-tuning) while still requiring a much smaller number of trainable params."}, {"Heading": "Official Review of Submission9237 by Reviewer CBjP", "Subheading": "Official ReviewbyReviewer CBjP01 Nov 2023, 03:25 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper focuses on the continual test time adaptation (CTTA), where the test input has a time-varying domain. The authors propose cost-effective CTTA method, called FEATHER, which mitigates the forgetting issue of previous methods in CTTA scenarios. The proposed method is particularly useful in practice as it does not require any access to the source dataset, whereas most of the existing ones do. The authors demonstrate the efficacy of the proposed method in various CTTA scenarios. In addition, they empirically show a comparative advantage over existing methods, even including ones requiring access to the source domain in a TTA scenario.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe proposed method, FEATHER, addresses the forgetting issue in CTTA with no access to the source domain, which is often limited in the practice of TTA yet is required for existing methods. Specifically, it proposes to employ a set of new parameters and clever initialization, that do not harm the performance at the beginning (without seeing the source dataset), while enabling an effective prevention of the forgetting issue. There was a similar approach (EcoTTA: Song et al. 2023) but it requires warm-up phase to find such a harmless initialization of additional parameters based on the source dataset. In addition, FEATHER is memory-efficient as it reduces the number of parameters to be updated in the procedure of TTA. Such benefit and efficacy of the proposed method have been demonstrated on a set of experiments (CIFAR10C, CIFAR100C, ImageNetC, ImageNet3DCC).\nWeaknesses:\nMy major concern is the limited justification of the proposed method. In my understanding, the main selling point is to address CTTA problems at reduced computational complexity with no access to the training dataset. However, there seem no comparisons to SOTA algorithms in terms of CTTA performance and computational complexity, although they require some access to the training dataset. In addition, as the reduced number of updating parameters does not always imply reduced computational complexity, it is necessary to report time complexity (wall-clock time to process a batch). Lastly, the proposed method may have architecture-dependent effectiveness. Hence, it is also necessary to provide discussion or experiment with various model architectures.\nQuestions:\nIn my understanding, Table 7 reports the performance on the most basic TTA scenario (i.e., no continual setup). Please clarify the setting for Table 7. If my understanding is correct, please provide a fair comparison to existing state-of-the-art (SOTA) methods in CTTA, although SOTA methods need some access to the training dataset. This would help to understand the effectiveness of the proposed method.\nThe proposed method seems an architecture-specific solution. Is it possible to apply FEATHER to other model architectures (e.g., ViT or other CNN-based ones)?\nCan you provide a comparison of TTA methods in terms of time complexity (wall-clock time) per batch? I do understand the time complexity would be proportional to the number of parameters. However, there can be other computational cost in TTA algorithms. For instance, in my understanding, COTTA is particularly slow due to the use of data augmentation to obtain a more robust pseudo-label.\nIn my understanding, it is straightforward to make a variant of COTTA, which updates only BN layers. Noting that adapting BN layers is parameter-effective in TTA, it is also interesting to compare FETHER to the COTTA variant, in terms of parameter complexity and TTA/CTTA performance.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer CBjP", "Subheading": "Official CommentbyAuthors20 Nov 2023, 16:56Everyone", "Content": "Comment:\nThanks for your detailed and insightful comments. In addition to our common response to all the reviewers, we provide below our response to your specific concerns/questions and hope that you will reconsider your original assessment and revise your score as you deem appropriate.\nComparison with other SOTA methods that use source data:\nPlease see our common response.\nMemory usage and wall-clock time comparisons:\nIn our common response, we have explained why we had shown results about savings in the number of parameters and how it results in reductions in memory usage and wall-clock time. We agree with your suggestion that it will be insightful to report these numbers as well, and have performed additional experiments and included these results in the updated version of the paper (Table 7). The table clearly shows that reducing the parameters (specifically\nupdatable parameters\n) directly reduces the memory consumption by a significant margin, as well as the time required for the adaptation. Note that the reported wall-clock times are averaged over all 15 corruptions for all the methods.\nIs the approach architecture-specific?\nPlease see our common response.\nClarification about Table 7:\nWe apologize for the misunderstanding. The experiments in Table 7 (of the original paper), as well as the rest of the paper, follow a\nlifelong/continual TTA\nsetup (not standard TTA). We have updated the caption in Table 7 in the new version of the paper (Table 4 in the updated version of the paper).\nVariant of CoTTA with only BN params updates:\nThanks for your suggestion. In the updated version, we report results (Table 10) not just for CoTTA with BN params but also for EATA (BN params), EATA (all params), and EATA + FEATHER (adapter params). Our experiments highlight that, with a significantly smaller number of trainable parameters, similar performance can be achieved while keeping the source knowledge intact."}, {"Heading": "Last day for the Discussion Period", "Subheading": "Official CommentbyAuthors22 Nov 2023, 01:18 (modified: 22 Nov 2023, 01:21)EveryoneRevisions", "Content": "Comment:\nDear Reviewer CBjP,\nAs the author-reviewer discussion period is about to get over (Nov 22, end-of-day AoE time), we request you to please take a look at our author response (and the updated version of the paper, which incorporates your suggestions and includes the experiments you had suggested) and let us know it your concerns are addressed, and if you have any follow-up questions.\nThanks."}]}, {"Heading": "Official Review of Submission9237 by Reviewer bPzr", "Subheading": "Official ReviewbyReviewer bPzr30 Oct 2023, 02:26 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes an adapter-based method for lifelong test-time adaptation. The authors assume that the given source model is a CNN and insert adapters composed of group convolutions and 1x1 convolutions between the layers of the model. During test time, only the inserted adapter and the batch normalization (BN) parameters of the source model are updated, while the remaining weights are fixed. The experiments demonstrate that the proposed approach achieves performance comparable to state-of-the-art methods, despite updating a very small number of trainable parameters.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThis paper is overall clearly clarified and well organized.\nThe use of adapters for lifelong test-time adaptation seems novel.\nWeaknesses:\nThe proposed method is only applicable to CNNs.\nThe authors argue for the importance of preserving the information of the source model in online TTA tasks. However, the proposed method does not exhibit outstanding performance compared to the CoTTA, which involves full fine-tuning of the model. Therefore, the authors fail to sufficiently explain why the use of adapters is suitable for online TTA tasks, apart from the fact that it reduces the number of trainable parameters.\nThe authors claim that the proposed method excels in terms of parameter update costs; however, the cost of training the adapters inserted between the model's layers, in terms of memory and computation, is not significantly lighter compared to full fine-tuning.\nQuestions:\nIs it possible to apply the proposed method to Transformers?\nWhy does CoTTA generally outperform the proposed method?\nCould you compare the proposed method with other methods in terms of memory and computation?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer bPzr", "Subheading": "Official CommentbyAuthors20 Nov 2023, 16:56Everyone", "Content": "Comment:\nWe thank the reviewer for the comments and suggestions, and are glad that the reviewer finds our idea novel. Please refer to our common response as well as the updated version of the paper that has incorporated the various comments from all the reviewers. Below, we respond to your specific comments/concerns, and we hope that you will consider revising your opinion and consider increasing the score in light of our response.\nIs FEATHER only applicable to CNNs?\nAs we mention in the common response, although we demonstrate our idea for generic CNN-based architectures for computer vision, our idea is general and can be applied to any deep learning architecture (including transformers) that allows the insertion of adapters between layers. Some implementational aspects will need to be changed based on the underlying architecture, but the rest of the idea is more broadly applicable.\nImprovement over CoTTA:\nPlease refer to our common response.\nMemory and computation savings:\nPlease refer to our common response.\nWhy CoTTA \u201coutperforms\u201d our method?\nWe respectfully disagree with this and would like to draw your attention to a few key points (also mentioned in our common response). Please note that, while CoTTA with\nall\nparameters trainable outperforms FEATHER marginally, CoTTA also has significantly more trainable parameters. In contrast, FEATHER only uses ~7.2% to 12.2% trainable parameters and yet performs comparably to CoTTA. Further, we demonstrate in Table 5 that with only 50.32% trainable parameters, FEATHER\noutperforms\nCoTTA, which highlights that even adapting just around half the number of parameters is enough."}, {"Heading": "Last day for the Discussion Period", "Subheading": "Official CommentbyAuthors22 Nov 2023, 01:22Everyone", "Content": "Comment:\nDear Reviewer bPzr,\nAs the author-reviewer discussion period is about to get over (Nov 22, end-of-day AoE time), we request you to please take a look at our author response (and the updated version of the paper, which incorporates your suggestions and includes some additional experiments) and let us know it your concerns are addressed, and if you have any follow-up questions.\nThanks."}, {"Heading": "Post-rebuttal", "Subheading": "Official CommentbyReviewer bPzr22 Nov 2023, 04:58Everyone", "Content": "Comment:\nThanks to the authors for addressing my concerns. However, I still have some concerns regarding the following points:\nOf course, one can imagine applying a similar approach to different architectures, but I believe it is meaningful to actually implement and observe the effects. As far as I know, TTA experiments do not incur high costs, yet despite that, the authors do not provide experimental results for different architectures.\nThe authors emphasize the importance of preserving source knowledge in TTA scenarios, proposing a method that freezes the source model and relies on adapters, but it does not surpass the performance of a full fine-tuning approach. There is a need to deliver contributions beyond confirming observations from existing adapter studies in the TTA scenario.\nThe reduction in memory or computation cost does not proportionally align with the reduction in parameters. To enhance TTA efficiency, there are better adapter-based methods available [1, 2].\n[1] Zhang, Jeffrey O., et al. \"Side-tuning: a baseline for network adaptation via additive side networks.\", ECCV 2020.\n[2] Sung, Yi-Lin, Jaemin Cho, and Mohit Bansal. \"Lst: Ladder side-tuning for parameter and memory efficient transfer learning.\", NeurIPS 2022."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors22 Nov 2023, 09:18 (modified: 22 Nov 2023, 09:21)EveryoneRevisions", "Content": "Comment:\nThank you for engaging in a discussion. We believe there is some potential misunderstanding about some of the key aspects, and we request you to look at our response below, which we hope will clarify the misunderstanding and we hope that you can do a fair assessment in light of these points.\nFor our experiments, for a fair comparison and to assess the improvement of performance over existing methods, we follow the architectures proposed in existing methods on lifelong TTA on the popularly used RobustBench platform, where the architectures are CNN-based. Since the numbers reported by other methods in the lifelong TTA setting use such architectures, it would be unfair to compare them against another architecture, like a transformer-based architecture.\nWe would reiterate that our aim is not to surpass the performance of the full fine-tuning approach but rather to perform at least comparably with a significantly smaller number of parameters (which also translates into memory and time savings, as our results show). Our experimental results show that FEATHER is flexible in terms of the available computational budget and even outperforms CoTTA if the computational budget is increased (roughly 50% of CoTTA budget; please refer to Table 5). Please note the primary aim here is to reduce the computational budget. Moreover, the results in Table 3 for the ImageNet-to-ImageNetC dataset show that FEATHER achieves an improvement with only ~10% of parameters being trained.\nWe respectfully disagree that a reduction in memory or computation cost does not align with the reduction in parameters (as shown in Table 7 and explained in the text around it, we get improvements on these metrics, too).  We would also like to highlight that\nboth the papers mentioned by you are about standard fine-tuning for transfer learning and not for TTA or lifelong TTA\n, whereas our work is about lifelong TTA. Lifelong TTA presents a very different set of challenges than standard fine-tuning, which is done during the training phase, whereas TTA or lifelong TTA must perform fine-tuning at inference time using the unlabeled test input(s).\nWe hope our response above clarifies the potential misunderstandings and that you reconsider your original assessment of our paper. We would be happy to answer any other concerns/comments you might have."}, {"Heading": "Official Comment by Reviewer bPzr", "Subheading": "Official CommentbyReviewer bPzr23 Nov 2023, 03:24Everyone", "Content": "Comment:\nThank you for the comment. My last question is:\nHow does the proposed adapter differ from previously suggested adapters in transfer learning research, and why is it superior in TTA scenarios?"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:05 (modified: 23 Nov 2023, 06:08)EveryoneRevisions", "Content": "Comment:\nThanks for going through our earlier response and the follow-up question. Our response to your question is given below, and we hope that it helps clarify the\ndifference\nbetween adapter design and\nupdate strategies used in lifelong TTA\nand\nstandard transfer learning\n.\nThe adapters used in our work are designed specifically, keeping in mind the challenges posed by TTA and lifelong TTA. Standard adapters used in transfer learning are not directly applicable in TTA (and especially lifelong TTA) because:\n(1) In TTA and lifelong TTA, the adapter parameters are trained at inference time using an\nunsupervised loss\n(which can be CoTTA, TENT, EATA, etc.), whereas, in transfer learning, during fine-tuning on the target domain, the adapter parameters are\ntrained using a supervised loss\ndefined on the target domain's labeled examples. Because of the need for unsupervised adapter parameter updates, we leverage learning objectives that are based on entropy or cross-entropy (utilizing pseudo labels).\n(2) Unlike standard transfer learning, in lifelong TTA, due to the need for unsupervised finetuning, there is a potential risk of error accumulation over longer horizons as the test domains keep drifting over time. Our framework FEATHER, because of the design strategies, such as\nidentity initialization\nof the adapter, ensures that such error accumulation is mitigated effectively.\n(3) In transfer learning using adapters, the adapter updates can leverage the labeled examples for multiple iterations, whereas, in our lifelong TTA setting, we have to operate in an\nonline\nsetting where we do not have the luxury to revisit the unlabeled test samples more than once. In this aspect, too, FEATHER\u2019s adapter update strategy is different from the adapter update used by standard supervised fine-tuning-based transfer learning."}]}, {"Heading": "Official Review of Submission9237 by Reviewer M9Xj", "Subheading": "Official ReviewbyReviewer M9Xj29 Oct 2023, 23:59 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work presents a novel FEATHER method for lifelong/continual test-time adaptation problems. With the lightweight adapter and freezing the base model, FEATHER is able to adapt the source pre-trained model to the non-stationary test distributions without forgetting the source knowledge and eliminate the error accumulation. More specifically, FEATHER inserts learnable adapter in to the source pre-trained model and only updates them with the unlabeled test data. And the work designs zero and identity initialization for adapters to preserving source knowledge. Experiments show that the FEATHER can achieve comparable performance with SOTA by adjusting few parameters.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nLeveraging adapters to address catastrophic forgetting and reduce the accumulation of errors is well motivated.\nThe paper is well organized.\nWeaknesses:\nHow to determine where to insert adapter\uff1fIn the work, a combination of PWC and GCO servers as a basic adapter. And adapters will be inserted in to the model between layers. However, there is no mention of where in the network the adapter should be inserted which is one of the most important aspects of method based on adapters. Where to add, from shallow layer to deep layer, or from deep layer to shallow layer, there is no specific experiment to analyze.\nWhy ZERO AND IDENTITY INITIALIZATION preserves the source knowledge? Maybe a residue architecture with zero initialization will be more simple and effective?\nDifference with ECoTTA [1]. In fact, adding adapters between layers has already been proposed in ecotta, and in their analysis experiments, they tried a similar variation of the method in their paper (refer to Architecture design in Section 4.2 in ECoTTA [1]). The choice and novelty of adapter structure is still open to question.\nWhat we should be noticed is that parameter efficient does not mean resource efficient! Inserting adapter into the original model will leads more computational resource including FLOPTS and memory of GPU. But there was little or no performance improvement.\nOver claim on the combination of other methods. Combined with tent and cotta, there is no performance improvement.\nWhat is the objective function in the experiments of Table 1,2,3,4,5?\nThe formulation of Lifelong/Continual Test-time adaptation have some inconformity with existing literature. In CoTTA [2], it is define as adapting the model to the test samples and make predictions for them in an online manner. The description in section 2 seems like an offline fashion.\nRefecrence:\n[1] Song et al., Ecotta: Memory-efficient continual test-time adaptation via self-distilled regularization. In CVPR, 2023.\n[2] Wang et al., Continual test-time domain adaptation. In CVPR 2022.\nQuestions:\nPlease refer to [Weakness].\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer M9Xj", "Subheading": "Official CommentbyAuthors20 Nov 2023, 16:56Everyone", "Content": "Comment:\nWe thank the reviewer for the comments and suggestions. We request the reviewer to take a look at the common response and the updated version of the paper, which incorporates your and other reviewers\u2019 suggestions. Below, we provide some clarifications regarding the results and novelty of the proposed approach. We hope that you will consider revising your assessment and raising your score.\nDeciding where to add adapters:\nOur approach based on adding adapters in between the layers is generic. Based on the computational budget of the deployment environment, the adapters can be added to the main architecture. In the updated version of the paper, we report the locations of the added adapter layers in Appendix F, and the configs for all the architectures will be released with the code base. The location of adapter parameters is dependent on the TTA environment. For example, if the expected noise is corruption, the domain shifts are expected in the initial layers, whereas if the domain shifts occur in semantic space, the suitable adapter locations would be in the deep(er) layers (close to the output layer). In the TTA setting, all the information about the domain shifts is usually not available a priori. To be generic and comply with the TTA setting, this decision should be made based on the dataset and the architecture for which FEATHER is being used. In our experiments and lifelong TTA settings, it would be unfair to predefine/suggest/assume any details related to the domain shifts. Hence the location of the used adapters is generic. (As described in Appendix F)\nZero and Identity initialization vs residue architecture:\nThe zero and Identity initialization preserves source knowledge since it acts as an identity operation to begin with during the start. Even though a residue architecture with zero initialization is simpler, it is not as effective as our proposed PWC and GCO-based adapters. In our earlier experiments, we found that, when adding a residual layer, the network collapses when the domain changes occur in the continual setting and adapter parameters are updated. We speculate the primary reason to be the flow of signal to pass through the added parameters and, after the update, the network starts to collapse. We also tried some other initialization schemes like near zero init; however, those do not work well with the continual TTA setup.\nDifference with EcoTTA:\nAs compared to EcoTTA, FEATHER employs more sophisticated adapters, which is supported by better performance in continual TTA, shown in Table 4 (Table 7 in the previous version), where we compare with EcoTTA as well. Please refer to general comments for more discussion and comparison with EcoTTA. Also, one may refer to section 4.2 of the EcoTTA paper for architecture-specific details, which are quite different from FEATHER.\nSavings in terms of computational/memory requirements:\nThanks for pointing this out and making this suggestion. We report the memory and compute savings in the general response and have updated the paper to also include these results. Our approach is more resource-efficient in terms of computational resources such as memory and FLOPs, which are usually required during the backward passes done during adaptation in test time. Further, we perform better than EcoTTA and other SOTA approaches in continual TTA, as highlighted in Table 4.\nImprovements when combining FEATHER with other methods:\nWe respectfully disagree that there is no improvement when FEATHER is combined with methods such as TENT and CoTTA. As compared to standard TENT and CoTTA, which require updating all the parameters (100%) during adaptation,  when these methods are augmented with FEATHER, significantly fewer parameters need to be updated, as shown in Table 6. Note that (as we mention in our common response as well as reported by the additional experiments) a reduction in trainable parameters directly affects the memory budget requirement as well as inference/adaptation time  (Table 7).\nThe objective function:\nThank you for pointing this out. The objective function in the experiments of Tables 1,2,3,4,5 is the same as that of CoTTA. We briefly mention this in the second line of Section 5.2. In the updated version of the paper, we highlight this in the table captions as well.\nInconformity in the formulation of Lifelong/Continual TTA:\nNote that, in Section 2, we start by defining the standard (non-continual) TTA setting. However, in the second last paragraph, we define the continual/lifelong TTA setting. Since the primary focus of this work is the behavior of adapters in a continual setting, we follow the continual setup for the entire experiments and results section and report the observed findings."}, {"Heading": "Last day for the Discussion Period", "Subheading": "Official CommentbyAuthors22 Nov 2023, 01:22Everyone", "Content": "Comment:\nDear Reviewer M9Xj,\nAs the author-reviewer discussion period is about to get over (Nov 22, end-of-day AoE time), we request you to please take a look at our author response (and the updated version of the paper, which incorporates your suggestions and includes the experiments you had suggested) and let us know it your concerns are addressed, and if you have any follow-up questions.\nThanks."}]}, {"Heading": "Official Review of Submission9237 by Reviewer F1KC", "Subheading": "Official ReviewbyReviewer F1KC16 Oct 2023, 06:54 (modified: 05 Dec 2023, 03:50)EveryoneRevisions", "Content": "Summary:\nThis work tackles the problem lifelong Test-Time Adaptation (TTA): adapting on a sequence of domain shifts presented at test time. The authors propose FEATHER; an orthogonal approach to TTA methods in the literature.\nInstead of adapting the weights of the pretrained model at test time, FEATHER inserts learnable adapters as additional modules in the network while keeping the original model parameters frozen.\nThe inserted adapters are initialized with identity mapping, so that the non-adapted model preserves its performance on source data.\nExperiments are conducted on four standard TTA benchmarks: CIFAR10-C, CIFAR100-C, ImageNet-C, and ImageNet-3DCC.\nThe experimental results show that FEATHER achieves competitive performance compared to state-of-the-art methods while adapting smaller number of parameters.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nThis work has the following strengths:\nThe problem this work tackles is both important and practical. Pretrained models are likely to experience domain shifts at test-time and adapting them on the fly is essential to ensure their reliability.\nThe proposed approach is easy to understand and simple to implement.\nThe experiments conducted in this work cover several standard benchmarks to prove the robustness of FEATHER.\nWeaknesses:\nDespite the strengths of this work, there are few weaknesses that should be addressed.\n(1) FEATHER lacks the strong objective. The proposed approach seem not improve performance nor efficiency. I will explain next.\n(1a) From the performance perspective, FEATHER does not provide performance improvement over other baselines (e.g. CoTTA).\n(1b) From the efficiency perspective, while FEATHER updates a smaller percentage of network parameters when compared to CoTTA, FEATHER is less efficient than CoTTA. In essence, FEATHER adds extra parameters to the network making the forward pass more expensive. Further, the gradient calculation for conducting an update step of FEATHER and CoTTA are similar since FEATHER adds its adapters after every layer. Hence, the gradient will require a back propagation through the entire network.\n(2) Missing experiments. While the experiments in this paper covered 4 benchmarks, there are key experiments missing to validate the effectiveness of FEATHER.\n(2a) Performance comparison. Strong and efficient baselines such as EATA, ECoTTA, and SAR shall be included in the main evaluation comparison. Appendix D only provides the comparison under one setup (ImageNet-C).\n(2b) Since FEATHER is an orthogonal approach to TTA methods, why is it assumed that it does not need accessing source data? For example, if FEATHER is combined with EATA, source data is necessary for the anti-forgetting regularizer. Having said that, I think it is necessary to compare FEATHER to TTA methods that leverage source data.\n(2c) Efficiency measures.  The efficiency comparison in this work is based on the percentage of parameters being updated compared to the total number of parameters. I am not sure if this is the right way to compare different TTA methods. First, FEATHER adds extra parameters to the network, and thus by construction, its forward pass is slower than the baseline (e.g. CoTTA). A comparison in terms of runtime and memory usage is more necessary. It is worth mentioning that methods like Tent and EATA only update the normalization layers making them even more efficient than FEATHER.\n(3) Writing. The writing of this paper can be vastly improved in several places such as:\nThe mathematical notation and problem description is not clear. In section 2 $f_\\theta$ outputs the prediction $\\hat y$ at the beginning, and later in the same paragraph it is assumed to output a probability vector.\nThe notation in the last paragraph in Sections 3.1 and 3.2 are not clear. What is the element wise addition? how is that different from a regular addition? What is the input and output shapes of the adapting layers?\nSection 3.3 should mention that FEATHER leverages the same loss function as CoTTA. It was only clear in the experiments how exactly the adaptation is conducted.\nQuestions:\nSuggestions: Here are some additional suggestions regarding the paper writing and organizing. Note that these comments were not taken into consideration in the paper evaluation.\nBoth Figure 3 and section 3.2 are conveying a very simple message: Initialize the adapters with identity mapping. I would rather invest this space in more experiments with more insights (e.g. combining FEATHER with EATA).\nFormatting and writing: The proposed method is simple while the methodology section is not. I would try to simplify the writing of Section 3 and remove redundant paragraphs.\nPlease consider reorganizing the tables in page 7 such that each table is presented with its own paragraph.\nFor ImageNet-C experiments, please consider a similar setup to the CIFAR10/100-C experiments where the corruptions are ordered, similar to the continual evaluation in EATA.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer F1KC", "Subheading": "Official CommentbyAuthors20 Nov 2023, 16:56Everyone", "Content": "Comment:\nThanks for your detailed review and positive remarks about our work tackling an important and practical problem, approach to be easy and simple to implement, and experimental evaluation on various benchmarks to be robust.\nWe believe that there is some potential misunderstanding regarding some key aspects. We request the reviewer to take a look at our common response (and the revised version of the paper which incorporates the various suggestions). In addition, we also respond below to the reviewer\u2019s individual comments. We hope our response will help address the questions/concerns and that the reviewer will reconsider the original assessment and consider raising the score.\nPerformance comparison of FEATHER vs. CoTTA:\nTable 3 clearly demonstrates that, for ImageNet-to-ImageNetC, FEATHER, with only 10.92% trainable adapter parameters, outperforms CoTTA (which adapts all (100%) of the network parameters) in terms of error rate. Further, Table 4 shows that FEATHER\u2019s performance is\ncomparable\nto CoTTA and other approaches, even\nwith only 6.71%\ntrainable adapters, while\noutperforming\nall these methods\nwith as few as 50.32%\ntrainable parameters (Table 5). FEATHER can be used with any desired number of trainable parameters depending on the computational budget. In Table 7 in Appendix of the old version (Now Table 4 in the main paper), FEATHER with CoTTA-based TTA objective outperforms EcoTTA for both CIFAR10-to-CIFAR10C and ImageNet-to-ImageNetC datasets. For ImageNet-to-ImageNetC datasets, FEATHER outperforms all the other approaches, including EcoTTA and CoTTA.\nEfficiency comparison of FEATHER vs CoTTA:\nWe believe the reviewer has missed a very important point here. The gradient calculation for conducting an update step of FEATHER and CoTTA is not similar. In FEATHER, the adapters are only present for some layers depending on the budget for the parameters. Thus, FEATHER does not introduce adapters after every layer. We have added the following line in section 3.1 to clarify this point: \u201cIn practice, we only insert the adapters in a few locations, depending on the computational and memory budget.\u201d. Further, the\nbackpropagation only requires the computation of gradients of the adapter parameters and not the entire network.\n(also see Appendix F for the architecture-specific adapter locations in detail.) Thus, FEATHER drastically improves the parameter efficiency over CoTTA. This is also reflected in the memory saving and wall-clock timing, which we have reported in the rebuttal (as requested by Reviewer CBjP) and in the updated version of the paper.\nComparison with baselines such as EATA, ECoTTA:\nIn Appendix Table 7 in the previous version (now Table 4 in the main paper), we have reported the results for the experiments on CIFAR10-to-CIFAR10C and ImageNet-to-ImageNetC, and FEATHER performs better than EcoTTA, which uses EATA loss.\nAccess to source data:\nThe initialization mechanism that we propose for FEATHER adapters circumvents the need for warm-up training of the adapters as in EcoTTA. Our approach does not inherently need source data for warm-up like EcoTTA. Our contribution is on the architectural aspect; however, if one wishes to use a learning objective like EATA, which depends on the source data for computing Fisher information, along with FEATHER, the source data would be utilized. However, this is a requirement of EATA and not that of FEATHER. We report the results of EATA + FEATHER in the updated version of the paper. (Table 6 and Table 7)\nEfficiency (memory/run-time) comparisons:\nWe have added the comparison in terms of runtime and memory usage in our common response. We provide detailed reasons for comparing the methods based on the number of trainable parameters.  We believe there is some misunderstanding regarding the results reported for TENT (the entire network). We would like to highlight that the TENT (100% trainable) is an additional setting run by us for a transparent comparison. The original TENT method using only BN params performs poorly in the continual setting due to error accumulation and forgetting over time."}, {"Heading": "Response to Writing and Suggestions", "Subheading": "Official CommentbyAuthors20 Nov 2023, 16:58Everyone", "Content": "Comment:\nWriting:\nThanks for pointing out the places where you found the writing to be unclear. In particular, we would like to clarify that:\nBy output, we meant the softmax probability vector (the predicted label corresponds to the index of the maximum value in the vector). We have clarified this.\nIt should be an element-wise addition throughout; the regular addition is a typo. The output and input shapes of the adapter layers are equal and will depend on the location in the architecture where the adapter layers are added; for example, if the ith layer has an output shape of 32x32x15 and we add the adapter layer between ith and i+1th layer the adapter\u2019s input and output shape would be 32x32x15, hence resulting in identity mapping of feature space during the initialization.\nWe do not explicitly mention CoTTA loss in Section 3.3 because our approach is generic to be used with various losses. In the experiments, we utilize CoTTA loss.\nOther suggestions:\nThanks for the suggestion about Figure 3 and section 3.2. We have updated the paper accordingly and have also added more experiments with FEATHER+EATA for comparison with EATA. Results are updated in Table 6.\nWe have incorporated the writing and formatting suggestions in the updated version and have also adjusted the locations of the tables.\nIn the updated version, we have included the results for ordered corruptions for ImageNet-C experiments (similar to EATA).\nThe lifelong setting reported by EATA includes switching between the corruption and the source domain in an alternating fashion (please refer to\nhttps://github.com/mr-eggplant/EATA/blob/main/main.py#L123\nfor the official implementation), making it different from the followed lifelong definition of CTTA methods where the unseen domains (corruptions) are encountered in a continual fashion.  Nevertheless, for transparency, we report the FEATHER results with the EATA number taken from the paper directly (Table 11 in EATA paper). The comparison is presented below. Note that FEATHER shows an improvement over the average error rate, though the per corruption error rate reported by the EATA paper performs better, highlighting the overall effectiveness of FEATHER over EATA.\nGauss.\nShot\nImpul.\nDefoc.\nGlass\nMotion\nZoom\nAvg.\n$34.9_{ \\pm 0.2}$\n$36.9_{ \\pm 0.1}$\n$35.8_{ \\pm 0.2}$\n$33.6_{ \\pm 0.3}$\n$33.3_{ \\pm 0.2}$\n$47.2_{ \\pm 0.3}$\n$52.7_{ \\pm 0.1}$\n$35.8_{ \\pm 0.2}$\n$26.58_{ \\pm 0.07}$\n$25.25_{ \\pm 0.079}$\n$28.94_{ \\pm 0.068}$\n$24.35_{ \\pm 0.08}$\n$22.57_{ \\pm 0.06}$\n$35.91_{ \\pm 0.07}$\n$41.61_{ \\pm 0.03}$\n$37.36_{ \\pm 0.02}$"}, {"Heading": "Last day for the Discussion Period", "Subheading": "Official CommentbyAuthors22 Nov 2023, 01:20Everyone", "Content": "Comment:\nDear Reviewer F1KC,\nAs the author-reviewer discussion period is about to get over (Nov 22, end-of-day AoE time), we request you to please take a look at our author response (and the updated version of the paper, which incorporates your suggestions and includes the experiments you had suggested along with the additional comparisons) and let us know it your concerns are addressed, and if you have any follow-up questions.\nThanks."}]}]}, "GrunXMbdXY": {"paper_info": {"Supplementary Material": "pdf", "Primary Area": "societal considerations including fairness, safety, privacy", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Label inference attack, Large-scale language model, Matrix flattening", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We develop a label inference attack based on gradients from federated large language model training, which can identify tokens used in training even when applied to large batches as used in modern large language models with large vocabulary sizes.", "Abstract": "Gradient exchange is widely applied in collaborative training of machine learning models, including Federated Learning. Curious-but-honest participants could potentially infer the output labels in recently used training data by analyzing the latest gradient updates. Previous works mostly demonstrate the attack performance under constraint training settings, such as dozens of short sentences in a batch and a small output space for labels. In this work, we propose a novel gradient flattening attack on the last linear layer of a language model, which significantly improves the attacker's efficiency in inferring the words used in training. We validate the capability of the attack on two language generation tasks: machine translation and language modeling. The attack environment is scaled up to industrial settings of a large output vocabulary and realistic training batch sizes. To mitigate the negative impact of the new attack, we explore two defense methods and demonstrate that adding differential privacy with small noise could effectively defend against our new attack without degrading model utility.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9236", "PDF Url": "https://openreview.net/pdf?id=GrunXMbdXY"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9236 by Area Chair teyD", "Subheading": "Meta ReviewbyArea Chair teyD06 Dec 2023, 05:57 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis submission suggests a new approach to bag of word recovery in gradient inversion attacks in federated learning. However, the submisson appears unaware of the equivalence of the word recovery problem to the label recovery problem, and thus does not provide comparison to a number of related work and algorithms solving the same task [1,2,3]. The task of word recovery is standard as initial step in recent gradient inversion attacks against language models  [4,5]. The omission of these comparisons makes it hard to contextualize this work, and I encourage the authors to revise their manuscript now that they have been provided additional information on the current state of the field. \nFurther, it is not always clear how important perfect word recovery really is. In [4,5], sentence recovery can succeed even if word recovery is only inexact, and in sufficiently large batches of data, word frequency can also be estimated from real data and used instead of word recovery. \n\n\n[1] Yin, Hongxu, et al. \"See through gradients: Image batch recovery via gradinversion.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n[2] Wainakh, Aidmar, et al. \"User-level label leakage from gradients in federated learning.\" arXiv preprint arXiv:2105.09369 (2021).\n[3] Geng, Jiahui, et al. \"Towards general deep leakage in federated learning.\" arXiv preprint arXiv:2110.09074 (2021).\n[4] Samyak Gupta, Yangsibo Huang, Zexuan Zhong, Tianyu Gao, Kai Li, and Danqi Chen. 2022. Recovering private text in federated learning of language models. In Advances in Neural Information Processing Systems\n[5] Fowl, Liam H., et al. \"Decepticons: Corrupted Transformers Breach Privacy in Federated Learning for Language Models.\" The Eleventh International Conference on Learning Representations. 2022.\nJustification For Why Not Higher Score:\nMissing comparison to related work.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9236 by Reviewer 2HVX", "Subheading": "Official ReviewbyReviewer 2HVX01 Nov 2023, 04:36 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper investigates the recovery of the set of words used during federated training of a large language model for the tasks of language modeling and machine translation. The paper proposes an attack, known as \u201cFlat-Chat\u201d, which is able to extract the set of words from the last linear layer\u2019s gradients. To do so, Flat Chat transforms last linear layer gradients and uses a gaussian mixture model to form two clusters (positive/negative), corresponding to tokens which (are/are not) used in the batch, respectively. \nThe paper also proposes two defenses (freezing and DP-SGD) against the attack.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe paper is easy to understand, and the methodology is novel and intuitive. The proposed method demonstrates performant recovery of a majority of tokens from the last linear layer, demonstrating significant leakage of tokens which does not depend on gradients of input embeddings.\nWeaknesses:\nExperimental results could be more comprehensive. In particular, more exploration (e.g. of larger batch sizes) would establish the failure mode of the approach.\n\nI am also curious about the gaussian mixture model of the word types; Does the frequency of each word in the batch impact the quality of the fit? Experiments that demonstrate robustness in this scenario would be helpful in establishing generality of the approach.\n\nFinally, further experiments which show performance of freeze/dp-sgd for language modelling would also help contextualize the benefits and drawbacks of the proposed defenses.\nQuestions:\n* I am a bit confused why results for Scratch with the task of Large Language Modelling are not included\n\n* Is the gaussian mixture model accurate at every epoch of fine-tuning? Or is it only at the first epoch?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 2HVX", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:44Everyone", "Content": "Comment:\nThank you for your appreciation and suggestions. \n\n---\n\n**W1:** more exploration (e.g. of larger batch sizes) on the failure mode of the approach.\n\n**A1:** (1) We have covered some experiments with the *failure* performance of RLG, such as 1,500 and 2,000 tokens in Table 2. (2) When scaling the batch size, the attacker will still be valid as we find **Prec.** score of FlatChat is kept stable or even grows in some cases (see Tables 2 and 3), which benefits from a relatively conservative batch size predictor.\n\n---\n\n**W2:** Does the frequency of each word in the batch impact the quality of the fit?\n\n**A2:** We consider it as a question out of curiosity instead of an argument of weakness. It is implicitly encoded in our Theorem 3, as scores of high-frequency words will be at the `centre\u2019 of the positive cluster. \n\n---\n\n**W3:** further experiments which show performance of freeze/dp-sgd for language modelling\n\n**A3:** Yes, we have demonstrated the performance of both freeze and dp-sgd on Machine Translation task in Figure 4.\n\n---\n\n**Q4:** why results for Scratch with the task of Large Language Modelling are not included\n\n**A4:** In many LLM application scenarios, we directly use well-trained LLM instead of LLM from scratch. Additionally, attacking Scratch is a relatively easier experimental setting for attackers as demonstrated in Machine Translation tasks.\n\n---\n\n**Q5:** Is the gaussian mixture model accurate at every epoch of fine-tuning? Or is it only at the first epoch?\n\n**A5:** GMM could be easily generalized to various settings:\n1. The feasibility of the Gaussian Mixture Model is proved by our Theorem 3 based on Theorem 4 (CLT) \n2. FlatChat empirically works on well-finetuned models, such as MT\u2019s FINETUNE and GPT-2. \n3. Because the data leakage in the later epochs is of less interest given the data has already been disclosed in the earlier epochs, we focus on the token recovery attack in the early training epoch. \n4. Any gradient-based reconstruction attacks will fail in an extreme case, say the model overfits a batch of data leading to zero loss and zero gradient vectors."}]}, {"Heading": "Official Review of Submission9236 by Reviewer t7LN", "Subheading": "Official ReviewbyReviewer t7LN31 Oct 2023, 13:21 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a privacy attack FLAT-Chat which recovers the set of words used in training a language model in the federated learning setting. The attack only assumes observing the gradients of the last linear layer instead of the embedding layer (as in previous work).  FLAT-Chat is inspired by the observation that the output layer gradients follow two distinct distributions for tokens used in v.s. not in training. Based on this, FLAT-Chat fits these two distributions with a two-mode Gaussian mixture, and then finds the cluster positive cluster where top K tokens are selected as the predicted training tokens. The attack is evaluated on machine translation and language modeling tasks on benchmark datasets and achieves much better attack efficiency than the previous attack Revealing Labels from Gradients (RLG).\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\n- This attack method is novel and based on an interesting empirical observation that the gradient norm distribution is a mixture model and these two mixtures correspond to tokens in/out of the training batch.\n- The attack is highly efficient and accurate as shown in Table 2, where an adversary can easily mount this attack to learn the tokens from users, demonstrating a realistic privacy concern.\nWeaknesses:\n- Some writings can be simplified, e.g. the lemmas and their proofs in Section 3.2 are simple rearrangement using some basic linear algebra which can be condensed in Equations and will not impact their readability. The theorems and the body texts are interleaved which makes the explanation of the attack less easy to follow. \n- In common practice, when training language models, the parameters of the embedding layer and the last layer are typically shared, i.e. they have the same gradients. It would be a stronger attack if this more common scenario is considered.\n- The attack is limited to inferring the bag of words while the order of the words cannot be recovered.\nQuestions:\n- How would tying the weights between input embedding and output layer change the performance of the attack?\n- Another potential defense is secure aggregation, where the server can only observe the aggregated gradients instead of individual\u2019s. How might this impact the attack? Could the adversary still infer useful information when the set of participants is large?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer t7LN", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:45 (modified: 23 Nov 2023, 06:06)EveryoneRevisions", "Content": "Comment:\nThank you for your comments and suggestions. We hope the following clarifications can address your concerns.\n\n---\n\n**W1:** Some writings can be simplified, e.g. the lemmas and their proofs in Section 3.2 can be condensed in Equations and will not impact their readability.\n\n**A1:** The proof of the properties is one of the key findings in this work as they ground the success of our word recovery attack. We sincerely appreciate your suggestions, and we will rearrange this content in our revision for better readability.\n\n---\n\n**W2:** It would be better to consider the common practice of the embedding layer and the last layer sharing the same parameters in a language model.\n\n**A2:**  Yes, we have conducted tests on this setting in our preliminary study on MT tasks and our method has demonstrated successful outcomes. However, it is important to note that the share-embedding setting exposes both embedding and the last linear layers to data reconstruction attacks. \n\n---\n\n**W3:**  The attack is limited to inferring the bag of words while the order of the words cannot be recovered.\n\n**A3:** Word reconstruction could also pose a privacy risk in instances like exposing trade secrets, healthcare patient diagnosis, or personal identifiable information (PII) such as credit card numbers. Furthermore, consolidated word reconstruction could serve as the first step of sequence reconstruction techniques, followed by iteratively swapping tokens and training them within a language model, as adapted in the prior work FILM and LAMP.\n\n---\n\n**Q4:** How would the performance change when tying the weights between input embedding and output layer?\n\n**A4:** Our implementation is in the context of weight tying and has demonstrated successful outcomes. We will add such an explanation to our revision.\n\n---\n\n**Q5:** Will the inference attack still be effective if using secure aggregation as defense? where the server can only observe the aggregated gradients instead of individual\u2019s.\n\n**A5:** Thanks for your question. That is why we need to consider the setting with more training tokens involved. It is worth noting that aggregating (say averaging) gradients from multiple batches (say from various clients) is equivalent to the gradients acquired from the `aggregated' (say concatenating all samples in these batches as a single batch) larger batch."}]}, {"Heading": "Official Review of Submission9236 by Reviewer CmSz", "Subheading": "Official ReviewbyReviewer CmSz31 Oct 2023, 07:37 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents a novel attack reconstructing client's tokens in federated model training.\nThe authors apply two-cluster Gaussian Mixture Model(GMM) to better classify the positive tokens (those involved in training) and negative tokens, and provide a theoretical analysis proving their attack effectiveness. \nExperiments on Language Modeling (LM) and Machine Translation (MT) show that FlatChat is more efficient and effective than previous method RLG.\nFinally, the authors apply two defenses, FREEZE and DP-SGD, to mitigate the attack, where the former one can hurt model utility and the latter one is found an ideal solution for both model privacy and utility.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\n1. **Interesting research problem**. Recovering exact user input from the uploaded gradient is challenging and even harder for language model because of discrete nature of texts, so the paper has good originality. \n\n2. **Attack with theoretical analysis**. This paper provides a new perspective from token distribution to infer the user's training texts in federated learning. The use of GMM permits infer trained tokens from gradients of a large batch of texts.\nWeaknesses:\n1. **Attack significance is low** because the order of tokens cannot be recovered. As the attack relies on gradient distribution of positive and negative tokens, the tokens' order information is hidden and not recovered. Although word distribution can leak partial privacy, in my opinion, this information is important to infer privacy underlying the training text. As a simple example, the two texts X = \"A is good, B is bad\", and Y = \"A is bad, B is good\" have the same word distribution but totally different meaning. I suggest the author to focus on or highlight specific scenarios where the word distribution can leak sufficient privacy. For example, it is possible to conduct an end-to-end case study showing how recovered tokens can lead to a more severe consequence.\n\n2. **The technical challenge is not clear.** As Fig.2 shows, most negative tokens have vector $s$ value between 0 and 0.02. While the I appreciate the authors' efforts in visualization, it makes me doubt whether the GMM is necesssary. As the next word prediction resembles to classification, a naive baseline can apply iDLG-similar approach to directly identify (for example, with threshold) the trained words (positive tokens). Note that iDLG also leverages the last layer's gradient to infer the labels of trained samples. In this sense, the GMM is only used to better classify positives and negatives. I suggest the authors to make the attack motivation and challenges more clear in the paper.\n\n3. **Problem importance is unclear.** From the main text, I cannot see that FL is a common solution for training/finetuning LMs, especially the large ones.  Although the authors have provided a long list of related works of training data inference attack in FL, I think it is still important to show that FL is or will be applied by organizations through real-world examples or case studies.\nThe only application I can imagine is using FL on mobile keyboard to predict the user's input behavior more accurately, but I'm not sure whether it trains such LMs. According to my experience, finetuning current LMs requires relative large memory, which is impractical to proceed on edge devices. \nPlease illustrate potential FL applications for LM training.\n\n4. **Comparison with more baselines is needed.** I note that in Table 1 a recent work FILM also infers trained words but is not compared in Section 4.2.1. I also notice that there is a slight difference between FILM and this work in terms of $\\Delta W$ but I think under FL setting the FILM can also work. Please consider compare with this attack or clarify why it is not suitable for comparison.\n\n5. **Defense (DP-SGD) can mitigate the attack, further reducing the attack significance.** To be honest, I'm quite surprised that small noises added by DP-SGD can mitigate the attack, which is different from the conclusion in (Gupta et al. 2022). This means that this previous attack is more powerful than proposed attack because DP-SGD can not defend it without degrading the model utility.\nQuestions:\nPlease see my concerns in weaknesses. Besides, I also have the following questions:\n\n1. What is the learning rate used in attack and DP-SGD? What is the resultant budget ($\\epsilon$, $\\delta$)?\n\n2. What does the 'Loss' in Figure 4 mean? Training loss or validation loss?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNone\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer CmSz", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:49 (modified: 23 Nov 2023, 06:08)EveryoneRevisions", "Content": "Comment:\nThank you for your comments and suggestions. We hope the following clarifications can address your concerns.\n\n---\n\n**W1:** Attack significance is low because the order of tokens cannot be recovered.\n\n**A1:** Revealing the training word types could also infringe serious risk for the scenarios requiring brief context, like healthcare diagnosis or personal identifiable information (PII), including credit card numbers and social security numbers. The significance of our work lies in that we are the first work that scaled up the word reconstruction attack to *industrial* settings, such as more than 10 K tokens in a batch, vocabulary size larger than 50 K and extremely fast inference speed. Furthermore, consolidated word reconstruction could serve as the first step of sequence reconstruction attacks, followed by iteratively swapping tokens and training them within a language model, as adapted in the prior work FILM and LAMP [1].\n\n\n---\n\n\n**W2:** The technical challenge is not clear, as prior work iDLG also leverages the last layer's gradient to infer the labels of trained samples in classification tasks.\n\n**A2:**  The focus of the iDLG is to infer the input data X, and it requires gradients from all layers. The usage of last layer gradients is just to infer the classification label for better gradient matching. However, our method focuses on inferring the output data Y from a single last layer's gradients. \n\n---\n\n**W3:** Please illustrate potential FL applications for LM training.\n\n**A3:**  The LM training can be under the scenarios like training LM for medical reports, financial reports, keyboard as mentioned etc. In many scenarios, the text corpus would be kept in clients for privacy concerns and FL will be their first choice in training shared powerful LMs (which could be used for many purposes, such as classification, QA, NLI, NLG, etc.).\n\n---\n\n\n**W4:** Including FILM as baseline for performance comparison.\n\n**A4:**  FILM targets sequence recovery while our work focuses on *industrial-scale* word recovery attack. Nonetheless, our work could serve as the first *Bag-of-Words* Extraction step of FILM.\n\n---\n\n\n**W5:** The attack significance is downgraded as it can be defended by DP-SGD. \n\n**A5:** The significance of our work is (1) We propose a new word recovery attack which works on *industrial-scale*, with theoretical proof and extensive empirical evidence; (2) We demonstrate the risk could be mitigated by DP-SGD. Our work enhances the motivation of using a proper security schema in FL. It is unfair to discredit a novel attack merely because it could be potentially defended, e.g., the many attack methods, FILM and LAMP [1], proposed by recent literature could also be defended by DP-SGD to some extent.\n\n---\n\n\n**Q6:** Used learning rate and the privacy budget in DP-SGD. \n\n**A6:** Our experiments use a learning rate of $5 \\times 10^{-4}$, as detailed in the footnote of Section 4.1, which introduces the experimental setup.  We will include the privacy budget in our revision.\n\n---\n\n**Q7:** What does the 'Loss' in Figure 4 mean?\n\n**A7:** The \u2018Loss\u2019 in Figure 4 denotes the averaged cross-entropy loss, indicating the utility (how efficiently it operates in a language prediction task) of a language model. We will include an explanation in our revision.\n\n---\n\n\n[1] LAMP: Extracting Text from Gradients with Language Model Priors (NeurIPS 2022)"}]}, {"Heading": "Official Review of Submission9236 by Reviewer 3Q3Y", "Subheading": "Official ReviewbyReviewer 3Q3Y30 Oct 2023, 06:26 (modified: 10 Nov 2023, 16:04)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a new gradient label leakage procedure. The procedure \"flattens\" the gradients of the last linear layer of the network and decomposes it into two terms corresponding to samples that are correctly classified and those that are not. Each term is approximated with a Gaussian whose unknown parameters are fitted jointly with a GMM on additional data. Then, each possible label is ranked based on its likelihood of being present in the data batch calculated using the parameters of those Gaussians. Finally, the total number of different labels present in the batch is estimated based on linear regression over the weights of the two Gaussian weight factors. This in combination with the ranking, produces the set of labels present in the data batch. The authors apply this technique to federated learning of LLMs and machine translation algorithms to leak the set of tokens that are used to train the Transformer models. The authors demonstrate this procedure results in 0.7/0.8 F1 score for large batches of many individual tokens with realistic-sized vocabularies.\nSoundness:\n2 fair\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\n- Experiments on fairly large models ( GPT-2 )\n- Experiments on large sequences and batches\n- The use of GMM is interesting\nWeaknesses:\n- **The description of the proposed method can be hard to read at times:**  \nI know a lot about this particular area of research and I still struggled to follow the presentation of Section 3 (the technical contribution section). To this end, in my opinion, the paper will really benefit from a paragraph (probably coupled with a summary figure) that summarizes the steps of the proposed method early on in Section 3, so that it is easier to follow what the paper is trying to achieve through the different subsections of Section 3. It needs not be long, consider something like the beginning of my paper summary above. Similarly, presenting the full algorithm at the end of Section 3 will help a lot in understanding how the different pieces of the algorithm fit together. Further, the paper will also benefit from giving more intuitive explanations of its steps throughout. One example of this will be to present Eq. 9 before Theorem 3 to make it intuitively clear where the GMM pieces come from in Eq.6. Finally, there are several key missing from Section 3. It should explicitly state that the GMMs and the regression model on $\\|\\mathcal{T}\\|$ need to be fitted on auxiliary data, and how estimating the number of unique tokens from the regression model is used together with the ranking to provide the set of recovered tokens. It should also state that during the LLM training, when multiple tokens are predicted, the CE loss is summed across all of them which mathematically is equivalent to the label recovery from a large batch. \n- **Citating and comparing to prior work:**  \nThe paper should cite and compare against prior label reconstruction attacks outside of RLG [5]. In particular, [1] can be used for recovering the set of unique tokens, while [2,3] can be used to recover the counts as well. Comparing against [1-3] is absolutely crucial, in my opinion, for accepting this paper, as those methods would work fast for large vocabularies and long sentences, unlike RLG, and have been shown to be effective at recovering labels to very good accuracy. Further, [2], in particular, is very closely related to FLAT-CHAT, as it derives the same \"flattening\" operation the authors claim as a contribution in the text. To this end, the authors should not claim the flattening operation as a contribution and instead clearly mark the derivation presented there as equivalent to the one made in [2].\nGiven the similarities to prior work, the authors should also consider including an explicit discussion of how their method differs from prior work. Finally, the authors acknowledge that FILM [4] can be applied to the same problem the authors consider but from the input side of the network. Yet, they do not provide a comparison. While beating it is not required for acceptance (due to the different requirements the attacker has), comparing against it is a good idea.\n- **The attack setting:**   \nLabel leakage attacks like [2] and [3], are capable not only of recovering the set of unique tokens in input data but also their counts. The authors should provide a discussion on whether counts are important from LLM privacy point of view.   \nFurther, the authors should better motivate their attacker's goal in general. While privacy is indeed violated by knowing the set of tokens fed to the network from a purely theoretical point of view, I would reasonably think that a large percent of the vocabulary tokens occur in a large batch of long excerpts of text anyway, and when the recovery has a precision of 0.85 and recall of 0.5 it will be very hard from a practical perspective to gain any reasonable sensitive information. That is, I expect the rank of rare tokens, which tend to be more private, to be lower in your method due to their lower occurrence rates. I also expect that the recall will be much lower than 0.5 for labels that are in the middle of the ranking.  Thus, in such a situation, the attacker will obtain that words like \"the\", \"I\", \"you\" are present in the batch with high accuracy, but will rarely obtain, let's say, a phone number. The problem gets even worse when considering the fact that LLMs are trained on tokens and not full words.\n- **Bad evaluation results:**  \nThe results shown in the experiment do not convince me in the superiority of the proposed method. In particular, RLG consistently and by big margins results in better reconstructions than FLAT-CHAT if RLG is in the mode where it is applicable (\\|\\mathcal{T}\\| < D). [1-3], which do not have such restrictions and tend to work much faster than RLG, might, therefore, turn out to be much better than FLATCHAT.  \n Even outside of these concerns, I find the precision of 0.85 and the recall of 0.5 in Table 2 and the 0.7 precision and 0.85 recall numbers in Table 3 not that convincing in terms of their practical attack relevance as outlined above. \n- **Suggestions:**  \n1. Essentially, the method proposes to model the $p_{i,j}$ as Gaussian distribution, which as $\\|\\mathcal{B}\\|->\\infty$ get closer to the truth but since $0\\leq p_{i,j}\\leq 1$ is a probability the approximation for finite $\\|\\mathcal{B}\\|$ is very bad. This is also reflected in the authors' shown negative clusters in the figures of Appendix A. The authors can consider modeling the $\\log p_{i,j} $ as Gaussian ( but $\\alpha_i$ still as Gaussian ). In my quick tests, this reflected the shown negative cluster pdf shapes much better. \n2. The authors propose to use Equation 12 as a ranking function. If a proper prior $p(s_t|t \\in \\mathcal{B})$ is used, Equation 12 can be used as a decision criterion instead, which will eliminate the need for using regression to fit $\\|\\mathcal{T}\\|$. This can possibly improve the performance of the method.\n- **Nits:**   \n1. In the first part of Eq. 13, $\\sigma_n$ and $\\sigma_p$ should be switched in the normalization constants of the Gaussians\n2. Equations 6 and 9 assume sum instead of mean gradient aggregation. Equation 7 assumes a  mean instead of sum. This needs to be made consistent throughout the paper.\nQuestions:\n- [Crucial] Can the authors provide a comparison to [1-3]? Can the authors provide an explanation of why they are better than [1-3] if they are?\n- Can you provide a comparison to FILM [4]? \n- Can you explain what auxiliary data was used to obtain the parameters of FLAT-CHAT in Table 2 (Machine Translation) experiments?\n- Can you explain why the precision and recall numbers between Tables 2 and 3 differ that much?\n- Can the authors explain why approximating $\\|\\mathcal{T}\\|$ separately is needed? Wouldn't using the optimal Bayesian criterion with a prior ratio of $\\frac{\\|\\mathcal{B}\\|}{(\\|\\mathcal{V}\\|-1)\\|\\mathcal{B}\\|}$ be sufficient?\n- Can the approximation of $\\|\\mathcal{T}\\|$ be improved by using some of the methods in [1-3] - it seems that currently, the approximation is far from perfect, to the point it has a few % difference on the final performance?\n- Can the authors explain the reasoning behind the Abs baseline in Appendix C? Seems that what the authors propose there is very similar to [1] - what are the similarities and differences?\n- Can you provide precise runtimes of the proposed method and baselines?\n- [Not so important] Can the authors run their experiments on a newer open-source LLM like Llama [6] or Chinchilla [7]?\n- [Not so important] Can the authors adapt their method to model the probabilities $p_{i,j}$ with a Log-Gaussian distribution? \n\nAll in all, the paper suffers from too many issues to be accepted right now. First and most importantly, it fails to compare to relevant prior work that has a reasonable chance to work better in practice than the proposed method and claims as a contribution the derivation of the \"flattening\" operation on the gradient despite the fact it is known. Second, the paper is hard to follow due to a lack of method summary and intuitive explanations. Finally, the paper needs to spend more time justifying the problem setting and their results in the context of this setting, as currently, I am not sure if the privacy concerns raised by the proposed attack are realistic.\n\n[1] Yin, Hongxu, et al. \"See through gradients: Image batch recovery via gradinversion.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.  \n[2] Wainakh, Aidmar, et al. \"User-level label leakage from gradients in federated learning.\" arXiv preprint arXiv:2105.09369 (2021).  \n[3] Geng, Jiahui, et al. \"Towards general deep leakage in federated learning.\" arXiv preprint arXiv:2110.09074 (2021).  \n[4] Samyak Gupta, Yangsibo Huang, Zexuan Zhong, Tianyu Gao, Kai Li, and Danqi Chen. 2022. Recovering private text in federated learning of language models. In Advances in Neural Information Processing Systems  \n[5] Trung Dang, Om Thakkar, Swaroop Ramaswamy, Rajiv Mathews, Peter Chin, and Fran\u00e7oise Beaufays, 2021. Revealing and protecting labels in distributed training. Advances in Neural Information Processing Systems, 34:1727\u20131738.\n[6] Touvron, Hugo, et al. \"Llama: Open and efficient foundation language models.\" arXiv preprint arXiv:2302.13971 (2023).   \n[7] Hoffmann, Jordan, et al. \"Training compute-optimal large language models.\" arXiv preprint arXiv:2203.15556 (2022).\nFlag For Ethics Review:\nYes, Privacy, security and safety\nDetails Of Ethics Concerns:\nIt is not strictly needed but the paper will benefit from an Ethics statement where the authors can explain what the implications of the proposed attack are to real FL setups and emphasize the proposed solution of using differential privacy.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Response to Reviewer 3Q3Y", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:57 (modified: 23 Nov 2023, 06:09)EveryoneRevisions", "Content": "Comment:\nThank you for your comments and suggestions. We hope the following clarifications can address your concerns.\n\n---\n\n**W1:** The description of the proposed method can be hard to read at times, suggesting reorganizing paragraphs and the algorithm in section 3 and including some missing information (e.g. GMM fitting, regression prediction and training loss constitution).\n\n**A1:** We sincerely appreciate these suggestions regarding rearrangements and supplements. We will incorporate them in our revision.\n\n---\n\n**W2:** Citation and comparison to related work: [1-4].\n\n**A2:** Thank you for pointing out the literature.\n\n[1] and [3] are for image reconstruction, focusing on image data in a continuous space while our work focuses on text data in a discrete space.\n\n[2] shares similar insights to our Lemmas 1 and 2. We have compared this baseline (coined Abs.) in Table 4. We will acknowledge our Abs. is equivalent to the suggested work. We would like to highlight our progress compared with [2]: (1) we have extended the theory and method (see GMM score and its results) and (2) our approach manages to estimate the number of tokens used in the recent training batch, which is often omitted in many related works.\n\n[4]  FILM targets sequence recovery while our work focuses on *industrial-scale* word recovery attack. Nonetheless, our work could serve as the first *Bag-of-Words* Extraction step of FILM.\n\n---\n\n**W3:** Considering not only recovering the unique tokens but also counts (frequency) in the attack setting from a practical perspective.\n\n**A3:** We argue recovering the appearance of tokens is the first and the most essential step for information leakage. The frequency of a token is arguably less important than know it is used or not. Nonetheless, we appreciate the suggestion and would like to leave it to future work.\n\n---\n\n**W4:** Bad evaluation results, compared with RLG in its applicable scenarios, or methods [1-3] with less restrictions. Besides, some presented precision-recall results.\n\n**A4:** Actually, the out-of-scope size of training data is quite common, imagining industrial FL scenarios using large training batches. DLG is not aware of the potential issue of a numerical value exceeding the range of $D$ which is usually several hundred. Our estimation model based on the parameters from GMM could solve the issue very well, according to Figure 3. \n\n---\n\n**S5:** Adapt modeling the probabilities pi,j with a Log-Gaussian distribution (log pi,j).\n\n**A5:** Thanks for the suggestion, this method may serve as a better estimator. We will consider adding this to our future work.\n\n---\n\n**S6:** Can the approximation of $|T|$ be improved by using $\\frac{|B|}{(|V|-1)|B|}$ or some of the methods in [1-3]?\n\n**A6:** There is an issue in the suggested method to estimate $|T|$: the $|B|$ is the suggested formula, $\\frac{|B|}{(|V|-1)|B|}$, will be canceled. We did not find promising methods in predicting $|T|$ in [1-3], especially under the setting of large batch size and large vocabulary size. \n\n---\n\n**N7:** Eq.13, Eq.6, Eq.9 and Eq. 7 modification suggestions.\n\n**A7:** We sincerely appreciate your suggestions, and we will incorporate them into our revision.\n\n---\n\n**Q8:** What auxiliary data was used to obtain the parameters of FLAT-CHAT in Table 2 (Machine Translation) experiments?\n\n**A8:** The auxiliary data used in Table 2 MT experiments for fine-tuning is the News-Commentary v15 de-en dataset. We will include an explanation in our revision.\n\n---\n\n**Q9:** Can you explain why the precision and recall numbers between Tables 2 and 3 differ that much?\n\n**A9:** The results in Table 2 and Table 3 are consistent. We assume you are asking the reason why RLG may have significantly different precision and recall when *\\# Tokens* is large. It is because RLG (1) fails the predict the correct size of the batch and (2) fails to predict the `*long-tail*\u2019 tokens.\n\n---\n\n**Q10:** Can the authors explain the reasoning behind the Abs baseline in Appendix C? the authors propose there is very similar to [1]\n\n**A10:**  Actually this methodology is similar to the one in [1], we will include the comparison and citation to our revision.\n\n---\n\n**Q11:** Can you provide precise runtimes of the proposed method and baselines?\n\n**A11:**  The runtime depends on the batch size of the training data, and we have provided the averaged running time for comparing the efficiency of RLG and our method in Table 3. Considering some cases of 1.5 seconds vs 34.3 hours, the significance of our approach is clear.\n\n---\n\n**Q12:** Run experiments on a newer open-source LLM like Llama [6] or Chinchilla [7].\n\n**A12:** Thanks for your suggestion. We assume our method is tested under general settings for LM which should also work for other transformer-based models including Llama and Chinchilla."}, {"Heading": "Response", "Subheading": "Official CommentbyReviewer 3Q3Y23 Nov 2023, 07:05 (modified: 23 Nov 2023, 07:06)EveryoneRevisions", "Content": "Comment:\nThe reviewer couldn't go through the comments thoroughly in the short time frame given. However, the admitted similarity of the method and results to prior work that is not even necessarily SOTA makes me reaffirm my initial grade. Further, the label recovery strategies of [1] and [3] are indeed relevant and can be applied with no modifications to the text setting. I will further read the rebuttal after the end of the discussion period."}]}]}, "UTGv8CayNt": {"paper_info": {"Primary Area": "applications to robotics, autonomy, planning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Hierarchical Imitation Learning, Robotic Manipulation", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "An imitation learning algorithm that solves hard low-level control tasks by adopting subgoal predictions learned from the unsupervised discovery of subgoals in the demonstrations.", "Abstract": "We study generalizable policy learning from demonstrations for complex low-level control tasks (e.g., contact-rich object manipulations). We propose a novel hierarchical imitation learning method that utilizes scalable, albeit sub-optimal, demonstrations. Firstly, we propose an observation space-agnostic approach that efficiently discovers the multi-step subgoal decomposition (sequences of key observations) of the demos in an unsupervised manner. By grouping temporarily close and functionally similar actions into subskill-level segments, the discovered breakpoints (the segment boundaries) constitute a chain of planning steps (i.e., the chain-of-thought) to complete the task. Next, we propose a Transformer-based design that effectively learns to predict the chain-of-thought (CoT) as the high-level guidance for low-level action. We couple action and CoT predictions via prompt tokens and a hybrid masking strategy, which enable dynamically updated CoT guidance at test time and improve feature representation of the trajectory for generalizable policy learning. Our method, named Chain-of-Thought Predictive Control (CoTPC), consistently surpasses existing strong baselines on a wide range of challenging low-level manipulation tasks with scalable yet sub-optimal demos.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9232", "PDF Url": "https://openreview.net/pdf?id=UTGv8CayNt"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9232 by Area Chair 7FNP", "Subheading": "Meta ReviewbyArea Chair 7FNP10 Dec 2023, 00:21 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThis paper presents a method for hierarchical planning from the demonstrations using a Transformer-based architecture. The demonstrations are decomposed into sequences of observations and are used for unsupervised discovery of subgoals. Experiments on the Moving Maze, Franka Kitchen and ManiSkill2 environments are used to evaluate the method.\nThe reviewers are split evenly (two 5s, two 6s).\nStrengths of the paper include good motivation, well-written, good experimental set up and in general addressing an important and complex problem.\nWeaknesses of the paper include limited novelty, limited experimentation and several points raised by reviewer QpAT on writing and comparison with existing methods. Looking into the discussion it is clear that the paper can be further improved with appropriate discussions as suggested by QpAT.\nJustification For Why Not Higher Score:\nThe critical reviewer makes a compelling argument that the paper should be improved. The two positive reviews while positive does not substantially elaborate on positives of the paper.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Official Review of Submission9232 by Reviewer 2mSo", "Subheading": "Official ReviewbyReviewer 2mSo01 Nov 2023, 22:31 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work proposes CoTPC, a Transformer-based architecture that performs hierarchical planning.\nAn important part of this method is the unsupervised discovery of subgoals, which assume that temporally close and similar actions belong to the same subskills.\nThe overall architecture uses learned subgoal embeddings and uses the goals discovered by the unsupervised algorithm to train these learned embeddings, as an auxiliary loss.\nThe remainder of the architecture fits into the family of the Behaviour transformer, with some design differences that impact the performance, and utilize the CoT learned embeddings.\nExperiments on the Moving Maze, Franka Kitchen and ManiSkill2 environments show the effectiveness of CoTPC over baselines.\nAn ablation study is also presented to showcase the importance of different design choices in the architecture.\nSoundness:\n3 good\nPresentation:\n2 fair\nContribution:\n3 good\nStrengths:\nThe dataset chosen for experiments are relevant, and the results are quite convincing, with the CoT model clearly performing better than the baselines. I thought the exposition of the experiments section clear and easy to follow. The choice made on experiments were clear and, to my knowledge, the choice of baselines are fair.\nAlthough the architecture is limited in novelty, the method as a whole is novel and the specific design decisions are novel. I particularly liked the use of learned embeddings that are trained using an auxiliary loss with targets generated using an unsupervised subgoal discovery process.\nThe proposed work is clearly motivated and properly positioned in the literature.\nWeaknesses:\nThe writing of section 4 needs improvements. Specifically, I found Section 4.2.2 quite hard to parse and easy to get lost. I would encourage the authors to re-write this section and redo Figure 1 so that things are clearer.\nSpecifically, I'm confused by what the inputs of $g_\\text{CoT}$.\nWhat is the CoT predictor? It appears once in the last paragraph of section 4.2.2.\nWhy aren't actions used as inputs to $g^x(.)$ functions?\nWhat exactly are the contents of ${ \\mathbf{S}^\\text{CoT}_{...}}$? Do they change with time? What is the (...) subscript?\nThere seems to be $T$ CoT features, but that seems confusing as these are suppose to represent subgoals and are trained using the auxiliary $L_\\text{CoT}$. I thought PELT was minimizing the number of goals. How do you ensure alignment between the learned tokens and the output of PELT?\nI found the ablation study to have limited value. I think it should aim to provide the reader with more intuition on what exactly is learned by CoT embeddings. This could possibly be shown on the maze environment, and would show clearly the discovery of the subgoals. I see Figure 5 in the appendix and it is a step in the right direction, but in my opinion, it would be be easier and more informative to show in the maze environment.\nAs a minor point, I would ask the authors to express the limitations of the approach. For instance, is it always possible to assume that actions that are similar or close temporally belong to the same subskill?\nQuestions:\nIt seems like BeT should have been explained in section 3 as the method seems to be heavily based on it. I leave that up to the authors to decide, but it could potentially ease the exposition. An alternative could be to present it in the appendix, similar to the Rt-1 paragraph.\nIn the last paragraph of section 5.4 named \"Shared tokens for CoT and action predictions\", I think the different variants should be shown as a three part diagram two help the reader understand the differences in inputs. As of right now, I am not entirely sure what the differences are.\nI would be curious to see what the effect of setting the component of the auxiliary loss term to 0, but keeping learnable prompt tokens. I think this is basically equivalent to BC but with added learnable tokens , maintain the same capacity as the CoTPC architecture.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Author Response to Reviewer 2mSo", "Subheading": "Official CommentbyAuthors21 Nov 2023, 15:26 (modified: 22 Nov 2023, 06:44)EveryoneRevisions", "Content": "Comment:\nThanks for the valuable review!\nSection 4.2.2 writing needs improvement\nWe\u2019ve updated Section 4.2.2 to make it clearer.\nWe reword all \u201cpredictors\u201d to \u201cdecoders\u201d to eliminate ambiguities.\nWe describe the inputs of the CoT decoders in more detail.\nRegarding why not use action tokens for predictions: The action tokens are not directly used as inputs to all the decoders since during inference there is no input for the action token corresponding to the current timestep (this will be a_t, exactly what we aim to predict). The action tokens in the past are used in the attention layers, though. The alternative is to add an extra prompt token for the current actions. We stick to the standard approach of using the state tokens for inputs to the decoders as in DT/BeT.\nThe content of the CoT tokens is the learnable prompt embeddings. Each CoT token has its embeddings (not shared since we do not use position embedding for the CoT tokens). They are fixed during inference.\nThe T CoT tokens correspond to the T timesteps in the context length of the Transformer. Each token is learned to predict the same CoT content (next and last subgoal). There is no alignment issue between subgoals and CoT tokens in this setup. Because we couple action prediction and CoT prediction, we need T branches for T action offset predictions in the first place. We find the alternative producing less generalizable policies.\nBeT should have been explained more\nWe\u2019ve added a brief intro to the BeT architecture in the appendix.\nThe third ablation study needs a diagram to illustrate the different variants of the architecture\nWe\u2019ve added a diagram in the appendix to illustrate the differences.\nCurious to see what the effect of setting the component of the auxiliary loss term to 0, but keeping learnable prompt tokens (maintain the same capacity as the CoTPC architecture)\nWe perform an ablation study on Peg Insertion and Push Chair with state observation (similar to our other ablation studies) where we simply add additional prompt tokens to the BeT baseline (no auxiliary loss and thus no CoT decoder). This variant (named BeT+prompt) has the same capacity as CoTPC yet performs very similarly to the BeT baseline (shown below). We report unseen SR for Push Chair and 0-shot SR for Peg Insertion (as in our other ablation studies).\nBeT\nBeT+prompt\nCoTPC\nPeg Insertion\n42.5\n43.0\n59.3\nPush Chair\n33.4\n32.7\n41.0\nLimitations of the approach\nWe will add a paragraph to discuss the limitation of action-based subskill discovery. Specifically, the assumption that similar actions that are also temporarily close should be grouped into the same subskill can be violated with complex manipulations with many micro-adjustments (e.g., standing and balancing on a rope). In this case, extra force feedback might be required to distinguish subskills that are only subtly different."}, {"Heading": "Additional Author Response", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:31Everyone", "Content": "Comment:\nIn the Maze task, since the state observation is essentially a vector of the position of the agent as well as the moving blocks, we find that the CoT tokens and the CoT decoder learn to predict the positions of the moving blocks relatively precisely from which the agent will reach them. Since it is a relatively simple task with very clear subgoals, the illustration provides less information than that of the ManiSkill2 tasks. We will add it to the Appendix if required."}]}, {"Heading": "Official Review of Submission9232 by Reviewer iFzy", "Subheading": "Official ReviewbyReviewer iFzy30 Oct 2023, 16:42 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents CoTPC, a behavior cloning method that predicts simultaneously multiple future sub-goals (Chain-of-thoughts), as well as low-level actions.  It also presents a method for discovering brakpoints and a chain of planning steps. It's evaluated on state-based tasks across various settings, from 2D moving maze, to franka kitchen, then to several tasks in maniskill2. The experiments show CoTPC outperforms other baselines as well as other ablation choices. It also show some preliminary results on 2 real world tasks.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nI like the general direction this paper is pursuing. Addressing suboptimality in demonstrations by finding shared hierarchical patterns and key states makes a lot of sense. Predicting a sequence of subgoals simultaneously, as opposed to auto-regressively one-by-one, is also reasonable in terms of better guiding low-level actions prediction.\nThe paper has a set of extensive experiments, as well as some preliminary study using realistic visual inputs and real-world experiments.\nIn addition, i was a reviewer reviewing this paper during its previous round of submission, back then one of my major concern is lacking of a automated machanisim for extracting key states from the demo. This has been addressed to some extent in this version.\nWeaknesses:\nI am still not fully convinced by using the term 'Chain-of-Thought'...\nReal world evaluation is a bit too simple\nQuestions:\nI have no further questions since I reviewed this before.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Author Response to Reviewer iFzy", "Subheading": "Official CommentbyAuthors22 Nov 2023, 02:15Everyone", "Content": "Comment:\nThanks for the valuable review (again)!\nRegarding the term CoT, we are willing to change the name to others (e.g., subskill-augmented or subskill-predictive control) if all of the reviewers think it is necessary (as the reviewer QpAT raised this point as well)."}, {"Heading": "Reviewer response", "Subheading": "Official CommentbyReviewer iFzy22 Nov 2023, 16:45Everyone", "Content": "Comment:\nThank you for your response. Yes renaming would be a good move. I'll keep my current positive score."}]}, {"Heading": "Official Review of Submission9232 by Reviewer HDpH", "Subheading": "Official ReviewbyReviewer HDpH28 Oct 2023, 18:06 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe authors present Chain-of-Thought (CoT) Predictive control, a transformer based approach to policy learning, trained via sequence modeling. The transformer is augmented with learnable CoT prompt tokens that guide low-level action learning. In addition, the transformer is trained to predict the next and last high-level prompt, further encouraging abstractions that capture higher level semantic information. The high-level prompts are discovered in an unsupervised manner, as changepoints in time, discovered with Pruned Exact Linear Time methods, using cosine similarity as a cost metric. The model is trained on suboptimal demos and surpasses other transformer based methods on held-out tasks.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper has several strengths:\nReasonably well written\nSimplistic and effective approach that outperforms similar methods\nNice to see their approach applied to complex dynamic settings, and generalizing favorably\nWeaknesses:\nMy main concern with the method is their motivation for how they perform sub-task decomposition. Cosine similarity metric seems heuristical, not well motivated, and anecdotal. Whilst the results are promising, it is unclear whether more principled decompositions  would lead to better results: e.g. obtained via bottleneck options [1] or gaussian processes [2]. The paper would benefit from a greater discussion/comparison on this front. It is unclear to me whether their decomposition approach would favor different tasks, with distinct action-space statistics.\nIn addition, there are a couple of presentation limitations:\nCitations are not in the correct ICLR format (surname and year)\nResults are lacking confidence intervals (how many runs/model seeds)\n[1] - Salter, Sasha, et al. \"Mo2: Model-based offline options.\" Conference on Lifelong Learning Agents. PMLR, 2022.\n[2] - Saat\u00e7i, Yunus, Ryan D. Turner, and Carl E. Rasmussen. \"Gaussian process change point models.\" Proceedings of the 27th International Conference on Machine Learning (ICML-10). 2010.\nQuestions:\nHow well does this approach to sub-task decomposition scale to larger action-spaces?\nHow sensitive is their approach to the beta parameter that controls the number of detected changepoints?\nFig 2 - Can the author's comment on what the action groupings correspond to intuitively for these examples?\nFlag For Ethics Review:\nNo ethics review needed.\nDetails Of Ethics Concerns:\nNA\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Author Response to Reviewer HDpH", "Subheading": "Official CommentbyAuthors22 Nov 2023, 01:10 (modified: 22 Nov 2023, 01:43)EveryoneRevisions", "Content": "Comment:\nThanks for the valuable review!\nMajor concern: Cosine similarity metric for sub-task decomposition seems heuristical. How does it scale up to a higher action dimension?\nOur subskill discovery approach by decomposing the action sequences is motivated by the intuition that functionally similar actions that are temporally close should be grouped into the same subskill. The choice of the metric to measure such functional similarity is an open problem. We tried cosine similarity, L2 distance, and a more complicated Hausdorff distance. Among these, we find that the cosine similarity exhibits both simplicity and generalizability. In our experiments, we find it works across different action spaces (e.g., delta position in Moving Maze, delta joint pose in Peg Insertion, and delta joint velocity in Push Chair) with different action statistics based on how they are generated (sampling-based methods such as RRT, heuristics, etc.) and scale well to higher action dimensions (e.g., Moving Maze uses 2-d actions, Push Chair uses 19-d actions with a dual-arm mobile robot). In practice, action spaces of much higher dimensions are relatively uncommon in robotic tasks.\nDiscussion about the proposed decomposition approach compared to others in the literature (e.g, [1] and [2])\nSkill or sub-skill discovery purely from offline demonstration sets is very challenging since there is barely any useful supervision. In the related literature, the option-based approach is a popular strategy. For instance, MO2 [1], an offline option learning framework using the bottleneck state principle, is shown to work well on continuous control problems for learning the options. However, this line of work has the shortcoming of relying on good state space representation. It is unclear if MO2 can work well for high-dimensional visual observations (e.g., the Pour task only supports visual observation due to soft-body manipulation). Our action-based approach is observation-agnostic and thus avoids this issue. Moreover, the option approach requires learning good initial and termination conditions for the options, which is a hard problem itself [2]. Usually, it requires further online learning for skill chaining to compensate for the suboptimal options (MO2 still requires online learning after the options learned from offline datasets are fixed).\nThe alternative, as we propose, is to utilize methods from the breakpoint detection community for time series modeling to perform action segmentation. Breakpoint detection methods can roughly be divided into predictive model-based approaches (e.g., [3]) and optimization-based ones (e.g., [4]). The former requires an underlying predictive model (UPM) where [3] chooses Gaussian Processes. However, it is unclear if it can model high-dimensional and complex control signals as the action sequences can be hard to model in the first place ([3] suggests it might require a large set of sensitive hyper-parameters). The latter does not model the time series directly but finds breakpoints by optimizing a cost function instead. In this case, a good choice of a metric can be critical.\nWe will add a discussion to the appendix.\nCitations should be in ICLR format\nWe will fix it.\nResults are lacking confidence intervals (how many runs/model seeds)\nFor all results on ManiSkill2, we report the best result among the three training runs in the original paper. We report the additional mean and std below. The format is best (mean \u00b1 std).\nStack Cube (unseen)\nPeg Insertion (0-shot)\nTurn Faucet (0-shot)\nPush Chair (0-shot)\nBeT\n73.0 (68.7\u00b14.0)\n42.5 (39.5\u00b12.7)\n32.5 (31.7\u00b10.8)\n33.4 (32.3\u00b11.0)\nCoTPC\n86.0 (84.0\u00b12.6)\n59.3 (51.5\u00b17.4)\n39.3 (35.4\u00b13.6)\n41.0 (36.4\u00b14.0)\nHow sensitive is their approach to the number of detected changepoints (length of CoT)?\nWe perform experiments on the Peg Insertion task (state observation policies) and find that shorter CoT (approximately -1 length on average) leads to slightly decreased performance (59.3 vs. 54.0 in terms of 0-shot SR); we find longer CoT (approximately +1 length on average) have very similar performance.\nFig 2 - Can the author's comment on what the action groupings correspond to intuitively for these examples?\nFigure 6 in the appendix (updated pdf version) illustrates semantically what each subskill corresponds to.\n[1] Mo2: Model-based offline options\n[2] Multi-skill Mobile Manipulation for Object Rearrangement\n[3] Gaussian process change point models\n[4] Optimal detection of changepoints with a linear computational cost"}]}, {"Heading": "Official Review of Submission9232 by Reviewer QpAT", "Subheading": "Official ReviewbyReviewer QpAT13 Oct 2023, 21:32 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a policy learning from the demonstration method. The authors propose a novel hierarchical imitation learning that utilizes scalable demonstrations. The demonstration is decomposed into a sequence of key observations, and then CoT is leveraged to generalize policy learning.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nI think the author's environment looks cool and real. This is very important in the policy learning domain and in the robotic domain. I see the supplementary video and I believe that this environment provides a good test environment for policy learning methods. The authors are encouraged by the reviewer to continue their study in this domain, even though this paper may be rejected.\nThe general direction of learning policy with demonstrations is good, and the hierarchical RL formulation for this task is also sound and important, although those two ideas are not very novel.\nThe numerical results are good and the improvement looks significant.\nI like the supplementary video as well, although it can be improved (see below).\nWeaknesses:\n1. About the novelty\n(1) I think CoT is not very novel in this context and I don't think the proposed approach can be regarded as CoT. The proposed approach refers to a demonstration split methodology (or a subgoal discovery mechanism in hierarchical RL). Since no language is involved, I don't think this method can be related to CoT.\n(2) This paper is not positioned well in the context of hierarchical RL + demonstration, so the novelty is not well-stated. The authors should mention, discuss, or compare the following works [1-5]. Disclaim: I am not an author of any of these works. The idea of learning subgoals by similarity or diversity is not novel.\n(3) Using transformers in policy learning is not novel as well, and I don't think the major goal of this paper is related to architecture design. If the goal is to claim the novelty of CoT control, the authors should try other architectures as well. Since nowadays transformers are very common architectures, I don't think this can be claimed as a major novelty.\n(4) It's unclear why the authors use a single model to learn CoT and learn the action. The authors should try to compare to architectures like [6].\n2. About the experiments\n(1) The authors should discuss their results and summarize the conclusions in the main text. I'm confused about the main result in Tab. 1, and this is because the results are not discussed (the authors only say results in Tab.1 without further explanations). It seems that BC, DT, and BeT are not hierarchical RL methods. So it is very unfair. The authors should not compare to methods that do not use subgoals. Instead, the authors should mainly compare to hierarchical RL methods that leverage demonstrations. The authors should search for [1-5] as long as their follow-up works to get the most related hierarchical RL methods to compare to.\n(2) The variance should be shown for each method, and the learning curves are required.\n(3) The supplementary videos should be combined with a presentation video, which can reveal the comparisons between the proposed approach and previous works.\n3. About the writing\n(1) The function of the model is not discussed and section 4.2 looks confusing as a result. I think the function and signature of the model should be discussed prior to the model details.\n(2) The details of the CoT algorithm are unclear. Particularly, these two sentences look very confusing to me.\n\"therefore, propose to group contiguous actions into segments, using a similarity-based heuristic to find these subskills.\" How does the group algorithm work? How to discretize continuous actions?\n\"We then utilize the Pruned Exact Linear Time (PELT) method [38] with cosine similarity as the cost metric to generate the changepoints in a per-trajectory manner.\" How does this work? I'm not familiar with the PELT method and this should be discussed in detail.\n(3) The authors assume the readers know the decision transformer and detection transformer in advance, which is not very good.\n[1] Jiang, Yiding, et al. \"Learning Options via Compression.\" Advances in Neural Information Processing Systems 35 (2022): 21184-21199.\n[2] Eysenbach, Benjamin, et al. \"Diversity is all you need: Learning skills without a reward function.\" arXiv preprint arXiv:1802.06070 (2018).\n[3] Konidaris, George, et al. \"Robot learning from demonstration by constructing skill trees.\" The International Journal of Robotics Research 31.3 (2012): 360-375.\n[4] Pickett, Marc, and Andrew G. Barto. \"Policyblocks: An algorithm for creating useful macro-actions in reinforcement learning.\" ICML. Vol. 19. 2002.\n[5] Kipf, Thomas, et al. \"Compile: Compositional imitation learning and execution.\" International Conference on Machine Learning. PMLR, 2019.\n[6] Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning\nQuestions:\nHow does the number of CoT affect the policy learning results?\nIf the transformer's weights are tuned, why the CoT can accurately serve as a target signal?\nHow efficient is the transformer architecture?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Author Response to Reviewer QpAT", "Subheading": "Official CommentbyAuthors22 Nov 2023, 01:42 (modified: 22 Nov 2023, 06:40)EveryoneRevisions", "Content": "Comment:\nThanks for the valuable feedback with so many details!\nSince no language is involved, I don't think this method can be related to CoT.\nWe name our work with chain-of-though similar to [7], which suggests that CoT generally refers to the key intermediate steps in sequential decision-making. Nevertheless, we are willing to change the name to others (e.g., subskill-augmented or subskill-predictive control) if all of the reviewers think it is necessary (as the reviewer iFzy also raised this point).\nNot positioned well in the context of hierarchical RL + demonstration regarding subgoal decomposition. See [1-5]\nWhile the high-level idea of utilizing the hierarchical principles for policy learning is shared with the approaches in the hierarchical RL + demonstration literature (e.g., [1-4]), all of these work relies on online interaction with the environments either by using online RL to learn to utilize the learned (sub)skills in a transfer learning setup (e.g, [1]) or by using online exploration to acquire the (sub)skills in the first place (e.g., [2]). On the contrary, ours is a completely offline imitation learning method.\nPurely offline subskill discovery that can be used for downstream imitation learning is very challenging, and recent work mostly relies on RL to provide extra supervision [6]. (Also see the author's response to reviewer HDpH). Work that is similar to ours in this setup includes CompILE [5] and PC [7]. CompILE adopts a VAE to perform soft-segmentation of the demo trajectories. However, its evaluation was carried out only on a limited set of relatively simple control tasks. We try our best to find [8] as a relevant follow-up work, yet its evaluation only involves grid worlds. On the other hand, [7] performs hierarchical policy learning with extra procedure-level supervision that limits its applicability and is hard to be directly compared with (also see a discussion in our Appendix). Notice that due to the relatively small previous work in this direction (subskill discovery + hierarchical offline policy learning), both [5] and [7] only use non-hierarchical imitation learning methods as baselines. Similarly in our comparison, we include several non-hierarchical strong baselines.\nWe will include a discussion regarding this in the appendix.\nSince nowadays transformers are very common architectures, I don't think the architecture design can be claimed as a major novelty.\nOur contributions are two-fold: a novel formulation of observation-agnostic subskill from offline demonstrations based on discovery based on breakpoint detection and a customized Transformer architecture for the subskill-augmented hierarchical imitation learning method.\nOur specific architecture design makes our framework suitable for leveraging the hierarchical information discovered in an offline manner. Granted, Transformers are common standard architectures nowadays. We do not aim for a major overhaul of Transformers (neither does existing work such as BeT). Nevertheless, our design to enhance Transformers for hierarchical imitation learning is shown to be effective and important with several ablations studies. Specifically, we add a diagram to the Appendix to better illustrate the differences in the network design in our third ablation study. We add an ablation study in the author's response to reviewer 2mSo in this direction.\nWhy do the authors use a single model to learn CoT and learn the action? Should try to compare to architectures like [9].\nHere we add another ablation study to verify our architecture design. We report unseen SR for Push Chair and 0-shot SR for Peg Insertion. In this study, we show that using two separate models for predicting the CoT and the actions respectively is outperformed by the joint modeling approach. Note that the reviewer mentioned [9], yet it is not directly comparable since the setup of [9] takes target images as inputs rather than trying to predict them as outputs. Intuitively, the auxiliary loss we propose together with the joint learning approach improves sequential feature learning by encouraging the model to extract information predictive of not only the actions but also the hierarchical structure of the task.\nCoTPC (sep)\nCoTPC\nPeg Insertion\n49.0\n59.3\nPush Chair\n35.7\n41.0\n[1] Learning Options via Compression\n[2] Diversity is all you need: Learning skills without a reward function\n[3] Robot learning from demonstration by constructing skill trees\n[4] Policyblocks: An algorithm for creating useful macro-actions in reinforcement learning\n[5] Compile: Compositional imitation learning and execution\n[6] Hierarchical Imitation Learning with Vector Quantized Models\n[7] Chain of Thought Imitation with Procedure Cloning\n[8] Unsupervised Learning of Temporal Abstractions with Slot-based Transformers\n[9] Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning"}, {"Heading": "Author Response to Reviewer QpAT (cont.)", "Subheading": "Official CommentbyAuthors22 Nov 2023, 02:13 (modified: 22 Nov 2023, 06:43)EveryoneRevisions", "Content": "Comment:\nNeed better writing for section 4.2 to introduce the details of the model\nWe updated Section 4.2 (mostly 4.2.2) to make it clearer (also see the author's response to the reviewer 2mSo).\nThe paper utilizes PELT for breakpoint detection. Might need to explain it in more detail as background knowledge. Should include an introduction to BeT as well.\nWe added a brief introduction paragraph to BeT to the appendix. We will add another short intro to the main paper for PELT. In short, PELT is an optimized version of a more classic breakpoint detection method that is based on the minimization of certain costs. A time series can be partitioned into consecutive groups where each group is associated with a cost term similar to the within-cluster distance in k-means. The total cost is the sum of all individual cost terms plus some penalty to control the number of groups. The classic breakpoint detection method performs dynamic programming to find the exact optimal partitioning that minimizes the total cost. PELT is an optimized version of the method.\nSensitivity of the length of CoT.\nWe perform experiments on the Peg Insertion task (state observation policies) and find that shorter CoT (approximately -1 length on average) leads to slightly decreased performance (59.3 vs. 54.0 in terms of 0-shot SR); we find longer CoT (approximately +1 length on average) have very similar performance.\nThe variance should be shown for each method, and the learning curves are required.\nFor all results on ManiSkill2, we report the best result among the three training runs in the original paper. We report the additional mean and std below. The format is best (mean \u00b1 std).\nStack Cube (unseen)\nPeg Insertion (0-shot)\nTurn Faucet (0-shot)\nPush Chair (0-shot)\nBeT\n73.0 (68.7\u00b14.0)\n42.5 (39.5\u00b12.7)\n32.5 (31.7\u00b10.8)\n33.4 (32.3\u00b11.0)\nCoTPC\n86.0 (84.0\u00b12.6)\n59.3 (51.5\u00b17.4)\n39.3 (35.4\u00b13.6)\n41.0 (36.4\u00b14.0)\nNote that the learning curves might not be very meaningful for purely offline imitation learning tasks. Both BeT and DT do not include them for the offline learning setup.\nHow efficient is the transformer architecture?\nWe use around 1 million parameters for all of the CoTPC, DT, and BeT models in our experiments. We wonder what additional information is requested here.\nIf the transformer's weights are tuned, why the CoT can accurately serve as a target signal?\nWe are not quite sure what is referred to here. The CoT tokens are learned to extract information predictive of the hierarchical structure of the task in the form of subgoals. The Transformer is learned to utilize the extracted information for better action decoding."}, {"Heading": "Thanks for your response.", "Subheading": "Official CommentbyReviewer QpAT22 Nov 2023, 02:29Everyone", "Content": "Comment:\nRenaming this paper is good. And I think experimenting with online setups is necessary. Besides, ComPILE is not restricted to \"relatively simple control tasks.\" It's a pretty general method, and I have seen or reviewed at least three drafts and papers using ComPILE. See\nhttps://scholar.google.com/scholar?cites=12302759254570528216&as_sdt=5,33&sciodt=0,33&hl=en\n."}, {"Heading": "Thanks for the additional feedback!", "Subheading": "Official CommentbyAuthors22 Nov 2023, 06:37Everyone", "Content": "Comment:\nWe agree that the online setup is very important. However, we believe it is out of the scope of this paper as offline policy learning and online policy learning have relatively different goals for solving hard control tasks based on the constraints of online interactions and the availability of offline demos. Although recently there are more approaches combining both, many works (DT, BeT, Diffusion Policy, PC, etc.) focus only on the offline setup. We will leave it as future work. We agree ComPILE is a rather general method and we have tried our best to search for the follow-up work on comPILE regarding the offline setup.\nThanks again for the feedback."}]}]}, "4dw16l4iqC": {"paper_info": {"Keywords": "Convolutional Networks, Pretrained, Wide FOV, Fisheye, Segmentation, Rectification", "TL;DR": "In this work we adapt pretrained CNNs to improve performance for wide-fov cameras, without any additional training or data required.", "Abstract": "In the vast majority of research, it is assumed images will be perspective or can be rectified to a perspective projection. However, in many applications it is beneficial to use non conventional cameras, such as fisheye cameras, that have a larger field of view (FOV). The issue arises that these large FOV images can't be rectified to a perspective projection without significant cropping of the original image. To address this issue we propose Rectify Convolutions (RectConv); a new approach for adapting pre-trained convolutional networks to operate with new non-perspective images, without any retraining. Replacing the convolutional layers of the network with RectConv layers allows the network to see both rectified patches and the entire FOV. We demonstrate RectConv adapting multiple pre-trained networks to perform segmentation and detection on fisheye imagery from two publicly available datasets. Our method shows improved results over both direct application of the network and naive pre-rectification of imagery. Our approach requires no additional data or training, and we develop a software tool that transforms existing pre-trained networks to operate on new camera geometries. We believe this work is a significant step toward adapting the vast resources available for perspective images to operate across a broad range of camera geometries. Code available upon acceptance.", "Primary Area": "representation learning for computer vision, audio, language, and other modalities", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9231", "PDF Url": "https://openreview.net/pdf?id=4dw16l4iqC"}, "review_info": []}, "nTwb2vBLOV": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Graph neural networks, Graph canonization, Stability", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "Abstract": "The expressivity of Graph Neural Networks (GNNs) has been studied broadly in recent years to reveal the design principles for more powerful GNNs. Graph canonization is known as a typical approach to distinguish non-isomorphic graphs, yet rarely adopted when developing expressive GNNs. This paper proposes to maximize the expressivity of GNNs by graph canonization, then the power of such GNNs is studies from the perspective of model stability. A stable GNN will map similar graphs to close graph representations in the vectorial space, and the stability of GNNs is critical to generalize their performance to unseen graphs. We theoretically reveal the trade-off of expressivity and stability in graph-canonization-enhanced GNNs. Then we introduce a notion of universal graph canonization as the general solution to address the trade-off and characterize a widely applicable sufficient condition to solve the universal graph canonization. A comprehensive set of experiments demonstrates the effectiveness of the proposed method. In many popular graph benchmark datasets, graph canonization successfully enhances GNNs and provides highly competitive performance, indicating the capability and great potential of proposed method in general graph representation learning. In graph datasets where the sufficient condition holds, GNNs enhanced by universal graph canonization consistently outperform GNN baselines and successfully improve the SOTA performance up to $31$%, providing the optimal solution to numerous challenging real-world graph analytical tasks like gene network representation learning in bioinformatics.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "learning on graphs and other geometries & topologies", "Submission Number": "9229", "PDF Url": "https://openreview.net/pdf?id=nTwb2vBLOV"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9229 by Area Chair va1y", "Subheading": "Meta ReviewbyArea Chair va1y19 Dec 2023, 23:30 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nAll reviewers appreciate the novelty of the idea and the theoretical result. There were initial concerns including discussion with respect to prior works and empirical study, but were fixed later by the author. Both reviewers recommend accept.\nJustification For Why Not Higher Score:\nThe significance of the contribution could be further clarified or developed.\nJustification For Why Not Lower Score:\nThis paper provides an interesting solution to a timely problem, and provides a solid empirical study."}, {"Heading": "Official Review of Submission9229 by Reviewer abzL", "Subheading": "Official ReviewbyReviewer abzL01 Nov 2023, 07:47 (modified: 30 Nov 2023, 17:40)EveryoneRevisions", "Content": "Summary:\nAuthors propose to tackle GNN expressivity issues by graph canonization. Either using ordering of nodes implied by the referene data distribution (e.g. image or voxel datasets that can give canonical ordering of nodes) or by running existing fast canonization algorithms. Inclusion of this ordering is shown to improve GNN expressive power and performance on real-world datasets.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n1 poor\nStrengths:\nI find the canonization of graphs to be a very intriguing avenue of making GNNs better or to automatically tailoring generic GNNs for a given data distribution if the canonization is specific for that distribution.\nThe authors do show that including such canonical order does improve the performance of backbone GNN architectures.\nWeaknesses:\nIn general I find the paper quite problematic. Mainly due to the total disregard for related work. Let me split this in three parts:\nIncluding ordering of nodes as features is very close to other feature augmentation techniques, widely used for GNN expressive power improvements, such as adding random walk embeddings (\nhttps://arxiv.org/pdf/2110.07875.pdf\n), graph laplacian embeddings (\nhttps://arxiv.org/abs/2202.13013\nhttps://arxiv.org/pdf/2201.13410.pdf\n) or even just random features (\nhttps://www.ijcai.org/proceedings/2021/0291.pdf\n). These are not mentioned among the types of expressive GNN architectures (only higher order and subgraph GNNs are mentioned), while conceptually they are very similar (add pre-computed features to increase power). Neither any of the experiments compare to these existing models.\nThe selection of discussed subgraph-based GNNs is quite peculiar, as it skips in my opinion some of the most popular works in this context (such as DropGNN\nhttps://arxiv.org/pdf/2111.06283.pdf\nand ESAN\nhttps://arxiv.org/pdf/2110.02910.pdf\nas well as various follow up works to these of which there has been many). They also say that subgraph GNNs are not more expressive than 2-WL, which in general is definitely not true, for example see theorem 6.5 in\nhttps://proceedings.mlr.press/v162/papp22a/papp22a.pdf\nwhere the marking GNN is very closely related to the DropGNN and one of the ESAN variants mentioned above. Also as shown in Table 1 here\nhttps://openreview.net/pdf?id=8WTAh0tj2jC\nexperimentally many of these expresive GNNs such as ESAN or DropGNN distinguish the usual 2-WL counter example graphs. (Note that here by 2-WL following the notation in those papers I mean the folklore WL hierarchy, where 2-WL is equal to the 3-WL in the usual WL hierarchy).\nThe known results for the power of assigning unique identifiers to nodes, such as the seminal work of\nhttps://arxiv.org/pdf/1907.03199.pdf\nwhich shows that GNNs with unique IDs are universal, although generally we don't have a way to assign such IDs in a stable manner. In my eyes the UG-GNN in Tables 4 and 5 essentially just a direct application of this in cases where the data comes with a good ID assignment due to the nature of data distribution.\nNote that many more of works in all 3 categories exist, I just cited a few important ones that came to my mind as an example.\nNow moving on to the experiments, its again very strange that none of the aforementioned baselines, especially the pre-computed feature ones are included. And generally almost. no expressive GNNs from the past couple of years are included in the benchmarks (e.g. ESAN, CIN, etc.). Not even giving nodes random noise/random IDs is compared against, which is a very usual expressive GNN baseline. Actually it is interesting that in Table 1 the GC-GNN does not achieve 100% test accuracy in any of the cases, usually expressive GNNs manage to hit 100% or at least 99%, with GNN augmented with random features also managing >90% test set accuracy. Random features are usually underperforming other expressive GNNs due to the poor stability of feature (or random ID) assignment, but as the authors point out their GC-GNN can also suffer from poor ordering stability.\nSo now, for me its completely unclear if this proposed expresivity enhancement is any better than existing, even simplest ones.\nWhile OGB benchmarks are mentioned, the model is not evaluated on any of them? Why is that? It is now the main standard GNN benchmark as the TU-Datasets usually have quite few graphs in them, which can induce high variance of the results.\nQuestions:\nPlease address the weaknesses above.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Author Response 1/3", "Subheading": "Official CommentbyAuthors20 Nov 2023, 17:54 (modified: 20 Nov 2023, 18:45)EveryoneRevisions", "Content": "Comment:\nWe appreciate the reviewer\u2019s effort in reviewing our paper. The reviewer\u2019s suggestion to compare the proposed method with more expressive GNNs can help to better evaluate the significance and contribution of our work. However, there are some misunderstandings of the methods and experiments in our paper.\n$\\textbf{Q1:}$  Comparison of our method against suggested expressive GNN baselines:  SignNet [1], GNN-RNI[2] (which exists in our paper),  ESAN [3] and DropGNN [4]. This is a question summarized from weakness 1, weakness 2 and other concerns of reviewer abzL.\n$\\textbf{Re1:}$ Reviewer abzL listed several expressive GNNs for comparison, and they can be categorized into two types: 1) feature augmentation GNNs that adds pre-computed/learnable features to improve the expressivity, such as SignNet [1] and GNN-RNI [2];   2) GNNs with markings that slightly perturbs the input graphs for multiple times to execute GNNs and then aggregates the final embeddings of these perturbed graphs in each run, including ESAN [3] and DropGNN [4].\nThese suggested GNNs are very good baselines, thus we provide the supplementary experiments to compare our (universal) graph canonization enhanced GNN ( GC-GNN/UGC-GNN) against these expressive GNNs.. The additional experiments are also added in the revision.\nTable 1. Supplementary experiments on TU datasets\nDataset\nDD\nMUTAG\nPROTEINS\nPTC-MR\nENZYMES\nSignNet\n78.2 +- 4.1\n88.3 +- 9.2\n75.6 +- 4.1\n64.3 +- 7.1\n37.5 +- 6.4\nGNN-RNI\n75.8+- 3.0\n90.4 +- 7.4\n73.5 +- 4.5\n58.2 +- 6.3\n30.7 +- 5.6\nESAN\n79.7 +- 3.8\n$\\textbf{91.0}$ +- $\\textbf{4.8}$\n75.8 +- 4.5\n65.7 +- 7.1\n37.9 +- 6.3\nDropGNN\n78.5+- 6.0\n90.4 +- 7.0\n76.3 +- 6.1\n62.7 +- 8.4\n$\\textbf{38.3}$ +- $\\textbf{7.1}$\nGC-GNN (ours)\n$\\textbf{91.3}$ +- $\\textbf{9.7}$\n86.2 +- 9.9\n$\\textbf{76.7}$ +- $\\textbf{5.1}$\n$\\textbf{66.9}$+- $\\textbf{7.1}$\n37.7 +- 6.9\nTable 2.  Supplementary experimental results on bioinformatical datasets\nDataset\nMayo\nMayo\nRosMap\nRosMap\nCancer\nCancer\nfMRI-ABIDE\nfMRI-ABIDE\nMetric\nAccuracy\nF1 score\nAccuracy\nF1 score\nAccuracy\nF1 score\nAccuracy\nF1 score\nSignNet\n0.527 +- 0.035\n0.514 +- 0.029\n0.544 +- 0.030\n0.609 +- 0.037\n0.572 +- 0.044\n0.553 +- 0.048\n0.628 +- 0.041\n0.597 +- 0.052\nGNN-RNI\n0.513 +- 0.027\n0.501 +- 0.031\n0.496 +- 0.041\n0.512 +- 0.037\n0.521 +- 0.041\n0.502 +- 0.069\n0.624 +- 0.021\n0.598 +- 0.050\nESAN\n0.579 +- 0.035\n0.605 +- 0.037\n0.581 +- 0.042\n0.614 +- 0.040\nOOM\nOOM\n0.629 +- 0.058\n0.596 +- 0.061\nDropGNN\n0.533 +- 0.042\n0.517 +- 0.039\n0.557 +- 0.045\n0.571 +- 0.050\nOOM\nOOM\n0.619 +- 0.063\n0.593 +- 0.072\nUGC-GNN (ours)\n$\\textbf{0.624}$ +- $\\textbf{0.036}$\n$\\textbf{0.713}$ +- $\\textbf{0.022}$\n$\\textbf{0.701}$ +- $\\textbf{0.025}$\n$\\textbf{0.689}$+- $\\textbf{0.019}$\n$\\textbf{0.714}$ +- $\\textbf{0.011}$\n$\\textbf{0.701}$ +- $\\textbf{0.032}$\n$\\textbf{0.648}$ +- $\\textbf{0.033}$\n$\\textbf{0.625}$ +- $\\textbf{0.060}$\nIn the experiment, ESAN implements the stochastic sampling on large-size graphs (i.e. bioinformatical datasets) and uses the ED policy for a strictly higher expressivity than 3-WL in distinguishing SR graphs. DropGNN sets the number of runs to be $k = ceil(\\frac{m}{100})$ and dropout probability to be $\\frac{1}{k}$, where $m$ is the average graph size. When the model  exceeds the GPU memory, we have an out-of-memory OOM problem.\nTable 1 and Table 2 in the response present the supplementary experimental results. The supplementary results are very similar to what is presented in our paper (Table 2, Table3, Table4 in the paper). That is, 1) when the universal graph canonization does not exist nor tractable, general graph canonization (GC-GNN) helps to enhance GNNs and can achieve highly competitive results in many scenarios like TU datasets. 2) When the universal graph canonization exists and is tractable by Definition 3.1 and Lemma 3.3 in our paper, GNN enhanced by universal graph canonization (UGC-GNN) successfully achieve the SOTA performance, as UGC-GNN maximizes the expressivity while maintaining the stability.\n[1] Sign and basis invariant networks for spectral graph representation learning\n[2] The surprising power of graph neural networks with random node initialization\n[3]  Equivariant subgraph aggregation networks.\n[4] DropGNN: Random dropouts increase the expressiveness of graph neural networks"}, {"Heading": "Author Response 2/3", "Subheading": "Official CommentbyAuthors20 Nov 2023, 18:03Everyone", "Content": "Comment:\n$\\textbf{Q2:}$  Weakness 2 states that \u201cThe selection of discussed subgraph-based GNNs is quite peculiar, as it skips in my opinion some of the most popular works in this context (DropGNN and ESAN). They also say that subgraph GNNs are not more expressive than 2-WL, which in general is definitely not true.\u201d\n$\\textbf{Re2:}$ Based on the last paragraph in the first page of our paper, the subgraph-based GNNs are defined as methods that improve the expressivity by encoding (learnable) local structures (i.e. induced k-hop neighborhoods) of nodes. In other words, subgraph-based GNNs formulate hierarchies of local isomorphism on neighborhood subgraphs. Thus, DropGNN and ESAN suggested by the reviewer abzL do not belong to subgraph-based GNNs. In fact, they are GNNs with markings that slightly perturbs the input graphs for multiple times to execute GNNs and then aggregates the learnt final embeddings of these perturbed graphs in each run. As theorem 6.3 in [5] shows, there always exists graphs distinguishable by 2-WL (3-WL) yet not distinguishable by subgraph-based GNNs, then subgraph-based GNNs can not be superior than 2-WL.\nFor subgraph-based GNNs, our paper have included many well-adopted powerful subgraph-based GNNs, including NGNN, GraphSNN, GNN-AK+.\n[5] A theoretical comparison of graph neural network extensions.\n$\\textbf{Q3:}$  Weakness 3 states that \u201cGNNs with unique IDs are universal, although generally we don't have a way to assign such IDs in a stable manner. In my eyes the UG-GNN in Tables 4 and 5 essentially just a direct application of this in cases where the data comes with a good ID assignment due to the nature of data distribution.\u201d\n$\\textbf{Re3:}$ Canonical labels generated by graph canonization can be viewed as the node\u2019s ID or position. However, we do not agree that Tables 3, 4 and 5 are essentially a direct application to datasets of good ID assignment. In practice, dominant graph canonization tools like Nauty [6] and Bliss [7] follow the paradigm of individualization and refinement (IR) to obtain the canonical labels, thus we can obtain different canonical labels by using different backtracking search heuristics when exploring the search space. Thus, it is not clear what node ID assignment is \u2018good\u2019. Then our theoretical results help to answer this problem: Lemma 2.4 indicates that any canonical labels generated by the IR paradigm is not good in terms of model stability, while Lemma 3.3 proposes methods to find the good ID assignments  (universal graph canonization in Definition 3.1) for many scenarios of great practical importance (which are listed as application scenarios in our paper). Our experimental results in Table3,4,5 align well with these theoretical findings, and Table 3 illustrates that UGC-GNN (universal graph canonization found by Lemma 3.3) significantly outperforms GC-GNN (general graph canonization follows the IR paradigm), indicating that our Lemma 3.3 helps to find 'good' ID assignments in these scenarios.\nOne of the main contributions of our paper is to show that  the model stability is also important when graph canonization techniques are used to enhance GNNs. In other words, our theory shows that a \u2018good\u2019 node ID assignment should be equivalent to canonical labels in breaking node asymmetry among isomorphic graphs, while maintaining the GNNs\u2019 stability.\n[6] Brendan D McKay and Adolfo Piperno. Practical graph isomorphism, ii. Journal of symbolic computation, 60:94\u2013112, 2014.\n[7]Tommi Junttila and Petteri Kaski. bliss: A tool for computing automorphism groups and canonical labelings of graphs. URL\nhttp://www\n. tcs. hut. fi/Software/bliss, 2012.\n$\\textbf{Q4:}$  Reviewer  abzL states that \u201cno expressive GNNs from the past couple of years are included in the benchmarks (e.g. ESAN, CIN, etc.). Not even giving nodes random noise/random IDs is compared against, which is a very usual expressive GNN baseline\u201d.\n$\\textbf{Re4:}$ These comments are not true. (1) GNN-RNI (random node initialization)  is already used as a baseline for comparison in Table 3 in our paper to show that the universal graph canonization helps GNN to achieve SOTA performance since it addresses the concern of GNN stability. (2) Baseline GNNs used in our paper include many well-adopted expressive GNN, including popular subgraph-based GNNs (i.e. GraphSNN (2022) ,GNN-AK+(2021), NGNN (2021)), state-of-the-art DAG GNNs like DAGNN, and dominant graph Transformers (i.e. Graphormer (2021), SAN (2021)). These baseline GNNs are widely adopted and have achieved top positions in leaderboards. The reason why we did not include GNNs with markings as baselines in our paper is that they are likely to have the out-of-memory (OOM) problem when applied to large-scale graphs like gene networks in Table 3 (Mayo, RosMap, Cancer). In order to avoid the OOM problem, DropGNN and ESAN are shallow (number layers < 3) and the embedding dimensions are small ($\\leq$ 8). Details of datasets are available in the Appendix A."}, {"Heading": "Author Response 3/3", "Subheading": "Official CommentbyAuthors20 Nov 2023, 18:07Everyone", "Content": "Comment:\n$\\textbf{Q5:}$  Reviewer abzL states that \u201cActually it is interesting that in Table 1 the GC-GNN does not achieve 100% test accuracy in any of the cases, usually expressive GNNs manage to hit 100% or at least 99%.\u201d and asks why GC-GNN is not tested on OGB datasets.\n$\\textbf{Re5:}$ The performance of GC-GNN in Table 1 aligns well with our theoretical findings. As we can see, there always exists a significant gap between the training performance and testing performance of GC-GNN on synthetic datasets. This performance can be explained by Lemma 2.4: the canonical node labeling/colourings used in GC-GNN are generated by graph canonization tools that follow the individualization-refinement paradigm (like Nauty), then GC-GNN is not stable and the generalization ability can not be guaranteed. Consequently, we test GC-GNN on some real-world datasets: TU datasets and OGB datasets. On TU datasets (Table 2 in the paper and Table 1 in the response 1), GC-GNN can achieve highly competitive (even the SOTA) results against other expressive GNNs. However, on OGB datasets, GC-GNN can still improve the performance yet it is not comparable to the SOTA results. These results explain why we formulate the universal graph canonization and design methods to find it (Table 3, 4, 5 in the paper). Now, our method of utilizing universal graph canonization is a general technique applicable to a wide range of real-world problems, and our next research is to extend this method to all graph learning problem.\nIn the paper, experiments on OGB datasets are in Table 7 (see Appendix B), and we describe the experimental results in the start of section 4.4. Here we summarize the results, and compare it with ESAN. When GIN is used as a base model in ogbg-molhiv, we fine-tune hyper-parameters of GC-GNN (GIN) to get better results than Table 7. Similar to ESAN, GC-GNN can improve the base GNN model, yet can not achieve the state-of-the-art performance.\nTable. Experimental results on OGB (Table 7 in our paper)\nDataset\nogbg-molhiv\nogbg-molpcba\nBase GIN\n0.7744 +- 0.0098\n0.2703 +- 0.0023\nESAN (GIN + ED)\n0.7803 +- 0.0170\n0.2782 +- 0.0036\nGC-GNN (GIN)\n0.7785 +- 0.0195\n0.2761 +- 0.0043\nBase GCN\n0.7501 +- 0.0140\n0.2422 +- 0.0034\nESAN (GCN +ED)\n0.7559 +- 0.0120\n0.2521 +- 0.0040\nGC-GNN (GCN)\n0.7609 +- 0.0158\n0.2510 +- 0.0047"}, {"Heading": "A friendly reminder for discussion", "Subheading": "Official CommentbyAuthors29 Nov 2023, 18:09 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\nDear Reviewer abzL,\nWe hope this message finds you well. The author response period for this submission was extended until the end of December 1st as the paper did not have three reviews.\nIt is close to the extension and we have not yet received feedback from you. Ensuring that our response effectively addresses your concerns is a priority for us. Therefore, might we inquire if you have any additional questions or concerns?\nWe appreciate your time and dedication committed to evaluating our work.\nBest Regards,\nThe Authors of Submission 9229"}, {"Heading": "Response to the Rebuttal", "Subheading": "Official CommentbyReviewer abzL30 Nov 2023, 17:39 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\nI thank the authors for their response and apologise for my late response.\nRegarding subgraph GNNs: its true that DropGNN can be understood through the marking prism, but ESAN goes beyond that.\nFor example the EGO and EGO+ strategies from ESAN, build ego graphs (potentially with root being marked) for each node and certainly share similarities to the strategy presented in \"Nested Graph Neural Networks\" by Zhang and Li that you reference as a subgraph model example. At the end of the day ESAN has Subgraph literally in the name and follow-up works do classify it as a subgraph GNN (e.g.\nhttps://proceedings.neurips.cc/paper_files/paper/2022/file/cb2a4cc70db72ea779abd01107782c7b-Paper-Conference.pdf\n). So if you don't mean to include it in your definition of subgraph GNN, this should be made clear (the two versions compared) and the separation boundary rigorously specified.\nI appreciate the extra experiments you have performed.\nI'm still not convinced by the significance of the contribution of this work. In the sense that it does not extend much beyond the current knowledge present in the field (good IDs are good).\nIt is quite unfortunate that we are the only two reviewers, so accounting for that I still raise my score to a week accept, but lower my confidence in this.\nThe PDF seems to not have been updated with the additional results. Why is that? It would be nice to see the final picture of the work.\nBut I trust that all the changes discussed will be incorporated in the final version.\nBy the way, a very common expressive GNN benchmark is the ZINC dataset, which discriminates the different expressive architectures quite well, while for example TU-Datasets are quite murky (most models do similarly). It would make the final paper version stronger if this is included."}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors01 Dec 2023, 20:40 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\nAgain, we would like to express our deep gratitude for these valuable comments, and they are helpful to improve our paper.\n$\\textbf{Q1:}$ Discussion regarding to subgraph-based GNNs.\n$\\textbf{Re1:}$ We agree that ESAN with EGO and EGO+ policy can be considered as a subgraph-based GNN. However, when the node-deleted subgraphs (ND) and the edge-deleted subgraphs (ED) polices are used, a graph is mapped to the set of subgraphs obtained  by removing a single node or edge, then it can be understood through the marking prism. Thus, it is really a good suggestion to clarify this point to avoid ambiguity.\n$\\textbf{Q2:}$ Response to 'In the sense that it does not extend much beyond the current knowledge present in the field (good IDs are good).'\n$\\textbf{Re2:}$. In the revision, we summarize that current dominant expressive GNNs as: high-order GNNs, subgraph-based GNNs, GNNs with marking, and feature augmentation GNNs. Overall, these expressive GNNs are powerful, yet still far from efficiently distinguishing any pair of nonisomorphic graphs. For instance, high-order GNNs and GNNs with markings are not scalable to large-scale graphs due to the space and time complexity; subgraph-based GNNs have an upper bounded expressicity as there always exists graphs distinguishable by 2-WL (3-WL) yet not distinguished by subgraph-based GNNs; Powerful feature augmentation GNNs like SignNet is also dependent on eigendecomposition, thus not suitable for large-scale graphs. Consequently, we propose to use graph canonization to enhance GNNs, as GNNs with graph canonization techniques (i.e. GC-GNN and UGC-GNN) can maximize the expressivity while do not increase the space/time complexity compare to a standard MP-GNN (message passing GNN).\nThough we know that 'good IDs are good', it is unclear what IDs are good in the field of graph canonization, and any IDs generated by graph canonization tools can help to maximize the expressivity of GNNs. Thus, our paper propose to study what IDs are good in the field of graph canonization from the perspective of GNN's stability.\n$\\textbf{Q3:}$ PDF seems to not have been updated with the additional results.\n$\\textbf{Re3:}$. We just update the PDF (rebuttal revision) and it should be visible now. We were waiting for the third reviewers' comments thus we did not update it. Based the feedback, ACs will take a closer look at the paper if the third reviewer is missed. Thus, we prepare the revision based on available comments from current two reviewers.\n$\\textbf{Q4:}$ Discussion of ZINC dataset.\n$\\textbf{Re4:}$. We agree that ZINC dataset is a good expressive benchmark dataset. As we pointed out in the Appendix B, a major limitation of graph canonization is that it cannot manipulate the heterogeneity of edges. In ZINC datasets, graphs contain edges of different types, and typical (expressive) GNNs usually uses an edge encoder (nn.Embedding(4, emb_dim)) for the edge embedding to encode the heterogeneity. Thus, these graphs are essentially not ideal to test graph-canonization-based method.\nHowever, we tried to integrated our method of using node IDs from graph canonization as augmented features in subgraph-based GNNs (NGNN). That is, for each subgraph extracted in NGNN, we run GNNs with graph canonization to obtain the subgraph embedding. In this case, our method can achieve a test MAE of $0.093 \\pm 0.005$, which is a competitive result."}]}, {"Heading": "Official Review of Submission9229 by Reviewer RfLx", "Subheading": "Official ReviewbyReviewer RfLx31 Oct 2023, 12:16 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis work focuses on the problems of the expressive power of graph neural networks (GNNs) where they aim to enhance the expressive power of GNNs by graph canonization. To this end, the paper first reveals the trade-off between the expressivity and stability in GNNs enhanced by graph canonization, showing that graph-canonization-enhanced GNNs maximize their expressive power at the cost of model stability. The paper further proposes a universal graph canonization to tackle this trade-off under a sufficient condition. The advantages of the proposed models against some GNN baselines are validated by their experimental results on both synthetic datasets and several benchmark datasets.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe paper is clear and well-structured.\nThe theoretical results that reveal the trade-off between expressivity in distinguishing non-isomorphic graphs and the stability in GNNs enhanced by graph canonization are interesting. The theoretical findings have shown the limitations of applying graph canonization to enhance the expressive power of GNNs. The proposed universal graph canonization to tackle the trade-off between expressivity and stability is novel.\nThe experimental results of the proposed model, UGC-GNN, on several bioinformatical graph datasets are impressive and consistently outperformed some well-known GNN baselines.\nWeaknesses:\nLack of experiments to compare the expressive power of the proposed models with high-order GNNs [1, 2] and subgraph-based GNNs [3, 4] in distinguishing non-isomorphic graphs. Since high-order GNNs also enhance the expressive power of GNNs, it would be helpful to conduct experiments to compare the expressive power of the proposed models and high-order GNNs. Are graph-canonization-enhanced GNNs more powerful than high-order GNNs and k-WL test algorithms?\nLack of computation cost comparison with k-WL-GNNs. High-order GNNs and subgraph-based GNNs may suffer from high computational cost when applied to large-scale graphs. The paper asserts that the proposed models are more efficient with a significantly low space and computation cost. It would be nice to provide empirical evidence to support the claim.\nAs shown in Table 7, the GC-GNN doesn't consistently enhance the performance of the GNN backbone. In some instances, the performance even diminishes. It would be beneficial to delve deeper into which graph properties might influence this fluctuation in performance when integrating the GNN backbone with GC-GNN or UGC-GNN.\nThe universal graph canonization problem is NP-hard. While the paper has provided a sufficient condition to compute the discrete coloring and discussed the applicability in several application scenarios, finding an injective function $l(v|\\mathbb{G})$ might be elusive or challenging for general graph learning contexts. Furthermore, if there could be multiple choices of $l(v|\\mathbb{G})$, it is unclear what the impact of applying different choices of $l(v|\\mathbb{G})$ is on the performance of the proposed model.\nOverall, the paper is well-written and easy to follow. The theoretical findings on the trade-off between expressive power and stability in graph-canonization-enhanced GNNs are interesting and the proposed universal graph canonization to tackle the trade-off is novel. Despite the potential high computational cost induced by the graph canonization algorithms and the effectiveness of the proposed models that might not be generalized to general graph datasets, the paper has provided some insights into the expressive power of GNNs enhanced by graph canonization methods. Therefore, the reviewer is inclined to accept the paper.\nReference\n[1] Weisfeiler and leman go neural: Higher-order graph neural networks, AAAI 2019.\n[2] Provably powerful graph networks, NeurIPS 2019.\n[3] Nested graph neural networks, NeurIPS 2021.\n[4] Equivariant Subgraph Aggregation Networks, ICLR 2022.\nQuestions:\nPlease refer to weaknesses\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Author Response 1/2", "Subheading": "Official CommentbyAuthors20 Nov 2023, 18:19 (modified: 20 Nov 2023, 18:44)EveryoneRevisions", "Content": "Comment:\nWe appreciate the reviewer\u2019s constructive feedback and positive review.\n$\\textbf{Q1:}$  Lack of experiments to compare the expressive power of the proposed models with high-order GNNs [1, 2] and subgraph-based GNNs [3, 4] in distinguishing non-isomorphic graphs.\n$\\textbf{Re1:}$ We agree that adding more expressive GNNs as baselines can help to evaluate the significance of our method. In our paper, the suggested nested GNN is already included (i.e. NGNN), while PPGN is included in bioinformatical datasets (Table 3).  Before we present the supplementary experimental results, we want to clarify that the term \u2018subgraph-based GNNs\u2019 in our paper indicates GNNs that improve the expressivity by encoding induced k-hop neighborhood of nodes. Then subgraph-based GNNs model hierarchies of local isomorphism on neighborhood subgraphs.  Thus, ESAN [4] with node-deleted policy (ND) and edge-deleted policy (ED) can not be catogorized into this group. ESAN can be categorized as GNNs with markings [6] that slightly perturbs the input graphs for multiple times to execute GNNs and then aggregates the learnt final embeddings of these perturbed graphs in each run. Another well-known example of GNNs with markings is DropGNN [5], and more details of GNNs with markings are available in [6].\nThus, in the supplementary experiments, we compare our methods against 1-2-3 GNN [1], PPGN [2] (on TU datasets), ESAN (ED) [4]  and DropGNN [5].\nTable 1. Supplementary experiments on TU datasets\nDataset\nDD\nMUTAG\nPROTEINS\nPTC-MR\nENZYMES\n1-2-3 GNN\n76.3\n86.1\n75.5\n60.9\n32.7\nPPGN\n78.5+- 5.1\n90.6 +- 8.7\n$\\textbf{77.2}$+- $\\textbf{4.7}$\n66.3 +- 8.6\n36.8 +- 5.9\nESAN\n79.7 +- 3.8\n$\\textbf{91.0}$ +- $\\textbf{4.8}$\n75.8 +- 4.5\n65.7 +- 7.1\n37.9 +- 6.3\nDropGNN\n78.5+- 6.0\n90.4 +- 7.0\n76.3 +- 6.1\n62.7 +- 8.4\n$\\textbf{38.3}$ +-$\\textbf{7.1}$\nGC-GNN (ours)\n$\\textbf{91.3}$ +- $\\textbf{9.7}$\n86.2 +- 9.9\n76.7 +- 5.1\n$\\textbf{66.9}$+- $\\textbf{7.1}$\n37.7 +- 6.9\nTable 2.  Supplementary experimental results on bioinformatical datasets\nDataset\nMayo\nMayo\nRosMap\nRosMap\nCancer\nCancer\nfMRI-ABIDE\nfMRI-ABIDE\nMetric\nAccuracy\nF1 score\nAccuracy\nF1 score\nAccuracy\nF1 score\nAccuracy\nF1 score\n1-2-3 GNN\nOOM\nOOM\nOOM\nOOM\nOOM\nOOM\n0.631 +- 0.041\n0.602 +- 0.052\nESAN\n0.579 +- 0.035\n0.605 +- 0.037\n0.581 +- 0.042\n0.614 +- 0.040\nOOM\nOOM\n0.629 +- 0.058\n0.596 +- 0.061\nDropGNN\n0.533 +- 0.042\n0.517 +- 0.039\n0.557 +- 0.045\n0.571 +- 0.050\nOOM\nOOM\n0.619 +- 0.063\n0.593 +- 0.072\nUGC-GNN (ours)\n$\\textbf{0.624}$ +- $\\textbf{0.036}$\n$\\textbf{0.713}$ +- $\\textbf{0.022}$\n$\\textbf{0.701}$ +- $\\textbf{0.025}$\n$\\textbf{0.689}$ +- $\\textbf{0.019}$\n$\\textbf{0.714}$ +- $\\textbf{0.011}$\n$\\textbf{0.701}$ +- $\\textbf{0.032}$\n$\\textbf{0.648}$ +- $\\textbf{0.033}$\n$\\textbf{0.625}$ +- $\\textbf{0.060}$\nThe supplementary results are very similar to expeiments in our paper (Table 2, Table3, Table4 in the paper). When the universal graph canonization does not exist nor tractable, general graph canonization (GC-GNN) helps to enhance GNNs and can achieve highly competitive results in many scenarios like TU datasets. 2) When the universal graph canonization exists and is tractable Lemma 3.3, GNN enhanced by universal graph canonization (UGC-GNN) successfully achieve the SOTA performance. We will add relevant discussion and supplementary experimental results in the revision.\n[1] Weisfeiler and leman go neural: Higher-order graph neural networks, AAAI 2019.\n[2] Provably powerful graph networks, NeurIPS 2019.\n[3] Nested graph neural networks, NeurIPS 2021.\n[4] Equivariant Subgraph Aggregation Networks, ICLR 2022.\n[5] Papp, P. A., Martinkus, K., Faber, L., & Wattenhofer, R. (2021). DropGNN: Random dropouts increase the expressiveness of graph neural networks. Advances in Neural Information Processing Systems, 34, 21997-22009.\n[6] Papp, P. A., & Wattenhofer, R. (2022, June). A theoretical comparison of graph neural network extensions. In International Conference on Machine Learning (pp. 17323-17345). PMLR."}, {"Heading": "Author Response 2/2", "Subheading": "Official CommentbyAuthors20 Nov 2023, 18:44Everyone", "Content": "Comment:\n$\\textbf{Q2:}$  Lack of computation cost comparison\n$\\textbf{Re2:}$ We agree that the comparison of computation cost can emphasize the advantage of graph-canonization-enhanced GNNs in complexity.  (1) For high-order GNNs, PPGN has a space complexity of $\\mathcal{O}(n^2)$ for each layer, while 1-2-3 GNNs has a space complexity of $\\mathcal{O}(n^3)$ for each layer. Then, as Table 2 in the response 1 shows, 1-2-3 GNNs always meet the OOM (out-of-memory) problem on large-scale datasets (Mayo, RosMap, Cancer). On the other hand, by reducing the embedding dimension and number of layers, PPGN can avoid OOM problem on these datasets as Table 3 in our paper indicates; (2) For subgraph-based GNNs like NGNN (nested GNN), we also implement the similar strategy to restrict the radius of subgraphs to be smaller than 2, then NGNN can avoid the OOM problem, too (Table 3 in our paper). Consequently, here we compare the average computation time per epoch of UGC-GNN against NGNN and PPGN on large-scale datasets. First, we find that UGC-GNN significantly reduces the computation complexity compared to high-order GNN PPGN, and this observation can be explained by the  $\\mathcal{O}(n^3)$ time complexity of PPGN and the large size of graphs. On the other hand, NGNN suffers from large subgraph sizes caused by the large average node degree in these datasets, then the extra computation burden is also larger than popular graph datasets with small average node degree (like OGB and TU datasets).\nTable 3. Average computation time per epoch\nDataset\nMayo\nRosMap\nCancer\nNGNN\n48s\n42s\n334s\nPPGN\n143s\n126s\n1261s\nUNGNN-GIN\n$\\textbf{13s}$\n$\\textbf{10s}$\n$\\textbf{89s}$\n$\\textbf{Q3:}$  GC-GNN doesn't consistently enhance the performance of the GNN backbone. It would be beneficial to delve deeper into which graph properties might influence this fluctuation in performance when integrating the GNN backbone with GC-GNN or UGC-GNN.\n$\\textbf{Re3:}$ This is a very insightful question. In fact, experimental results (Table3, Table4, Table 5) indicate that UGC-GNN can consistently achieve the SOTA performance. We run multiple experiments to fine-tune hyper-parameters of GC-GNN on OGB datasets, and the following table updates results when base GNN is GIN and dataset is ogbg-molhiv.  Based on these updated results, we find that though GC-GNN can still improve the performance on these two OGB datasets, it is not comparable to the SOTA model. Thus, our next research is to delve deeper into this problem to extend the idea of universal graph canonization to general graph learning problems.\nDataset\nogbg-molhiv\nogbg-molpcba\nBase GIN\n0.7744 +- 0.0098\n0.2703 +- 0.0023\nGC-GNN (GIN)\n0.7785 +- 0.0195\n0.2761 +- 0.0043\nBase GCN\n0.7501 +- 0.0140\n0.2422 +- 0.0034\nGC-GNN (GCN)\n0.7609 +- 0.0158\n0.2510 +- 0.0047\n$\\textbf{Q4:}$   Finding an injective function $l(v|\\mathbb{G})$ might be challenging for general graph learning contexts. Furthermore, if there could be multiple choices of $l(v|\\mathbb{G})$, it is unclear what the impact of applying different choices of  is on the performance of the proposed model.\n$\\textbf{Re4:}$ This question is very relevant to the last question (Q3). At this moment, our method of finding universal graph canonization is a general technique applicable to a wide range of real-world graph learning problems. For general graph learning contexts, our paper shows that finding the universal graph canonical labels  $l(v|\\mathbb{G})$ can be NP-hard. The theoretical results and experiments in our paper indicates that once a (learnable) node labelling/colouring (discrete or continuous) can be equivalent to canonical labels in breaking node asymmetry among isomorphic graphs, while maintaining the GNNs\u2019 stability,  GNNs\u2019 capability in graph-level prediction can be significantly enhanced. Hence, we believe the next step is to design deep neural architectures to learn such node labelling/colouring, instead of directly solving the NP-hard problem.\nIf there are multiple choices of universal graph canonization $l(v|\\mathbb{G})$, we can arbitrarily choose one as they all can maximize the expressivity and maintain the stability. A very simple example is that if we randomly permute $l(v|\\mathbb{G})$ for gene network datasets, the output node colouring is still a universal graph canonization. The following table demonstrates the experimental results.\nDataset\nMayo\nMayo\nRosMap\nRosMap\nCancer\nCancer\nMetric\nAccuracy\nF1 score\nAccuracy\nF1 score\nAccuracy\nF1 score\nUGC-GNN\n0.624 +- 0.036\n0.713 +- 0.022\n0.701 +- 0.025\n0.689+- 0.019\n0.714 +- 0.011\n0.701 +- 0.032\nUGC-GNN (permute)\n0.624 +- 0.035\n0.712 +- 0.022\n0.701 +- 0.025\n0.689+- 0.019\n0.715 +- 0.010\n0.701 +- 0.032"}, {"Heading": "A friendly reminder for discussion", "Subheading": "Official CommentbyAuthors29 Nov 2023, 18:12 (modified: 15 Mar 2024, 00:25)EveryoneRevisions", "Content": "Comment:\nDear Reviewer RfLx,\nWe hope this message finds you well. The author response period for this submission was extended until the end of December 1st as the paper did not have three reviews.\nIt is close to the extension and we have not yet received feedback from you. Ensuring that our response effectively addresses your concerns is a priority for us. Therefore, might we inquire if you have any additional questions or concerns?\nWe appreciate your time and dedication committed to evaluating our work.\nBest Regards,\nThe Authors of Submission 9229"}]}]}, "bUv5gJAAxH": {"paper_info": {"Primary Area": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Implicit Bias, Adversarial Attacks, Intrinsic Dimension, Neural Networks, Fourier Transform", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "Intrinsic Dimension reveals correlation between implicit bias and adversarial attacks in the frequency domain.", "Abstract": "Despite their impressive performance in classification, neural networks are known to be vulnerable to adversarial attacks. These attacks are small perturbations of the input data designed to fool the model. Naturally, a question arises regarding the potential connection between the architecture, settings, or properties of the model and the nature of the attack. In this work, we aim to shed light on this problem by focusing on the implicit bias of the neural network, which refers to its inherent inclination to favor specific patterns or outcomes. Specifically, we investigate one aspect of the implicit bias, which involves the essential Fourier frequencies required for accurate image classification. We conduct tests to assess the statistical relationship between these frequencies and those necessary for a successful attack. To delve into this relationship, we propose a new method that can uncover non-linear correlations between sets of coordinates, which, in our case, are the aforementioned frequencies. By exploiting the entanglement between intrinsic dimension and correlation, we provide empirical evidence that the network bias in Fourier space and the target frequencies of adversarial attacks are closely tied.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9228", "PDF Url": "https://openreview.net/pdf?id=bUv5gJAAxH"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9228 by Area Chair j92x", "Subheading": "Meta ReviewbyArea Chair j92x14 Dec 2023, 07:51 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper investigates the relationship between the implicit bias of an NN architecture and adversarial attacks. Concerns about the novelty and the statistical procedures used (biases) were raised in the reviews. Some of these have been clarified in the discussion.\nJustification For Why Not Higher Score:\nNA\nJustification For Why Not Lower Score:\nNA"}, {"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 09:01Everyone", "Content": "Comment:\nWe thank the Reviewers for their comments and suggestions on our work. The main weaknesses and questions raised by each Reviewer are addressed in the individual replies.\nWe uploaded a revised version of our manuscript, containing the following modifications:\nClarifications on the limits of the Z-test for non-linear correlation (section 3.2) and on the untargeted nature of the adversarial attacks we employ (section 4.3);\nAdditional results on the correlation between essential frequency and adversarial frequency masks with variable perturbation magnitude (section A.8 in the Appendix);\nFixed paragraph spacing."}, {"Heading": "Official Review of Submission9228 by Reviewer Zxej", "Subheading": "Official ReviewbyReviewer Zxej02 Nov 2023, 23:59 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper presents an empirical investigation of the correlation between the \nessential input frequencies required for accuracy of neural network image classifiers, and the frequencies targeted by adversarial attacks. They follow a recent approach by Karantzas et al. in which a Fourier mask is computed for a given input image, and then compared (in the Fourier space) with a mask similarly computed for a successful attack of the image. The authors seek to test their assertion that the network spectral bias determines the nature of successful attacks. Following Karantzas et al., the modulatory masks are computed by applying a Fast Fourier Transform, and then masking with a matrix of traininable parameters between 0 and 1. The result is converted back into an image by taking the real part of the inverse FFT, and then fed to the pretrained classifier to obtain a prediction that is used to train the mask parameters.\nThe authors assess the relationships between original images and their successfully attacked counterparts through a test based on intrinsic dimensionality on a vector formed by flattening and concatenating the two masks. They reason that correlation between the two would be revealed by a strong drop in ID, as compared with that of vector in which the coordinates derived from one of the masks. Z-scores are used to test the hypothesis that the drop in ID is significant. The authors then present empirical evidence for their claims based on this test.\nSoundness:\n2 fair\nPresentation:\n4 excellent\nContribution:\n2 fair\nStrengths:\nS1) The authors' observation that ID collapses when two sets of variables are highly correlated is an interesting. The contrast in ID between the cases of shuffled vs unshuffled variables is a compelling argument for the existence or lack of a correlation effect.\nS2) For the image datasets and learning models considered in the empirical evaluation, the authors have made a good case for regarding the susceptibility of adversarial attack as being revealed by frequency components. The authors further exploit the idea of shuffling to demonstrate the existence of class-specific information in the masks.\nS3) The paper presentation is of a high standard: well-organized, well-written, and clear.\nWeaknesses:\nW1) Among the technical contributions of the paper, the only novel idea is that of testing correlation using intrinsic dimensionality and variable shuffling. In other respects, the authors draw upon the Fourier mask framework of Karantzas et al. for analyzing the robustness of ANNs.\nW2) The authors have not accounted for the potential for bias in their Z-score test. The variance of the ID (and therefore the significance of the Z-score) itself strongly depends on the dimensionality within which it is assessed. Setting a threshold for hypothesis testing that is uniform across all dimensions may not be appropriate here. Estimation of ID also has its own biases that may confound hypothesis testing of this type. Accounting for (and if necessary, adjusting for) dimensional bias would greatly improve both the importance and novelty of the results.\nQuestions:\nPlease address the point raised as W2.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 08:28Everyone", "Content": "Comment:\nWe thank the Reviewer for carefully reading our manuscript and for providing interesting points of discussion. We try here to address the weaknesses pointed out in the review.\nW1:\nThe Reviewer correctly references Karantzas et al. (2022) as the main inspiration for our Fourier mask framework. However, we would like to note that, while the concept of essential frequency mask had already been explored in the aforementioned paper, the adversarial frequency masks are a novel contribution of our work.\nW2:\nIndeed, it is crucial to consider the variance associated with ID estimation. Employing a maximum-likelihood approach, one can obtain an expression for the variance and incorporate this insight as a correction term in the Z-score test. This would result in a slight modification of the p-value while maintaining unchanged conclusions. Additionally, addressing the bias in ID estimation could likely enhance the results and enable the extension of the test to datasets with a higher intrinsic dimension. However, tackling this remains an open problem in the unsupervised learning community, and its solution falls beyond the scope of this work. It is noteworthy, though, that the method proposed here remains independent of the ID estimator used (that is, if one had a perfect ID estimator, it would equally work on the method).  Moreover, by comparing measures of the ID estimated on the same embedding dimension, one could expect that many of the potential biases vanish \u2013 or, at least, are mitigated \u2013 by error compensation."}, {"Heading": "Official Comment by Reviewer Zxej", "Subheading": "Official CommentbyReviewer Zxej23 Nov 2023, 00:27Everyone", "Content": "Comment:\nThank you for your replies."}]}, {"Heading": "Official Review of Submission9228 by Reviewer hyn3", "Subheading": "Official ReviewbyReviewer hyn330 Oct 2023, 14:34 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe primary objective of the paper is to find a correlation between the frequencies that a hypothesis is attending to correctly classify an image with the frequencies that adversarial attacks take advantage of. The proposal is that if such a correlation exists, then \"the network spectral bias determines the nature of the adversarial attacks in the Fourier space\".\nTo this end, the paper first provides a light review of the concept of \"implicit bias\" and its relationship with Fourier transform of images. The paper then follows to describe the issue of adversarial attacks and the concept of intrinsic dimension of a data set. Next, the methodology of the proposal is described in which a method of Karantzas et al. is used to obtain the aforementioned frequencies. The paper then describes a method for determining the existence of correlation between two sets of data based on the difference between the intrinsic dimension of the concatenation of the two sets with the intrinsic dimension of the concatenation of one of the sets with a random shuffling of the other set. The argument is supported by providing an example of a 2D spiral.\nFinally, the paper reports the results of performing the proposed method on CIFAR and ImageNet data sets. The results suggest that the intrinsic dimension of concatenated natural and adversarial frequencies is on average increased by 4 or 5 almost surely when one the natural or adversarial samples is randomized.\nSoundness:\n1 poor\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nOriginality:\nThe paper is original in its use of topological information to determine correlation between two sets of data.\nQuality:\nThe paper is well-written for the most parts.\nClarity:\nThe language is simple and the paper refrains from using complicated mathematical concepts.\nSignificance:\nThe paper proposes a method for solving the problem of efficient determination of correlation between subsets of $\\mathbb{R}^n$ for $n >> 1$. This is a very well-known problem and is a subject of active research.\nWeaknesses:\nMinor:\nThe Z-test is not used in practice that much. Moreover, it is not appropriate if the statistics of the population is not known beforehand. I think that it should be replaced with a t-test at the very least. Moreover, the distribution of intrinsic dimension cannot be normal, as it is a positive number, so a Poisson/Gamma distribution is more appropriate. Even though the issue of the distribution does not appear to be detrimental to the results of the paper, the issues of Z-test should be clearly stated in the paper.\nThe conventional $\\epsilon$ for $\\ell_\\infty$ attacks of CIFAR is $\\frac{8}{255} \\approx 0.03$, whereas in the experiments it is $0.01$ (refer to\nhttps://robustbench.github.io/\n).\nMajor:\nThe proposal is poorly supported and the original concepts that are introduced in the paper does not have any rigorous or concrete definition.\nThe literature review does not clear up what exactly \"implicit bias\" is, or how it is related to Fourier transform. The paper just assumes that the reader has the required background knowledge and only describes these relations as some \"deep connection\".\nQuestions:\nPlease elaborate on the significance of the proposal from the perspective of robustness in machine learning. Specifically, I don't see the significance of providing \"empirical evidence that the network bias in Fourier space and the target frequencies of adversarial attacks are closely tied\". The literature on this issue is pretty big as evident from a simple search in Google Scholar.\nI don't find the verbal description of the proposed correlation test convincing at all. Even if the concept is sound, no formal statement or expression of the method is present. I cannot see how it is possible to verify the arguments made in the paper in its current form.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 08:40Everyone", "Content": "Comment:\nWe thank the Reviewer for their comments and for giving us the opportunity to improve the robustness of our work. We respond here to the weaknesses and questions raised in the review.\nMinor weaknesses:\n1.\nThe Reviewer is right when assessing that the true distribution of the ID cannot be Gaussian, due to the impossibility of obtaining negative values. However, in all our tests, the distribution of the IDs computed after shuffling was nearly Gaussian, somehow justifying the choice of the Z-test. In any case, we coincide with the Reviewer's statement that, although the results of the paper are not affected by this issue, it should be at least commented on, so we added a sentence to the paper on the limitations of the Z-test (section 3.2).\n2.\nAs we detail in the paper (section 4.3), we chose $\\epsilon=0.01$ for PGD to maintain consistency with the perturbation sizes found by the other attacks. This choice does not harm the efficacy of the attack, which succeeds in almost 99% of the cases (please see Table 4, in the Appendix). However, motivated by this suggestion and by other points raised in the Reviews, we decided to test our method on other perturbation magnitudes, including $\\epsilon=0.03$. The results confirm our findings and they are reported in the Appendix (Section A.8) in the revised version of our pdf.\nMajor weaknesses:\n1.\nPlease refer to the response to question 2.\n2.\nWe could only provide a compact literature review due to space constraints. However, in section 2.1 we provide pointers to a number of papers that have analysed implicit bias in Fourier space (e.g. Rahaman et al., 2019 and Fridovich-Keil et al., 2022). The connection between implicit bias and adversarial attacks has not been as thoroughly investigated and it is, in fact, the focus of our work.\nQuestions:\n1.\nWe believe that understanding the phenomenon of adversarial vulnerability is a fundamental milestone towards building more robust and reliable models. As anticipated in the previous point, the literature on the relationship between implicit bias and adversarial attacks is, to the best of our knowledge, quite limited at the moment. We cite one paper by Faghri et al. (2021) as the main inspiration four our work. However, it is a purely theoretical paper and it deals with linear networks. Our work extends their results to more complex and useful models using an empirical approach.\n2.\nThe strong connection between correlations among data features and the intrinsic dimension of a dataset is a widely acknowledged concept in the field of unsupervised learning. For instance, in the context of hyper-planar manifolds, these correlations manifest in the PCA spectrum, creating a discernible gap that establishes the correct projection dimension. In the case of non-linear manifolds, where correlations exhibit non-linear characteristics, this connection persists, although its mathematical definition becomes somewhat elusive and hinges on the specific method employed for determining the intrinsic dimension. Since our method is designed to be agnostic to the intrinsic dimension determination technique, we purposefully refrain from providing a detailed mathematical description, opting instead to showcase the intuitive aspects of the method and its application to both toy and realistic models. We hold the firm belief that the tests we present are sufficient to support the conclusions outlined in the paper. This confidence is rooted in our verification that artificial uncorrelated by-design datasets with the same macro-features as those investigated in the paper yield clearly different results than those that we found correlated."}, {"Heading": "Official Comment by Reviewer hyn3", "Subheading": "Official CommentbyReviewer hyn318 Nov 2023, 03:05Everyone", "Content": "Comment:\nThank you for the detailed response. However, I am not convinced that the paper is ready to be published.\nWe could only provide a compact literature review due to space constraints.\nThe definition and the description of \"implicit bias\" is central to the argument of the paper. Even though its description would be written in the literature review, it is crucial for it to be present in the paper. IMHO, the paper should be reorganized so that the definitions could be placed in the main text.\nalthough its mathematical definition becomes somewhat elusive and hinges on the specific method employed for determining the intrinsic dimension.\nWhile it is perfectly fine for a paper to be somewhat of an \"idea proposal\", I don't think that it is enough for a top conference or journal. The proposal of a theory-oriented paper would be valuable when it deals with the nuances of the mathematical definitions."}]}, {"Heading": "Official Review of Submission9228 by Reviewer avqz", "Subheading": "Official ReviewbyReviewer avqz28 Oct 2023, 05:46 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe goal of this paper is to explore the connections between implicit bias and the adversarial vulnerability of deep neural networks.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe research topic in this paper is essential for the ML community.\nWeaknesses:\nThe contributions are somewhat limited. In this paper, the authors do not provide sufficient evidence to support their arguments for the strong correlations between implicit bias and adversarial attacks. From Tab.2, the cosine similarity is not sharp. The authors should present many more results (such as the adversarial success rates against non-linear correlations) to clarify this. Moreover, the important thing is that the authors need to give a clear presentation about why we need to relate the implicit bias and adversarial attack together. Then, the proposed method is limited and incompleted in Sec.3.2, which is challenging to apply to practical applications.\nHow do we know the adversarial class? Since we usually adopt an untargeted adversarial attack, how do we compute Eq.(1) for adversarial examples? Also, the obtained frequency masks should be explained further. Compared to the model trained with original features, what is the performance if we only consider the mask features of images to train a model?\nFinally, this paper does not propose new methods or strategies on top of their findings. What can we do next after finding the correlations?\nQuestions:\nPlease address all my concerns in the Weaknesses part.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 08:47 (modified: 16 Nov 2023, 08:48)EveryoneRevisions", "Content": "Comment:\nWe thank the Reviewer for their feedback on our work. Please see our response below.\nOn the cosine similarity:\nThe fact that the cosine similarity between masks is not sharp is one of the crucial points of our work. We find that the correlation between sets of masks is highly non-linear and thus not detectable by cosine similarity. This is the reason why we designed and applied a novel non-linear correlation method based on intrinsic dimension estimation.\nOn additional results:\nWe thank the Reviewer for suggesting to inspect how correlations are related to adversarial success rates. We ran an experiment using PGD with variable perturbation budgets and found that correlation appears in any case. Results are available in the Appendix of the revised pdf (section A.8).\nThe proposed method is limited and incompleted:\nWe are aware that there are limitations to our ID-based correlation approach, mainly related to the computational issues of ID estimation in the case of very high-dimensional or high-ID data sets. We clearly state these limitations in the paper (sections 3.2 and 4.6). However, we do not fully understand what the Reviewer refers to with the term \u2018incompleted\u2019.\nWhy we need to relate the implicit bias and adversarial attack:\nThe problem of adversarial vulnerability of neural networks remains largely unresolved and, to a certain extent, not fully understood. We believe that our work represents a step towards understanding adversarial attacks and, potentially, defending against them.\nOn the adversarial class:\nThe Reviewer is right in saying that the attacks we employ are untargeted. We state this point explicitly in the revised version of our pdf file. The adversarial class is simply known by feeding the adversarial input to the classifier.\nNew methods or strategies on top of our findings:\nWe believe that this work can be a starting point towards new strategies for adversarial defence, as indicated in the future directions (section 5). Moreover, we sketch what we believe to be a promising idea in this direction in the last lines of the section that deals with class-specific masks (section 4.7)."}]}, {"Heading": "Official Review of Submission9228 by Reviewer 3jNL", "Subheading": "Official ReviewbyReviewer 3jNL24 Oct 2023, 11:41 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe focus in this paper is on minimum one-norm frequency masks of images with respect to a given neural network classifier.  They are such that if the fast Fourier transform of an image is multiplied pixel-wise by the mask and then the inverse of the fast Fourier transform is applied, the resulting image is assigned the same class by the network as the original image.  The authors propose a technique based on the notion of intrinsic dimension to measure possibly non-linear correlation, and apply it to assess correlation between the frequency masks of images and their adversarial perturbations.  The main result is that some correlation is shown in this way for CIFAR-10 and Imagenette datasets.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe figures in the paper help with understanding.\nThe authors indicate interesting directions for future work in the last section.\nWeaknesses:\nThe reported decreases in the estimates of intrinsic dimension compared with the randomly shuffled data are relatively small.\nOne would expect some correlation between the frequency masks of the images and their adversarial perturbations simply because the adversarial noise is small.  I am not sure what beyond that I can conclude from the main result in the paper.\nThe proposed technique for assessing possibly non-linear correlation makes sense, however this paper shows that it is currently not practical for high-dimensional data, e.g. already for the Imagenette dataset there are computational and reliability issues.\nThe lack of space between paragraphs makes the paper harder to read, and is contrary to the formatting instructions in the LaTeX template for the conference.\nQuestions:\nWhat classes do the adversarial attacks used in the paper target, this does not seem to be stated anywhere in the paper?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Official Comment by Authors", "Subheading": "Official CommentbyAuthors16 Nov 2023, 08:53Everyone", "Content": "Comment:\nWe thank the Reviewer for their comments on our work, and respond to the weaknesses and questions that were outlined in the review.\nOn the small decreases in intrinsic dimension:\nIt is true that in some cases the decreases in the intrinsic dimension (ID) compared to the shuffled data sets are relatively small. This is the reason why we decided to adopt a statistical test to assess the significance of such variations.\nCorrelation is expected:\nWe agree that a strong connection between the implicit bias and the adversarial vulnerability of a neural network was to be expected. However, we point out that, to the best of our knowledge, this work is the first one to explicitly pinpoint such a connection. Besides, our result is not limited to prove the correlation: we give a very precise image-specific map of the spectral implicit bias. This information is potentially useful to design new strategies for adversarial defense and interpretable networks, topics which we are addressing as future goals. Moreover, motivated by this comment and by points raised by other Reviewers, we decided to test our approach on adversarial attacks with higher perturbation budget (namely, PGD with $\\epsilon=0.03$). Our findings are not harmed by this choice, as shown in the revised pdf (Appendix, section A.8). Thus, the correlation is not solely justified by the fact that adversarial noise is small.\nIssues of the correlation method:\nWhile it is clear that some limitations emerge in the case of very high-dimensional data and/or very high-ID data (the case of Fourier masks on Imagenette is particularly challenging as it falls into both categories), we believe that the range of feasible applications of our ID-based correlation method is still very broad.\nParagraph spacing:\nWe thank the Reviewer for pointing out this issue, we fixed the paragraph spacing in the new version of our manuscript.\nQuestion:\nAll attacks are used in their untargeted version, meaning that the only goal of the attack is to produce misclassification, regardless of the adversarial class. We thank the Reviewer for giving us the opportunity to clarify this point in the revised pdf file."}, {"Heading": "Official Comment by Reviewer 3jNL", "Subheading": "Official CommentbyReviewer 3jNL16 Nov 2023, 11:14Everyone", "Content": "Comment:\nThank you for these responses."}]}]}, "QqqkskOFO9": {"paper_info": {"Primary Area": "reinforcement learning", "Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "Off-policy reinforcement learning, actor-critic methods, TD3, discrete action spaces, continuous action spaces", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We identify and address a key drawback in actor-critic methods when the actor fails to find actions that maximize the critic.", "Abstract": "Value-based actor-critic approaches have been widely employed for continuous and large discrete action space reinforcement learning tasks. Traditionally, an actor-network is trained to find the action that maximizes the critic (action-value function) with gradient ascent.\nWe identify that often an actor fails to maximize the critic because (i) certain tasks have challenging action-value landscapes with several local optima, and (ii) the critic landscape varies non-stationarily over training. This inability to find the optimal action often leads to sample-inefficient training and suboptimal convergence. To address the challenge of better maximization of the critic's landscape, we present a novel reformulation of the actor by employing a sequence of sub-actors with increasingly tractable action-value landscapes.\nIn large discrete and continuous action space tasks, we demonstrate that our approach finds actions that better maximize the action-value function than conventional actor-network approaches, enabling better performance.https://sites.google.com/view/complexaction", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "Supplementary Material": "zip", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Submission Number": "9227", "PDF Url": "https://openreview.net/pdf?id=QqqkskOFO9"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:55 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nReject"}, {"Heading": "Meta Review of Submission9227 by Area Chair id9y", "Subheading": "Meta ReviewbyArea Chair id9y05 Dec 2023, 06:03 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper proposes a new scheme for maximising the critic in an actor-critic algorithm (like TD3 on DDPG). The proposed algorithm (SAVO) works by maintaining an an ensemble of critics and actors. Actions are then selected using a (heuristic) maximisation rule (see line 13 in Algorithm 1). Experiments are done extensively and include MineWorld, a recommender system simulator and continuous control tasks.\nStrengths:\nusing gradient based algorithms for recommender systems / in setting with huge action spaces is a valid and much needed area of research, in scope for ICLR.\nevaluation (after paper update) uses performance profiles generated with the rliable library\npaper is mostly well-written\nWeaknesses:\nthe heuristic maximisation rule is not justified formally. In other words, there is no proof that the output of Algorithm 1 solves any MDP given infinite data, which seems like a major concern for an RL method.\nthe method claims to find better local optima, but the justification for that is purely experimental (no theory) and insufficient\nthe method to embed discrete action spaces in a continuous space used by the paper leads to a piecewise-constant critic. This is at odds with the deterministic gradient theorem, which emphasises following the gradient of the critic. I understand the authors cite [1] which seems to do the same. However, the work [1] is not peer-reviewed.\n[1] Dulac-Arnold, Gabriel, et al. \"Deep reinforcement learning in large discrete action spaces.\" arXiv preprint arXiv:1512.07679 (2015).\nJustification For Why Not Higher Score:\nThis is a strong reject. The weaknesses identified in the meta-review seem very serious. Any RL algorithm should compute the optimal policy given infinite data but I am not sure this is the case here.\nJustification For Why Not Lower Score:\nN/A"}, {"Heading": "Added: visual evidence of hypothesis, ensemble and CEM baselines, design choice validation, complexity analysis, RLiable aggregation", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:54Everyone", "Content": "Comment:\nWe thank the reviewers for their constructive feedback that helped improve our paper significantly. All reviewers appreciated (i) the importance of the\nproblem\nof actors being unable to find the value-maximizing action, (ii) our novel\nalgorithm\nto prune the optimization landscape successively, and (iii) promising\nexperimental\nresults. We accommodate all feedback in the form of baselines, ablations, and visual analysis:\nVisual Evidence of Pruning Optimization Landscape [oxP1, AC]\n[Figure 3, 11]\nWe show that SAVO successfully prunes the Q-optimization landscape enabling the actors to find better globally optimal actions. Every $Q_i$ function reduces the number of locally optimal peaks, by pruning away the Q-landscape below previous actions $a_0, ..., a_{i-1}$, as seen in Fig 3 (top) results of Hopper. To obtain this result, we project the N-dimensional action space of environments to 2-D for visualization. As we see in Inverted-Pendulum-Hard result, the primary actor $\\pi_0$ was stuck in a locally optimal peak. But, SAVO\u2019s successive actor-critics finds a more optimal peak of $a_1$.\nNew Ensemble Baseline [ZeCv, MBmv, oxP1]\n[Figure 2]\nWe appreciate the reviewers\u2019 suggestion that a comparison to ensemble-based methods is necessary. We add an ensemble baseline in Fig. 3, where we train an ensemble of TD3 actors with a single primary critic. Just like our method, we select the action from the ensemble that maximizes the Q-value. Fig. 3 shows SAVO (Ours) consistently outperforms the Ensemble baseline. This helps delineate the contributions of better exploration with multiple actors with better optimization landscapes obtained using SAVO.\nThree New Evolution-based & CEM Baselines [ZeCv, MBmv]\n[Figure 2]\nWe thank the reviewers for pointing out relevant literature on evolutionary methods for better Q-function optimization by building up on CEM or emulating CEM. We add a thorough discussion in Section 2 and experiments in Section 6 on the following baselines:\nCEM-Actors: following evolutionary approaches like QT-Opt and an upper-bound to CEM-RL, CGP, GRAC (Section 2.4).\nGreedy Actor-Critic: Follows Neumann et al. (2023) by training a high-entropy proposal policy to sample actions, rate them with Q-value, and greedily train actor on best actions.\nGreedy TD3: We implement a version of Greedy-AC with our TD3-based improvements to exploration and update procedure.\nSAVO outperforms all the baselines consistently, showing the importance of directly tackling the problem of challenging optimization landscapes.\nFiLM, DeepSet Design Choices [MBmv, oxP1, ojfo]\n[Appendix D2, D3]\nWe clarify the introduction of the architectural design choices of successive actor-critics in SAVO, and add a better description of these modules. In brief, the Deep Set is used as a summarizer to encode the previous actors\u2019 actions into a latent. Alternate approaches like LSTM and Transformers can also be used. Subsequently, the encoded action-summary must condition the next successive actor and critic. This can be done with a FiLM scheme to modulate all the layers of the actor and critic neural networks, or simply by concatenating the summary with the state space. We add experiments with these design choices and a detailed discussion.\nResults\n: We uniformly choose DeepSet as it is more scalable to an increasing number of actor-critic pairs, and FiLM for overall better results.\nAdditional Results\nComputational Complexity Analysis [ZeCv, MBmv]\n[Figure 4(d)]\nWe investigate the impact of varying the number of actor-critic pairs on the performance of SAVO and the GPU compute memory cost across different Mujoco environments with $1 \\to 3 \\to 5$ actors-critics. We see a significant gain in performance, with only a minor increase in GPU usage, such as from $619 \\to 637 \\to 673$ MB for hopper task. In fact, prior approaches like TD3 often fail in complex optimization landscapes in both discrete and continuous action space environments that we have analyzed. Thus, we trade-off a miniscule amount of compute for significant improvements in performance and sample complexity.\nRLiable results\nMore Mujoco-Hard Environments [MBmv]\n[Figure 2]\nAdded: Inverted-Pendulum, Inverted-Double-Pendulum, Ant, HalfCheetah. SAVO consistently outperforms or matches the other best baselines across various environments.\nRLiable for aggregate statistics across 14 environments [AC]\n[Figure 4 (c)]\nAs per the recommendation, we provide a summarized comparison across all 14 tasks with RLiable, demonstrating SAVO outperforming the baselines.\nOther editing comments and clarifications are addressed inline to reviews below. We hope our revision addresses all the concerns of the reviewers with: visual confirmation of our hypothesis, 4 additional baselines, FiLM and DeepSet design choice validation, computational complexity analysis, and consistent performance gain of SAVO across 14 tasks."}, {"Heading": "Comment from AC", "Subheading": "Official CommentbyArea Chair id9y15 Nov 2023, 14:30 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nDear Authors,\nTo facilitate discussion about your paper, it would be great if you addressed the points brought up by the reviewers.\nIn addition, I have the following questions:\nTowards the bottom of page 3, you introduce a nearest-neighbour mapping from continuous to discrete actions. However, if you use this mapping, the true critic will be piecewise constant, making the use of gradient based algorithms challenging. Can you elaborate exactly why this works? As I understand this, the algorithms might still work due to function approximation - although we will never learn the true (piecewise flat) critic, we will learn some version of it \"smoothed out\" with function approximation.\nYou base your algorithm on TD3, which uses two copies of the critic do battle overestimation bias. However, such two-critic mechanism does not seem to be included in Algorithm 1. Can you elaborate?\nYou are making claims that the critic approximation scheme you use helps battle local optima. Do you have any direct evidence supporting that hypothesis? How do you count the local optima?\nWhy not use RLiable (\nhttps://github.com/google-research/rliable\n) or a similar library to summarise results across environments in a robust way?\nMinor nitpick: in the beginning of section 3.2, high-stake => \"high-stakes\".", "Replies": [{"Heading": "Added visual evidence and RLiable results", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:57 (modified: 15 Mar 2024, 00:26)EveryoneRevisions", "Content": "Comment:\nThank you for your insightful questions. We have incorporated your suggestions in the revision, and clarify your questions below:\n1. How nearest-neighbor mapping works in the discrete action setting?\nA common strategy used in large discrete action spaces is to represent discrete actions with continuous representations, and solve the task like continuous action space RL. We follow the strategy of Wolpertinger [1], where a Q-function is learned over the continuous space. The actor\u2019s continuous output is used to obtain k nearest-neighbor true action representations. Finally, the Q-value is evaluated over these \u201ctrue\u201d actions and the best Q-valued action is chosen.\nHowever, as you correctly point out, while training the actor with gradient ascent over the Q-function, there will be times when the critic is queried for \u201cfake\u201d action representations, not associated with any true discrete action. The critic would be undefined on such intermediate actions \u2014 a neural network would at-best interpolate or smooth the Q-values when queried on such samples. This creates a smoothed piecewise-like critic with a challenging optimization landscape with many locally optima, as there are peaks on the true action representations, and the in-between landscape is hard to optimize.\n[1] runs gradient ascent on this critic landscape completely ignoring the problem and thus underperforms empirically (Figure 2). In contrast, SAVO learns a sequence of actor-critics that successively simplify Q-value landscapes. This results in finding the action that better finds the optimal \u201ctrue\u201d peak of the Q-function.\n2. Twin-critics of TD3 in Algorithm 1\n[Algorithm 1]\nWe follow TD3 and do use twin critics for primary critic to avoid overestimation (along with other improvements like clipped double Q-learning, delayed policy updates, and target policy smoothing). As per your suggestion, we modify Algorithm 1 to denote that the update follows TD3.\n3. Direct evidence showing reduced local optima\n[Figure 3, 11]\nAs per your suggestion, we visualize the Q-value landscapes resulting in the successive critics of SAVO for all continuous control environments. For high-dimensional action spaces, we project the action space to 2D and generate a plot of Q-value over the action space. We observe:\nsuccessive critics $Q_0 \\to Q_1 \\to Q_2$ have optimization landscapes with fewer local optima, as most optima below previously selected actions are pruned away. This is visually seen as the warm (high Q-value) regions of the contour plot increase successively.\nBetter Q-valued actions are found than just a single actor $\\pi_0$ that maximizes $Q_0$. Since all the peaks below the Q-value of previous actions vanish in successive critics, successive actors can focus on optimizing over better peaks.\nFigure 4 (a) also demonstrates our actions have 40-50% better Q-values than the baseline over the course of training, and result in better returns than if we evaluated just using a single actor.\n4. RLiable to summarize results\n[Figure 4 (c)]\nAs per your recommendation, we provide a summarized comparison across all 14 tasks with RLiable, demonstrating SAVO outperforming the baselines.\n[References]\n[1] Dulac-Arnold, Gabriel, et al. \"Deep reinforcement learning in large discrete action spaces.\" arXiv preprint arXiv:1512.07679 (2015)."}]}, {"Heading": "Official Review of Submission9227 by Reviewer ZeCv", "Subheading": "Official ReviewbyReviewer ZeCv31 Oct 2023, 17:50 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper claims that actor often finds actions that cannot maximize the critic and this leads to sample inefficient training and suboptimal convergence. The paper proposes an algorithm that roughly works as follows. First, in addition to a primary critic, another K actors and critics are initialized, and they are queried in order: an actor\u2019s input depends on all previous actors\u2019 outputs; second, the action with highest primary critic value is executed; third, K updates applied to the K actor-critic pairs; last, the primary critic is updated by its own maximum action. Experiments are conducted to verify their claims.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe presentation is reasonably clear.\nThe proposed problem regarding the actor often cannot align well with the maximum action worths studying, it looks interesting to me.\nWeaknesses:\nThe critical claims are not well-supported: 1) why the proposed method can help find maximum action; 2) the connection between finding maximum action and improved sample efficiency; 3) the actual benefit of the proposed algorithm, is it from finding the maximum, or ensemble, or exploration? 4) experiments are not well-designed; 4) highly related works are missing.\nTo support the claim of the paper, the following experiments need to be done:\nadd experiments to verify the proposed method does find action with a higher action value; current version directly jumps into sample efficiency, leaving the critical claim unverified;\nThe connection between finding the maximum action and improved sample efficiency is not supported, please justify;  would it introduce overestimation that hurts learning?\nplease add ensemble-based exploration method for comparison, as it is known that ensemble would provide benefits of enhancing sample efficiency. Another purpose of adding ensemble is to verify if the main benefit really comes from finding the maximum action or from exploration, If it is the letter, then the pitch of the paper should be modified and another set of baselines aiming at better exploration should be compared.\nAny comments on the convergence of such an algorithm? I am a bit concerned that the update of an actor depends on all previous actors output could result in high non-stationarity. This would make the training difficult.\nThe proposed algorithm seems to have much higher computation cost, which weaken the practical utility.\nPotential flaws of the experiment design.\nIn the algorithm, it seems at each time step, the algorithm update both policy and critic parameters K times, do the authors do the same thing for baselines?\nPlease add baselines as suggested by below missing related works.\nThere are several missing references that are highly relevant:\nA model reference adaptive search method for global optimization by Jiaqiao et al.\nQ-learning for continuous actions with cross-entropy guided policies by Riley et al.\nGreedy Actor-Critic: A New Conditional Cross-Entropy Method for Policy Improvement by Samuel et al\nCEM-RL: Combining evolutionary and gradient-based methods for policy search by Alois et al.\nWire fitting algorithm by Baird et al. the title is likely RL with high-dimensional continuous actions.\nAmong these, 2,3,4 are highly relevant and should be also compared. Please explain what the differences are between your work and those existing ones and comment on the significance of such difference. I consider this one of the critical weaknesses of this work.\nQuestions:\nsee above.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Important Baselines from Related Work added", "Subheading": "Official CommentbyAuthors23 Nov 2023, 07:00 (modified: 23 Nov 2023, 07:32)EveryoneRevisions", "Content": "Comment:\nWe thank you for your constructive feedback that helped improve our paper significantly. We address your concerns below:\nImportant Baselines from Related Work added:\nWe appreciate the reviewer\u2019s suggestions and pointing out the relevant work and baselines from prior work. We have added a discussion and comparison to all the suggested baselines:\nEnsemble actors\n[\nFigure 2\n,\nSection 2.3\n] As per your suggestion, we implement an ensemble-actors approach where we train multiple actors with the same critic, but explore using the critic maximizing action found by the actors. This approach helps disentangle SAVO\u2019s ability to prune the optimization landscape from the improved exploration due to the presence of multiple actors. Please refer to combined response for further details, and Section 2.3 for a discussion and references of past work.\nEvolutionary Actors\n[\nFigure 2\n,\nSection 2.4\n] As per your suggestion, we add:\nCEM-actor baseline\n: Algorithms like QT-Opt, CGP, CEM-RL, and GRAC employ CEM as the actor in online RL training. We implement QT-Opt style CEM, where the critic is still trained with our TD3-augmented tricks. These algorithms involving CEM require infeasible amounts of repetitive evaluations of the Q-function and do not scale well to high-dimensional action spaces (Yan et al., 2019). Note that CGP, CEM-RL and GRAC can be considered as suboptimal versions of a good CEM actor in the QT-Opt, because they already use CEM as a guide to train their actors. Thus, we only implement and compare against the QT-Opt style CEM baseline.\nGreedy-actor\ncritic baseline: emulates CEM by sampling from a high-entropy action proposal policy, evaluating these actions with the Q-function, and training the actor to greedily follow the best actions. However, since this approach also depends on gradient ascent and samples actions around the mean actions of a single-actor, thus limiting its ability to find the globally optimal action.\nGreedy-TD3\n: We implement another version of Greedy-actor-critic in TD3 style training, where the critic now benefits from TD3 update tricks, and the exploration is performed with OUNoise added to the mean action of the stochastic greedy policy.\nComputational Cost Analysis\n[Figure 4(d)]\nPlease refer to combined response.\nClarifications\n\u201cThe connection between finding the maximum action and improved sample efficiency is not supported\u201d\nWe bring attention to Figure 4(a) and Figure(b) where we already show that SAVO results in an improved Q-value of its actions, which translates into a sample efficiency improvement when evaluating SAVO with all its actors v/s only a single actor.\n\u201cWould it introduce overestimation?\u201d\nNo. SAVO only improves the actor\u2019s capability to find the Q-value maximizing action, which is the key goal of the base algorithm of DPG / DDPG / TD3.\nThere is still exploration on top of the action found by SAVO, so the exploration is not hindered.\n\u201cIt seems at each time step, the algorithm update both policy and critic parameters K times?\u201d\nNo. We clarify that, as shown in Lines 16 and 17 of Algorithm 1, each individual $Q_i$ and $\\pi_i$ is only updated once every iteration. $K$ denotes the number of actor-critic pairs, as written in the first line of Algorithm 1. So, the for loop in line 15 is to denote all the actor-critic pairs. To further clarify, all the baselines and ablations are based on the same algorithm design and implemented in the same code file, for fairness.\n[References]\nYan et al. Learning probabilistic multi-modal actor models for vision-based robotic grasping. ICRA 2019."}]}, {"Heading": "Official Review of Submission9227 by Reviewer MBmv", "Subheading": "Official ReviewbyReviewer MBmv30 Oct 2023, 05:47 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper proposes a continuous actor value optimization method to address the issue that traditional single actor-critic algorithms are prone to failing into local optima, in order to improve sampling efficiency and final performance in large discrete action spaces and continuous action spaces. The effectiveness of the proposed method is ultimately demonstrated through experiments.\nSoundness:\n1 poor\nPresentation:\n1 poor\nContribution:\n2 fair\nStrengths:\nThis paper presents a novel reformulation of the actor. I think that addressing the challenge of better maximization value function by \"pruning\" an optimization landscape is an interesting work.\nWeaknesses:\nThe writing expression is not sufficiently clear and the logic is confusing, especially in Introduction and Related Work sections. It is difficult to understand the structure of the article. The contribution is not clear, and it is not suitable to use a large space to introduce the experimental environment.\nThis paper lacks many vital technical explanations, including an introduction to deep-set and FiLM layer, the motivation behind their usage, and analysis of their effects.\nThe experimental results are not sufficiently reliable. The baselines are outdated. There is no mention of hyperparameter sensitivity or setting experiments.\nQuestions:\nIn Relate Work, the introduction of prior work is outdated. Please supplement it with the latest relevant work.\nThe work presented in this paper seems to fall under the domain of ensemble methods. It may be necessary to supplement it with relevant work and introduce ensemble-based value optimization algorithms as additional baselines.\nIn Algorithm 1, the \"state s\" in lines 8 and 10 need clarification.\nDoes the proposed method in this paper suffer from the problem of action values overestimation?\nWhy only select 3 seeds in some experiments, such as Figure 4?\nIs the modification of the experimental setup fair? Other baselines may not have been designed specifically to address the problem presented in this paper.\nThe experiment in the Appendix only has the Easy environments, what about the other Hard environments?\nDue to the utilization of ensemble methods, I am concerned about the computational efficiency of the algorithm. Please supplement the experiments or provide an analysis.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n3: reject, not good enough\nConfidence:\n5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Added several new experiments and clarifications", "Subheading": "Official CommentbyAuthors23 Nov 2023, 07:10 (modified: 23 Nov 2023, 07:17)EveryoneRevisions", "Content": "Comment:\nWe thank you for your constructive feedback that helped improve our paper significantly. We address your concerns below:\nTechnical explanation and analysis of FiLM, DeepSet\nPlease refer to the combined response\nAdded latest baselines\nThanks for your suggestion. Please refer to the combined response. We have added 4 new baselines: CEM, Greedy-AC, Greedy-AC-TD3, Ensemble.\nAdded more experimental benchmarks\n\u201cThe experimental results are not sufficiently reliable.\u201d \"The experiment in the Appendix only has the Easy environments, what about the other Hard environments?\u201d\n[Figure 2]\nWe added more continuous control environments in the paper, and report results across 11 environments.\n[Figure 4(c)]\nWe also report the results using the RLiable library (also suggested by AC) to demonstrate that our method outperforms the baselines and ablations reliably across the environments.\nComputational Efficiency\n\u201cI am concerned about the computational efficiency of the algorithm. Please supplement the experiments or provide an analysis.\u201d\n[Figure 4 (d)]\nThank you for this suggestion. We have added a complexity v/s performance analysis that shows the computational requirement increase is negligible. Please refer to the combined response.\nSupplemented discussion in Related Work\n[Section 2]\nAdded discussion on evolutionary methods and ensemble methods, and also restructured the related work section significantly.\nClarifications\n\u201cThere is no mention of hyperparameter sensitivity or setting experiments.\u201d\nAppendix E.2 and E.3 already provides a discussion of hyperparameter sensitivity and setting details across all baselines.\nTo reiterate, the sensitive hyperparameters were found to be learning rates and network sizes of actors and critics, and were searched for each baseline.\n[Figure 4 (c)]\nA key hyperparameter of our approach is $K$, the number of actor-critic pairs. Figure.4 shows the improvement in performance as $K$ increases in continuous control tasks. However, we chose $K$=3 across environments as that is enough to show significant gain with our method.\n[Appendix D2, D3]\nWe also add experiments to show different design choices are viable: FiLM v/s No-FiLM for conditioning, and DeepSet v/s LSTM v/s Transformer for past action summarization.\n\u201cIn Algorithm 1, the \"state s\" in lines 8 and 10 need clarification.\u201d\nWe correct the typo in lines 8-10, as $s$ \u2192 $s_t$. $s_t$ is the state observed in Line 5.\n\"Does the proposed method in this paper suffer from the problem of action values overestimation?\u201d\nSince our algorithm is based on TD3, the problem of overestimation is reduced by the presence of twin critics and delayed updates. We clarify this in Algorithm 1 to alleviate the concern of overstimation. To further justify, in the Q-learning update of primary critic in Line 19 of Algorithm 1, our method only modifies the search of the Q-value maximizing action. This is a key requirement of the DPG algorithm and the training objective of DPG, DDPG, TD3, etc. Works like DDPG and TD3 alleviate the issues of overestimation of Q-functions, and our implementation being based on TD3, also benefits from those solutions. All the baselines and ablations also equivalently benefit from this, and do not suffer from overestimation any more than TD3.\n\u201cWhy only select 3 seeds in some experiments, such as Figure 4?\u201d\nAll analysis results have been updated with 5 seeds. No trend is affected.\n\u201cIs the modification of the experimental setup fair? Other baselines may not have been designed specifically to address the problem presented in this paper.\nTo exemplify the problem of challenging Q-function landscapes, we curate hard benchmarks of continuous control tasks, but we also reported results on the original easy benchmarks with relatively simple optimization landscapes, in Figure 2. SAVO outperforms baselines in both the easy and hard versions of the tasks, but more significantly in the hard versions. This shows that our algorithm\u2019s contribution is more robust to challenging optimization landscapes, that would be more common as RL scales up to harder problems. This is already evident in our results in the discrete action space environments, where the optimization landscape is already challenging because of the presence of only few valid points in the action representation space, that correspond to actual discrete actions.\nThe baselines from various prior works (Figure 2) are indeed incapable of addressing the problems of Q-function optimization presented in this paper. That is the key claim that we are making. All the implementations of the baselines are fair and based on the same code skeleton (code is attached in supplementary), and we clearly demonstrate that it is because of the better optimization of the Q-function by SAVO\u2019s successive actors than baseline actors like single actors, Sampling-augmented actors, CEM Actors, and Ensemble of Actors."}]}, {"Heading": "Official Review of Submission9227 by Reviewer oxP1", "Subheading": "Official ReviewbyReviewer oxP128 Oct 2023, 19:46 (modified: 24 Nov 2023, 00:12)EveryoneRevisions", "Content": "Summary:\nThis paper studied an interesting problem that the training of the policy network often cannot effectively optimize the learned value function. This could lead to sub-optimal learning performance and ineffective exploration. To address this issue, this paper proposed a new ensemble technique that utilizes a sequence of separately trained actor-critic pairs to gradually refine/restrict the action space being considered. The newly proposed algorithm has been experimented on multiple benchmark problems with both discrete and continuous action spaces. The performance results showed that the new algorithm can achieve better overall performance across all the benchmark problems.\nSoundness:\n2 fair\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nIt is a well-known problem in the literature that the trained policy network in an actor-critic algorithm may often fail to optimize the learned value function. This inconsistency could potentially weaken the performance of the learning process. This paper developed an interesting new algorithm to address this issue. The effectiveness of the new algorithm is also evidenced by promising experiment results.\nWeaknesses:\nWhile the idea of using a series of successive actor-critic pairs to gradually refine/restrict the action space is interesting, however, this also means that the action selection decision from the policy network may be highly sensitive to the minor nuances of the learned critic. This often introduces bias to the learning process, resulting in degraded learning stability and restricted exploration. Hence, the downside of using multiple successive actor-critic pairs should be extensively examined in this paper. It is important to know why successively restricting the action space based on the trained critic will not affect the learning stability with a solid theoretical foundation. It is also important to know why this actually helps to improve the effectiveness of exploration, rather than restricting exploration, as claimed by the authors.\nSince the newly proposed algorithm uses an ensemble of actor-critic pairs, it is related to ensemble actor-critic algorithms. Hence, in section 2, it seems necessary for the authors to review existing ensemble actor-critic methods and clearly highlight the key novelty of the new algorithm, compared to existing ensemble algorithms. Furthermore, the experiment study should include more state-of-the-art ensemble baselines, in order to clearly show the advantages of the new algorithm over existing ensemble algorithms.\nSome parts of the new algorithm design seem to lack technical clarity. In particular, it is not clear to me how deep-set is used to produce Z as a concatenation of previously selected actions and state. It is also unclear how FiLM is used to enable a policy to choose its actions that are conditional on Z. Meanwhile, The motivations and rationales of using deep-set and FiLM should be clearly explained and strongly justified.\nThe authors stated that their new ensemble technique can be applied to many different actor-critic algorithms. Given this statement, it is not clear why they focus primarily on applying their new technique to TD3 alone. To demonstrate the wide applicability of the new technique, the authors should study its possible application to other algorithms, such as SAC.\nI don't quite understand some mathematical formulas presented in this paper. For example, I don't know how to find the optimal action a' based on the primary critic, as part of the final training objective, which is further conditional on $\\Pi$. The formula for policy gradient in the final training objective also misses some brackets such as }. Meanwhile, it remains questionable why the policy gradient formula is valid, i.e. what kind of gradient is being calculated and why the gradient allows the trained policy network to maximize the expected return. I think more detailed and thorough theoretical analysis is necessary to justify the validity and effectiveness of the proposed training objective.\nSome statements in this paper are not easy to understand. For example, what does it mean by \"navigate the action-value landscape more proficiently\" on page 1? What does it mean by \"distribute the optimization load over to the critic\" on page 5? What does it mean by \"slower than the original inefficiencies of the actor\" on page 5? What does it mean precisely for the optimization landscape of Q to be more tractable? If the number of local optima of Q's landscape can be reduced, to which extent can such reduction be actually achieved?\nThe English presentation of this paper may need to be improved. The authors are highly recommended to conduct more rounds of proof-reading of their paper to substantially improve the presentation clarity and quality.\n======\nThank the authors for responding to my questions. the response has addressed some of my concerns. Meanwhile, I have some further doubts regarding the response:\nI understand that the new algorithm does not follow the conventional ensemble strategies. However, for the sake of showing the true strength of the new algorithm, its benefits in terms of exploration, policy gradient estimation, value function learning etc. may need to be further expanded, compared to previously proposed ensemble methods.\nLine 13 of Algorithm 1 is based on the estimated Q-function. Due to the estimation noise/error, I don't believe it is guaranteed that the new action selection method is definitely better than the case of using a single actor. To a large extent, I feel the intuitive discussion (including some illustrative figures) about the stability issue or the direct advantage of identifying the best possible action is not sufficiently convincing. It would be great if the authors can present a more thorough theoretical analysis to justify these major claims.\nI am not so sure how the policy gradient should be calculated for the new form of actor-critics. Specifically, does Q_i in the new form satisfy any Bellman equation and why? Why can the effective state space be expanded with actions chosen by other actors? What is the new definition of policy gradient on the basis of the expanded state space, especially when the action component of the state space is affected by the learning process of other actors (hence the expanded state space may no longer satisfy the Markov property)? Perhaps more detailed mathematical derivation could help to clarify these concerns.\nQuestions:\nWhy will successively restricting the action space based on the trained critic not affect the learning stability and improve the exploration effectiveness?\nWhy is the new policy gradient formula valid, i.e. what kind of gradient is being calculated and why the gradient allows the trained policy network to maximize the expected return?\nPlease refer to the previous section regarding questions on the clarity of some statements.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Thank you for your review! Here are our responses.", "Subheading": "Official CommentbyAuthors23 Nov 2023, 07:00 (modified: 23 Nov 2023, 07:22)EveryoneRevisions", "Content": "Comment:\nWe express gratitude for your valuable feedback and constructive input. Your positive remarks regarding the approach and experimental performance are acknowledged and appreciated. Below, we provide responses to the concerns you raised.\nNew Ensemble Baseline\nNovelty over ensemble methods: Ours is not a typical ensemble method, where usually the constituents of the ensemble are symmetric. In fact, ours is a sequential ensemble, where successive actor-critic pairs optimize different optimization problems, building up on the past actor-critic pairs.\nOur added visual result in\nFig.3\nshows how this successive optimization eases the Q-function optimization landscape, which indeed helps the successive actors to find more globally optimal actions than before, with respect to the current Q-function\nVisual demonstration of improving optimization landscape\n[New Figure.3]\nThe optimization landscape of Q-value concretely represents the landscape where the N-D action space represents the independent variable and the 1-D Q-value represents the dependent variable. For visualization, we map the action space to 2-D when N > 1. Fig .3 demonstrates that the Q-function becomes more easy to globally optmize with every iteration of our successive actor-critics. This is because the locally optimal peaks below past actions\u2019 Q-values are pruned away from the optimization landscape. As we can observe:\nThe number of local optima are reduced in $Q_0 \\to Q_1 \\to Q_2$, as most action values are shifted up in the Q-value space. This enables successive actors $\\pi_0 \\to \\pi_1 \\to \\pi_2$ to focus on more optimal regions of the true Q-value space.\nThe actions $a_1$ and $a_2$ found by $\\pi_1$ and $\\pi_2$ are indeed more optimal than $\\pi_0$ whose actions were only locally optimal peaks, but globally suboptimal.\nLearning stability\nAction selection decision\nThis is true for all actor-critic methods, especially those learned with deep learning. However, the key goal of any RL agent is to take actions that maximize its expected return in the environment, which is why actor-critic algorithms learn actors that can find actions to maximize the Q-values. This does not create any\nbias\nin learning of the actors, because their true objective is to maximize the critic. While the Q-function itself can be biased during deep RL training, it is still the best estimate of the objective for the actor. Our method does not degrade the primary critic\u2019s function which is already based on stabilizing tricks adopted from TD3, like twin critics, delayed updates, and soft-action evaluation. Thus, stability of training of the primary critic is not negatively affected at all by our method. And the actor learned by our method is guaranteed to be better than a single actor, because of the max operator in Line 13 of Algorithm 1, which ensures the action is always at least as good as the one suggested by a single actor.\nPlease also refer to combined response for more details.\nExploration\nExploration for each successive actor $\\pi_i$ still follows the standard OU Noise based exploration from DDPG, TD3. The successive actors provide an action that has a higher Q-value than a single actor would have provided, but the exploration term is still added over the actions while acting in the environment. We have modified the Algorithm 1 to clarify this important detail.\nFurthermore, the sample efficiency improvements across 14 tasks (Fig.4 using RLiable as AC suggested) empirically justifies that our method never hurts exploration in the environment.\nValidity of policy gradient objective\nEach successive actor-critic pair solves its own deterministic policy gradient objective, where only the effective state space is modified. Conventional actor-critics take the form $\\pi(s, a)$ and $Q(s, a)$. Whereas, each of our successive actor-critics take the form $\\pi_i({s, a_{0:i-1}}, a)$ and $Q_i({s, a_{0:i-1}}, a, a)$. Thus, only the effective state space of the MDP is modified, and we can directly apply any actor-critic algorithm to train these actor-critics (we use TD3).\nPlease do let us know if you have any leftover concerns or questions."}, {"Heading": "Respnose continued", "Subheading": "Official CommentbyAuthors23 Nov 2023, 07:07 (modified: 23 Nov 2023, 07:25)EveryoneRevisions", "Content": "Comment:\nTechnical explanation and analysis of FiLM, DeepSet\nIn Appendix C.3 and C.4, we added the descriptions of Deepset along with other design choices of list-summarizers as well as Feature-wise Linear Modulation (FiLM). In short, Deepset effectively aggregates the information in the list input while FiLM helps to condition on preceding list-input. Those modules contribute to better training the list of actor-critics in SAVO.\nWe also added ablations in Appendix.D.2 & D.3 to compare (i) FiLM v/s no-FiLM and (ii) the choice of DeepSet v/s LSTM v/s Transformers to aggregate the information from previous selected actions. The results validated our choice of DeepSet as it is more scalable to an increasing number of actor-critic pairs. Also, we acknowledge that this design choice depends on the environment and the use-case as some tasks in continuous domains show that LSTM / Transformers outperform Deepset.\nClarifications\nBaseline Selection of TD3\nWe choose TD3 because of its unified applicability to both action-representation-based discrete action spaces and continuous action space. Particularly, the Wolpertinger algorithm [Dulac et al 2015] is based on the DDPG algorithm and is the most commonly used base algorithm for large discrete action spaces. While we agree with the reviewer\u2019s suggestion that combining SAVO with SAC would be good to show wider applicability of our method, we think this extension might offer more flexibility in the design choices. Thus, for this project, we decided to stick to the simple architecture of TD3 as described above.\nHow to find the optimal action a' based on the primary critic\nWe improved the clarity of writing in the approach section and added the following qualitative result to support our claim;\n[New Figure.3]\nThe optimization landscape of Q-value concretely represents the landscape where the N-D action space represents the independent variable and the 1-D Q-value represents the dependent variable. For visualization, we map the action space to 2-D when N > 1. Fig.3 demonstrates that the Q-function becomes more easy to globally optmize with every iteration of our successive actor-critics. This is because the locally optimal peaks below past actions\u2019 Q-values are pruned away from the optimization landscape. As we can observe:\nThe number of local optima are reduced in $Q_0 \\to Q_1 \\to Q_2$, as most action values are shifted up in the Q-value space. This enables successive actors $\\pi_0 \\to \\pi_1 \\to \\pi_2$ to focus on more optimal regions of the true Q-value space.\nThe actions $a_1$ and $a_2$ found by $\\pi_1$ and $\\pi_2$ are indeed more optimal than $\\pi_0$ whose actions were only locally optimal peaks, but globally suboptimal.\nLanguage clarifications\nAs per the reviewer\u2019s suggestion, we have improved the language-ambiguous stataments:\n\"navigate the action-value landscape more proficiently\" \u2192 \u201cglobally optimize the Q-value landscape\u201d\nAn actor is trained with gradient ascent over the Q-value landscape and can get stuck in local optima, which we resolve.\n\"distribute the optimization load over to the critic\" \u2192 \u201cutilize the critic to evaluate multiple actions\u201d.\n\"This can make the learning procedure even slower than the original inefficiencies of the actor\" \u2192 \u201cA larger action space in the joint-actor-critic model present another optimization challenge, making this solution infeasible\u201d."}]}, {"Heading": "Official Review of Submission9227 by Reviewer ojfo", "Subheading": "Official ReviewbyReviewer ojfo23 Oct 2023, 23:39 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThe paper presents a novel reformulation of the actor by employing a sequence of sub-actors, which solves the problem of non-convex and high-dimensional, and non-stationary during action-value optimization landscape training. The logical assumption stated by the authors is an ensemble of successive actor-critic modules can collectively navigate the action-value landscape more proficiently than a single, monolithic actor. The authors demonstrate improvement over continuous and large discrete action space reinforcement learning tasks.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nThe paper is well written and well structured. The idea of successive actor modules for \"pruning\" all actions with Q-values lower than the baseline is interesting and (to the best of my knowledge) novel. The experimental setup (especially on large discrete action space RL tasks and more discontinuous variants of continuous RL tasks) appears rigorous.\nWeaknesses:\n1.The paper's central assumption feels reasonable, and the experiment seems to confirm it. But there is no theoretical proof.\n2.The key parts of the successive actor-critic modules adopt both \u2018deep-set\u2019 and \u2018FiLM\u2019 methods, but lack a description of potential advantages and an explanation of alternative methods.\n3.From the structure of the proposed method, it can fluidly integrated into other widely adopted RL algorithms. In the experiment, TD3 was selected as the baseline. Is it possible to add other RL methods to the ablation study to illustrate the applicability of the method.\n4.FIG. 1 is a diagram illustrating the core ideas of the paper. Can 'tractable' be explained from the perspective of real data in the experimental part? FIG. 4 seems intended to explain, but is insufficient.\nQuestions:\n1.Algorithm 1, line 17 has a prominent '{' symbol. What is the difference between $(s_t|A)$ and $(s_t,A)$ in formulas $a=\\pi_{i}(s_t|A)$ and $\\pi_{\\phi_i}(s_t,A)$.\n2.Legend should be added to FIG. 7, although it is related to FIG. 3.\n3.Although there is not enough time to go through the source code carefully, it is recommended that the method abbreviation be consistent in the code(called FLAIR) and the paper(called SAVO).\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n5: marginally below the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Thank you for your review! Here are our responses.", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:56 (modified: 23 Nov 2023, 07:16)EveryoneRevisions", "Content": "Comment:\nWe thank you for your constructive feedback. We appreciate your positive comments on the approach and experimental performance. We address your concerns below:\nFiLM, DeepSet Design Choices\nIn Appendix C.3 and C.4, we added the descriptions of Deepset along with other design choices of list-summarizers as well as Feature-wise Linear Modulation (FiLM). In short, Deepset effectively aggregates the information in the list input while FiLM helps to condition on preceding list-input. Those modules contribute to better training the list of actor-critics in SAVO.\nWe also added ablations in Appendix.D.2 & D.3 to compare (i) FiLM v/s no-FiLM and (ii) the choice of DeepSet v/s LSTM v/s Transformers to aggregate the information from previous selected actions. The results validated our choice of DeepSet as it is more scalable to an increasing number of actor-critic pairs. Also, we acknowledge that this design choice depends on the environment and the use-case as some tasks in continuous domains show that LSTM / Transformers outperform Deepset.\nVisual insights on central claim\n[New Figure.3]\nThe optimization landscape of Q-value concretely represents the landscape where the N-D action space represents the independent variable and the 1-D Q-value represents the dependent variable. For visualization, we map the action space to 2-D when N > 1. Fig.3 demonstrates that the Q-function becomes more easy to globally optmize with every iteration of our successive actor-critics. This is because the locally optimal peaks below past actions\u2019 Q-values are pruned away from the optimization landscape. As we can observe:\nThe number of local optima are reduced in $Q_0 \\to Q_1 \\to Q_2$, as most action values are shifted up in the Q-value space. This enables successive actors $\\pi_0 \\to \\pi_1 \\to \\pi_2$ to focus on more optimal regions of the true Q-value space.\nThe actions $a_1$ and $a_2$ found by $\\pi_1$ and $\\pi_2$ are indeed more optimal than $\\pi_0$ whose actions were only locally optimal peaks, but globally suboptimal\nClarifications of Baseline Selection\nWe choose TD3 because of its unified applicability to both action-representation-based discrete action spaces and continuous action space. Particularly, the Wolpertinger algorithm [Dulac et al 2015] is based on the DDPG algorithm and is the most commonly used base algorithm for large discrete action spaces. While we agree with the reviewer\u2019s suggestion that combining SAVO with SAC would be good to show wider applicability of our method, we think this extension might offer more flexibility in the design choices. Thus, for this project, we decided to stick to the simple architecture of TD3 as described above.\nNotational fixes\nWe have fixed all the suggested typos, missing legends, and source code naming in our revision. Thank you for your detailed suggestions.\nPlease do let us know if you have any leftover concerns or questions."}]}]}, "FMMF1a9ifL": {"paper_info": {"Code Of Ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "Keywords": "energy minimization, conformational optimization, geometry optimization", "Submission Guidelines": "I certify that this submission complies with the submission instructions as described onhttps://iclr.cc/Conferences/2024/AuthorGuide.", "TL;DR": "We propose a data-efficient framework for conformational energy minimization with neural networks", "Abstract": "Molecular conformation optimization is crucial to computer-aided drug discovery and materials design.\nTraditional energy minimization techniques rely on iterative optimization methods that use molecular forces calculated by a physical simulator (oracle) as anti-gradients.\nHowever, this is a computationally expensive approach that requires many interactions with a physical simulator.\nOne way to accelerate this procedure is to replace the physical simulator with a neural network.\nDespite recent progress in neural networks for molecular conformation energy prediction, such models are prone to errors due to distribution shift, leading to inaccurate energy minimization.\nWe find that the quality of energy minimization with neural networks can be improved by providing optimization trajectories as additional training data.\nStill, obtaining complete optimization trajectories demands a lot of additional computations.\nTo reduce the required additional data, we present the Gradual Optimization Learning Framework (GOLF) for energy minimization with neural networks.\nThe framework consists of an efficient data-collecting scheme and an external optimizer.\nThe external optimizer utilizes gradients from the energy prediction model to generate optimization trajectories, and the data-collecting scheme selects additional training data to be processed by the physical simulator. \nOur results demonstrate that the neural network trained with GOLF performs \\textit{on par} with the oracle on a benchmark of diverse drug-like molecules using significantly less additional data.", "Anonymous Url": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "No Acknowledgement Section": "I certify that there is no acknowledgement section in this submission for double blind review.", "Primary Area": "applications to physical sciences (physics, chemistry, biology, etc.)", "Submission Number": "9224", "PDF Url": "https://openreview.net/pdf?id=FMMF1a9ifL"}, "review_info": [{"Heading": "Paper Decision", "Subheading": "DecisionbyProgram Chairs16 Jan 2024, 06:53 (modified: 16 Feb 2024, 15:43)EveryoneRevisions", "Content": "Decision:\nAccept (poster)"}, {"Heading": "Meta Review of Submission9224 by Area Chair VMac", "Subheading": "Meta ReviewbyArea Chair VMac08 Dec 2023, 12:58 (modified: 16 Feb 2024, 15:31)EveryoneRevisions", "Content": "Metareview:\nThe paper first studied the out-of-distribution generalization challenge when using a neural network potential (NNP) which shows significantly more data than large static datasets are required for successful geometry optimization, then proposes the GOLF method, an active learning strategy that achieves successful geometry optimization with much fewer additional data. The empirical investigation is done in fine quality, and the empirical advantage seems significant. Generalization to larger-scale molecules is also demonstrated. Nevertheless, the proposed method does not seem particularly technically inspiring and requires a third predictor (in addition to the NNP and the accurate labeler). It also lacks comparison to other active learning methods (even in a smaller scale).\nJustification For Why Not Higher Score:\nThere remain weaknesses as mentioned in the Metareview.\nJustification For Why Not Lower Score:\nThe paper makes a valuable contribution to highlight the generalization issue of NNP in real use cases to the community, and proposes an effective method that addresses the problem to a certain promising extent. The authors seem to have addressed other issues raised by the reviewers."}, {"Heading": "General answer", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:46 (modified: 23 Nov 2023, 06:58)EveryoneRevisions", "Content": "Comment:\nWe thank all the reviewers for pointing out the flaws of the manuscript. This helped us to significantly improve the writing and the presentation of the paper. We list the main changes below and we will refer to them in personal answers:\nReworked and fixed \u201cNotaion and Preliminaries\u201d (including the renaming of GO and SO to $\\mathcal{O}_G, \\mathcal{O}_S$).\nMoved \u201cExternal Optimizers\u201d experiment to Appendix: results, yet interesting, are not of high importance for the paper.\nAdded metrics. We would like to thank the reviewer RbRE for pointing out that it is important to explain which percentage of optimized energy may be treated as the \u201csolution\u201d. We added the explanation of the\nchemical precision\nto the manuscript and provided additional energy metrics for all the models along with the percentage of \u201csolved\u201d conformations (we call it $\\operatorname{pct}_{\\text{success}}$), which is a percentage of final conformations with energy less than optimal plus\nchemical precision\n.\nExtended the evaluation of the proposed approach: a larger nablaDFT subset (19477 conformations) and a subset of SPICE (1832 conformations). We will extend the SPICE evaluation dataset in the camera-ready version.\nFixed Table 3 in Section 6.4 (\u201dLarger Molecules\u201d). The DFT computation timeout was initially chosen for smaller molecular size, we have found that increasing this parameter reduces the percentage of diverged optimizations.\nImproved writing and presentation of the manuscript.\nReleased the source code.\nExtended the appendix:\nAdded the hyperparameter tables and training details that were missing in the initial submit.\nAdded the description of nablaDFT dataset and the way the conformations are collected.\nAdded a visualization of final conformations for different optimization methods."}, {"Heading": "Official Review of Submission9224 by Reviewer DBvP", "Subheading": "Official ReviewbyReviewer DBvP05 Nov 2023, 01:03 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nThis paper introduces GOLF, a framework for improving molecular conformation optimization with neural networks. GOLF addresses distribution shift issues, enhancing energy prediction and optimization. It outperforms traditional methods and reduces the need for physical simulator interactions by 50 times.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n2 fair\nStrengths:\nThe development of the proposed GOLF is clear.\nDemonstrated outstanding performance in conformation optimization tasks.\nGeneralization to larger molecules.\nWeaknesses:\nDataset Limitation: The paper may be limited by the availability and diversity of datasets used for testing, potentially impacting the generalizability of the results.\nComplexity: It seems that the complexity of GOLF is not clearly discussed in the paper.\nPractical Implementation: Though the algorithm is not very complicated, this paper does not release code, which leaves me cautious about the practical implementation and complexity of the algorithm.\nOverall, while the paper presents valuable contributions, addressing these weaknesses could enhance its overall impact and relevance in the field of molecular conformation optimization.\nQuestions:\nSame with the 'weaknesses' part:\nWhy not use more datasets besides nablaDFT?\nWhat's the complexity of GOLF? It seems that you only show experiment results on subsets of nablaDFT. Is it because the computational complexity of the method is very high?\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to Official Review of Submission9224 by Reviewer DBvP (1/ 2)", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:23 (modified: 23 Nov 2023, 06:29)EveryoneRevisions", "Content": "Comment:\nWeaknesses\nWeakness 1\nDataset Limitation: The paper may be limited by the availability and diversity of datasets used for testing, potentially impacting the generalizability of the results.\nWe agree that the experimental section could benefit from a more diverse evaluation dataset. Therefore we significantly extended the main evaluation dataset (10x) by sampling more conformations with less than 35 atoms from the nablaDFT dataset. The extended evaluation dataset contains 20k conformations for X molecules. It contains  $\\mathcal{D}_{\\text{test}}$ as its subset.\nMoreover, we selected 1828 molecules (1 conformation per molecule) from the SPICE dataset, optimized them with $\\mathcal{O}_G$ to get the optimal energy. We evaluated all non-generative models from our paper on this new SPICE test set $\\mathcal{D}_{\\text{test}}^{\\text{SPICE}}$.\nWe provide the results in the table below. We understand that the size of the $\\mathcal{D}_{\\text{test}}^{\\text{SPICE}}$ may raise similar concerns, but we were unable to collect a larger dataset during the rebuttal due to the need for an expensive $\\mathcal{O}_G$ optimizations. We will extend the $\\mathcal{D}_{\\text{test}}^{\\text{SPICE}}$ to ~20k conformations and provide results for generative models in the camera-ready version.\nSPICE test (1828 conformations)\nOpenFF\nRDKit\n$f^{baseline}$\n$f^{traj-10k}$\n$f^{traj-100k}$\n$f^{traj-500k}$\n$f^{GOLF-1k}$\n$f^{GOLF-10k}$\n$SPICE-f^{baseline}$\n$SPICE-f^{GOLF-10k}$\n$\\overline{\\operatorname{pct}}_{100}$\n61.14\n77.58\n72.71\n73.22\n77.06\n80.25\n80.31\n82.41\n79.76\n86.59\n$\\operatorname{pct}_{\\text{div}}$\n5.38\n8.15\n27.73\n17.45\n16.02\n12.80\n13.56\n12.41\n23.08\n15.09\n$\\overline{E^{\\text{res}}_{100}}$\n12.58\n8.42\n13.62\n9.63\n8.09\n6.88\n6.63\n6.06\n6.06\n4.19\n$\\operatorname{pct}_{\\text{solved}}$\n0.05\n10.72\n6.35\n5.17\n15.90\n25.65\n17.53\n27.73\n8.91\n19.41\nThe OpenFF is a non-neural force field used in the original SPICE paper [1]. $SPICE-f^{baseline}$ was trained on ~10000 conformations (2.5 conformations per molecule) from the SPICE dataset. $SPICE-f^{GOLF-10k}$ was trained with the same hyperparameters as $f^{GOLF-10k}$ and used $SPICE-f^{baseline}$ to initialize the NNP. These preliminary results show that models trained on nablaDFT and SPICE datasets demonstrate comparable performance on $\\mathcal{D}_{\\text{test}}^{\\text{SPICE}}$.\nExtended test (19477 conformations)\nRDKit\n$f^{baseline}$\n$f^{rdkit}$\n$f^{traj-10k}$\n$f^{traj-100k}$\n$f^{traj-500k}$\n$f^{GOLF-10k}$\n$\\overline{\\operatorname{pct}}_{100}$\n85.47\n77.88\n93.04\n95.08\n96.15\n98.75\n98.78\n$\\operatorname{pct}_{\\text{div}}$\n0.62\n7.46\n4.43\n4.50\n2.77\n1.99\n2.98\n$\\overline{E^{\\text{res}}_{100}}$\n5.50\n8.58\n2.77\n1.96\n1.50\n0.53\n0.51\n$\\operatorname{pct}_{\\text{solved}}$\n4.05\n8.18\n35.42\n37.01\n52.71\n73.41\n77.26\nThese results show that all conclusions made in the first version of the paper hold on an extended evaluation dataset.\nWeakness 2\nComplexity: It seems that the complexity of GOLF is not clearly discussed in the paper.\nInference: GOLF uses NNPs that rely on Message Passing [2]. In the worst case, the computational complexity is quadratic in terms of the number of atoms in the molecule. We provide average inference time for baselines and NNPs and compare them with the average $\\mathcal{O}_G$. All the measurements were made on the same machine with a 16-core Intel(R) Xeon(R) Gold 6278C and a single Tesla V100 GPU. The results are in the table below.\nModel\nIterative Optimization with NNP (100 steps)\nConfOpt (single step)\nTorsional Diffusion (single step)\nUniMol+ (single step)\nIterative Optimization with $\\mathcal{O}_G$ (until convergence, ~25 steps on average)\nAverage Inference time (seconds)\n1.312\n0.005\n0.48\n0.002\n2634.787\nTraining: around 2/3 of the computational complexity during training comes from various NN operations. We use DFT-based oracle, which complexity is $O(N^4)$ [3]. For example, the training of the GOLF-10k on our machine with 120 workers for DFT calculations takes approximately 20 hours .\n[1] Eastman, P., Behara, P. K., Dotson, D. L., Galvelis, R., Herr, J. E., Horton, J. T., ... & Markland, T. E. (2023). Spice, a dataset of drug-like molecules and peptides for training machine learning potentials. Scientific Data, 10(1), 11.\n[2] Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., & Dahl, G. E. (2020). Message passing neural networks.\nMachine learning meets quantum physics\n, 199-214.\n[3] Kohn, W., & Sham, L. J. (1965). Self-consistent equations including exchange and correlation effects.\nPhysical review\n,\n140\n(4A), A1133."}, {"Heading": "Answer to Official Review of Submission9224 by Reviewer DBvP (2/ 2)", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:31 (modified: 23 Nov 2023, 05:59)EveryoneRevisions", "Content": "Comment:\nQuestions\nQuestion 1\nWhy not use more datasets besides nablaDFT?\nWe have not considered datasets such as QM9 and GEOM as they contain equilibrium conformations. We have not considered MD17 and other similar datasets due to the low diversity of the molecules.\nAdditionally, to answer your first question, we trained the $f^{\\text{baseline}}$ and the $f^{\\text{GOLF-10k}}$ on a subset of SPICE dataset. For the SPICE training set $\\mathcal{D}^{\\text{SPICE}}_{\\text{train}}$, we collected 4000 molecules with roughly 2.5 conformations per molecule resulting in approximately 10k conformations (the same size as $\\mathcal{D}_{\\text{train}}$). We evaluated these models both on the $\\mathcal{D}_{\\text{test}}^{\\text{SPICE}}$ and the extended $\\mathcal{D}_{\\text{test}}$. The results are in the table below.\nNablaDFT\n$f^{GOLF-10k}$\n$\\operatorname{SPICE}-f^{GOLF-10k}$\n$\\overline{\\operatorname{pct}}_{100}$\n98.78\n91.71\n$\\operatorname{pct}_{\\text{div}}$\n2.98\n12.69\n$\\overline{E^{\\text{res}}_{100}}$\n0.51\n3.27\n$\\operatorname{pct}_{\\text{solved}}$\n77.26\n17.27\nSPICE\n$f^{GOLF-10k}$\n$\\operatorname{SPICE}-f^{GOLF-10k}$\n$\\overline{\\operatorname{pct}}_{100}$\n82.41\n86.59\n$\\operatorname{pct}_{\\text{div}}$\n12.41\n15.09\n$\\overline{E^{\\text{res}}_{100}}$\n6.06\n4.19\n$\\operatorname{pct}_{\\text{solved}}$\n27.73\n19.41\nThe main take-away from these tables is that the percentage of optimizations solved is larger for the $f^{\\text{GOLF-10k}}$ trained on NablaDFT. This is likely due to the presence of near-optimal conformations in SPICE which can in theory result in collecting highly correlated training samples.\nQuestion 2\nWhat's the complexity of GOLF? It seems that you only show experiment results on subsets of nablaDFT. Is it because the computational complexity of the method is very high?\nThe high computational complexity of the evaluation procedure is tied to the need to optimize every conformation with $\\mathcal{O}_G$. Estimating the percentage of optimized energy and other reported metrics requires running a minimization procedure with a DFT-based oracle. For example, it takes ~593 CPU days to calculate optimal energies for 19477 conformations in the extended evaluation dataset. While the optimization of 19477 conformation with GOLF-10k takes ~7.1 hours on a single V100 GPU."}]}, {"Heading": "Official Review of Submission9224 by Reviewer bemc", "Subheading": "Official ReviewbyReviewer bemc01 Nov 2023, 00:21 (modified: 27 Nov 2023, 11:23)EveryoneRevisions", "Content": "Summary:\nThis paper proposes a gradual optimization learning framework (GOLF) for molecular conformation minimization. The framework is designed to improve the training of Neural Network Potentials (NNP). The authors first claim that NNPs trained on existing datasets suboptimal in energy minimization due to the distribution shift and perform experiments to show (a large amount of) additional data from the optimization trajectories can help improve the NNP's performance.  The GOLF framework uses a surrogate oracle (MMFF) to evaluate the conformation energy and expand the training data by selecting the incorrect prediction and re-evaluating with the genuine oracle (DFT), which reduces the required additional data. The experiments on the nablaDFT dataset demonstrate the effectiveness of the proposed method.\nSoundness:\n2 fair\nPresentation:\n2 fair\nContribution:\n2 fair\nStrengths:\nThe proposed method sounds reasonable and the experiments shows its effectiveness.  The method also looks easy to implement, which can improve the conformation energy minimization performance at a small cost.\nWeaknesses:\nThe writing is not very clear, especially in the introduction section. It takes me a while to understand simply enriching the training dataset is actually a preliminary baseline method the authors want to compare with. Also, lots of experiment details are mixed with the method, which makes the paper not very easy to read.\nThe calculation of COV and MAT looks problematic. It seems the authors optimize\none conformation per molecule\nand take them of the entire test set as the generation set. However, in the conformation generation setting, models generate\nmultiple conformations per molecule\nto construct the generation set, and then COV and MAT are calculated per molecule,  and finally the average / median of them on the entire test set is reported.\nQuestions:\nAre the conformations in nablaDFT dataset equilibrium ones or the intermediate state sampled from the optimization process? How large is the training set D0? More description about this dataset is needed.\nConfOpt and TorsionDiff are designed to generate equilibrium low-energy conformers, and not guaranteed to achieve a lower energy by repeatedly applied. Thus, I think it's unfair to compare these models with GOLF in terms of pct.\nThe statement of \"We hypothesize that in the case of ConfOpt, the main problems are the choice of the architecture and the fact that the model generates optimal conformations from SMILES and does not use initial geometries. \" doesn't make sense to me. ConfOpt takes the 2D molecular graph as input and also utilizes initial 3D conformations.\nDoes $f^{traj-10k /100k }$ keep the total number of updates equal to $5 \\times 10^5$? If so, please provide more training details, otherwise, the comparison between them and $f^{GOLF}$ is unfair.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to Official Review of Submission9224 by Reviewer bemc (1/2)", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:34 (modified: 23 Nov 2023, 06:49)EveryoneRevisions", "Content": "Comment:\nWeaknesses\nWeakness 1\nThe writing is not very clear, especially in the introduction section. It takes me a while to understand simply enriching the training dataset is actually a preliminary baseline method the authors want to compare with. Also, lots of experiment details are mixed with the method, which makes the paper not very easy to read.\nWe agree that some additional context regarding the use of $f^{\\text{traj-*}}$ as a baseline is needed. We added clarifying sentences in the revision of the manuscript. Unfortunately, we do not see a way to separate the method from some experiment details, as the GOLF is mainly motivated by the empirical results obtained in section 4. We believe that introducing our framework without a preliminary discussion of experimental details and results will be more confusing for the reader. We will be happy to consider any suggestions on improving the writing of the manuscript.\nWeakness 2\nThe calculation of COV and MAT looks problematic. It seems the authors optimize one conformation per molecule and take them of the entire test set as the generation set. However, in the conformation generation setting, models generate multiple conformations per molecule to construct the generation set, and then COV and MAT are calculated per molecule, and finally the average / median of them on the entire test set is reported.\nWe agree that such metrics are indeed not ideal for the conformation optimization task due to the problem you described above. However, we decided to compute these metrics to provide a fair comparison with ConfOpt and Torsional Diffusion, as the main results in these papers are reported in terms of COV and MAT.\nQuestions\nQuestion 1\nAre the conformations in nablaDFT dataset equilibrium ones or the intermediate state sampled from the optimization process? How large is the training set D0? More description about this dataset is needed.\nThe conformations in the nablaDFT are generated using the following procedure:\nFirst, several thousand different conformations per molecule are sampled using Rdkit's ETKG [1] based on a SMILES representation of the molecule.\nSecond, these conformations are clustered using Butina [2].\nThe authors then identify the smallest number of clusters needed to cover 95% of generated conformations.\nCentroids of these identified clusters are chosen and evaluated with a DFT-based oracle.\nThe training dataset contains 4000 molecules and 10000 conformations (~2.5 conformations per molecule). We apologize for not providing this information in the first version of the paper. We added this information in the revision. We also added a brief description of the nablaDFT dataset in the appendix of the revised manuscript.\nQuestion 2\nConfOpt and TorsionDiff are designed to generate equilibrium low-energy conformers, and not guaranteed to achieve a lower energy by repeatedly applied. Thus, I think it's unfair to compare these models with GOLF in terms of pct.\nWe would like to clarify that in our experiments, these models are trained to generate a single optimal conformation from an initial random conformation. We use these models in the intended way and do not repeatedly apply any of them. The training dataset for these models consists of optimal conformations obtained with $\\mathcal{O}_G$ and, thus, we expect them to generate optimal conformations, altough the inference of these models is different to $f^{\\text{GOLF-*}}$, we think it is still valuable to compare the generative approach (ConfOpt, TorsionDiff) with an iterative optimization approach.\nQuestion 3\nThe statement of \"We hypothesize that in the case of ConfOpt, the main problems are the choice of the architecture and the fact that the model generates optimal conformations from SMILES and does not use initial geometries. \" doesn't make sense to me. ConfOpt takes the 2D molecular graph as input and also utilizes initial 3D conformations.\nWe follow the original implementation [\nhttps://github.com/guanjq/confopt_official]\n, which takes the 2D molecular graph, generates a random conformation with Rdkit\u2019s ETKG, and optimizes it with MMFF. This implementation does not provide any means to supply the model with an initial conformation of our choice.\n[1] [Wang, S., Witek, J., Landrum, G. A., & Riniker, S. (2020). Improving conformer generation for small rings and macrocycles based on distance geometry and experimental torsional-angle preferences.\nJournal of chemical information and modeling\n,\n60\n(4), 2044-2058.]\n[2] Barnard, J. M., & Downs, G. M. (1992). Clustering of chemical structures based on two-dimensional similarity measures.\nJournal of chemical information and computer sciences\n,\n32\n(6), 644-649."}, {"Heading": "Answer to Official Review of Submission9224 by Reviewer bemc (2/2)", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:10Everyone", "Content": "Comment:\nQuestion 4\nDoes $f^{\\text{traj-10k/100k}}$ keep the total number of updates equal to $5 \\times 10^5$? If so, please provide more training details, otherwise, the comparison between them and is unfair.\nYes, the number of NN updates for all models except for $f^{\\text{traj-500k}}$ is equal to $5 \\times 10^5$. For $f^{\\text{traj-500k}}$ the number of updates is equal to $10^6$ as $5 \\times 10^5$ is not enough for the training to converge. We have added a table with hyperparameters along with an additional explanatory sentence in the appendix."}]}, {"Heading": "Official Review of Submission9224 by Reviewer HQch", "Subheading": "Official ReviewbyReviewer HQch31 Oct 2023, 23:04 (modified: 10 Nov 2023, 12:26)EveryoneRevisions", "Content": "Summary:\nIn the paper, the authors present Gradual Optimization Learning Framework (GOLF), a framework for improving the efficiency of generating low-energy molecular conformation prediction models, a crucial technology used in computer-aided drug discovery and materials design.\nOverall, the paper is well written and presents some valuable insights into applying active learning efficiently for the discovery of energy minimized conformations. Traditional approaches, such as Density-functional theory (DFT) models, use high-fidelity physics-based numerical quantum chemistry simulators whose computational costs are exponential with respect to the complexity of the molecule under study. Unfortunately, this limits their applicability to simple molecules with few atoms or electrons. To address computational complexity and to scale conformal optimization to more complex molecules, researchers have explored various alternatives based on lower fidelity linear models and, more recently, neural network models that leverage the availability of computed quantum property molecular databases. Sadly, these alternate approaches lead to inaccurate predictions and suffer from distribution shift. To scale conformal energy prediction to larger molecules while addressing computational cost, the authors propose GOLF, an automated data augmentation scheme and a hybrid computational approach that combines the use of both high and low-fidelity simulators as well as neural networks.\nIn Section 1, the authors present the concept of low-energy molecular conformations and their uses. This section is well written and provides an adequate background of the approach and the insights that motivate the solution. The authors indicate that the fundamental problem with traditional approaches, such as DFT, to obtain optimal conformations is their high computational cost. These approaches, which are based on numerical quantum chemistry simulations that calculate anti-gradients representing molecular forces, are iterative by nature and, when given a sufficiently complex molecule or physical system, may fail to complete even a single iteration. For this reason, the authors claim that \u201creducing the number of interactions with the physical simulator\u201d is crucial for efficiency. The authors then go on to describe current methods that apply Neural Network Potentials (NNP), a form of deep neural networks, to the problem. NNP-based techniques significantly reduce computational complexity by using the gradients inherent to neural networks to model the molecular forces, thereby obviating the need for expensive simulations. Unfortunately, the NNP approach suffers from distribution shift resulting in inaccurate predictions. The authors then introduce GOLF, which employs a data augmentation active learning scheme to improve the diversity of the training dataset, thereby alleviating the distribution shift. By doing so, GOLF achieves energy minimized conformation prediction accuracy comparable with that of high-fidelity simulations while retaining the intrinsic efficiencies gained by using neural networks. A novel framework for data-efficient training of NNPs, GOLF comprises three components: 1) a computationally expensive high-fidelity simulation that is a genuine oracle (GO) used to calculate the ground truth energies and forces; 2) an optimizer that uses the NNP gradients to produce optimization trajectories that constitute the additional training dataset; and 3) a computationally inexpensive low-fidelity simulation that is a surrogate oracle (SO) used to augment the training dataset. Finally, the authors then conclude this section by summarizing their contributions.\nHowever, there are various weaknesses in this section as well that can be addressed to improve the quality of the paper. 1) The statement that \u201creducing the number of interactions with the physical simulator\u201d is unclear and the reviewer assumes the efficiency objective is attained by reducing the number of iterations required to produce optimal low-energy conformations. 2) The authors state that they augment the dataset with \u201coptimization trajectories\u201d without explaining what such a trajectory is and how the trajectories address distribution shift. At a minimum, providing a reference to the discussion of augmented data in Section 5 would be useful. 3) Moreover, as GOLF requires running the high-fidelity simulation, GO, to produce the anti-gradients, it is unclear whether GOLF can be successful when GO fails to complete a single iteration. This is a serious flaw in the paper and needs to be addressed. 4) In addition, the \u201cAb initio property\u201d phrase is used without a definition or description and seems rather superfluous to the narrative. 5) The adequacy of the requirement for 5 X 105  \u201cadditional oracle interactions\u201d, which presumably means optimization trajectories that augment the training dataset, is likely anecdotal based on the molecules selected for the experiments. If that is not the case, an explanation of why it is generally applicable should be articulated.\nIn the \u201cRelated Works\u201d section (Section 2), the authors describe a variety of contemporary approaches to conformation generation. The benefits and drawbacks of these methods are discussed. However, it is not clear to the reviewer how GOLF addresses the drawbacks of these approaches. Successfully addressing the drawbacks could demonstrate GOLF\u2019s superiority. Also, form the exposition in this section, it is not clear how significantly different the GOLF approach is to the active learning technique presented by Kulichecnko et al. (2023). Finally, the phrase \u201cwe believe it is necessary to explore further the ability \u2026\u201d is confusing. Are the authors proposing future work or teeing up the discussion in the remainder of the paper?\nIn the \u201cNotations and Preliminaries\u201d section (Section 3), the authors summarize the theoretical foundation of their approach. Although informative, the notation is somewhat cryptic and can benefit from slightly greater verbosity or additional graphics. Also, mentioning GOLF models in this section, without any discussion as to what they are or how they differ from ftraj, seems premature and confusing. At the very least, there should be a forward reference to Section 5 that articulates how GOLF intelligently identifies the datasets that promote diversity, which enhances prediction performance. Moreover, a small discussion of the NNP architecture used in the experimentation would be useful for the sake of completeness.\nSection 4 presents \u201cConformation Optimization\u201d. This section is well written and the both the graphic, Figure 1, and the table, Table 1, provide valuable insight. The Figure 1 graphic clearly depicts the distribution shift, in terns of Mean Square Error (MSE), increasing as the optimization progresses. The graphic also depicts that the prediction accuracy improves \u2013 MSE decreases \u2013 when augmenting the training dataset with GO produced optimization trajectories. This is an important result but without highlighting it, the reader can easily miss that it is one of the contributions of the paper. Table 1 seems to be highlighting precision of the approach, but the word is not used in the discussion. It is unclear to the reviewer as to the innovativeness of the approach, which may be construed as a weakness. Moreover, using the GO to provide the baseline training dataset may limit the scalability of the approach.\nThe authors present a sound argument in Section 5 where they present the GOLF algorithm and discuss using a high-performance low-cost surrogate oracle to make the data generation computationally tractable. The \u201cExperiments\u201d section, Section 6 is reasonably complete though much of the discussion seems anecdotal. The reviewer is unable to determine how many of the experimental results were achieved through a fortuitous selection of the molecules under study. Also, the authors report that the GOLF technique can produce \u201ca high percentage of diverged conformations\u201d. This is not surprising as the training dataset is likely to be much noisier as a result of the choice to use a low-cost simulation. It would be nice to get better characterization of the noise and its effects, including the loss in efficiency resulting from these unusable conformations.\nSections 7, 8, and Appendices conclude the paper. An explicit tie back to the goals and contributions identified in the Introduction would be beneficial.\nSoundness:\n3 good\nPresentation:\n3 good\nContribution:\n3 good\nStrengths:\nOverall, the paper is well written and informative. It seems relevant to improving the computational tractability of conformational energy minimization. The insight to use active learning to address the distribution shift and improve accuracy is valuable. Also, the approach to active learning by using low-cost simulation to augment the training data set without impacting the quality of the subsequent model is somewhat innovative.\nWeaknesses:\nThe various weaknesses are already detailed above. Here I summarize the most important ones. Using GO to generate the baseline dataset may limit the scalability of the approach. It is unclear why the authors do not use the molecular databases they mention in the \u201cIntroduction\u201d section to extract the baseline dataset. Some of the discussion is somewhat cryptic and can benefit from some additional discussion or graphics. The results seem anecdotal, tied to the selected dataset and molecules, and thus may not generalize particularly well.\nQuestions:\nSuggestions:\nClean up the use of \"interactions with the physical simulator\" and the \"number of iterations\" in several locations in the paper. They seem to imply the same concept. If they are, just use a single phrase for both.\nAdditional references early on in the paper to the results later on in the paper will help the reader question many of the seemingly unsupported statements.\nA better tie-in to how GOLF addresses the drawbacks of the \"Related Works\" section will improve the quality of  the paper.\nReduce the amount of mathematical notation in the \u201cNotations and Preliminaries\u201d section (Section 3) to simplify the narrative and improve understandability.\nThe main result in Section 4, the decrease in MSE by augmenting the dataset, should be highlighted and tied-in to the wording of the contributions listed in the introduction section of the paper.\nQuestions:\nGOLF requires running the high-fidelity simulation, GO, to produce the anti-gradients initial training data. In a different section of the paper, the claim is that for a sufficiently complex system, the physical simulation may not succeed in completing even a single iteration in a reasonable amount of time. Taken together, these two statements seem to suggest that GOLF is atomic complexity scale limited. How do the authors claim to address this apparent limitation?\nIn the Experiments section (Section 6), how much of the results are related to the selection of the molecules under study? Stated differently, how do the authors plan to address the generalizability of the approach?\nThe additional data generated for Active Learning are selected based only on errors. Without some sort of approach to balance the introduction of new data, does the approach bias the dataset distribution causing the learned distribution to fail to generalize to other molecules?\nHow different is the GOLF approach from the active learning technique presented by Kulichecnko et al. (2023).\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n6: marginally above the acceptance threshold\nConfidence:\n3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to Official Review of Submission9224 by Reviewer HQch (1/4)", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:27 (modified: 23 Nov 2023, 06:35)EveryoneRevisions", "Content": "Comment:\nWe appreciate your suggestions on improving the writing of the introduction. We found them very useful and incorporated the proposed modifications in the revised manuscript. We summarize the changes below:\nIntroduction\nThe statement that \u201creducing the number of interactions with the physical simulator\u201d is unclear\nWe replaced this sentence with the following: \u201cTherefore, it is crucial to develope alternative approaches (such as Neural Networks-based) that reduce the computational complexity of iterative optimization.\u201d\nThe authors state that they augment the dataset with \u201coptimization trajectories\u201d without explaining what such a trajectory is and how the trajectories address distribution shift.\nWe added a reference to Section 4.\nMoreover, as GOLF requires running the high-fidelity simulation, GO, to produce the anti-gradients, it is unclear whether GOLF can be successful when GO fails to complete a single iteration.\nWe reworked this sentence: \u201cHowever, for large molecules even a single iteration may take up several hours of CPU-compute.\u201c\nConsidering your question, refer to the answer to Question 1.\nIn addition, the \u201cAb initio property\u201d phrase is used without a definition or description and seems rather superfluous to the narrative.\n\u201c\nAb initio\n\u201d is a latin term that means \u201cfrom first principles\u201d. It is widely used in quantum chemistry literature implying that the only inputs into an\nab initio\ncalculation are\u00a0physical constants.\nThe adequacy of the requirement for $5 \\times 10^5$ \u201cadditional oracle interactions\u201d, which presumably means optimization trajectories that augment the training dataset, is likely anecdotal based on the molecules selected for the experiments. If that is not the case, an explanation of why it is generally applicable should be articulated.\nWe agree that this constant may not hold on another dataset. However, we believe that the reduction in the amount of required oracle interactions will still be significant. We decided to remove $5 \\times 10^5$ from the abstract and the intro, replacing it with a more appropriate statement.\nNotation and preliminaries\nThe notation is somewhat cryptic and can benefit from slightly greater verbosity or additional graphics.\nWe reworked the notation in the revised version of the manuscript.\nAlso, mentioning GOLF models in this section, without any discussion as to what they are or how they differ from ftraj, seems premature and confusing.\nWe added a reference to Section 5.\nMoreover, a small discussion of the NNP architecture used in the experimentation would be useful for the sake of completeness.\nWe listed all the hyperparameters in Appendix.\nConformation Optimization with NNPs\nThis is an important result but without highlighting it, the reader can easily miss that it is one of the contributions of the paper.\nWe referenced Figure 1 in the contributions section.\nIt is unclear to the reviewer as to the innovativeness of the approach, which may be construed as a weakness. Moreover, using the GO to provide the baseline training dataset may limit the scalability of the approach.\nWhile working on the topic of molecular optimization, we found that this area is severely under-researched. To the best of our knowledge, there are no papers that present the idea of enriching the training dataset with optimization trajectories. However, in this year Open Catalyst challenge [\nhttps://opencatalystproject.org/challenge.html]\n, a similar dataset of optimization trajectories for adsorbate-catalyst pairs has been published. We will cite the OCP23 challenge in the revision."}, {"Heading": "Answer to Official Review of Submission9224 by Reviewer HQch (2/4)", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:30 (modified: 23 Nov 2023, 06:35)EveryoneRevisions", "Content": "Comment:\nExperiments\nThe \u201cExperiments\u201d section, Section 6 is reasonably complete though much of the discussion seems anecdotal. The reviewer is unable to determine how many of the experimental results were achieved through a fortuitous selection of the molecules under study.\nIn our experiments, we use a randomly selected subset $\\mathcal{D}_0$ of the nablaDFT dataset. The conformations in the nabla DFT dataset are generated based on SMILES representations of molecules from the MOSES dataset. The MOSES dataset consists of a large number of druglike molecules and is considered to be representative.  To ensure reasonable computational cost of DFT computations, the subset  $\\mathcal{D}_0$ is limited to molecules with number of atoms < 36. However, apart from the increased computational cost we do not forsee any issues with using GOLF with bigger molecules.\nTherefore we significantly extended the main evaluation dataset (10x) by sampling more conformations with less than 35 atoms from the nablaDFT dataset. The extended evaluation dataset contains 20k conformations for X molecules. It contains  $\\mathcal{D}_{\\text{test}}$ as its subset.\nMoreover, we selected 1828 molecules (1 conformation per molecule) from the SPICE dataset, optimized them with $\\mathcal{O}_G$ to get the optimal energy. We evaluated all non-generative models from our paper on this new SPICE test set $\\mathcal{D}_{\\text{test}}^{\\text{SPICE}}$.\nWe provide the results in the table below. We understand that the size of the $\\mathcal{D}_{\\text{test}}^{\\text{SPICE}}$ may raise similar concerns, but we were unable to collect a larger dataset during the rebuttal due to the need for an expensive $\\mathcal{O}_G$ optimizations. We will extend the $\\mathcal{D}_{\\text{test}}^{\\text{SPICE}}$ to ~20k conformations and provide results for generative models in the camera-ready version.\nSPICE test (1828 conformations)\nOpenFF\nRDKit\n$f^{baseline}$\n$f^{traj-10k}$\n$f^{traj-100k}$\n$f^{traj-500k}$\n$f^{GOLF-1k}$\n$f^{GOLF-10k}$\n$SPICE-f^{baseline}$\n$SPICE-f^{GOLF-10k}$\n$\\overline{\\operatorname{pct}}_{100}$\n61.14\n77.58\n72.71\n73.22\n77.06\n80.25\n80.31\n82.41\n79.76\n86.59\n$\\operatorname{pct}_{\\text{div}}$\n5.38\n8.15\n27.73\n17.45\n16.02\n12.80\n13.56\n12.41\n23.08\n15.09\n$\\overline{E^{\\text{res}}_{100}}$\n12.58\n8.42\n13.62\n9.63\n8.09\n6.88\n6.63\n6.06\n6.06\n4.19\n$\\operatorname{pct}_{\\text{solved}}$\n0.05\n10.72\n6.35\n5.17\n15.90\n25.65\n17.53\n27.73\n8.91\n19.41\nThe OpenFF is a non-neural force field used in the original SPICE paper [1]. $SPICE-f^{baseline}$ was trained on ~10000 conformations (2.5 conformations per molecule) from the SPICE dataset. $SPICE-f^{GOLF-10k}$ was trained with the same hyperparameters as $f^{GOLF-10k}$ and used $SPICE-f^{baseline}$ to initialize the NNP. These preliminary results show that models trained on nablaDFT and SPICE datasets demonstrate comparable performance on $\\mathcal{D}_{\\text{test}}^{\\text{SPICE}}$.\nExtended test (19477 conformations)\nRDKit\n$f^{baseline}$\n$f^{rdkit}$\n$f^{traj-10k}$\n$f^{traj-100k}$\n$f^{traj-500k}$\n$f^{GOLF-10k}$\n$\\overline{\\operatorname{pct}}_{100}$\n85.47\n77.88\n93.04\n95.08\n96.15\n98.75\n98.78\n$\\operatorname{pct}_{\\text{div}}$\n0.62\n7.46\n4.43\n4.50\n2.77\n1.99\n2.98\n$\\overline{E^{\\text{res}}_{100}}$\n5.50\n8.58\n2.77\n1.96\n1.50\n0.53\n0.51\n$\\operatorname{pct}_{\\text{solved}}$\n4.05\n8.18\n35.42\n37.01\n52.71\n73.41\n77.26\nThese results show that all conclusions made in the first version of the paper hold on an extended evaluation dataset.\n[1] Eastman, P., Behara, P. K., Dotson, D. L., Galvelis, R., Herr, J. E., Horton, J. T., ... & Markland, T. E. (2023). Spice, a dataset of drug-like molecules and peptides for training machine learning potentials. Scientific Data, 10(1), 11."}, {"Heading": "Answer to Official Review of Submission9224 by Reviewer HQch (3/4)", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:32 (modified: 23 Nov 2023, 06:34)EveryoneRevisions", "Content": "Comment:\nAlso, the authors report that the GOLF technique can produce \u201ca high percentage of diverged conformations\u201d. This is not surprising as the training dataset is likely to be much noisier as a result of the choice to use a low-cost simulation. It would be nice to get better characterization of the noise and its effects, including the loss in efficiency resulting from these unusable conformations.\nFirst, we would like to stress that we do not use the low-cost simulation neither to estimate energies/forces for the newly collected data, nor to generate conformations for training. To estimate energies and forces, we use DFT. Additional conformations for training are generated during the optimization with the NNP. The low-cost simuator is used to select a single conformation from the optimization trajectory. This selected conformation is then evaluated with the DFT-based oracle and added to the training set.\nSecond, the \u201chigh percentage of diverged conformations\u201d refers to the experiment in Section 6.4 (applying NNP trained with GOLF  to larger molecules than in the training dataset). In our code, the optimization is considered diverged either when the initial energy is lower than the final energy or when the DFT-worker is timed out. For small molecules in $\\mathcal{D}\n0, \\mathcal{D}\n{\\text{test}}$ this happens when the resulting conformation is poor, but we found that for larger molecules this can also happen with reasonable near-optimal conformations. We also found that increasing the timeout value solves this problem (see updated table in section 6.4).\nWe extended the $\\mathcal{D}_{\\text{LM}}$ to 2000 molecules (1 conformation per molecule) and re-evaluated NNPs with the increased timeout value. We updated section 6.4 in the revision. As it can be seen from the updated Table 3, $f^{\\text{GOLF-10k}}$ on large molecules experiences a small performance drop, while retaining the same percentage of diverged optimizations.\nWeaknesses\nWeakness 1\nUsing GO to generate the baseline dataset may limit the scalability of the approach. It is unclear why the authors do not use the molecular databases they mention in the \u201cIntroduction\u201d section to extract the baseline dataset.\nFirst, the limited scalability of this approach is stated as the main motivation for our proposed GOLF framework. Second, we would like to note that we are not aware of any molecular databases that contain optimization trajectories. In our paper, we identify enriching the training dataset $\\mathcal{D}_0$ with optimization trajectories as a crucial step to overcome the distribution shift. In Figure 1, we illustrate that enriching the training dataset with optimization trajectories helps alliviate the distribution shift. We agree, that in theory, datasets containing both near-optimal and sub-optimal conformations can be used to improve the optimization quality of NNPs. To test that, we trained a baseline model $\\operatorname{SPICE}-f^{\\text{baseline}}$ on a subset of SPICE dataset and showed that it suffers from the similar issues (see answer to \u201cExperiments\u201d section).\nWeakness 2\nSome of the discussion is somewhat cryptic and can benefit from some additional discussion or graphics.\nWe appreciate your suggestions on improving the writing of our paper! Following various ideas proposed by the reviewers we have reworked the manuscript and uploaded a corrected version as a revision. If you still have any concerns or suggestions, please let us know. We will be happy to improve the writing further.\nWeakness 3\nThe results seem anecdotal, tied to the selected dataset and molecules, and thus may not generalize particularly well\nIn order to resolve this concern, we decided to provide additional experiments both on a bigger subset of nablaDFT dataset and a subset of SPICE dataset. See answer to \u201cExperiments\u201d section for more details."}, {"Heading": "Answer to Official Review of Submission9224 by Reviewer HQch (4/4)", "Subheading": "Official CommentbyAuthors23 Nov 2023, 06:34Everyone", "Content": "Comment:\nQuestions\nQuestion 1\nGOLF requires running the high-fidelity simulation, GO, to produce the anti-gradients initial training data. In a different section of the paper, the claim is that for a sufficiently complex system, the physical simulation may not succeed in completing even a single iteration in a reasonable amount of time. Taken together, these two statements seem to suggest that GOLF is atomic complexity scale limited. How do the authors claim to address this apparent limitation?\nYes, the GOLF indeed requires a high-fidelity simulator to collect the training data which may may fail on a sufficiently complex system. However, any deep learning model that aims to match the quality of the physical simulator is subject to the same limitation. Motivated by this limitation, we tested the generalization of NNPs trained with GOLF to larger molecules (see section 6.4).\nQuestion 2\nIn the Experiments section (Section 6), how much of the results are related to the selection of the molecules under study? Stated differently, how do the authors plan to address the generalizability of the approach?\nPlease see the answer to Weakness 3.\nQuestion 3\nThe additional data generated for Active Learning are selected based only on errors. Without some sort of approach to balance the introduction of new data, does the approach bias the dataset distribution causing the learned distribution to fail to generalize to other molecules?\nFirst of all, we would like to note that we test the NNPs on a subset from the same distribution than the train dataset. The train dataset $\\mathcal{D}_0$ and the evaluation dataset $\\mathcal{D}_{\\text{test}}$ share no molecules. Our evaluation results described in Section 6.1 and 6.2 show that the NNP successfully generalizes to unseen molecules from the same distribution. Considering the balancing of the new data, we use the following technique: 10% of each mini-batch is sampled from the initial training dataset $\\mathcal{D}_0$. We have added this detail to the appendix of the revised manuscript.\nQuestion 4\nHow different is the GOLF approach from the active learning technique presented by Kulichecnko et al. (2023).\nThe method presented in the Kulichenko et al. paper is an interesting and promising approach for the exploration of the configuration space of a single molecule. Unfortunately, it requires training a new NNP ensemble for each new molecule, which is a completely different problem setup compared with ours. Moreover, the focus of the method is to enrich the MD trajectories with the conformations for which the ensemble is uncertain, which is shown to improve the energy prediction. In theory, this approach may also improve the atomic forces prediction, but it remains to be studied."}]}, {"Heading": "Official Review of Submission9224 by Reviewer RbRE", "Subheading": "Official ReviewbyReviewer RbRE31 Oct 2023, 22:37 (modified: 27 Nov 2023, 10:58)EveryoneRevisions", "Content": "Summary:\nThe authors propose an active learning approach to train neural network potentials by employing a cheap surrogate oracle before querying the much more expensive genuine oracle.\nSoundness:\n2 fair\nPresentation:\n4 excellent\nContribution:\n3 good\nStrengths:\nThe paper is very well written with clear insight and motivation. The method is very neat and the results are promising. I am excited to see more work that follows these mixed genuine and surrogate oracle approach.\nWeaknesses:\nAdditional baselines and metrics could make the result stronger.\nIn terms of the baseline, the true innovation of the framework is the \"active learning\" component, and not \"conformer generation\" itself. Therefore, the baseline conversation probably should focus on other active learning approaches such as Kulichenko et al (2023) or Chem et al. (2019). While these methods require OG, the author can still compare to these methods by contrasting the OG query budget to the same amount, but use random selection instead of SG estimates as proposed by GOLF. The comparison to TD/ConfOpt, while interesting, the problem setup and training data requirement are very different from what the authors are trying to demonstrate here.\nIn terms of the metrics, it would be very helpful if the authors can provide more context about why \"percentage of minimized energy\" is a meaningful metric, and why >98% is considered solving the optimization. If >98% is broadly considered as solving the optimization, can the authors report what percentage of targets in the test set is \"solved\" under different experiment setup?\nQuestions:\nI would consider raising my score if the authors can address my concerns around baselines and metrics as mentioned in the Weaknesses section.\nFlag For Ethics Review:\nNo ethics review needed.\nRating:\n8: accept, good paper\nConfidence:\n4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\nCode Of Conduct:\nYes", "Replies": [{"Heading": "Answer to Official Review of Submission9224 by Reviewer RbRE", "Subheading": "Official CommentbyAuthors23 Nov 2023, 05:05 (modified: 23 Nov 2023, 06:52)EveryoneRevisions", "Content": "Comment:\nWeakness 1\nIn terms of the baseline, the true innovation of the framework is the \"active learning\" component, and not \"conformer generation\" itself. Therefore, the baseline conversation probably should focus on other active learning approaches such as Kulichenko et al (2023) or Chem et al. (2019). While these methods require OG, the author can still compare to these methods by contrasting the OG query budget to the same amount, but use random selection instead of SG estimates as proposed by GOLF.\nThe method (UDD) presented in Kulichenko et al. (2023) is designed for the exploration of the configuration space of a\nsingle\nmolecule. The method generates new data by running molecular dynamics from a set of initial conformations. To better explore the space, the energy in molecular dynamics is augmented with a $E_{\\text{bias}}$ term that encourages the MD to sample conformations from regions of configuration space where the ensemble of NNPs is uncertain. In theory, this approach may also improve the atomic forces prediction, which would help the solution of the optimization task, but it remains to be studied. However, the UDD requires training a new NNP ensemble for each new molecule, which is a completely different problem setup compared with the one in our study. While it is an interesting task to adjust the UDD for the multi-molecule setup, we believe it is out of the scope of the current study.\nIf we understood you correctly, by Chem et al.(2019) you meant Chan et al. (2019) - \"Bayesian optimization for conformer generation\". While interesting, this approach requires DFT calculations during the inference, whereas GOLF only interacts with the oracle during the training phase and thus is more efficient.\nWeakness 2\nThe comparison to TD/ConfOpt, while interesting, the problem setup and training data requirement are very different from what the authors are trying to demonstrate here.\nWe agree that the generative setting is sufficiently different from the iterative optimization one. However, it is possible to formulate the problem of finding optimal geometries as a generative task. If it is possible to generate optimal geometries directly (e.g., without further relaxation), our framework would be superfluous. Contrary to this, our experiments show that it is still unclear if the generative models can achieve comparable performance.\nWeakness 3\nIn terms of the metrics, it would be very helpful if the authors can provide more context about why \"percentage of minimized energy\" is a meaningful metric, and why >98% is considered solving the optimization. If >98% is broadly considered as solving the optimization, can the authors report what percentage of targets in the test set is \"solved\" under different experiment setup?\nThank you very much for pointing this out! Generally accepted chemical precision is 1 kcal/mol [1]. The average total optimized energy is 43.2 kcal/mol therefore 2% is about the chemical precision. We removed the \"2%\" from the manuscript as it is indeed more correct to reason about being \u201c\non par\n\u201d with the optimizer in terms of chemical precision. Following your suggestion, we decided to add the percentage of \u201csolved\u201d conformations (we call it $\\operatorname{pct}_{\\text{solved}}$) as one of the metrics for all the experiments. We found that it helps to better demonstrate the superiority of the GOLF compared to the baseline approaches.\n[1] Helgaker, T., Ruden, T. A., J\u00f8rgensen, P., Olsen, J., & Klopper, W. (2004). A priori calculation of molecular properties to chemical accuracy.\nJournal of Physical Organic Chemistry\n,\n17\n(11), 913-933."}]}]}}